{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "----------------Preprocessing the data-------------------\n",
      "The total number of training samples = 11050\n",
      "The total number of validation samples = 1950\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "\n",
    "np.random.shuffle(X_train.to_numpy()) #Randomly shuffle the training data for batching\n",
    "\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "print(\"----------------Preprocessing the data-------------------\")\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "\n",
    "#Separating 15% of the training Data as Validation Dataset\n",
    "X_valid = X_train.iloc[(int(0.85*m)):]\n",
    "valid_class = train_class[(int(0.85*m)):]\n",
    "X_train = X_train.iloc[0:int(0.85*m)]\n",
    "train_class = train_class[0:int(0.85*m)]\n",
    "\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The total number of validation samples = {}\".format(X_valid.shape[0]))\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n",
      "--------------------Done----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "valid_class_enc = pd.get_dummies(valid_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()\n",
    "print(\"--------------------Done----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Adding the intercept term in the dataset as bias------------\n",
      "-----------------------------Done----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "print(\"--------Adding the intercept term in the dataset as bias------------\")\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_valid = np.hstack((np.ones((X_valid.shape[0],1)), X_valid.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))\n",
    "print(\"-----------------------------Done----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Forming mini-batches of size 100---------------------\n",
      "The number of mini-batches formed is = 111\n"
     ]
    }
   ],
   "source": [
    "#Mini-Batch formation\n",
    "\n",
    "batch_size = 100 # Mini-Batch Size\n",
    "\n",
    "print(\"----------------Forming mini-batches of size {}---------------------\".format(batch_size))\n",
    "mini_batch = [(X_train[i:i+batch_size,:], train_class_enc[i:i+batch_size]) for i in range(0, m, batch_size)]\n",
    "print(\"The number of mini-batches formed is = {}\".format(len(mini_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta Initialization \n",
    "\n",
    "def theta_init(n, r, arch=[50], mode='normal'):\n",
    "    theta = []\n",
    "    for i in range(len(arch)+1):\n",
    "        if i == 0:\n",
    "            dim0=n+1\n",
    "            dim1=arch[i]\n",
    "        elif (i == len(arch)):\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1 = r\n",
    "        else:\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1= arch[i]\n",
    "        if (mode=='normal'):\n",
    "            theta.append(np.random.normal(0,0.05, (dim0,dim1)))\n",
    "        elif(mode=='random'):\n",
    "            theta.append(2*np.random.random((dim0, dim1))-1)\n",
    "        elif(mode=='uniform'):\n",
    "            theta.append(np.random.uniform(-0.05,0.05, (dim0,dim1)))\n",
    "            \n",
    "        #theta.append(np.zeros((dim0, dim1)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#ReLU Activation Function\n",
    "def relu_act(x):\n",
    "    return np.maximum(0.0, x)\n",
    "\n",
    "#Derivative of ReLU activation Function\n",
    "def deriv_relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))\n",
    "\n",
    "def deriv_softplus(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "\n",
    "def forward_prop(data, theta, act_fn='sigmoid'):\n",
    "    fm = []\n",
    "    fm.append(data)\n",
    "    #Sigmoid Activation Function \n",
    "    if (act_fn == 'sigmoid'):\n",
    "        for l in range(len(theta)):\n",
    "            fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "            if (l!=len(theta)-1):\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1])) #Add intercept term as bias for each layer\n",
    "    #ReLU Activation Function \n",
    "    elif(act_fn == 'relu'):\n",
    "        for l in range(len(theta)):\n",
    "            if (l != len(theta)-1):\n",
    "                fm.append(relu_act(np.dot(fm[l], theta[l])))\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1])) #Add intercept term as bias for each layer\n",
    "            else:\n",
    "                fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "    #Softplus Activation Function       \n",
    "    elif(act_fn == 'softplus'):\n",
    "        for l in range(len(theta)):\n",
    "            if (l != len(theta)-1):\n",
    "                fm.append(softplus(np.dot(fm[l], theta[l])))\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1])) #Add intercept term as bias for each layer\n",
    "            else:\n",
    "                fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward_prop(fm, Y_b, theta, batch_size, act_fn='sigmoid', cost_fn='sqr_error'):\n",
    "    delta = [None]*len(fm)\n",
    "    for l in range(len(fm)-1, 0, -1):\n",
    "        if (l == len(fm)-1):\n",
    "            if (cost_fn=='entropy'):\n",
    "                delta[l] = ((1/batch_size)*((Y_b/fm[l])-((1-Y_b)/(1-fm[l])))*fm[l]*(1-fm[l])) #Entropy Loss\n",
    "            else:\n",
    "                delta[l] = ((1/batch_size)*(Y_b - fm[l])*fm[l]*(1-fm[l])) #MSE\n",
    "        elif (l+1 == len(fm)-1):\n",
    "            if (act_fn == 'sigmoid'):\n",
    "                delta[l]=(np.dot(delta[l+1], theta[l].T)*fm[l]*(1-fm[l]))\n",
    "            elif(act_fn == 'relu'):\n",
    "                delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_relu(fm[l])\n",
    "            elif(act_fn=='softplus'):\n",
    "                delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_softplus(fm[l])\n",
    "        else:\n",
    "            if (act_fn == 'sigmoid'):\n",
    "                delta[l]=(np.dot(delta[l+1][:,1:], theta[l].T)*fm[l]*(1-fm[l])) #To remove delta corresponding to bias node\n",
    "            elif(act_fn == 'relu'):\n",
    "                delta[l]=np.dot(delta[l+1][:,1:], theta[l].T)*deriv_relu(fm[l])\n",
    "            elif(act_fn=='softplus'):\n",
    "                delta[l]=np.dot(delta[l+1][:,1:], theta[l].T)*deriv_softplus(fm[l])\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function \n",
    "def cost_total(X, theta, Y, m, act_fn='sigmoid', cost_fn='sqr_error'):\n",
    "    fm = forward_prop(X, theta, act_fn)\n",
    "    if (cost_fn == 'sqr_error'):\n",
    "        cost = (1/(2*m))*np.sum((Y-fm[-1])**2) #MSE\n",
    "    else:\n",
    "        cost = -(1/m)*(np.sum(((Y*np.log(fm[-1]))+((1-Y)*(np.log(1-fm[-1])))))) #Cross Entropy\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, theta, actual_class, act_fn='sigmoid'):\n",
    "    pred_class = forward_prop(data, theta, act_fn)\n",
    "    test_pred_class = pred_class[-1]\n",
    "    for i in range(len(test_pred_class)):\n",
    "        test_pred_class[i][test_pred_class[i] == np.max(test_pred_class[i])] = 1 #Choose one with max probability\n",
    "        test_pred_class[i][test_pred_class[i] != np.max(test_pred_class[i])] = 0\n",
    "\n",
    "\n",
    "    test_acc = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if (np.array_equal(test_pred_class[i], actual_class[i])):\n",
    "            test_acc+=1\n",
    "    test_acc /= data.shape[0]\n",
    "\n",
    "    return (test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART AB - One Hidden Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(mini_batch, X_valid, valid_class_enc, theta, lr, act_fn='sigmoid', lr_mode='constant', cost_fn='sqr_error'):\n",
    "    lr0=lr\n",
    "    epoch = 1 # Number of epochs\n",
    "    early_stop=0 #Early stop count of iteration\n",
    "    \n",
    "    cost_init = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0], act_fn, cost_fn)\n",
    "    \n",
    "    while(True):\n",
    "        count_batch = 0\n",
    "        print(\"Initial Cost on Val dataset for this epoch {} = {}\".format(epoch, cost_init))\n",
    "        \n",
    "        if(lr_mode == \"adaptive\"):\n",
    "            lr = lr0/(np.power(epoch, 1/4))\n",
    "            print(\"learning rate for this epoch = \", lr)\n",
    "        \n",
    "        for b in mini_batch:\n",
    "            X_b = b[0] \n",
    "            Y_b = b[1]\n",
    "            \n",
    "            #Forward Propagation\n",
    "            fm = forward_prop(X_b, theta, act_fn)\n",
    "            \n",
    "            if (count_batch % 60 == 0):\n",
    "                print(\"Error on this batch = \"+str(cost_total(X_b, theta, Y_b, batch_size, act_fn, cost_fn)))\n",
    "                    \n",
    "            #Backward Propagation\n",
    "            delta = [None]*len(fm)\n",
    "            delta = backward_prop(fm, Y_b, theta, batch_size, act_fn, cost_fn)\n",
    "\n",
    "            #Theta Update\n",
    "            for t in range(len(theta)):\n",
    "                if (t == len(theta)-1):\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1]) \n",
    "                else:\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1])[:,1:]\n",
    "\n",
    "            count_batch+=1\n",
    "\n",
    "        epoch+=1 #Number of epochs\n",
    "                \n",
    "        cost_final = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0], act_fn, cost_fn)\n",
    "        print(\"Cost on val dataset after {} epochs is = {}\".format(epoch, cost_final))\n",
    "        \n",
    "        #Stopping criteria for sigmoid - when Validation loss stops decreasing beyond a threshold for 10 epochs\n",
    "        if (act_fn =='sigmoid'):\n",
    "            if (abs(cost_final-cost_init) < 1e-05):\n",
    "                early_stop +=1\n",
    "            else:\n",
    "                early_stop=0\n",
    "            if (early_stop == 10):\n",
    "                print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "                break\n",
    "        \n",
    "        #Stopping criteria for relu - when Validation loss increases continuously for 10 epochs\n",
    "        elif(act_fn=='relu' or act_fn=='softplus'):\n",
    "            if ((cost_final-cost_init) > 0):\n",
    "                early_stop +=1\n",
    "            else:\n",
    "                early_stop=0\n",
    "            if (early_stop == 10):\n",
    "                print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "                break\n",
    "        \n",
    "        cost_init = cost_final\n",
    "    return epoch, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(\"Accuracy with number of hidden units \\n in one hidden layer network\")\n",
    "    ax.plot(arch_test, train_accuracy, marker='o', label='Train Accuracy')\n",
    "    ax.plot(arch_test, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "    ax.plot(arch_test, test_accuracy, marker='o', label='Test Accuracy')\n",
    "    ax.set_xlabel(\"number of hidden units\")\n",
    "    ax.set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plots/partc/accuracy_normal_lr0.5_cube.png\", dpi=1000, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_epoch(arch_test, epochs, train_time):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(211)\n",
    "    plt.title(\"Epochs/Time with number of hidden units \\n in one hidden layer network\")\n",
    "    ax.plot(arch_test, epochs, c='b', marker='o', label='#epochs')\n",
    "    ax.set_xlabel(\"number of hidden units\")\n",
    "    ax.set_ylabel(\"Epochs\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = fig.add_subplot(212)\n",
    "    ax1.plot(arch_test, train_time, c='b', marker='o', label='train time')\n",
    "    ax1.set_xlabel(\"number of hidden units\")\n",
    "    ax1.set_ylabel(\"train time(sec)\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plots/partc/epochs_time_normal_lr0.5_cube.png\", dpi=1000, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_test = [1,5,10,50,100] # Specifically for part a and b\n",
    "#arch = [50] #means one hidden layer with 50 perceptrons (DEFAULT)\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 1 hidden layer with 1 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 1)\n",
      "theta between layer 1 and layer 2 is (2, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2519140993343103\n",
      "Error on this batch = 3.2521425944234545\n",
      "Error on this batch = 0.4978580119964171\n",
      "Cost on val dataset after 2 epochs is = 0.4862347192657634\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4862347192657634\n",
      "Error on this batch = 0.48614471880585103\n",
      "Error on this batch = 0.48289187960649105\n",
      "Cost on val dataset after 3 epochs is = 0.4818940037674934\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4818940037674934\n",
      "Error on this batch = 0.4818104066821387\n",
      "Error on this batch = 0.48135580468339784\n",
      "Cost on val dataset after 4 epochs is = 0.4811457959209773\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4811457959209773\n",
      "Error on this batch = 0.48105925376063535\n",
      "Error on this batch = 0.4809999087221998\n",
      "Cost on val dataset after 5 epochs is = 0.4809473066775132\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4809473066775132\n",
      "Error on this batch = 0.4808564335525884\n",
      "Error on this batch = 0.48089472851073917\n",
      "Cost on val dataset after 6 epochs is = 0.4808861523337416\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4808861523337416\n",
      "Error on this batch = 0.4807910939714662\n",
      "Error on this batch = 0.48086082336429614\n",
      "Cost on val dataset after 7 epochs is = 0.48086680712091406\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.48086680712091406\n",
      "Error on this batch = 0.48076812942373415\n",
      "Error on this batch = 0.4808500099325594\n",
      "Cost on val dataset after 8 epochs is = 0.48086131780294455\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48086131780294455\n",
      "Error on this batch = 0.48075967679250525\n",
      "Error on this batch = 0.480847068551227\n",
      "Cost on val dataset after 9 epochs is = 0.4808604684618455\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4808604684618455\n",
      "Error on this batch = 0.48075648590406367\n",
      "Error on this batch = 0.4808467700760326\n",
      "Cost on val dataset after 10 epochs is = 0.4808610456599938\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4808610456599938\n",
      "Error on this batch = 0.4807552610807218\n",
      "Error on this batch = 0.48084725585982724\n",
      "Cost on val dataset after 11 epochs is = 0.4808619232178538\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4808619232178538\n",
      "Error on this batch = 0.4807547806332175\n",
      "Error on this batch = 0.48084787451445343\n",
      "Cost on val dataset after 12 epochs is = 0.4808627310470193\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4808627310470193\n",
      "Error on this batch = 0.48075458256516457\n",
      "Error on this batch = 0.48084841804171286\n",
      "Cost on val dataset after 13 epochs is = 0.48086337404672397\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48086337404672397\n",
      "Error on this batch = 0.48075449114034013\n",
      "Error on this batch = 0.48084883950360796\n",
      "Cost on val dataset after 14 epochs is = 0.48086385252841246\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.48086385252841246\n",
      "Error on this batch = 0.4807544398805992\n",
      "Error on this batch = 0.48084914654269306\n",
      "Cost on val dataset after 15 epochs is = 0.4808641948647735\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4808641948647735\n",
      "Error on this batch = 0.4807544040254\n",
      "Error on this batch = 0.48084936151675195\n",
      "Cost on val dataset after 16 epochs is = 0.480864433053668\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.480864433053668\n",
      "Error on this batch = 0.4807543745621515\n",
      "Error on this batch = 0.48084950731513654\n",
      "Cost on val dataset after 17 epochs is = 0.4808645947987575\n",
      "cost initial= 0.480864433053668 , cost final=0.4808645947987575 , change in cost= 1.6174508948862965e-07\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 1 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 17\n",
      "The training time = 1.060sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 5 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 5)\n",
      "theta between layer 1 and layer 2 is (6, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.3016196064769834\n",
      "Error on this batch = 3.3012654325740587\n",
      "Error on this batch = 0.4827180943058321\n",
      "Cost on val dataset after 2 epochs is = 0.48119702190255687\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48119702190255687\n",
      "Error on this batch = 0.4810458079596366\n",
      "Error on this batch = 0.48095075703086254\n",
      "Cost on val dataset after 3 epochs is = 0.4809113979722743\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4809113979722743\n",
      "Error on this batch = 0.48077943267942536\n",
      "Error on this batch = 0.48090000891482504\n",
      "Cost on val dataset after 4 epochs is = 0.4809014315734396\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4809014315734396\n",
      "Error on this batch = 0.48076904400423986\n",
      "Error on this batch = 0.48089736516896525\n",
      "Cost on val dataset after 5 epochs is = 0.48090094743542416\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48090094743542416\n",
      "Error on this batch = 0.48076757028630257\n",
      "Error on this batch = 0.480896124810921\n",
      "Cost on val dataset after 6 epochs is = 0.4808997015481933\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4808997015481933\n",
      "Error on this batch = 0.4807661529559921\n",
      "Error on this batch = 0.4808944667118557\n",
      "Cost on val dataset after 7 epochs is = 0.48089797833889114\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.48089797833889114\n",
      "Error on this batch = 0.48076473122989855\n",
      "Error on this batch = 0.4808926735136164\n",
      "Cost on val dataset after 8 epochs is = 0.4808961580798549\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4808961580798549\n",
      "Error on this batch = 0.48076339159632\n",
      "Error on this batch = 0.48089091354504804\n",
      "Cost on val dataset after 9 epochs is = 0.4808943875893539\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4808943875893539\n",
      "Error on this batch = 0.4807621461833547\n",
      "Error on this batch = 0.4808892428376265\n",
      "Cost on val dataset after 10 epochs is = 0.48089270917332394\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48089270917332394\n",
      "Error on this batch = 0.4807609870749323\n",
      "Error on this batch = 0.48088767248033865\n",
      "Cost on val dataset after 11 epochs is = 0.48089112852786703\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48089112852786703\n",
      "Error on this batch = 0.4807599040469242\n",
      "Error on this batch = 0.4808861987430593\n",
      "Cost on val dataset after 12 epochs is = 0.4808896401625252\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4808896401625252\n",
      "Error on this batch = 0.48075888797634964\n",
      "Error on this batch = 0.4808848139060743\n",
      "Cost on val dataset after 13 epochs is = 0.48088823592056407\n",
      "cost initial= 0.4808896401625252 , cost final=0.48088823592056407 , change in cost= -1.4042419611559609e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 5 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 13\n",
      "The training time = 0.851sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 10 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 10)\n",
      "theta between layer 1 and layer 2 is (11, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2138546782328503\n",
      "Error on this batch = 3.21231154661315\n",
      "Error on this batch = 0.4812818170083387\n",
      "Cost on val dataset after 2 epochs is = 0.48103561191416133\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48103561191416133\n",
      "Error on this batch = 0.48093335851263525\n",
      "Error on this batch = 0.4809370991375834\n",
      "Cost on val dataset after 3 epochs is = 0.48099732454659566\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48099732454659566\n",
      "Error on this batch = 0.48091106049967436\n",
      "Error on this batch = 0.48092122959081646\n",
      "Cost on val dataset after 4 epochs is = 0.48098007997747333\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.48098007997747333\n",
      "Error on this batch = 0.48089456218963805\n",
      "Error on this batch = 0.4809085822944995\n",
      "Cost on val dataset after 5 epochs is = 0.48096285642882464\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48096285642882464\n",
      "Error on this batch = 0.48087786621422746\n",
      "Error on this batch = 0.48089661874458417\n",
      "Cost on val dataset after 6 epochs is = 0.4809459419455936\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4809459419455936\n",
      "Error on this batch = 0.48086154746705945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4808847914170438\n",
      "Cost on val dataset after 7 epochs is = 0.480928471379602\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.480928471379602\n",
      "Error on this batch = 0.48084456558257244\n",
      "Error on this batch = 0.48087228859583414\n",
      "Cost on val dataset after 8 epochs is = 0.4809086579556926\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4809086579556926\n",
      "Error on this batch = 0.4808249341291825\n",
      "Error on this batch = 0.4808575538272428\n",
      "Cost on val dataset after 9 epochs is = 0.48088264315349316\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48088264315349316\n",
      "Error on this batch = 0.4807983464981166\n",
      "Error on this batch = 0.48083672966032026\n",
      "Cost on val dataset after 10 epochs is = 0.4808398737512902\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4808398737512902\n",
      "Error on this batch = 0.48075299557717416\n",
      "Error on this batch = 0.4807968942267619\n",
      "Cost on val dataset after 11 epochs is = 0.48074346908050397\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48074346908050397\n",
      "Error on this batch = 0.48064904328512714\n",
      "Error on this batch = 0.4806813029999805\n",
      "Cost on val dataset after 12 epochs is = 0.480482340834077\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.480482340834077\n",
      "Error on this batch = 0.4803880722116762\n",
      "Error on this batch = 0.48035512470470965\n",
      "Cost on val dataset after 13 epochs is = 0.48003965251345665\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48003965251345665\n",
      "Error on this batch = 0.4799834167434187\n",
      "Error on this batch = 0.479895164263573\n",
      "Cost on val dataset after 14 epochs is = 0.47948335171848044\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.47948335171848044\n",
      "Error on this batch = 0.4794429757060513\n",
      "Error on this batch = 0.47936644798474976\n",
      "Cost on val dataset after 15 epochs is = 0.4788134712970487\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4788134712970487\n",
      "Error on this batch = 0.4787681815791781\n",
      "Error on this batch = 0.47879571626572043\n",
      "Cost on val dataset after 16 epochs is = 0.4780579489430936\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4780579489430936\n",
      "Error on this batch = 0.47798521223827733\n",
      "Error on this batch = 0.4782601966879467\n",
      "Cost on val dataset after 17 epochs is = 0.4772402167294683\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.4772402167294683\n",
      "Error on this batch = 0.47709688101467784\n",
      "Error on this batch = 0.4779066118874175\n",
      "Cost on val dataset after 18 epochs is = 0.47635967564217296\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.47635967564217296\n",
      "Error on this batch = 0.47608961310294545\n",
      "Error on this batch = 0.47792979469015495\n",
      "Cost on val dataset after 19 epochs is = 0.47542202249686916\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.47542202249686916\n",
      "Error on this batch = 0.4750276427425061\n",
      "Error on this batch = 0.47840289828579885\n",
      "Cost on val dataset after 20 epochs is = 0.4744738427646003\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4744738427646003\n",
      "Error on this batch = 0.47405124289366074\n",
      "Error on this batch = 0.4792742187032259\n",
      "Cost on val dataset after 21 epochs is = 0.47355705338092824\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.47355705338092824\n",
      "Error on this batch = 0.47311431109067786\n",
      "Error on this batch = 0.4802401898133155\n",
      "Cost on val dataset after 22 epochs is = 0.4726290186732591\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4726290186732591\n",
      "Error on this batch = 0.47195455924802504\n",
      "Error on this batch = 0.48085338913157716\n",
      "Cost on val dataset after 23 epochs is = 0.47157066153845106\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.47157066153845106\n",
      "Error on this batch = 0.4705028360472072\n",
      "Error on this batch = 0.48072824934389824\n",
      "Cost on val dataset after 24 epochs is = 0.4703081945546895\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.4703081945546895\n",
      "Error on this batch = 0.46877555939166954\n",
      "Error on this batch = 0.4800359639371913\n",
      "Cost on val dataset after 25 epochs is = 0.4689323976174675\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4689323976174675\n",
      "Error on this batch = 0.4671037297361832\n",
      "Error on this batch = 0.478936486310853\n",
      "Cost on val dataset after 26 epochs is = 0.4673665628386778\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.4673665628386778\n",
      "Error on this batch = 0.46531514705495\n",
      "Error on this batch = 0.4773494734925853\n",
      "Cost on val dataset after 27 epochs is = 0.4655385004561782\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.4655385004561782\n",
      "Error on this batch = 0.4632782668234119\n",
      "Error on this batch = 0.4750462190976282\n",
      "Cost on val dataset after 28 epochs is = 0.4631117933331089\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4631117933331089\n",
      "Error on this batch = 0.4607000292023136\n",
      "Error on this batch = 0.4720392862083235\n",
      "Cost on val dataset after 29 epochs is = 0.46023784271994\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.46023784271994\n",
      "Error on this batch = 0.4577103892415645\n",
      "Error on this batch = 0.468377567341178\n",
      "Cost on val dataset after 30 epochs is = 0.4568221919940399\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.4568221919940399\n",
      "Error on this batch = 0.4542766347875347\n",
      "Error on this batch = 0.46385469547847813\n",
      "Cost on val dataset after 31 epochs is = 0.4524965551653664\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.4524965551653664\n",
      "Error on this batch = 0.44973249511727886\n",
      "Error on this batch = 0.45784282625681855\n",
      "Cost on val dataset after 32 epochs is = 0.4461796134279377\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.4461796134279377\n",
      "Error on this batch = 0.4422146926629962\n",
      "Error on this batch = 0.45043713680756087\n",
      "Cost on val dataset after 33 epochs is = 0.43839886356293484\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.43839886356293484\n",
      "Error on this batch = 0.43269858402444983\n",
      "Error on this batch = 0.4426100764099266\n",
      "Cost on val dataset after 34 epochs is = 0.4295958789780238\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.4295958789780238\n",
      "Error on this batch = 0.4227126164994679\n",
      "Error on this batch = 0.4346982645452962\n",
      "Cost on val dataset after 35 epochs is = 0.42033182356957377\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.42033182356957377\n",
      "Error on this batch = 0.41358907114700943\n",
      "Error on this batch = 0.4270104907052532\n",
      "Cost on val dataset after 36 epochs is = 0.41110214605621126\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.41110214605621126\n",
      "Error on this batch = 0.40557691389878403\n",
      "Error on this batch = 0.4196427783355172\n",
      "Cost on val dataset after 37 epochs is = 0.4021725598811353\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.4021725598811353\n",
      "Error on this batch = 0.3983377291049869\n",
      "Error on this batch = 0.4125325274430214\n",
      "Cost on val dataset after 38 epochs is = 0.39347255198825726\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.39347255198825726\n",
      "Error on this batch = 0.39145598793985203\n",
      "Error on this batch = 0.4054557352817105\n",
      "Cost on val dataset after 39 epochs is = 0.38458128375839323\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.38458128375839323\n",
      "Error on this batch = 0.38452236726695127\n",
      "Error on this batch = 0.3981241067351493\n",
      "Cost on val dataset after 40 epochs is = 0.37556619277900644\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.37556619277900644\n",
      "Error on this batch = 0.3774656512362655\n",
      "Error on this batch = 0.3907558780398365\n",
      "Cost on val dataset after 41 epochs is = 0.3669635342931488\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.3669635342931488\n",
      "Error on this batch = 0.37078780215016516\n",
      "Error on this batch = 0.38379805106279985\n",
      "Cost on val dataset after 42 epochs is = 0.3590831420193184\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.3590831420193184\n",
      "Error on this batch = 0.3649589779685033\n",
      "Error on this batch = 0.3776823074319395\n",
      "Cost on val dataset after 43 epochs is = 0.3521050379263962\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.3521050379263962\n",
      "Error on this batch = 0.3599896570871087\n",
      "Error on this batch = 0.37225086432971777\n",
      "Cost on val dataset after 44 epochs is = 0.3459486034391479\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.3459486034391479\n",
      "Error on this batch = 0.35562645748281446\n",
      "Error on this batch = 0.3672695683004558\n",
      "Cost on val dataset after 45 epochs is = 0.34045882556291723\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.34045882556291723\n",
      "Error on this batch = 0.3515026156457482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.36258816264877086\n",
      "Cost on val dataset after 46 epochs is = 0.3355208712261168\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.3355208712261168\n",
      "Error on this batch = 0.3475442008486657\n",
      "Error on this batch = 0.35827709032619903\n",
      "Cost on val dataset after 47 epochs is = 0.3310492036409551\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.3310492036409551\n",
      "Error on this batch = 0.34380887335058147\n",
      "Error on this batch = 0.354375632747112\n",
      "Cost on val dataset after 48 epochs is = 0.3269641984186822\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.3269641984186822\n",
      "Error on this batch = 0.34027377641573936\n",
      "Error on this batch = 0.3508385222988271\n",
      "Cost on val dataset after 49 epochs is = 0.3232004067552941\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.3232004067552941\n",
      "Error on this batch = 0.33689385304200087\n",
      "Error on this batch = 0.34758965906621037\n",
      "Cost on val dataset after 50 epochs is = 0.3197138301162313\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.3197138301162313\n",
      "Error on this batch = 0.33364767684393554\n",
      "Error on this batch = 0.3445498064772876\n",
      "Cost on val dataset after 51 epochs is = 0.3164804633535902\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.3164804633535902\n",
      "Error on this batch = 0.3305222925692148\n",
      "Error on this batch = 0.3416535203762871\n",
      "Cost on val dataset after 52 epochs is = 0.3134839866921171\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.3134839866921171\n",
      "Error on this batch = 0.32749154427152266\n",
      "Error on this batch = 0.33885737676224315\n",
      "Cost on val dataset after 53 epochs is = 0.31070603644234895\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.31070603644234895\n",
      "Error on this batch = 0.32453402154612837\n",
      "Error on this batch = 0.33613527717007413\n",
      "Cost on val dataset after 54 epochs is = 0.308125829969586\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.308125829969586\n",
      "Error on this batch = 0.32164150972007954\n",
      "Error on this batch = 0.33347158926848786\n",
      "Cost on val dataset after 55 epochs is = 0.30572264293809037\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.30572264293809037\n",
      "Error on this batch = 0.31881076407534553\n",
      "Error on this batch = 0.33085694538571475\n",
      "Cost on val dataset after 56 epochs is = 0.30347711144258516\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.30347711144258516\n",
      "Error on this batch = 0.3160391141710895\n",
      "Error on this batch = 0.32828583265705547\n",
      "Cost on val dataset after 57 epochs is = 0.3013717481528373\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.3013717481528373\n",
      "Error on this batch = 0.3133250572077569\n",
      "Error on this batch = 0.32575548903262574\n",
      "Cost on val dataset after 58 epochs is = 0.2993914556923948\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.2993914556923948\n",
      "Error on this batch = 0.31066958471081274\n",
      "Error on this batch = 0.32326543761919496\n",
      "Cost on val dataset after 59 epochs is = 0.2975239416646462\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.2975239416646462\n",
      "Error on this batch = 0.3080765048676068\n",
      "Error on this batch = 0.32081692360078107\n",
      "Cost on val dataset after 60 epochs is = 0.29575967467661585\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.29575967467661585\n",
      "Error on this batch = 0.3055517507300876\n",
      "Error on this batch = 0.3184121033525084\n",
      "Cost on val dataset after 61 epochs is = 0.29409136414704173\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.29409136414704173\n",
      "Error on this batch = 0.30310232714054364\n",
      "Error on this batch = 0.31605338585941\n",
      "Cost on val dataset after 62 epochs is = 0.2925132480759805\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.2925132480759805\n",
      "Error on this batch = 0.30073549462641447\n",
      "Error on this batch = 0.3137432520879482\n",
      "Cost on val dataset after 63 epochs is = 0.29102044665996357\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.29102044665996357\n",
      "Error on this batch = 0.29845830802671974\n",
      "Error on this batch = 0.3114844304867039\n",
      "Cost on val dataset after 64 epochs is = 0.28960848812849854\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.28960848812849854\n",
      "Error on this batch = 0.2962772717245129\n",
      "Error on this batch = 0.30928006292453974\n",
      "Cost on val dataset after 65 epochs is = 0.28827301261005456\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.28827301261005456\n",
      "Error on this batch = 0.29419792249631654\n",
      "Error on this batch = 0.30713359135086704\n",
      "Cost on val dataset after 66 epochs is = 0.2870096100631521\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.2870096100631521\n",
      "Error on this batch = 0.2922243798649008\n",
      "Error on this batch = 0.30504830767042396\n",
      "Cost on val dataset after 67 epochs is = 0.28581372795947463\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.28581372795947463\n",
      "Error on this batch = 0.29035901096187994\n",
      "Error on this batch = 0.3030266590944872\n",
      "Cost on val dataset after 68 epochs is = 0.28468059568794246\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.28468059568794246\n",
      "Error on this batch = 0.2886023096659685\n",
      "Error on this batch = 0.30106945624255493\n",
      "Cost on val dataset after 69 epochs is = 0.28360513589745506\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.28360513589745506\n",
      "Error on this batch = 0.28695301770297404\n",
      "Error on this batch = 0.29917514457240074\n",
      "Cost on val dataset after 70 epochs is = 0.2825818268720512\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.2825818268720512\n",
      "Error on this batch = 0.285408497884182\n",
      "Error on this batch = 0.29733936636585945\n",
      "Cost on val dataset after 71 epochs is = 0.2816044068024346\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.2816044068024346\n",
      "Error on this batch = 0.28396536098244524\n",
      "Error on this batch = 0.295555233313319\n",
      "Cost on val dataset after 72 epochs is = 0.2806650993942658\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.2806650993942658\n",
      "Error on this batch = 0.28262020061613163\n",
      "Error on this batch = 0.29381499715310605\n",
      "Cost on val dataset after 73 epochs is = 0.27975238458651686\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.27975238458651686\n",
      "Error on this batch = 0.28136969015140295\n",
      "Error on this batch = 0.2921140837798976\n",
      "Cost on val dataset after 74 epochs is = 0.27884354014075075\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.27884354014075075\n",
      "Error on this batch = 0.2802068832578699\n",
      "Error on this batch = 0.2904606049315777\n",
      "Cost on val dataset after 75 epochs is = 0.27787467636705077\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.27787467636705077\n",
      "Error on this batch = 0.27910181709529974\n",
      "Error on this batch = 0.2889073219051133\n",
      "Cost on val dataset after 76 epochs is = 0.2767559986736796\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.2767559986736796\n",
      "Error on this batch = 0.27801850198887956\n",
      "Error on this batch = 0.2872939770797644\n",
      "Cost on val dataset after 77 epochs is = 0.2756636913041333\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.2756636913041333\n",
      "Error on this batch = 0.2770690875403836\n",
      "Error on this batch = 0.2853235642236787\n",
      "Cost on val dataset after 78 epochs is = 0.2745468615870062\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.2745468615870062\n",
      "Error on this batch = 0.2762010099503136\n",
      "Error on this batch = 0.28310137469723684\n",
      "Cost on val dataset after 79 epochs is = 0.2733237082627805\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.2733237082627805\n",
      "Error on this batch = 0.275268972473496\n",
      "Error on this batch = 0.28071661107784623\n",
      "Cost on val dataset after 80 epochs is = 0.27195038598177296\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.27195038598177296\n",
      "Error on this batch = 0.2742307530270303\n",
      "Error on this batch = 0.27824038401980494\n",
      "Cost on val dataset after 81 epochs is = 0.2704104996513718\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.2704104996513718\n",
      "Error on this batch = 0.2731257075536653\n",
      "Error on this batch = 0.27564832248579624\n",
      "Cost on val dataset after 82 epochs is = 0.2687353955070172\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.2687353955070172\n",
      "Error on this batch = 0.27198440831336645\n",
      "Error on this batch = 0.27297272605680595\n",
      "Cost on val dataset after 83 epochs is = 0.2669818956081228\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.2669818956081228\n",
      "Error on this batch = 0.27079306596495323\n",
      "Error on this batch = 0.270297323172696\n",
      "Cost on val dataset after 84 epochs is = 0.2651834577977227\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.2651834577977227\n",
      "Error on this batch = 0.2695288604273272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.26768982219825527\n",
      "Cost on val dataset after 85 epochs is = 0.2633671576260864\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.2633671576260864\n",
      "Error on this batch = 0.26816603322708144\n",
      "Error on this batch = 0.265197744445473\n",
      "Cost on val dataset after 86 epochs is = 0.2615634454961238\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.2615634454961238\n",
      "Error on this batch = 0.26669582575845596\n",
      "Error on this batch = 0.26283779914004224\n",
      "Cost on val dataset after 87 epochs is = 0.2598062206927073\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.2598062206927073\n",
      "Error on this batch = 0.26514059352015557\n",
      "Error on this batch = 0.260609934152862\n",
      "Cost on val dataset after 88 epochs is = 0.25812290145309574\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.25812290145309574\n",
      "Error on this batch = 0.2635334704155314\n",
      "Error on this batch = 0.25851157039085154\n",
      "Cost on val dataset after 89 epochs is = 0.25653009510079827\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.25653009510079827\n",
      "Error on this batch = 0.26190234863132056\n",
      "Error on this batch = 0.2565396693643615\n",
      "Cost on val dataset after 90 epochs is = 0.25503500681885366\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.25503500681885366\n",
      "Error on this batch = 0.26026571502468737\n",
      "Error on this batch = 0.25469026271442485\n",
      "Cost on val dataset after 91 epochs is = 0.25363848084827983\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.25363848084827983\n",
      "Error on this batch = 0.25863445362362947\n",
      "Error on this batch = 0.2529587506847978\n",
      "Cost on val dataset after 92 epochs is = 0.25233748788671895\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.25233748788671895\n",
      "Error on this batch = 0.2570145884904285\n",
      "Error on this batch = 0.2513401887705421\n",
      "Cost on val dataset after 93 epochs is = 0.2511268104698586\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.2511268104698586\n",
      "Error on this batch = 0.25540961810163154\n",
      "Error on this batch = 0.24982921205414044\n",
      "Cost on val dataset after 94 epochs is = 0.2500001563283198\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.2500001563283198\n",
      "Error on this batch = 0.2538224762478945\n",
      "Error on this batch = 0.2484197894268088\n",
      "Cost on val dataset after 95 epochs is = 0.24895086701260855\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.24895086701260855\n",
      "Error on this batch = 0.2522570417556384\n",
      "Error on this batch = 0.24710502164073855\n",
      "Cost on val dataset after 96 epochs is = 0.24797232585788673\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.24797232585788673\n",
      "Error on this batch = 0.25071889444029194\n",
      "Error on this batch = 0.24587709093467894\n",
      "Cost on val dataset after 97 epochs is = 0.2470581649594909\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.2470581649594909\n",
      "Error on this batch = 0.24921508957939673\n",
      "Error on this batch = 0.2447273969697411\n",
      "Cost on val dataset after 98 epochs is = 0.24620236038438134\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.24620236038438134\n",
      "Error on this batch = 0.24775307652453044\n",
      "Error on this batch = 0.2436468563117424\n",
      "Cost on val dataset after 99 epochs is = 0.2453992677655812\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.2453992677655812\n",
      "Error on this batch = 0.24633931766519465\n",
      "Error on this batch = 0.2426262850881779\n",
      "Cost on val dataset after 100 epochs is = 0.24464360683961917\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.24464360683961917\n",
      "Error on this batch = 0.24497828161203367\n",
      "Error on this batch = 0.24165674779455992\n",
      "Cost on val dataset after 101 epochs is = 0.2439303722416155\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.2439303722416155\n",
      "Error on this batch = 0.24367210965061709\n",
      "Error on this batch = 0.24072975733018695\n",
      "Cost on val dataset after 102 epochs is = 0.2432546251465343\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.2432546251465343\n",
      "Error on this batch = 0.2424207117422508\n",
      "Error on this batch = 0.2398372414123134\n",
      "Cost on val dataset after 103 epochs is = 0.24261108746885116\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.24261108746885116\n",
      "Error on this batch = 0.2412217309880855\n",
      "Error on this batch = 0.23897122746875776\n",
      "Cost on val dataset after 104 epochs is = 0.2419934629698432\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.2419934629698432\n",
      "Error on this batch = 0.24006970279146608\n",
      "Error on this batch = 0.23812321689099228\n",
      "Cost on val dataset after 105 epochs is = 0.24139398067311757\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.24139398067311757\n",
      "Error on this batch = 0.2389538169401888\n",
      "Error on this batch = 0.23728196770326293\n",
      "Cost on val dataset after 106 epochs is = 0.2408061971887263\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.2408061971887263\n",
      "Error on this batch = 0.23785646585297707\n",
      "Error on this batch = 0.23641476748170256\n",
      "Cost on val dataset after 107 epochs is = 0.2402291451050274\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.2402291451050274\n",
      "Error on this batch = 0.23676287844348307\n",
      "Error on this batch = 0.23540639975313\n",
      "Cost on val dataset after 108 epochs is = 0.23965481140013767\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.23965481140013767\n",
      "Error on this batch = 0.23568209763300324\n",
      "Error on this batch = 0.2340660148675146\n",
      "Cost on val dataset after 109 epochs is = 0.23907373505304766\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.23907373505304766\n",
      "Error on this batch = 0.23472538253666933\n",
      "Error on this batch = 0.2325081668219331\n",
      "Cost on val dataset after 110 epochs is = 0.2384907695081024\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.2384907695081024\n",
      "Error on this batch = 0.23405266780385056\n",
      "Error on this batch = 0.23113155750266193\n",
      "Cost on val dataset after 111 epochs is = 0.2379134926490315\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.2379134926490315\n",
      "Error on this batch = 0.23367170046384314\n",
      "Error on this batch = 0.22997133632218694\n",
      "Cost on val dataset after 112 epochs is = 0.2373640637310892\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.2373640637310892\n",
      "Error on this batch = 0.23352702518463134\n",
      "Error on this batch = 0.2288840361586156\n",
      "Cost on val dataset after 113 epochs is = 0.2368728854066634\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.2368728854066634\n",
      "Error on this batch = 0.23339372290569835\n",
      "Error on this batch = 0.22776014699818312\n",
      "Cost on val dataset after 114 epochs is = 0.2364615352557532\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.2364615352557532\n",
      "Error on this batch = 0.23308738118049888\n",
      "Error on this batch = 0.2266131656157785\n",
      "Cost on val dataset after 115 epochs is = 0.23607538841901315\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.23607538841901315\n",
      "Error on this batch = 0.23257118632640683\n",
      "Error on this batch = 0.22553858930794657\n",
      "Cost on val dataset after 116 epochs is = 0.23562034560341064\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.23562034560341064\n",
      "Error on this batch = 0.2318948896084021\n",
      "Error on this batch = 0.2245831894331772\n",
      "Cost on val dataset after 117 epochs is = 0.2351182667778651\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.2351182667778651\n",
      "Error on this batch = 0.23114640972465722\n",
      "Error on this batch = 0.2237418697397771\n",
      "Cost on val dataset after 118 epochs is = 0.23461550926289176\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.23461550926289176\n",
      "Error on this batch = 0.230370498921508\n",
      "Error on this batch = 0.22299007053755432\n",
      "Cost on val dataset after 119 epochs is = 0.23413047612786558\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.23413047612786558\n",
      "Error on this batch = 0.22958984989459358\n",
      "Error on this batch = 0.22229750908066567\n",
      "Cost on val dataset after 120 epochs is = 0.23366616056689407\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.23366616056689407\n",
      "Error on this batch = 0.22881678391971796\n",
      "Error on this batch = 0.22164099374306406\n",
      "Cost on val dataset after 121 epochs is = 0.23322072814596492\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.23322072814596492\n",
      "Error on this batch = 0.2280554874512004\n",
      "Error on this batch = 0.22100781816320741\n",
      "Cost on val dataset after 122 epochs is = 0.23279112936484944\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.23279112936484944\n",
      "Error on this batch = 0.22730488375118782\n",
      "Error on this batch = 0.22039233156836333\n",
      "Cost on val dataset after 123 epochs is = 0.23237402128322965\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.23237402128322965\n",
      "Error on this batch = 0.22656116659333542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.21979197457181351\n",
      "Cost on val dataset after 124 epochs is = 0.23196609279214248\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.23196609279214248\n",
      "Error on this batch = 0.22581958360632332\n",
      "Error on this batch = 0.21920491827737235\n",
      "Cost on val dataset after 125 epochs is = 0.23156429939763346\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.23156429939763346\n",
      "Error on this batch = 0.2250754648223609\n",
      "Error on this batch = 0.21862907492651956\n",
      "Cost on val dataset after 126 epochs is = 0.23116601664523578\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.23116601664523578\n",
      "Error on this batch = 0.22432464618153872\n",
      "Error on this batch = 0.2180618580086104\n",
      "Cost on val dataset after 127 epochs is = 0.2307690860175414\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.2307690860175414\n",
      "Error on this batch = 0.22356355605897957\n",
      "Error on this batch = 0.21750027626797613\n",
      "Cost on val dataset after 128 epochs is = 0.23037177010804383\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.23037177010804383\n",
      "Error on this batch = 0.2227891808817929\n",
      "Error on this batch = 0.21694114506501094\n",
      "Cost on val dataset after 129 epochs is = 0.22997265060339497\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.22997265060339497\n",
      "Error on this batch = 0.22199899458081881\n",
      "Error on this batch = 0.21638130012739715\n",
      "Cost on val dataset after 130 epochs is = 0.22957049893339534\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.22957049893339534\n",
      "Error on this batch = 0.22119084676320555\n",
      "Error on this batch = 0.21581775778721407\n",
      "Cost on val dataset after 131 epochs is = 0.22916414233787363\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.22916414233787363\n",
      "Error on this batch = 0.22036279226384278\n",
      "Error on this batch = 0.2152478139519925\n",
      "Cost on val dataset after 132 epochs is = 0.2287523429611528\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.2287523429611528\n",
      "Error on this batch = 0.21951288469757316\n",
      "Error on this batch = 0.21466910566201236\n",
      "Cost on val dataset after 133 epochs is = 0.22833370314446014\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.22833370314446014\n",
      "Error on this batch = 0.21863900284941057\n",
      "Error on this batch = 0.21407966882888013\n",
      "Cost on val dataset after 134 epochs is = 0.22790660536153062\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.22790660536153062\n",
      "Error on this batch = 0.21773879600186058\n",
      "Error on this batch = 0.21347802292187418\n",
      "Cost on val dataset after 135 epochs is = 0.2274691917700211\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.2274691917700211\n",
      "Error on this batch = 0.21680981474103658\n",
      "Error on this batch = 0.21286330996404623\n",
      "Cost on val dataset after 136 epochs is = 0.22701938870082453\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.22701938870082453\n",
      "Error on this batch = 0.21584985514738975\n",
      "Error on this batch = 0.21223551549335695\n",
      "Cost on val dataset after 137 epochs is = 0.22655498758142603\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.22655498758142603\n",
      "Error on this batch = 0.21485751433443578\n",
      "Error on this batch = 0.211595799061443\n",
      "Cost on val dataset after 138 epochs is = 0.22607380698703844\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.22607380698703844\n",
      "Error on this batch = 0.21383295296956192\n",
      "Error on this batch = 0.21094694938102698\n",
      "Cost on val dataset after 139 epochs is = 0.22557398138332896\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.22557398138332896\n",
      "Error on this batch = 0.21277888564841682\n",
      "Error on this batch = 0.2102939328981411\n",
      "Cost on val dataset after 140 epochs is = 0.22505444816311101\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.22505444816311101\n",
      "Error on this batch = 0.21170184896014732\n",
      "Error on this batch = 0.20964440261039494\n",
      "Cost on val dataset after 141 epochs is = 0.22451571567411469\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.22451571567411469\n",
      "Error on this batch = 0.21061375322525888\n",
      "Error on this batch = 0.20900889307819448\n",
      "Cost on val dataset after 142 epochs is = 0.223960917693059\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.223960917693059\n",
      "Error on this batch = 0.20953341255062952\n",
      "Error on this batch = 0.20840033963538912\n",
      "Cost on val dataset after 143 epochs is = 0.2233968469742889\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.2233968469742889\n",
      "Error on this batch = 0.20848688125128134\n",
      "Error on this batch = 0.20783262300846886\n",
      "Cost on val dataset after 144 epochs is = 0.22283406701608613\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.22283406701608613\n",
      "Error on this batch = 0.2075041609540333\n",
      "Error on this batch = 0.20731808599841586\n",
      "Cost on val dataset after 145 epochs is = 0.22228492763467306\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.22228492763467306\n",
      "Error on this batch = 0.2066100793904347\n",
      "Error on this batch = 0.2068645497923116\n",
      "Cost on val dataset after 146 epochs is = 0.2217596077861953\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.2217596077861953\n",
      "Error on this batch = 0.20581199472502854\n",
      "Error on this batch = 0.20647325103102346\n",
      "Cost on val dataset after 147 epochs is = 0.22126275747422525\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.22126275747422525\n",
      "Error on this batch = 0.20509367473809814\n",
      "Error on this batch = 0.20613914187865642\n",
      "Cost on val dataset after 148 epochs is = 0.22079340350807156\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.22079340350807156\n",
      "Error on this batch = 0.2044216916377406\n",
      "Error on this batch = 0.2058533213619989\n",
      "Cost on val dataset after 149 epochs is = 0.2203473779596682\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.2203473779596682\n",
      "Error on this batch = 0.20375818065010085\n",
      "Error on this batch = 0.20560589150751538\n",
      "Cost on val dataset after 150 epochs is = 0.21991929363124244\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.21991929363124244\n",
      "Error on this batch = 0.20307015896640607\n",
      "Error on this batch = 0.2053879209952464\n",
      "Cost on val dataset after 151 epochs is = 0.21950287418897002\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.21950287418897002\n",
      "Error on this batch = 0.20233353685064795\n",
      "Error on this batch = 0.20519231337671057\n",
      "Cost on val dataset after 152 epochs is = 0.2190909178879378\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.2190909178879378\n",
      "Error on this batch = 0.20153481550521146\n",
      "Error on this batch = 0.2050139080366736\n",
      "Cost on val dataset after 153 epochs is = 0.21867619094478158\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.21867619094478158\n",
      "Error on this batch = 0.200671732433442\n",
      "Error on this batch = 0.2048491087418128\n",
      "Cost on val dataset after 154 epochs is = 0.21825303585088615\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.21825303585088615\n",
      "Error on this batch = 0.19975218366243688\n",
      "Error on this batch = 0.2046951636766447\n",
      "Cost on val dataset after 155 epochs is = 0.21781862674196606\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.21781862674196606\n",
      "Error on this batch = 0.1987913005877333\n",
      "Error on this batch = 0.204549292021918\n",
      "Cost on val dataset after 156 epochs is = 0.21737319470982264\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.21737319470982264\n",
      "Error on this batch = 0.1978077373990498\n",
      "Error on this batch = 0.20440809986233457\n",
      "Cost on val dataset after 157 epochs is = 0.21691932022906693\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.21691932022906693\n",
      "Error on this batch = 0.19682041356048458\n",
      "Error on this batch = 0.20426761577580224\n",
      "Cost on val dataset after 158 epochs is = 0.21646081397744815\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.21646081397744815\n",
      "Error on this batch = 0.19584638705858004\n",
      "Error on this batch = 0.2041237624443828\n",
      "Cost on val dataset after 159 epochs is = 0.21600171156431708\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.21600171156431708\n",
      "Error on this batch = 0.19489992165795827\n",
      "Error on this batch = 0.2039727960634746\n",
      "Cost on val dataset after 160 epochs is = 0.21554566324549473\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.21554566324549473\n",
      "Error on this batch = 0.1939923968174322\n",
      "Error on this batch = 0.20381146764896685\n",
      "Cost on val dataset after 161 epochs is = 0.2150957070267134\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.2150957070267134\n",
      "Error on this batch = 0.19313249477796132\n",
      "Error on this batch = 0.20363706047684013\n",
      "Cost on val dataset after 162 epochs is = 0.21465422853666313\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.21465422853666313\n",
      "Error on this batch = 0.1923261389644753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.20344766583826537\n",
      "Cost on val dataset after 163 epochs is = 0.21422288251575372\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.21422288251575372\n",
      "Error on this batch = 0.19157604789914245\n",
      "Error on this batch = 0.2032428626875197\n",
      "Cost on val dataset after 164 epochs is = 0.21380236779464387\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.21380236779464387\n",
      "Error on this batch = 0.1908813559713091\n",
      "Error on this batch = 0.20302446517201453\n",
      "Cost on val dataset after 165 epochs is = 0.21339216202617772\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.21339216202617772\n",
      "Error on this batch = 0.1902379598358226\n",
      "Error on this batch = 0.2027967251377145\n",
      "Cost on val dataset after 166 epochs is = 0.21299049310395465\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.21299049310395465\n",
      "Error on this batch = 0.18963970178078932\n",
      "Error on this batch = 0.20256569560322416\n",
      "Cost on val dataset after 167 epochs is = 0.21259475474454537\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.21259475474454537\n",
      "Error on this batch = 0.18907978234761125\n",
      "Error on this batch = 0.20233801562146297\n",
      "Cost on val dataset after 168 epochs is = 0.21220225820915534\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.21220225820915534\n",
      "Error on this batch = 0.18855173303429718\n",
      "Error on this batch = 0.20211963194546975\n",
      "Cost on val dataset after 169 epochs is = 0.21181092963981651\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.21181092963981651\n",
      "Error on this batch = 0.18804973897666685\n",
      "Error on this batch = 0.2019148773066519\n",
      "Cost on val dataset after 170 epochs is = 0.21141952439911046\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.21141952439911046\n",
      "Error on this batch = 0.18756839681533508\n",
      "Error on this batch = 0.20172603639899347\n",
      "Cost on val dataset after 171 epochs is = 0.21102702188403116\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.21102702188403116\n",
      "Error on this batch = 0.18710184266976776\n",
      "Error on this batch = 0.20155311125275202\n",
      "Cost on val dataset after 172 epochs is = 0.2106306607619543\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.2106306607619543\n",
      "Error on this batch = 0.18664144480948658\n",
      "Error on this batch = 0.20139263996682438\n",
      "Cost on val dataset after 173 epochs is = 0.21022000025212864\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.21022000025212864\n",
      "Error on this batch = 0.18616798708965485\n",
      "Error on this batch = 0.20122927972105553\n",
      "Cost on val dataset after 174 epochs is = 0.20974901863090942\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.20974901863090942\n",
      "Error on this batch = 0.18560979636820304\n",
      "Error on this batch = 0.2009530862547804\n",
      "Cost on val dataset after 175 epochs is = 0.20900038820127745\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.20900038820127745\n",
      "Error on this batch = 0.18456031950159563\n",
      "Error on this batch = 0.20058740685770432\n",
      "Cost on val dataset after 176 epochs is = 0.20832432460162773\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.20832432460162773\n",
      "Error on this batch = 0.18383139611628313\n",
      "Error on this batch = 0.20109931309718498\n",
      "Cost on val dataset after 177 epochs is = 0.20810333715118925\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.20810333715118925\n",
      "Error on this batch = 0.18343586009934731\n",
      "Error on this batch = 0.20132001105730105\n",
      "Cost on val dataset after 178 epochs is = 0.20789886834607504\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.20789886834607504\n",
      "Error on this batch = 0.18267752597939926\n",
      "Error on this batch = 0.20097264781316068\n",
      "Cost on val dataset after 179 epochs is = 0.2076075184556633\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.2076075184556633\n",
      "Error on this batch = 0.1819221969106696\n",
      "Error on this batch = 0.20050066186578247\n",
      "Cost on val dataset after 180 epochs is = 0.20728715001684742\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.20728715001684742\n",
      "Error on this batch = 0.18127790662581597\n",
      "Error on this batch = 0.20006839090845382\n",
      "Cost on val dataset after 181 epochs is = 0.20696416031622902\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.20696416031622902\n",
      "Error on this batch = 0.18073185995360838\n",
      "Error on this batch = 0.1996899775565965\n",
      "Cost on val dataset after 182 epochs is = 0.20664832764587326\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.20664832764587326\n",
      "Error on this batch = 0.18026152708361146\n",
      "Error on this batch = 0.19935214523453174\n",
      "Cost on val dataset after 183 epochs is = 0.20634425311651744\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.20634425311651744\n",
      "Error on this batch = 0.17984802063703853\n",
      "Error on this batch = 0.19904333671291347\n",
      "Cost on val dataset after 184 epochs is = 0.2060538981913983\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.2060538981913983\n",
      "Error on this batch = 0.17947664686687148\n",
      "Error on this batch = 0.19875633511515717\n",
      "Cost on val dataset after 185 epochs is = 0.20577762647769712\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.20577762647769712\n",
      "Error on this batch = 0.17913651671378789\n",
      "Error on this batch = 0.1984866698404234\n",
      "Cost on val dataset after 186 epochs is = 0.20551493057322512\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.20551493057322512\n",
      "Error on this batch = 0.1788198427692469\n",
      "Error on this batch = 0.19823130842125072\n",
      "Cost on val dataset after 187 epochs is = 0.20526489429670178\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.20526489429670178\n",
      "Error on this batch = 0.17852116818704822\n",
      "Error on this batch = 0.19798798987852861\n",
      "Cost on val dataset after 188 epochs is = 0.20502645662458632\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.20502645662458632\n",
      "Error on this batch = 0.17823669937921346\n",
      "Error on this batch = 0.19775494060699966\n",
      "Cost on val dataset after 189 epochs is = 0.20479855387169904\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.20479855387169904\n",
      "Error on this batch = 0.17796379571353732\n",
      "Error on this batch = 0.19753076057436672\n",
      "Cost on val dataset after 190 epochs is = 0.20458019204270905\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.20458019204270905\n",
      "Error on this batch = 0.17770060396560297\n",
      "Error on this batch = 0.19731436885725764\n",
      "Cost on val dataset after 191 epochs is = 0.20437047987041315\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.20437047987041315\n",
      "Error on this batch = 0.17744580456122458\n",
      "Error on this batch = 0.19710496215323825\n",
      "Cost on val dataset after 192 epochs is = 0.20416864031193752\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.20416864031193752\n",
      "Error on this batch = 0.1771984370601769\n",
      "Error on this batch = 0.19690197167073378\n",
      "Cost on val dataset after 193 epochs is = 0.20397401082299263\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.20397401082299263\n",
      "Error on this batch = 0.1769577794465065\n",
      "Error on this batch = 0.1967050166218377\n",
      "Cost on val dataset after 194 epochs is = 0.20378603807772636\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.20378603807772636\n",
      "Error on this batch = 0.1767232633027213\n",
      "Error on this batch = 0.19651385632919222\n",
      "Cost on val dataset after 195 epochs is = 0.20360426986239852\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.20360426986239852\n",
      "Error on this batch = 0.17649441290584403\n",
      "Error on this batch = 0.19632834318047976\n",
      "Cost on val dataset after 196 epochs is = 0.20342834513851088\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.20342834513851088\n",
      "Error on this batch = 0.17627080054486333\n",
      "Error on this batch = 0.1961483779872831\n",
      "Cost on val dataset after 197 epochs is = 0.2032579824050995\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.2032579824050995\n",
      "Error on this batch = 0.17605201327443978\n",
      "Error on this batch = 0.19597386886249482\n",
      "Cost on val dataset after 198 epochs is = 0.2030929662217702\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.2030929662217702\n",
      "Error on this batch = 0.17583762822701102\n",
      "Error on this batch = 0.19580469483503346\n",
      "Cost on val dataset after 199 epochs is = 0.20293313188155296\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.20293313188155296\n",
      "Error on this batch = 0.17562719471775357\n",
      "Error on this batch = 0.195640675935679\n",
      "Cost on val dataset after 200 epochs is = 0.20277834860338884\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.20277834860338884\n",
      "Error on this batch = 0.17542022184840939\n",
      "Error on this batch = 0.19548155205374496\n",
      "Cost on val dataset after 201 epochs is = 0.20262850213639605\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.20262850213639605\n",
      "Error on this batch = 0.17521617035184547\n",
      "Error on this batch = 0.19532697306346078\n",
      "Cost on val dataset after 202 epochs is = 0.20248347820998133\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.20248347820998133\n",
      "Error on this batch = 0.17501444732651025\n",
      "Error on this batch = 0.19517650219034555\n",
      "Cost on val dataset after 203 epochs is = 0.20234314866723815\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.20234314866723815\n",
      "Error on this batch = 0.17481440261822964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.19502963311122337\n",
      "Cost on val dataset after 204 epochs is = 0.20220736220975957\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.20220736220975957\n",
      "Error on this batch = 0.17461532608664893\n",
      "Error on this batch = 0.1948858189052661\n",
      "Cost on val dataset after 205 epochs is = 0.2020759413411737\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.2020759413411737\n",
      "Error on this batch = 0.17441644573589984\n",
      "Error on this batch = 0.19474450821602482\n",
      "Cost on val dataset after 206 epochs is = 0.20194868633985935\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.20194868633985935\n",
      "Error on this batch = 0.1742169274070872\n",
      "Error on this batch = 0.19460518190482035\n",
      "Cost on val dataset after 207 epochs is = 0.20182538607522607\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.20182538607522607\n",
      "Error on this batch = 0.17401587722609854\n",
      "Error on this batch = 0.19446738326408053\n",
      "Cost on val dataset after 208 epochs is = 0.20170583439802509\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.20170583439802509\n",
      "Error on this batch = 0.17381234832001838\n",
      "Error on this batch = 0.19433073697885772\n",
      "Cost on val dataset after 209 epochs is = 0.20158984977307995\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.20158984977307995\n",
      "Error on this batch = 0.1736053536225283\n",
      "Error on this batch = 0.19419495562335376\n",
      "Cost on val dataset after 210 epochs is = 0.20147729478476906\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.20147729478476906\n",
      "Error on this batch = 0.17339388693199898\n",
      "Error on this batch = 0.1940598358013865\n",
      "Cost on val dataset after 211 epochs is = 0.20136809126914867\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.20136809126914867\n",
      "Error on this batch = 0.17317695464883084\n",
      "Error on this batch = 0.19392524762861216\n",
      "Cost on val dataset after 212 epochs is = 0.2012622265836496\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.2012622265836496\n",
      "Error on this batch = 0.17295362063461703\n",
      "Error on this batch = 0.1937911208958732\n",
      "Cost on val dataset after 213 epochs is = 0.20115974756697744\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.20115974756697744\n",
      "Error on this batch = 0.17272306618254896\n",
      "Error on this batch = 0.19365742990489487\n",
      "Cost on val dataset after 214 epochs is = 0.20106074138077895\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.20106074138077895\n",
      "Error on this batch = 0.1724846656516237\n",
      "Error on this batch = 0.19352417787754078\n",
      "Cost on val dataset after 215 epochs is = 0.20096530616135647\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.20096530616135647\n",
      "Error on this batch = 0.17223807496805862\n",
      "Error on this batch = 0.1933913816493849\n",
      "Cost on val dataset after 216 epochs is = 0.2008735179433861\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.2008735179433861\n",
      "Error on this batch = 0.17198332411888909\n",
      "Error on this batch = 0.19325905784065767\n",
      "Cost on val dataset after 217 epochs is = 0.20078540211555698\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.20078540211555698\n",
      "Error on this batch = 0.1717208965400257\n",
      "Error on this batch = 0.19312721216922943\n",
      "Cost on val dataset after 218 epochs is = 0.20070091677757176\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.20070091677757176\n",
      "Error on this batch = 0.17145177116170138\n",
      "Error on this batch = 0.19299583346768734\n",
      "Cost on val dataset after 219 epochs is = 0.20061995197738441\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.20061995197738441\n",
      "Error on this batch = 0.17117740230912187\n",
      "Error on this batch = 0.19286489311528027\n",
      "Cost on val dataset after 220 epochs is = 0.20054234417976663\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.20054234417976663\n",
      "Error on this batch = 0.1708996233790483\n",
      "Error on this batch = 0.19273434919833846\n",
      "Cost on val dataset after 221 epochs is = 0.20046790114324903\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.20046790114324903\n",
      "Error on this batch = 0.17062048165300117\n",
      "Error on this batch = 0.19260415329390035\n",
      "Cost on val dataset after 222 epochs is = 0.2003964300264569\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.2003964300264569\n",
      "Error on this batch = 0.1703420356168287\n",
      "Error on this batch = 0.19247425702652976\n",
      "Cost on val dataset after 223 epochs is = 0.20032776159753576\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.20032776159753576\n",
      "Error on this batch = 0.17006616043501432\n",
      "Error on this batch = 0.19234461595276373\n",
      "Cost on val dataset after 224 epochs is = 0.200261765593756\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.200261765593756\n",
      "Error on this batch = 0.16979440349105032\n",
      "Error on this batch = 0.19221518973315962\n",
      "Cost on val dataset after 225 epochs is = 0.20019835555820661\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.20019835555820661\n",
      "Error on this batch = 0.16952791229457706\n",
      "Error on this batch = 0.19208593921916337\n",
      "Cost on val dataset after 226 epochs is = 0.20013748456041805\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.20013748456041805\n",
      "Error on this batch = 0.16926743258547824\n",
      "Error on this batch = 0.19195682219032123\n",
      "Cost on val dataset after 227 epochs is = 0.2000791350927544\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.2000791350927544\n",
      "Error on this batch = 0.16901335680470161\n",
      "Error on this batch = 0.19182778964724498\n",
      "Cost on val dataset after 228 epochs is = 0.2000233068402582\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.2000233068402582\n",
      "Error on this batch = 0.16876579737724498\n",
      "Error on this batch = 0.19169878396779289\n",
      "Cost on val dataset after 229 epochs is = 0.1999700053106511\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.1999700053106511\n",
      "Error on this batch = 0.16852466325862125\n",
      "Error on this batch = 0.19156973932051258\n",
      "Cost on val dataset after 230 epochs is = 0.19991923310860144\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.19991923310860144\n",
      "Error on this batch = 0.16828972644867196\n",
      "Error on this batch = 0.1914405839169418\n",
      "Cost on val dataset after 231 epochs is = 0.19987098447021698\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.19987098447021698\n",
      "Error on this batch = 0.1680606730577598\n",
      "Error on this batch = 0.19131124320619847\n",
      "Cost on val dataset after 232 epochs is = 0.1998252428181475\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.1998252428181475\n",
      "Error on this batch = 0.16783713887595986\n",
      "Error on this batch = 0.19118164303008442\n",
      "Cost on val dataset after 233 epochs is = 0.19978198061726388\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.19978198061726388\n",
      "Error on this batch = 0.167618732094669\n",
      "Error on this batch = 0.19105171200374874\n",
      "Cost on val dataset after 234 epochs is = 0.19974116064875802\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.19974116064875802\n",
      "Error on this batch = 0.1674050466100728\n",
      "Error on this batch = 0.1909213828286037\n",
      "Cost on val dataset after 235 epochs is = 0.19970273787954493\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.19970273787954493\n",
      "Error on this batch = 0.16719566905531963\n",
      "Error on this batch = 0.19079059270697493\n",
      "Cost on val dataset after 236 epochs is = 0.1996666612882103\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.1996666612882103\n",
      "Error on this batch = 0.1669901819995271\n",
      "Error on this batch = 0.1906592833554491\n",
      "Cost on val dataset after 237 epochs is = 0.19963287523985562\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.19963287523985562\n",
      "Error on this batch = 0.1667881649937403\n",
      "Error on this batch = 0.19052740122031672\n",
      "Cost on val dataset after 238 epochs is = 0.19960132022431581\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.19960132022431581\n",
      "Error on this batch = 0.16658919451851406\n",
      "Error on this batch = 0.19039489838918244\n",
      "Cost on val dataset after 239 epochs is = 0.1995719329544133\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.1995719329544133\n",
      "Error on this batch = 0.16639284345791303\n",
      "Error on this batch = 0.19026173443806485\n",
      "Cost on val dataset after 240 epochs is = 0.19954464595483623\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.19954464595483623\n",
      "Error on this batch = 0.16619868049346057\n",
      "Error on this batch = 0.19012787913864007\n",
      "Cost on val dataset after 241 epochs is = 0.19951938686492157\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.19951938686492157\n",
      "Error on this batch = 0.16600626975858848\n",
      "Error on this batch = 0.1899933156398764\n",
      "Cost on val dataset after 242 epochs is = 0.1994960777416981\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.1994960777416981\n",
      "Error on this batch = 0.165815171188553\n",
      "Error on this batch = 0.18985804347347335\n",
      "Cost on val dataset after 243 epochs is = 0.19947463468832394\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.19947463468832394\n",
      "Error on this batch = 0.1656249421921293\n",
      "Error on this batch = 0.18972208055882522\n",
      "Cost on val dataset after 244 epochs is = 0.1994549681387328\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.1994549681387328\n",
      "Error on this batch = 0.1654351414677071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.18958546337864612\n",
      "Cost on val dataset after 245 epochs is = 0.1994369840773405\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.1994369840773405\n",
      "Error on this batch = 0.16524533583903506\n",
      "Error on this batch = 0.18944824476555874\n",
      "Cost on val dataset after 246 epochs is = 0.19942058633161452\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.19942058633161452\n",
      "Error on this batch = 0.16505511071029488\n",
      "Error on this batch = 0.18931048934901298\n",
      "Cost on val dataset after 247 epochs is = 0.19940567982953886\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.19940567982953886\n",
      "Error on this batch = 0.16486408399936037\n",
      "Error on this batch = 0.18917226757690223\n",
      "Cost on val dataset after 248 epochs is = 0.1993921743954883\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.1993921743954883\n",
      "Error on this batch = 0.1646719222495642\n",
      "Error on this batch = 0.18903365003546374\n",
      "Cost on val dataset after 249 epochs is = 0.19937998836569856\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.19937998836569856\n",
      "Error on this batch = 0.16447835638542177\n",
      "Error on this batch = 0.18889470408383674\n",
      "Cost on val dataset after 250 epochs is = 0.19936905117979092\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.19936905117979092\n",
      "Error on this batch = 0.16428319384454199\n",
      "Error on this batch = 0.18875549426404667\n",
      "Cost on val dataset after 251 epochs is = 0.19935930425346382\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.19935930425346382\n",
      "Error on this batch = 0.16408632410485813\n",
      "Error on this batch = 0.1886160866478982\n",
      "Cost on val dataset after 252 epochs is = 0.1993506998425113\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.1993506998425113\n",
      "Error on this batch = 0.16388771600404206\n",
      "Error on this batch = 0.18847655581754325\n",
      "Cost on val dataset after 253 epochs is = 0.19934319811210188\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.19934319811210188\n",
      "Error on this batch = 0.16368740718565997\n",
      "Error on this batch = 0.18833699224756228\n",
      "Cost on val dataset after 254 epochs is = 0.1993367630138902\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.1993367630138902\n",
      "Error on this batch = 0.1634854876487487\n",
      "Error on this batch = 0.18819750781795017\n",
      "Cost on val dataset after 255 epochs is = 0.1993313577014126\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.1993313577014126\n",
      "Error on this batch = 0.1632820800578105\n",
      "Error on this batch = 0.18805823786258274\n",
      "Cost on val dataset after 256 epochs is = 0.19932694006764842\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.19932694006764842\n",
      "Error on this batch = 0.16307731904323106\n",
      "Error on this batch = 0.18791933904918087\n",
      "Cost on val dataset after 257 epochs is = 0.199323458652401\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.199323458652401\n",
      "Error on this batch = 0.16287133049255698\n",
      "Error on this batch = 0.1877809830340841\n",
      "Cost on val dataset after 258 epochs is = 0.1993208487457204\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.1993208487457204\n",
      "Error on this batch = 0.16266421023158983\n",
      "Error on this batch = 0.18764334602637242\n",
      "Cost on val dataset after 259 epochs is = 0.19931902807785098\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.19931902807785098\n",
      "Error on this batch = 0.1624559997815784\n",
      "Error on this batch = 0.18750659415444723\n",
      "Cost on val dataset after 260 epochs is = 0.19931789107344097\n",
      "cost initial= 0.19931902807785098 , cost final=0.19931789107344097 , change in cost= -1.137004410012299e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 10 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 260\n",
      "The training time = 20.370sec\n",
      "The training accuracy is = 81.258%\n",
      "The validation accuracy is = 72.821%\n",
      "The test accuracy is = 72.108%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 50 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 50)\n",
      "theta between layer 1 and layer 2 is (51, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.4198192865048322\n",
      "Error on this batch = 3.4202848064809017\n",
      "Error on this batch = 0.480167146283967\n",
      "Cost on val dataset after 2 epochs is = 0.47945217515538197\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.47945217515538197\n",
      "Error on this batch = 0.4790290624106092\n",
      "Error on this batch = 0.4780468422892399\n",
      "Cost on val dataset after 3 epochs is = 0.4764234998038342\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4764234998038342\n",
      "Error on this batch = 0.47585081348813\n",
      "Error on this batch = 0.4732062217893474\n",
      "Cost on val dataset after 4 epochs is = 0.4683659492303805\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4683659492303805\n",
      "Error on this batch = 0.46721321034686847\n",
      "Error on this batch = 0.45808700067627817\n",
      "Cost on val dataset after 5 epochs is = 0.4396709445195497\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4396709445195497\n",
      "Error on this batch = 0.43678415250092856\n",
      "Error on this batch = 0.42423064788165804\n",
      "Cost on val dataset after 6 epochs is = 0.394059992931313\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.394059992931313\n",
      "Error on this batch = 0.3894123656168105\n",
      "Error on this batch = 0.38308619431036633\n",
      "Cost on val dataset after 7 epochs is = 0.3406334244798474\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.3406334244798474\n",
      "Error on this batch = 0.3345848851152849\n",
      "Error on this batch = 0.3402373591349204\n",
      "Cost on val dataset after 8 epochs is = 0.296411755959325\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.296411755959325\n",
      "Error on this batch = 0.2872930051071299\n",
      "Error on this batch = 0.30238142980918176\n",
      "Cost on val dataset after 9 epochs is = 0.26099520641783597\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.26099520641783597\n",
      "Error on this batch = 0.24736678768446355\n",
      "Error on this batch = 0.27083925872322007\n",
      "Cost on val dataset after 10 epochs is = 0.23352772505579936\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.23352772505579936\n",
      "Error on this batch = 0.21573366199006994\n",
      "Error on this batch = 0.2467986711826115\n",
      "Cost on val dataset after 11 epochs is = 0.21294627641301359\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.21294627641301359\n",
      "Error on this batch = 0.19240040616000534\n",
      "Error on this batch = 0.22879737577312448\n",
      "Cost on val dataset after 12 epochs is = 0.19731383699021196\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.19731383699021196\n",
      "Error on this batch = 0.17523801341825\n",
      "Error on this batch = 0.2147087630318286\n",
      "Cost on val dataset after 13 epochs is = 0.1851216856756727\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.1851216856756727\n",
      "Error on this batch = 0.16212401920527847\n",
      "Error on this batch = 0.2031646231963936\n",
      "Cost on val dataset after 14 epochs is = 0.17540655701856991\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.17540655701856991\n",
      "Error on this batch = 0.15165373668574708\n",
      "Error on this batch = 0.19342293981465822\n",
      "Cost on val dataset after 15 epochs is = 0.1675145964178297\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.1675145964178297\n",
      "Error on this batch = 0.14298511101994685\n",
      "Error on this batch = 0.18504885708263769\n",
      "Cost on val dataset after 16 epochs is = 0.16098120355786932\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.16098120355786932\n",
      "Error on this batch = 0.13561584744142113\n",
      "Error on this batch = 0.17775192983536706\n",
      "Cost on val dataset after 17 epochs is = 0.15547690927582222\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.15547690927582222\n",
      "Error on this batch = 0.1292367562693988\n",
      "Error on this batch = 0.1713219769814191\n",
      "Cost on val dataset after 18 epochs is = 0.15076761395823976\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.15076761395823976\n",
      "Error on this batch = 0.1236464458015341\n",
      "Error on this batch = 0.16560163213906098\n",
      "Cost on val dataset after 19 epochs is = 0.14668427565866793\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.14668427565866793\n",
      "Error on this batch = 0.11870403095480214\n",
      "Error on this batch = 0.1604709152842825\n",
      "Cost on val dataset after 20 epochs is = 0.1431021936733553\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.1431021936733553\n",
      "Error on this batch = 0.11430317152465086\n",
      "Error on this batch = 0.15583709179125277\n",
      "Cost on val dataset after 21 epochs is = 0.13992749747924568\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.13992749747924568\n",
      "Error on this batch = 0.1103580280547404\n",
      "Error on this batch = 0.15162768363461143\n",
      "Cost on val dataset after 22 epochs is = 0.13708828427448397\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.13708828427448397\n",
      "Error on this batch = 0.10679621652423794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1477853764537962\n",
      "Cost on val dataset after 23 epochs is = 0.13452864178093413\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.13452864178093413\n",
      "Error on this batch = 0.10355569313271877\n",
      "Error on this batch = 0.14426410799243541\n",
      "Cost on val dataset after 24 epochs is = 0.13220450144338483\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.13220450144338483\n",
      "Error on this batch = 0.10058336617533536\n",
      "Error on this batch = 0.14102603752851361\n",
      "Cost on val dataset after 25 epochs is = 0.130080700108994\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.130080700108994\n",
      "Error on this batch = 0.09783416635099666\n",
      "Error on this batch = 0.1380392652252828\n",
      "Cost on val dataset after 26 epochs is = 0.1281288654784933\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.1281288654784933\n",
      "Error on this batch = 0.09527015217029189\n",
      "Error on this batch = 0.1352761924485992\n",
      "Cost on val dataset after 27 epochs is = 0.1263258735202972\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.1263258735202972\n",
      "Error on this batch = 0.09285964887911602\n",
      "Error on this batch = 0.13271240183948332\n",
      "Cost on val dataset after 28 epochs is = 0.12465270609091252\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.12465270609091252\n",
      "Error on this batch = 0.09057648129514619\n",
      "Error on this batch = 0.13032593492301595\n",
      "Cost on val dataset after 29 epochs is = 0.12309359003405561\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.12309359003405561\n",
      "Error on this batch = 0.08839930259709246\n",
      "Error on this batch = 0.1280968575042784\n",
      "Cost on val dataset after 30 epochs is = 0.12163533804937567\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.12163533804937567\n",
      "Error on this batch = 0.08631099128291023\n",
      "Error on this batch = 0.12600701950306686\n",
      "Cost on val dataset after 31 epochs is = 0.12026684027564186\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.12026684027564186\n",
      "Error on this batch = 0.08429810509418718\n",
      "Error on this batch = 0.1240399316332627\n",
      "Cost on val dataset after 32 epochs is = 0.11897867312023896\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.11897867312023896\n",
      "Error on this batch = 0.08235040374779555\n",
      "Error on this batch = 0.12218069799653013\n",
      "Cost on val dataset after 33 epochs is = 0.11776279982968169\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.11776279982968169\n",
      "Error on this batch = 0.0804604523495605\n",
      "Error on this batch = 0.12041596252684776\n",
      "Cost on val dataset after 34 epochs is = 0.116612340389587\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.116612340389587\n",
      "Error on this batch = 0.07862329475972869\n",
      "Error on this batch = 0.11873384612240066\n",
      "Cost on val dataset after 35 epochs is = 0.1155213910823697\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.1155213910823697\n",
      "Error on this batch = 0.07683615777022133\n",
      "Error on this batch = 0.11712386690340534\n",
      "Cost on val dataset after 36 epochs is = 0.11448487810349832\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.11448487810349832\n",
      "Error on this batch = 0.07509813095350525\n",
      "Error on this batch = 0.11557684681534579\n",
      "Cost on val dataset after 37 epochs is = 0.11349843439130587\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.11349843439130587\n",
      "Error on this batch = 0.07340977548361476\n",
      "Error on this batch = 0.114084814227976\n",
      "Cost on val dataset after 38 epochs is = 0.1125582930280483\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.1125582930280483\n",
      "Error on this batch = 0.07177264882243295\n",
      "Error on this batch = 0.11264091503284802\n",
      "Cost on val dataset after 39 epochs is = 0.11166119354494772\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.11166119354494772\n",
      "Error on this batch = 0.07018877784113993\n",
      "Error on this batch = 0.11123934391357779\n",
      "Cost on val dataset after 40 epochs is = 0.1108042992237551\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.1108042992237551\n",
      "Error on this batch = 0.06866014912786483\n",
      "Error on this batch = 0.10987530231533316\n",
      "Cost on val dataset after 41 epochs is = 0.10998512436840509\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.10998512436840509\n",
      "Error on this batch = 0.0671882940083801\n",
      "Error on this batch = 0.10854498021766704\n",
      "Cost on val dataset after 42 epochs is = 0.10920147085943904\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.10920147085943904\n",
      "Error on this batch = 0.06577402370011702\n",
      "Error on this batch = 0.1072455469245634\n",
      "Cost on val dataset after 43 epochs is = 0.10845137333519785\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.10845137333519785\n",
      "Error on this batch = 0.06441732933234344\n",
      "Error on this batch = 0.10597512560260468\n",
      "Cost on val dataset after 44 epochs is = 0.10773305223695707\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.10773305223695707\n",
      "Error on this batch = 0.06311742178285118\n",
      "Error on this batch = 0.10473272240372584\n",
      "Cost on val dataset after 45 epochs is = 0.10704487387709297\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.10704487387709297\n",
      "Error on this batch = 0.061872862511612094\n",
      "Error on this batch = 0.1035180882217814\n",
      "Cost on val dataset after 46 epochs is = 0.10638531681490458\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.10638531681490458\n",
      "Error on this batch = 0.060681733124708225\n",
      "Error on this batch = 0.102331510384962\n",
      "Cost on val dataset after 47 epochs is = 0.10575294425068384\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.10575294425068384\n",
      "Error on this batch = 0.05954180309612015\n",
      "Error on this batch = 0.10117355764626938\n",
      "Cost on val dataset after 48 epochs is = 0.10514638274075087\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.10514638274075087\n",
      "Error on this batch = 0.058450672773996126\n",
      "Error on this batch = 0.10004482362507551\n",
      "Cost on val dataset after 49 epochs is = 0.10456430788417204\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.10456430788417204\n",
      "Error on this batch = 0.05740588450140074\n",
      "Error on this batch = 0.0989457196438217\n",
      "Cost on val dataset after 50 epochs is = 0.10400543730186776\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.10400543730186776\n",
      "Error on this batch = 0.05640500413437154\n",
      "Error on this batch = 0.0978763532565754\n",
      "Cost on val dataset after 51 epochs is = 0.10346853019596426\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.10346853019596426\n",
      "Error on this batch = 0.05544567826097122\n",
      "Error on this batch = 0.0968365007089196\n",
      "Cost on val dataset after 52 epochs is = 0.10295239158153884\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.10295239158153884\n",
      "Error on this batch = 0.05452567159823687\n",
      "Error on this batch = 0.09582565425061539\n",
      "Cost on val dataset after 53 epochs is = 0.10245587864159034\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.10245587864159034\n",
      "Error on this batch = 0.05364288751482259\n",
      "Error on this batch = 0.09484311033096593\n",
      "Cost on val dataset after 54 epochs is = 0.1019779068899971\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.1019779068899971\n",
      "Error on this batch = 0.052795374204895204\n",
      "Error on this batch = 0.09388806500049214\n",
      "Cost on val dataset after 55 epochs is = 0.10151745468217965\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.10151745468217965\n",
      "Error on this batch = 0.05198131970339418\n",
      "Error on this batch = 0.09295969317313935\n",
      "Cost on val dataset after 56 epochs is = 0.10107356557032043\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.10107356557032043\n",
      "Error on this batch = 0.051199039697887645\n",
      "Error on this batch = 0.09205720124428683\n",
      "Cost on val dataset after 57 epochs is = 0.10064534867451075\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.10064534867451075\n",
      "Error on this batch = 0.05044696214917982\n",
      "Error on this batch = 0.09117985264475642\n",
      "Cost on val dataset after 58 epochs is = 0.10023197753288512\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.10023197753288512\n",
      "Error on this batch = 0.04972361195710105\n",
      "Error on this batch = 0.0903269715235141\n",
      "Cost on val dataset after 59 epochs is = 0.09983268790116774\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.09983268790116774\n",
      "Error on this batch = 0.04902759767909698\n",
      "Error on this batch = 0.08949793160916243\n",
      "Cost on val dataset after 60 epochs is = 0.09944677484773555\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.09944677484773555\n",
      "Error on this batch = 0.0483576011061672\n",
      "Error on this batch = 0.08869213693035638\n",
      "Cost on val dataset after 61 epochs is = 0.09907358935160764\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.09907358935160764\n",
      "Error on this batch = 0.04771236963478087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.087908999781279\n",
      "Cost on val dataset after 62 epochs is = 0.09871253451570429\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.09871253451570429\n",
      "Error on this batch = 0.047090710929073264\n",
      "Error on this batch = 0.08714791985791602\n",
      "Cost on val dataset after 63 epochs is = 0.09836306146628139\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.09836306146628139\n",
      "Error on this batch = 0.04649148926461361\n",
      "Error on this batch = 0.08640826716686699\n",
      "Cost on val dataset after 64 epochs is = 0.09802466500539163\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.09802466500539163\n",
      "Error on this batch = 0.04591362303206497\n",
      "Error on this batch = 0.0856893701772751\n",
      "Cost on val dataset after 65 epochs is = 0.09769687909457717\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.09769687909457717\n",
      "Error on this batch = 0.045356083012048874\n",
      "Error on this batch = 0.08499050972964156\n",
      "Cost on val dataset after 66 epochs is = 0.09737927226094513\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.09737927226094513\n",
      "Error on this batch = 0.04481789112151462\n",
      "Error on this batch = 0.08431091842929102\n",
      "Cost on val dataset after 67 epochs is = 0.09707144302994704\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.09707144302994704\n",
      "Error on this batch = 0.044298119355588556\n",
      "Error on this batch = 0.08364978466593691\n",
      "Cost on val dataset after 68 epochs is = 0.09677301550826262\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.09677301550826262\n",
      "Error on this batch = 0.04379588864200404\n",
      "Error on this batch = 0.08300626004943268\n",
      "Cost on val dataset after 69 epochs is = 0.09648363526707061\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.09648363526707061\n",
      "Error on this batch = 0.04331036734731626\n",
      "Error on this batch = 0.0823794689416562\n",
      "Cost on val dataset after 70 epochs is = 0.09620296570003335\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.09620296570003335\n",
      "Error on this batch = 0.042840769270540806\n",
      "Error on this batch = 0.08176851885539069\n",
      "Cost on val dataset after 71 epochs is = 0.09593068502917466\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.09593068502917466\n",
      "Error on this batch = 0.04238635112964026\n",
      "Error on this batch = 0.08117251070798416\n",
      "Cost on val dataset after 72 epochs is = 0.09566648408407345\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.09566648408407345\n",
      "Error on this batch = 0.041946409734028085\n",
      "Error on this batch = 0.08059054818267822\n",
      "Cost on val dataset after 73 epochs is = 0.0954100648825732\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.0954100648825732\n",
      "Error on this batch = 0.041520279159085814\n",
      "Error on this batch = 0.08002174571384245\n",
      "Cost on val dataset after 74 epochs is = 0.09516113991903632\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.09516113991903632\n",
      "Error on this batch = 0.041107328237465025\n",
      "Error on this batch = 0.079465234858912\n",
      "Cost on val dataset after 75 epochs is = 0.0949194319612147\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.0949194319612147\n",
      "Error on this batch = 0.04070695856177919\n",
      "Error on this batch = 0.0789201690489894\n",
      "Cost on val dataset after 76 epochs is = 0.0946846741056622\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.0946846741056622\n",
      "Error on this batch = 0.040318603020128345\n",
      "Error on this batch = 0.07838572690900471\n",
      "Cost on val dataset after 77 epochs is = 0.09445660985598675\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.09445660985598675\n",
      "Error on this batch = 0.039941724742104494\n",
      "Error on this batch = 0.0778611144773989\n",
      "Cost on val dataset after 78 epochs is = 0.0942349930525289\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.0942349930525289\n",
      "Error on this batch = 0.03957581626956719\n",
      "Error on this batch = 0.07734556670895917\n",
      "Cost on val dataset after 79 epochs is = 0.09401958756599452\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.09401958756599452\n",
      "Error on this batch = 0.039220398786128256\n",
      "Error on this batch = 0.07683834861339593\n",
      "Cost on val dataset after 80 epochs is = 0.09381016674221997\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.09381016674221997\n",
      "Error on this batch = 0.03887502131050945\n",
      "Error on this batch = 0.07633875629485393\n",
      "Cost on val dataset after 81 epochs is = 0.09360651263310574\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.09360651263310574\n",
      "Error on this batch = 0.03853925984181944\n",
      "Error on this batch = 0.07584611805290692\n",
      "Cost on val dataset after 82 epochs is = 0.09340841506595202\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.09340841506595202\n",
      "Error on this batch = 0.038212716509486724\n",
      "Error on this batch = 0.07535979561556656\n",
      "Cost on val dataset after 83 epochs is = 0.0932156705965771\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.0932156705965771\n",
      "Error on this batch = 0.03789501881381442\n",
      "Error on this batch = 0.07487918551605136\n",
      "Cost on val dataset after 84 epochs is = 0.09302808137266906\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.09302808137266906\n",
      "Error on this batch = 0.03758581904545059\n",
      "Error on this batch = 0.0744037205996472\n",
      "Cost on val dataset after 85 epochs is = 0.09284545391556033\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.09284545391556033\n",
      "Error on this batch = 0.037284793950251846\n",
      "Error on this batch = 0.07393287164569755\n",
      "Cost on val dataset after 86 epochs is = 0.09266759782198704\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.09266759782198704\n",
      "Error on this batch = 0.036991644664633644\n",
      "Error on this batch = 0.07346614909349734\n",
      "Cost on val dataset after 87 epochs is = 0.09249432440119613\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.09249432440119613\n",
      "Error on this batch = 0.03670609688219243\n",
      "Error on this batch = 0.07300310484144729\n",
      "Cost on val dataset after 88 epochs is = 0.09232544530433492\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.09232544530433492\n",
      "Error on this batch = 0.03642790111382983\n",
      "Error on this batch = 0.07254333401302582\n",
      "Cost on val dataset after 89 epochs is = 0.0921607712774927\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.0921607712774927\n",
      "Error on this batch = 0.03615683275985442\n",
      "Error on this batch = 0.07208647642519508\n",
      "Cost on val dataset after 90 epochs is = 0.09200011127436096\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.09200011127436096\n",
      "Error on this batch = 0.03589269153129937\n",
      "Error on this batch = 0.0716322172612297\n",
      "Cost on val dataset after 91 epochs is = 0.09184327227672069\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.09184327227672069\n",
      "Error on this batch = 0.03563529959049857\n",
      "Error on this batch = 0.07118028621264469\n",
      "Cost on val dataset after 92 epochs is = 0.09169006023589271\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.09169006023589271\n",
      "Error on this batch = 0.03538449773980227\n",
      "Error on this batch = 0.07073045427248388\n",
      "Cost on val dataset after 93 epochs is = 0.09154028248400094\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.09154028248400094\n",
      "Error on this batch = 0.03514013922093321\n",
      "Error on this batch = 0.07028252764509808\n",
      "Cost on val dataset after 94 epochs is = 0.09139375171024039\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.09139375171024039\n",
      "Error on this batch = 0.03490208128546733\n",
      "Error on this batch = 0.06983633901599884\n",
      "Cost on val dataset after 95 epochs is = 0.09125029120264641\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.09125029120264641\n",
      "Error on this batch = 0.03467017554364154\n",
      "Error on this batch = 0.0693917375547026\n",
      "Cost on val dataset after 96 epochs is = 0.09110974072482479\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.09110974072482479\n",
      "Error on this batch = 0.034444258803044046\n",
      "Error on this batch = 0.06894857999720944\n",
      "Cost on val dataset after 97 epochs is = 0.09097196238998832\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.09097196238998832\n",
      "Error on this batch = 0.03422414617309865\n",
      "Error on this batch = 0.06850672533288854\n",
      "Cost on val dataset after 98 epochs is = 0.09083684629359597\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.09083684629359597\n",
      "Error on this batch = 0.03400962742063018\n",
      "Error on this batch = 0.06806603472200355\n",
      "Cost on val dataset after 99 epochs is = 0.0907043162298415\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.0907043162298415\n",
      "Error on this batch = 0.03380046627132963\n",
      "Error on this batch = 0.06762637669758091\n",
      "Cost on val dataset after 100 epochs is = 0.09057433612027532\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.09057433612027532\n",
      "Error on this batch = 0.03359640133729835\n",
      "Error on this batch = 0.06718763630437682\n",
      "Cost on val dataset after 101 epochs is = 0.0904469175105564\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.0904469175105564\n",
      "Error on this batch = 0.03339714731501949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06674972625603698\n",
      "Cost on val dataset after 102 epochs is = 0.09032212759692788\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.09032212759692788\n",
      "Error on this batch = 0.03320239627687999\n",
      "Error on this batch = 0.0663125984944603\n",
      "Cost on val dataset after 103 epochs is = 0.09020009591403082\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.09020009591403082\n",
      "Error on this batch = 0.033011820952825885\n",
      "Error on this batch = 0.06587625524850843\n",
      "Cost on val dataset after 104 epochs is = 0.09008101646847098\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.09008101646847098\n",
      "Error on this batch = 0.032825083940701695\n",
      "Error on this batch = 0.06544075923810051\n",
      "Cost on val dataset after 105 epochs is = 0.08996514149038358\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.08996514149038358\n",
      "Error on this batch = 0.03264185705492927\n",
      "Error on this batch = 0.06500624267292962\n",
      "Cost on val dataset after 106 epochs is = 0.08985276404713217\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.08985276404713217\n",
      "Error on this batch = 0.03246185129171833\n",
      "Error on this batch = 0.06457291405963105\n",
      "Cost on val dataset after 107 epochs is = 0.08974418992975208\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.08974418992975208\n",
      "Error on this batch = 0.03228484966611056\n",
      "Error on this batch = 0.06414106084884423\n",
      "Cost on val dataset after 108 epochs is = 0.0896397034875964\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.0896397034875964\n",
      "Error on this batch = 0.03211072726338366\n",
      "Error on this batch = 0.06371104547187068\n",
      "Cost on val dataset after 109 epochs is = 0.08953953525696388\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.08953953525696388\n",
      "Error on this batch = 0.03193944445044752\n",
      "Error on this batch = 0.06328329342555963\n",
      "Cost on val dataset after 110 epochs is = 0.08944383937571151\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.08944383937571151\n",
      "Error on this batch = 0.031771013775483865\n",
      "Error on this batch = 0.06285827482244255\n",
      "Cost on val dataset after 111 epochs is = 0.08935268551025707\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.08935268551025707\n",
      "Error on this batch = 0.031605457637735576\n",
      "Error on this batch = 0.062436483396118736\n",
      "Cost on val dataset after 112 epochs is = 0.08926606482869558\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.08926606482869558\n",
      "Error on this batch = 0.031442776962533316\n",
      "Error on this batch = 0.06201841719405402\n",
      "Cost on val dataset after 113 epochs is = 0.08918390520230247\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.08918390520230247\n",
      "Error on this batch = 0.0312829398711487\n",
      "Error on this batch = 0.06160456315558867\n",
      "Cost on val dataset after 114 epochs is = 0.08910608947933206\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.08910608947933206\n",
      "Error on this batch = 0.03112588637111811\n",
      "Error on this batch = 0.061195385486694905\n",
      "Cost on val dataset after 115 epochs is = 0.08903247219221795\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.08903247219221795\n",
      "Error on this batch = 0.030971539978888765\n",
      "Error on this batch = 0.06079131673659829\n",
      "Cost on val dataset after 116 epochs is = 0.08896289258169339\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.08896289258169339\n",
      "Error on this batch = 0.030819819123039292\n",
      "Error on this batch = 0.06039275066129204\n",
      "Cost on val dataset after 117 epochs is = 0.08889718376175437\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.08889718376175437\n",
      "Error on this batch = 0.030670645118396296\n",
      "Error on this batch = 0.06000003649782077\n",
      "Cost on val dataset after 118 epochs is = 0.08883517876216958\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.08883517876216958\n",
      "Error on this batch = 0.03052394632396376\n",
      "Error on this batch = 0.05961347462716687\n",
      "Cost on val dataset after 119 epochs is = 0.088776714356358\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.088776714356358\n",
      "Error on this batch = 0.03037965932425068\n",
      "Error on this batch = 0.05923331369188553\n",
      "Cost on val dataset after 120 epochs is = 0.08872163341801888\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.08872163341801888\n",
      "Error on this batch = 0.03023772820489948\n",
      "Error on this batch = 0.05885974918034712\n",
      "Cost on val dataset after 121 epochs is = 0.08866978631063177\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.08866978631063177\n",
      "Error on this batch = 0.030098102822349277\n",
      "Error on this batch = 0.05849292340843612\n",
      "Cost on val dataset after 122 epochs is = 0.08862103161077577\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.08862103161077577\n",
      "Error on this batch = 0.029960736711003855\n",
      "Error on this batch = 0.05813292677249113\n",
      "Cost on val dataset after 123 epochs is = 0.08857523632673373\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.08857523632673373\n",
      "Error on this batch = 0.029825585045726983\n",
      "Error on this batch = 0.05777980011927108\n",
      "Cost on val dataset after 124 epochs is = 0.08853227569312723\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.08853227569312723\n",
      "Error on this batch = 0.029692602905201166\n",
      "Error on this batch = 0.05743353806920599\n",
      "Cost on val dataset after 125 epochs is = 0.08849203258699329\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.08849203258699329\n",
      "Error on this batch = 0.029561743956064035\n",
      "Error on this batch = 0.05709409312855373\n",
      "Cost on val dataset after 126 epochs is = 0.08845439660692984\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.08845439660692984\n",
      "Error on this batch = 0.029432959588206912\n",
      "Error on this batch = 0.05676138043018868\n",
      "Cost on val dataset after 127 epochs is = 0.08841926287206091\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.08841926287206091\n",
      "Error on this batch = 0.02930619847040784\n",
      "Error on this batch = 0.056435282951271634\n",
      "Cost on val dataset after 128 epochs is = 0.08838653062035211\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.08838653062035211\n",
      "Error on this batch = 0.02918140645743106\n",
      "Error on this batch = 0.056115657069660055\n",
      "Cost on val dataset after 129 epochs is = 0.08835610170676873\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.08835610170676873\n",
      "Error on this batch = 0.029058526760802703\n",
      "Error on this batch = 0.05580233833925602\n",
      "Cost on val dataset after 130 epochs is = 0.08832787911384125\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.08832787911384125\n",
      "Error on this batch = 0.02893750029167376\n",
      "Error on this batch = 0.055495147385288705\n",
      "Cost on val dataset after 131 epochs is = 0.0883017655862758\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.0883017655862758\n",
      "Error on this batch = 0.02881826609135386\n",
      "Error on this batch = 0.055193895839737384\n",
      "Cost on val dataset after 132 epochs is = 0.0882776624863244\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.0882776624863244\n",
      "Error on this batch = 0.028700761779264852\n",
      "Error on this batch = 0.05489839224950334\n",
      "Cost on val dataset after 133 epochs is = 0.0882554689395446\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.0882554689395446\n",
      "Error on this batch = 0.028584923965908057\n",
      "Error on this batch = 0.0546084478902247\n",
      "Cost on val dataset after 134 epochs is = 0.0882350813054413\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.0882350813054413\n",
      "Error on this batch = 0.02847068859768309\n",
      "Error on this batch = 0.05432388240245314\n",
      "Cost on val dataset after 135 epochs is = 0.08821639297001731\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.08821639297001731\n",
      "Error on this batch = 0.028357991219949193\n",
      "Error on this batch = 0.05404452913169097\n",
      "Cost on val dataset after 136 epochs is = 0.08819929442416886\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.08819929442416886\n",
      "Error on this batch = 0.028246767164651753\n",
      "Error on this batch = 0.05377023999870875\n",
      "Cost on val dataset after 137 epochs is = 0.08818367357008029\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.08818367357008029\n",
      "Error on this batch = 0.028136951690266736\n",
      "Error on this batch = 0.05350088965161921\n",
      "Cost on val dataset after 138 epochs is = 0.08816941619329118\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.08816941619329118\n",
      "Error on this batch = 0.02802848012669609\n",
      "Error on this batch = 0.053236378555394044\n",
      "Cost on val dataset after 139 epochs is = 0.08815640655401016\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.08815640655401016\n",
      "Error on this batch = 0.027921288108175395\n",
      "Error on this batch = 0.05297663455455526\n",
      "Cost on val dataset after 140 epochs is = 0.08814452808443154\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.08814452808443154\n",
      "Error on this batch = 0.027815312013455405\n",
      "Error on this batch = 0.052721612296583786\n",
      "Cost on val dataset after 141 epochs is = 0.08813366421548675\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.08813366421548675\n",
      "Error on this batch = 0.027710489768418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.0524712897317359\n",
      "Cost on val dataset after 142 epochs is = 0.08812369936793361\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.08812369936793361\n",
      "Error on this batch = 0.027606762182547016\n",
      "Error on this batch = 0.05222566074735013\n",
      "Cost on val dataset after 143 epochs is = 0.08811452008682992\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.08811452008682992\n",
      "Error on this batch = 0.02750407494815466\n",
      "Error on this batch = 0.05198472297212236\n",
      "Cost on val dataset after 144 epochs is = 0.08810601613702268\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.08810601613702268\n",
      "Error on this batch = 0.027402381273175857\n",
      "Error on this batch = 0.051748460179649076\n",
      "Cost on val dataset after 145 epochs is = 0.08809808111954542\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.08809808111954542\n",
      "Error on this batch = 0.02730164479378902\n",
      "Error on this batch = 0.05151682004523945\n",
      "Cost on val dataset after 146 epochs is = 0.08809061193777072\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.08809061193777072\n",
      "Error on this batch = 0.027201841932745642\n",
      "Error on this batch = 0.051289690928685135\n",
      "Cost on val dataset after 147 epochs is = 0.08808350652368421\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.08808350652368421\n",
      "Error on this batch = 0.02710296238984673\n",
      "Error on this batch = 0.05106688606370816\n",
      "Cost on val dataset after 148 epochs is = 0.08807666001244427\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.08807666001244427\n",
      "Error on this batch = 0.027005006352644533\n",
      "Error on this batch = 0.050848148184988\n",
      "Cost on val dataset after 149 epochs is = 0.0880699611860501\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.0880699611860501\n",
      "Error on this batch = 0.026907977857548476\n",
      "Error on this batch = 0.05063318656916121\n",
      "Cost on val dataset after 150 epochs is = 0.08806329280707076\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.08806329280707076\n",
      "Error on this batch = 0.026811875853168736\n",
      "Error on this batch = 0.05042174445370291\n",
      "Cost on val dataset after 151 epochs is = 0.08805653951382203\n",
      "cost initial= 0.08806329280707076 , cost final=0.08805653951382203 , change in cost= -6.7532932487290864e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 50 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 151\n",
      "The training time = 19.428sec\n",
      "The training accuracy is = 95.900%\n",
      "The validation accuracy is = 89.641%\n",
      "The test accuracy is = 88.477%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 100 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.417146543324373\n",
      "Error on this batch = 3.419129840686809\n",
      "Error on this batch = 0.48051074016705453\n",
      "Cost on val dataset after 2 epochs is = 0.4782646363474272\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4782646363474272\n",
      "Error on this batch = 0.4769542035391652\n",
      "Error on this batch = 0.47596588098577985\n",
      "Cost on val dataset after 3 epochs is = 0.47086283768395515\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47086283768395515\n",
      "Error on this batch = 0.46988623045086825\n",
      "Error on this batch = 0.46168140199179014\n",
      "Cost on val dataset after 4 epochs is = 0.43997664452775787\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.43997664452775787\n",
      "Error on this batch = 0.4377081680220942\n",
      "Error on this batch = 0.4180406211954513\n",
      "Cost on val dataset after 5 epochs is = 0.38366264235468295\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.38366264235468295\n",
      "Error on this batch = 0.37817676568872627\n",
      "Error on this batch = 0.3703968829337984\n",
      "Cost on val dataset after 6 epochs is = 0.3239803083386801\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.3239803083386801\n",
      "Error on this batch = 0.3135608772608014\n",
      "Error on this batch = 0.32226860209357994\n",
      "Cost on val dataset after 7 epochs is = 0.27243658017209077\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.27243658017209077\n",
      "Error on this batch = 0.25595365831945033\n",
      "Error on this batch = 0.2818497652244164\n",
      "Cost on val dataset after 8 epochs is = 0.23675775822756176\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.23675775822756176\n",
      "Error on this batch = 0.21709148470222617\n",
      "Error on this batch = 0.2512156052727976\n",
      "Cost on val dataset after 9 epochs is = 0.21205481013340213\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.21205481013340213\n",
      "Error on this batch = 0.19079666784126134\n",
      "Error on this batch = 0.22925528850346585\n",
      "Cost on val dataset after 10 epochs is = 0.19462185967509302\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.19462185967509302\n",
      "Error on this batch = 0.17258271965929495\n",
      "Error on this batch = 0.213192468449185\n",
      "Cost on val dataset after 11 epochs is = 0.18176597194028862\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.18176597194028862\n",
      "Error on this batch = 0.15910149541599827\n",
      "Error on this batch = 0.20055750647820808\n",
      "Cost on val dataset after 12 epochs is = 0.17184833404626637\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.17184833404626637\n",
      "Error on this batch = 0.1483424328570384\n",
      "Error on this batch = 0.1900843445890414\n",
      "Cost on val dataset after 13 epochs is = 0.16393028166080417\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.16393028166080417\n",
      "Error on this batch = 0.13935711670696424\n",
      "Error on this batch = 0.18111236339910328\n",
      "Cost on val dataset after 14 epochs is = 0.15743112921236227\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.15743112921236227\n",
      "Error on this batch = 0.1316864387526349\n",
      "Error on this batch = 0.17326982662058618\n",
      "Cost on val dataset after 15 epochs is = 0.1519677831891075\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.1519677831891075\n",
      "Error on this batch = 0.12506927733608422\n",
      "Error on this batch = 0.16631761146325916\n",
      "Cost on val dataset after 16 epochs is = 0.14728045008569543\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.14728045008569543\n",
      "Error on this batch = 0.11932821559831741\n",
      "Error on this batch = 0.1600829249599746\n",
      "Cost on val dataset after 17 epochs is = 0.14319012042222376\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.14319012042222376\n",
      "Error on this batch = 0.11432327313153107\n",
      "Error on this batch = 0.15443775583275363\n",
      "Cost on val dataset after 18 epochs is = 0.1395709675380303\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.1395709675380303\n",
      "Error on this batch = 0.10993389971385184\n",
      "Error on this batch = 0.14928799533977313\n",
      "Cost on val dataset after 19 epochs is = 0.1363322278382418\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.1363322278382418\n",
      "Error on this batch = 0.10605367871185033\n",
      "Error on this batch = 0.14456352624478291\n",
      "Cost on val dataset after 20 epochs is = 0.13340652560745314\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.13340652560745314\n",
      "Error on this batch = 0.10258977678280105\n",
      "Error on this batch = 0.1402101876411909\n",
      "Cost on val dataset after 21 epochs is = 0.1307424295822074\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.1307424295822074\n",
      "Error on this batch = 0.09946336670241135\n",
      "Error on this batch = 0.13618445607105187\n",
      "Cost on val dataset after 22 epochs is = 0.12829970339614225\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.12829970339614225\n",
      "Error on this batch = 0.09660949288312697\n",
      "Error on this batch = 0.13245027111408758\n",
      "Cost on val dataset after 23 epochs is = 0.12604623201006718\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.12604623201006718\n",
      "Error on this batch = 0.09397603091039962\n",
      "Error on this batch = 0.12897713618828632\n",
      "Cost on val dataset after 24 epochs is = 0.12395597325720423\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.12395597325720423\n",
      "Error on this batch = 0.09152196764374271\n",
      "Error on this batch = 0.12573890159391382\n",
      "Cost on val dataset after 25 epochs is = 0.12200753976897437\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.12200753976897437\n",
      "Error on this batch = 0.08921539013894361\n",
      "Error on this batch = 0.12271292124862335\n",
      "Cost on val dataset after 26 epochs is = 0.12018318310160193\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.12018318310160193\n",
      "Error on this batch = 0.08703151150718277\n",
      "Error on this batch = 0.11987942763817047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 27 epochs is = 0.11846804694403232\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.11846804694403232\n",
      "Error on this batch = 0.08495093888467196\n",
      "Error on this batch = 0.11722104096286116\n",
      "Cost on val dataset after 28 epochs is = 0.11684960617837445\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.11684960617837445\n",
      "Error on this batch = 0.08295828151531222\n",
      "Error on this batch = 0.11472236978513987\n",
      "Cost on val dataset after 29 epochs is = 0.11531723662712846\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.11531723662712846\n",
      "Error on this batch = 0.08104112238627416\n",
      "Error on this batch = 0.11236968526423624\n",
      "Cost on val dataset after 30 epochs is = 0.11386187833313617\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.11386187833313617\n",
      "Error on this batch = 0.07918932662240954\n",
      "Error on this batch = 0.11015066065481458\n",
      "Cost on val dataset after 31 epochs is = 0.11247576677539255\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.11247576677539255\n",
      "Error on this batch = 0.07739462527038253\n",
      "Error on this batch = 0.10805416909237485\n",
      "Cost on val dataset after 32 epochs is = 0.11115221371078822\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.11115221371078822\n",
      "Error on this batch = 0.07565039306158328\n",
      "Error on this batch = 0.10607013387797148\n",
      "Cost on val dataset after 33 epochs is = 0.10988542527241675\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.10988542527241675\n",
      "Error on this batch = 0.07395153522713376\n",
      "Error on this batch = 0.10418942867234644\n",
      "Cost on val dataset after 34 epochs is = 0.10867035119230631\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.10867035119230631\n",
      "Error on this batch = 0.07229441024869881\n",
      "Error on this batch = 0.10240382731400903\n",
      "Cost on val dataset after 35 epochs is = 0.1075025644325328\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.1075025644325328\n",
      "Error on this batch = 0.07067673743187283\n",
      "Error on this batch = 0.10070599873904026\n",
      "Cost on val dataset after 36 epochs is = 0.10637817245561185\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.10637817245561185\n",
      "Error on this batch = 0.06909746399617134\n",
      "Error on this batch = 0.09908952649264458\n",
      "Cost on val dataset after 37 epochs is = 0.10529375837744669\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.10529375837744669\n",
      "Error on this batch = 0.06755658934678443\n",
      "Error on this batch = 0.09754891056030114\n",
      "Cost on val dataset after 38 epochs is = 0.10424634439766685\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.10424634439766685\n",
      "Error on this batch = 0.06605495759133334\n",
      "Error on this batch = 0.09607950495978239\n",
      "Cost on val dataset after 39 epochs is = 0.10323336663712207\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.10323336663712207\n",
      "Error on this batch = 0.06459403018520836\n",
      "Error on this batch = 0.0946773750473783\n",
      "Cost on val dataset after 40 epochs is = 0.10225265411209988\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.10225265411209988\n",
      "Error on this batch = 0.06317564480015868\n",
      "Error on this batch = 0.09333910413407892\n",
      "Cost on val dataset after 41 epochs is = 0.10130241285696868\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.10130241285696868\n",
      "Error on this batch = 0.061801765774191095\n",
      "Error on this batch = 0.09206160019661518\n",
      "Cost on val dataset after 42 epochs is = 0.100381221937385\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.100381221937385\n",
      "Error on this batch = 0.06047424061815216\n",
      "Error on this batch = 0.09084193852056269\n",
      "Cost on val dataset after 43 epochs is = 0.0994880458244496\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.0994880458244496\n",
      "Error on this batch = 0.05919458785267669\n",
      "Error on this batch = 0.08967724819806489\n",
      "Cost on val dataset after 44 epochs is = 0.0986222569229281\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.0986222569229281\n",
      "Error on this batch = 0.05796384241845466\n",
      "Error on this batch = 0.08856463448438831\n",
      "Cost on val dataset after 45 epochs is = 0.09778364657653708\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.09778364657653708\n",
      "Error on this batch = 0.056782473759967755\n",
      "Error on this batch = 0.08750113067092158\n",
      "Cost on val dataset after 46 epochs is = 0.0969723907630876\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.0969723907630876\n",
      "Error on this batch = 0.05565037567129849\n",
      "Error on this batch = 0.08648368295944366\n",
      "Cost on val dataset after 47 epochs is = 0.09618894067127581\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.09618894067127581\n",
      "Error on this batch = 0.054566913475948456\n",
      "Error on this batch = 0.08550917782789735\n",
      "Cost on val dataset after 48 epochs is = 0.09543383675509029\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.09543383675509029\n",
      "Error on this batch = 0.053531004745132775\n",
      "Error on this batch = 0.08457451608432895\n",
      "Cost on val dataset after 49 epochs is = 0.0947074867782936\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.0947074867782936\n",
      "Error on this batch = 0.05254120518383412\n",
      "Error on this batch = 0.08367671967255401\n",
      "Cost on val dataset after 50 epochs is = 0.09400997514033037\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.09400997514033037\n",
      "Error on this batch = 0.051595777827279844\n",
      "Error on this batch = 0.08281303478680062\n",
      "Cost on val dataset after 51 epochs is = 0.09334096204643422\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.09334096204643422\n",
      "Error on this batch = 0.05069274496717523\n",
      "Error on this batch = 0.08198098944730195\n",
      "Cost on val dataset after 52 epochs is = 0.0926996927752054\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.0926996927752054\n",
      "Error on this batch = 0.04982994238085652\n",
      "Error on this batch = 0.08117838967892023\n",
      "Cost on val dataset after 53 epochs is = 0.09208509252280533\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.09208509252280533\n",
      "Error on this batch = 0.049005091332101125\n",
      "Error on this batch = 0.0804032754404786\n",
      "Cost on val dataset after 54 epochs is = 0.09149589626422211\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.09149589626422211\n",
      "Error on this batch = 0.04821588110919663\n",
      "Error on this batch = 0.0796538707807453\n",
      "Cost on val dataset after 55 epochs is = 0.09093076746423545\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.09093076746423545\n",
      "Error on this batch = 0.04746004206394491\n",
      "Error on this batch = 0.07892854822180516\n",
      "Cost on val dataset after 56 epochs is = 0.09038838265970789\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.09038838265970789\n",
      "Error on this batch = 0.046735396116781215\n",
      "Error on this batch = 0.07822580802020705\n",
      "Cost on val dataset after 57 epochs is = 0.08986748047203458\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.08986748047203458\n",
      "Error on this batch = 0.04603988456272209\n",
      "Error on this batch = 0.07754426469291031\n",
      "Cost on val dataset after 58 epochs is = 0.08936688392550579\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.08936688392550579\n",
      "Error on this batch = 0.045371579706468504\n",
      "Error on this batch = 0.07688263489393664\n",
      "Cost on val dataset after 59 epochs is = 0.08888550625789822\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.08888550625789822\n",
      "Error on this batch = 0.04472868704037495\n",
      "Error on this batch = 0.07623972527951794\n",
      "Cost on val dataset after 60 epochs is = 0.08842234791948364\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.08842234791948364\n",
      "Error on this batch = 0.04410954248168235\n",
      "Error on this batch = 0.07561442193021581\n",
      "Cost on val dataset after 61 epochs is = 0.08797648948416298\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.08797648948416298\n",
      "Error on this batch = 0.04351260724001275\n",
      "Error on this batch = 0.07500568335477778\n",
      "Cost on val dataset after 62 epochs is = 0.08754708296640405\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.08754708296640405\n",
      "Error on this batch = 0.04293646177783709\n",
      "Error on this batch = 0.07441253801196963\n",
      "Cost on val dataset after 63 epochs is = 0.08713334271732334\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.08713334271732334\n",
      "Error on this batch = 0.042379799772902266\n",
      "Error on this batch = 0.07383408583470687\n",
      "Cost on val dataset after 64 epochs is = 0.08673453647463925\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.08673453647463925\n",
      "Error on this batch = 0.04184142263237881\n",
      "Error on this batch = 0.07326950217815066\n",
      "Cost on val dataset after 65 epochs is = 0.08634997699707868\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.08634997699707868\n",
      "Error on this batch = 0.041320234748899155\n",
      "Error on this batch = 0.07271804216089317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 66 epochs is = 0.0859790147537139\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.0859790147537139\n",
      "Error on this batch = 0.040815239301728375\n",
      "Error on this batch = 0.07217904340004422\n",
      "Cost on val dataset after 67 epochs is = 0.08562103212363212\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.08562103212363212\n",
      "Error on this batch = 0.040325534069989254\n",
      "Error on this batch = 0.0716519254549122\n",
      "Cost on val dataset after 68 epochs is = 0.08527543933473306\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.08527543933473306\n",
      "Error on this batch = 0.03985030653797871\n",
      "Error on this batch = 0.07113618480995697\n",
      "Cost on val dataset after 69 epochs is = 0.08494167191576348\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.08494167191576348\n",
      "Error on this batch = 0.039388827585606107\n",
      "Error on this batch = 0.07063138499705343\n",
      "Cost on val dataset after 70 epochs is = 0.08461918890268791\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.08461918890268791\n",
      "Error on this batch = 0.038940443268073624\n",
      "Error on this batch = 0.07013714248087732\n",
      "Cost on val dataset after 71 epochs is = 0.0843074707016805\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.0843074707016805\n",
      "Error on this batch = 0.03850456459006732\n",
      "Error on this batch = 0.06965310996704309\n",
      "Cost on val dataset after 72 epochs is = 0.08400601563096402\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.08400601563096402\n",
      "Error on this batch = 0.03808065575205912\n",
      "Error on this batch = 0.06917895940877582\n",
      "Cost on val dataset after 73 epochs is = 0.08371433483072932\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.08371433483072932\n",
      "Error on this batch = 0.03766822196988928\n",
      "Error on this batch = 0.06871436690272019\n",
      "Cost on val dataset after 74 epochs is = 0.0834319462765642\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.0834319462765642\n",
      "Error on this batch = 0.03726679838626474\n",
      "Error on this batch = 0.06825900102943315\n",
      "Cost on val dataset after 75 epochs is = 0.08315836971532015\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.08315836971532015\n",
      "Error on this batch = 0.036875941555172126\n",
      "Error on this batch = 0.06781251544533266\n",
      "Cost on val dataset after 76 epochs is = 0.08289312508072169\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.08289312508072169\n",
      "Error on this batch = 0.03649522444502681\n",
      "Error on this batch = 0.06737454593274157\n",
      "Cost on val dataset after 77 epochs is = 0.08263573694380709\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.08263573694380709\n",
      "Error on this batch = 0.036124235052399194\n",
      "Error on this batch = 0.0669447115332854\n",
      "Cost on val dataset after 78 epochs is = 0.08238574640518492\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.08238574640518492\n",
      "Error on this batch = 0.03576257779581697\n",
      "Error on this batch = 0.06652261861832993\n",
      "Cost on val dataset after 79 epochs is = 0.082142729382131\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.082142729382131\n",
      "Error on this batch = 0.03540987611568333\n",
      "Error on this batch = 0.06610786597396627\n",
      "Cost on val dataset after 80 epochs is = 0.08190631708687085\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.08190631708687085\n",
      "Error on this batch = 0.035065774441569185\n",
      "Error on this batch = 0.06570004878386584\n",
      "Cost on val dataset after 81 epochs is = 0.08167621221240398\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.08167621221240398\n",
      "Error on this batch = 0.03472993819184767\n",
      "Error on this batch = 0.0652987601807491\n",
      "Cost on val dataset after 82 epochs is = 0.08145219471404734\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.08145219471404734\n",
      "Error on this batch = 0.034402051694564076\n",
      "Error on this batch = 0.06490359046447942\n",
      "Cost on val dataset after 83 epochs is = 0.08123411453772313\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.08123411453772313\n",
      "Error on this batch = 0.03408181523319853\n",
      "Error on this batch = 0.0645141252528188\n",
      "Cost on val dataset after 84 epochs is = 0.08102187349748381\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.08102187349748381\n",
      "Error on this batch = 0.03376894296707309\n",
      "Error on this batch = 0.06412994406413992\n",
      "Cost on val dataset after 85 epochs is = 0.08081540200385409\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.08081540200385409\n",
      "Error on this batch = 0.03346316293055522\n",
      "Error on this batch = 0.06375062019714586\n",
      "Cost on val dataset after 86 epochs is = 0.08061463684465385\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.08061463684465385\n",
      "Error on this batch = 0.03316421919930971\n",
      "Error on this batch = 0.06337572186177988\n",
      "Cost on val dataset after 87 epochs is = 0.0804195041963217\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.0804195041963217\n",
      "Error on this batch = 0.03287187544401838\n",
      "Error on this batch = 0.06300481387635715\n",
      "Cost on val dataset after 88 epochs is = 0.08022990922923685\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.08022990922923685\n",
      "Error on this batch = 0.0325859188590653\n",
      "Error on this batch = 0.06263745906577471\n",
      "Cost on val dataset after 89 epochs is = 0.08004573154685322\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.08004573154685322\n",
      "Error on this batch = 0.03230616367393953\n",
      "Error on this batch = 0.06227321866370687\n",
      "Cost on val dataset after 90 epochs is = 0.07986682476619367\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.07986682476619367\n",
      "Error on this batch = 0.032032453762052625\n",
      "Error on this batch = 0.061911651337409175\n",
      "Cost on val dataset after 91 epochs is = 0.07969301854674694\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.07969301854674694\n",
      "Error on this batch = 0.03176466405706844\n",
      "Error on this batch = 0.061552310764526316\n",
      "Cost on val dataset after 92 epochs is = 0.07952412181643088\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.07952412181643088\n",
      "Error on this batch = 0.03150270058848624\n",
      "Error on this batch = 0.06119474191880811\n",
      "Cost on val dataset after 93 epochs is = 0.07935992644954296\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.07935992644954296\n",
      "Error on this batch = 0.03124649905074101\n",
      "Error on this batch = 0.060838476333885984\n",
      "Cost on val dataset after 94 epochs is = 0.07920021103994407\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.07920021103994407\n",
      "Error on this batch = 0.03099602196814994\n",
      "Error on this batch = 0.060483026599378834\n",
      "Cost on val dataset after 95 epochs is = 0.07904474464607543\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.07904474464607543\n",
      "Error on this batch = 0.030751254676794706\n",
      "Error on this batch = 0.06012788020561921\n",
      "Cost on val dataset after 96 epochs is = 0.07889329049812173\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.07889329049812173\n",
      "Error on this batch = 0.030512200446994955\n",
      "Error on this batch = 0.059772492622486136\n",
      "Cost on val dataset after 97 epochs is = 0.0787456097028684\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.0787456097028684\n",
      "Error on this batch = 0.030278875082803802\n",
      "Error on this batch = 0.05941627923915031\n",
      "Cost on val dataset after 98 epochs is = 0.07860146499182304\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.07860146499182304\n",
      "Error on this batch = 0.03005130128777887\n",
      "Error on this batch = 0.05905860559884303\n",
      "Cost on val dataset after 99 epochs is = 0.07846062453742063\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.07846062453742063\n",
      "Error on this batch = 0.029829503046884143\n",
      "Error on this batch = 0.05869877533426378\n",
      "Cost on val dataset after 100 epochs is = 0.07832286579661328\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.07832286579661328\n",
      "Error on this batch = 0.029613500289797513\n",
      "Error on this batch = 0.058336015407792347\n",
      "Cost on val dataset after 101 epochs is = 0.07818797922298076\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.07818797922298076\n",
      "Error on this batch = 0.029403304156099066\n",
      "Error on this batch = 0.057969458675107104\n",
      "Cost on val dataset after 102 epochs is = 0.07805577154092139\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.07805577154092139\n",
      "Error on this batch = 0.02919891321497564\n",
      "Error on this batch = 0.05759812432763506\n",
      "Cost on val dataset after 103 epochs is = 0.07792606816060274\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.07792606816060274\n",
      "Error on this batch = 0.02900031095287926\n",
      "Error on this batch = 0.057220897296371157\n",
      "Cost on val dataset after 104 epochs is = 0.0777987143079602\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.0777987143079602\n",
      "Error on this batch = 0.028807464757772423\n",
      "Error on this batch = 0.05683650813125829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 105 epochs is = 0.07767357459340919\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.07767357459340919\n",
      "Error on this batch = 0.028620326601302856\n",
      "Error on this batch = 0.05644351525752783\n",
      "Cost on val dataset after 106 epochs is = 0.07755053100765581\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.07755053100765581\n",
      "Error on this batch = 0.028438835762982225\n",
      "Error on this batch = 0.05604029210447626\n",
      "Cost on val dataset after 107 epochs is = 0.07742947959263298\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.07742947959263298\n",
      "Error on this batch = 0.028262924269974034\n",
      "Error on this batch = 0.05562502285598647\n",
      "Cost on val dataset after 108 epochs is = 0.07731032615788218\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.07731032615788218\n",
      "Error on this batch = 0.028092526084908254\n",
      "Error on this batch = 0.05519571300966435\n",
      "Cost on val dataset after 109 epochs is = 0.0771929813620983\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.0771929813620983\n",
      "Error on this batch = 0.027927591134718713\n",
      "Error on this batch = 0.05475022482517068\n",
      "Cost on val dataset after 110 epochs is = 0.07707735538193991\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.07707735538193991\n",
      "Error on this batch = 0.02776810462428886\n",
      "Error on this batch = 0.05428635265000747\n",
      "Cost on val dataset after 111 epochs is = 0.07696335248922719\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.07696335248922719\n",
      "Error on this batch = 0.027614110312321465\n",
      "Error on this batch = 0.05380195741339097\n",
      "Cost on val dataset after 112 epochs is = 0.07685086638645992\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.07685086638645992\n",
      "Error on this batch = 0.027465733168283695\n",
      "Error on this batch = 0.05329518009434688\n",
      "Cost on val dataset after 113 epochs is = 0.07673977818959117\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.07673977818959117\n",
      "Error on this batch = 0.02732319186089508\n",
      "Error on this batch = 0.052764745790169716\n",
      "Cost on val dataset after 114 epochs is = 0.0766299602544172\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.0766299602544172\n",
      "Error on this batch = 0.027186785465006903\n",
      "Error on this batch = 0.05221034738145106\n",
      "Cost on val dataset after 115 epochs is = 0.07652128976881985\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.07652128976881985\n",
      "Error on this batch = 0.027056834633271434\n",
      "Error on this batch = 0.05163305783129884\n",
      "Cost on val dataset after 116 epochs is = 0.0764136744956908\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.0764136744956908\n",
      "Error on this batch = 0.02693356223793386\n",
      "Error on this batch = 0.051035670502050164\n",
      "Cost on val dataset after 117 epochs is = 0.0763070874723964\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.0763070874723964\n",
      "Error on this batch = 0.026816921003423033\n",
      "Error on this batch = 0.05042283300104512\n",
      "Cost on val dataset after 118 epochs is = 0.07620159868990532\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.07620159868990532\n",
      "Error on this batch = 0.02670641625813157\n",
      "Error on this batch = 0.049800859402293146\n",
      "Cost on val dataset after 119 epochs is = 0.07609738612937743\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.07609738612937743\n",
      "Error on this batch = 0.026601008018683064\n",
      "Error on this batch = 0.04917719716275278\n",
      "Cost on val dataset after 120 epochs is = 0.0759947145955313\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.0759947145955313\n",
      "Error on this batch = 0.02649916760141654\n",
      "Error on this batch = 0.048559652994828735\n",
      "Cost on val dataset after 121 epochs is = 0.07589388809774004\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.07589388809774004\n",
      "Error on this batch = 0.026399093609736583\n",
      "Error on this batch = 0.04795556740441725\n",
      "Cost on val dataset after 122 epochs is = 0.07579519605678971\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.07579519605678971\n",
      "Error on this batch = 0.026299006126417376\n",
      "Error on this batch = 0.04737112074487273\n",
      "Cost on val dataset after 123 epochs is = 0.07569887284445255\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.07569887284445255\n",
      "Error on this batch = 0.026197406611201176\n",
      "Error on this batch = 0.046810882480419876\n",
      "Cost on val dataset after 124 epochs is = 0.07560507843324729\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.07560507843324729\n",
      "Error on this batch = 0.026093231075038404\n",
      "Error on this batch = 0.046277639740334005\n",
      "Cost on val dataset after 125 epochs is = 0.07551389793856028\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.07551389793856028\n",
      "Error on this batch = 0.0259858894174039\n",
      "Error on this batch = 0.045772485244693385\n",
      "Cost on val dataset after 126 epochs is = 0.07542535419223396\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.07542535419223396\n",
      "Error on this batch = 0.02587522587556137\n",
      "Error on this batch = 0.045295101709657754\n",
      "Cost on val dataset after 127 epochs is = 0.07533942684590592\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.07533942684590592\n",
      "Error on this batch = 0.025761441631452487\n",
      "Error on this batch = 0.044844151324773984\n",
      "Cost on val dataset after 128 epochs is = 0.07525607153347456\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.07525607153347456\n",
      "Error on this batch = 0.0256450052148832\n",
      "Error on this batch = 0.04441767587319479\n",
      "Cost on val dataset after 129 epochs is = 0.07517523408325354\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.07517523408325354\n",
      "Error on this batch = 0.025526560424833877\n",
      "Error on this batch = 0.04401343644352771\n",
      "Cost on val dataset after 130 epochs is = 0.07509685800601955\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.07509685800601955\n",
      "Error on this batch = 0.025406836590056717\n",
      "Error on this batch = 0.04362915842386793\n",
      "Cost on val dataset after 131 epochs is = 0.0750208868022091\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.0750208868022091\n",
      "Error on this batch = 0.02528656860193859\n",
      "Error on this batch = 0.04326268100593735\n",
      "Cost on val dataset after 132 epochs is = 0.07494726407648539\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.07494726407648539\n",
      "Error on this batch = 0.025166434975544227\n",
      "Error on this batch = 0.04291203055968959\n",
      "Cost on val dataset after 133 epochs is = 0.07487593380433605\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.07487593380433605\n",
      "Error on this batch = 0.025047018046337303\n",
      "Error on this batch = 0.042575443143658374\n",
      "Cost on val dataset after 134 epochs is = 0.07480684161622508\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.07480684161622508\n",
      "Error on this batch = 0.024928784847426142\n",
      "Error on this batch = 0.04225135824785046\n",
      "Cost on val dataset after 135 epochs is = 0.07473993683845004\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.07473993683845004\n",
      "Error on this batch = 0.024812083957760682\n",
      "Error on this batch = 0.041938399458667334\n",
      "Cost on val dataset after 136 epochs is = 0.07467517461517156\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.07467517461517156\n",
      "Error on this batch = 0.02469715317520441\n",
      "Error on this batch = 0.04163535164661167\n",
      "Cost on val dataset after 137 epochs is = 0.07461251752780368\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.07461251752780368\n",
      "Error on this batch = 0.024584133827231375\n",
      "Error on this batch = 0.041341139727178185\n",
      "Cost on val dataset after 138 epochs is = 0.07455193641824151\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.07455193641824151\n",
      "Error on this batch = 0.02447308856992996\n",
      "Error on this batch = 0.041054811020148366\n",
      "Cost on val dataset after 139 epochs is = 0.07449341040574856\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.07449341040574856\n",
      "Error on this batch = 0.024364020175391597\n",
      "Error on this batch = 0.04077552138433927\n",
      "Cost on val dataset after 140 epochs is = 0.07443692626900722\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.07443692626900722\n",
      "Error on this batch = 0.024256889210733226\n",
      "Error on this batch = 0.04050252432386706\n",
      "Cost on val dataset after 141 epochs is = 0.07438247742276596\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.07438247742276596\n",
      "Error on this batch = 0.02415162895547507\n",
      "Error on this batch = 0.04023516192020669\n",
      "Cost on val dataset after 142 epochs is = 0.07433006267528243\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.07433006267528243\n",
      "Error on this batch = 0.024048156519173504\n",
      "Error on this batch = 0.039972856543247434\n",
      "Cost on val dataset after 143 epochs is = 0.07427968485462992\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.07427968485462992\n",
      "Error on this batch = 0.02394637983274142\n",
      "Error on this batch = 0.03971510263825412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 144 epochs is = 0.07423134928818517\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.07423134928818517\n",
      "Error on this batch = 0.02384620082527901\n",
      "Error on this batch = 0.03946145829769626\n",
      "Cost on val dataset after 145 epochs is = 0.07418506204715195\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.07418506204715195\n",
      "Error on this batch = 0.023747515538008912\n",
      "Error on this batch = 0.0392115366796148\n",
      "Cost on val dataset after 146 epochs is = 0.07414082784693829\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.07414082784693829\n",
      "Error on this batch = 0.023650212152176185\n",
      "Error on this batch = 0.03896499756087959\n",
      "Cost on val dataset after 147 epochs is = 0.07409864753223493\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.07409864753223493\n",
      "Error on this batch = 0.023554167990839793\n",
      "Error on this batch = 0.03872153939782667\n",
      "Cost on val dataset after 148 epochs is = 0.07405851517249509\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.07405851517249509\n",
      "Error on this batch = 0.02345924658943696\n",
      "Error on this batch = 0.03848089221991023\n",
      "Cost on val dataset after 149 epochs is = 0.07402041493909446\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.07402041493909446\n",
      "Error on this batch = 0.02336529596734555\n",
      "Error on this batch = 0.03824281152564732\n",
      "Cost on val dataset after 150 epochs is = 0.07398431810018763\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.07398431810018763\n",
      "Error on this batch = 0.02327214923927001\n",
      "Error on this batch = 0.03800707311161434\n",
      "Cost on val dataset after 151 epochs is = 0.07395018059402794\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.07395018059402794\n",
      "Error on this batch = 0.02317962856005786\n",
      "Error on this batch = 0.0377734684909745\n",
      "Cost on val dataset after 152 epochs is = 0.07391794164254331\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.07391794164254331\n",
      "Error on this batch = 0.023087552935320704\n",
      "Error on this batch = 0.037541800336663995\n",
      "Cost on val dataset after 153 epochs is = 0.07388752367432223\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.07388752367432223\n",
      "Error on this batch = 0.022995749552003765\n",
      "Error on this batch = 0.03731187735601205\n",
      "Cost on val dataset after 154 epochs is = 0.07385883345698803\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.07385883345698803\n",
      "Error on this batch = 0.022904067094090513\n",
      "Error on this batch = 0.03708350831695616\n",
      "Cost on val dataset after 155 epochs is = 0.07383176396224216\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.07383176396224216\n",
      "Error on this batch = 0.02281238840656607\n",
      "Error on this batch = 0.03685649564785519\n",
      "Cost on val dataset after 156 epochs is = 0.07380619639144785\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.07380619639144785\n",
      "Error on this batch = 0.022720639431758286\n",
      "Error on this batch = 0.03663062994793451\n",
      "Cost on val dataset after 157 epochs is = 0.07378200219342217\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.07378200219342217\n",
      "Error on this batch = 0.02262879198318967\n",
      "Error on this batch = 0.036405687474690945\n",
      "Cost on val dataset after 158 epochs is = 0.07375904568822357\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.07375904568822357\n",
      "Error on this batch = 0.022536859551637374\n",
      "Error on this batch = 0.03618143278164071\n",
      "Cost on val dataset after 159 epochs is = 0.07373718851022597\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.07373718851022597\n",
      "Error on this batch = 0.022444887322304728\n",
      "Error on this batch = 0.03595762795149579\n",
      "Cost on val dataset after 160 epochs is = 0.07371629678922036\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.07371629678922036\n",
      "Error on this batch = 0.022352939104678126\n",
      "Error on this batch = 0.035734048449848795\n",
      "Cost on val dataset after 161 epochs is = 0.07369625055194978\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.07369625055194978\n",
      "Error on this batch = 0.02226108438863731\n",
      "Error on this batch = 0.03551050395653997\n",
      "Cost on val dataset after 162 epochs is = 0.07367695294435182\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.07367695294435182\n",
      "Error on this batch = 0.02216938815626562\n",
      "Error on this batch = 0.035286861203130834\n",
      "Cost on val dataset after 163 epochs is = 0.07365833593787645\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.07365833593787645\n",
      "Error on this batch = 0.022077904710370938\n",
      "Error on this batch = 0.035063065362754664\n",
      "Cost on val dataset after 164 epochs is = 0.07364036019085915\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.07364036019085915\n",
      "Error on this batch = 0.02198667520021485\n",
      "Error on this batch = 0.034839157030027434\n",
      "Cost on val dataset after 165 epochs is = 0.07362300922924113\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.07362300922924113\n",
      "Error on this batch = 0.021895727398597513\n",
      "Error on this batch = 0.03461528286410606\n",
      "Cost on val dataset after 166 epochs is = 0.0736062803517869\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.0736062803517869\n",
      "Error on this batch = 0.02180507608037263\n",
      "Error on this batch = 0.03439169884067154\n",
      "Cost on val dataset after 167 epochs is = 0.07359017513527566\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.07359017513527566\n",
      "Error on this batch = 0.02171472302521548\n",
      "Error on this batch = 0.03416876542293168\n",
      "Cost on val dataset after 168 epochs is = 0.07357469115043846\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.07357469115043846\n",
      "Error on this batch = 0.02162465664909284\n",
      "Error on this batch = 0.0339469341736186\n",
      "Cost on val dataset after 169 epochs is = 0.07355981488253001\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.07355981488253001\n",
      "Error on this batch = 0.0215348518841166\n",
      "Error on this batch = 0.03372672603316932\n",
      "Cost on val dataset after 170 epochs is = 0.07354551521689635\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.07354551521689635\n",
      "Error on this batch = 0.02144527088456538\n",
      "Error on this batch = 0.033508702849448964\n",
      "Cost on val dataset after 171 epochs is = 0.07353173741641206\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.07353173741641206\n",
      "Error on this batch = 0.021355864656354133\n",
      "Error on this batch = 0.033293435170137047\n",
      "Cost on val dataset after 172 epochs is = 0.07351839851882436\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.07351839851882436\n",
      "Error on this batch = 0.021266575225146408\n",
      "Error on this batch = 0.03308146996229765\n",
      "Cost on val dataset after 173 epochs is = 0.0735053856237886\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.0735053856237886\n",
      "Error on this batch = 0.021177337761400895\n",
      "Error on this batch = 0.03287330147899735\n",
      "Cost on val dataset after 174 epochs is = 0.07349255820892955\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.07349255820892955\n",
      "Error on this batch = 0.021088082173244153\n",
      "Error on this batch = 0.03266934741849203\n",
      "Cost on val dataset after 175 epochs is = 0.07347975455298453\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.07347975455298453\n",
      "Error on this batch = 0.02099873390187013\n",
      "Error on this batch = 0.032469931700928455\n",
      "Cost on val dataset after 176 epochs is = 0.07346680110111226\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.07346680110111226\n",
      "Error on this batch = 0.02090921386806177\n",
      "Error on this batch = 0.03227527522674634\n",
      "Cost on val dataset after 177 epochs is = 0.07345352292553747\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.07345352292553747\n",
      "Error on this batch = 0.020819437675678617\n",
      "Error on this batch = 0.0320854966382955\n",
      "Cost on val dataset after 178 epochs is = 0.07343975380208745\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.07343975380208745\n",
      "Error on this batch = 0.020729314280076624\n",
      "Error on this batch = 0.03190062518619539\n",
      "Cost on val dataset after 179 epochs is = 0.07342534552674715\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.07342534552674715\n",
      "Error on this batch = 0.020638744347281485\n",
      "Error on this batch = 0.03172062582477143\n",
      "Cost on val dataset after 180 epochs is = 0.07341017684665403\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.07341017684665403\n",
      "Error on this batch = 0.02054761840948952\n",
      "Error on this batch = 0.03154543232355081\n",
      "Cost on val dataset after 181 epochs is = 0.07339416187754254\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.07339416187754254\n",
      "Error on this batch = 0.020455814700060984\n",
      "Error on this batch = 0.031374979626856196\n",
      "Cost on val dataset after 182 epochs is = 0.07337725650529928\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.07337725650529928\n",
      "Error on this batch = 0.02036319641884142\n",
      "Error on this batch = 0.03120922565512057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 183 epochs is = 0.07335946051701078\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.07335946051701078\n",
      "Error on this batch = 0.02026960832304475\n",
      "Error on this batch = 0.031048157113022137\n",
      "Cost on val dataset after 184 epochs is = 0.07334081414681834\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.07334081414681834\n",
      "Error on this batch = 0.020174872884016128\n",
      "Error on this batch = 0.03089178109957972\n",
      "Cost on val dataset after 185 epochs is = 0.07332138981485205\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.07332138981485205\n",
      "Error on this batch = 0.020078786488028567\n",
      "Error on this batch = 0.03074010945908885\n",
      "Cost on val dataset after 186 epochs is = 0.07330128154236783\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.07330128154236783\n",
      "Error on this batch = 0.019981116096181882\n",
      "Error on this batch = 0.030593143222540548\n",
      "Cost on val dataset after 187 epochs is = 0.07328059484277691\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.07328059484277691\n",
      "Error on this batch = 0.019881596533763604\n",
      "Error on this batch = 0.030450861520083743\n",
      "Cost on val dataset after 188 epochs is = 0.0732594390074997\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.0732594390074997\n",
      "Error on this batch = 0.01977992840224018\n",
      "Error on this batch = 0.030313215949097614\n",
      "Cost on val dataset after 189 epochs is = 0.0732379224326679\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.0732379224326679\n",
      "Error on this batch = 0.01967577661962732\n",
      "Error on this batch = 0.030180129387615804\n",
      "Cost on val dataset after 190 epochs is = 0.07321615060747001\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.07321615060747001\n",
      "Error on this batch = 0.0195687697578777\n",
      "Error on this batch = 0.030051497804422126\n",
      "Cost on val dataset after 191 epochs is = 0.07319422581688764\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.07319422581688764\n",
      "Error on this batch = 0.019458500576531083\n",
      "Error on this batch = 0.02992719407660987\n",
      "Cost on val dataset after 192 epochs is = 0.07317224743084386\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.07317224743084386\n",
      "Error on this batch = 0.019344528411287715\n",
      "Error on this batch = 0.029807073506702725\n",
      "Cost on val dataset after 193 epochs is = 0.0731503117314676\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.0731503117314676\n",
      "Error on this batch = 0.019226384365670188\n",
      "Error on this batch = 0.02969098120505146\n",
      "Cost on val dataset after 194 epochs is = 0.07312851050368574\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.07312851050368574\n",
      "Error on this batch = 0.019103580564240167\n",
      "Error on this batch = 0.02957876155706791\n",
      "Cost on val dataset after 195 epochs is = 0.07310692807225726\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.07310692807225726\n",
      "Error on this batch = 0.01897562498943504\n",
      "Error on this batch = 0.029470269605678938\n",
      "Cost on val dataset after 196 epochs is = 0.07308563707639885\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.07308563707639885\n",
      "Error on this batch = 0.018842043499030604\n",
      "Error on this batch = 0.029365383566815666\n",
      "Cost on val dataset after 197 epochs is = 0.073064693884245\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.073064693884245\n",
      "Error on this batch = 0.0187024103198083\n",
      "Error on this batch = 0.02926401731683538\n",
      "Cost on val dataset after 198 epochs is = 0.07304413491125139\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.07304413491125139\n",
      "Error on this batch = 0.018556387475223004\n",
      "Error on this batch = 0.029166131951080986\n",
      "Cost on val dataset after 199 epochs is = 0.0730239750209652\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.0730239750209652\n",
      "Error on this batch = 0.0184037722066551\n",
      "Error on this batch = 0.02907174616261401\n",
      "Cost on val dataset after 200 epochs is = 0.07300420871783198\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.07300420871783198\n",
      "Error on this batch = 0.01824454977441295\n",
      "Error on this batch = 0.0289809446119714\n",
      "Cost on val dataset after 201 epochs is = 0.07298481435531912\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.07298481435531912\n",
      "Error on this batch = 0.018078948080578593\n",
      "Error on this batch = 0.02889387764691179\n",
      "Cost on val dataset after 202 epochs is = 0.07296576150754226\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.07296576150754226\n",
      "Error on this batch = 0.017907493079078008\n",
      "Error on this batch = 0.028810725680004538\n",
      "Cost on val dataset after 203 epochs is = 0.07294702204307282\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.07294702204307282\n",
      "Error on this batch = 0.017731076278251347\n",
      "Error on this batch = 0.02873155009980755\n",
      "Cost on val dataset after 204 epochs is = 0.07292858515675153\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.07292858515675153\n",
      "Error on this batch = 0.01755107795212426\n",
      "Error on this batch = 0.02865587065776076\n",
      "Cost on val dataset after 205 epochs is = 0.07291047173448835\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.07291047173448835\n",
      "Error on this batch = 0.017369633977063224\n",
      "Error on this batch = 0.028581909659449064\n",
      "Cost on val dataset after 206 epochs is = 0.07289273094663477\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.07289273094663477\n",
      "Error on this batch = 0.017190049134524196\n",
      "Error on this batch = 0.028506432955595833\n",
      "Cost on val dataset after 207 epochs is = 0.07287541360182852\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.07287541360182852\n",
      "Error on this batch = 0.01701676441226874\n",
      "Error on this batch = 0.028427043846260908\n",
      "Cost on val dataset after 208 epochs is = 0.0728585928036438\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.0728585928036438\n",
      "Error on this batch = 0.01685378146048953\n",
      "Error on this batch = 0.028344632081692866\n",
      "Cost on val dataset after 209 epochs is = 0.07284240604388022\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.07284240604388022\n",
      "Error on this batch = 0.01670267081622432\n",
      "Error on this batch = 0.028261655932140136\n",
      "Cost on val dataset after 210 epochs is = 0.07282693944332226\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.07282693944332226\n",
      "Error on this batch = 0.016562831119438255\n",
      "Error on this batch = 0.028179742741547244\n",
      "Cost on val dataset after 211 epochs is = 0.07281213195543774\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.07281213195543774\n",
      "Error on this batch = 0.016432988805334833\n",
      "Error on this batch = 0.028099487356163383\n",
      "Cost on val dataset after 212 epochs is = 0.07279784381933935\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.07279784381933935\n",
      "Error on this batch = 0.01631199941332366\n",
      "Error on this batch = 0.028020995544169546\n",
      "Cost on val dataset after 213 epochs is = 0.07278394684671571\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.07278394684671571\n",
      "Error on this batch = 0.016198962912154634\n",
      "Error on this batch = 0.02794422619361319\n",
      "Cost on val dataset after 214 epochs is = 0.07277035907595246\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.07277035907595246\n",
      "Error on this batch = 0.016093142699005206\n",
      "Error on this batch = 0.027869115838963354\n",
      "Cost on val dataset after 215 epochs is = 0.07275704214817102\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.07275704214817102\n",
      "Error on this batch = 0.015993890860348466\n",
      "Error on this batch = 0.027795608389186786\n",
      "Cost on val dataset after 216 epochs is = 0.07274398779092489\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.07274398779092489\n",
      "Error on this batch = 0.015900609767589443\n",
      "Error on this batch = 0.027723656091876644\n",
      "Cost on val dataset after 217 epochs is = 0.07273120514317195\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.07273120514317195\n",
      "Error on this batch = 0.015812738138309232\n",
      "Error on this batch = 0.02765321530790148\n",
      "Cost on val dataset after 218 epochs is = 0.07271871162160819\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.07271871162160819\n",
      "Error on this batch = 0.015729748704683834\n",
      "Error on this batch = 0.02758424332405574\n",
      "Cost on val dataset after 219 epochs is = 0.0727065269043513\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.0727065269043513\n",
      "Error on this batch = 0.01565114995027341\n",
      "Error on this batch = 0.027516696917431794\n",
      "Cost on val dataset after 220 epochs is = 0.0726946690619193\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.0726946690619193\n",
      "Error on this batch = 0.015576488427610247\n",
      "Error on this batch = 0.027450532096675043\n",
      "Cost on val dataset after 221 epochs is = 0.07268315211214695\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.07268315211214695\n",
      "Error on this batch = 0.01550535039609201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.027385704400297667\n",
      "Cost on val dataset after 222 epochs is = 0.07267198466918615\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.07267198466918615\n",
      "Error on this batch = 0.015437362519601693\n",
      "Error on this batch = 0.027322169329242838\n",
      "Cost on val dataset after 223 epochs is = 0.07266116968234765\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.07266116968234765\n",
      "Error on this batch = 0.015372191696716185\n",
      "Error on this batch = 0.02725988262515823\n",
      "Cost on val dataset after 224 epochs is = 0.07265070539378254\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.07265070539378254\n",
      "Error on this batch = 0.015309544155699935\n",
      "Error on this batch = 0.0271988001224724\n",
      "Cost on val dataset after 225 epochs is = 0.07264058747721804\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.07264058747721804\n",
      "Error on this batch = 0.015249163970258599\n",
      "Error on this batch = 0.027138876895403886\n",
      "Cost on val dataset after 226 epochs is = 0.07263081185893497\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.07263081185893497\n",
      "Error on this batch = 0.015190831221237338\n",
      "Error on this batch = 0.027080065573092164\n",
      "Cost on val dataset after 227 epochs is = 0.0726213772112995\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.0726213772112995\n",
      "Error on this batch = 0.015134360079757988\n",
      "Error on this batch = 0.02702231409482362\n",
      "Cost on val dataset after 228 epochs is = 0.07261228596359172\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.07261228596359172\n",
      "Error on this batch = 0.015079597005661199\n",
      "Error on this batch = 0.026965563621013516\n",
      "Cost on val dataset after 229 epochs is = 0.07260354314399473\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.07260354314399473\n",
      "Error on this batch = 0.015026419029738726\n",
      "Error on this batch = 0.026909747421065645\n",
      "Cost on val dataset after 230 epochs is = 0.0725951532374639\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.0725951532374639\n",
      "Error on this batch = 0.01497473185619051\n",
      "Error on this batch = 0.026854791171975218\n",
      "Cost on val dataset after 231 epochs is = 0.07258711598536513\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.07258711598536513\n",
      "Error on this batch = 0.014924467433097215\n",
      "Error on this batch = 0.026800614503329753\n",
      "Cost on val dataset after 232 epochs is = 0.07257942228939362\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.07257942228939362\n",
      "Error on this batch = 0.014875580695168669\n",
      "Error on this batch = 0.026747133242821394\n",
      "Cost on val dataset after 233 epochs is = 0.07257205116242325\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.07257205116242325\n",
      "Error on this batch = 0.014828045257051722\n",
      "Error on this batch = 0.0266942618259355\n",
      "Cost on val dataset after 234 epochs is = 0.07256496828782624\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.07256496828782624\n",
      "Error on this batch = 0.014781847838047582\n",
      "Error on this batch = 0.02664191559958468\n",
      "Cost on val dataset after 235 epochs is = 0.0725581264296861\n",
      "cost initial= 0.07256496828782624 , cost final=0.0725581264296861 , change in cost= -6.841858140135826e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 100 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 235\n",
      "The training time = 45.782sec\n",
      "The training accuracy is = 97.683%\n",
      "The validation accuracy is = 91.795%\n",
      "The test accuracy is = 90.723%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []\n",
    "\n",
    "lr=0.5\n",
    "\n",
    "for i in range(len(arch_test)):\n",
    "    #Choose between normal or random. Normal gives better results\n",
    "    theta = theta_init(n, r, [arch_test[i]], 'normal')\n",
    "    #print(theta[0].shape, theta[1].shape, theta[2].shape)\n",
    "    print(\"Training the network with {} hidden layer with {} units\".format(len([arch_test[i]]), arch_test[i]))\n",
    "    print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "    for j in range(len(theta)):\n",
    "        print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "\n",
    "    start = time.time()\n",
    "    epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'sigmoid')\n",
    "    \n",
    "    epochs.append(epoch)\n",
    "    train_time.append(time.time()-start)\n",
    "    train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "    valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "    test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "    print(\"\\n------------------------------------------------------------------------------\")\n",
    "    print(\"The stats for number of units in the hidden layer = {} are as below:\".format(arch_test[i]))\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"The number of epochs = {}\".format(epochs[-1]))\n",
    "    print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "    print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "    print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "    print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "    print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------Plotting Graphs for Part B - Fixed LR - One Hidden Layer ------------------\")\n",
    "plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy)\n",
    "plot_epoch(arch_test, epochs, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Adaptive Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 1 hidden layer with 1 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 1)\n",
      "theta between layer 1 and layer 2 is (2, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2597392406061334\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.258361740537336\n",
      "Error on this batch = 0.5819904510458613\n",
      "Cost on val dataset after 2 epochs is = 0.5204024792332181\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.5204024792332181\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.5202182476249874\n",
      "Error on this batch = 0.50212506489877\n",
      "Cost on val dataset after 3 epochs is = 0.4949624359871587\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4949624359871587\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4948485111676423\n",
      "Error on this batch = 0.49057920223495843\n",
      "Cost on val dataset after 4 epochs is = 0.48822364573631355\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.48822364573631355\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48812951795626336\n",
      "Error on this batch = 0.4864411017911279\n",
      "Cost on val dataset after 5 epochs is = 0.4853560069995764\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4853560069995764\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4852702521139584\n",
      "Error on this batch = 0.48444401232249745\n",
      "Cost on val dataset after 6 epochs is = 0.48385197513995554\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.48385197513995554\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4837703251632127\n",
      "Error on this batch = 0.4833204755751648\n",
      "Cost on val dataset after 7 epochs is = 0.4829630768751136\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4829630768751136\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4828835239700297\n",
      "Error on this batch = 0.48262590249868903\n",
      "Cost on val dataset after 8 epochs is = 0.48239537342820915\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48239537342820915\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.48231683908040085\n",
      "Error on this batch = 0.48216814886298764\n",
      "Cost on val dataset after 9 epochs is = 0.4820125168039131\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4820125168039131\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.48193437077273643\n",
      "Error on this batch = 0.48185217896092314\n",
      "Cost on val dataset after 10 epochs is = 0.48174369797047717\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48174369797047717\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.4816655508392964\n",
      "Error on this batch = 0.4816263026976067\n",
      "Cost on val dataset after 11 epochs is = 0.48154900226022057\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48154900226022057\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.48147060441885525\n",
      "Error on this batch = 0.48146034510635366\n",
      "Cost on val dataset after 12 epochs is = 0.4814044829327383\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4814044829327383\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48132567079928623\n",
      "Error on this batch = 0.48133569922196545\n",
      "Cost on val dataset after 13 epochs is = 0.4812950513242689\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4812950513242689\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4812157166894792\n",
      "Error on this batch = 0.4812403789143144\n",
      "Cost on val dataset after 14 epochs is = 0.48121081643960084\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.48121081643960084\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.48113088802007736\n",
      "Error on this batch = 0.48116638272522755\n",
      "Cost on val dataset after 15 epochs is = 0.4811450796186406\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4811450796186406\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.4810645114585555\n",
      "Error on this batch = 0.4811082084759502\n",
      "Cost on val dataset after 16 epochs is = 0.48109317858907674\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.48109317858907674\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4810119424985157\n",
      "Error on this batch = 0.48106197673483236\n",
      "Cost on val dataset after 17 epochs is = 0.4810517922426216\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.4810517922426216\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4809698727154488\n",
      "Error on this batch = 0.48102489308147767\n",
      "Cost on val dataset after 18 epochs is = 0.48101850719097006\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.48101850719097006\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.4809358978999215\n",
      "Error on this batch = 0.4809949070962916\n",
      "Cost on val dataset after 19 epochs is = 0.4809915390568528\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.4809915390568528\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.4809082403824344\n",
      "Error on this batch = 0.48097048982628543\n",
      "Cost on val dataset after 20 epochs is = 0.4809695483947119\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4809695483947119\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.48088556564955726\n",
      "Error on this batch = 0.48095048489487513\n",
      "Cost on val dataset after 21 epochs is = 0.480951516224597\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.480951516224597\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.48086685835643295\n",
      "Error on this batch = 0.4809340066729284\n",
      "Cost on val dataset after 22 epochs is = 0.48093665811171704\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.48093665811171704\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.48085133674238\n",
      "Error on this batch = 0.4809203692673546\n",
      "Cost on val dataset after 23 epochs is = 0.48092436375149034\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.48092436375149034\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.4808383924561351\n",
      "Error on this batch = 0.4809090361332837\n",
      "Cost on val dataset after 24 epochs is = 0.48091415378257\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.48091415378257\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.480827547543312\n",
      "Error on this batch = 0.48089958375872416\n",
      "Cost on val dataset after 25 epochs is = 0.48090564845372946\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.48090564845372946\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.4808184232417862\n",
      "Error on this batch = 0.48089167512098707\n",
      "Cost on val dataset after 26 epochs is = 0.4808985445840222\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.4808985445840222\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.4808107170377391\n",
      "Error on this batch = 0.48088504003672217\n",
      "Cost on val dataset after 27 epochs is = 0.48089259841351206\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.48089259841351206\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.48080418558877314\n",
      "Error on this batch = 0.48087946044557656\n",
      "Cost on val dataset after 28 epochs is = 0.4808876126959658\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4808876126959658\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.48079863187182853\n",
      "Error on this batch = 0.4808747592713812\n",
      "Cost on val dataset after 29 epochs is = 0.4808834268849919\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.4808834268849919\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.4807938954118523\n",
      "Error on this batch = 0.4808707919088892\n",
      "Cost on val dataset after 30 epochs is = 0.48087990960226196\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.48087990960226196\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.48078984478306425\n",
      "Error on this batch = 0.4808674396588134\n",
      "Cost on val dataset after 31 epochs is = 0.48087695280725723\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.48087695280725723\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.4807863718045745\n",
      "Error on this batch = 0.4808646046234041\n",
      "Cost on val dataset after 32 epochs is = 0.4808744672481807\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.4808744672481807\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.48078338701169443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4808622057072821\n",
      "Cost on val dataset after 33 epochs is = 0.48087237888632844\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.48087237888632844\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.4807808160964955\n",
      "Error on this batch = 0.48086017546199744\n",
      "Cost on val dataset after 34 epochs is = 0.4808706260663819\n",
      "cost initial= 0.48087237888632844 , cost final=0.4808706260663819 , change in cost= -1.7528199465211003e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 1 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 34\n",
      "The training time = 2.163sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 5 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 5)\n",
      "theta between layer 1 and layer 2 is (6, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2884481219596324\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.287007203952446\n",
      "Error on this batch = 0.49897808664779675\n",
      "Cost on val dataset after 2 epochs is = 0.4865578565525861\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4865578565525861\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.4862483057750571\n",
      "Error on this batch = 0.483406225275497\n",
      "Cost on val dataset after 3 epochs is = 0.4822794022366817\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4822794022366817\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4821105944181454\n",
      "Error on this batch = 0.481714140829764\n",
      "Cost on val dataset after 4 epochs is = 0.4814090111840232\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4814090111840232\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48127966463242666\n",
      "Error on this batch = 0.4812444781063708\n",
      "Cost on val dataset after 5 epochs is = 0.481122525673021\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.481122525673021\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4810097464237582\n",
      "Error on this batch = 0.48106822884843936\n",
      "Cost on val dataset after 6 epochs is = 0.48100651870635475\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.48100651870635475\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.48090187501931086\n",
      "Error on this batch = 0.48099115573123585\n",
      "Cost on val dataset after 7 epochs is = 0.4809538867390374\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4809538867390374\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4808535234604673\n",
      "Error on this batch = 0.48095419451914956\n",
      "Cost on val dataset after 8 epochs is = 0.4809283100849405\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4809283100849405\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4808302445842416\n",
      "Error on this batch = 0.48093534590460507\n",
      "Cost on val dataset after 9 epochs is = 0.48091534528442004\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48091534528442004\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.4808184860964096\n",
      "Error on this batch = 0.48092529834701436\n",
      "Cost on val dataset after 10 epochs is = 0.48090861380937544\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48090861380937544\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.4808123368784131\n",
      "Error on this batch = 0.4809197503883323\n",
      "Cost on val dataset after 11 epochs is = 0.4809050848901941\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4809050848901941\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.48080902775299666\n",
      "Error on this batch = 0.4809165860814039\n",
      "Cost on val dataset after 12 epochs is = 0.4809032404331069\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4809032404331069\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48080719352933543\n",
      "Error on this batch = 0.4809147150402417\n",
      "Cost on val dataset after 13 epochs is = 0.48090229032710086\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48090229032710086\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4808061359894963\n",
      "Error on this batch = 0.48091355551189163\n",
      "Cost on val dataset after 14 epochs is = 0.4809018120424333\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4809018120424333\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.48080548867964235\n",
      "Error on this batch = 0.4809127890621804\n",
      "Cost on val dataset after 15 epochs is = 0.4809015756488622\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4809015756488622\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.4808050560204363\n",
      "Error on this batch = 0.4809122382454738\n",
      "Cost on val dataset after 16 epochs is = 0.4809014550381529\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4809014550381529\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.48080473277100655\n",
      "Error on this batch = 0.4809118031282054\n",
      "Cost on val dataset after 17 epochs is = 0.48090138126616333\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.48090138126616333\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.48080446236080576\n",
      "Error on this batch = 0.4809114272702392\n",
      "Cost on val dataset after 18 epochs is = 0.4809013173256754\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.4809013173256754\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.4808042147651926\n",
      "Error on this batch = 0.48091107900608093\n",
      "Cost on val dataset after 19 epochs is = 0.4809012441937833\n",
      "cost initial= 0.4809013173256754 , cost final=0.4809012441937833 , change in cost= -7.313189215318872e-08\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 5 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 19\n",
      "The training time = 1.215sec\n",
      "The training accuracy is = 3.928%\n",
      "The validation accuracy is = 2.974%\n",
      "The test accuracy is = 3.800%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 10 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 10)\n",
      "theta between layer 1 and layer 2 is (11, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2708585206102443\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.2741713120071916\n",
      "Error on this batch = 0.4871291320862221\n",
      "Cost on val dataset after 2 epochs is = 0.4825887531052519\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4825887531052519\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.48228837867881197\n",
      "Error on this batch = 0.48153559050390415\n",
      "Cost on val dataset after 3 epochs is = 0.48129831723234257\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48129831723234257\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.48112272119109706\n",
      "Error on this batch = 0.48112804393300146\n",
      "Cost on val dataset after 4 epochs is = 0.4811132453323031\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4811132453323031\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48097114574172867\n",
      "Error on this batch = 0.48104845399481494\n",
      "Cost on val dataset after 5 epochs is = 0.48106821345786166\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48106821345786166\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4809389924731349\n",
      "Error on this batch = 0.48102578802783086\n",
      "Cost on val dataset after 6 epochs is = 0.4810531489557464\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4810531489557464\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4809296492132114\n",
      "Error on this batch = 0.4810168451397722\n",
      "Cost on val dataset after 7 epochs is = 0.4810461328688657\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4810461328688657\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.48092540137423767\n",
      "Error on this batch = 0.4810118236828902\n",
      "Cost on val dataset after 8 epochs is = 0.48104156658626607\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48104156658626607\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.48092228385566727\n",
      "Error on this batch = 0.48100806636253474\n",
      "Cost on val dataset after 9 epochs is = 0.48103781503906357\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48103781503906357\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.48091937178044564\n",
      "Error on this batch = 0.4810047768107806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 10 epochs is = 0.4810343673084456\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4810343673084456\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.480916481605657\n",
      "Error on this batch = 0.4810017030440847\n",
      "Cost on val dataset after 11 epochs is = 0.48103106224571907\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48103106224571907\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4809136069741128\n",
      "Error on this batch = 0.4809987635196389\n",
      "Cost on val dataset after 12 epochs is = 0.4810278525830765\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4810278525830765\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48091077379551955\n",
      "Error on this batch = 0.48099593164119336\n",
      "Cost on val dataset after 13 epochs is = 0.48102472781311595\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48102472781311595\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.48090800522828164\n",
      "Error on this batch = 0.4809931982501489\n",
      "Cost on val dataset after 14 epochs is = 0.4810216880620939\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4810216880620939\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4809053158580807\n",
      "Error on this batch = 0.4809905592176925\n",
      "Cost on val dataset after 15 epochs is = 0.4810187353161667\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4810187353161667\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.48090271294141435\n",
      "Error on this batch = 0.48098801144207665\n",
      "Cost on val dataset after 16 epochs is = 0.481015870738236\n",
      "cost initial= 0.4810187353161667 , cost final=0.481015870738236 , change in cost= -2.8645779306946118e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 10 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 16\n",
      "The training time = 1.121sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 50 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 50)\n",
      "theta between layer 1 and layer 2 is (51, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.432333393911887\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.4325365973151007\n",
      "Error on this batch = 0.4816799445840069\n",
      "Cost on val dataset after 2 epochs is = 0.4811310837562912\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4811310837562912\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.4809476615658362\n",
      "Error on this batch = 0.4809422897462403\n",
      "Cost on val dataset after 3 epochs is = 0.4807636732506059\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4807636732506059\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4805579543179439\n",
      "Error on this batch = 0.48059490344520767\n",
      "Cost on val dataset after 4 epochs is = 0.4804193978131324\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4804193978131324\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.4801582422429723\n",
      "Error on this batch = 0.4802392062749708\n",
      "Cost on val dataset after 5 epochs is = 0.4800511215770093\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4800511215770093\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.47972384140699026\n",
      "Error on this batch = 0.47984843821733036\n",
      "Cost on val dataset after 6 epochs is = 0.47964409516789963\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.47964409516789963\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4792375703832661\n",
      "Error on this batch = 0.47940489424889743\n",
      "Cost on val dataset after 7 epochs is = 0.4791833203572708\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4791833203572708\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4786788211408088\n",
      "Error on this batch = 0.47889015503073795\n",
      "Cost on val dataset after 8 epochs is = 0.4786507559620688\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4786507559620688\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4780216704689768\n",
      "Error on this batch = 0.4782816185270896\n",
      "Cost on val dataset after 9 epochs is = 0.4780232840770061\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4780232840770061\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.47723168551668765\n",
      "Error on this batch = 0.47754984435306524\n",
      "Cost on val dataset after 10 epochs is = 0.4772701879242917\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4772701879242917\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.47626156576623163\n",
      "Error on this batch = 0.4766556855187335\n",
      "Cost on val dataset after 11 epochs is = 0.47634988591143557\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.47634988591143557\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4750455502404155\n",
      "Error on this batch = 0.4755475168242492\n",
      "Cost on val dataset after 12 epochs is = 0.47520634368775766\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.47520634368775766\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.4734939713144921\n",
      "Error on this batch = 0.4741611553074326\n",
      "Cost on val dataset after 13 epochs is = 0.4737676446554184\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4737676446554184\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.47149412389500284\n",
      "Error on this batch = 0.4724304214649544\n",
      "Cost on val dataset after 14 epochs is = 0.47195409791279475\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.47195409791279475\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4689336897037091\n",
      "Error on this batch = 0.47032276689406943\n",
      "Cost on val dataset after 15 epochs is = 0.46970751620475243\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.46970751620475243\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.46576695565961984\n",
      "Error on this batch = 0.4678987161231362\n",
      "Cost on val dataset after 16 epochs is = 0.4670359010446531\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4670359010446531\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4620969720624404\n",
      "Error on this batch = 0.46532695197889995\n",
      "Cost on val dataset after 17 epochs is = 0.464021845059292\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.464021845059292\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4581600911514769\n",
      "Error on this batch = 0.4627814979206925\n",
      "Cost on val dataset after 18 epochs is = 0.46076414932386217\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.46076414932386217\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.45417984434454356\n",
      "Error on this batch = 0.46032196918175217\n",
      "Cost on val dataset after 19 epochs is = 0.4573220654570584\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.4573220654570584\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.4502565516045523\n",
      "Error on this batch = 0.45789243563585535\n",
      "Cost on val dataset after 20 epochs is = 0.4537063371775303\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4537063371775303\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.44637960828556944\n",
      "Error on this batch = 0.4553908357385549\n",
      "Cost on val dataset after 21 epochs is = 0.4498809827432542\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.4498809827432542\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.4424763731836791\n",
      "Error on this batch = 0.45271310577580975\n",
      "Cost on val dataset after 22 epochs is = 0.4457636796851843\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4457636796851843\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.4384397880204572\n",
      "Error on this batch = 0.4497566987384009\n",
      "Cost on val dataset after 23 epochs is = 0.44124868546201085\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.44124868546201085\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.4341545959475549\n",
      "Error on this batch = 0.446416657977873\n",
      "Cost on val dataset after 24 epochs is = 0.4362664469062646\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.4362664469062646\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.42954866601813585\n",
      "Error on this batch = 0.44260964294386973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 25 epochs is = 0.4308390192203968\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4308390192203968\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.42463729820746243\n",
      "Error on this batch = 0.43832162491402576\n",
      "Cost on val dataset after 26 epochs is = 0.42504557291164574\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.42504557291164574\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.41948296891911485\n",
      "Error on this batch = 0.4336120664941014\n",
      "Cost on val dataset after 27 epochs is = 0.4189259015501969\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.4189259015501969\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.41410075649129957\n",
      "Error on this batch = 0.42855988913067267\n",
      "Cost on val dataset after 28 epochs is = 0.4124580820502143\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4124580820502143\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.4084357983657928\n",
      "Error on this batch = 0.4232254193501368\n",
      "Cost on val dataset after 29 epochs is = 0.4056320408135874\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.4056320408135874\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.40243147395154466\n",
      "Error on this batch = 0.41766227080205\n",
      "Cost on val dataset after 30 epochs is = 0.3985280787403657\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.3985280787403657\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.3961066517103239\n",
      "Error on this batch = 0.4119454112895529\n",
      "Cost on val dataset after 31 epochs is = 0.3913116596827842\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.3913116596827842\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.38956152100226404\n",
      "Error on this batch = 0.4061651498650477\n",
      "Cost on val dataset after 32 epochs is = 0.3841479375294367\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.3841479375294367\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.3829106141068073\n",
      "Error on this batch = 0.4003895451292566\n",
      "Cost on val dataset after 33 epochs is = 0.37713647538413114\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.37713647538413114\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.3762285631961899\n",
      "Error on this batch = 0.3946462297225676\n",
      "Cost on val dataset after 34 epochs is = 0.3703158763048405\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.3703158763048405\n",
      "learning rate for this epoch =  0.20706193828327601\n",
      "Error on this batch = 0.3695526017227866\n",
      "Error on this batch = 0.38893691824383825\n",
      "Cost on val dataset after 35 epochs is = 0.363696920896734\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.363696920896734\n",
      "learning rate for this epoch =  0.20556680845025985\n",
      "Error on this batch = 0.36290704158974485\n",
      "Error on this batch = 0.38325869695957127\n",
      "Cost on val dataset after 36 epochs is = 0.3572840682426129\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.3572840682426129\n",
      "learning rate for this epoch =  0.20412414523193154\n",
      "Error on this batch = 0.35631648867177335\n",
      "Error on this batch = 0.3776148268342326\n",
      "Cost on val dataset after 37 epochs is = 0.3510805700531517\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.3510805700531517\n",
      "learning rate for this epoch =  0.2027307249193849\n",
      "Error on this batch = 0.34980576099513727\n",
      "Error on this batch = 0.37201522949372284\n",
      "Cost on val dataset after 38 epochs is = 0.34508652730861644\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.34508652730861644\n",
      "learning rate for this epoch =  0.20138360231828867\n",
      "Error on this batch = 0.34339573777919435\n",
      "Error on this batch = 0.3664727145341491\n",
      "Cost on val dataset after 39 epochs is = 0.33929686598166353\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.33929686598166353\n",
      "learning rate for this epoch =  0.20008008009612496\n",
      "Error on this batch = 0.337100787007826\n",
      "Error on this batch = 0.36099940221391025\n",
      "Cost on val dataset after 40 epochs is = 0.333701218172429\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.333701218172429\n",
      "learning rate for this epoch =  0.19881768219176266\n",
      "Error on this batch = 0.3309285557474891\n",
      "Error on this batch = 0.3556048000752023\n",
      "Cost on val dataset after 41 epochs is = 0.32828516910117317\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.32828516910117317\n",
      "learning rate for this epoch =  0.19759413066220238\n",
      "Error on this batch = 0.3248810929359412\n",
      "Error on this batch = 0.3502952675461174\n",
      "Cost on val dataset after 42 epochs is = 0.32303195285227887\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.32303195285227887\n",
      "learning rate for this epoch =  0.1964073254502565\n",
      "Error on this batch = 0.3189563889464066\n",
      "Error on this batch = 0.3450742156125314\n",
      "Cost on val dataset after 43 epochs is = 0.3179240479034149\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.3179240479034149\n",
      "learning rate for this epoch =  0.19525532664475806\n",
      "Error on this batch = 0.3131498990343821\n",
      "Error on this batch = 0.3399425827039322\n",
      "Cost on val dataset after 44 epochs is = 0.312944474355369\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.312944474355369\n",
      "learning rate for this epoch =  0.19413633887611162\n",
      "Error on this batch = 0.3074559005231848\n",
      "Error on this batch = 0.33489937630132505\n",
      "Cost on val dataset after 45 epochs is = 0.30807777092616734\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.30807777092616734\n",
      "learning rate for this epoch =  0.19304869754804485\n",
      "Error on this batch = 0.30186862570488304\n",
      "Error on this batch = 0.3299422142463464\n",
      "Cost on val dataset after 46 epochs is = 0.30331068690659263\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.30331068690659263\n",
      "learning rate for this epoch =  0.19199085665396748\n",
      "Error on this batch = 0.29638313241749925\n",
      "Error on this batch = 0.32506785851854825\n",
      "Cost on val dataset after 47 epochs is = 0.298632630290758\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.298632630290758\n",
      "learning rate for this epoch =  0.1909613779654767\n",
      "Error on this batch = 0.29099589245704865\n",
      "Error on this batch = 0.3202727521439309\n",
      "Cost on val dataset after 48 epochs is = 0.2940359041972479\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.2940359041972479\n",
      "learning rate for this epoch =  0.18995892141289814\n",
      "Error on this batch = 0.28570510911013847\n",
      "Error on this batch = 0.31555356674710483\n",
      "Cost on val dataset after 49 epochs is = 0.28951575160758114\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.28951575160758114\n",
      "learning rate for this epoch =  0.1889822365046136\n",
      "Error on this batch = 0.2805108047662898\n",
      "Error on this batch = 0.3109077441397881\n",
      "Cost on val dataset after 50 epochs is = 0.28507021812111544\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.28507021812111544\n",
      "learning rate for this epoch =  0.1880301546543197\n",
      "Error on this batch = 0.2754147314218986\n",
      "Error on this batch = 0.3063339750757709\n",
      "Cost on val dataset after 51 epochs is = 0.2806998412857163\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.2806998412857163\n",
      "learning rate for this epoch =  0.18710158230410626\n",
      "Error on this batch = 0.2704201494271501\n",
      "Error on this batch = 0.30183252803740573\n",
      "Cost on val dataset after 52 epochs is = 0.2764071895136236\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.2764071895136236\n",
      "learning rate for this epoch =  0.1861954947469912\n",
      "Error on this batch = 0.26553150651935603\n",
      "Error on this batch = 0.29740535439025245\n",
      "Cost on val dataset after 53 epochs is = 0.2721962986790607\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.2721962986790607\n",
      "learning rate for this epoch =  0.18531093056582568\n",
      "Error on this batch = 0.2607540449326325\n",
      "Error on this batch = 0.29305595673736945\n",
      "Cost on val dataset after 54 epochs is = 0.26807207434981095\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.26807207434981095\n",
      "learning rate for this epoch =  0.18444698661672027\n",
      "Error on this batch = 0.25609337166318663\n",
      "Error on this batch = 0.28878907421783295\n",
      "Cost on val dataset after 55 epochs is = 0.26403972905986395\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.26403972905986395\n",
      "learning rate for this epoch =  0.1836028134946796\n",
      "Error on this batch = 0.25155503474827695\n",
      "Error on this batch = 0.28461026798535094\n",
      "Cost on val dataset after 56 epochs is = 0.260104306920193\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.260104306920193\n",
      "learning rate for this epoch =  0.18277761142725618\n",
      "Error on this batch = 0.2471441449870821\n",
      "Error on this batch = 0.2805254788636504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 57 epochs is = 0.2562703223868598\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.2562703223868598\n",
      "learning rate for this epoch =  0.18197062654897384\n",
      "Error on this batch = 0.2428650682544209\n",
      "Error on this batch = 0.27654060452233153\n",
      "Cost on val dataset after 58 epochs is = 0.2525415173157063\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.2525415173157063\n",
      "learning rate for this epoch =  0.1811811475152165\n",
      "Error on this batch = 0.23872119841991782\n",
      "Error on this batch = 0.27266112603794185\n",
      "Cost on val dataset after 59 epochs is = 0.2489207258471806\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.2489207258471806\n",
      "learning rate for this epoch =  0.180408502419387\n",
      "Error on this batch = 0.2347148121852778\n",
      "Error on this batch = 0.26889180438382276\n",
      "Cost on val dataset after 60 epochs is = 0.24540982945864656\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.24540982945864656\n",
      "learning rate for this epoch =  0.17965205598154213\n",
      "Error on this batch = 0.2308470039286113\n",
      "Error on this batch = 0.2652364597550986\n",
      "Cost on val dataset after 61 epochs is = 0.24200978179168514\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.24200978179168514\n",
      "learning rate for this epoch =  0.1789112069805131\n",
      "Error on this batch = 0.2271176962536032\n",
      "Error on this batch = 0.26169783771717897\n",
      "Cost on val dataset after 62 epochs is = 0.23872068256831466\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.23872068256831466\n",
      "learning rate for this epoch =  0.1781853859048144\n",
      "Error on this batch = 0.223525717769585\n",
      "Error on this batch = 0.2582775572141501\n",
      "Cost on val dataset after 63 epochs is = 0.23554188129348447\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.23554188129348447\n",
      "learning rate for this epoch =  0.17747405280050266\n",
      "Error on this batch = 0.22006893429145458\n",
      "Error on this batch = 0.25497612860412494\n",
      "Cost on val dataset after 64 epochs is = 0.23247209419226306\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.23247209419226306\n",
      "learning rate for this epoch =  0.17677669529663687\n",
      "Error on this batch = 0.21674441517421145\n",
      "Error on this batch = 0.2517930260865378\n",
      "Cost on val dataset after 65 epochs is = 0.22950952150388837\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.22950952150388837\n",
      "learning rate for this epoch =  0.1760928267911618\n",
      "Error on this batch = 0.21354861450600449\n",
      "Error on this batch = 0.24872679792135757\n",
      "Cost on val dataset after 66 epochs is = 0.2266519562395852\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.2266519562395852\n",
      "learning rate for this epoch =  0.17542198478193427\n",
      "Error on this batch = 0.21047754790996578\n",
      "Error on this batch = 0.2457751989096115\n",
      "Cost on val dataset after 67 epochs is = 0.2238968792329648\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.2238968792329648\n",
      "learning rate for this epoch =  0.1747637293292756\n",
      "Error on this batch = 0.20752694935584123\n",
      "Error on this batch = 0.24293533186869462\n",
      "Cost on val dataset after 68 epochs is = 0.22124153839141797\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.22124153839141797\n",
      "learning rate for this epoch =  0.1741176416378927\n",
      "Error on this batch = 0.20469239775101677\n",
      "Error on this batch = 0.24020378764649594\n",
      "Cost on val dataset after 69 epochs is = 0.21868301233824405\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.21868301233824405\n",
      "learning rate for this epoch =  0.1734833227472955\n",
      "Error on this batch = 0.20196940908731598\n",
      "Error on this batch = 0.2375767761365586\n",
      "Cost on val dataset after 70 epochs is = 0.2162182601296517\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.2162182601296517\n",
      "learning rate for this epoch =  0.1728603923209705\n",
      "Error on this batch = 0.19935349552417517\n",
      "Error on this batch = 0.23505024349422715\n",
      "Cost on val dataset after 71 epochs is = 0.2138441595394646\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.2138441595394646\n",
      "learning rate for this epoch =  0.17224848752556968\n",
      "Error on this batch = 0.19684019713280174\n",
      "Error on this batch = 0.23261997312002922\n",
      "Cost on val dataset after 72 epochs is = 0.2115575366609635\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.2115575366609635\n",
      "learning rate for this epoch =  0.17164726199225983\n",
      "Error on this batch = 0.19442509455972556\n",
      "Error on this batch = 0.23028166985332327\n",
      "Cost on val dataset after 73 epochs is = 0.20935518941848594\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.20935518941848594\n",
      "learning rate for this epoch =  0.17105638485316074\n",
      "Error on this batch = 0.19210381144267508\n",
      "Error on this batch = 0.22803102815812223\n",
      "Cost on val dataset after 74 epochs is = 0.20723390714784076\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.20723390714784076\n",
      "learning rate for this epoch =  0.1704755398464977\n",
      "Error on this batch = 0.18987201429189157\n",
      "Error on this batch = 0.2258637859045264\n",
      "Cost on val dataset after 75 epochs is = 0.20519048782652283\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.20519048782652283\n",
      "learning rate for this epoch =  0.16990442448471224\n",
      "Error on this batch = 0.18772541531668374\n",
      "Error on this batch = 0.22377576573193644\n",
      "Cost on val dataset after 76 epochs is = 0.20322175393255068\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.20322175393255068\n",
      "learning rate for this epoch =  0.16934274928032858\n",
      "Error on this batch = 0.1856597810408293\n",
      "Error on this batch = 0.22176290603780924\n",
      "Cost on val dataset after 77 epochs is = 0.20132456738075996\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.20132456738075996\n",
      "learning rate for this epoch =  0.16879023702486318\n",
      "Error on this batch = 0.1836709471478741\n",
      "Error on this batch = 0.21982128348900964\n",
      "Cost on val dataset after 78 epochs is = 0.19949584358848352\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.19949584358848352\n",
      "learning rate for this epoch =  0.16824662211650757\n",
      "Error on this batch = 0.18175483824539002\n",
      "Error on this batch = 0.21794712870633112\n",
      "Cost on val dataset after 79 epochs is = 0.19773256448060017\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.19773256448060017\n",
      "learning rate for this epoch =  0.1677116499327062\n",
      "Error on this batch = 0.17990749028653827\n",
      "Error on this batch = 0.21613683650168888\n",
      "Cost on val dataset after 80 epochs is = 0.1960317901452003\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.1960317901452003\n",
      "learning rate for this epoch =  0.1671850762441055\n",
      "Error on this batch = 0.17812507316581522\n",
      "Error on this batch = 0.21438697179581348\n",
      "Cost on val dataset after 81 epochs is = 0.19439066886223938\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.19439066886223938\n",
      "learning rate for this epoch =  0.16666666666666666\n",
      "Error on this batch = 0.17640391131104877\n",
      "Error on this batch = 0.2126942721306928\n",
      "Cost on val dataset after 82 epochs is = 0.1928064453070953\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.1928064453070953\n",
      "learning rate for this epoch =  0.16615619614902008\n",
      "Error on this batch = 0.1747405006873027\n",
      "Error on this batch = 0.2110556475179529\n",
      "Cost on val dataset after 83 epochs is = 0.19127646684031566\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.19127646684031566\n",
      "learning rate for this epoch =  0.16565344849239508\n",
      "Error on this batch = 0.17313152130409287\n",
      "Error on this batch = 0.20946817822626687\n",
      "Cost on val dataset after 84 epochs is = 0.18979818790466185\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.18979818790466185\n",
      "learning rate for this epoch =  0.16515821590069035\n",
      "Error on this batch = 0.17157384493302552\n",
      "Error on this batch = 0.20792911099998526\n",
      "Cost on val dataset after 85 epochs is = 0.18836917264256248\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.18836917264256248\n",
      "learning rate for this epoch =  0.164670298558459\n",
      "Error on this batch = 0.17006453822333392\n",
      "Error on this batch = 0.20643585411058638\n",
      "Cost on val dataset after 86 epochs is = 0.18698709591296175\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.18698709591296175\n",
      "learning rate for this epoch =  0.16418950423477013\n",
      "Error on this batch = 0.16860086172577776\n",
      "Error on this batch = 0.20498597156725054\n",
      "Cost on val dataset after 87 epochs is = 0.18564974292526984\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.18564974292526984\n",
      "learning rate for this epoch =  0.16371564791108048\n",
      "Error on this batch = 0.16718026551314652\n",
      "Error on this batch = 0.20357717674961373\n",
      "Cost on val dataset after 88 epochs is = 0.18435500772307953\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.18435500772307953\n",
      "learning rate for this epoch =  0.16324855143140263\n",
      "Error on this batch = 0.16580038214733506\n",
      "Error on this batch = 0.20220732567256433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 89 epochs is = 0.1831008907469176\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1831008907469176\n",
      "learning rate for this epoch =  0.1627880431731981\n",
      "Error on this batch = 0.1644590177224032\n",
      "Error on this batch = 0.2008744100484762\n",
      "Cost on val dataset after 90 epochs is = 0.18188549568929502\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.18188549568929502\n",
      "learning rate for this epoch =  0.16233395773754944\n",
      "Error on this batch = 0.16315414164117506\n",
      "Error on this batch = 0.1995765502755002\n",
      "Cost on val dataset after 91 epochs is = 0.1807070258318478\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.1807070258318478\n",
      "learning rate for this epoch =  0.16188613565728216\n",
      "Error on this batch = 0.16188387568468293\n",
      "Error on this batch = 0.19831198845053932\n",
      "Cost on val dataset after 92 epochs is = 0.17956378002748996\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.17956378002748996\n",
      "learning rate for this epoch =  0.161444423121811\n",
      "Error on this batch = 0.16064648282711702\n",
      "Error on this batch = 0.19707908148136583\n",
      "Cost on val dataset after 93 epochs is = 0.17845414846318913\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.17845414846318913\n",
      "learning rate for this epoch =  0.16100867171758368\n",
      "Error on this batch = 0.15944035614575244\n",
      "Error on this batch = 0.19587629435312134\n",
      "Cost on val dataset after 94 epochs is = 0.17737660831314783\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.17737660831314783\n",
      "learning rate for this epoch =  0.160578738183079\n",
      "Error on this batch = 0.15826400808244476\n",
      "Error on this batch = 0.19470219358930854\n",
      "Cost on val dataset after 95 epochs is = 0.17632971936895095\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.17632971936895095\n",
      "learning rate for this epoch =  0.16015448417739933\n",
      "Error on this batch = 0.157116060233993\n",
      "Error on this batch = 0.19355544093556445\n",
      "Cost on val dataset after 96 epochs is = 0.1753121197131221\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.1753121197131221\n",
      "learning rate for this epoch =  0.1597357760615681\n",
      "Error on this batch = 0.15599523378379318\n",
      "Error on this batch = 0.19243478728534505\n",
      "Cost on val dataset after 97 epochs is = 0.17432252148562263\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.17432252148562263\n",
      "learning rate for this epoch =  0.15932248469171095\n",
      "Error on this batch = 0.15490034063607966\n",
      "Error on this batch = 0.19133906685958885\n",
      "Cost on val dataset after 98 epochs is = 0.17335970677895657\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.17335970677895657\n",
      "learning rate for this epoch =  0.15891448522335927\n",
      "Error on this batch = 0.15383027527520374\n",
      "Error on this batch = 0.19026719164702158\n",
      "Cost on val dataset after 99 epochs is = 0.17242252368640992\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.17242252368640992\n",
      "learning rate for this epoch =  0.15851165692617153\n",
      "Error on this batch = 0.1527840073439937\n",
      "Error on this batch = 0.18921814610765836\n",
      "Cost on val dataset after 100 epochs is = 0.17150988251918428\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.17150988251918428\n",
      "learning rate for this epoch =  0.15811388300841897\n",
      "Error on this batch = 0.15176057491540115\n",
      "Error on this batch = 0.188190982138979\n",
      "Cost on val dataset after 101 epochs is = 0.1706207522014064\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.1706207522014064\n",
      "learning rate for this epoch =  0.1577210504506286\n",
      "Error on this batch = 0.150759078418597\n",
      "Error on this batch = 0.18718481430198047\n",
      "Cost on val dataset after 102 epochs is = 0.16975415684684683\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.16975415684684683\n",
      "learning rate for this epoch =  0.1573330498478208\n",
      "Error on this batch = 0.14977867517288895\n",
      "Error on this batch = 0.18619881530267116\n",
      "Cost on val dataset after 103 epochs is = 0.16890917251735263\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.16890917251735263\n",
      "learning rate for this epoch =  0.15694977525981785\n",
      "Error on this batch = 0.14881857447897168\n",
      "Error on this batch = 0.18523221172343227\n",
      "Cost on val dataset after 104 epochs is = 0.16808492416020843\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.16808492416020843\n",
      "learning rate for this epoch =  0.15657112406913673\n",
      "Error on this batch = 0.14787803321601936\n",
      "Error on this batch = 0.1842842799979143\n",
      "Cost on val dataset after 105 epochs is = 0.16728058271966734\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.16728058271966734\n",
      "learning rate for this epoch =  0.1561969968460128\n",
      "Error on this batch = 0.14695635189413403\n",
      "Error on this batch = 0.1833543426226693\n",
      "Cost on val dataset after 106 epochs is = 0.16649536241654844\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.16649536241654844\n",
      "learning rate for this epoch =  0.15582729722013278\n",
      "Error on this batch = 0.14605287111400547\n",
      "Error on this batch = 0.1824417645984596\n",
      "Cost on val dataset after 107 epochs is = 0.16572851818892667\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.16572851818892667\n",
      "learning rate for this epoch =  0.15546193175868359\n",
      "Error on this batch = 0.14516696838881957\n",
      "Error on this batch = 0.18154595009406777\n",
      "Cost on val dataset after 108 epochs is = 0.16497934328643565\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.16497934328643565\n",
      "learning rate for this epoch =  0.15510080985034994\n",
      "Error on this batch = 0.1442980552870949\n",
      "Error on this batch = 0.1806663393254005\n",
      "Cost on val dataset after 109 epochs is = 0.16424716701045833\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.16424716701045833\n",
      "learning rate for this epoch =  0.1547438435949191\n",
      "Error on this batch = 0.14344557485896478\n",
      "Error on this batch = 0.17980240564269043\n",
      "Cost on val dataset after 110 epochs is = 0.16353135259243465\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.16353135259243465\n",
      "learning rate for this epoch =  0.1543909476981724\n",
      "Error on this batch = 0.1426089993122608\n",
      "Error on this batch = 0.17895365281861572\n",
      "Cost on val dataset after 111 epochs is = 0.16283129520260298\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.16283129520260298\n",
      "learning rate for this epoch =  0.15404203937176525\n",
      "Error on this batch = 0.14178782790846708\n",
      "Error on this batch = 0.17811961253015626\n",
      "Cost on val dataset after 112 epochs is = 0.1621464200816825\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.1621464200816825\n",
      "learning rate for this epoch =  0.1536970382378161\n",
      "Error on this batch = 0.14098158505211925\n",
      "Error on this batch = 0.17729984202696955\n",
      "Cost on val dataset after 113 epochs is = 0.16147618078825543\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.16147618078825543\n",
      "learning rate for this epoch =  0.15335586623794323\n",
      "Error on this batch = 0.14018981855046442\n",
      "Error on this batch = 0.17649392197899227\n",
      "Cost on val dataset after 114 epochs is = 0.16082005755490217\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.16082005755490217\n",
      "learning rate for this epoch =  0.1530184475465045\n",
      "Error on this batch = 0.1394120980231623\n",
      "Error on this batch = 0.1757014544958545\n",
      "Cost on val dataset after 115 epochs is = 0.16017755574646392\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.16017755574646392\n",
      "learning rate for this epoch =  0.15268470848781107\n",
      "Error on this batch = 0.1386480134444733\n",
      "Error on this batch = 0.1749220613105401\n",
      "Cost on val dataset after 116 epochs is = 0.15954820441413747\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.15954820441413747\n",
      "learning rate for this epoch =  0.1523545774571\n",
      "Error on this batch = 0.13789717380276206\n",
      "Error on this batch = 0.17415538211954698\n",
      "Cost on val dataset after 117 epochs is = 0.15893155493944153\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.15893155493944153\n",
      "learning rate for this epoch =  0.15202798484506466\n",
      "Error on this batch = 0.13715920586424868\n",
      "Error on this batch = 0.1734010730716087\n",
      "Cost on val dataset after 118 epochs is = 0.1583271797624249\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.1583271797624249\n",
      "learning rate for this epoch =  0.15170486296575364\n",
      "Error on this batch = 0.13643375302978547\n",
      "Error on this batch = 0.17265880539685402\n",
      "Cost on val dataset after 119 epochs is = 0.15773467118881065\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.15773467118881065\n",
      "learning rate for this epoch =  0.1513851459876605\n",
      "Error on this batch = 0.13572047427504427\n",
      "Error on this batch = 0.17192826416810852\n",
      "Cost on val dataset after 120 epochs is = 0.15715364027108109\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.15715364027108109\n",
      "learning rate for this epoch =  0.1510687698678384\n",
      "Error on this batch = 0.13501904316588642\n",
      "Error on this batch = 0.1712091471859125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 121 epochs is = 0.15658371575880936\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.15658371575880936\n",
      "learning rate for this epoch =  0.15075567228888181\n",
      "Error on this batch = 0.13432914694187997\n",
      "Error on this batch = 0.1705011639787388\n",
      "Cost on val dataset after 122 epochs is = 0.15602454311382913\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.15602454311382913\n",
      "learning rate for this epoch =  0.1504457925986288\n",
      "Error on this batch = 0.1336504856619447\n",
      "Error on this batch = 0.16980403490986434\n",
      "Cost on val dataset after 123 epochs is = 0.15547578358610503\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.15547578358610503\n",
      "learning rate for this epoch =  0.15013907175244492\n",
      "Error on this batch = 0.1329827714069663\n",
      "Error on this batch = 0.1691174903823866\n",
      "Cost on val dataset after 124 epochs is = 0.15493711334642557\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.15493711334642557\n",
      "learning rate for this epoch =  0.1498354522579582\n",
      "Error on this batch = 0.13232572753494506\n",
      "Error on this batch = 0.16844127013397622\n",
      "Cost on val dataset after 125 epochs is = 0.15440822267228207\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.15440822267228207\n",
      "learning rate for this epoch =  0.14953487812212204\n",
      "Error on this batch = 0.13167908798485053\n",
      "Error on this batch = 0.16777512261313463\n",
      "Cost on val dataset after 126 epochs is = 0.15388881518352826\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.15388881518352826\n",
      "learning rate for this epoch =  0.14923729480049114\n",
      "Error on this batch = 0.13104259662585588\n",
      "Error on this batch = 0.16711880442896515\n",
      "Cost on val dataset after 127 epochs is = 0.15337860712463156\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.15337860712463156\n",
      "learning rate for this epoch =  0.14894264914859962\n",
      "Error on this batch = 0.13041600664903913\n",
      "Error on this batch = 0.1664720798667736\n",
      "Cost on val dataset after 128 epochs is = 0.1528773266905303\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.1528773266905303\n",
      "learning rate for this epoch =  0.14865088937534013\n",
      "Error on this batch = 0.12979907999897874\n",
      "Error on this batch = 0.16583472046217584\n",
      "Cost on val dataset after 129 epochs is = 0.15238471339330342\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.15238471339330342\n",
      "learning rate for this epoch =  0.14836196499824542\n",
      "Error on this batch = 0.12919158684294452\n",
      "Error on this batch = 0.16520650462680064\n",
      "Cost on val dataset after 130 epochs is = 0.151900517467039\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.151900517467039\n",
      "learning rate for this epoch =  0.14807582680058123\n",
      "Error on this batch = 0.12859330507560787\n",
      "Error on this batch = 0.164587217319126\n",
      "Cost on val dataset after 131 epochs is = 0.15142449930845708\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.15142449930845708\n",
      "learning rate for this epoch =  0.14779242679016388\n",
      "Error on this batch = 0.12800401985737137\n",
      "Error on this batch = 0.16397664975446405\n",
      "Cost on val dataset after 132 epochs is = 0.15095642895100075\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.15095642895100075\n",
      "learning rate for this epoch =  0.1475117181598202\n",
      "Error on this batch = 0.12742352318455946\n",
      "Error on this batch = 0.163374599148605\n",
      "Cost on val dataset after 133 epochs is = 0.15049608557025784\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.15049608557025784\n",
      "learning rate for this epoch =  0.147233655249413\n",
      "Error on this batch = 0.12685161348982227\n",
      "Error on this batch = 0.16278086849013587\n",
      "Cost on val dataset after 134 epochs is = 0.150043257018716\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.150043257018716\n",
      "learning rate for this epoch =  0.1469581935093583\n",
      "Error on this batch = 0.1262880952711922\n",
      "Error on this batch = 0.16219526633695083\n",
      "Cost on val dataset after 135 epochs is = 0.14959773938798257\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.14959773938798257\n",
      "learning rate for this epoch =  0.14668528946556555\n",
      "Error on this batch = 0.12573277874830205\n",
      "Error on this batch = 0.16161760663296357\n",
      "Cost on val dataset after 136 epochs is = 0.14915933659672503\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.14915933659672503\n",
      "learning rate for this epoch =  0.14641490068573487\n",
      "Error on this batch = 0.12518547954432738\n",
      "Error on this batch = 0.16104770854150827\n",
      "Cost on val dataset after 137 epochs is = 0.14872786000269927\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.14872786000269927\n",
      "learning rate for this epoch =  0.14614698574694937\n",
      "Error on this batch = 0.12464601839225964\n",
      "Error on this batch = 0.16048539629236971\n",
      "Cost on val dataset after 138 epochs is = 0.14830312803734316\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.14830312803734316\n",
      "learning rate for this epoch =  0.145881504204504\n",
      "Error on this batch = 0.12411422086415361\n",
      "Error on this batch = 0.1599304990398083\n",
      "Cost on val dataset after 139 epochs is = 0.1478849658615094\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.1478849658615094\n",
      "learning rate for this epoch =  0.14561841656191457\n",
      "Error on this batch = 0.12358991712202379\n",
      "Error on this batch = 0.15938285072934172\n",
      "Cost on val dataset after 140 epochs is = 0.1474732050410074\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.1474732050410074\n",
      "learning rate for this epoch =  0.14535768424205484\n",
      "Error on this batch = 0.1230729416890926\n",
      "Error on this batch = 0.15884228997140656\n",
      "Cost on val dataset after 141 epochs is = 0.14706768324070935\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.14706768324070935\n",
      "learning rate for this epoch =  0.14509926955937089\n",
      "Error on this batch = 0.1225631332401213\n",
      "Error on this batch = 0.1583086599203509\n",
      "Cost on val dataset after 142 epochs is = 0.14666824393605934\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.14666824393605934\n",
      "learning rate for this epoch =  0.1448431356931257\n",
      "Error on this batch = 0.12206033440958247\n",
      "Error on this batch = 0.15778180815750087\n",
      "Cost on val dataset after 143 epochs is = 0.14627473614089687\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.14627473614089687\n",
      "learning rate for this epoch =  0.14458924666162856\n",
      "Error on this batch = 0.12156439161646039\n",
      "Error on this batch = 0.15726158657730513\n",
      "Cost on val dataset after 144 epochs is = 0.14588701415058047\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.14588701415058047\n",
      "learning rate for this epoch =  0.14433756729740646\n",
      "Error on this batch = 0.12107515490449759\n",
      "Error on this batch = 0.15674785127578317\n",
      "Cost on val dataset after 145 epochs is = 0.1455049372994619\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.1455049372994619\n",
      "learning rate for this epoch =  0.14408806322327672\n",
      "Error on this batch = 0.12059247779673878\n",
      "Error on this batch = 0.15624046244070117\n",
      "Cost on val dataset after 146 epochs is = 0.1451283697318222\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.1451283697318222\n",
      "learning rate for this epoch =  0.14384070082928266\n",
      "Error on this batch = 0.12011621716325817\n",
      "Error on this batch = 0.1557392842430617\n",
      "Cost on val dataset after 147 epochs is = 0.1447571801854401\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.1447571801854401\n",
      "learning rate for this epoch =  0.1435954472504545\n",
      "Error on this batch = 0.11964623310099565\n",
      "Error on this batch = 0.15524418472963286\n",
      "Cost on val dataset after 148 epochs is = 0.1443912417870173\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.1443912417870173\n",
      "learning rate for this epoch =  0.1433522703453617\n",
      "Error on this batch = 0.11918238882466799\n",
      "Error on this batch = 0.15475503571635546\n",
      "Cost on val dataset after 149 epochs is = 0.14403043185873252\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.14403043185873252\n",
      "learning rate for this epoch =  0.1431111386754225\n",
      "Error on this batch = 0.11872455056776442\n",
      "Error on this batch = 0.15427171268255765\n",
      "Cost on val dataset after 150 epochs is = 0.14367463173524697\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.14367463173524697\n",
      "learning rate for this epoch =  0.14287202148493997\n",
      "Error on this batch = 0.11827258749268303\n",
      "Error on this batch = 0.153794094665981\n",
      "Cost on val dataset after 151 epochs is = 0.1433237265905249\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.1433237265905249\n",
      "learning rate for this epoch =  0.14263488868183333\n",
      "Error on this batch = 0.11782637160911051\n",
      "Error on this batch = 0.15332206415867397\n",
      "Cost on val dataset after 152 epochs is = 0.14297760527387435\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.14297760527387435\n",
      "learning rate for this epoch =  0.14239971081903682\n",
      "Error on this batch = 0.1173857776997989\n",
      "Error on this batch = 0.15285550700385206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 153 epochs is = 0.14263616015465203\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.14263616015465203\n",
      "learning rate for this epoch =  0.14216645907653844\n",
      "Error on this batch = 0.11695068325294208\n",
      "Error on this batch = 0.15239431229385045\n",
      "Cost on val dataset after 154 epochs is = 0.14229928697511143\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.14229928697511143\n",
      "learning rate for this epoch =  0.14193510524403224\n",
      "Error on this batch = 0.11652096840040599\n",
      "Error on this batch = 0.15193837226931325\n",
      "Cost on val dataset after 155 epochs is = 0.14196688471090552\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.14196688471090552\n",
      "learning rate for this epoch =  0.1417056217041599\n",
      "Error on this batch = 0.11609651586111898\n",
      "Error on this batch = 0.1514875822197722\n",
      "Cost on val dataset after 156 epochs is = 0.14163885543878865\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.14163885543878865\n",
      "learning rate for this epoch =  0.14147798141631754\n",
      "Error on this batch = 0.11567721088897823\n",
      "Error on this batch = 0.15104184038577048\n",
      "Cost on val dataset after 157 epochs is = 0.1413151042110896\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.1413151042110896\n",
      "learning rate for this epoch =  0.14125215790100537\n",
      "Error on this batch = 0.11526294122468014\n",
      "Error on this batch = 0.15060104786268286\n",
      "Cost on val dataset after 158 epochs is = 0.14099553893655462\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.14099553893655462\n",
      "learning rate for this epoch =  0.14102812522469854\n",
      "Error on this batch = 0.11485359705093118\n",
      "Error on this batch = 0.1501651085063765\n",
      "Cost on val dataset after 159 epochs is = 0.14068007026718665\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.14068007026718665\n",
      "learning rate for this epoch =  0.1408058579852188\n",
      "Error on this batch = 0.11444907095054463\n",
      "Error on this batch = 0.14973392884084555\n",
      "Cost on val dataset after 160 epochs is = 0.14036861149072824\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.14036861149072824\n",
      "learning rate for this epoch =  0.14058533129758727\n",
      "Error on this batch = 0.11404925786697515\n",
      "Error on this batch = 0.14930741796793962\n",
      "Cost on val dataset after 161 epochs is = 0.14006107842845955\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.14006107842845955\n",
      "learning rate for this epoch =  0.14036652078033962\n",
      "Error on this batch = 0.11365405506688772\n",
      "Error on this batch = 0.14888548747929142\n",
      "Cost on val dataset after 162 epochs is = 0.1397573893380031\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.1397573893380031\n",
      "learning rate for this epoch =  0.14014940254228575\n",
      "Error on this batch = 0.11326336210440083\n",
      "Error on this batch = 0.14846805137053345\n",
      "Cost on val dataset after 163 epochs is = 0.13945746482084573\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.13945746482084573\n",
      "learning rate for this epoch =  0.13993395316969692\n",
      "Error on this batch = 0.11287708078668388\n",
      "Error on this batch = 0.1480550259578784\n",
      "Cost on val dataset after 164 epochs is = 0.13916122773430706\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.13916122773430706\n",
      "learning rate for this epoch =  0.13972014971390403\n",
      "Error on this batch = 0.11249511514062716\n",
      "Error on this batch = 0.1476463297971212\n",
      "Cost on val dataset after 165 epochs is = 0.13886860310770102\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.13886860310770102\n",
      "learning rate for this epoch =  0.13950796967929133\n",
      "Error on this batch = 0.11211737138033892\n",
      "Error on this batch = 0.14724188360510657\n",
      "Cost on val dataset after 166 epochs is = 0.1385795180624517\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.1385795180624517\n",
      "learning rate for this epoch =  0.13929739101167085\n",
      "Error on this batch = 0.11174375787525609\n",
      "Error on this batch = 0.1468416101836904\n",
      "Cost on val dataset after 167 epochs is = 0.13829390173594103\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.13829390173594103\n",
      "learning rate for this epoch =  0.13908839208702292\n",
      "Error on this batch = 0.11137418511868799\n",
      "Error on this batch = 0.14644543434621046\n",
      "Cost on val dataset after 168 epochs is = 0.1380116852088782\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.1380116852088782\n",
      "learning rate for this epoch =  0.13888095170058953\n",
      "Error on this batch = 0.11100856569663861\n",
      "Error on this batch = 0.1460532828464688\n",
      "Cost on val dataset after 169 epochs is = 0.1377328014359958\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.1377328014359958\n",
      "learning rate for this epoch =  0.1386750490563073\n",
      "Error on this batch = 0.11064681425678007\n",
      "Error on this batch = 0.14566508431021644\n",
      "Cost on val dataset after 170 epochs is = 0.13745718517988745\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.13745718517988745\n",
      "learning rate for this epoch =  0.13847066375656708\n",
      "Error on this batch = 0.11028884747747299\n",
      "Error on this batch = 0.14528076916912108\n",
      "Cost on val dataset after 171 epochs is = 0.13718477294781506\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.13718477294781506\n",
      "learning rate for this epoch =  0.1382677757922894\n",
      "Error on this batch = 0.10993458403675031\n",
      "Error on this batch = 0.14490026959718857\n",
      "Cost on val dataset after 172 epochs is = 0.1369155029313232\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.1369155029313232\n",
      "learning rate for this epoch =  0.1380663655333028\n",
      "Error on this batch = 0.1095839445812008\n",
      "Error on this batch = 0.14452351944960096\n",
      "Cost on val dataset after 173 epochs is = 0.136649314948509\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.136649314948509\n",
      "learning rate for this epoch =  0.13786641371901512\n",
      "Error on this batch = 0.10923685169470383\n",
      "Error on this batch = 0.1441504542039263\n",
      "Cost on val dataset after 174 epochs is = 0.13638615038880458\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.13638615038880458\n",
      "learning rate for this epoch =  0.13766790144936686\n",
      "Error on this batch = 0.10889322986698372\n",
      "Error on this batch = 0.1437810109036504\n",
      "Cost on val dataset after 175 epochs is = 0.13612595216013806\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.13612595216013806\n",
      "learning rate for this epoch =  0.1374708101760565\n",
      "Error on this batch = 0.108553005461963\n",
      "Error on this batch = 0.1434151281039736\n",
      "Cost on val dataset after 176 epochs is = 0.1358686646383478\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.1358686646383478\n",
      "learning rate for this epoch =  0.1372751216940281\n",
      "Error on this batch = 0.10821610668590693\n",
      "Error on this batch = 0.14305274581981367\n",
      "Cost on val dataset after 177 epochs is = 0.13561423361873076\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.13561423361873076\n",
      "learning rate for this epoch =  0.1370808181332119\n",
      "Error on this batch = 0.10788246355535924\n",
      "Error on this batch = 0.14269380547594995\n",
      "Cost on val dataset after 178 epochs is = 0.13536260626961533\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.13536260626961533\n",
      "learning rate for this epoch =  0.13688788195050916\n",
      "Error on this batch = 0.10755200786487942\n",
      "Error on this batch = 0.14233824985924345\n",
      "Cost on val dataset after 179 epochs is = 0.13511373108785293\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.13511373108785293\n",
      "learning rate for this epoch =  0.13669629592201246\n",
      "Error on this batch = 0.10722467315459724\n",
      "Error on this batch = 0.14198602307286456\n",
      "Cost on val dataset after 180 epochs is = 0.13486755785613097\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.13486755785613097\n",
      "learning rate for this epoch =  0.13650604313545334\n",
      "Error on this batch = 0.10690039467760556\n",
      "Error on this batch = 0.14163707049245847\n",
      "Cost on val dataset after 181 epochs is = 0.13462403760201552\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.13462403760201552\n",
      "learning rate for this epoch =  0.13631710698286975\n",
      "Error on this batch = 0.10657910936721883\n",
      "Error on this batch = 0.14129133872417768\n",
      "Cost on val dataset after 182 epochs is = 0.13438312255863544\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.13438312255863544\n",
      "learning rate for this epoch =  0.1361294711534851\n",
      "Error on this batch = 0.10626075580412572\n",
      "Error on this batch = 0.14094877556451205\n",
      "Cost on val dataset after 183 epochs is = 0.13414476612692788\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.13414476612692788\n",
      "learning rate for this epoch =  0.13594311962679215\n",
      "Error on this batch = 0.10594527418346926\n",
      "Error on this batch = 0.14060932996184466\n",
      "Cost on val dataset after 184 epochs is = 0.13390892283936748\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.13390892283936748\n",
      "learning rate for this epoch =  0.13575803666583477\n",
      "Error on this batch = 0.10563260628188842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.14027295197966397\n",
      "Cost on val dataset after 185 epochs is = 0.13367554832510678\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.13367554832510678\n",
      "learning rate for this epoch =  0.13557420681068058\n",
      "Error on this batch = 0.10532269542455634\n",
      "Error on this batch = 0.13993959276136345\n",
      "Cost on val dataset after 186 epochs is = 0.13344459927646046\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.13344459927646046\n",
      "learning rate for this epoch =  0.13539161487207826\n",
      "Error on this batch = 0.10501548645225192\n",
      "Error on this batch = 0.13960920449656003\n",
      "Cost on val dataset after 187 epochs is = 0.13321603341666818\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.13321603341666818\n",
      "learning rate for this epoch =  0.13521024592529318\n",
      "Error on this batch = 0.10471092568850063\n",
      "Error on this batch = 0.13928174038886554\n",
      "Cost on val dataset after 188 epochs is = 0.13298980946887634\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.13298980946887634\n",
      "learning rate for this epoch =  0.1350300853041159\n",
      "Error on this batch = 0.10440896090682071\n",
      "Error on this batch = 0.13895715462504535\n",
      "Cost on val dataset after 189 epochs is = 0.13276588712628068\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.13276588712628068\n",
      "learning rate for this epoch =  0.13485111859503687\n",
      "Error on this batch = 0.10410954129811022\n",
      "Error on this batch = 0.13863540234550129\n",
      "Cost on val dataset after 190 epochs is = 0.1325442270233771\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.1325442270233771\n",
      "learning rate for this epoch =  0.13467333163158285\n",
      "Error on this batch = 0.10381261743820912\n",
      "Error on this batch = 0.13831643961601772\n",
      "Cost on val dataset after 191 epochs is = 0.1323247907082682\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.1323247907082682\n",
      "learning rate for this epoch =  0.13449671048880912\n",
      "Error on this batch = 0.10351814125566947\n",
      "Error on this batch = 0.13800022340071025\n",
      "Cost on val dataset after 192 epochs is = 0.13210754061597887\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.13210754061597887\n",
      "learning rate for this epoch =  0.13432124147794275\n",
      "Error on this batch = 0.10322606599976589\n",
      "Error on this batch = 0.1376867115361211\n",
      "Cost on val dataset after 193 epochs is = 0.1318924400427347\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.1318924400427347\n",
      "learning rate for this epoch =  0.1341469111411715\n",
      "Error on this batch = 0.10293634620877586\n",
      "Error on this batch = 0.13737586270640445\n",
      "Cost on val dataset after 194 epochs is = 0.13167945312116036\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.13167945312116036\n",
      "learning rate for this epoch =  0.13397370624657456\n",
      "Error on this batch = 0.10264893767855936\n",
      "Error on this batch = 0.1370676364195491\n",
      "Cost on val dataset after 195 epochs is = 0.13146854479635756\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.13146854479635756\n",
      "learning rate for this epoch =  0.13380161378318955\n",
      "Error on this batch = 0.10236379743146336\n",
      "Error on this batch = 0.13676199298458766\n",
      "Cost on val dataset after 196 epochs is = 0.13125968080282402\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.13125968080282402\n",
      "learning rate for this epoch =  0.1336306209562122\n",
      "Error on this batch = 0.10208088368557697\n",
      "Error on this batch = 0.13645889348974233\n",
      "Cost on val dataset after 197 epochs is = 0.13105282764217688\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.13105282764217688\n",
      "learning rate for this epoch =  0.13346071518232402\n",
      "Error on this batch = 0.10180015582436017\n",
      "Error on this batch = 0.13615829978146154\n",
      "Cost on val dataset after 198 epochs is = 0.13084795256164627\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.13084795256164627\n",
      "learning rate for this epoch =  0.13329188408514428\n",
      "Error on this batch = 0.10152157436666706\n",
      "Error on this batch = 0.13586017444430162\n",
      "Cost on val dataset after 199 epochs is = 0.13064502353330637\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.13064502353330637\n",
      "learning rate for this epoch =  0.13312411549080203\n",
      "Error on this batch = 0.10124510093718328\n",
      "Error on this batch = 0.13556448078161137\n",
      "Cost on val dataset after 200 epochs is = 0.13044400923401278\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.13044400923401278\n",
      "learning rate for this epoch =  0.13295739742362472\n",
      "Error on this batch = 0.10097069823729492\n",
      "Error on this batch = 0.13527118279697872\n",
      "Cost on val dataset after 201 epochs is = 0.13024487902601675\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.13024487902601675\n",
      "learning rate for this epoch =  0.13279171810193946\n",
      "Error on this batch = 0.10069833001640481\n",
      "Error on this batch = 0.1349802451764002\n",
      "Cost on val dataset after 202 epochs is = 0.13004760293822887\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.13004760293822887\n",
      "learning rate for this epoch =  0.13262706593398382\n",
      "Error on this batch = 0.10042796104371032\n",
      "Error on this batch = 0.1346916332711373\n",
      "Cost on val dataset after 203 epochs is = 0.12985215164810485\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.12985215164810485\n",
      "learning rate for this epoch =  0.13246342951392248\n",
      "Error on this batch = 0.10015955708045468\n",
      "Error on this batch = 0.1344053130812235\n",
      "Cost on val dataset after 204 epochs is = 0.1296584964641292\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.1296584964641292\n",
      "learning rate for this epoch =  0.13230079761796648\n",
      "Error on this batch = 0.09989308485266288\n",
      "Error on this batch = 0.1341212512395896\n",
      "Cost on val dataset after 205 epochs is = 0.12946660930887183\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.12946660930887183\n",
      "learning rate for this epoch =  0.13213915920059222\n",
      "Error on this batch = 0.0996285120243709\n",
      "Error on this batch = 0.1338394149967754\n",
      "Cost on val dataset after 206 epochs is = 0.1292764627025957\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.1292764627025957\n",
      "learning rate for this epoch =  0.13197850339085695\n",
      "Error on this batch = 0.09936580717135664\n",
      "Error on this batch = 0.13355977220619808\n",
      "Cost on val dataset after 207 epochs is = 0.12908802974739322\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.12908802974739322\n",
      "learning rate for this epoch =  0.1318188194888078\n",
      "Error on this batch = 0.09910493975537797\n",
      "Error on this batch = 0.13328229130994854\n",
      "Cost on val dataset after 208 epochs is = 0.12890128411183105\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.12890128411183105\n",
      "learning rate for this epoch =  0.13166009696198164\n",
      "Error on this batch = 0.09884588009892376\n",
      "Error on this batch = 0.13300694132508956\n",
      "Cost on val dataset after 209 epochs is = 0.12871620001608364\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.12871620001608364\n",
      "learning rate for this epoch =  0.1315023254419931\n",
      "Error on this batch = 0.09858859936048069\n",
      "Error on this batch = 0.13273369183042977\n",
      "Cost on val dataset after 210 epochs is = 0.12853275221753654\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.12853275221753654\n",
      "learning rate for this epoch =  0.1313454947212079\n",
      "Error on this batch = 0.09833306951031912\n",
      "Error on this batch = 0.13246251295375017\n",
      "Cost on val dataset after 211 epochs is = 0.12835091599684206\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.12835091599684206\n",
      "learning rate for this epoch =  0.13118959474949932\n",
      "Error on this batch = 0.09807926330679917\n",
      "Error on this batch = 0.13219337535946\n",
      "Cost on val dataset after 212 epochs is = 0.1281706671444096\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.1281706671444096\n",
      "learning rate for this epoch =  0.1310346156310848\n",
      "Error on this batch = 0.09782715427319721\n",
      "Error on this batch = 0.1319262502366611\n",
      "Cost on val dataset after 213 epochs is = 0.12799198194731512\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.12799198194731512\n",
      "learning rate for this epoch =  0.13088054762144102\n",
      "Error on this batch = 0.09757671667505259\n",
      "Error on this batch = 0.13166110928760041\n",
      "Cost on val dataset after 214 epochs is = 0.1278148371766134\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.1278148371766134\n",
      "learning rate for this epoch =  0.13072738112429463\n",
      "Error on this batch = 0.09732792549803293\n",
      "Error on this batch = 0.13139792471649148\n",
      "Cost on val dataset after 215 epochs is = 0.1276392100750393\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.1276392100750393\n",
      "learning rate for this epoch =  0.1305751066886864\n",
      "Error on this batch = 0.09708075642631574\n",
      "Error on this batch = 0.13113666921868744\n",
      "Cost on val dataset after 216 epochs is = 0.12746507834508247\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.12746507834508247\n",
      "learning rate for this epoch =  0.13042371500610728\n",
      "Error on this batch = 0.09683518582148332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.13087731597018853\n",
      "Cost on val dataset after 217 epochs is = 0.12729242013742334\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.12729242013742334\n",
      "learning rate for this epoch =  0.13027319690770342\n",
      "Error on this batch = 0.09659119070192762\n",
      "Error on this batch = 0.13061983861746781\n",
      "Cost on val dataset after 218 epochs is = 0.1271212140397166\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.1271212140397166\n",
      "learning rate for this epoch =  0.13012354336154894\n",
      "Error on this batch = 0.09634874872276009\n",
      "Error on this batch = 0.13036421126760067\n",
      "Cost on val dataset after 219 epochs is = 0.12695143906570966\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.12695143906570966\n",
      "learning rate for this epoch =  0.12997474546998408\n",
      "Error on this batch = 0.09610783815622219\n",
      "Error on this batch = 0.13011040847868408\n",
      "Cost on val dataset after 220 epochs is = 0.126783074644685\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.126783074644685\n",
      "learning rate for this epoch =  0.12982679446701692\n",
      "Error on this batch = 0.09586843787259092\n",
      "Error on this batch = 0.12985840525053155\n",
      "Cost on val dataset after 221 epochs is = 0.1266161006112141\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.1266161006112141\n",
      "learning rate for this epoch =  0.12967968171578698\n",
      "Error on this batch = 0.09563052732157318\n",
      "Error on this batch = 0.12960817701563232\n",
      "Cost on val dataset after 222 epochs is = 0.12645049719521248\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.12645049719521248\n",
      "learning rate for this epoch =  0.12953339870608896\n",
      "Error on this batch = 0.09539408651418356\n",
      "Error on this batch = 0.1293596996303623\n",
      "Cost on val dataset after 223 epochs is = 0.12628624501228594\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.12628624501228594\n",
      "learning rate for this epoch =  0.12938793705195484\n",
      "Error on this batch = 0.09515909600509759\n",
      "Error on this batch = 0.12911294936643633\n",
      "Cost on val dataset after 224 epochs is = 0.12612332505435664\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.12612332505435664\n",
      "learning rate for this epoch =  0.12924328848929265\n",
      "Error on this batch = 0.0949255368754746\n",
      "Error on this batch = 0.1288679029025907\n",
      "Cost on val dataset after 225 epochs is = 0.1259617186805607\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.1259617186805607\n",
      "learning rate for this epoch =  0.12909944487358055\n",
      "Error on this batch = 0.09469339071624226\n",
      "Error on this batch = 0.12862453731648657\n",
      "Cost on val dataset after 226 epochs is = 0.12580140760840744\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.12580140760840744\n",
      "learning rate for this epoch =  0.1289563981776146\n",
      "Error on this batch = 0.09446263961183533\n",
      "Error on this batch = 0.12838283007682524\n",
      "Cost on val dataset after 227 epochs is = 0.12564237390519173\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.12564237390519173\n",
      "learning rate for this epoch =  0.12881414048930848\n",
      "Error on this batch = 0.0942332661243811\n",
      "Error on this batch = 0.12814275903566624\n",
      "Cost on val dataset after 228 epochs is = 0.12548459997965034\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.12548459997965034\n",
      "learning rate for this epoch =  0.1286726640095442\n",
      "Error on this batch = 0.09400525327832307\n",
      "Error on this batch = 0.1279043024209401\n",
      "Cost on val dataset after 229 epochs is = 0.1253280685738552\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.1253280685738552\n",
      "learning rate for this epoch =  0.12853196105007209\n",
      "Error on this batch = 0.09377858454547539\n",
      "Error on this batch = 0.1276674388291488\n",
      "Cost on val dataset after 230 epochs is = 0.12517276275533457\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.12517276275533457\n",
      "learning rate for this epoch =  0.12839202403145872\n",
      "Error on this batch = 0.0935532438304994\n",
      "Error on this batch = 0.12743214721824575\n",
      "Cost on val dataset after 231 epochs is = 0.1250186659094153\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.1250186659094153\n",
      "learning rate for this epoch =  0.12825284548108173\n",
      "Error on this batch = 0.0933292154567939\n",
      "Error on this batch = 0.1271984069006892\n",
      "Cost on val dataset after 232 epochs is = 0.12486576173177905\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.12486576173177905\n",
      "learning rate for this epoch =  0.1281144180311698\n",
      "Error on this batch = 0.09310648415279106\n",
      "Error on this batch = 0.12696619753666233\n",
      "Cost on val dataset after 233 epochs is = 0.12471403422122447\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.12471403422122447\n",
      "learning rate for this epoch =  0.12797673441688712\n",
      "Error on this batch = 0.0928850350386492\n",
      "Error on this batch = 0.1267354991274543\n",
      "Cost on val dataset after 234 epochs is = 0.12456346767263037\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.12456346767263037\n",
      "learning rate for this epoch =  0.12783978747446093\n",
      "Error on this batch = 0.09266485361333433\n",
      "Error on this batch = 0.1265062920089965\n",
      "Cost on val dataset after 235 epochs is = 0.1244140466701115\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.1244140466701115\n",
      "learning rate for this epoch =  0.12770357013935066\n",
      "Error on this batch = 0.09244592574208145\n",
      "Error on this batch = 0.1262785568455481\n",
      "Cost on val dataset after 236 epochs is = 0.12426575608036242\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.12426575608036242\n",
      "learning rate for this epoch =  0.12756807544445822\n",
      "Error on this batch = 0.09222823764422751\n",
      "Error on this batch = 0.12605227462352714\n",
      "Cost on val dataset after 237 epochs is = 0.12411858104618223\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.12411858104618223\n",
      "learning rate for this epoch =  0.1274332965183777\n",
      "Error on this batch = 0.09201177588140765\n",
      "Error on this batch = 0.1258274266454808\n",
      "Cost on val dataset after 238 epochs is = 0.12397250698017531\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.12397250698017531\n",
      "learning rate for this epoch =  0.12729922658368395\n",
      "Error on this batch = 0.0917965273461056\n",
      "Error on this batch = 0.1256039945241918\n",
      "Cost on val dataset after 239 epochs is = 0.12382751955862199\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.12382751955862199\n",
      "learning rate for this epoch =  0.12716585895525878\n",
      "Error on this batch = 0.09158247925055114\n",
      "Error on this batch = 0.12538196017691555\n",
      "Cost on val dataset after 240 epochs is = 0.12368360471551414\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.12368360471551414\n",
      "learning rate for this epoch =  0.12703318703865368\n",
      "Error on this batch = 0.091369619115955\n",
      "Error on this batch = 0.12516130581974483\n",
      "Cost on val dataset after 241 epochs is = 0.12354074863675014\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.12354074863675014\n",
      "learning rate for this epoch =  0.12690120432848842\n",
      "Error on this batch = 0.09115793476207351\n",
      "Error on this batch = 0.12494201396209781\n",
      "Cost on val dataset after 242 epochs is = 0.12339893775448497\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.12339893775448497\n",
      "learning rate for this epoch =  0.12676990440688446\n",
      "Error on this batch = 0.09094741429709557\n",
      "Error on this batch = 0.12472406740132583\n",
      "Cost on val dataset after 243 epochs is = 0.12325815874162992\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.12325815874162992\n",
      "learning rate for this epoch =  0.12663928094193208\n",
      "Error on this batch = 0.0907380461078424\n",
      "Error on this batch = 0.12450744921743738\n",
      "Cost on val dataset after 244 epochs is = 0.12311839850649768\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.12311839850649768\n",
      "learning rate for this epoch =  0.12650932768619078\n",
      "Error on this batch = 0.0905298188502737\n",
      "Error on this batch = 0.12429214276793568\n",
      "Cost on val dataset after 245 epochs is = 0.12297964418758864\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.12297964418758864\n",
      "learning rate for this epoch =  0.12638003847522164\n",
      "Error on this batch = 0.09032272144029115\n",
      "Error on this batch = 0.12407813168276575\n",
      "Cost on val dataset after 246 epochs is = 0.12284188314851342\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.12284188314851342\n",
      "learning rate for this epoch =  0.1262514072261512\n",
      "Error on this batch = 0.0901167430448327\n",
      "Error on this batch = 0.12386539985936888\n",
      "Cost on val dataset after 247 epochs is = 0.12270510297304821\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.12270510297304821\n",
      "learning rate for this epoch =  0.12612342793626585\n",
      "Error on this batch = 0.08991187307324867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.12365393145784126\n",
      "Cost on val dataset after 248 epochs is = 0.12256929146031857\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.12256929146031857\n",
      "learning rate for this epoch =  0.1259960946816361\n",
      "Error on this batch = 0.08970810116895392\n",
      "Error on this batch = 0.12344371089619412\n",
      "Cost on val dataset after 249 epochs is = 0.12243443662010801\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.12243443662010801\n",
      "learning rate for this epoch =  0.12586940161576976\n",
      "Error on this batch = 0.08950541720134719\n",
      "Error on this batch = 0.12323472284571314\n",
      "Cost on val dataset after 250 epochs is = 0.12230052666828745\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.12230052666828745\n",
      "learning rate for this epoch =  0.12574334296829354\n",
      "Error on this batch = 0.08930381125799147\n",
      "Error on this batch = 0.12302695222641424\n",
      "Cost on val dataset after 251 epochs is = 0.12216755002236222\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.12216755002236222\n",
      "learning rate for this epoch =  0.1256179130436622\n",
      "Error on this batch = 0.08910327363704805\n",
      "Error on this batch = 0.1228203842025934\n",
      "Cost on val dataset after 252 epochs is = 0.12203549529713312\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.12203549529713312\n",
      "learning rate for this epoch =  0.12549310621989482\n",
      "Error on this batch = 0.08890379483995708\n",
      "Error on this batch = 0.12261500417846896\n",
      "Cost on val dataset after 253 epochs is = 0.121904351300468\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.121904351300468\n",
      "learning rate for this epoch =  0.125368916947337\n",
      "Error on this batch = 0.08870536556435847\n",
      "Error on this batch = 0.1224107977939132\n",
      "Cost on val dataset after 254 epochs is = 0.1217741070291806\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.1217741070291806\n",
      "learning rate for this epoch =  0.12524533974744914\n",
      "Error on this batch = 0.08850797669724603\n",
      "Error on this batch = 0.12220775092027182\n",
      "Cost on val dataset after 255 epochs is = 0.12164475166501436\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.12164475166501436\n",
      "learning rate for this epoch =  0.12512236921161915\n",
      "Error on this batch = 0.08831161930834858\n",
      "Error on this batch = 0.12200584965626923\n",
      "Cost on val dataset after 256 epochs is = 0.12151627457072683\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.12151627457072683\n",
      "learning rate for this epoch =  0.125\n",
      "Error on this batch = 0.08811628464373181\n",
      "Error on this batch = 0.12180508032399726\n",
      "Cost on val dataset after 257 epochs is = 0.12138866528627282\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.12138866528627282\n",
      "learning rate for this epoch =  0.12487822684037092\n",
      "Error on this batch = 0.08792196411961445\n",
      "Error on this batch = 0.12160542946498605\n",
      "Cost on val dataset after 258 epochs is = 0.12126191352508314\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.12126191352508314\n",
      "learning rate for this epoch =  0.12475704452702165\n",
      "Error on this batch = 0.08772864931639311\n",
      "Error on this batch = 0.12140688383635485\n",
      "Cost on val dataset after 259 epochs is = 0.1211360091704362\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.1211360091704362\n",
      "learning rate for this epoch =  0.12463644791965951\n",
      "Error on this batch = 0.08753633197286956\n",
      "Error on this batch = 0.12120943040704102\n",
      "Cost on val dataset after 260 epochs is = 0.12101094227191987\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.12101094227191987\n",
      "learning rate for this epoch =  0.12451643194233865\n",
      "Error on this batch = 0.0873450039806746\n",
      "Error on this batch = 0.12101305635410567\n",
      "Cost on val dataset after 261 epochs is = 0.12088670304198106\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.12088670304198106\n",
      "learning rate for this epoch =  0.12439699158241055\n",
      "Error on this batch = 0.08715465737888405\n",
      "Error on this batch = 0.12081774905911437\n",
      "Cost on val dataset after 262 epochs is = 0.12076328185256037\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.12076328185256037\n",
      "learning rate for this epoch =  0.12427812188949586\n",
      "Error on this batch = 0.08696528434881927\n",
      "Error on this batch = 0.1206234961045908\n",
      "Cost on val dataset after 263 epochs is = 0.12064066923180998\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.12064066923180998\n",
      "learning rate for this epoch =  0.1241598179744767\n",
      "Error on this batch = 0.08677687720902924\n",
      "Error on this batch = 0.12043028527054254\n",
      "Cost on val dataset after 264 epochs is = 0.12051885586089177\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.12051885586089177\n",
      "learning rate for this epoch =  0.12404207500850907\n",
      "Error on this batch = 0.08658942841044724\n",
      "Error on this batch = 0.12023810453105682\n",
      "Cost on val dataset after 265 epochs is = 0.12039783257085376\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.12039783257085376\n",
      "learning rate for this epoch =  0.12392488822205483\n",
      "Error on this batch = 0.08640293053171803\n",
      "Error on this batch = 0.12004694205096485\n",
      "Cost on val dataset after 266 epochs is = 0.12027759033958312\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.12027759033958312\n",
      "learning rate for this epoch =  0.12380825290393263\n",
      "Error on this batch = 0.0862173762746903\n",
      "Error on this batch = 0.11985678618257381\n",
      "Cost on val dataset after 267 epochs is = 0.12015812028883262\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.12015812028883262\n",
      "learning rate for this epoch =  0.12369216440038802\n",
      "Error on this batch = 0.08603275846006941\n",
      "Error on this batch = 0.1196676254624644\n",
      "Cost on val dataset after 268 epochs is = 0.1200394136813196\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.1200394136813196\n",
      "learning rate for this epoch =  0.1235766181141811\n",
      "Error on this batch = 0.08584907002322664\n",
      "Error on this batch = 0.11947944860835286\n",
      "Cost on val dataset after 269 epochs is = 0.11992146191789484\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.11992146191789484\n",
      "learning rate for this epoch =  0.12346160950369273\n",
      "Error on this batch = 0.08566630401015847\n",
      "Error on this batch = 0.1192922445160162\n",
      "Cost on val dataset after 270 epochs is = 0.11980425653477957\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.11980425653477957\n",
      "learning rate for this epoch =  0.12334713408204756\n",
      "Error on this batch = 0.08548445357359395\n",
      "Error on this batch = 0.11910600225627899\n",
      "Cost on val dataset after 271 epochs is = 0.1196877892008687\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.1196877892008687\n",
      "learning rate for this epoch =  0.12323318741625437\n",
      "Error on this batch = 0.08530351196924403\n",
      "Error on this batch = 0.11892071107206122\n",
      "Cost on val dataset after 272 epochs is = 0.11957205171509877\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.11957205171509877\n",
      "learning rate for this epoch =  0.12311976512636309\n",
      "Error on this batch = 0.08512347255218906\n",
      "Error on this batch = 0.11873636037548431\n",
      "Cost on val dataset after 273 epochs is = 0.1194570360038785\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.1194570360038785\n",
      "learning rate for this epoch =  0.12300686288463769\n",
      "Error on this batch = 0.08494432877340084\n",
      "Error on this batch = 0.11855293974503639\n",
      "Cost on val dataset after 274 epochs is = 0.11934273411858044\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.11934273411858044\n",
      "learning rate for this epoch =  0.12289447641474543\n",
      "Error on this batch = 0.08476607417639474\n",
      "Error on this batch = 0.1183704389227933\n",
      "Cost on val dataset after 275 epochs is = 0.11922913823309221\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.11922913823309221\n",
      "learning rate for this epoch =  0.12278260149096118\n",
      "Error on this batch = 0.08458870239400831\n",
      "Error on this batch = 0.1181888478116957\n",
      "Cost on val dataset after 276 epochs is = 0.11911624064142529\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.11911624064142529\n",
      "learning rate for this epoch =  0.12267123393738709\n",
      "Error on this batch = 0.08441220714530216\n",
      "Error on this batch = 0.11800815647288043\n",
      "Cost on val dataset after 277 epochs is = 0.11900403375538036\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.11900403375538036\n",
      "learning rate for this epoch =  0.12256036962718717\n",
      "Error on this batch = 0.08423658223258017\n",
      "Error on this batch = 0.1178283551230653\n",
      "Cost on val dataset after 278 epochs is = 0.11889251010226755\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.11889251010226755\n",
      "learning rate for this epoch =  0.12245000448183609\n",
      "Error on this batch = 0.08406182153852441\n",
      "Error on this batch = 0.11764943413198588\n",
      "Cost on val dataset after 279 epochs is = 0.1187816623226796\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.1187816623226796\n",
      "learning rate for this epoch =  0.12234013447038239\n",
      "Error on this batch = 0.08388791902344261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11747138401988325\n",
      "Cost on val dataset after 280 epochs is = 0.11867148316831756\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.11867148316831756\n",
      "learning rate for this epoch =  0.12223075560872526\n",
      "Error on this batch = 0.08371486872262317\n",
      "Error on this batch = 0.11729419545504213\n",
      "Cost on val dataset after 281 epochs is = 0.11856196549986651\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.11856196549986651\n",
      "learning rate for this epoch =  0.12212186395890517\n",
      "Error on this batch = 0.08354266474379603\n",
      "Error on this batch = 0.11711785925137758\n",
      "Cost on val dataset after 282 epochs is = 0.11845310228492097\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.11845310228492097\n",
      "learning rate for this epoch =  0.12201345562840739\n",
      "Error on this batch = 0.0833713012646946\n",
      "Error on this batch = 0.11694236636606978\n",
      "Cost on val dataset after 283 epochs is = 0.11834488659595803\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.11834488659595803\n",
      "learning rate for this epoch =  0.12190552676947876\n",
      "Error on this batch = 0.08320077253071702\n",
      "Error on this batch = 0.11676770789724569\n",
      "Cost on val dataset after 284 epochs is = 0.11823731160835714\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.11823731160835714\n",
      "learning rate for this epoch =  0.12179807357845675\n",
      "Error on this batch = 0.08303107285268262\n",
      "Error on this batch = 0.11659387508170671\n",
      "Cost on val dataset after 285 epochs is = 0.11813037059846573\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.11813037059846573\n",
      "learning rate for this epoch =  0.12169109229511134\n",
      "Error on this batch = 0.08286219660468107\n",
      "Error on this batch = 0.1164208592927011\n",
      "Cost on val dataset after 286 epochs is = 0.11802405694170864\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.11802405694170864\n",
      "learning rate for this epoch =  0.12158457920199858\n",
      "Error on this batch = 0.08269413822201106\n",
      "Error on this batch = 0.11624865203774049\n",
      "Cost on val dataset after 287 epochs is = 0.11791836411074118\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.11791836411074118\n",
      "learning rate for this epoch =  0.1214785306238262\n",
      "Error on this batch = 0.08252689219920614\n",
      "Error on this batch = 0.11607724495645957\n",
      "Cost on val dataset after 288 epochs is = 0.11781328567364395\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.11781328567364395\n",
      "learning rate for this epoch =  0.12137294292683086\n",
      "Error on this batch = 0.08236045308814399\n",
      "Error on this batch = 0.11590662981851788\n",
      "Cost on val dataset after 289 epochs is = 0.11770881529215864\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.11770881529215864\n",
      "learning rate for this epoch =  0.12126781251816648\n",
      "Error on this batch = 0.08219481549623762\n",
      "Error on this batch = 0.1157367985215426\n",
      "Cost on val dataset after 290 epochs is = 0.117604946719964\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.117604946719964\n",
      "learning rate for this epoch =  0.121163135845304\n",
      "Error on this batch = 0.08202997408470473\n",
      "Error on this batch = 0.11556774308911223\n",
      "Cost on val dataset after 291 epochs is = 0.11750167380099028\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.11750167380099028\n",
      "learning rate for this epoch =  0.12105890939544156\n",
      "Error on this batch = 0.08186592356691329\n",
      "Error on this batch = 0.11539945566877925\n",
      "Cost on val dataset after 292 epochs is = 0.11739899046777208\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.11739899046777208\n",
      "learning rate for this epoch =  0.1209551296949258\n",
      "Error on this batch = 0.08170265870680064\n",
      "Error on this batch = 0.11523192853013192\n",
      "Cost on val dataset after 293 epochs is = 0.11729689073983766\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.11729689073983766\n",
      "learning rate for this epoch =  0.12085179330868305\n",
      "Error on this batch = 0.08154017431736386\n",
      "Error on this batch = 0.11506515406289364\n",
      "Cost on val dataset after 294 epochs is = 0.11719536872213468\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.11719536872213468\n",
      "learning rate for this epoch =  0.12074889683966107\n",
      "Error on this batch = 0.08137846525921823\n",
      "Error on this batch = 0.11489912477505929\n",
      "Cost on val dataset after 295 epochs is = 0.11709441860349067\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.11709441860349067\n",
      "learning rate for this epoch =  0.12064643692828043\n",
      "Error on this batch = 0.08121752643922271\n",
      "Error on this batch = 0.11473383329106834\n",
      "Cost on val dataset after 296 epochs is = 0.11699403465510812\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.11699403465510812\n",
      "learning rate for this epoch =  0.120544410251896\n",
      "Error on this batch = 0.08105735280916887\n",
      "Error on this batch = 0.11456927235001266\n",
      "Cost on val dataset after 297 epochs is = 0.11689421122909249\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.11689421122909249\n",
      "learning rate for this epoch =  0.12044281352426756\n",
      "Error on this batch = 0.08089793936453196\n",
      "Error on this batch = 0.11440543480387959\n",
      "Cost on val dataset after 298 epochs is = 0.1167949427570132\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.1167949427570132\n",
      "learning rate for this epoch =  0.12034164349504001\n",
      "Error on this batch = 0.08073928114328133\n",
      "Error on this batch = 0.11424231361582879\n",
      "Cost on val dataset after 299 epochs is = 0.11669622374849617\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.11669622374849617\n",
      "learning rate for this epoch =  0.12024089694923273\n",
      "Error on this batch = 0.0805813732247485\n",
      "Error on this batch = 0.11407990185850203\n",
      "Cost on val dataset after 300 epochs is = 0.1165980487898471\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.1165980487898471\n",
      "learning rate for this epoch =  0.12014057070673773\n",
      "Error on this batch = 0.08042421072855045\n",
      "Error on this batch = 0.113918192712366\n",
      "Cost on val dataset after 301 epochs is = 0.11650041254270548\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.11650041254270548\n",
      "learning rate for this epoch =  0.1200406616218266\n",
      "Error on this batch = 0.08026778881356667\n",
      "Error on this batch = 0.11375717946408631\n",
      "Cost on val dataset after 302 epochs is = 0.11640330974272747\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.11640330974272747\n",
      "learning rate for this epoch =  0.11994116658266626\n",
      "Error on this batch = 0.08011210267696688\n",
      "Error on this batch = 0.11359685550493281\n",
      "Cost on val dataset after 303 epochs is = 0.11630673519829803\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.11630673519829803\n",
      "learning rate for this epoch =  0.1198420825108428\n",
      "Error on this batch = 0.07995714755328914\n",
      "Error on this batch = 0.11343721432921537\n",
      "Cost on val dataset after 304 epochs is = 0.11621068378927069\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.11621068378927069\n",
      "learning rate for this epoch =  0.11974340636089367\n",
      "Error on this batch = 0.07980291871356468\n",
      "Error on this batch = 0.11327824953274894\n",
      "Cost on val dataset after 305 epochs is = 0.11611515046573496\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.11611515046573496\n",
      "learning rate for this epoch =  0.11964513511984808\n",
      "Error on this batch = 0.0796494114644891\n",
      "Error on this batch = 0.11311995481134808\n",
      "Cost on val dataset after 306 epochs is = 0.11602013024681049\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.11602013024681049\n",
      "learning rate for this epoch =  0.11954726580677509\n",
      "Error on this batch = 0.07949662114763709\n",
      "Error on this batch = 0.1129623239593495\n",
      "Cost on val dataset after 307 epochs is = 0.1159256182194671\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.1159256182194671\n",
      "learning rate for this epoch =  0.11944979547233951\n",
      "Error on this batch = 0.07934454313871991\n",
      "Error on this batch = 0.11280535086816258\n",
      "Cost on val dataset after 308 epochs is = 0.11583160953737046\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.11583160953737046\n",
      "learning rate for this epoch =  0.1193527211983654\n",
      "Error on this batch = 0.07919317284688278\n",
      "Error on this batch = 0.11264902952484648\n",
      "Cost on val dataset after 309 epochs is = 0.1157380994197526\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.1157380994197526\n",
      "learning rate for this epoch =  0.11925604009740705\n",
      "Error on this batch = 0.07904250571404176\n",
      "Error on this batch = 0.1124933540107142\n",
      "Cost on val dataset after 310 epochs is = 0.11564508315030667\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.11564508315030667\n",
      "learning rate for this epoch =  0.11915974931232703\n",
      "Error on this batch = 0.07889253721425739\n",
      "Error on this batch = 0.11233831849996215\n",
      "Cost on val dataset after 311 epochs is = 0.11555255607610555\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.11555255607610555\n",
      "learning rate for this epoch =  0.1190638460158816\n",
      "Error on this batch = 0.07874326285314445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11218391725832491\n",
      "Cost on val dataset after 312 epochs is = 0.11546051360654346\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.11546051360654346\n",
      "learning rate for this epoch =  0.11896832741031306\n",
      "Error on this batch = 0.07859467816731569\n",
      "Error on this batch = 0.11203014464175459\n",
      "Cost on val dataset after 313 epochs is = 0.11536895121230037\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.11536895121230037\n",
      "learning rate for this epoch =  0.11887319072694875\n",
      "Error on this batch = 0.07844677872385844\n",
      "Error on this batch = 0.11187699509512429\n",
      "Cost on val dataset after 314 epochs is = 0.11527786442432844\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.11527786442432844\n",
      "learning rate for this epoch =  0.11877843322580707\n",
      "Error on this batch = 0.07829956011984222\n",
      "Error on this batch = 0.11172446315095468\n",
      "Cost on val dataset after 315 epochs is = 0.1151872488328602\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.1151872488328602\n",
      "learning rate for this epoch =  0.11868405219520976\n",
      "Error on this batch = 0.07815301798185677\n",
      "Error on this batch = 0.1115725434281637\n",
      "Cost on val dataset after 316 epochs is = 0.11509710008643759\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.11509710008643759\n",
      "learning rate for this epoch =  0.11859004495140096\n",
      "Error on this batch = 0.07800714796557788\n",
      "Error on this batch = 0.11142123063083831\n",
      "Cost on val dataset after 317 epochs is = 0.11500741389096213\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.11500741389096213\n",
      "learning rate for this epoch =  0.11849640883817222\n",
      "Error on this batch = 0.07786194575536116\n",
      "Error on this batch = 0.11127051954702794\n",
      "Cost on val dataset after 318 epochs is = 0.11491818600876473\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.11491818600876473\n",
      "learning rate for this epoch =  0.11840314122649412\n",
      "Error on this batch = 0.07771740706386124\n",
      "Error on this batch = 0.1111204050475589\n",
      "Cost on val dataset after 319 epochs is = 0.11482941225769569\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.11482941225769569\n",
      "learning rate for this epoch =  0.11831023951415345\n",
      "Error on this batch = 0.07757352763167594\n",
      "Error on this batch = 0.11097088208486973\n",
      "Cost on val dataset after 320 epochs is = 0.11474108851023371\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.11474108851023371\n",
      "learning rate for this epoch =  0.11821770112539698\n",
      "Error on this batch = 0.0774303032270139\n",
      "Error on this batch = 0.11082194569186612\n",
      "Cost on val dataset after 321 epochs is = 0.114653210692614\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.114653210692614\n",
      "learning rate for this epoch =  0.11812552351058042\n",
      "Error on this batch = 0.0772877296453843\n",
      "Error on this batch = 0.11067359098079557\n",
      "Cost on val dataset after 322 epochs is = 0.11456577478397462\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.11456577478397462\n",
      "learning rate for this epoch =  0.11803370414582362\n",
      "Error on this batch = 0.07714580270930813\n",
      "Error on this batch = 0.11052581314214083\n",
      "Cost on val dataset after 323 epochs is = 0.11447877681552106\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.11447877681552106\n",
      "learning rate for this epoch =  0.11794224053267104\n",
      "Error on this batch = 0.07700451826804938\n",
      "Error on this batch = 0.11037860744353176\n",
      "Cost on val dataset after 324 epochs is = 0.11439221286970841\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.11439221286970841\n",
      "learning rate for this epoch =  0.11785113019775793\n",
      "Error on this batch = 0.07686387219736533\n",
      "Error on this batch = 0.11023196922867523\n",
      "Cost on val dataset after 325 epochs is = 0.11430607907944078\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.11430607907944078\n",
      "learning rate for this epoch =  0.11776037069248181\n",
      "Error on this batch = 0.07672386039927483\n",
      "Error on this batch = 0.1100858939163023\n",
      "Cost on val dataset after 326 epochs is = 0.1142203716272876\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.1142203716272876\n",
      "learning rate for this epoch =  0.11766995959267931\n",
      "Error on this batch = 0.07658447880184359\n",
      "Error on this batch = 0.10994037699913206\n",
      "Cost on val dataset after 327 epochs is = 0.11413508674471655\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.11413508674471655\n",
      "learning rate for this epoch =  0.11757989449830816\n",
      "Error on this batch = 0.0764457233589857\n",
      "Error on this batch = 0.10979541404285215\n",
      "Cost on val dataset after 328 epochs is = 0.11405022071134265\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.11405022071134265\n",
      "learning rate for this epoch =  0.11749017303313421\n",
      "Error on this batch = 0.0763075900502802\n",
      "Error on this batch = 0.10965100068511503\n",
      "Cost on val dataset after 329 epochs is = 0.11396576985419285\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.11396576985419285\n",
      "learning rate for this epoch =  0.11740079284442367\n",
      "Error on this batch = 0.07617007488080192\n",
      "Error on this batch = 0.10950713263454954\n",
      "Cost on val dataset after 330 epochs is = 0.11388173054698676\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.11388173054698676\n",
      "learning rate for this epoch =  0.11731175160264\n",
      "Error on this batch = 0.07603317388096563\n",
      "Error on this batch = 0.10936380566978755\n",
      "Cost on val dataset after 331 epochs is = 0.1137980992094319\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.1137980992094319\n",
      "learning rate for this epoch =  0.11722304700114572\n",
      "Error on this batch = 0.07589688310638301\n",
      "Error on this batch = 0.10922101563850489\n",
      "Cost on val dataset after 332 epochs is = 0.113714872306534\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.113714872306534\n",
      "learning rate for this epoch =  0.11713467675590904\n",
      "Error on this batch = 0.07576119863773126\n",
      "Error on this batch = 0.10907875845647647\n",
      "Cost on val dataset after 333 epochs is = 0.11363204634792186\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.11363204634792186\n",
      "learning rate for this epoch =  0.11704663860521486\n",
      "Error on this batch = 0.07562611658063248\n",
      "Error on this batch = 0.10893703010664446\n",
      "Cost on val dataset after 334 epochs is = 0.11354961788718637\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.11354961788718637\n",
      "learning rate for this epoch =  0.1169589303093807\n",
      "Error on this batch = 0.07549163306554382\n",
      "Error on this batch = 0.10879582663820024\n",
      "Cost on val dataset after 335 epochs is = 0.11346758352123341\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.11346758352123341\n",
      "learning rate for this epoch =  0.11687154965047665\n",
      "Error on this batch = 0.0753577442476567\n",
      "Error on this batch = 0.10865514416567827\n",
      "Cost on val dataset after 336 epochs is = 0.11338593988965018\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.11338593988965018\n",
      "learning rate for this epoch =  0.11678449443205002\n",
      "Error on this batch = 0.07522444630680501\n",
      "Error on this batch = 0.10851497886806272\n",
      "Cost on val dataset after 337 epochs is = 0.11330468367408511\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.11330468367408511\n",
      "learning rate for this epoch =  0.11669776247885426\n",
      "Error on this batch = 0.07509173544738174\n",
      "Error on this batch = 0.10837532698790542\n",
      "Cost on val dataset after 338 epochs is = 0.11322381159764051\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.11322381159764051\n",
      "learning rate for this epoch =  0.1166113516365818\n",
      "Error on this batch = 0.07495960789826278\n",
      "Error on this batch = 0.1082361848304556\n",
      "Cost on val dataset after 339 epochs is = 0.11314332042427808\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.11314332042427808\n",
      "learning rate for this epoch =  0.1165252597716015\n",
      "Error on this batch = 0.07482805991273794\n",
      "Error on this batch = 0.10809754876280016\n",
      "Cost on val dataset after 340 epochs is = 0.11306320695823673\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.11306320695823673\n",
      "learning rate for this epoch =  0.11643948477069971\n",
      "Error on this batch = 0.07469708776844815\n",
      "Error on this batch = 0.10795941521301479\n",
      "Cost on val dataset after 341 epochs is = 0.11298346804346276\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.11298346804346276\n",
      "learning rate for this epoch =  0.11635402454082565\n",
      "Error on this batch = 0.07456668776732854\n",
      "Error on this batch = 0.1078217806693251\n",
      "Cost on val dataset after 342 epochs is = 0.11290410056305177\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.11290410056305177\n",
      "learning rate for this epoch =  0.1162688770088405\n",
      "Error on this batch = 0.07443685623555676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1076846416792776\n",
      "Cost on val dataset after 343 epochs is = 0.11282510143870231\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.11282510143870231\n",
      "learning rate for this epoch =  0.11618404012127041\n",
      "Error on this batch = 0.07430758952350607\n",
      "Error on this batch = 0.10754799484892004\n",
      "Cost on val dataset after 344 epochs is = 0.11274646763018073\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.11274646763018073\n",
      "learning rate for this epoch =  0.11609951184406334\n",
      "Error on this batch = 0.07417888400570234\n",
      "Error on this batch = 0.10741183684199085\n",
      "Cost on val dataset after 345 epochs is = 0.11266819613479744\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.11266819613479744\n",
      "learning rate for this epoch =  0.11601529016234945\n",
      "Error on this batch = 0.07405073608078525\n",
      "Error on this batch = 0.10727616437911706\n",
      "Cost on val dataset after 346 epochs is = 0.11259028398689384\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.11259028398689384\n",
      "learning rate for this epoch =  0.11593137308020533\n",
      "Error on this batch = 0.0739231421714726\n",
      "Error on this batch = 0.10714097423702092\n",
      "Cost on val dataset after 347 epochs is = 0.11251272825733986\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.11251272825733986\n",
      "learning rate for this epoch =  0.11584775862042163\n",
      "Error on this batch = 0.07379609872452723\n",
      "Error on this batch = 0.10700626324773428\n",
      "Cost on val dataset after 348 epochs is = 0.11243552605304187\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.11243552605304187\n",
      "learning rate for this epoch =  0.11576444482427425\n",
      "Error on this batch = 0.07366960221072684\n",
      "Error on this batch = 0.1068720282978207\n",
      "Cost on val dataset after 349 epochs is = 0.11235867451646099\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.11235867451646099\n",
      "learning rate for this epoch =  0.11568142975129903\n",
      "Error on this batch = 0.07354364912483545\n",
      "Error on this batch = 0.10673826632760496\n",
      "Cost on val dataset after 350 epochs is = 0.11228217082514091\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.11228217082514091\n",
      "learning rate for this epoch =  0.11559871147906978\n",
      "Error on this batch = 0.07341823598557681\n",
      "Error on this batch = 0.10660497433040966\n",
      "Cost on val dataset after 351 epochs is = 0.11220601219124576\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.11220601219124576\n",
      "learning rate for this epoch =  0.11551628810297963\n",
      "Error on this batch = 0.0732933593356088\n",
      "Error on this batch = 0.1064721493517985\n",
      "Cost on val dataset after 352 epochs is = 0.11213019586110705\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.11213019586110705\n",
      "learning rate for this epoch =  0.11543415773602565\n",
      "Error on this batch = 0.07316901574149914\n",
      "Error on this batch = 0.10633978848882628\n",
      "Cost on val dataset after 353 epochs is = 0.11205471911478018\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.11205471911478018\n",
      "learning rate for this epoch =  0.11535231850859669\n",
      "Error on this batch = 0.07304520179370154\n",
      "Error on this batch = 0.10620788888929479\n",
      "Cost on val dataset after 354 epochs is = 0.11197957926560959\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.11197957926560959\n",
      "learning rate for this epoch =  0.11527076856826429\n",
      "Error on this batch = 0.07292191410653207\n",
      "Error on this batch = 0.10607644775101506\n",
      "Cost on val dataset after 355 epochs is = 0.11190477365980316\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.11190477365980316\n",
      "learning rate for this epoch =  0.1151895060795769\n",
      "Error on this batch = 0.07279914931814563\n",
      "Error on this batch = 0.10594546232107505\n",
      "Cost on val dataset after 356 epochs is = 0.1118302996760145\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.1118302996760145\n",
      "learning rate for this epoch =  0.11510852922385682\n",
      "Error on this batch = 0.07267690409051249\n",
      "Error on this batch = 0.10581492989511279\n",
      "Cost on val dataset after 357 epochs is = 0.11175615472493422\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.11175615472493422\n",
      "learning rate for this epoch =  0.11502783619900045\n",
      "Error on this batch = 0.07255517510939356\n",
      "Error on this batch = 0.10568484781659511\n",
      "Cost on val dataset after 358 epochs is = 0.11168233624888896\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.11168233624888896\n",
      "learning rate for this epoch =  0.11494742521928122\n",
      "Error on this batch = 0.07243395908431569\n",
      "Error on this batch = 0.10555521347610086\n",
      "Cost on val dataset after 359 epochs is = 0.11160884172144837\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.11160884172144837\n",
      "learning rate for this epoch =  0.11486729451515557\n",
      "Error on this batch = 0.07231325274854541\n",
      "Error on this batch = 0.10542602431060961\n",
      "Cost on val dataset after 360 epochs is = 0.1115356686470399\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.1115356686470399\n",
      "learning rate for this epoch =  0.11478744233307164\n",
      "Error on this batch = 0.07219305285906172\n",
      "Error on this batch = 0.10529727780279441\n",
      "Cost on val dataset after 361 epochs is = 0.11146281456057107\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.11146281456057107\n",
      "learning rate for this epoch =  0.11470786693528087\n",
      "Error on this batch = 0.07207335619652713\n",
      "Error on this batch = 0.10516897148031934\n",
      "Cost on val dataset after 362 epochs is = 0.1113902770270589\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.1113902770270589\n",
      "learning rate for this epoch =  0.11462856659965227\n",
      "Error on this batch = 0.07195415956525761\n",
      "Error on this batch = 0.1050411029151413\n",
      "Cost on val dataset after 363 epochs is = 0.11131805364126655\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.11131805364126655\n",
      "learning rate for this epoch =  0.11454953961948931\n",
      "Error on this batch = 0.07183545979319\n",
      "Error on this batch = 0.10491366972281566\n",
      "Cost on val dataset after 364 epochs is = 0.11124614202734706\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.11124614202734706\n",
      "learning rate for this epoch =  0.11447078430334955\n",
      "Error on this batch = 0.07171725373184812\n",
      "Error on this batch = 0.10478666956180639\n",
      "Cost on val dataset after 365 epochs is = 0.11117453983849312\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.11117453983849312\n",
      "learning rate for this epoch =  0.11439229897486693\n",
      "Error on this batch = 0.07159953825630609\n",
      "Error on this batch = 0.10466010013279937\n",
      "Cost on val dataset after 366 epochs is = 0.11110324475659436\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.11110324475659436\n",
      "learning rate for this epoch =  0.11431408197257639\n",
      "Error on this batch = 0.07148231026515\n",
      "Error on this batch = 0.1045339591780201\n",
      "Cost on val dataset after 367 epochs is = 0.1110322544918999\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.1110322544918999\n",
      "learning rate for this epoch =  0.11423613164974125\n",
      "Error on this batch = 0.0713655666804365\n",
      "Error on this batch = 0.10440824448055441\n",
      "Cost on val dataset after 368 epochs is = 0.11096156678268784\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.11096156678268784\n",
      "learning rate for this epoch =  0.11415844637418282\n",
      "Error on this batch = 0.07124930444764932\n",
      "Error on this batch = 0.1042829538636729\n",
      "Cost on val dataset after 369 epochs is = 0.11089117939494025\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.11089117939494025\n",
      "learning rate for this epoch =  0.11408102452811265\n",
      "Error on this batch = 0.07113352053565289\n",
      "Error on this batch = 0.10415808519015883\n",
      "Cost on val dataset after 370 epochs is = 0.11082109012202401\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.11082109012202401\n",
      "learning rate for this epoch =  0.11400386450796704\n",
      "Error on this batch = 0.07101821193664326\n",
      "Error on this batch = 0.1040336363616392\n",
      "Cost on val dataset after 371 epochs is = 0.11075129678437728\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.11075129678437728\n",
      "learning rate for this epoch =  0.11392696472424395\n",
      "Error on this batch = 0.07090337566609606\n",
      "Error on this batch = 0.10390960531791915\n",
      "Cost on val dataset after 372 epochs is = 0.11068179722920125\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.11068179722920125\n",
      "learning rate for this epoch =  0.11385032360134212\n",
      "Error on this batch = 0.07078900876271164\n",
      "Error on this batch = 0.10378599003631914\n",
      "Cost on val dataset after 373 epochs is = 0.11061258933015734\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.11061258933015734\n",
      "learning rate for this epoch =  0.11377393957740255\n",
      "Error on this batch = 0.07067510828835719\n",
      "Error on this batch = 0.10366278853101597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 374 epochs is = 0.11054367098706898\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.11054367098706898\n",
      "learning rate for this epoch =  0.11369781110415222\n",
      "Error on this batch = 0.07056167132800545\n",
      "Error on this batch = 0.10353999885238611\n",
      "Cost on val dataset after 375 epochs is = 0.11047504012562868\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.11047504012562868\n",
      "learning rate for this epoch =  0.11362193664674994\n",
      "Error on this batch = 0.07044869498967085\n",
      "Error on this batch = 0.10341761908635239\n",
      "Cost on val dataset after 376 epochs is = 0.11040669469710965\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.11040669469710965\n",
      "learning rate for this epoch =  0.11354631468363437\n",
      "Error on this batch = 0.070336176404342\n",
      "Error on this batch = 0.10329564735373375\n",
      "Cost on val dataset after 377 epochs is = 0.11033863267808183\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.11033863267808183\n",
      "learning rate for this epoch =  0.1134709437063741\n",
      "Error on this batch = 0.07022411272591116\n",
      "Error on this batch = 0.10317408180959783\n",
      "Cost on val dataset after 378 epochs is = 0.11027085207013229\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.11027085207013229\n",
      "learning rate for this epoch =  0.11339582221952002\n",
      "Error on this batch = 0.07011250113110042\n",
      "Error on this batch = 0.10305292064261642\n",
      "Cost on val dataset after 379 epochs is = 0.11020335089959002\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.11020335089959002\n",
      "learning rate for this epoch =  0.11332094874045952\n",
      "Error on this batch = 0.07000133881938457\n",
      "Error on this batch = 0.10293216207442427\n",
      "Cost on val dataset after 380 epochs is = 0.11013612721725441\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.11013612721725441\n",
      "learning rate for this epoch =  0.1132463217992727\n",
      "Error on this batch = 0.06989062301291092\n",
      "Error on this batch = 0.1028118043589803\n",
      "Cost on val dataset after 381 epochs is = 0.11006917909812773\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.11006917909812773\n",
      "learning rate for this epoch =  0.11317193993859079\n",
      "Error on this batch = 0.06978035095641541\n",
      "Error on this batch = 0.10269184578193226\n",
      "Cost on val dataset after 382 epochs is = 0.11000250464115154\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.11000250464115154\n",
      "learning rate for this epoch =  0.11309780171345626\n",
      "Error on this batch = 0.06967051991713596\n",
      "Error on this batch = 0.10257228465998437\n",
      "Cost on val dataset after 383 epochs is = 0.1099361019689461\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.1099361019689461\n",
      "learning rate for this epoch =  0.11302390569118509\n",
      "Error on this batch = 0.06956112718472204\n",
      "Error on this batch = 0.10245311934026763\n",
      "Cost on val dataset after 384 epochs is = 0.10986996922755377\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.10986996922755377\n",
      "learning rate for this epoch =  0.11295025045123061\n",
      "Error on this batch = 0.06945217007114142\n",
      "Error on this batch = 0.10233434819971363\n",
      "Cost on val dataset after 385 epochs is = 0.1098041045861851\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.1098041045861851\n",
      "learning rate for this epoch =  0.11287683458504956\n",
      "Error on this batch = 0.0693436459105835\n",
      "Error on this batch = 0.10221596964443119\n",
      "Cost on val dataset after 386 epochs is = 0.10973850623696844\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.10973850623696844\n",
      "learning rate for this epoch =  0.11280365669596971\n",
      "Error on this batch = 0.06923555205935947\n",
      "Error on this batch = 0.1020979821090865\n",
      "Cost on val dataset after 387 epochs is = 0.10967317239470213\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.10967317239470213\n",
      "learning rate for this epoch =  0.11273071539905938\n",
      "Error on this batch = 0.06912788589579917\n",
      "Error on this batch = 0.10198038405628605\n",
      "Cost on val dataset after 388 epochs is = 0.10960810129660985\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.10960810129660985\n",
      "learning rate for this epoch =  0.11265800932099873\n",
      "Error on this batch = 0.06902064482014517\n",
      "Error on this batch = 0.10186317397596341\n",
      "Cost on val dataset after 389 epochs is = 0.1095432912020982\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.1095432912020982\n",
      "learning rate for this epoch =  0.11258553709995278\n",
      "Error on this batch = 0.06891382625444352\n",
      "Error on this batch = 0.10174635038476874\n",
      "Cost on val dataset after 390 epochs is = 0.10947874039251715\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.10947874039251715\n",
      "learning rate for this epoch =  0.11251329738544609\n",
      "Error on this batch = 0.06880742764243147\n",
      "Error on this batch = 0.10162991182546229\n",
      "Cost on val dataset after 391 epochs is = 0.10941444717092269\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.10941444717092269\n",
      "learning rate for this epoch =  0.11244128883823923\n",
      "Error on this batch = 0.0687014464494225\n",
      "Error on this batch = 0.10151385686631137\n",
      "Cost on val dataset after 392 epochs is = 0.10935040986184175\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.10935040986184175\n",
      "learning rate for this epoch =  0.11236951013020673\n",
      "Error on this batch = 0.0685958801621881\n",
      "Error on this batch = 0.1013981841004905\n",
      "Cost on val dataset after 393 epochs is = 0.10928662681103923\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.10928662681103923\n",
      "learning rate for this epoch =  0.11229795994421696\n",
      "Error on this batch = 0.06849072628883696\n",
      "Error on this batch = 0.10128289214548566\n",
      "Cost on val dataset after 394 epochs is = 0.1092230963852871\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.1092230963852871\n",
      "learning rate for this epoch =  0.11222663697401325\n",
      "Error on this batch = 0.06838598235869144\n",
      "Error on this batch = 0.10116797964250239\n",
      "Cost on val dataset after 395 epochs is = 0.10915981697213514\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.10915981697213514\n",
      "learning rate for this epoch =  0.11215553992409688\n",
      "Error on this batch = 0.06828164592216118\n",
      "Error on this batch = 0.10105344525587746\n",
      "Cost on val dataset after 396 epochs is = 0.1090967869796838\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.1090967869796838\n",
      "learning rate for this epoch =  0.11208466750961145\n",
      "Error on this batch = 0.06817771455061414\n",
      "Error on this batch = 0.10093928767249467\n",
      "Cost on val dataset after 397 epochs is = 0.10903400483635825\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.10903400483635825\n",
      "learning rate for this epoch =  0.11201401845622891\n",
      "Error on this batch = 0.06807418583624528\n",
      "Error on this batch = 0.10082550560120507\n",
      "Cost on val dataset after 398 epochs is = 0.1089714689906842\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.1089714689906842\n",
      "learning rate for this epoch =  0.11194359150003692\n",
      "Error on this batch = 0.06797105739194265\n",
      "Error on this batch = 0.10071209777225068\n",
      "Cost on val dataset after 399 epochs is = 0.1089091779110652\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.1089091779110652\n",
      "learning rate for this epoch =  0.11187338538742793\n",
      "Error on this batch = 0.06786832685115121\n",
      "Error on this batch = 0.10059906293669339\n",
      "Cost on val dataset after 400 epochs is = 0.1088471300855609\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.1088471300855609\n",
      "learning rate for this epoch =  0.11180339887498948\n",
      "Error on this batch = 0.06776599186773423\n",
      "Error on this batch = 0.10048639986584754\n",
      "Cost on val dataset after 401 epochs is = 0.10878532402166687\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.10878532402166687\n",
      "learning rate for this epoch =  0.11173363072939616\n",
      "Error on this batch = 0.06766405011583287\n",
      "Error on this batch = 0.10037410735071747\n",
      "Cost on val dataset after 402 epochs is = 0.10872375824609509\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.10872375824609509\n",
      "learning rate for this epoch =  0.11166407972730269\n",
      "Error on this batch = 0.06756249928972334\n",
      "Error on this batch = 0.10026218420143965\n",
      "Cost on val dataset after 403 epochs is = 0.10866243130455605\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.10866243130455605\n",
      "learning rate for this epoch =  0.1115947446552388\n",
      "Error on this batch = 0.06746133710367222\n",
      "Error on this batch = 0.10015062924672954\n",
      "Cost on val dataset after 404 epochs is = 0.10860134176154103\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.10860134176154103\n",
      "learning rate for this epoch =  0.11152562430950505\n",
      "Error on this batch = 0.06736056129178984\n",
      "Error on this batch = 0.10003944133333331\n",
      "Cost on val dataset after 405 epochs is = 0.10854048820010556\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.10854048820010556\n",
      "learning rate for this epoch =  0.11145671749607033\n",
      "Error on this batch = 0.06726016960788213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.09992861932548465\n",
      "Cost on val dataset after 406 epochs is = 0.10847986922165376\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.10847986922165376\n",
      "learning rate for this epoch =  0.1113880230304705\n",
      "Error on this batch = 0.06716015982530041\n",
      "Error on this batch = 0.09981816210436659\n",
      "Cost on val dataset after 407 epochs is = 0.10841948344572287\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.10841948344572287\n",
      "learning rate for this epoch =  0.11131953973770842\n",
      "Error on this batch = 0.06706052973678978\n",
      "Error on this batch = 0.09970806856757886\n",
      "Cost on val dataset after 408 epochs is = 0.1083593295097687\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.1083593295097687\n",
      "learning rate for this epoch =  0.11125126645215519\n",
      "Error on this batch = 0.06696127715433618\n",
      "Error on this batch = 0.09959833762861023\n",
      "Cost on val dataset after 409 epochs is = 0.10829940606895148\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.10829940606895148\n",
      "learning rate for this epoch =  0.11118320201745278\n",
      "Error on this batch = 0.0668623999090118\n",
      "Error on this batch = 0.09948896821631649\n",
      "Cost on val dataset after 410 epochs is = 0.10823971179592196\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.10823971179592196\n",
      "learning rate for this epoch =  0.11111534528641788\n",
      "Error on this batch = 0.06676389585081934\n",
      "Error on this batch = 0.09937995927440425\n",
      "Cost on val dataset after 411 epochs is = 0.10818024538060798\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.10818024538060798\n",
      "learning rate for this epoch =  0.11104769512094681\n",
      "Error on this batch = 0.06666576284853509\n",
      "Error on this batch = 0.09927130976092009\n",
      "Cost on val dataset after 412 epochs is = 0.10812100553000142\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.10812100553000142\n",
      "learning rate for this epoch =  0.11098025039192183\n",
      "Error on this batch = 0.06656799878955097\n",
      "Error on this batch = 0.09916301864774571\n",
      "Cost on val dataset after 413 epochs is = 0.10806199096794514\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.10806199096794514\n",
      "learning rate for this epoch =  0.11091300997911864\n",
      "Error on this batch = 0.06647060157971549\n",
      "Error on this batch = 0.09905508492009915\n",
      "Cost on val dataset after 414 epochs is = 0.10800320043492027\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.10800320043492027\n",
      "learning rate for this epoch =  0.11084597277111498\n",
      "Error on this batch = 0.06637356914317394\n",
      "Error on this batch = 0.0989475075760419\n",
      "Cost on val dataset after 415 epochs is = 0.10794463268783341\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.10794463268783341\n",
      "learning rate for this epoch =  0.11077913766520031\n",
      "Error on this batch = 0.06627689942220769\n",
      "Error on this batch = 0.0988402856259921\n",
      "Cost on val dataset after 416 epochs is = 0.10788628649980418\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.10788628649980418\n",
      "learning rate for this epoch =  0.11071250356728685\n",
      "Error on this batch = 0.0661805903770729\n",
      "Error on this batch = 0.09873341809224438\n",
      "Cost on val dataset after 417 epochs is = 0.10782816065995257\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.10782816065995257\n",
      "learning rate for this epoch =  0.11064606939182157\n",
      "Error on this batch = 0.06608463998583859\n",
      "Error on this batch = 0.09862690400849551\n",
      "Cost on val dataset after 418 epochs is = 0.10777025397318624\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.10777025397318624\n",
      "learning rate for this epoch =  0.11057983406169934\n",
      "Error on this batch = 0.06598904624422425\n",
      "Error on this batch = 0.09852074241937718\n",
      "Cost on val dataset after 419 epochs is = 0.10771256525998799\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.10771256525998799\n",
      "learning rate for this epoch =  0.11051379650817714\n",
      "Error on this batch = 0.06589380716543705\n",
      "Error on this batch = 0.09841493237999485\n",
      "Cost on val dataset after 420 epochs is = 0.10765509335620294\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.10765509335620294\n",
      "learning rate for this epoch =  0.11044795567078942\n",
      "Error on this batch = 0.06579892078000879\n",
      "Error on this batch = 0.09830947295547343\n",
      "Cost on val dataset after 421 epochs is = 0.10759783711282564\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.10759783711282564\n",
      "learning rate for this epoch =  0.1103823104972644\n",
      "Error on this batch = 0.06570438513563243\n",
      "Error on this batch = 0.09820436322050993\n",
      "Cost on val dataset after 422 epochs is = 0.10754079539578712\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.10754079539578712\n",
      "learning rate for this epoch =  0.11031685994344151\n",
      "Error on this batch = 0.0656101982969987\n",
      "Error on this batch = 0.09809960225893263\n",
      "Cost on val dataset after 423 epochs is = 0.10748396708574172\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.10748396708574172\n",
      "learning rate for this epoch =  0.11025160297318981\n",
      "Error on this batch = 0.06551635834563271\n",
      "Error on this batch = 0.0979951891632675\n",
      "Cost on val dataset after 424 epochs is = 0.1074273510778537\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.1074273510778537\n",
      "learning rate for this epoch =  0.11018653855832754\n",
      "Error on this batch = 0.06542286337973031\n",
      "Error on this batch = 0.09789112303431143\n",
      "Cost on val dataset after 425 epochs is = 0.10737094628158382\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.10737094628158382\n",
      "learning rate for this epoch =  0.11012166567854233\n",
      "Error on this batch = 0.06532971151399504\n",
      "Error on this batch = 0.09778740298071269\n",
      "Cost on val dataset after 426 epochs is = 0.10731475162047559\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.10731475162047559\n",
      "learning rate for this epoch =  0.11005698332131283\n",
      "Error on this batch = 0.06523690087947466\n",
      "Error on this batch = 0.09768402811855854\n",
      "Cost on val dataset after 427 epochs is = 0.10725876603194133\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.10725876603194133\n",
      "learning rate for this epoch =  0.10999249048183099\n",
      "Error on this batch = 0.06514442962339857\n",
      "Error on this batch = 0.09758099757097025\n",
      "Cost on val dataset after 428 epochs is = 0.10720298846704825\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.10720298846704825\n",
      "learning rate for this epoch =  0.10992818616292545\n",
      "Error on this batch = 0.06505229590901516\n",
      "Error on this batch = 0.09747831046770497\n",
      "Cost on val dataset after 429 epochs is = 0.10714741789030395\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.10714741789030395\n",
      "learning rate for this epoch =  0.10986406937498579\n",
      "Error on this batch = 0.06496049791543002\n",
      "Error on this batch = 0.09737596594476564\n",
      "Cost on val dataset after 430 epochs is = 0.10709205327944224\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.10709205327944224\n",
      "learning rate for this epoch =  0.10980013913588772\n",
      "Error on this batch = 0.06486903383744401\n",
      "Error on this batch = 0.09727396314401791\n",
      "Cost on val dataset after 431 epochs is = 0.1070368936252083\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.1070368936252083\n",
      "learning rate for this epoch =  0.10973639447091926\n",
      "Error on this batch = 0.06477790188539252\n",
      "Error on this batch = 0.0971723012128146\n",
      "Cost on val dataset after 432 epochs is = 0.10698193793114419\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.10698193793114419\n",
      "learning rate for this epoch =  0.10967283441270771\n",
      "Error on this batch = 0.06468710028498512\n",
      "Error on this batch = 0.09707097930362801\n",
      "Cost on val dataset after 433 epochs is = 0.10692718521337369\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.10692718521337369\n",
      "learning rate for this epoch =  0.10960945800114749\n",
      "Error on this batch = 0.0645966272771457\n",
      "Error on this batch = 0.09696999657368935\n",
      "Cost on val dataset after 434 epochs is = 0.10687263450038766\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.10687263450038766\n",
      "learning rate for this epoch =  0.10954626428332909\n",
      "Error on this batch = 0.0645064811178538\n",
      "Error on this batch = 0.09686935218463624\n",
      "Cost on val dataset after 435 epochs is = 0.1068182848328287\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.1068182848328287\n",
      "learning rate for this epoch =  0.10948325231346849\n",
      "Error on this batch = 0.06441666007798637\n",
      "Error on this batch = 0.09676904530216775\n",
      "Cost on val dataset after 436 epochs is = 0.10676413526327634\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.10676413526327634\n",
      "learning rate for this epoch =  0.1094204211528378\n",
      "Error on this batch = 0.06432716244316057\n",
      "Error on this batch = 0.096669075095707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 437 epochs is = 0.10671018485603187\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.10671018485603187\n",
      "learning rate for this epoch =  0.1093577698696965\n",
      "Error on this batch = 0.06423798651357748\n",
      "Error on this batch = 0.09656944073807179\n",
      "Cost on val dataset after 438 epochs is = 0.1066564326869032\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.1066564326869032\n",
      "learning rate for this epoch =  0.1092952975392236\n",
      "Error on this batch = 0.06414913060386669\n",
      "Error on this batch = 0.09647014140515277\n",
      "Cost on val dataset after 439 epochs is = 0.10660287784299015\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.10660287784299015\n",
      "learning rate for this epoch =  0.10923300324345062\n",
      "Error on this batch = 0.06406059304293209\n",
      "Error on this batch = 0.09637117627559931\n",
      "Cost on val dataset after 440 epochs is = 0.10654951942246949\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.10654951942246949\n",
      "learning rate for this epoch =  0.10917088607119531\n",
      "Error on this batch = 0.06397237217379856\n",
      "Error on this batch = 0.09627254453051362\n",
      "Cost on val dataset after 441 epochs is = 0.10649635653438026\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.10649635653438026\n",
      "learning rate for this epoch =  0.1091089451179962\n",
      "Error on this batch = 0.06388446635345968\n",
      "Error on this batch = 0.09617424535315212\n",
      "Cost on val dataset after 442 epochs is = 0.10644338829840955\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.10644338829840955\n",
      "learning rate for this epoch =  0.10904717948604793\n",
      "Error on this batch = 0.06379687395272689\n",
      "Error on this batch = 0.096076277928635\n",
      "Cost on val dataset after 443 epochs is = 0.10639061384467827\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.10639061384467827\n",
      "learning rate for this epoch =  0.10898558828413735\n",
      "Error on this batch = 0.0637095933560795\n",
      "Error on this batch = 0.09597864144366351\n",
      "Cost on val dataset after 444 epochs is = 0.10633803231352733\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.10633803231352733\n",
      "learning rate for this epoch =  0.10892417062758035\n",
      "Error on this batch = 0.06362262296151608\n",
      "Error on this batch = 0.09588133508624495\n",
      "Cost on val dataset after 445 epochs is = 0.10628564285530441\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.10628564285530441\n",
      "learning rate for this epoch =  0.10886292563815944\n",
      "Error on this batch = 0.06353596118040718\n",
      "Error on this batch = 0.09578435804542554\n",
      "Cost on val dataset after 446 epochs is = 0.10623344463015112\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.10623344463015112\n",
      "learning rate for this epoch =  0.10880185244406208\n",
      "Error on this batch = 0.06344960643734897\n",
      "Error on this batch = 0.09568770951103123\n",
      "Cost on val dataset after 447 epochs is = 0.10618143680779046\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.10618143680779046\n",
      "learning rate for this epoch =  0.10874095017981981\n",
      "Error on this batch = 0.06336355717001858\n",
      "Error on this batch = 0.09559138867341592\n",
      "Cost on val dataset after 448 epochs is = 0.10612961856731536\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.10612961856731536\n",
      "learning rate for this epoch =  0.10868021798624786\n",
      "Error on this batch = 0.06327781182903067\n",
      "Error on this batch = 0.09549539472321797\n",
      "Cost on val dataset after 449 epochs is = 0.10607798909697735\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.10607798909697735\n",
      "learning rate for this epoch =  0.10861965501038574\n",
      "Error on this batch = 0.06319236887779489\n",
      "Error on this batch = 0.09539972685112387\n",
      "Cost on val dataset after 450 epochs is = 0.10602654759397673\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.10602654759397673\n",
      "learning rate for this epoch =  0.10855926040543842\n",
      "Error on this batch = 0.0631072267923756\n",
      "Error on this batch = 0.09530438424763986\n",
      "Cost on val dataset after 451 epochs is = 0.10597529326425267\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.10597529326425267\n",
      "learning rate for this epoch =  0.1084990333307181\n",
      "Error on this batch = 0.06302238406135204\n",
      "Error on this batch = 0.09520936610287155\n",
      "Cost on val dataset after 452 epochs is = 0.10592422532227502\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.10592422532227502\n",
      "learning rate for this epoch =  0.10843897295158678\n",
      "Error on this batch = 0.06293783918568054\n",
      "Error on this batch = 0.0951146716063105\n",
      "Cost on val dataset after 453 epochs is = 0.10587334299083669\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.10587334299083669\n",
      "learning rate for this epoch =  0.10837907843939941\n",
      "Error on this batch = 0.06285359067855781\n",
      "Error on this batch = 0.09502029994662899\n",
      "Cost on val dataset after 454 epochs is = 0.10582264550084716\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.10582264550084716\n",
      "learning rate for this epoch =  0.10831934897144786\n",
      "Error on this batch = 0.0627696370652858\n",
      "Error on this batch = 0.09492625031148197\n",
      "Cost on val dataset after 455 epochs is = 0.10577213209112747\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.10577213209112747\n",
      "learning rate for this epoch =  0.10825978373090529\n",
      "Error on this batch = 0.06268597688313786\n",
      "Error on this batch = 0.09483252188731665\n",
      "Cost on val dataset after 456 epochs is = 0.10572180200820581\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.10572180200820581\n",
      "learning rate for this epoch =  0.10820038190677136\n",
      "Error on this batch = 0.0626026086812266\n",
      "Error on this batch = 0.09473911385918964\n",
      "Cost on val dataset after 457 epochs is = 0.10567165450611526\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.10567165450611526\n",
      "learning rate for this epoch =  0.10814114269381797\n",
      "Error on this batch = 0.06251953102037291\n",
      "Error on this batch = 0.09464602541059108\n",
      "Cost on val dataset after 458 epochs is = 0.10562168884619234\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.10562168884619234\n",
      "learning rate for this epoch =  0.10808206529253567\n",
      "Error on this batch = 0.06243674247297654\n",
      "Error on this batch = 0.09455325572327672\n",
      "Cost on val dataset after 459 epochs is = 0.10557190429687732\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.10557190429687732\n",
      "learning rate for this epoch =  0.10802314890908067\n",
      "Error on this batch = 0.06235424162288817\n",
      "Error on this batch = 0.09446080397710674\n",
      "Cost on val dataset after 460 epochs is = 0.10552230013351602\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.10552230013351602\n",
      "learning rate for this epoch =  0.10796439275522242\n",
      "Error on this batch = 0.062272027065282884\n",
      "Error on this batch = 0.09436866934989184\n",
      "Cost on val dataset after 461 epochs is = 0.10547287563816357\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.10547287563816357\n",
      "learning rate for this epoch =  0.10790579604829184\n",
      "Error on this batch = 0.06219009740653521\n",
      "Error on this batch = 0.09427685101724684\n",
      "Cost on val dataset after 462 epochs is = 0.10542363009938972\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.10542363009938972\n",
      "learning rate for this epoch =  0.10784735801113018\n",
      "Error on this batch = 0.06210845126409537\n",
      "Error on this batch = 0.09418534815245089\n",
      "Cost on val dataset after 463 epochs is = 0.10537456281208585\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.10537456281208585\n",
      "learning rate for this epoch =  0.10778907787203826\n",
      "Error on this batch = 0.062027087266367256\n",
      "Error on this batch = 0.09409415992631485\n",
      "Cost on val dataset after 464 epochs is = 0.1053256730772746\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.1053256730772746\n",
      "learning rate for this epoch =  0.1077309548647265\n",
      "Error on this batch = 0.06194600405258762\n",
      "Error on this batch = 0.09400328550705571\n",
      "Cost on val dataset after 465 epochs is = 0.10527696020192072\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.10527696020192072\n",
      "learning rate for this epoch =  0.10767298822826553\n",
      "Error on this batch = 0.06186520027270687\n",
      "Error on this batch = 0.09391272406017745\n",
      "Cost on val dataset after 466 epochs is = 0.10522842349874464\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.10522842349874464\n",
      "learning rate for this epoch =  0.10761517720703706\n",
      "Error on this batch = 0.061784674587271146\n",
      "Error on this batch = 0.09382247474835918\n",
      "Cost on val dataset after 467 epochs is = 0.10518006228603823\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.10518006228603823\n",
      "learning rate for this epoch =  0.10755752105068565\n",
      "Error on this batch = 0.06170442566730606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.09373253673134936\n",
      "Cost on val dataset after 468 epochs is = 0.10513187588748256\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.10513187588748256\n",
      "learning rate for this epoch =  0.1075000190140709\n",
      "Error on this batch = 0.0616244521942015\n",
      "Error on this batch = 0.09364290916586704\n",
      "Cost on val dataset after 469 epochs is = 0.10508386363196831\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.10508386363196831\n",
      "learning rate for this epoch =  0.10744267035722005\n",
      "Error on this batch = 0.06154475285959809\n",
      "Error on this batch = 0.09355359120550932\n",
      "Cost on val dataset after 470 epochs is = 0.10503602485341872\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.10503602485341872\n",
      "learning rate for this epoch =  0.10738547434528128\n",
      "Error on this batch = 0.061465326365274894\n",
      "Error on this batch = 0.09346458200066521\n",
      "Cost on val dataset after 471 epochs is = 0.10498835889061499\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.10498835889061499\n",
      "learning rate for this epoch =  0.10732843024847744\n",
      "Error on this batch = 0.06138617142303874\n",
      "Error on this batch = 0.09337588069843582\n",
      "Cost on val dataset after 472 epochs is = 0.10494086508702422\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.10494086508702422\n",
      "learning rate for this epoch =  0.10727153734206031\n",
      "Error on this batch = 0.06130728675461456\n",
      "Error on this batch = 0.09328748644256077\n",
      "Cost on val dataset after 473 epochs is = 0.10489354279063047\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.10489354279063047\n",
      "learning rate for this epoch =  0.1072147949062655\n",
      "Error on this batch = 0.061228671091537325\n",
      "Error on this batch = 0.09319939837335067\n",
      "Cost on val dataset after 474 epochs is = 0.10484639135376825\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.10484639135376825\n",
      "learning rate for this epoch =  0.10715820222626746\n",
      "Error on this batch = 0.06115032317504524\n",
      "Error on this batch = 0.0931116156276254\n",
      "Cost on val dataset after 475 epochs is = 0.10479941013295907\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.10479941013295907\n",
      "learning rate for this epoch =  0.1071017585921356\n",
      "Error on this batch = 0.061072241755974144\n",
      "Error on this batch = 0.09302413733865858\n",
      "Cost on val dataset after 476 epochs is = 0.104752598488751\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.104752598488751\n",
      "learning rate for this epoch =  0.1070454632987902\n",
      "Error on this batch = 0.060994425594653484\n",
      "Error on this batch = 0.09293696263612748\n",
      "Cost on val dataset after 477 epochs is = 0.10470595578556117\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.10470595578556117\n",
      "learning rate for this epoch =  0.10698931564595948\n",
      "Error on this batch = 0.0609168734608033\n",
      "Error on this batch = 0.09285009064606876\n",
      "Cost on val dataset after 478 epochs is = 0.10465948139152134\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.10465948139152134\n",
      "learning rate for this epoch =  0.1069333149381366\n",
      "Error on this batch = 0.06083958413343262\n",
      "Error on this batch = 0.09276352049084001\n",
      "Cost on val dataset after 479 epochs is = 0.1046131746783268\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.1046131746783268\n",
      "learning rate for this epoch =  0.10687746048453738\n",
      "Error on this batch = 0.06076255640073904\n",
      "Error on this batch = 0.092677251289086\n",
      "Cost on val dataset after 480 epochs is = 0.10456703502108841\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.10456703502108841\n",
      "learning rate for this epoch =  0.10682175159905852\n",
      "Error on this batch = 0.06068578906000964\n",
      "Error on this batch = 0.09259128215571125\n",
      "Cost on val dataset after 481 epochs is = 0.10452106179818782\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.10452106179818782\n",
      "learning rate for this epoch =  0.1067661876002362\n",
      "Error on this batch = 0.06060928091752292\n",
      "Error on this batch = 0.09250561220185688\n",
      "Cost on val dataset after 482 epochs is = 0.10447525439113621\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.10447525439113621\n",
      "learning rate for this epoch =  0.1067107678112051\n",
      "Error on this batch = 0.06053303078845214\n",
      "Error on this batch = 0.09242024053488318\n",
      "Cost on val dataset after 483 epochs is = 0.10442961218443633\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.10442961218443633\n",
      "learning rate for this epoch =  0.10665549155965787\n",
      "Error on this batch = 0.06045703749676969\n",
      "Error on this batch = 0.09233516625835707\n",
      "Cost on val dataset after 484 epochs is = 0.10438413456544794\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.10438413456544794\n",
      "learning rate for this epoch =  0.10660035817780521\n",
      "Error on this batch = 0.06038129987515276\n",
      "Error on this batch = 0.09225038847204402\n",
      "Cost on val dataset after 485 epochs is = 0.10433882092425703\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.10433882092425703\n",
      "learning rate for this epoch =  0.10654536700233612\n",
      "Error on this batch = 0.060305816764889955\n",
      "Error on this batch = 0.09216590627190538\n",
      "Cost on val dataset after 486 epochs is = 0.10429367065354792\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.10429367065354792\n",
      "learning rate for this epoch =  0.10649051737437876\n",
      "Error on this batch = 0.06023058701578906\n",
      "Error on this batch = 0.09208171875009986\n",
      "Cost on val dataset after 487 epochs is = 0.10424868314847972\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.10424868314847972\n",
      "learning rate for this epoch =  0.10643580863946162\n",
      "Error on this batch = 0.06015560948608632\n",
      "Error on this batch = 0.09199782499498962\n",
      "Cost on val dataset after 488 epochs is = 0.10420385780656581\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.10420385780656581\n",
      "learning rate for this epoch =  0.10638124014747533\n",
      "Error on this batch = 0.06008088304235601\n",
      "Error on this batch = 0.09191422409115099\n",
      "Cost on val dataset after 489 epochs is = 0.10415919402755715\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.10415919402755715\n",
      "learning rate for this epoch =  0.1063268112526345\n",
      "Error on this batch = 0.0600064065594218\n",
      "Error on this batch = 0.09183091511938919\n",
      "Cost on val dataset after 490 epochs is = 0.10411469121332928\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.10411469121332928\n",
      "learning rate for this epoch =  0.10627252131344038\n",
      "Error on this batch = 0.05993217892026877\n",
      "Error on this batch = 0.09174789715675737\n",
      "Cost on val dataset after 491 epochs is = 0.10407034876777291\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.10407034876777291\n",
      "learning rate for this epoch =  0.10621836969264359\n",
      "Error on this batch = 0.05985819901595664\n",
      "Error on this batch = 0.09166516927657979\n",
      "Cost on val dataset after 492 epochs is = 0.10402616609668802\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.10402616609668802\n",
      "learning rate for this epoch =  0.10616435575720744\n",
      "Error on this batch = 0.059784465745533776\n",
      "Error on this batch = 0.09158273054847857\n",
      "Cost on val dataset after 493 epochs is = 0.10398214260768218\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.10398214260768218\n",
      "learning rate for this epoch =  0.1061104788782716\n",
      "Error on this batch = 0.059710978015952404\n",
      "Error on this batch = 0.09150058003840475\n",
      "Cost on val dataset after 494 epochs is = 0.10393827771007193\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.10393827771007193\n",
      "learning rate for this epoch =  0.10605673843111615\n",
      "Error on this batch = 0.05963773474198481\n",
      "Error on this batch = 0.09141871680867251\n",
      "Cost on val dataset after 495 epochs is = 0.10389457081478835\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.10389457081478835\n",
      "learning rate for this epoch =  0.10600313379512592\n",
      "Error on this batch = 0.05956473484614021\n",
      "Error on this batch = 0.09133713991799755\n",
      "Cost on val dataset after 496 epochs is = 0.10385102133428598\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.10385102133428598\n",
      "learning rate for this epoch =  0.10594966435375541\n",
      "Error on this batch = 0.05949197725858288\n",
      "Error on this batch = 0.09125584842153835\n",
      "Cost on val dataset after 497 epochs is = 0.10380762868245576\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.10380762868245576\n",
      "learning rate for this epoch =  0.10589632949449389\n",
      "Error on this batch = 0.05941946091705095\n",
      "Error on this batch = 0.0911748413709411\n",
      "Cost on val dataset after 498 epochs is = 0.1037643922745413\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.1037643922745413\n",
      "learning rate for this epoch =  0.10584312860883092\n",
      "Error on this batch = 0.05934718476677625\n",
      "Error on this batch = 0.09109411781438778\n",
      "Cost on val dataset after 499 epochs is = 0.10372131152705928\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.10372131152705928\n",
      "learning rate for this epoch =  0.10579006109222232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.05927514776040512\n",
      "Error on this batch = 0.09101367679664747\n",
      "Cost on val dataset after 500 epochs is = 0.1036783858577228\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.1036783858577228\n",
      "learning rate for this epoch =  0.10573712634405641\n",
      "Error on this batch = 0.05920334885791975\n",
      "Error on this batch = 0.09093351735913015\n",
      "Cost on val dataset after 501 epochs is = 0.10363561468536918\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.10363561468536918\n",
      "learning rate for this epoch =  0.1056843237676206\n",
      "Error on this batch = 0.05913178702656076\n",
      "Error on this batch = 0.09085363853994416\n",
      "Cost on val dataset after 502 epochs is = 0.10359299742989074\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.10359299742989074\n",
      "learning rate for this epoch =  0.10563165277006838\n",
      "Error on this batch = 0.05906046124075026\n",
      "Error on this batch = 0.09077403937395563\n",
      "Cost on val dataset after 503 epochs is = 0.10355053351216956\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.10355053351216956\n",
      "learning rate for this epoch =  0.10557911276238661\n",
      "Error on this batch = 0.058989370482016065\n",
      "Error on this batch = 0.09069471889285115\n",
      "Cost on val dataset after 504 epochs is = 0.10350822235401524\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.10350822235401524\n",
      "learning rate for this epoch =  0.10552670315936317\n",
      "Error on this batch = 0.05891851373891659\n",
      "Error on this batch = 0.09061567612520254\n",
      "Cost on val dataset after 505 epochs is = 0.1034660633781068\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.1034660633781068\n",
      "learning rate for this epoch =  0.105474423379555\n",
      "Error on this batch = 0.05884789000696634\n",
      "Error on this batch = 0.09053691009653445\n",
      "Cost on val dataset after 506 epochs is = 0.10342405600793772\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.10342405600793772\n",
      "learning rate for this epoch =  0.10542227284525636\n",
      "Error on this batch = 0.05877749828856251\n",
      "Error on this batch = 0.09045841982939372\n",
      "Cost on val dataset after 507 epochs is = 0.10338219966776419\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.10338219966776419\n",
      "learning rate for this epoch =  0.10537025098246748\n",
      "Error on this batch = 0.05870733759291206\n",
      "Error on this batch = 0.09038020434342155\n",
      "Cost on val dataset after 508 epochs is = 0.10334049378255702\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.10334049378255702\n",
      "learning rate for this epoch =  0.10531835722086355\n",
      "Error on this batch = 0.05863740693595984\n",
      "Error on this batch = 0.09030226265542733\n",
      "Cost on val dataset after 509 epochs is = 0.10329893777795691\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.10329893777795691\n",
      "learning rate for this epoch =  0.10526659099376405\n",
      "Error on this batch = 0.058567705340317196\n",
      "Error on this batch = 0.09022459377946455\n",
      "Cost on val dataset after 510 epochs is = 0.10325753108023258\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.10325753108023258\n",
      "learning rate for this epoch =  0.10521495173810227\n",
      "Error on this batch = 0.058498231835191435\n",
      "Error on this batch = 0.09014719672690862\n",
      "Cost on val dataset after 511 epochs is = 0.10321627311624251\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.10321627311624251\n",
      "learning rate for this epoch =  0.10516343889439533\n",
      "Error on this batch = 0.05842898545631594\n",
      "Error on this batch = 0.09007007050653658\n",
      "Cost on val dataset after 512 epochs is = 0.10317516331339951\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.10317516331339951\n",
      "learning rate for this epoch =  0.10511205190671433\n",
      "Error on this batch = 0.05835996524588106\n",
      "Error on this batch = 0.08999321412460827\n",
      "Cost on val dataset after 513 epochs is = 0.1031342010996386\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.1031342010996386\n",
      "learning rate for this epoch =  0.10506079022265488\n",
      "Error on this batch = 0.05829117025246578\n",
      "Error on this batch = 0.08991662658494917\n",
      "Cost on val dataset after 514 epochs is = 0.10309338590338771\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.10309338590338771\n",
      "learning rate for this epoch =  0.10500965329330811\n",
      "Error on this batch = 0.05822259953096992\n",
      "Error on this batch = 0.08984030688903463\n",
      "Cost on val dataset after 515 epochs is = 0.10305271715354133\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.10305271715354133\n",
      "learning rate for this epoch =  0.10495864057323148\n",
      "Error on this batch = 0.05815425214254698\n",
      "Error on this batch = 0.08976425403607567\n",
      "Cost on val dataset after 516 epochs is = 0.10301219427943717\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.10301219427943717\n",
      "learning rate for this epoch =  0.10490775152042053\n",
      "Error on this batch = 0.058086127154537925\n",
      "Error on this batch = 0.0896884670231059\n",
      "Cost on val dataset after 517 epochs is = 0.10297181671083545\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.10297181671083545\n",
      "learning rate for this epoch =  0.10485698559628044\n",
      "Error on this batch = 0.058018223640405306\n",
      "Error on this batch = 0.08961294484506949\n",
      "Cost on val dataset after 518 epochs is = 0.10293158387790095\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.10293158387790095\n",
      "learning rate for this epoch =  0.10480634226559798\n",
      "Error on this batch = 0.0579505406796685\n",
      "Error on this batch = 0.08953768649491065\n",
      "Cost on val dataset after 519 epochs is = 0.10289149521118775\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.10289149521118775\n",
      "learning rate for this epoch =  0.10475582099651397\n",
      "Error on this batch = 0.05788307735783883\n",
      "Error on this batch = 0.08946269096366354\n",
      "Cost on val dataset after 520 epochs is = 0.10285155014162652\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.10285155014162652\n",
      "learning rate for this epoch =  0.10470542126049572\n",
      "Error on this batch = 0.05781583276635635\n",
      "Error on this batch = 0.08938795724054367\n",
      "Cost on val dataset after 521 epochs is = 0.10281174810051408\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.10281174810051408\n",
      "learning rate for this epoch =  0.10465514253230984\n",
      "Error on this batch = 0.05774880600252621\n",
      "Error on this batch = 0.08931348431303975\n",
      "Cost on val dataset after 522 epochs is = 0.10277208851950591\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.10277208851950591\n",
      "learning rate for this epoch =  0.10460498428999554\n",
      "Error on this batch = 0.05768199616945658\n",
      "Error on this batch = 0.08923927116700622\n",
      "Cost on val dataset after 523 epochs is = 0.1027325708306102\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.1027325708306102\n",
      "learning rate for this epoch =  0.10455494601483782\n",
      "Error on this batch = 0.05761540237599654\n",
      "Error on this batch = 0.08916531678675689\n",
      "Cost on val dataset after 524 epochs is = 0.10269319446618488\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.10269319446618488\n",
      "learning rate for this epoch =  0.10450502719134125\n",
      "Error on this batch = 0.05754902373667495\n",
      "Error on this batch = 0.08909162015515854\n",
      "Cost on val dataset after 525 epochs is = 0.1026539588589364\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.1026539588589364\n",
      "learning rate for this epoch =  0.10445522730720382\n",
      "Error on this batch = 0.05748285937163969\n",
      "Error on this batch = 0.08901818025372556\n",
      "Cost on val dataset after 526 epochs is = 0.10261486344192054\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.10261486344192054\n",
      "learning rate for this epoch =  0.10440554585329116\n",
      "Error on this batch = 0.057416908406597814\n",
      "Error on this batch = 0.08894499606271478\n",
      "Cost on val dataset after 527 epochs is = 0.10257590764854554\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.10257590764854554\n",
      "learning rate for this epoch =  0.10435598232361096\n",
      "Error on this batch = 0.05735116997275603\n",
      "Error on this batch = 0.08887206656122039\n",
      "Cost on val dataset after 528 epochs is = 0.1025370909125769\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.1025370909125769\n",
      "learning rate for this epoch =  0.10430653621528765\n",
      "Error on this batch = 0.05728564320676194\n",
      "Error on this batch = 0.0887993907272697\n",
      "Cost on val dataset after 529 epochs is = 0.10249841266814397\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.10249841266814397\n",
      "learning rate for this epoch =  0.10425720702853739\n",
      "Error on this batch = 0.057220327250645714\n",
      "Error on this batch = 0.08872696753791852\n",
      "Cost on val dataset after 530 epochs is = 0.10245987234974845\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.10245987234974845\n",
      "learning rate for this epoch =  0.10420799426664315\n",
      "Error on this batch = 0.05715522125176263\n",
      "Error on this batch = 0.08865479596934722\n",
      "Cost on val dataset after 531 epochs is = 0.10242146939227445\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.10242146939227445\n",
      "learning rate for this epoch =  0.10415889743593033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.05709032436273592\n",
      "Error on this batch = 0.08858287499695626\n",
      "Cost on val dataset after 532 epochs is = 0.10238320323100018\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.10238320323100018\n",
      "learning rate for this epoch =  0.10410991604574225\n",
      "Error on this batch = 0.057025635741400356\n",
      "Error on this batch = 0.08851120359546219\n",
      "Cost on val dataset after 533 epochs is = 0.10234507330161101\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.10234507330161101\n",
      "learning rate for this epoch =  0.10406104960841617\n",
      "Error on this batch = 0.0569611545507464\n",
      "Error on this batch = 0.08843978073899347\n",
      "Cost on val dataset after 534 epochs is = 0.10230707904021429\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.10230707904021429\n",
      "learning rate for this epoch =  0.1040122976392594\n",
      "Error on this batch = 0.05689687995886493\n",
      "Error on this batch = 0.088368605401186\n",
      "Cost on val dataset after 535 epochs is = 0.10226921988335491\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.10226921988335491\n",
      "learning rate for this epoch =  0.10396365965652576\n",
      "Error on this batch = 0.056832811138892436\n",
      "Error on this batch = 0.08829767655527865\n",
      "Cost on val dataset after 536 epochs is = 0.10223149526803285\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.10223149526803285\n",
      "learning rate for this epoch =  0.10391513518139214\n",
      "Error on this batch = 0.056768947268957044\n",
      "Error on this batch = 0.08822699317420855\n",
      "Cost on val dataset after 537 epochs is = 0.1021939046317212\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.1021939046317212\n",
      "learning rate for this epoch =  0.10386672373793533\n",
      "Error on this batch = 0.05670528753212475\n",
      "Error on this batch = 0.08815655423070588\n",
      "Cost on val dataset after 538 epochs is = 0.10215644741238596\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.10215644741238596\n",
      "learning rate for this epoch =  0.10381842485310916\n",
      "Error on this batch = 0.05664183111634651\n",
      "Error on this batch = 0.08808635869738847\n",
      "Cost on val dataset after 539 epochs is = 0.10211912304850623\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.10211912304850623\n",
      "learning rate for this epoch =  0.10377023805672174\n",
      "Error on this batch = 0.056578577214405894\n",
      "Error on this batch = 0.08801640554685623\n",
      "Cost on val dataset after 540 epochs is = 0.1020819309790958\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.1020819309790958\n",
      "learning rate for this epoch =  0.10372216288141306\n",
      "Error on this batch = 0.05651552502386697\n",
      "Error on this batch = 0.08794669375178449\n",
      "Cost on val dataset after 541 epochs is = 0.10204487064372562\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.10204487064372562\n",
      "learning rate for this epoch =  0.10367419886263263\n",
      "Error on this batch = 0.05645267374702314\n",
      "Error on this batch = 0.08787722228501768\n",
      "Cost on val dataset after 542 epochs is = 0.10200794148254672\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.10200794148254672\n",
      "learning rate for this epoch =  0.10362634553861746\n",
      "Error on this batch = 0.05639002259084634\n",
      "Error on this batch = 0.08780799011966166\n",
      "Cost on val dataset after 543 epochs is = 0.10197114293631411\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.10197114293631411\n",
      "learning rate for this epoch =  0.10357860245037034\n",
      "Error on this batch = 0.05632757076693671\n",
      "Error on this batch = 0.08773899622917603\n",
      "Cost on val dataset after 544 epochs is = 0.10193447444641159\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.10193447444641159\n",
      "learning rate for this epoch =  0.10353096914163801\n",
      "Error on this batch = 0.05626531749147299\n",
      "Error on this batch = 0.0876702395874657\n",
      "Cost on val dataset after 545 epochs is = 0.10189793545487671\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.10189793545487671\n",
      "learning rate for this epoch =  0.10348344515888994\n",
      "Error on this batch = 0.056203261985163414\n",
      "Error on this batch = 0.08760171916897154\n",
      "Cost on val dataset after 546 epochs is = 0.10186152540442653\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.10186152540442653\n",
      "learning rate for this epoch =  0.10343603005129703\n",
      "Error on this batch = 0.056141403473196995\n",
      "Error on this batch = 0.08753343394876063\n",
      "Cost on val dataset after 547 epochs is = 0.10182524373848388\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.10182524373848388\n",
      "learning rate for this epoch =  0.1033887233707106\n",
      "Error on this batch = 0.05607974118519536\n",
      "Error on this batch = 0.08746538290261566\n",
      "Cost on val dataset after 548 epochs is = 0.10178908990120399\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.10178908990120399\n",
      "learning rate for this epoch =  0.10334152467164161\n",
      "Error on this batch = 0.056018274355165494\n",
      "Error on this batch = 0.08739756500712346\n",
      "Cost on val dataset after 549 epochs is = 0.10175306333750139\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.10175306333750139\n",
      "learning rate for this epoch =  0.10329443351124007\n",
      "Error on this batch = 0.05595700222145244\n",
      "Error on this batch = 0.08732997923976296\n",
      "Cost on val dataset after 550 epochs is = 0.10171716349307738\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.10171716349307738\n",
      "learning rate for this epoch =  0.10324744944927464\n",
      "Error on this batch = 0.05589592402669293\n",
      "Error on this batch = 0.08726262457899203\n",
      "Cost on val dataset after 551 epochs is = 0.10168138981444744\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.10168138981444744\n",
      "learning rate for this epoch =  0.10320057204811232\n",
      "Error on this batch = 0.0558350390177693\n",
      "Error on this batch = 0.08719550000433365\n",
      "Cost on val dataset after 552 epochs is = 0.10164574174896902\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.10164574174896902\n",
      "learning rate for this epoch =  0.10315380087269863\n",
      "Error on this batch = 0.05577434644576412\n",
      "Error on this batch = 0.0871286044964612\n",
      "Cost on val dataset after 553 epochs is = 0.10161021874486952\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.10161021874486952\n",
      "learning rate for this epoch =  0.10310713549053749\n",
      "Error on this batch = 0.0557138455659151\n",
      "Error on this batch = 0.0870619370372826\n",
      "Cost on val dataset after 554 epochs is = 0.10157482025127416\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.10157482025127416\n",
      "learning rate for this epoch =  0.10306057547167191\n",
      "Error on this batch = 0.055653535637570715\n",
      "Error on this batch = 0.08699549661002381\n",
      "Cost on val dataset after 555 epochs is = 0.1015395457182342\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.1015395457182342\n",
      "learning rate for this epoch =  0.1030141203886643\n",
      "Error on this batch = 0.05559341592414618\n",
      "Error on this batch = 0.08692928219931116\n",
      "Cost on val dataset after 556 epochs is = 0.10150439459675485\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.10150439459675485\n",
      "learning rate for this epoch =  0.10296776981657725\n",
      "Error on this batch = 0.05553348569307996\n",
      "Error on this batch = 0.0868632927912525\n",
      "Cost on val dataset after 557 epochs is = 0.1014693663388234\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.1014693663388234\n",
      "learning rate for this epoch =  0.10292152333295448\n",
      "Error on this batch = 0.05547374421579072\n",
      "Error on this batch = 0.08679752737351809\n",
      "Cost on val dataset after 558 epochs is = 0.10143446039743717\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.10143446039743717\n",
      "learning rate for this epoch =  0.10287538051780193\n",
      "Error on this batch = 0.05541419076763497\n",
      "Error on this batch = 0.08673198493541945\n",
      "Cost on val dataset after 559 epochs is = 0.10139967622663129\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.10139967622663129\n",
      "learning rate for this epoch =  0.10282934095356899\n",
      "Error on this batch = 0.055354824627864695\n",
      "Error on this batch = 0.08666666446798786\n",
      "Cost on val dataset after 560 epochs is = 0.10136501328150639\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.10136501328150639\n",
      "learning rate for this epoch =  0.10278340422512992\n",
      "Error on this batch = 0.05529564507958616\n",
      "Error on this batch = 0.08660156496405154\n",
      "Cost on val dataset after 561 epochs is = 0.10133047101825622\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.10133047101825622\n",
      "learning rate for this epoch =  0.10273756991976561\n",
      "Error on this batch = 0.05523665140971844\n",
      "Error on this batch = 0.08653668541831179\n",
      "Cost on val dataset after 562 epochs is = 0.10129604889419477\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.10129604889419477\n",
      "learning rate for this epoch =  0.10269183762714515\n",
      "Error on this batch = 0.055177842908952945\n",
      "Error on this batch = 0.08647202482741795\n",
      "Cost on val dataset after 563 epochs is = 0.10126174636778339\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.10126174636778339\n",
      "learning rate for this epoch =  0.10264620693930798\n",
      "Error on this batch = 0.0551192188717131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08640758219004141\n",
      "Cost on val dataset after 564 epochs is = 0.10122756289865747\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.10122756289865747\n",
      "learning rate for this epoch =  0.10260067745064594\n",
      "Error on this batch = 0.055060778596114524\n",
      "Error on this batch = 0.08634335650694837\n",
      "Cost on val dataset after 565 epochs is = 0.10119349794765294\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.10119349794765294\n",
      "learning rate for this epoch =  0.10255524875788552\n",
      "Error on this batch = 0.05500252138392593\n",
      "Error on this batch = 0.08627934678107138\n",
      "Cost on val dataset after 566 epochs is = 0.10115955097683225\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.10115955097683225\n",
      "learning rate for this epoch =  0.10250992046007043\n",
      "Error on this batch = 0.054944446540529754\n",
      "Error on this batch = 0.08621555201758004\n",
      "Cost on val dataset after 567 epochs is = 0.10112572144951029\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.10112572144951029\n",
      "learning rate for this epoch =  0.10246469215854406\n",
      "Error on this batch = 0.05488655337488407\n",
      "Error on this batch = 0.08615197122395013\n",
      "Cost on val dataset after 568 epochs is = 0.10109200883027943\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.10109200883027943\n",
      "learning rate for this epoch =  0.10241956345693246\n",
      "Error on this batch = 0.05482884119948414\n",
      "Error on this batch = 0.08608860341003194\n",
      "Cost on val dataset after 569 epochs is = 0.10105841258503477\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.10105841258503477\n",
      "learning rate for this epoch =  0.1023745339611271\n",
      "Error on this batch = 0.054771309330324994\n",
      "Error on this batch = 0.08602544758811721\n",
      "Cost on val dataset after 570 epochs is = 0.10102493218099844\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.10102493218099844\n",
      "learning rate for this epoch =  0.10232960327926806\n",
      "Error on this batch = 0.054713957086863906\n",
      "Error on this batch = 0.08596250277300493\n",
      "Cost on val dataset after 571 epochs is = 0.1009915670867438\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.1009915670867438\n",
      "learning rate for this epoch =  0.10228477102172728\n",
      "Error on this batch = 0.05465678379198366\n",
      "Error on this batch = 0.08589976798206603\n",
      "Cost on val dataset after 572 epochs is = 0.10095831677221884\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.10095831677221884\n",
      "learning rate for this epoch =  0.10224003680109194\n",
      "Error on this batch = 0.05459978877195582\n",
      "Error on this batch = 0.08583724223530671\n",
      "Cost on val dataset after 573 epochs is = 0.10092518070876957\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.10092518070876957\n",
      "learning rate for this epoch =  0.10219540023214801\n",
      "Error on this batch = 0.0545429713564047\n",
      "Error on this batch = 0.08577492455543084\n",
      "Cost on val dataset after 574 epochs is = 0.1008921583691624\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.1008921583691624\n",
      "learning rate for this epoch =  0.10215086093186404\n",
      "Error on this batch = 0.054486330878271545\n",
      "Error on this batch = 0.08571281396790081\n",
      "Cost on val dataset after 575 epochs is = 0.10085924922760643\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.10085924922760643\n",
      "learning rate for this epoch =  0.10210641851937487\n",
      "Error on this batch = 0.05442986667377903\n",
      "Error on this batch = 0.08565090950099752\n",
      "Cost on val dataset after 576 epochs is = 0.10082645275977499\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.10082645275977499\n",
      "learning rate for this epoch =  0.10206207261596577\n",
      "Error on this batch = 0.05437357808239618\n",
      "Error on this batch = 0.08558921018587903\n",
      "Cost on val dataset after 577 epochs is = 0.10079376844282674\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.10079376844282674\n",
      "learning rate for this epoch =  0.10201782284505649\n",
      "Error on this batch = 0.05431746444680366\n",
      "Error on this batch = 0.08552771505663781\n",
      "Cost on val dataset after 578 epochs is = 0.10076119575542618\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.10076119575542618\n",
      "learning rate for this epoch =  0.10197366883218573\n",
      "Error on this batch = 0.054261525112859206\n",
      "Error on this batch = 0.08546642315035716\n",
      "Cost on val dataset after 579 epochs is = 0.1007287341777637\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.1007287341777637\n",
      "learning rate for this epoch =  0.1019296102049953\n",
      "Error on this batch = 0.0542057594295637\n",
      "Error on this batch = 0.08540533350716603\n",
      "Cost on val dataset after 580 epochs is = 0.10069638319157506\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.10069638319157506\n",
      "learning rate for this epoch =  0.10188564659321496\n",
      "Error on this batch = 0.054150166749027236\n",
      "Error on this batch = 0.08534444517029303\n",
      "Cost on val dataset after 581 epochs is = 0.10066414228016016\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.10066414228016016\n",
      "learning rate for this epoch =  0.10184177762864698\n",
      "Error on this batch = 0.054094746426435754\n",
      "Error on this batch = 0.0852837571861189\n",
      "Cost on val dataset after 582 epochs is = 0.10063201092840153\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.10063201092840153\n",
      "learning rate for this epoch =  0.10179800294515103\n",
      "Error on this batch = 0.05403949782001765\n",
      "Error on this batch = 0.08522326860422785\n",
      "Cost on val dataset after 583 epochs is = 0.1005999886227821\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.1005999886227821\n",
      "learning rate for this epoch =  0.10175432217862923\n",
      "Error on this batch = 0.05398442029101128\n",
      "Error on this batch = 0.08516297847745787\n",
      "Cost on val dataset after 584 epochs is = 0.10056807485140228\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.10056807485140228\n",
      "learning rate for this epoch =  0.10171073496701123\n",
      "Error on this batch = 0.05392951320363177\n",
      "Error on this batch = 0.08510288586194965\n",
      "Cost on val dataset after 585 epochs is = 0.10053626910399668\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.10053626910399668\n",
      "learning rate for this epoch =  0.10166724095023941\n",
      "Error on this batch = 0.05387477592503931\n",
      "Error on this batch = 0.08504298981719446\n",
      "Cost on val dataset after 586 epochs is = 0.10050457087195025\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.10050457087195025\n",
      "learning rate for this epoch =  0.10162383977025442\n",
      "Error on this batch = 0.05382020782530668\n",
      "Error on this batch = 0.08498328940608055\n",
      "Cost on val dataset after 587 epochs is = 0.10047297964831373\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.10047297964831373\n",
      "learning rate for this epoch =  0.10158053107098057\n",
      "Error on this batch = 0.0537658082773876\n",
      "Error on this batch = 0.08492378369493879\n",
      "Cost on val dataset after 588 epochs is = 0.10044149492781856\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.10044149492781856\n",
      "learning rate for this epoch =  0.10153731449831156\n",
      "Error on this batch = 0.05371157665708518\n",
      "Error on this batch = 0.0848644717535867\n",
      "Cost on val dataset after 589 epochs is = 0.1004101162068913\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.1004101162068913\n",
      "learning rate for this epoch =  0.1014941897000962\n",
      "Error on this batch = 0.05365751234302065\n",
      "Error on this batch = 0.08480535265537167\n",
      "Cost on val dataset after 590 epochs is = 0.10037884298366748\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.10037884298366748\n",
      "learning rate for this epoch =  0.10145115632612439\n",
      "Error on this batch = 0.053603614716602264\n",
      "Error on this batch = 0.08474642547721258\n",
      "Cost on val dataset after 591 epochs is = 0.10034767475800474\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.10034767475800474\n",
      "learning rate for this epoch =  0.10140821402811308\n",
      "Error on this batch = 0.05354988316199456\n",
      "Error on this batch = 0.08468768929964067\n",
      "Cost on val dataset after 592 epochs is = 0.10031661103149572\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.10031661103149572\n",
      "learning rate for this epoch =  0.10136536245969245\n",
      "Error on this batch = 0.05349631706608779\n",
      "Error on this batch = 0.0846291432068391\n",
      "Cost on val dataset after 593 epochs is = 0.10028565130747992\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.10028565130747992\n",
      "learning rate for this epoch =  0.10132260127639228\n",
      "Error on this batch = 0.05344291581846743\n",
      "Error on this batch = 0.0845707862866811\n",
      "Cost on val dataset after 594 epochs is = 0.10025479509105557\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.10025479509105557\n",
      "learning rate for this epoch =  0.10127993013562818\n",
      "Error on this batch = 0.05338967881138434\n",
      "Error on this batch = 0.08451261763076748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 595 epochs is = 0.10022404188909059\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.10022404188909059\n",
      "learning rate for this epoch =  0.10123734869668825\n",
      "Error on this batch = 0.05333660543972453\n",
      "Error on this batch = 0.0844546363344623\n",
      "Cost on val dataset after 596 epochs is = 0.10019339121023303\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.10019339121023303\n",
      "learning rate for this epoch =  0.10119485662071964\n",
      "Error on this batch = 0.05328369510097973\n",
      "Error on this batch = 0.08439684149692823\n",
      "Cost on val dataset after 597 epochs is = 0.10016284256492114\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.10016284256492114\n",
      "learning rate for this epoch =  0.10115245357071535\n",
      "Error on this batch = 0.053230947195217815\n",
      "Error on this batch = 0.08433923222116001\n",
      "Cost on val dataset after 598 epochs is = 0.1001323954653928\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.1001323954653928\n",
      "learning rate for this epoch =  0.10111013921150111\n",
      "Error on this batch = 0.05317836112505345\n",
      "Error on this batch = 0.0842818076140172\n",
      "Cost on val dataset after 599 epochs is = 0.10010204942569456\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.10010204942569456\n",
      "learning rate for this epoch =  0.1010679132097223\n",
      "Error on this batch = 0.0531259362956191\n",
      "Error on this batch = 0.0842245667862559\n",
      "Cost on val dataset after 600 epochs is = 0.10007180396168992\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.10007180396168992\n",
      "learning rate for this epoch =  0.10102577523383117\n",
      "Error on this batch = 0.05307367211453624\n",
      "Error on this batch = 0.08416750885255893\n",
      "Cost on val dataset after 601 epochs is = 0.10004165859106737\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.10004165859106737\n",
      "learning rate for this epoch =  0.10098372495407393\n",
      "Error on this batch = 0.053021567991886454\n",
      "Error on this batch = 0.08411063293156534\n",
      "Cost on val dataset after 602 epochs is = 0.1000116128333478\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.1000116128333478\n",
      "learning rate for this epoch =  0.10094176204247814\n",
      "Error on this batch = 0.05296962334018313\n",
      "Error on this batch = 0.08405393814589865\n",
      "Cost on val dataset after 603 epochs is = 0.09998166620989155\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.09998166620989155\n",
      "learning rate for this epoch =  0.10089988617284017\n",
      "Error on this batch = 0.05291783757434318\n",
      "Error on this batch = 0.08399742362219378\n",
      "Cost on val dataset after 604 epochs is = 0.09995181824390476\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.09995181824390476\n",
      "learning rate for this epoch =  0.10085809702071269\n",
      "Error on this batch = 0.05286621011165882\n",
      "Error on this batch = 0.08394108849112358\n",
      "Cost on val dataset after 605 epochs is = 0.09992206846044546\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.09992206846044546\n",
      "learning rate for this epoch =  0.10081639426339235\n",
      "Error on this batch = 0.052814740371769774\n",
      "Error on this batch = 0.08388493188742337\n",
      "Cost on val dataset after 606 epochs is = 0.09989241638642916\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.09989241638642916\n",
      "learning rate for this epoch =  0.10077477757990758\n",
      "Error on this batch = 0.05276342777663563\n",
      "Error on this batch = 0.0838289529499152\n",
      "Cost on val dataset after 607 epochs is = 0.09986286155063391\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.09986286155063391\n",
      "learning rate for this epoch =  0.10073324665100637\n",
      "Error on this batch = 0.05271227175050818\n",
      "Error on this batch = 0.08377315082153071\n",
      "Cost on val dataset after 608 epochs is = 0.09983340348370505\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.09983340348370505\n",
      "learning rate for this epoch =  0.10069180115914433\n",
      "Error on this batch = 0.052661271719904236\n",
      "Error on this batch = 0.08371752464933291\n",
      "Cost on val dataset after 609 epochs is = 0.09980404171815939\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.09980404171815939\n",
      "learning rate for this epoch =  0.1006504407884727\n",
      "Error on this batch = 0.05261042711357849\n",
      "Error on this batch = 0.08366207358453713\n",
      "Cost on val dataset after 610 epochs is = 0.09977477578838914\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.09977477578838914\n",
      "learning rate for this epoch =  0.10060916522482655\n",
      "Error on this batch = 0.05255973736249666\n",
      "Error on this batch = 0.08360679678253082\n",
      "Cost on val dataset after 611 epochs is = 0.09974560523066521\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.09974560523066521\n",
      "learning rate for this epoch =  0.10056797415571314\n",
      "Error on this batch = 0.052509201899808663\n",
      "Error on this batch = 0.08355169340289229\n",
      "Cost on val dataset after 612 epochs is = 0.09971652958314042\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.09971652958314042\n",
      "learning rate for this epoch =  0.10052686727030014\n",
      "Error on this batch = 0.05245882016082232\n",
      "Error on this batch = 0.08349676260940864\n",
      "Cost on val dataset after 613 epochs is = 0.09968754838585206\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.09968754838585206\n",
      "learning rate for this epoch =  0.10048584425940424\n",
      "Error on this batch = 0.05240859158297696\n",
      "Error on this batch = 0.08344200357009263\n",
      "Cost on val dataset after 614 epochs is = 0.09965866118072413\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.09965866118072413\n",
      "learning rate for this epoch =  0.10044490481547967\n",
      "Error on this batch = 0.05235851560581738\n",
      "Error on this batch = 0.08338741545719841\n",
      "Cost on val dataset after 615 epochs is = 0.09962986751156941\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.09962986751156941\n",
      "learning rate for this epoch =  0.10040404863260693\n",
      "Error on this batch = 0.05230859167096815\n",
      "Error on this batch = 0.08333299744723636\n",
      "Cost on val dataset after 616 epochs is = 0.09960116692409088\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.09960116692409088\n",
      "learning rate for this epoch =  0.10036327540648149\n",
      "Error on this batch = 0.05225881922210785\n",
      "Error on this batch = 0.08327874872098728\n",
      "Cost on val dataset after 617 epochs is = 0.09957255896588309\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.09957255896588309\n",
      "learning rate for this epoch =  0.10032258483440272\n",
      "Error on this batch = 0.05220919770494391\n",
      "Error on this batch = 0.08322466846351517\n",
      "Cost on val dataset after 618 epochs is = 0.09954404318643294\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.09954404318643294\n",
      "learning rate for this epoch =  0.10028197661526282\n",
      "Error on this batch = 0.052159726567187335\n",
      "Error on this batch = 0.08317075586417931\n",
      "Cost on val dataset after 619 epochs is = 0.09951561913712043\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.09951561913712043\n",
      "learning rate for this epoch =  0.10024145044953589\n",
      "Error on this batch = 0.05211040525852813\n",
      "Error on this batch = 0.08311701011664542\n",
      "Cost on val dataset after 620 epochs is = 0.0994872863712188\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.0994872863712188\n",
      "learning rate for this epoch =  0.10020100603926707\n",
      "Error on this batch = 0.05206123323061039\n",
      "Error on this batch = 0.08306343041889601\n",
      "Cost on val dataset after 621 epochs is = 0.09945904444389468\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.09945904444389468\n",
      "learning rate for this epoch =  0.1001606430880618\n",
      "Error on this batch = 0.05201220993700839\n",
      "Error on this batch = 0.08301001597323948\n",
      "Cost on val dataset after 622 epochs is = 0.09943089291220765\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.09943089291220765\n",
      "learning rate for this epoch =  0.10012036130107511\n",
      "Error on this batch = 0.05196333483320228\n",
      "Error on this batch = 0.08295676598631868\n",
      "Cost on val dataset after 623 epochs is = 0.09940283133510988\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.09940283133510988\n",
      "learning rate for this epoch =  0.10008016038500113\n",
      "Error on this batch = 0.05191460737655459\n",
      "Error on this batch = 0.08290367966911844\n",
      "Cost on val dataset after 624 epochs is = 0.09937485927344525\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.09937485927344525\n",
      "learning rate for this epoch =  0.10004004004806248\n",
      "Error on this batch = 0.051866027026286655\n",
      "Error on this batch = 0.0828507562369723\n",
      "Cost on val dataset after 625 epochs is = 0.09934697628994825\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.09934697628994825\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 0.05181759324345581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08279799490956846\n",
      "Cost on val dataset after 626 epochs is = 0.09931918194924286\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.09931918194924286\n",
      "learning rate for this epoch =  0.09996003995206232\n",
      "Error on this batch = 0.05176930549093245\n",
      "Error on this batch = 0.08274539491095449\n",
      "Cost on val dataset after 627 epochs is = 0.09929147581784085\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.09929147581784085\n",
      "learning rate for this epoch =  0.0999201596169957\n",
      "Error on this batch = 0.051721163233377734\n",
      "Error on this batch = 0.08269295546954177\n",
      "Cost on val dataset after 628 epochs is = 0.09926385746414043\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.09926385746414043\n",
      "learning rate for this epoch =  0.09988035870903386\n",
      "Error on this batch = 0.05167316593722159\n",
      "Error on this batch = 0.08264067581810874\n",
      "Cost on val dataset after 629 epochs is = 0.09923632645842399\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.09923632645842399\n",
      "learning rate for this epoch =  0.09984063694388798\n",
      "Error on this batch = 0.05162531307064102\n",
      "Error on this batch = 0.0825885551938035\n",
      "Cost on val dataset after 630 epochs is = 0.09920888237285634\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.09920888237285634\n",
      "learning rate for this epoch =  0.09980099403873664\n",
      "Error on this batch = 0.05157760410353898\n",
      "Error on this batch = 0.08253659283814561\n",
      "Cost on val dataset after 631 epochs is = 0.09918152478148233\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.09918152478148233\n",
      "learning rate for this epoch =  0.099761429712216\n",
      "Error on this batch = 0.05153003850752349\n",
      "Error on this batch = 0.08248478799702698\n",
      "Cost on val dataset after 632 epochs is = 0.09915425326022444\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.09915425326022444\n",
      "learning rate for this epoch =  0.09972194368440992\n",
      "Error on this batch = 0.05148261575588714\n",
      "Error on this batch = 0.08243313992071213\n",
      "Cost on val dataset after 633 epochs is = 0.09912706738688042\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.09912706738688042\n",
      "learning rate for this epoch =  0.09968253567684038\n",
      "Error on this batch = 0.05143533532358735\n",
      "Error on this batch = 0.08238164786383781\n",
      "Cost on val dataset after 634 epochs is = 0.0990999667411205\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.0990999667411205\n",
      "learning rate for this epoch =  0.09964320541245761\n",
      "Error on this batch = 0.05138819668722672\n",
      "Error on this batch = 0.08233031108541156\n",
      "Cost on val dataset after 635 epochs is = 0.0990729509044846\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.0990729509044846\n",
      "learning rate for this epoch =  0.09960395261563074\n",
      "Error on this batch = 0.051341199325034045\n",
      "Error on this batch = 0.08227912884880974\n",
      "Cost on val dataset after 636 epochs is = 0.09904601946037962\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.09904601946037962\n",
      "learning rate for this epoch =  0.0995647770121382\n",
      "Error on this batch = 0.05129434271684578\n",
      "Error on this batch = 0.08222810042177489\n",
      "Cost on val dataset after 637 epochs is = 0.09901917199407625\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.09901917199407625\n",
      "learning rate for this epoch =  0.0995256783291583\n",
      "Error on this batch = 0.05124762634408814\n",
      "Error on this batch = 0.08217722507641234\n",
      "Cost on val dataset after 638 epochs is = 0.09899240809270615\n",
      "Initial Cost on Val dataset for this epoch 638 = 0.09899240809270615\n",
      "learning rate for this epoch =  0.09948665629526\n",
      "Error on this batch = 0.051201049689759394\n",
      "Error on this batch = 0.082126502089186\n",
      "Cost on val dataset after 639 epochs is = 0.09896572734525853\n",
      "Initial Cost on Val dataset for this epoch 639 = 0.09896572734525853\n",
      "learning rate for this epoch =  0.09944771064039355\n",
      "Error on this batch = 0.05115461223841311\n",
      "Error on this batch = 0.08207593074091377\n",
      "Cost on val dataset after 640 epochs is = 0.09893912934257741\n",
      "Initial Cost on Val dataset for this epoch 640 = 0.09893912934257741\n",
      "learning rate for this epoch =  0.09940884109588133\n",
      "Error on this batch = 0.05110831347614182\n",
      "Error on this batch = 0.08202551031676186\n",
      "Cost on val dataset after 641 epochs is = 0.09891261367735792\n",
      "Initial Cost on Val dataset for this epoch 641 = 0.09891261367735792\n",
      "learning rate for this epoch =  0.09937004739440881\n",
      "Error on this batch = 0.05106215289056104\n",
      "Error on this batch = 0.08197524010623901\n",
      "Cost on val dataset after 642 epochs is = 0.09888617994414342\n",
      "Initial Cost on Val dataset for this epoch 642 = 0.09888617994414342\n",
      "learning rate for this epoch =  0.09933132927001546\n",
      "Error on this batch = 0.051016129970794286\n",
      "Error on this batch = 0.08192511940318958\n",
      "Cost on val dataset after 643 epochs is = 0.09885982773932205\n",
      "Initial Cost on Val dataset for this epoch 643 = 0.09885982773932205\n",
      "learning rate for this epoch =  0.09929268645808582\n",
      "Error on this batch = 0.050970244207458375\n",
      "Error on this batch = 0.08187514750578627\n",
      "Cost on val dataset after 644 epochs is = 0.0988335566611235\n",
      "Initial Cost on Val dataset for this epoch 644 = 0.0988335566611235\n",
      "learning rate for this epoch =  0.09925411869534059\n",
      "Error on this batch = 0.050924495092649597\n",
      "Error on this batch = 0.08182532371652217\n",
      "Cost on val dataset after 645 epochs is = 0.0988073663096157\n",
      "Initial Cost on Val dataset for this epoch 645 = 0.0988073663096157\n",
      "learning rate for this epoch =  0.0992156257198279\n",
      "Error on this batch = 0.05087888211993032\n",
      "Error on this batch = 0.08177564734220225\n",
      "Cost on val dataset after 646 epochs is = 0.09878125628670163\n",
      "Initial Cost on Val dataset for this epoch 646 = 0.09878125628670163\n",
      "learning rate for this epoch =  0.09917720727091442\n",
      "Error on this batch = 0.05083340478431654\n",
      "Error on this batch = 0.08172611769393423\n",
      "Cost on val dataset after 647 epochs is = 0.09875522619611603\n",
      "Initial Cost on Val dataset for this epoch 647 = 0.09875522619611603\n",
      "learning rate for this epoch =  0.09913886308927693\n",
      "Error on this batch = 0.05078806258226589\n",
      "Error on this batch = 0.08167673408711888\n",
      "Cost on val dataset after 648 epochs is = 0.09872927564342218\n",
      "Initial Cost on Val dataset for this epoch 648 = 0.09872927564342218\n",
      "learning rate for this epoch =  0.09910059291689342\n",
      "Error on this batch = 0.050742855011666484\n",
      "Error on this batch = 0.08162749584143981\n",
      "Cost on val dataset after 649 epochs is = 0.0987034042360088\n",
      "Initial Cost on Val dataset for this epoch 649 = 0.0987034042360088\n",
      "learning rate for this epoch =  0.09906239649703485\n",
      "Error on this batch = 0.050697781571826306\n",
      "Error on this batch = 0.08157840228085263\n",
      "Cost on val dataset after 650 epochs is = 0.09867761158308695\n",
      "Initial Cost on Val dataset for this epoch 650 = 0.09867761158308695\n",
      "learning rate for this epoch =  0.09902427357425653\n",
      "Error on this batch = 0.05065284176346365\n",
      "Error on this batch = 0.08152945273357366\n",
      "Cost on val dataset after 651 epochs is = 0.09865189729568696\n",
      "Initial Cost on Val dataset for this epoch 651 = 0.09865189729568696\n",
      "learning rate for this epoch =  0.09898622389438974\n",
      "Error on this batch = 0.05060803508869803\n",
      "Error on this batch = 0.08148064653206813\n",
      "Cost on val dataset after 652 epochs is = 0.09862626098665551\n",
      "Initial Cost on Val dataset for this epoch 652 = 0.09862626098665551\n",
      "learning rate for this epoch =  0.09894824720453346\n",
      "Error on this batch = 0.05056336105104193\n",
      "Error on this batch = 0.08143198301303788\n",
      "Cost on val dataset after 653 epochs is = 0.09860070227065278\n",
      "Initial Cost on Val dataset for this epoch 653 = 0.09860070227065278\n",
      "learning rate for this epoch =  0.09891034325304611\n",
      "Error on this batch = 0.05051881915539345\n",
      "Error on this batch = 0.08138346151740841\n",
      "Cost on val dataset after 654 epochs is = 0.09857522076414967\n",
      "Initial Cost on Val dataset for this epoch 654 = 0.09857522076414967\n",
      "learning rate for this epoch =  0.09887251178953727\n",
      "Error on this batch = 0.05047440890802955\n",
      "Error on this batch = 0.08133508139031559\n",
      "Cost on val dataset after 655 epochs is = 0.09854981608542515\n",
      "Initial Cost on Val dataset for this epoch 655 = 0.09854981608542515\n",
      "learning rate for this epoch =  0.09883475256485971\n",
      "Error on this batch = 0.050430129816600354\n",
      "Error on this batch = 0.0812868419810921\n",
      "Cost on val dataset after 656 epochs is = 0.0985244878545637\n",
      "Initial Cost on Val dataset for this epoch 656 = 0.0985244878545637\n",
      "learning rate for this epoch =  0.09879706533110119\n",
      "Error on this batch = 0.05038598139012388\n",
      "Error on this batch = 0.0812387426432529\n",
      "Cost on val dataset after 657 epochs is = 0.09849923569345291\n",
      "Initial Cost on Val dataset for this epoch 657 = 0.09849923569345291\n",
      "learning rate for this epoch =  0.09875944984157659\n",
      "Error on this batch = 0.050341963138982086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08119078273448083\n",
      "Cost on val dataset after 658 epochs is = 0.09847405922578115\n",
      "Initial Cost on Val dataset for this epoch 658 = 0.09847405922578115\n",
      "learning rate for this epoch =  0.09872190585081982\n",
      "Error on this batch = 0.05029807457491736\n",
      "Error on this batch = 0.08114296161661139\n",
      "Cost on val dataset after 659 epochs is = 0.09844895807703555\n",
      "Initial Cost on Val dataset for this epoch 659 = 0.09844895807703555\n",
      "learning rate for this epoch =  0.09868443311457611\n",
      "Error on this batch = 0.05025431521102995\n",
      "Error on this batch = 0.08109527865561718\n",
      "Cost on val dataset after 660 epochs is = 0.0984239318744997\n",
      "Initial Cost on Val dataset for this epoch 660 = 0.0984239318744997\n",
      "learning rate for this epoch =  0.09864703138979418\n",
      "Error on this batch = 0.05021068456177634\n",
      "Error on this batch = 0.08104773322159221\n",
      "Cost on val dataset after 661 epochs is = 0.09839898024725224\n",
      "Initial Cost on Val dataset for this epoch 661 = 0.09839898024725224\n",
      "learning rate for this epoch =  0.09860970043461836\n",
      "Error on this batch = 0.05016718214296837\n",
      "Error on this batch = 0.08100032468873533\n",
      "Cost on val dataset after 662 epochs is = 0.0983741028261647\n",
      "Initial Cost on Val dataset for this epoch 662 = 0.0983741028261647\n",
      "learning rate for this epoch =  0.09857244000838114\n",
      "Error on this batch = 0.050123807471773335\n",
      "Error on this batch = 0.08095305243533364\n",
      "Cost on val dataset after 663 epochs is = 0.09834929924390032\n",
      "Initial Cost on Val dataset for this epoch 663 = 0.09834929924390032\n",
      "learning rate for this epoch =  0.09853524987159529\n",
      "Error on this batch = 0.05008056006671474\n",
      "Error on this batch = 0.08090591584374565\n",
      "Cost on val dataset after 664 epochs is = 0.09832456913491246\n",
      "Initial Cost on Val dataset for this epoch 664 = 0.09832456913491246\n",
      "learning rate for this epoch =  0.0984981297859465\n",
      "Error on this batch = 0.05003743944767404\n",
      "Error on this batch = 0.08085891430038349\n",
      "Cost on val dataset after 665 epochs is = 0.09829991213544347\n",
      "Initial Cost on Val dataset for this epoch 665 = 0.09829991213544347\n",
      "learning rate for this epoch =  0.09846107951428583\n",
      "Error on this batch = 0.04999444513589324\n",
      "Error on this batch = 0.08081204719569535\n",
      "Cost on val dataset after 666 epochs is = 0.09827532788352382\n",
      "Initial Cost on Val dataset for this epoch 666 = 0.09827532788352382\n",
      "learning rate for this epoch =  0.09842409882062221\n",
      "Error on this batch = 0.04995157665397832\n",
      "Error on this batch = 0.08076531392414749\n",
      "Cost on val dataset after 667 epochs is = 0.09825081601897105\n",
      "Initial Cost on Val dataset for this epoch 667 = 0.09825081601897105\n",
      "learning rate for this epoch =  0.09838718747011513\n",
      "Error on this batch = 0.04990883352590347\n",
      "Error on this batch = 0.08071871388420558\n",
      "Cost on val dataset after 668 epochs is = 0.09822637618338921\n",
      "Initial Cost on Val dataset for this epoch 668 = 0.09822637618338921\n",
      "learning rate for this epoch =  0.09835034522906724\n",
      "Error on this batch = 0.04986621527701624\n",
      "Error on this batch = 0.08067224647831614\n",
      "Cost on val dataset after 669 epochs is = 0.09820200802016839\n",
      "Initial Cost on Val dataset for this epoch 669 = 0.09820200802016839\n",
      "learning rate for this epoch =  0.09831357186491718\n",
      "Error on this batch = 0.04982372143404339\n",
      "Error on this batch = 0.0806259111128874\n",
      "Cost on val dataset after 670 epochs is = 0.09817771117448448\n",
      "Initial Cost on Val dataset for this epoch 670 = 0.09817771117448448\n",
      "learning rate for this epoch =  0.09827686714623232\n",
      "Error on this batch = 0.049781351525097745\n",
      "Error on this batch = 0.08057970719826991\n",
      "Cost on val dataset after 671 epochs is = 0.09815348529329897\n",
      "Initial Cost on Val dataset for this epoch 671 = 0.09815348529329897\n",
      "learning rate for this epoch =  0.09824023084270153\n",
      "Error on this batch = 0.04973910507968562\n",
      "Error on this batch = 0.08053363414873715\n",
      "Cost on val dataset after 672 epochs is = 0.0981293300253591\n",
      "Initial Cost on Val dataset for this epoch 672 = 0.0981293300253591\n",
      "learning rate for this epoch =  0.09820366272512825\n",
      "Error on this batch = 0.049696981628715324\n",
      "Error on this batch = 0.08048769138246527\n",
      "Cost on val dataset after 673 epochs is = 0.0981052450211982\n",
      "Initial Cost on Val dataset for this epoch 673 = 0.0981052450211982\n",
      "learning rate for this epoch =  0.0981671625654233\n",
      "Error on this batch = 0.04965498070450616\n",
      "Error on this batch = 0.08044187832151313\n",
      "Cost on val dataset after 674 epochs is = 0.09808122993313603\n",
      "Initial Cost on Val dataset for this epoch 674 = 0.09808122993313603\n",
      "learning rate for this epoch =  0.09813073013659797\n",
      "Error on this batch = 0.0496131018407984\n",
      "Error on this batch = 0.08039619439180186\n",
      "Cost on val dataset after 675 epochs is = 0.09805728441527951\n",
      "Initial Cost on Val dataset for this epoch 675 = 0.09805728441527951\n",
      "learning rate for this epoch =  0.09809436521275706\n",
      "Error on this batch = 0.04957134457276388\n",
      "Error on this batch = 0.08035063902309403\n",
      "Cost on val dataset after 676 epochs is = 0.09803340812352347\n",
      "Initial Cost on Val dataset for this epoch 676 = 0.09803340812352347\n",
      "learning rate for this epoch =  0.09805806756909202\n",
      "Error on this batch = 0.049529708437017275\n",
      "Error on this batch = 0.0803052116489729\n",
      "Cost on val dataset after 677 epochs is = 0.09800960071555177\n",
      "Initial Cost on Val dataset for this epoch 677 = 0.09800960071555177\n",
      "learning rate for this epoch =  0.09802183698187408\n",
      "Error on this batch = 0.049488192971628264\n",
      "Error on this batch = 0.08025991170682106\n",
      "Cost on val dataset after 678 epochs is = 0.09798586185083834\n",
      "Initial Cost on Val dataset for this epoch 678 = 0.09798586185083834\n",
      "learning rate for this epoch =  0.09798567322844758\n",
      "Error on this batch = 0.04944679771613414\n",
      "Error on this batch = 0.08021473863779915\n",
      "Cost on val dataset after 679 epochs is = 0.09796219119064863\n",
      "Initial Cost on Val dataset for this epoch 679 = 0.09796219119064863\n",
      "learning rate for this epoch =  0.09794957608722307\n",
      "Error on this batch = 0.049405522211553164\n",
      "Error on this batch = 0.0801696918868241\n",
      "Cost on val dataset after 680 epochs is = 0.097938588398041\n",
      "Initial Cost on Val dataset for this epoch 680 = 0.097938588398041\n",
      "learning rate for this epoch =  0.09791354533767088\n",
      "Error on this batch = 0.049364366000398605\n",
      "Error on this batch = 0.08012477090254748\n",
      "Cost on val dataset after 681 epochs is = 0.0979150531378685\n",
      "Initial Cost on Val dataset for this epoch 681 = 0.0979150531378685\n",
      "learning rate for this epoch =  0.09787758076031428\n",
      "Error on this batch = 0.04932332862669318\n",
      "Error on this batch = 0.08007997513733323\n",
      "Cost on val dataset after 682 epochs is = 0.09789158507678061\n",
      "Initial Cost on Val dataset for this epoch 682 = 0.09789158507678061\n",
      "learning rate for this epoch =  0.09784168213672302\n",
      "Error on this batch = 0.04928240963598423\n",
      "Error on this batch = 0.08003530404723552\n",
      "Cost on val dataset after 683 epochs is = 0.0978681838832252\n",
      "Initial Cost on Val dataset for this epoch 683 = 0.0978681838832252\n",
      "learning rate for this epoch =  0.09780584924950686\n",
      "Error on this batch = 0.04924160857535938\n",
      "Error on this batch = 0.0799907570919763\n",
      "Cost on val dataset after 684 epochs is = 0.0978448492274506\n",
      "Initial Cost on Val dataset for this epoch 684 = 0.0978448492274506\n",
      "learning rate for this epoch =  0.09777008188230901\n",
      "Error on this batch = 0.04920092499346245\n",
      "Error on this batch = 0.07994633373492267\n",
      "Cost on val dataset after 685 epochs is = 0.09782158078150782\n",
      "Initial Cost on Val dataset for this epoch 685 = 0.09782158078150782\n",
      "learning rate for this epoch =  0.09773437981979974\n",
      "Error on this batch = 0.04916035844051016\n",
      "Error on this batch = 0.07990203344306386\n",
      "Cost on val dataset after 686 epochs is = 0.09779837821925293\n",
      "Initial Cost on Val dataset for this epoch 686 = 0.09779837821925293\n",
      "learning rate for this epoch =  0.09769874284767002\n",
      "Error on this batch = 0.049119908468309055\n",
      "Error on this batch = 0.07985785568698854\n",
      "Cost on val dataset after 687 epochs is = 0.09777524121634934\n",
      "Initial Cost on Val dataset for this epoch 687 = 0.09777524121634934\n",
      "learning rate for this epoch =  0.0976631707526253\n",
      "Error on this batch = 0.04907957463027274\n",
      "Error on this batch = 0.07981379994086116\n",
      "Cost on val dataset after 688 epochs is = 0.09775216945027046\n",
      "Initial Cost on Val dataset for this epoch 688 = 0.09775216945027046\n",
      "learning rate for this epoch =  0.09762766332237903\n",
      "Error on this batch = 0.04903935648143959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07976986568239919\n",
      "Cost on val dataset after 689 epochs is = 0.09772916260030222\n",
      "Initial Cost on Val dataset for this epoch 689 = 0.09772916260030222\n",
      "learning rate for this epoch =  0.09759222034564662\n",
      "Error on this batch = 0.04899925357849062\n",
      "Error on this batch = 0.07972605239284901\n",
      "Cost on val dataset after 690 epochs is = 0.09770622034754571\n",
      "Initial Cost on Val dataset for this epoch 690 = 0.09770622034754571\n",
      "learning rate for this epoch =  0.09755684161213918\n",
      "Error on this batch = 0.04895926547976779\n",
      "Error on this batch = 0.07968235955696266\n",
      "Cost on val dataset after 691 epochs is = 0.09768334237492006\n",
      "Initial Cost on Val dataset for this epoch 691 = 0.09768334237492006\n",
      "learning rate for this epoch =  0.09752152691255746\n",
      "Error on this batch = 0.04891939174529224\n",
      "Error on this batch = 0.07963878666297367\n",
      "Cost on val dataset after 692 epochs is = 0.09766052836716498\n",
      "Initial Cost on Val dataset for this epoch 692 = 0.09766052836716498\n",
      "learning rate for this epoch =  0.09748627603858566\n",
      "Error on this batch = 0.04887963193678271\n",
      "Error on this batch = 0.07959533320257318\n",
      "Cost on val dataset after 693 epochs is = 0.09763777801084378\n",
      "Initial Cost on Val dataset for this epoch 693 = 0.09763777801084378\n",
      "learning rate for this epoch =  0.09745108878288547\n",
      "Error on this batch = 0.048839985617674504\n",
      "Error on this batch = 0.07955199867088585\n",
      "Cost on val dataset after 694 epochs is = 0.097615090994346\n",
      "Initial Cost on Val dataset for this epoch 694 = 0.097615090994346\n",
      "learning rate for this epoch =  0.09741596493909016\n",
      "Error on this batch = 0.048800452353137826\n",
      "Error on this batch = 0.0795087825664454\n",
      "Cost on val dataset after 695 epochs is = 0.09759246700789036\n",
      "Initial Cost on Val dataset for this epoch 695 = 0.09759246700789036\n",
      "learning rate for this epoch =  0.09738090430179841\n",
      "Error on this batch = 0.04876103171009675\n",
      "Error on this batch = 0.07946568439117027\n",
      "Cost on val dataset after 696 epochs is = 0.09756990574352747\n",
      "Initial Cost on Val dataset for this epoch 696 = 0.09756990574352747\n",
      "learning rate for this epoch =  0.09734590666656863\n",
      "Error on this batch = 0.048721723257247634\n",
      "Error on this batch = 0.07942270365033897\n",
      "Cost on val dataset after 697 epochs is = 0.09754740689514269\n",
      "Initial Cost on Val dataset for this epoch 697 = 0.09754740689514269\n",
      "learning rate for this epoch =  0.09731097182991302\n",
      "Error on this batch = 0.04868252656507801\n",
      "Error on this batch = 0.07937983985256535\n",
      "Cost on val dataset after 698 epochs is = 0.09752497015845872\n",
      "Initial Cost on Val dataset for this epoch 698 = 0.09752497015845872\n",
      "learning rate for this epoch =  0.09727609958929176\n",
      "Error on this batch = 0.048643441205884916\n",
      "Error on this batch = 0.07933709250977368\n",
      "Cost on val dataset after 699 epochs is = 0.09750259523103844\n",
      "Initial Cost on Val dataset for this epoch 699 = 0.09750259523103844\n",
      "learning rate for this epoch =  0.09724128974310718\n",
      "Error on this batch = 0.04860446675379319\n",
      "Error on this batch = 0.07929446113717388\n",
      "Cost on val dataset after 700 epochs is = 0.0974802818122874\n",
      "Initial Cost on Val dataset for this epoch 700 = 0.0974802818122874\n",
      "learning rate for this epoch =  0.09720654209069819\n",
      "Error on this batch = 0.04856560278477362\n",
      "Error on this batch = 0.07925194525323598\n",
      "Cost on val dataset after 701 epochs is = 0.0974580296034563\n",
      "Initial Cost on Val dataset for this epoch 701 = 0.0974580296034563\n",
      "learning rate for this epoch =  0.09717185643233449\n",
      "Error on this batch = 0.048526848876660846\n",
      "Error on this batch = 0.07920954437966522\n",
      "Cost on val dataset after 702 epochs is = 0.09743583830764352\n",
      "Initial Cost on Val dataset for this epoch 702 = 0.09743583830764352\n",
      "learning rate for this epoch =  0.09713723256921088\n",
      "Error on this batch = 0.048488204609170714\n",
      "Error on this batch = 0.07916725804137657\n",
      "Cost on val dataset after 703 epochs is = 0.09741370762979724\n",
      "Initial Cost on Val dataset for this epoch 703 = 0.09741370762979724\n",
      "learning rate for this epoch =  0.09710267030344186\n",
      "Error on this batch = 0.048449669563917636\n",
      "Error on this batch = 0.07912508576646905\n",
      "Cost on val dataset after 704 epochs is = 0.09739163727671761\n",
      "Initial Cost on Val dataset for this epoch 704 = 0.09739163727671761\n",
      "learning rate for this epoch =  0.09706816943805581\n",
      "Error on this batch = 0.048411243324431405\n",
      "Error on this batch = 0.07908302708620032\n",
      "Cost on val dataset after 705 epochs is = 0.09736962695705882\n",
      "Initial Cost on Val dataset for this epoch 705 = 0.09736962695705882\n",
      "learning rate for this epoch =  0.09703372977698975\n",
      "Error on this batch = 0.04837292547617333\n",
      "Error on this batch = 0.07904108153496085\n",
      "Cost on val dataset after 706 epochs is = 0.0973476763813308\n",
      "Initial Cost on Val dataset for this epoch 706 = 0.0973476763813308\n",
      "learning rate for this epoch =  0.09699935112508366\n",
      "Error on this batch = 0.04833471560655252\n",
      "Error on this batch = 0.07899924865024813\n",
      "Cost on val dataset after 707 epochs is = 0.09732578526190085\n",
      "Initial Cost on Val dataset for this epoch 707 = 0.09732578526190085\n",
      "learning rate for this epoch =  0.09696503328807513\n",
      "Error on this batch = 0.04829661330494073\n",
      "Error on this batch = 0.07895752797264051\n",
      "Cost on val dataset after 708 epochs is = 0.09730395331299513\n",
      "Initial Cost on Val dataset for this epoch 708 = 0.09730395331299513\n",
      "learning rate for this epoch =  0.09693077607259398\n",
      "Error on this batch = 0.04825861816268777\n",
      "Error on this batch = 0.07891591904577137\n",
      "Cost on val dataset after 709 epochs is = 0.09728218025069979\n",
      "Initial Cost on Val dataset for this epoch 709 = 0.09728218025069979\n",
      "learning rate for this epoch =  0.09689657928615694\n",
      "Error on this batch = 0.04822072977313532\n",
      "Error on this batch = 0.07887442141630288\n",
      "Cost on val dataset after 710 epochs is = 0.09726046579296194\n",
      "Initial Cost on Val dataset for this epoch 710 = 0.09726046579296194\n",
      "learning rate for this epoch =  0.09686244273716216\n",
      "Error on this batch = 0.048182947731630725\n",
      "Error on this batch = 0.07883303463389957\n",
      "Cost on val dataset after 711 epochs is = 0.0972388096595904\n",
      "Initial Cost on Val dataset for this epoch 711 = 0.0972388096595904\n",
      "learning rate for this epoch =  0.09682836623488422\n",
      "Error on this batch = 0.04814527163553987\n",
      "Error on this batch = 0.0787917582512022\n",
      "Cost on val dataset after 712 epochs is = 0.09721721157225607\n",
      "Initial Cost on Val dataset for this epoch 712 = 0.09721721157225607\n",
      "learning rate for this epoch =  0.09679434958946864\n",
      "Error on this batch = 0.048107701084259526\n",
      "Error on this batch = 0.07875059182380102\n",
      "Cost on val dataset after 713 epochs is = 0.0971956712544923\n",
      "Initial Cost on Val dataset for this epoch 713 = 0.0971956712544923\n",
      "learning rate for this epoch =  0.09676039261192684\n",
      "Error on this batch = 0.0480702356792288\n",
      "Error on this batch = 0.0787095349102096\n",
      "Cost on val dataset after 714 epochs is = 0.09717418843169451\n",
      "Initial Cost on Val dataset for this epoch 714 = 0.09717418843169451\n",
      "learning rate for this epoch =  0.09672649511413095\n",
      "Error on this batch = 0.048032875023940054\n",
      "Error on this batch = 0.07866858707183771\n",
      "Cost on val dataset after 715 epochs is = 0.09715276283111995\n",
      "Initial Cost on Val dataset for this epoch 715 = 0.09715276283111995\n",
      "learning rate for this epoch =  0.0966926569088086\n",
      "Error on this batch = 0.04799561872394879\n",
      "Error on this batch = 0.07862774787296505\n",
      "Cost on val dataset after 716 epochs is = 0.09713139418188708\n",
      "Initial Cost on Val dataset for this epoch 716 = 0.09713139418188708\n",
      "learning rate for this epoch =  0.09665887780953801\n",
      "Error on this batch = 0.04795846638688298\n",
      "Error on this batch = 0.0785870168807141\n",
      "Cost on val dataset after 717 epochs is = 0.09711008221497419\n",
      "Initial Cost on Val dataset for this epoch 717 = 0.09711008221497419\n",
      "learning rate for this epoch =  0.09662515763074277\n",
      "Error on this batch = 0.047921417622451355\n",
      "Error on this batch = 0.07854639366502345\n",
      "Cost on val dataset after 718 epochs is = 0.09708882666321839\n",
      "Initial Cost on Val dataset for this epoch 718 = 0.09708882666321839\n",
      "learning rate for this epoch =  0.09659149618768699\n",
      "Error on this batch = 0.04788447204245116\n",
      "Error on this batch = 0.07850587779862077\n",
      "Cost on val dataset after 719 epochs is = 0.09706762726131353\n",
      "Initial Cost on Val dataset for this epoch 719 = 0.09706762726131353\n",
      "learning rate for this epoch =  0.09655789329647017\n",
      "Error on this batch = 0.047847629260774606\n",
      "Error on this batch = 0.07846546885699582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 720 epochs is = 0.09704648374580836\n",
      "Initial Cost on Val dataset for this epoch 720 = 0.09704648374580836\n",
      "learning rate for this epoch =  0.09652434877402243\n",
      "Error on this batch = 0.04781088889341493\n",
      "Error on this batch = 0.07842516641837347\n",
      "Cost on val dataset after 721 epochs is = 0.09702539585510404\n",
      "Initial Cost on Val dataset for this epoch 721 = 0.09702539585510404\n",
      "learning rate for this epoch =  0.09649086243809947\n",
      "Error on this batch = 0.04777425055847127\n",
      "Error on this batch = 0.07838497006368639\n",
      "Cost on val dataset after 722 epochs is = 0.09700436332945124\n",
      "Initial Cost on Val dataset for this epoch 722 = 0.09700436332945124\n",
      "learning rate for this epoch =  0.09645743410727778\n",
      "Error on this batch = 0.047737713876152645\n",
      "Error on this batch = 0.07834487937654809\n",
      "Cost on val dataset after 723 epochs is = 0.0969833859109469\n",
      "Initial Cost on Val dataset for this epoch 723 = 0.0969833859109469\n",
      "learning rate for this epoch =  0.09642406360094986\n",
      "Error on this batch = 0.04770127846878122\n",
      "Error on this batch = 0.07830489394322551\n",
      "Cost on val dataset after 724 epochs is = 0.09696246334353081\n",
      "Initial Cost on Val dataset for this epoch 724 = 0.09696246334353081\n",
      "learning rate for this epoch =  0.09639075073931928\n",
      "Error on this batch = 0.04766494396079448\n",
      "Error on this batch = 0.07826501335261196\n",
      "Cost on val dataset after 725 epochs is = 0.09694159537298143\n",
      "Initial Cost on Val dataset for this epoch 725 = 0.09694159537298143\n",
      "learning rate for this epoch =  0.09635749534339606\n",
      "Error on this batch = 0.04762870997874666\n",
      "Error on this batch = 0.07822523719619963\n",
      "Cost on val dataset after 726 epochs is = 0.09692078174691177\n",
      "Initial Cost on Val dataset for this epoch 726 = 0.09692078174691177\n",
      "learning rate for this epoch =  0.0963242972349919\n",
      "Error on this batch = 0.047592576151309046\n",
      "Error on this batch = 0.07818556506805252\n",
      "Cost on val dataset after 727 epochs is = 0.09690002221476426\n",
      "Initial Cost on Val dataset for this epoch 727 = 0.09690002221476426\n",
      "learning rate for this epoch =  0.09629115623671548\n",
      "Error on this batch = 0.04755654210926941\n",
      "Error on this batch = 0.07814599656477886\n",
      "Cost on val dataset after 728 epochs is = 0.09687931652780585\n",
      "Initial Cost on Val dataset for this epoch 728 = 0.09687931652780585\n",
      "learning rate for this epoch =  0.09625807217196783\n",
      "Error on this batch = 0.047520607485530934\n",
      "Error on this batch = 0.07810653128550397\n",
      "Cost on val dataset after 729 epochs is = 0.09685866443912243\n",
      "Initial Cost on Val dataset for this epoch 729 = 0.09685866443912243\n",
      "learning rate for this epoch =  0.09622504486493763\n",
      "Error on this batch = 0.047484771915109504\n",
      "Error on this batch = 0.07806716883184282\n",
      "Cost on val dataset after 730 epochs is = 0.09683806570361267\n",
      "Initial Cost on Val dataset for this epoch 730 = 0.09683806570361267\n",
      "learning rate for this epoch =  0.09619207414059677\n",
      "Error on this batch = 0.047449035035130774\n",
      "Error on this batch = 0.07802790880787266\n",
      "Cost on val dataset after 731 epochs is = 0.09681752007798172\n",
      "Initial Cost on Val dataset for this epoch 731 = 0.09681752007798172\n",
      "learning rate for this epoch =  0.09615915982469565\n",
      "Error on this batch = 0.047413396484825884\n",
      "Error on this batch = 0.07798875082010569\n",
      "Cost on val dataset after 732 epochs is = 0.09679702732073445\n",
      "Initial Cost on Val dataset for this epoch 732 = 0.09679702732073445\n",
      "learning rate for this epoch =  0.09612630174375877\n",
      "Error on this batch = 0.047377855905526636\n",
      "Error on this batch = 0.07794969447746179\n",
      "Cost on val dataset after 733 epochs is = 0.09677658719216814\n",
      "Initial Cost on Val dataset for this epoch 733 = 0.09677658719216814\n",
      "learning rate for this epoch =  0.09609349972508012\n",
      "Error on this batch = 0.04734241294065953\n",
      "Error on this batch = 0.07791073939124112\n",
      "Cost on val dataset after 734 epochs is = 0.09675619945436507\n",
      "Initial Cost on Val dataset for this epoch 734 = 0.09675619945436507\n",
      "learning rate for this epoch =  0.09606075359671883\n",
      "Error on this batch = 0.047307067235739124\n",
      "Error on this batch = 0.07787188517509694\n",
      "Cost on val dataset after 735 epochs is = 0.09673586387118431\n",
      "Initial Cost on Val dataset for this epoch 735 = 0.09673586387118431\n",
      "learning rate for this epoch =  0.09602806318749467\n",
      "Error on this batch = 0.04727181843836047\n",
      "Error on this batch = 0.07783313144500824\n",
      "Cost on val dataset after 736 epochs is = 0.0967155802082534\n",
      "Initial Cost on Val dataset for this epoch 736 = 0.0967155802082534\n",
      "learning rate for this epoch =  0.09599542832698374\n",
      "Error on this batch = 0.04723666619819083\n",
      "Error on this batch = 0.07779447781925258\n",
      "Cost on val dataset after 737 epochs is = 0.09669534823295962\n",
      "Initial Cost on Val dataset for this epoch 737 = 0.09669534823295962\n",
      "learning rate for this epoch =  0.095962848845514\n",
      "Error on this batch = 0.047201610166960374\n",
      "Error on this batch = 0.07775592391837899\n",
      "Cost on val dataset after 738 epochs is = 0.0966751677144408\n",
      "Initial Cost on Val dataset for this epoch 738 = 0.0966751677144408\n",
      "learning rate for this epoch =  0.09593032457416101\n",
      "Error on this batch = 0.04716664999845252\n",
      "Error on this batch = 0.0777174693651808\n",
      "Cost on val dataset after 739 epochs is = 0.09665503842357573\n",
      "Initial Cost on Val dataset for this epoch 739 = 0.09665503842357573\n",
      "learning rate for this epoch =  0.09589785534474361\n",
      "Error on this batch = 0.047131785348492945\n",
      "Error on this batch = 0.07767911378466856\n",
      "Cost on val dataset after 740 epochs is = 0.0966349601329743\n",
      "Initial Cost on Val dataset for this epoch 740 = 0.0966349601329743\n",
      "learning rate for this epoch =  0.09586544098981967\n",
      "Error on this batch = 0.04709701587493838\n",
      "Error on this batch = 0.07764085680404322\n",
      "Cost on val dataset after 741 epochs is = 0.0966149326169672\n",
      "Initial Cost on Val dataset for this epoch 741 = 0.0966149326169672\n",
      "learning rate for this epoch =  0.09583308134268179\n",
      "Error on this batch = 0.047062341237664417\n",
      "Error on this batch = 0.07760269805266905\n",
      "Cost on val dataset after 742 epochs is = 0.09659495565159527\n",
      "Initial Cost on Val dataset for this epoch 742 = 0.09659495565159527\n",
      "learning rate for this epoch =  0.09580077623735313\n",
      "Error on this batch = 0.04702776109855271\n",
      "Error on this batch = 0.077564637162047\n",
      "Cost on val dataset after 743 epochs is = 0.09657502901459863\n",
      "Initial Cost on Val dataset for this epoch 743 = 0.09657502901459863\n",
      "learning rate for this epoch =  0.09576852550858327\n",
      "Error on this batch = 0.04699327512147745\n",
      "Error on this batch = 0.07752667376578788\n",
      "Cost on val dataset after 744 epochs is = 0.09655515248540521\n",
      "Initial Cost on Val dataset for this epoch 744 = 0.09655515248540521\n",
      "learning rate for this epoch =  0.09573632899184395\n",
      "Error on this batch = 0.04695888297229145\n",
      "Error on this batch = 0.07748880749958566\n",
      "Cost on val dataset after 745 epochs is = 0.09653532584511927\n",
      "Initial Cost on Val dataset for this epoch 745 = 0.09653532584511927\n",
      "learning rate for this epoch =  0.09570418652332507\n",
      "Error on this batch = 0.04692458431881119\n",
      "Error on this batch = 0.0774510380011912\n",
      "Cost on val dataset after 746 epochs is = 0.0965155488765093\n",
      "Initial Cost on Val dataset for this epoch 746 = 0.0965155488765093\n",
      "learning rate for this epoch =  0.0956720979399305\n",
      "Error on this batch = 0.046890378830801716\n",
      "Error on this batch = 0.07741336491038571\n",
      "Cost on val dataset after 747 epochs is = 0.09649582136399593\n",
      "Initial Cost on Val dataset for this epoch 747 = 0.09649582136399593\n",
      "learning rate for this epoch =  0.0956400630792741\n",
      "Error on this batch = 0.04685626617996086\n",
      "Error on this batch = 0.07737578786895438\n",
      "Cost on val dataset after 748 epochs is = 0.0964761430936393\n",
      "Initial Cost on Val dataset for this epoch 748 = 0.0964761430936393\n",
      "learning rate for this epoch =  0.09560808177967559\n",
      "Error on this batch = 0.04682224603990269\n",
      "Error on this batch = 0.07733830652066039\n",
      "Cost on val dataset after 749 epochs is = 0.09645651385312623\n",
      "Initial Cost on Val dataset for this epoch 749 = 0.09645651385312623\n",
      "learning rate for this epoch =  0.09557615388015658\n",
      "Error on this batch = 0.04678831808614088\n",
      "Error on this batch = 0.0773009205112188\n",
      "Cost on val dataset after 750 epochs is = 0.09643693343175717\n",
      "Initial Cost on Val dataset for this epoch 750 = 0.09643693343175717\n",
      "learning rate for this epoch =  0.09554427922043668\n",
      "Error on this batch = 0.046754481996071434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07726362948827074\n",
      "Cost on val dataset after 751 epochs is = 0.09641740162043283\n",
      "Initial Cost on Val dataset for this epoch 751 = 0.09641740162043283\n",
      "learning rate for this epoch =  0.0955124576409294\n",
      "Error on this batch = 0.046720737448954754\n",
      "Error on this batch = 0.07722643310135754\n",
      "Cost on val dataset after 752 epochs is = 0.09639791821164063\n",
      "Initial Cost on Val dataset for this epoch 752 = 0.09639791821164063\n",
      "learning rate for this epoch =  0.09548068898273834\n",
      "Error on this batch = 0.04668708412589766\n",
      "Error on this batch = 0.07718933100189528\n",
      "Cost on val dataset after 753 epochs is = 0.09637848299944092\n",
      "Initial Cost on Val dataset for this epoch 753 = 0.09637848299944092\n",
      "learning rate for this epoch =  0.09544897308765321\n",
      "Error on this batch = 0.04665352170983499\n",
      "Error on this batch = 0.07715232284314927\n",
      "Cost on val dataset after 754 epochs is = 0.09635909577945283\n",
      "Initial Cost on Val dataset for this epoch 754 = 0.09635909577945283\n",
      "learning rate for this epoch =  0.09541730979814601\n",
      "Error on this batch = 0.04662004988551059\n",
      "Error on this batch = 0.07711540828020888\n",
      "Cost on val dataset after 755 epochs is = 0.0963397563488402\n",
      "Initial Cost on Val dataset for this epoch 755 = 0.0963397563488402\n",
      "learning rate for this epoch =  0.09538569895736723\n",
      "Error on this batch = 0.04658666833945829\n",
      "Error on this batch = 0.07707858696996234\n",
      "Cost on val dataset after 756 epochs is = 0.09632046450629714\n",
      "Initial Cost on Val dataset for this epoch 756 = 0.09632046450629714\n",
      "learning rate for this epoch =  0.0953541404091419\n",
      "Error on this batch = 0.046553376759982355\n",
      "Error on this batch = 0.07704185857107192\n",
      "Cost on val dataset after 757 epochs is = 0.0963012200520333\n",
      "Initial Cost on Val dataset for this epoch 757 = 0.0963012200520333\n",
      "learning rate for this epoch =  0.09532263399796595\n",
      "Error on this batch = 0.04652017483713792\n",
      "Error on this batch = 0.07700522274394907\n",
      "Cost on val dataset after 758 epochs is = 0.09628202278775946\n",
      "Initial Cost on Val dataset for this epoch 758 = 0.09628202278775946\n",
      "learning rate for this epoch =  0.09529117956900235\n",
      "Error on this batch = 0.04648706226271096\n",
      "Error on this batch = 0.07696867915072997\n",
      "Cost on val dataset after 759 epochs is = 0.09626287251667229\n",
      "Initial Cost on Val dataset for this epoch 759 = 0.09626287251667229\n",
      "learning rate for this epoch =  0.09525977696807737\n",
      "Error on this batch = 0.046454038730198176\n",
      "Error on this batch = 0.07693222745525109\n",
      "Cost on val dataset after 760 epochs is = 0.09624376904343956\n",
      "Initial Cost on Val dataset for this epoch 760 = 0.09624376904343956\n",
      "learning rate for this epoch =  0.095228426041677\n",
      "Error on this batch = 0.046421103934786746\n",
      "Error on this batch = 0.07689586732302509\n",
      "Cost on val dataset after 761 epochs is = 0.09622471217418498\n",
      "Initial Cost on Val dataset for this epoch 761 = 0.09622471217418498\n",
      "learning rate for this epoch =  0.09519712663694305\n",
      "Error on this batch = 0.04638825757333384\n",
      "Error on this batch = 0.07685959842121667\n",
      "Cost on val dataset after 762 epochs is = 0.09620570171647297\n",
      "Initial Cost on Val dataset for this epoch 762 = 0.09620570171647297\n",
      "learning rate for this epoch =  0.09516587860166968\n",
      "Error on this batch = 0.04635549934434599\n",
      "Error on this batch = 0.07682342041861902\n",
      "Cost on val dataset after 763 epochs is = 0.09618673747929331\n",
      "Initial Cost on Val dataset for this epoch 763 = 0.09618673747929331\n",
      "learning rate for this epoch =  0.09513468178429965\n",
      "Error on this batch = 0.04632282894795841\n",
      "Error on this batch = 0.07678733298563005\n",
      "Cost on val dataset after 764 epochs is = 0.09616781927304587\n",
      "Initial Cost on Val dataset for this epoch 764 = 0.09616781927304587\n",
      "learning rate for this epoch =  0.0951035360339208\n",
      "Error on this batch = 0.046290246085914345\n",
      "Error on this batch = 0.07675133579422919\n",
      "Cost on val dataset after 765 epochs is = 0.09614894690952495\n",
      "Initial Cost on Val dataset for this epoch 765 = 0.09614894690952495\n",
      "learning rate for this epoch =  0.09507244120026234\n",
      "Error on this batch = 0.04625775046154406\n",
      "Error on this batch = 0.07671542851795403\n",
      "Cost on val dataset after 766 epochs is = 0.0961301202019041\n",
      "Initial Cost on Val dataset for this epoch 766 = 0.0961301202019041\n",
      "learning rate for this epoch =  0.09504139713369145\n",
      "Error on this batch = 0.046225341779744106\n",
      "Error on this batch = 0.07667961083187753\n",
      "Cost on val dataset after 767 epochs is = 0.09611133896472035\n",
      "Initial Cost on Val dataset for this epoch 767 = 0.09611133896472035\n",
      "learning rate for this epoch =  0.09501040368520958\n",
      "Error on this batch = 0.046193019746956436\n",
      "Error on this batch = 0.07664388241258538\n",
      "Cost on val dataset after 768 epochs is = 0.09609260301385869\n",
      "Initial Cost on Val dataset for this epoch 768 = 0.09609260301385869\n",
      "learning rate for this epoch =  0.09497946070644907\n",
      "Error on this batch = 0.04616078407114749\n",
      "Error on this batch = 0.0766082429381532\n",
      "Cost on val dataset after 769 epochs is = 0.0960739121665367\n",
      "Initial Cost on Val dataset for this epoch 769 = 0.0960739121665367\n",
      "learning rate for this epoch =  0.09494856804966957\n",
      "Error on this batch = 0.046128634461787464\n",
      "Error on this batch = 0.07657269208812459\n",
      "Cost on val dataset after 770 epochs is = 0.09605526624128878\n",
      "Initial Cost on Val dataset for this epoch 770 = 0.09605526624128878\n",
      "learning rate for this epoch =  0.09491772556775467\n",
      "Error on this batch = 0.046096570629829275\n",
      "Error on this batch = 0.0765372295434889\n",
      "Cost on val dataset after 771 epochs is = 0.09603666505795085\n",
      "Initial Cost on Val dataset for this epoch 771 = 0.09603666505795085\n",
      "learning rate for this epoch =  0.09488693311420834\n",
      "Error on this batch = 0.0460645922876881\n",
      "Error on this batch = 0.07650185498665939\n",
      "Cost on val dataset after 772 epochs is = 0.09601810843764462\n",
      "Initial Cost on Val dataset for this epoch 772 = 0.09601810843764462\n",
      "learning rate for this epoch =  0.0948561905431516\n",
      "Error on this batch = 0.046032699149220535\n",
      "Error on this batch = 0.07646656810145162\n",
      "Cost on val dataset after 773 epochs is = 0.09599959620276236\n",
      "Initial Cost on Val dataset for this epoch 773 = 0.09599959620276236\n",
      "learning rate for this epoch =  0.09482549770931908\n",
      "Error on this batch = 0.04600089092970422\n",
      "Error on this batch = 0.07643136857306232\n",
      "Cost on val dataset after 774 epochs is = 0.09598112817695124\n",
      "Initial Cost on Val dataset for this epoch 774 = 0.09598112817695124\n",
      "learning rate for this epoch =  0.09479485446805574\n",
      "Error on this batch = 0.04596916734581709\n",
      "Error on this batch = 0.07639625608804791\n",
      "Cost on val dataset after 775 epochs is = 0.0959627041850983\n",
      "Initial Cost on Val dataset for this epoch 775 = 0.0959627041850983\n",
      "learning rate for this epoch =  0.09476426067531338\n",
      "Error on this batch = 0.04593752811561736\n",
      "Error on this batch = 0.07636123033430385\n",
      "Cost on val dataset after 776 epochs is = 0.09594432405331488\n",
      "Initial Cost on Val dataset for this epoch 776 = 0.09594432405331488\n",
      "learning rate for this epoch =  0.0947337161876474\n",
      "Error on this batch = 0.04590597295852309\n",
      "Error on this batch = 0.07632629100104381\n",
      "Cost on val dataset after 777 epochs is = 0.09592598760892165\n",
      "Initial Cost on Val dataset for this epoch 777 = 0.09592598760892165\n",
      "learning rate for this epoch =  0.09470322086221351\n",
      "Error on this batch = 0.045874501595292216\n",
      "Error on this batch = 0.07629143777877945\n",
      "Cost on val dataset after 778 epochs is = 0.0959076946804334\n",
      "Initial Cost on Val dataset for this epoch 778 = 0.0959076946804334\n",
      "learning rate for this epoch =  0.09467277455676439\n",
      "Error on this batch = 0.045843113748002685\n",
      "Error on this batch = 0.07625667035929996\n",
      "Cost on val dataset after 779 epochs is = 0.09588944509754409\n",
      "Initial Cost on Val dataset for this epoch 779 = 0.09588944509754409\n",
      "learning rate for this epoch =  0.0946423771296465\n",
      "Error on this batch = 0.045811809140032744\n",
      "Error on this batch = 0.07622198843565232\n",
      "Cost on val dataset after 780 epochs is = 0.09587123869111194\n",
      "Initial Cost on Val dataset for this epoch 780 = 0.09587123869111194\n",
      "learning rate for this epoch =  0.09461202843979676\n",
      "Error on this batch = 0.04578058749604129\n",
      "Error on this batch = 0.07618739170212149\n",
      "Cost on val dataset after 781 epochs is = 0.09585307529314475\n",
      "Initial Cost on Val dataset for this epoch 781 = 0.09585307529314475\n",
      "learning rate for this epoch =  0.09458172834673945\n",
      "Error on this batch = 0.04574944854194847\n",
      "Error on this batch = 0.07615287985421092\n",
      "Cost on val dataset after 782 epochs is = 0.09583495473678513\n",
      "Initial Cost on Val dataset for this epoch 782 = 0.09583495473678513\n",
      "learning rate for this epoch =  0.09455147671058287\n",
      "Error on this batch = 0.045718392004916834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07611845258862336\n",
      "Cost on val dataset after 783 epochs is = 0.0958168768562961\n",
      "Initial Cost on Val dataset for this epoch 783 = 0.0958168768562961\n",
      "learning rate for this epoch =  0.09452127339201631\n",
      "Error on this batch = 0.045687417613331914\n",
      "Error on this batch = 0.07608410960324187\n",
      "Cost on val dataset after 784 epochs is = 0.09579884148704669\n",
      "Initial Cost on Val dataset for this epoch 784 = 0.09579884148704669\n",
      "learning rate for this epoch =  0.0944911182523068\n",
      "Error on this batch = 0.04565652509678378\n",
      "Error on this batch = 0.07604985059711095\n",
      "Cost on val dataset after 785 epochs is = 0.09578084846549777\n",
      "Initial Cost on Val dataset for this epoch 785 = 0.09578084846549777\n",
      "learning rate for this epoch =  0.09446101115329605\n",
      "Error on this batch = 0.04562571418604842\n",
      "Error on this batch = 0.07601567527041811\n",
      "Cost on val dataset after 786 epochs is = 0.09576289762918791\n",
      "Initial Cost on Val dataset for this epoch 786 = 0.09576289762918791\n",
      "learning rate for this epoch =  0.09443095195739727\n",
      "Error on this batch = 0.04559498461306921\n",
      "Error on this batch = 0.0759815833244756\n",
      "Cost on val dataset after 787 epochs is = 0.09574498881671954\n",
      "Initial Cost on Val dataset for this epoch 787 = 0.09574498881671954\n",
      "learning rate for this epoch =  0.09440094052759214\n",
      "Error on this batch = 0.04556433611093907\n",
      "Error on this batch = 0.07594757446170236\n",
      "Cost on val dataset after 788 epochs is = 0.09572712186774529\n",
      "Initial Cost on Val dataset for this epoch 788 = 0.09572712186774529\n",
      "learning rate for this epoch =  0.09437097672742772\n",
      "Error on this batch = 0.045533768413882444\n",
      "Error on this batch = 0.07591364838560613\n",
      "Cost on val dataset after 789 epochs is = 0.09570929662295423\n",
      "Initial Cost on Val dataset for this epoch 789 = 0.09570929662295423\n",
      "learning rate for this epoch =  0.09434106042101341\n",
      "Error on this batch = 0.04550328125723759\n",
      "Error on this batch = 0.07587980480076599\n",
      "Cost on val dataset after 790 epochs is = 0.09569151292405866\n",
      "Initial Cost on Val dataset for this epoch 790 = 0.09569151292405866\n",
      "learning rate for this epoch =  0.09431119147301793\n",
      "Error on this batch = 0.0454728743774392\n",
      "Error on this batch = 0.07584604341281499\n",
      "Cost on val dataset after 791 epochs is = 0.09567377061378089\n",
      "Initial Cost on Val dataset for this epoch 791 = 0.09567377061378089\n",
      "learning rate for this epoch =  0.09428136974866627\n",
      "Error on this batch = 0.0454425475120012\n",
      "Error on this batch = 0.07581236392842311\n",
      "Cost on val dataset after 792 epochs is = 0.09565606953584012\n",
      "Initial Cost on Val dataset for this epoch 792 = 0.09565606953584012\n",
      "learning rate for this epoch =  0.09425159511373676\n",
      "Error on this batch = 0.04541230039949969\n",
      "Error on this batch = 0.07577876605528029\n",
      "Cost on val dataset after 793 epochs is = 0.0956384095349397\n",
      "Initial Cost on Val dataset for this epoch 793 = 0.0956384095349397\n",
      "learning rate for this epoch =  0.09422186743455808\n",
      "Error on this batch = 0.04538213277955631\n",
      "Error on this batch = 0.07574524950207995\n",
      "Cost on val dataset after 794 epochs is = 0.09562079045675442\n",
      "Initial Cost on Val dataset for this epoch 794 = 0.09562079045675442\n",
      "learning rate for this epoch =  0.0941921865780063\n",
      "Error on this batch = 0.045352044392821644\n",
      "Error on this batch = 0.07571181397850263\n",
      "Cost on val dataset after 795 epochs is = 0.09560321214791814\n",
      "Initial Cost on Val dataset for this epoch 795 = 0.09560321214791814\n",
      "learning rate for this epoch =  0.09416255241150198\n",
      "Error on this batch = 0.04532203498095894\n",
      "Error on this batch = 0.07567845919519965\n",
      "Cost on val dataset after 796 epochs is = 0.09558567445601146\n",
      "Initial Cost on Val dataset for this epoch 796 = 0.09558567445601146\n",
      "learning rate for this epoch =  0.09413296480300724\n",
      "Error on this batch = 0.04529210428662804\n",
      "Error on this batch = 0.0756451848637775\n",
      "Cost on val dataset after 797 epochs is = 0.09556817722954973\n",
      "Initial Cost on Val dataset for this epoch 797 = 0.09556817722954973\n",
      "learning rate for this epoch =  0.09410342362102285\n",
      "Error on this batch = 0.04526225205346957\n",
      "Error on this batch = 0.07561199069678196\n",
      "Cost on val dataset after 798 epochs is = 0.09555072031797113\n",
      "Initial Cost on Val dataset for this epoch 798 = 0.09555072031797113\n",
      "learning rate for this epoch =  0.09407392873458542\n",
      "Error on this batch = 0.04523247802608938\n",
      "Error on this batch = 0.07557887640768284\n",
      "Cost on val dataset after 799 epochs is = 0.09553330357162507\n",
      "Initial Cost on Val dataset for this epoch 799 = 0.09553330357162507\n",
      "learning rate for this epoch =  0.09404448001326453\n",
      "Error on this batch = 0.045202781950043146\n",
      "Error on this batch = 0.07554584171085851\n",
      "Cost on val dataset after 800 epochs is = 0.09551592684176075\n",
      "Initial Cost on Val dataset for this epoch 800 = 0.09551592684176075\n",
      "learning rate for this epoch =  0.09401507732715984\n",
      "Error on this batch = 0.04517316357182103\n",
      "Error on this batch = 0.07551288632158143\n",
      "Cost on val dataset after 801 epochs is = 0.09549858998051583\n",
      "Initial Cost on Val dataset for this epoch 801 = 0.09549858998051583\n",
      "learning rate for this epoch =  0.09398572054689833\n",
      "Error on this batch = 0.04514362263883305\n",
      "Error on this batch = 0.07548000995600289\n",
      "Cost on val dataset after 802 epochs is = 0.09548129284090545\n",
      "Initial Cost on Val dataset for this epoch 802 = 0.09548129284090545\n",
      "learning rate for this epoch =  0.09395640954363149\n",
      "Error on this batch = 0.045114158899394054\n",
      "Error on this batch = 0.07544721233113888\n",
      "Cost on val dataset after 803 epochs is = 0.09546403527681145\n",
      "Initial Cost on Val dataset for this epoch 803 = 0.09546403527681145\n",
      "learning rate for this epoch =  0.09392714418903259\n",
      "Error on this batch = 0.045084772102709496\n",
      "Error on this batch = 0.07541449316485578\n",
      "Cost on val dataset after 804 epochs is = 0.09544681714297167\n",
      "Initial Cost on Val dataset for this epoch 804 = 0.09544681714297167\n",
      "learning rate for this epoch =  0.0938979243552938\n",
      "Error on this batch = 0.045055461998860846\n",
      "Error on this batch = 0.07538185217585629\n",
      "Cost on val dataset after 805 epochs is = 0.09542963829496945\n",
      "Initial Cost on Val dataset for this epoch 805 = 0.09542963829496945\n",
      "learning rate for this epoch =  0.0938687499151236\n",
      "Error on this batch = 0.04502622833879177\n",
      "Error on this batch = 0.07534928908366559\n",
      "Cost on val dataset after 806 epochs is = 0.09541249858922356\n",
      "Initial Cost on Val dataset for this epoch 806 = 0.09541249858922356\n",
      "learning rate for this epoch =  0.09383962074174393\n",
      "Error on this batch = 0.04499707087429395\n",
      "Error on this batch = 0.07531680360861798\n",
      "Cost on val dataset after 807 epochs is = 0.09539539788297813\n",
      "Initial Cost on Val dataset for this epoch 807 = 0.09539539788297813\n",
      "learning rate for this epoch =  0.09381053670888753\n",
      "Error on this batch = 0.044967989357993614\n",
      "Error on this batch = 0.07528439547184343\n",
      "Cost on val dataset after 808 epochs is = 0.09537833603429272\n",
      "Initial Cost on Val dataset for this epoch 808 = 0.09537833603429272\n",
      "learning rate for this epoch =  0.09378149769079532\n",
      "Error on this batch = 0.04493898354333796\n",
      "Error on this batch = 0.07525206439525452\n",
      "Cost on val dataset after 809 epochs is = 0.09536131290203295\n",
      "Initial Cost on Val dataset for this epoch 809 = 0.09536131290203295\n",
      "learning rate for this epoch =  0.09375250356221361\n",
      "Error on this batch = 0.0449100531845818\n",
      "Error on this batch = 0.0752198101015336\n",
      "Cost on val dataset after 810 epochs is = 0.09534432834586082\n",
      "Initial Cost on Val dataset for this epoch 810 = 0.09534432834586082\n",
      "learning rate for this epoch =  0.09372355419839151\n",
      "Error on this batch = 0.04488119803677454\n",
      "Error on this batch = 0.07518763231412023\n",
      "Cost on val dataset after 811 epochs is = 0.09532738222622568\n",
      "Initial Cost on Val dataset for this epoch 811 = 0.09532738222622568\n",
      "learning rate for this epoch =  0.09369464947507833\n",
      "Error on this batch = 0.04485241785574703\n",
      "Error on this batch = 0.07515553075719876\n",
      "Cost on val dataset after 812 epochs is = 0.09531047440435514\n",
      "Initial Cost on Val dataset for this epoch 812 = 0.09531047440435514\n",
      "learning rate for this epoch =  0.09366578926852086\n",
      "Error on this batch = 0.044823712398098986\n",
      "Error on this batch = 0.07512350515568614\n",
      "Cost on val dataset after 813 epochs is = 0.0952936047422463\n",
      "Initial Cost on Val dataset for this epoch 813 = 0.0952936047422463\n",
      "learning rate for this epoch =  0.09363697345546085\n",
      "Error on this batch = 0.04479508142118634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07509155523522011\n",
      "Cost on val dataset after 814 epochs is = 0.09527677310265706\n",
      "Initial Cost on Val dataset for this epoch 814 = 0.09527677310265706\n",
      "learning rate for this epoch =  0.09360820191313243\n",
      "Error on this batch = 0.04476652468310876\n",
      "Error on this batch = 0.07505968072214746\n",
      "Cost on val dataset after 815 epochs is = 0.09525997934909779\n",
      "Initial Cost on Val dataset for this epoch 815 = 0.09525997934909779\n",
      "learning rate for this epoch =  0.09357947451925948\n",
      "Error on this batch = 0.04473804194269745\n",
      "Error on this batch = 0.07502788134351257\n",
      "Cost on val dataset after 816 epochs is = 0.09524322334582293\n",
      "Initial Cost on Val dataset for this epoch 816 = 0.09524322334582293\n",
      "learning rate for this epoch =  0.09355079115205313\n",
      "Error on this batch = 0.04470963295950297\n",
      "Error on this batch = 0.07499615682704627\n",
      "Cost on val dataset after 817 epochs is = 0.09522650495782316\n",
      "Initial Cost on Val dataset for this epoch 817 = 0.09522650495782316\n",
      "learning rate for this epoch =  0.09352215169020917\n",
      "Error on this batch = 0.04468129749378336\n",
      "Error on this batch = 0.0749645069011547\n",
      "Cost on val dataset after 818 epochs is = 0.09520982405081732\n",
      "Initial Cost on Val dataset for this epoch 818 = 0.09520982405081732\n",
      "learning rate for this epoch =  0.09349355601290561\n",
      "Error on this batch = 0.04465303530649226\n",
      "Error on this batch = 0.07493293129490888\n",
      "Cost on val dataset after 819 epochs is = 0.0951931804912449\n",
      "Initial Cost on Val dataset for this epoch 819 = 0.0951931804912449\n",
      "learning rate for this epoch =  0.09346500399980012\n",
      "Error on this batch = 0.044624846159267345\n",
      "Error on this batch = 0.0749014297380338\n",
      "Cost on val dataset after 820 epochs is = 0.09517657414625835\n",
      "Initial Cost on Val dataset for this epoch 820 = 0.09517657414625835\n",
      "learning rate for this epoch =  0.09343649553102754\n",
      "Error on this batch = 0.04459672981441864\n",
      "Error on this batch = 0.07487000196089849\n",
      "Cost on val dataset after 821 epochs is = 0.09516000488371598\n",
      "Initial Cost on Val dataset for this epoch 821 = 0.09516000488371598\n",
      "learning rate for this epoch =  0.0934080304871974\n",
      "Error on this batch = 0.04456868603491744\n",
      "Error on this batch = 0.07483864769450571\n",
      "Cost on val dataset after 822 epochs is = 0.09514347257217462\n",
      "Initial Cost on Val dataset for this epoch 822 = 0.09514347257217462\n",
      "learning rate for this epoch =  0.09337960874939158\n",
      "Error on this batch = 0.04454071458438472\n",
      "Error on this batch = 0.07480736667048239\n",
      "Cost on val dataset after 823 epochs is = 0.0951269770808828\n",
      "Initial Cost on Val dataset for this epoch 823 = 0.0951269770808828\n",
      "learning rate for this epoch =  0.09335123019916165\n",
      "Error on this batch = 0.04451281522708032\n",
      "Error on this batch = 0.07477615862106983\n",
      "Cost on val dataset after 824 epochs is = 0.09511051827977376\n",
      "Initial Cost on Val dataset for this epoch 824 = 0.09511051827977376\n",
      "learning rate for this epoch =  0.09332289471852671\n",
      "Error on this batch = 0.04448498772789175\n",
      "Error on this batch = 0.07474502327911446\n",
      "Cost on val dataset after 825 epochs is = 0.09509409603945904\n",
      "Initial Cost on Val dataset for this epoch 825 = 0.09509409603945904\n",
      "learning rate for this epoch =  0.09329460218997072\n",
      "Error on this batch = 0.04445723185232344\n",
      "Error on this batch = 0.07471396037805875\n",
      "Cost on val dataset after 826 epochs is = 0.09507771023122179\n",
      "Initial Cost on Val dataset for this epoch 826 = 0.09507771023122179\n",
      "learning rate for this epoch =  0.09326635249644033\n",
      "Error on this batch = 0.04442954736648602\n",
      "Error on this batch = 0.07468296965193232\n",
      "Cost on val dataset after 827 epochs is = 0.09506136072701059\n",
      "Initial Cost on Val dataset for this epoch 827 = 0.09506136072701059\n",
      "learning rate for this epoch =  0.09323814552134235\n",
      "Error on this batch = 0.04440193403708552\n",
      "Error on this batch = 0.07465205083534324\n",
      "Cost on val dataset after 828 epochs is = 0.09504504739943327\n",
      "Initial Cost on Val dataset for this epoch 828 = 0.09504504739943327\n",
      "learning rate for this epoch =  0.09320998114854143\n",
      "Error on this batch = 0.044374391631413095\n",
      "Error on this batch = 0.07462120366346979\n",
      "Cost on val dataset after 829 epochs is = 0.09502877012175082\n",
      "Initial Cost on Val dataset for this epoch 829 = 0.09502877012175082\n",
      "learning rate for this epoch =  0.09318185926235777\n",
      "Error on this batch = 0.04434691991733446\n",
      "Error on this batch = 0.07459042787205204\n",
      "Cost on val dataset after 830 epochs is = 0.09501252876787171\n",
      "Initial Cost on Val dataset for this epoch 830 = 0.09501252876787171\n",
      "learning rate for this epoch =  0.09315377974756468\n",
      "Error on this batch = 0.04431951866327962\n",
      "Error on this batch = 0.07455972319738415\n",
      "Cost on val dataset after 831 epochs is = 0.09499632321234597\n",
      "Initial Cost on Val dataset for this epoch 831 = 0.09499632321234597\n",
      "learning rate for this epoch =  0.09312574248938638\n",
      "Error on this batch = 0.04429218763823275\n",
      "Error on this batch = 0.07452908937630649\n",
      "Cost on val dataset after 832 epochs is = 0.09498015333035983\n",
      "Initial Cost on Val dataset for this epoch 832 = 0.09498015333035983\n",
      "learning rate for this epoch =  0.0930977473734956\n",
      "Error on this batch = 0.044264926611721975\n",
      "Error on this batch = 0.07449852614619838\n",
      "Cost on val dataset after 833 epochs is = 0.09496401899773028\n",
      "Initial Cost on Val dataset for this epoch 833 = 0.09496401899773028\n",
      "learning rate for this epoch =  0.09306979428601131\n",
      "Error on this batch = 0.04423773535380945\n",
      "Error on this batch = 0.07446803324497057\n",
      "Cost on val dataset after 834 epochs is = 0.09494792009089961\n",
      "Initial Cost on Val dataset for this epoch 834 = 0.09494792009089961\n",
      "learning rate for this epoch =  0.0930418831134965\n",
      "Error on this batch = 0.04421061363508153\n",
      "Error on this batch = 0.07443761041105855\n",
      "Cost on val dataset after 835 epochs is = 0.09493185648693041\n",
      "Initial Cost on Val dataset for this epoch 835 = 0.09493185648693041\n",
      "learning rate for this epoch =  0.09301401374295587\n",
      "Error on this batch = 0.044183561226638836\n",
      "Error on this batch = 0.07440725738341554\n",
      "Cost on val dataset after 836 epochs is = 0.09491582806350066\n",
      "Initial Cost on Val dataset for this epoch 836 = 0.09491582806350066\n",
      "learning rate for this epoch =  0.09298618606183358\n",
      "Error on this batch = 0.04415657790008664\n",
      "Error on this batch = 0.07437697390150604\n",
      "Cost on val dataset after 837 epochs is = 0.09489983469889864\n",
      "Initial Cost on Val dataset for this epoch 837 = 0.09489983469889864\n",
      "learning rate for this epoch =  0.09295839995801103\n",
      "Error on this batch = 0.044129663427525216\n",
      "Error on this batch = 0.07434675970529961\n",
      "Cost on val dataset after 838 epochs is = 0.09488387627201827\n",
      "Initial Cost on Val dataset for this epoch 838 = 0.09488387627201827\n",
      "learning rate for this epoch =  0.09293065531980463\n",
      "Error on this batch = 0.04410281758154028\n",
      "Error on this batch = 0.07431661453526467\n",
      "Cost on val dataset after 839 epochs is = 0.09486795266235454\n",
      "Initial Cost on Val dataset for this epoch 839 = 0.09486795266235454\n",
      "learning rate for this epoch =  0.09290295203596367\n",
      "Error on this batch = 0.044076040135193624\n",
      "Error on this batch = 0.07428653813236276\n",
      "Cost on val dataset after 840 epochs is = 0.09485206374999891\n",
      "Initial Cost on Val dataset for this epoch 840 = 0.09485206374999891\n",
      "learning rate for this epoch =  0.09287528999566799\n",
      "Error on this batch = 0.044049330862013694\n",
      "Error on this batch = 0.07425653023804296\n",
      "Cost on val dataset after 841 epochs is = 0.09483620941563488\n",
      "Initial Cost on Val dataset for this epoch 841 = 0.09483620941563488\n",
      "learning rate for this epoch =  0.09284766908852593\n",
      "Error on this batch = 0.04402268953598634\n",
      "Error on this batch = 0.07422659059423635\n",
      "Cost on val dataset after 842 epochs is = 0.09482038954053382\n",
      "Initial Cost on Val dataset for this epoch 842 = 0.09482038954053382\n",
      "learning rate for this epoch =  0.09282008920457209\n",
      "Error on this batch = 0.043996115931545614\n",
      "Error on this batch = 0.07419671894335107\n",
      "Cost on val dataset after 843 epochs is = 0.09480460400655079\n",
      "Initial Cost on Val dataset for this epoch 843 = 0.09480460400655079\n",
      "learning rate for this epoch =  0.09279255023426522\n",
      "Error on this batch = 0.04396960982356474\n",
      "Error on this batch = 0.07416691502826735\n",
      "Cost on val dataset after 844 epochs is = 0.09478885269612032\n",
      "Initial Cost on Val dataset for this epoch 844 = 0.09478885269612032\n",
      "learning rate for this epoch =  0.09276505206848605\n",
      "Error on this batch = 0.04394317098734701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07413717859233268\n",
      "Cost on val dataset after 845 epochs is = 0.09477313549225258\n",
      "Initial Cost on Val dataset for this epoch 845 = 0.09477313549225258\n",
      "learning rate for this epoch =  0.09273759459853521\n",
      "Error on this batch = 0.04391679919861694\n",
      "Error on this batch = 0.07410750937935758\n",
      "Cost on val dataset after 846 epochs is = 0.09475745227852954\n",
      "Initial Cost on Val dataset for this epoch 846 = 0.09475745227852954\n",
      "learning rate for this epoch =  0.0927101777161311\n",
      "Error on this batch = 0.04389049423351121\n",
      "Error on this batch = 0.07407790713361122\n",
      "Cost on val dataset after 847 epochs is = 0.0947418029391011\n",
      "Initial Cost on Val dataset for this epoch 847 = 0.0947418029391011\n",
      "learning rate for this epoch =  0.09268280131340775\n",
      "Error on this batch = 0.043864255868570255\n",
      "Error on this batch = 0.07404837159981748\n",
      "Cost on val dataset after 848 epochs is = 0.09472618735868144\n",
      "Initial Cost on Val dataset for this epoch 848 = 0.09472618735868144\n",
      "learning rate for this epoch =  0.09265546528291284\n",
      "Error on this batch = 0.04383808388072927\n",
      "Error on this batch = 0.07401890252315116\n",
      "Cost on val dataset after 849 epochs is = 0.09471060542254552\n",
      "Initial Cost on Val dataset for this epoch 849 = 0.09471060542254552\n",
      "learning rate for this epoch =  0.09262816951760545\n",
      "Error on this batch = 0.043811978047309685\n",
      "Error on this batch = 0.07398949964923443\n",
      "Cost on val dataset after 850 epochs is = 0.09469505701652549\n",
      "Initial Cost on Val dataset for this epoch 850 = 0.09469505701652549\n",
      "learning rate for this epoch =  0.09260091391085426\n",
      "Error on this batch = 0.04378593814601068\n",
      "Error on this batch = 0.07396016272413346\n",
      "Cost on val dataset after 851 epochs is = 0.09467954202700732\n",
      "Initial Cost on Val dataset for this epoch 851 = 0.09467954202700732\n",
      "learning rate for this epoch =  0.09257369835643524\n",
      "Error on this batch = 0.04375996395490077\n",
      "Error on this batch = 0.07393089149435533\n",
      "Cost on val dataset after 852 epochs is = 0.09466406034092748\n",
      "Initial Cost on Val dataset for this epoch 852 = 0.09466406034092748\n",
      "learning rate for this epoch =  0.09254652274852981\n",
      "Error on this batch = 0.0437340552524094\n",
      "Error on this batch = 0.07390168570684516\n",
      "Cost on val dataset after 853 epochs is = 0.0946486118457697\n",
      "Initial Cost on Val dataset for this epoch 853 = 0.0946486118457697\n",
      "learning rate for this epoch =  0.0925193869817227\n",
      "Error on this batch = 0.043708211817318716\n",
      "Error on this batch = 0.07387254510898346\n",
      "Cost on val dataset after 854 epochs is = 0.09463319642956174\n",
      "Initial Cost on Val dataset for this epoch 854 = 0.09463319642956174\n",
      "learning rate for this epoch =  0.092492290951\n",
      "Error on this batch = 0.043682433428755336\n",
      "Error on this batch = 0.07384346944858355\n",
      "Cost on val dataset after 855 epochs is = 0.09461781398087236\n",
      "Initial Cost on Val dataset for this epoch 855 = 0.09461781398087236\n",
      "learning rate for this epoch =  0.09246523455174717\n",
      "Error on this batch = 0.043656719866182296\n",
      "Error on this batch = 0.07381445847388944\n",
      "Cost on val dataset after 856 epochs is = 0.09460246438880827\n",
      "Initial Cost on Val dataset for this epoch 856 = 0.09460246438880827\n",
      "learning rate for this epoch =  0.092438217679747\n",
      "Error on this batch = 0.043631070909391105\n",
      "Error on this batch = 0.07378551193357372\n",
      "Cost on val dataset after 857 epochs is = 0.0945871475430111\n",
      "Initial Cost on Val dataset for this epoch 857 = 0.0945871475430111\n",
      "learning rate for this epoch =  0.09241124023117771\n",
      "Error on this batch = 0.043605486338493656\n",
      "Error on this batch = 0.07375662957673568\n",
      "Cost on val dataset after 858 epochs is = 0.09457186333365468\n",
      "Initial Cost on Val dataset for this epoch 858 = 0.09457186333365468\n",
      "learning rate for this epoch =  0.09238430210261095\n",
      "Error on this batch = 0.043579965933914624\n",
      "Error on this batch = 0.07372781115289992\n",
      "Cost on val dataset after 859 epochs is = 0.09455661165144201\n",
      "Initial Cost on Val dataset for this epoch 859 = 0.09455661165144201\n",
      "learning rate for this epoch =  0.09235740319100984\n",
      "Error on this batch = 0.043554509476383625\n",
      "Error on this batch = 0.07369905641201457\n",
      "Cost on val dataset after 860 epochs is = 0.09454139238760258\n",
      "Initial Cost on Val dataset for this epoch 860 = 0.09454139238760258\n",
      "learning rate for this epoch =  0.09233054339372707\n",
      "Error on this batch = 0.04352911674692745\n",
      "Error on this batch = 0.07367036510445049\n",
      "Cost on val dataset after 861 epochs is = 0.09452620543388965\n",
      "Initial Cost on Val dataset for this epoch 861 = 0.09452620543388965\n",
      "learning rate for this epoch =  0.09230372260850297\n",
      "Error on this batch = 0.043503787526862896\n",
      "Error on this batch = 0.07364173698099989\n",
      "Cost on val dataset after 862 epochs is = 0.09451105068257754\n",
      "Initial Cost on Val dataset for this epoch 862 = 0.09451105068257754\n",
      "learning rate for this epoch =  0.09227694073346356\n",
      "Error on this batch = 0.0434785215977889\n",
      "Error on this batch = 0.0736131717928757\n",
      "Cost on val dataset after 863 epochs is = 0.09449592802645913\n",
      "Initial Cost on Val dataset for this epoch 863 = 0.09449592802645913\n",
      "learning rate for this epoch =  0.09225019766711869\n",
      "Error on this batch = 0.043453318741579566\n",
      "Error on this batch = 0.07358466929171095\n",
      "Cost on val dataset after 864 epochs is = 0.09448083735884315\n",
      "Initial Cost on Val dataset for this epoch 864 = 0.09448083735884315\n",
      "learning rate for this epoch =  0.09222349330836013\n",
      "Error on this batch = 0.04342817874037669\n",
      "Error on this batch = 0.0735562292295582\n",
      "Cost on val dataset after 865 epochs is = 0.09446577857355173\n",
      "Initial Cost on Val dataset for this epoch 865 = 0.09446577857355173\n",
      "learning rate for this epoch =  0.09219682755645973\n",
      "Error on this batch = 0.04340310137658277\n",
      "Error on this batch = 0.07352785135888952\n",
      "Cost on val dataset after 866 epochs is = 0.09445075156491796\n",
      "Initial Cost on Val dataset for this epoch 866 = 0.09445075156491796\n",
      "learning rate for this epoch =  0.09217020031106751\n",
      "Error on this batch = 0.04337808643285392\n",
      "Error on this batch = 0.07349953543259617\n",
      "Cost on val dataset after 867 epochs is = 0.09443575622778337\n",
      "Initial Cost on Val dataset for this epoch 867 = 0.09443575622778337\n",
      "learning rate for this epoch =  0.09214361147220981\n",
      "Error on this batch = 0.04335313369209292\n",
      "Error on this batch = 0.07347128120398899\n",
      "Cost on val dataset after 868 epochs is = 0.09442079245749568\n",
      "Initial Cost on Val dataset for this epoch 868 = 0.09442079245749568\n",
      "learning rate for this epoch =  0.09211706094028746\n",
      "Error on this batch = 0.0433282429374426\n",
      "Error on this batch = 0.0734430884267984\n",
      "Cost on val dataset after 869 epochs is = 0.09440586014990622\n",
      "Initial Cost on Val dataset for this epoch 869 = 0.09440586014990622\n",
      "learning rate for this epoch =  0.09209054861607395\n",
      "Error on this batch = 0.04330341395227892\n",
      "Error on this batch = 0.07341495685517516\n",
      "Cost on val dataset after 870 epochs is = 0.09439095920136781\n",
      "Initial Cost on Val dataset for this epoch 870 = 0.09439095920136781\n",
      "learning rate for this epoch =  0.0920640744007136\n",
      "Error on this batch = 0.04327864652020466\n",
      "Error on this batch = 0.0733868862436908\n",
      "Cost on val dataset after 871 epochs is = 0.09437608950873232\n",
      "Initial Cost on Val dataset for this epoch 871 = 0.09437608950873232\n",
      "learning rate for this epoch =  0.09203763819571976\n",
      "Error on this batch = 0.04325394042504274\n",
      "Error on this batch = 0.07335887634733866\n",
      "Cost on val dataset after 872 epochs is = 0.09436125096934858\n",
      "Initial Cost on Val dataset for this epoch 872 = 0.09436125096934858\n",
      "learning rate for this epoch =  0.09201123990297302\n",
      "Error on this batch = 0.043229295450830034\n",
      "Error on this batch = 0.07333092692153458\n",
      "Cost on val dataset after 873 epochs is = 0.09434644348105992\n",
      "Initial Cost on Val dataset for this epoch 873 = 0.09434644348105992\n",
      "learning rate for this epoch =  0.09198487942471935\n",
      "Error on this batch = 0.043204711381811124\n",
      "Error on this batch = 0.07330303772211826\n",
      "Cost on val dataset after 874 epochs is = 0.09433166694220213\n",
      "Initial Cost on Val dataset for this epoch 874 = 0.09433166694220213\n",
      "learning rate for this epoch =  0.09195855666356846\n",
      "Error on this batch = 0.04318018800243237\n",
      "Error on this batch = 0.0732752085053545\n",
      "Cost on val dataset after 875 epochs is = 0.09431692125160122\n",
      "Initial Cost on Val dataset for this epoch 875 = 0.09431692125160122\n",
      "learning rate for this epoch =  0.09193227152249185\n",
      "Error on this batch = 0.04315572509733571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07324743902793468\n",
      "Cost on val dataset after 876 epochs is = 0.0943022063085712\n",
      "Initial Cost on Val dataset for this epoch 876 = 0.0943022063085712\n",
      "learning rate for this epoch =  0.09190602390482124\n",
      "Error on this batch = 0.04313132245135311\n",
      "Error on this batch = 0.07321972904697821\n",
      "Cost on val dataset after 877 epochs is = 0.09428752201291199\n",
      "Initial Cost on Val dataset for this epoch 877 = 0.09428752201291199\n",
      "learning rate for this epoch =  0.09187981371424671\n",
      "Error on this batch = 0.04310697984950077\n",
      "Error on this batch = 0.07319207832003445\n",
      "Cost on val dataset after 878 epochs is = 0.09427286826490723\n",
      "Initial Cost on Val dataset for this epoch 878 = 0.09427286826490723\n",
      "learning rate for this epoch =  0.091853640854815\n",
      "Error on this batch = 0.04308269707697363\n",
      "Error on this batch = 0.07316448660508451\n",
      "Cost on val dataset after 879 epochs is = 0.09425824496532224\n",
      "Initial Cost on Val dataset for this epoch 879 = 0.09425824496532224\n",
      "learning rate for this epoch =  0.09182750523092773\n",
      "Error on this batch = 0.04305847391914003\n",
      "Error on this batch = 0.07313695366054336\n",
      "Cost on val dataset after 880 epochs is = 0.09424365201540183\n",
      "Initial Cost on Val dataset for this epoch 880 = 0.09424365201540183\n",
      "learning rate for this epoch =  0.0918014067473398\n",
      "Error on this batch = 0.04303431016153637\n",
      "Error on this batch = 0.07310947924526175\n",
      "Cost on val dataset after 881 epochs is = 0.09422908931686826\n",
      "Initial Cost on Val dataset for this epoch 881 = 0.09422908931686826\n",
      "learning rate for this epoch =  0.09177534530915758\n",
      "Error on this batch = 0.0430102055898621\n",
      "Error on this batch = 0.07308206311852877\n",
      "Cost on val dataset after 882 epochs is = 0.09421455677191903\n",
      "Initial Cost on Val dataset for this epoch 882 = 0.09421455677191903\n",
      "learning rate for this epoch =  0.09174932082183727\n",
      "Error on this batch = 0.04298615998997482\n",
      "Error on this batch = 0.07305470504007415\n",
      "Cost on val dataset after 883 epochs is = 0.094200054283225\n",
      "Initial Cost on Val dataset for this epoch 883 = 0.094200054283225\n",
      "learning rate for this epoch =  0.09172333319118318\n",
      "Error on this batch = 0.0429621731478854\n",
      "Error on this batch = 0.07302740477007064\n",
      "Cost on val dataset after 884 epochs is = 0.09418558175392812\n",
      "Initial Cost on Val dataset for this epoch 884 = 0.09418558175392812\n",
      "learning rate for this epoch =  0.0916973823233461\n",
      "Error on this batch = 0.042938244849753344\n",
      "Error on this batch = 0.07300016206913688\n",
      "Cost on val dataset after 885 epochs is = 0.09417113908763948\n",
      "Initial Cost on Val dataset for this epoch 885 = 0.09417113908763948\n",
      "learning rate for this epoch =  0.09167146812482159\n",
      "Error on this batch = 0.04291437488188241\n",
      "Error on this batch = 0.07297297669833999\n",
      "Cost on val dataset after 886 epochs is = 0.09415672618843708\n",
      "Initial Cost on Val dataset for this epoch 886 = 0.09415672618843708\n",
      "learning rate for this epoch =  0.09164559050244833\n",
      "Error on this batch = 0.04289056303071634\n",
      "Error on this batch = 0.0729458484191985\n",
      "Cost on val dataset after 887 epochs is = 0.094142342960864\n",
      "Initial Cost on Val dataset for this epoch 887 = 0.094142342960864\n",
      "learning rate for this epoch =  0.09161974936340654\n",
      "Error on this batch = 0.04286680908283449\n",
      "Error on this batch = 0.07291877699368532\n",
      "Cost on val dataset after 888 epochs is = 0.09412798930992607\n",
      "Initial Cost on Val dataset for this epoch 888 = 0.09412798930992607\n",
      "learning rate for this epoch =  0.09159394461521626\n",
      "Error on this batch = 0.042843112824948085\n",
      "Error on this batch = 0.07289176218423067\n",
      "Cost on val dataset after 889 epochs is = 0.09411366514108993\n",
      "Initial Cost on Val dataset for this epoch 889 = 0.09411366514108993\n",
      "learning rate for this epoch =  0.09156817616573577\n",
      "Error on this batch = 0.04281947404389632\n",
      "Error on this batch = 0.07286480375372537\n",
      "Cost on val dataset after 890 epochs is = 0.09409937036028089\n",
      "Initial Cost on Val dataset for this epoch 890 = 0.09409937036028089\n",
      "learning rate for this epoch =  0.09154244392315995\n",
      "Error on this batch = 0.042795892526642676\n",
      "Error on this batch = 0.07283790146552399\n",
      "Cost on val dataset after 891 epochs is = 0.09408510487388087\n",
      "Initial Cost on Val dataset for this epoch 891 = 0.09408510487388087\n",
      "learning rate for this epoch =  0.09151674779601875\n",
      "Error on this batch = 0.0427723680602716\n",
      "Error on this batch = 0.07281105508344816\n",
      "Cost on val dataset after 892 epochs is = 0.09407086858872626\n",
      "Initial Cost on Val dataset for this epoch 892 = 0.09407086858872626\n",
      "learning rate for this epoch =  0.0914910876931754\n",
      "Error on this batch = 0.04274890043198504\n",
      "Error on this batch = 0.07278426437179009\n",
      "Cost on val dataset after 893 epochs is = 0.09405666141210581\n",
      "Initial Cost on Val dataset for this epoch 893 = 0.09405666141210581\n",
      "learning rate for this epoch =  0.09146546352382512\n",
      "Error on this batch = 0.042725489429099435\n",
      "Error on this batch = 0.07275752909531578\n",
      "Cost on val dataset after 894 epochs is = 0.09404248325175861\n",
      "Initial Cost on Val dataset for this epoch 894 = 0.09404248325175861\n",
      "learning rate for this epoch =  0.09143987519749323\n",
      "Error on this batch = 0.042702134839042866\n",
      "Error on this batch = 0.07273084901926889\n",
      "Cost on val dataset after 895 epochs is = 0.09402833401587177\n",
      "Initial Cost on Val dataset for this epoch 895 = 0.09402833401587177\n",
      "learning rate for this epoch =  0.09141432262403383\n",
      "Error on this batch = 0.042678836449352206\n",
      "Error on this batch = 0.07270422390937405\n",
      "Cost on val dataset after 896 epochs is = 0.0940142136130784\n",
      "Initial Cost on Val dataset for this epoch 896 = 0.0940142136130784\n",
      "learning rate for this epoch =  0.09138880571362809\n",
      "Error on this batch = 0.042655594047670484\n",
      "Error on this batch = 0.07267765353184066\n",
      "Cost on val dataset after 897 epochs is = 0.09400012195245544\n",
      "Initial Cost on Val dataset for this epoch 897 = 0.09400012195245544\n",
      "learning rate for this epoch =  0.09136332437678274\n",
      "Error on this batch = 0.042632407421744775\n",
      "Error on this batch = 0.07265113765336662\n",
      "Cost on val dataset after 898 epochs is = 0.09398605894352147\n",
      "Initial Cost on Val dataset for this epoch 898 = 0.09398605894352147\n",
      "learning rate for this epoch =  0.09133787852432855\n",
      "Error on this batch = 0.042609276359423756\n",
      "Error on this batch = 0.07262467604114202\n",
      "Cost on val dataset after 899 epochs is = 0.09397202449623444\n",
      "Initial Cost on Val dataset for this epoch 899 = 0.09397202449623444\n",
      "learning rate for this epoch =  0.09131246806741879\n",
      "Error on this batch = 0.04258620064865587\n",
      "Error on this batch = 0.07259826846285304\n",
      "Cost on val dataset after 900 epochs is = 0.0939580185209896\n",
      "Initial Cost on Val dataset for this epoch 900 = 0.0939580185209896\n",
      "learning rate for this epoch =  0.09128709291752768\n",
      "Error on this batch = 0.04256318007748748\n",
      "Error on this batch = 0.07257191468668574\n",
      "Cost on val dataset after 901 epochs is = 0.09394404092861712\n",
      "Initial Cost on Val dataset for this epoch 901 = 0.09394404092861712\n",
      "learning rate for this epoch =  0.09126175298644894\n",
      "Error on this batch = 0.04254021443406126\n",
      "Error on this batch = 0.07254561448133001\n",
      "Cost on val dataset after 902 epochs is = 0.09393009163038003\n",
      "Initial Cost on Val dataset for this epoch 902 = 0.09393009163038003\n",
      "learning rate for this epoch =  0.09123644818629414\n",
      "Error on this batch = 0.04251730350661487\n",
      "Error on this batch = 0.07251936761598349\n",
      "Cost on val dataset after 903 epochs is = 0.09391617053797167\n",
      "Initial Cost on Val dataset for this epoch 903 = 0.09391617053797167\n",
      "learning rate for this epoch =  0.09121117842949143\n",
      "Error on this batch = 0.04249444708347954\n",
      "Error on this batch = 0.0724931738603555\n",
      "Cost on val dataset after 904 epochs is = 0.0939022775635137\n",
      "Initial Cost on Val dataset for this epoch 904 = 0.0939022775635137\n",
      "learning rate for this epoch =  0.09118594362878382\n",
      "Error on this batch = 0.04247164495307937\n",
      "Error on this batch = 0.07246703298467104\n",
      "Cost on val dataset after 905 epochs is = 0.09388841261955355\n",
      "Initial Cost on Val dataset for this epoch 905 = 0.09388841261955355\n",
      "learning rate for this epoch =  0.09116074369722786\n",
      "Error on this batch = 0.04244889690393025\n",
      "Error on this batch = 0.07244094475967479\n",
      "Cost on val dataset after 906 epochs is = 0.09387457561906228\n",
      "Initial Cost on Val dataset for this epoch 906 = 0.09387457561906228\n",
      "learning rate for this epoch =  0.09113557854819211\n",
      "Error on this batch = 0.0424262027246394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07241490895663515\n",
      "Cost on val dataset after 907 epochs is = 0.09386076647543204\n",
      "Initial Cost on Val dataset for this epoch 907 = 0.09386076647543204\n",
      "learning rate for this epoch =  0.09111044809535562\n",
      "Error on this batch = 0.042403562203904815\n",
      "Error on this batch = 0.07238892534734825\n",
      "Cost on val dataset after 908 epochs is = 0.09384698510247381\n",
      "Initial Cost on Val dataset for this epoch 908 = 0.09384698510247381\n",
      "learning rate for this epoch =  0.09108535225270664\n",
      "Error on this batch = 0.04238097513051527\n",
      "Error on this batch = 0.07236299370414208\n",
      "Cost on val dataset after 909 epochs is = 0.093833231414415\n",
      "Initial Cost on Val dataset for this epoch 909 = 0.093833231414415\n",
      "learning rate for this epoch =  0.09106029093454096\n",
      "Error on this batch = 0.04235844129335014\n",
      "Error on this batch = 0.07233711379988048\n",
      "Cost on val dataset after 910 epochs is = 0.0938195053258969\n",
      "Initial Cost on Val dataset for this epoch 910 = 0.0938195053258969\n",
      "learning rate for this epoch =  0.09103526405546067\n",
      "Error on this batch = 0.04233596048137972\n",
      "Error on this batch = 0.07231128540796707\n",
      "Cost on val dataset after 911 epochs is = 0.09380580675197234\n",
      "Initial Cost on Val dataset for this epoch 911 = 0.09380580675197234\n",
      "learning rate for this epoch =  0.09101027153037257\n",
      "Error on this batch = 0.042313532483665525\n",
      "Error on this batch = 0.07228550830234952\n",
      "Cost on val dataset after 912 epochs is = 0.09379213560810323\n",
      "Initial Cost on Val dataset for this epoch 912 = 0.09379213560810323\n",
      "learning rate for this epoch =  0.09098531327448692\n",
      "Error on this batch = 0.042291157089361014\n",
      "Error on this batch = 0.07225978225752351\n",
      "Cost on val dataset after 913 epochs is = 0.09377849181015795\n",
      "Initial Cost on Val dataset for this epoch 913 = 0.09377849181015795\n",
      "learning rate for this epoch =  0.09096038920331581\n",
      "Error on this batch = 0.04226883408771227\n",
      "Error on this batch = 0.07223410704853676\n",
      "Cost on val dataset after 914 epochs is = 0.09376487527440888\n",
      "Initial Cost on Val dataset for this epoch 914 = 0.09376487527440888\n",
      "learning rate for this epoch =  0.09093549923267195\n",
      "Error on this batch = 0.042246563268059215\n",
      "Error on this batch = 0.072208482450993\n",
      "Cost on val dataset after 915 epochs is = 0.09375128591752988\n",
      "Initial Cost on Val dataset for this epoch 915 = 0.09375128591752988\n",
      "learning rate for this epoch =  0.0909106432786672\n",
      "Error on this batch = 0.04222434441983662\n",
      "Error on this batch = 0.07218290824105601\n",
      "Cost on val dataset after 916 epochs is = 0.0937377236565936\n",
      "Initial Cost on Val dataset for this epoch 916 = 0.0937377236565936\n",
      "learning rate for this epoch =  0.09088582125771116\n",
      "Error on this batch = 0.04220217733257573\n",
      "Error on this batch = 0.07215738419545378\n",
      "Cost on val dataset after 917 epochs is = 0.09372418840906906\n",
      "Initial Cost on Val dataset for this epoch 917 = 0.09372418840906906\n",
      "learning rate for this epoch =  0.09086103308650982\n",
      "Error on this batch = 0.04218006179590573\n",
      "Error on this batch = 0.07213191009148215\n",
      "Cost on val dataset after 918 epochs is = 0.0937106800928188\n",
      "Initial Cost on Val dataset for this epoch 918 = 0.0937106800928188\n",
      "learning rate for this epoch =  0.09083627868206413\n",
      "Error on this batch = 0.04215799759955575\n",
      "Error on this batch = 0.07210648570700907\n",
      "Cost on val dataset after 919 epochs is = 0.09369719862609646\n",
      "Initial Cost on Val dataset for this epoch 919 = 0.09369719862609646\n",
      "learning rate for this epoch =  0.09081155796166877\n",
      "Error on this batch = 0.042135984533356804\n",
      "Error on this batch = 0.0720811108204783\n",
      "Cost on val dataset after 920 epochs is = 0.09368374392754389\n",
      "Initial Cost on Val dataset for this epoch 920 = 0.09368374392754389\n",
      "learning rate for this epoch =  0.09078687084291064\n",
      "Error on this batch = 0.04211402238724409\n",
      "Error on this batch = 0.07205578521091348\n",
      "Cost on val dataset after 921 epochs is = 0.09367031591618855\n",
      "Initial Cost on Val dataset for this epoch 921 = 0.09367031591618855\n",
      "learning rate for this epoch =  0.09076221724366758\n",
      "Error on this batch = 0.04209211095125939\n",
      "Error on this batch = 0.07203050865792171\n",
      "Cost on val dataset after 922 epochs is = 0.09365691451144077\n",
      "Initial Cost on Val dataset for this epoch 922 = 0.09365691451144077\n",
      "learning rate for this epoch =  0.09073759708210706\n",
      "Error on this batch = 0.04207025001555385\n",
      "Error on this batch = 0.07200528094169775\n",
      "Cost on val dataset after 923 epochs is = 0.09364353963309108\n",
      "Initial Cost on Val dataset for this epoch 923 = 0.09364353963309108\n",
      "learning rate for this epoch =  0.09071301027668477\n",
      "Error on this batch = 0.04204843937039067\n",
      "Error on this batch = 0.07198010184302742\n",
      "Cost on val dataset after 924 epochs is = 0.09363019120130722\n",
      "Initial Cost on Val dataset for this epoch 924 = 0.09363019120130722\n",
      "learning rate for this epoch =  0.09068845674614334\n",
      "Error on this batch = 0.042026678806148306\n",
      "Error on this batch = 0.07195497114329164\n",
      "Cost on val dataset after 925 epochs is = 0.09361686913663159\n",
      "Initial Cost on Val dataset for this epoch 925 = 0.09361686913663159\n",
      "learning rate for this epoch =  0.09066393640951106\n",
      "Error on this batch = 0.04200496811332366\n",
      "Error on this batch = 0.07192988862446989\n",
      "Cost on val dataset after 926 epochs is = 0.09360357335997829\n",
      "Initial Cost on Val dataset for this epoch 926 = 0.09360357335997829\n",
      "learning rate for this epoch =  0.09063944918610045\n",
      "Error on this batch = 0.041983307082535504\n",
      "Error on this batch = 0.07190485406914401\n",
      "Cost on val dataset after 927 epochs is = 0.09359030379263028\n",
      "Initial Cost on Val dataset for this epoch 927 = 0.09359030379263028\n",
      "learning rate for this epoch =  0.0906149949955071\n",
      "Error on this batch = 0.041961695504528225\n",
      "Error on this batch = 0.0718798672605018\n",
      "Cost on val dataset after 928 epochs is = 0.09357706035623661\n",
      "Initial Cost on Val dataset for this epoch 928 = 0.09357706035623661\n",
      "learning rate for this epoch =  0.09059057375760825\n",
      "Error on this batch = 0.04194013317017555\n",
      "Error on this batch = 0.07185492798234057\n",
      "Cost on val dataset after 929 epochs is = 0.09356384297280942\n",
      "Initial Cost on Val dataset for this epoch 929 = 0.09356384297280942\n",
      "learning rate for this epoch =  0.09056618539256157\n",
      "Error on this batch = 0.04191861987048478\n",
      "Error on this batch = 0.07183003601907048\n",
      "Cost on val dataset after 930 epochs is = 0.09355065156472106\n",
      "Initial Cost on Val dataset for this epoch 930 = 0.09355065156472106\n",
      "learning rate for this epoch =  0.09054182982080389\n",
      "Error on this batch = 0.04189715539660073\n",
      "Error on this batch = 0.07180519115571828\n",
      "Cost on val dataset after 931 epochs is = 0.09353748605470141\n",
      "Initial Cost on Val dataset for this epoch 931 = 0.09353748605470141\n",
      "learning rate for this epoch =  0.09051750696304985\n",
      "Error on this batch = 0.041875739539810504\n",
      "Error on this batch = 0.07178039317793056\n",
      "Cost on val dataset after 932 epochs is = 0.0935243463658345\n",
      "Initial Cost on Val dataset for this epoch 932 = 0.0935243463658345\n",
      "learning rate for this epoch =  0.0904932167402907\n",
      "Error on this batch = 0.041854372091547756\n",
      "Error on this batch = 0.07175564187197703\n",
      "Cost on val dataset after 933 epochs is = 0.09351123242155596\n",
      "Initial Cost on Val dataset for this epoch 933 = 0.09351123242155596\n",
      "learning rate for this epoch =  0.09046895907379304\n",
      "Error on this batch = 0.04183305284339772\n",
      "Error on this batch = 0.071730937024754\n",
      "Cost on val dataset after 934 epochs is = 0.09349814414564983\n",
      "Initial Cost on Val dataset for this epoch 934 = 0.09349814414564983\n",
      "learning rate for this epoch =  0.09044473388509751\n",
      "Error on this batch = 0.04181178158710215\n",
      "Error on this batch = 0.07170627842378748\n",
      "Cost on val dataset after 935 epochs is = 0.09348508146224564\n",
      "Initial Cost on Val dataset for this epoch 935 = 0.09348508146224564\n",
      "learning rate for this epoch =  0.0904205410960176\n",
      "Error on this batch = 0.04179055811456436\n",
      "Error on this batch = 0.07168166585723636\n",
      "Cost on val dataset after 936 epochs is = 0.09347204429581546\n",
      "Initial Cost on Val dataset for this epoch 936 = 0.09347204429581546\n",
      "learning rate for this epoch =  0.09039638062863838\n",
      "Error on this batch = 0.04176938221785475\n",
      "Error on this batch = 0.07165709911389563\n",
      "Cost on val dataset after 937 epochs is = 0.09345903257117079\n",
      "Initial Cost on Val dataset for this epoch 937 = 0.09345903257117079\n",
      "learning rate for this epoch =  0.09037225240531528\n",
      "Error on this batch = 0.041748253689216135\n",
      "Error on this batch = 0.07163257798319936\n",
      "Cost on val dataset after 938 epochs is = 0.09344604621345957\n",
      "Initial Cost on Val dataset for this epoch 938 = 0.09344604621345957\n",
      "learning rate for this epoch =  0.09034815634867288\n",
      "Error on this batch = 0.041727172321069615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07160810225522365\n",
      "Cost on val dataset after 939 epochs is = 0.09343308514816326\n",
      "Initial Cost on Val dataset for this epoch 939 = 0.09343308514816326\n",
      "learning rate for this epoch =  0.09032409238160365\n",
      "Error on this batch = 0.04170613790602018\n",
      "Error on this batch = 0.07158367172068977\n",
      "Cost on val dataset after 940 epochs is = 0.09342014930109364\n",
      "Initial Cost on Val dataset for this epoch 940 = 0.09342014930109364\n",
      "learning rate for this epoch =  0.09030006042726675\n",
      "Error on this batch = 0.041685150236863075\n",
      "Error on this batch = 0.07155928617096684\n",
      "Cost on val dataset after 941 epochs is = 0.09340723859838986\n",
      "Initial Cost on Val dataset for this epoch 941 = 0.09340723859838986\n",
      "learning rate for this epoch =  0.0902760604090869\n",
      "Error on this batch = 0.041664209106589745\n",
      "Error on this batch = 0.07153494539807467\n",
      "Cost on val dataset after 942 epochs is = 0.09339435296651531\n",
      "Initial Cost on Val dataset for this epoch 942 = 0.09339435296651531\n",
      "learning rate for this epoch =  0.09025209225075301\n",
      "Error on this batch = 0.041643314308394255\n",
      "Error on this batch = 0.0715106491946867\n",
      "Cost on val dataset after 943 epochs is = 0.09338149233225472\n",
      "Initial Cost on Val dataset for this epoch 943 = 0.09338149233225472\n",
      "learning rate for this epoch =  0.09022815587621721\n",
      "Error on this batch = 0.04162246563567978\n",
      "Error on this batch = 0.07148639735413244\n",
      "Cost on val dataset after 944 epochs is = 0.09336865662271086\n",
      "Initial Cost on Val dataset for this epoch 944 = 0.09336865662271086\n",
      "learning rate for this epoch =  0.0902042512096935\n",
      "Error on this batch = 0.0416016628820654\n",
      "Error on this batch = 0.07146218967040029\n",
      "Cost on val dataset after 945 epochs is = 0.09335584576530169\n",
      "Initial Cost on Val dataset for this epoch 945 = 0.09335584576530169\n",
      "learning rate for this epoch =  0.09018037817565662\n",
      "Error on this batch = 0.041580905841392804\n",
      "Error on this batch = 0.07143802593813994\n",
      "Cost on val dataset after 946 epochs is = 0.09334305968775714\n",
      "Initial Cost on Val dataset for this epoch 946 = 0.09334305968775714\n",
      "learning rate for this epoch =  0.09015653669884087\n",
      "Error on this batch = 0.041560194307733334\n",
      "Error on this batch = 0.0714139059526652\n",
      "Cost on val dataset after 947 epochs is = 0.09333029831811608\n",
      "Initial Cost on Val dataset for this epoch 947 = 0.09333029831811608\n",
      "learning rate for this epoch =  0.09013272670423898\n",
      "Error on this batch = 0.041539528075394995\n",
      "Error on this batch = 0.07138982950995597\n",
      "Cost on val dataset after 948 epochs is = 0.09331756158472344\n",
      "Initial Cost on Val dataset for this epoch 948 = 0.09331756158472344\n",
      "learning rate for this epoch =  0.09010894811710093\n",
      "Error on this batch = 0.04151890693892993\n",
      "Error on this batch = 0.07136579640666105\n",
      "Cost on val dataset after 949 epochs is = 0.09330484941622685\n",
      "Initial Cost on Val dataset for this epoch 949 = 0.09330484941622685\n",
      "learning rate for this epoch =  0.09008520086293277\n",
      "Error on this batch = 0.04149833069314158\n",
      "Error on this batch = 0.07134180644010017\n",
      "Cost on val dataset after 950 epochs is = 0.09329216174157375\n",
      "Initial Cost on Val dataset for this epoch 950 = 0.09329216174157375\n",
      "learning rate for this epoch =  0.09006148486749553\n",
      "Error on this batch = 0.041477799133092505\n",
      "Error on this batch = 0.07131785940826649\n",
      "Cost on val dataset after 951 epochs is = 0.09327949849000827\n",
      "Initial Cost on Val dataset for this epoch 951 = 0.09327949849000827\n",
      "learning rate for this epoch =  0.09003780005680402\n",
      "Error on this batch = 0.041457312054111774\n",
      "Error on this batch = 0.07129395510982862\n",
      "Cost on val dataset after 952 epochs is = 0.09326685959106838\n",
      "Initial Cost on Val dataset for this epoch 952 = 0.09326685959106838\n",
      "learning rate for this epoch =  0.09001414635712576\n",
      "Error on this batch = 0.041436869251802955\n",
      "Error on this batch = 0.07127009334413285\n",
      "Cost on val dataset after 953 epochs is = 0.09325424497458257\n",
      "Initial Cost on Val dataset for this epoch 953 = 0.09325424497458257\n",
      "learning rate for this epoch =  0.08999052369497976\n",
      "Error on this batch = 0.04141647052205199\n",
      "Error on this batch = 0.07124627391120515\n",
      "Cost on val dataset after 954 epochs is = 0.093241654570667\n",
      "Initial Cost on Val dataset for this epoch 954 = 0.093241654570667\n",
      "learning rate for this epoch =  0.08996693199713549\n",
      "Error on this batch = 0.041396115661035265\n",
      "Error on this batch = 0.07122249661175332\n",
      "Cost on val dataset after 955 epochs is = 0.09322908830972246\n",
      "Initial Cost on Val dataset for this epoch 955 = 0.09322908830972246\n",
      "learning rate for this epoch =  0.08994337119061177\n",
      "Error on this batch = 0.041375804465227775\n",
      "Error on this batch = 0.07119876124716883\n",
      "Cost on val dataset after 956 epochs is = 0.09321654612243134\n",
      "Initial Cost on Val dataset for this epoch 956 = 0.09321654612243134\n",
      "learning rate for this epoch =  0.08991984120267553\n",
      "Error on this batch = 0.041355536731411395\n",
      "Error on this batch = 0.07117506761952877\n",
      "Cost on val dataset after 957 epochs is = 0.09320402793975474\n",
      "Initial Cost on Val dataset for this epoch 957 = 0.09320402793975474\n",
      "learning rate for this epoch =  0.08989634196084093\n",
      "Error on this batch = 0.041335312256683264\n",
      "Error on this batch = 0.07115141553159779\n",
      "Cost on val dataset after 958 epochs is = 0.09319153369292933\n",
      "Initial Cost on Val dataset for this epoch 958 = 0.09319153369292933\n",
      "learning rate for this epoch =  0.089872873392868\n",
      "Error on this batch = 0.041315130838464297\n",
      "Error on this batch = 0.07112780478682973\n",
      "Cost on val dataset after 959 epochs is = 0.09317906331346468\n",
      "Initial Cost on Val dataset for this epoch 959 = 0.09317906331346468\n",
      "learning rate for this epoch =  0.08984943542676176\n",
      "Error on this batch = 0.041294992274507863\n",
      "Error on this batch = 0.07110423518936947\n",
      "Cost on val dataset after 960 epochs is = 0.09316661673313997\n",
      "Initial Cost on Val dataset for this epoch 960 = 0.09316661673313997\n",
      "learning rate for this epoch =  0.08982602799077107\n",
      "Error on this batch = 0.041274896362908306\n",
      "Error on this batch = 0.07108070654405457\n",
      "Cost on val dataset after 961 epochs is = 0.09315419388400141\n",
      "Initial Cost on Val dataset for this epoch 961 = 0.09315419388400141\n",
      "learning rate for this epoch =  0.08980265101338746\n",
      "Error on this batch = 0.04125484290210992\n",
      "Error on this batch = 0.071057218656417\n",
      "Cost on val dataset after 962 epochs is = 0.09314179469835918\n",
      "Initial Cost on Val dataset for this epoch 962 = 0.09314179469835918\n",
      "learning rate for this epoch =  0.0897793044233442\n",
      "Error on this batch = 0.04123483169091571\n",
      "Error on this batch = 0.07103377133268453\n",
      "Cost on val dataset after 963 epochs is = 0.09312941910878461\n",
      "Initial Cost on Val dataset for this epoch 963 = 0.09312941910878461\n",
      "learning rate for this epoch =  0.0897559881496152\n",
      "Error on this batch = 0.041214862528496446\n",
      "Error on this batch = 0.07101036437978249\n",
      "Cost on val dataset after 964 epochs is = 0.09311706704810738\n",
      "Initial Cost on Val dataset for this epoch 964 = 0.09311706704810738\n",
      "learning rate for this epoch =  0.08973270212141383\n",
      "Error on this batch = 0.041194935214399625\n",
      "Error on this batch = 0.07098699760533506\n",
      "Cost on val dataset after 965 epochs is = 0.09310473844941268\n",
      "Initial Cost on Val dataset for this epoch 965 = 0.09310473844941268\n",
      "learning rate for this epoch =  0.08970944626819201\n",
      "Error on this batch = 0.04117504954855867\n",
      "Error on this batch = 0.07096367081766679\n",
      "Cost on val dataset after 966 epochs is = 0.0930924332460384\n",
      "Initial Cost on Val dataset for this epoch 966 = 0.0930924332460384\n",
      "learning rate for this epoch =  0.0896862205196391\n",
      "Error on this batch = 0.04115520533130208\n",
      "Error on this batch = 0.07094038382580398\n",
      "Cost on val dataset after 967 epochs is = 0.0930801513715725\n",
      "Initial Cost on Val dataset for this epoch 967 = 0.0930801513715725\n",
      "learning rate for this epoch =  0.08966302480568086\n",
      "Error on this batch = 0.0411354023633627\n",
      "Error on this batch = 0.07091713643947602\n",
      "Cost on val dataset after 968 epochs is = 0.0930678927598501\n",
      "Initial Cost on Val dataset for this epoch 968 = 0.0930678927598501\n",
      "learning rate for this epoch =  0.08963985905647841\n",
      "Error on this batch = 0.04111564044588705\n",
      "Error on this batch = 0.0708939284691167\n",
      "Cost on val dataset after 969 epochs is = 0.09305565734495101\n",
      "Initial Cost on Val dataset for this epoch 969 = 0.09305565734495101\n",
      "learning rate for this epoch =  0.08961672320242715\n",
      "Error on this batch = 0.04109591938044474\n",
      "Error on this batch = 0.07087075972586539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 970 epochs is = 0.09304344506119694\n",
      "Initial Cost on Val dataset for this epoch 970 = 0.09304344506119694\n",
      "learning rate for this epoch =  0.08959361717415586\n",
      "Error on this batch = 0.04107623896903794\n",
      "Error on this batch = 0.07084763002156837\n",
      "Cost on val dataset after 971 epochs is = 0.0930312558431489\n",
      "Initial Cost on Val dataset for this epoch 971 = 0.0930312558431489\n",
      "learning rate for this epoch =  0.08957054090252553\n",
      "Error on this batch = 0.04105659901411074\n",
      "Error on this batch = 0.07082453916877979\n",
      "Cost on val dataset after 972 epochs is = 0.0930190896256047\n",
      "Initial Cost on Val dataset for this epoch 972 = 0.0930190896256047\n",
      "learning rate for this epoch =  0.08954749431862849\n",
      "Error on this batch = 0.04103699931855877\n",
      "Error on this batch = 0.07080148698076301\n",
      "Cost on val dataset after 973 epochs is = 0.09300694634359633\n",
      "Initial Cost on Val dataset for this epoch 973 = 0.09300694634359633\n",
      "learning rate for this epoch =  0.08952447735378725\n",
      "Error on this batch = 0.041017439685738837\n",
      "Error on this batch = 0.0707784732714916\n",
      "Cost on val dataset after 974 epochs is = 0.09299482593238746\n",
      "Initial Cost on Val dataset for this epoch 974 = 0.09299482593238746\n",
      "learning rate for this epoch =  0.08950148993955362\n",
      "Error on this batch = 0.04099791991947841\n",
      "Error on this batch = 0.07075549785565034\n",
      "Cost on val dataset after 975 epochs is = 0.09298272832747101\n",
      "Initial Cost on Val dataset for this epoch 975 = 0.09298272832747101\n",
      "learning rate for this epoch =  0.08947853200770761\n",
      "Error on this batch = 0.04097843982408543\n",
      "Error on this batch = 0.07073256054863632\n",
      "Cost on val dataset after 976 epochs is = 0.09297065346456673\n",
      "Initial Cost on Val dataset for this epoch 976 = 0.09297065346456673\n",
      "learning rate for this epoch =  0.08945560349025655\n",
      "Error on this batch = 0.04095899920435784\n",
      "Error on this batch = 0.07070966116655984\n",
      "Cost on val dataset after 977 epochs is = 0.09295860127961882\n",
      "Initial Cost on Val dataset for this epoch 977 = 0.09295860127961882\n",
      "learning rate for this epoch =  0.08943270431943395\n",
      "Error on this batch = 0.040939597865593313\n",
      "Error on this batch = 0.0706867995262454\n",
      "Cost on val dataset after 978 epochs is = 0.09294657170879358\n",
      "Initial Cost on Val dataset for this epoch 978 = 0.09294657170879358\n",
      "learning rate for this epoch =  0.08940983442769869\n",
      "Error on this batch = 0.04092023561359905\n",
      "Error on this batch = 0.07066397544523252\n",
      "Cost on val dataset after 979 epochs is = 0.09293456468847715\n",
      "Initial Cost on Val dataset for this epoch 979 = 0.09293456468847715\n",
      "learning rate for this epoch =  0.08938699374773387\n",
      "Error on this batch = 0.04090091225470143\n",
      "Error on this batch = 0.07064118874177673\n",
      "Cost on val dataset after 980 epochs is = 0.09292258015527313\n",
      "Initial Cost on Val dataset for this epoch 980 = 0.09292258015527313\n",
      "learning rate for this epoch =  0.089364182212446\n",
      "Error on this batch = 0.04088162759575576\n",
      "Error on this batch = 0.07061843923485037\n",
      "Cost on val dataset after 981 epochs is = 0.09291061804600065\n",
      "Initial Cost on Val dataset for this epoch 981 = 0.09291061804600065\n",
      "learning rate for this epoch =  0.08934139975496388\n",
      "Error on this batch = 0.04086238144415605\n",
      "Error on this batch = 0.07059572674414331\n",
      "Cost on val dataset after 982 epochs is = 0.09289867829769194\n",
      "Initial Cost on Val dataset for this epoch 982 = 0.09289867829769194\n",
      "learning rate for this epoch =  0.08931864630863778\n",
      "Error on this batch = 0.04084317360784476\n",
      "Error on this batch = 0.07057305109006388\n",
      "Cost on val dataset after 983 epochs is = 0.09288676084759041\n",
      "Initial Cost on Val dataset for this epoch 983 = 0.09288676084759041\n",
      "learning rate for this epoch =  0.08929592180703835\n",
      "Error on this batch = 0.040824003895322515\n",
      "Error on this batch = 0.07055041209373947\n",
      "Cost on val dataset after 984 epochs is = 0.09287486563314852\n",
      "Initial Cost on Val dataset for this epoch 984 = 0.09287486563314852\n",
      "learning rate for this epoch =  0.08927322618395579\n",
      "Error on this batch = 0.040804872115657885\n",
      "Error on this batch = 0.07052780957701744\n",
      "Cost on val dataset after 985 epochs is = 0.09286299259202574\n",
      "Initial Cost on Val dataset for this epoch 985 = 0.09286299259202574\n",
      "learning rate for this epoch =  0.08925055937339876\n",
      "Error on this batch = 0.040785778078497065\n",
      "Error on this batch = 0.07050524336246565\n",
      "Cost on val dataset after 986 epochs is = 0.09285114166208668\n",
      "Initial Cost on Val dataset for this epoch 986 = 0.09285114166208668\n",
      "learning rate for this epoch =  0.08922792130959359\n",
      "Error on this batch = 0.04076672159407356\n",
      "Error on this batch = 0.07048271327337313\n",
      "Cost on val dataset after 987 epochs is = 0.09283931278139912\n",
      "Initial Cost on Val dataset for this epoch 987 = 0.09283931278139912\n",
      "learning rate for this epoch =  0.08920531192698324\n",
      "Error on this batch = 0.04074770247321793\n",
      "Error on this batch = 0.07046021913375089\n",
      "Cost on val dataset after 988 epochs is = 0.0928275058882322\n",
      "Initial Cost on Val dataset for this epoch 988 = 0.0928275058882322\n",
      "learning rate for this epoch =  0.08918273116022643\n",
      "Error on this batch = 0.040728720527367396\n",
      "Error on this batch = 0.07043776076833241\n",
      "Cost on val dataset after 989 epochs is = 0.0928157209210546\n",
      "Initial Cost on Val dataset for this epoch 989 = 0.0928157209210546\n",
      "learning rate for this epoch =  0.08916017894419664\n",
      "Error on this batch = 0.04070977556857552\n",
      "Error on this batch = 0.07041533800257431\n",
      "Cost on val dataset after 990 epochs is = 0.09280395781853272\n",
      "Initial Cost on Val dataset for this epoch 990 = 0.09280395781853272\n",
      "learning rate for this epoch =  0.08913765521398127\n",
      "Error on this batch = 0.04069086740952172\n",
      "Error on this batch = 0.07039295066265681\n",
      "Cost on val dataset after 991 epochs is = 0.09279221651952918\n",
      "Initial Cost on Val dataset for this epoch 991 = 0.09279221651952918\n",
      "learning rate for this epoch =  0.08911515990488066\n",
      "Error on this batch = 0.04067199586352092\n",
      "Error on this batch = 0.07037059857548447\n",
      "Cost on val dataset after 992 epochs is = 0.09278049696310094\n",
      "Initial Cost on Val dataset for this epoch 992 = 0.09278049696310094\n",
      "learning rate for this epoch =  0.0890926929524072\n",
      "Error on this batch = 0.040653160744532936\n",
      "Error on this batch = 0.07034828156868655\n",
      "Cost on val dataset after 993 epochs is = 0.09276879908849779\n",
      "Initial Cost on Val dataset for this epoch 993 = 0.09276879908849779\n",
      "learning rate for this epoch =  0.08907025429228442\n",
      "Error on this batch = 0.040634361867172085\n",
      "Error on this batch = 0.07032599947061761\n",
      "Cost on val dataset after 994 epochs is = 0.09275712283516095\n",
      "Initial Cost on Val dataset for this epoch 994 = 0.09275712283516095\n",
      "learning rate for this epoch =  0.08904784386044612\n",
      "Error on this batch = 0.040615599046716466\n",
      "Error on this batch = 0.07030375211035808\n",
      "Cost on val dataset after 995 epochs is = 0.09274546814272146\n",
      "Initial Cost on Val dataset for this epoch 995 = 0.09274546814272146\n",
      "learning rate for this epoch =  0.08902546159303537\n",
      "Error on this batch = 0.040596872099117345\n",
      "Error on this batch = 0.07028153931771451\n",
      "Cost on val dataset after 996 epochs is = 0.09273383495099864\n",
      "Initial Cost on Val dataset for this epoch 996 = 0.09273383495099864\n",
      "learning rate for this epoch =  0.0890031074264038\n",
      "Error on this batch = 0.040578180841008456\n",
      "Error on this batch = 0.07025936092322038\n",
      "Cost on val dataset after 997 epochs is = 0.09272222319999902\n",
      "Initial Cost on Val dataset for this epoch 997 = 0.09272222319999902\n",
      "learning rate for this epoch =  0.08898078129711047\n",
      "Error on this batch = 0.040559525089715276\n",
      "Error on this batch = 0.0702372167581361\n",
      "Cost on val dataset after 998 epochs is = 0.09271063282991475\n",
      "Initial Cost on Val dataset for this epoch 998 = 0.09271063282991475\n",
      "learning rate for this epoch =  0.08895848314192122\n",
      "Error on this batch = 0.04054090466326409\n",
      "Error on this batch = 0.0702151066544498\n",
      "Cost on val dataset after 999 epochs is = 0.09269906378112244\n",
      "Initial Cost on Val dataset for this epoch 999 = 0.09269906378112244\n",
      "learning rate for this epoch =  0.08893621289780759\n",
      "Error on this batch = 0.04052231938039118\n",
      "Error on this batch = 0.07019303044487758\n",
      "Cost on val dataset after 1000 epochs is = 0.09268751599418197\n",
      "Initial Cost on Val dataset for this epoch 1000 = 0.09268751599418197\n",
      "learning rate for this epoch =  0.08891397050194613\n",
      "Error on this batch = 0.040503769060551705\n",
      "Error on this batch = 0.07017098796286395\n",
      "Cost on val dataset after 1001 epochs is = 0.09267598940983528\n",
      "Initial Cost on Val dataset for this epoch 1001 = 0.09267598940983528\n",
      "learning rate for this epoch =  0.0888917558917174\n",
      "Error on this batch = 0.04048525352392874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07014897904258209\n",
      "Cost on val dataset after 1002 epochs is = 0.09266448396900528\n",
      "Initial Cost on Val dataset for this epoch 1002 = 0.09266448396900528\n",
      "learning rate for this epoch =  0.0888695690047051\n",
      "Error on this batch = 0.04046677259144205\n",
      "Error on this batch = 0.07012700351893433\n",
      "Cost on val dataset after 1003 epochs is = 0.09265299961279483\n",
      "Initial Cost on Val dataset for this epoch 1003 = 0.09265299961279483\n",
      "learning rate for this epoch =  0.08884740977869533\n",
      "Error on this batch = 0.04044832608475691\n",
      "Error on this batch = 0.07010506122755243\n",
      "Cost on val dataset after 1004 epochs is = 0.09264153628248578\n",
      "Initial Cost on Val dataset for this epoch 1004 = 0.09264153628248578\n",
      "learning rate for this epoch =  0.0888252781516756\n",
      "Error on this batch = 0.04042991382629268\n",
      "Error on this batch = 0.07008315200479799\n",
      "Cost on val dataset after 1005 epochs is = 0.09263009391953785\n",
      "Initial Cost on Val dataset for this epoch 1005 = 0.09263009391953785\n",
      "learning rate for this epoch =  0.08880317406183406\n",
      "Error on this batch = 0.04041153563923142\n",
      "Error on this batch = 0.07006127568776259\n",
      "Cost on val dataset after 1006 epochs is = 0.09261867246558801\n",
      "Initial Cost on Val dataset for this epoch 1006 = 0.09261867246558801\n",
      "learning rate for this epoch =  0.08878109744755859\n",
      "Error on this batch = 0.040393191347526385\n",
      "Error on this batch = 0.07003943211426822\n",
      "Cost on val dataset after 1007 epochs is = 0.09260727186244937\n",
      "Initial Cost on Val dataset for this epoch 1007 = 0.09260727186244937\n",
      "learning rate for this epoch =  0.08875904824743605\n",
      "Error on this batch = 0.0403748807759103\n",
      "Error on this batch = 0.07001762112286751\n",
      "Cost on val dataset after 1008 epochs is = 0.09259589205211066\n",
      "Initial Cost on Val dataset for this epoch 1008 = 0.09259589205211066\n",
      "learning rate for this epoch =  0.08873702640025133\n",
      "Error on this batch = 0.04035660374990371\n",
      "Error on this batch = 0.06999584255284404\n",
      "Cost on val dataset after 1009 epochs is = 0.09258453297673525\n",
      "Initial Cost on Val dataset for this epoch 1009 = 0.09258453297673525\n",
      "learning rate for this epoch =  0.08871503184498658\n",
      "Error on this batch = 0.04033836009582302\n",
      "Error on this batch = 0.06997409624421243\n",
      "Cost on val dataset after 1010 epochs is = 0.0925731945786606\n",
      "Initial Cost on Val dataset for this epoch 1010 = 0.0925731945786606\n",
      "learning rate for this epoch =  0.08869306452082039\n",
      "Error on this batch = 0.04032014964078865\n",
      "Error on this batch = 0.06995238203771882\n",
      "Cost on val dataset after 1011 epochs is = 0.09256187680039774\n",
      "Initial Cost on Val dataset for this epoch 1011 = 0.09256187680039774\n",
      "learning rate for this epoch =  0.0886711243671269\n",
      "Error on this batch = 0.0403019722127328\n",
      "Error on this batch = 0.06993069977484088\n",
      "Cost on val dataset after 1012 epochs is = 0.09255057958463038\n",
      "Initial Cost on Val dataset for this epoch 1012 = 0.09255057958463038\n",
      "learning rate for this epoch =  0.08864921132347509\n",
      "Error on this batch = 0.040283827640407346\n",
      "Error on this batch = 0.06990904929778814\n",
      "Cost on val dataset after 1013 epochs is = 0.09253930287421469\n",
      "Initial Cost on Val dataset for this epoch 1013 = 0.09253930287421469\n",
      "learning rate for this epoch =  0.0886273253296278\n",
      "Error on this batch = 0.040265715753391496\n",
      "Error on this batch = 0.06988743044950199\n",
      "Cost on val dataset after 1014 epochs is = 0.0925280466121786\n",
      "Initial Cost on Val dataset for this epoch 1014 = 0.0925280466121786\n",
      "learning rate for this epoch =  0.08860546632554109\n",
      "Error on this batch = 0.04024763638209926\n",
      "Error on this batch = 0.06986584307365613\n",
      "Cost on val dataset after 1015 epochs is = 0.09251681074172151\n",
      "Initial Cost on Val dataset for this epoch 1015 = 0.09251681074172151\n",
      "learning rate for this epoch =  0.0885836342513633\n",
      "Error on this batch = 0.04022958935778693\n",
      "Error on this batch = 0.0698442870146564\n",
      "Cost on val dataset after 1016 epochs is = 0.09250559520621385\n",
      "Initial Cost on Val dataset for this epoch 1016 = 0.09250559520621385\n",
      "learning rate for this epoch =  0.08856182904743433\n",
      "Error on this batch = 0.040211574512560355\n",
      "Error on this batch = 0.06982276211764125\n",
      "Cost on val dataset after 1017 epochs is = 0.09249439994919664\n",
      "Initial Cost on Val dataset for this epoch 1017 = 0.09249439994919664\n",
      "learning rate for this epoch =  0.08854005065428476\n",
      "Error on this batch = 0.04019359167938205\n",
      "Error on this batch = 0.0698012682284816\n",
      "Cost on val dataset after 1018 epochs is = 0.09248322491438139\n",
      "Initial Cost on Val dataset for this epoch 1018 = 0.09248322491438139\n",
      "learning rate for this epoch =  0.08851829901263515\n",
      "Error on this batch = 0.04017564069207818\n",
      "Error on this batch = 0.06977980519378099\n",
      "Cost on val dataset after 1019 epochs is = 0.09247207004564964\n",
      "Initial Cost on Val dataset for this epoch 1019 = 0.09247207004564964\n",
      "learning rate for this epoch =  0.08849657406339513\n",
      "Error on this batch = 0.040157721385345485\n",
      "Error on this batch = 0.06975837286087579\n",
      "Cost on val dataset after 1020 epochs is = 0.09246093528705296\n",
      "Initial Cost on Val dataset for this epoch 1020 = 0.09246093528705296\n",
      "learning rate for this epoch =  0.08847487574766279\n",
      "Error on this batch = 0.040139833594757875\n",
      "Error on this batch = 0.06973697107783516\n",
      "Cost on val dataset after 1021 epochs is = 0.09244982058281256\n",
      "Initial Cost on Val dataset for this epoch 1021 = 0.09244982058281256\n",
      "learning rate for this epoch =  0.08845320400672366\n",
      "Error on this batch = 0.040121977156773174\n",
      "Error on this batch = 0.06971559969346111\n",
      "Cost on val dataset after 1022 epochs is = 0.09243872587731931\n",
      "Initial Cost on Val dataset for this epoch 1022 = 0.09243872587731931\n",
      "learning rate for this epoch =  0.0884315587820501\n",
      "Error on this batch = 0.04010415190873934\n",
      "Error on this batch = 0.06969425855728856\n",
      "Cost on val dataset after 1023 epochs is = 0.09242765111513368\n",
      "Initial Cost on Val dataset for this epoch 1023 = 0.09242765111513368\n",
      "learning rate for this epoch =  0.08840994001530049\n",
      "Error on this batch = 0.04008635768890095\n",
      "Error on this batch = 0.0696729475195853\n",
      "Cost on val dataset after 1024 epochs is = 0.09241659624098558\n",
      "Initial Cost on Val dataset for this epoch 1024 = 0.09241659624098558\n",
      "learning rate for this epoch =  0.08838834764831843\n",
      "Error on this batch = 0.040068594336405104\n",
      "Error on this batch = 0.0696516664313521\n",
      "Cost on val dataset after 1025 epochs is = 0.09240556119977433\n",
      "Initial Cost on Val dataset for this epoch 1025 = 0.09240556119977433\n",
      "learning rate for this epoch =  0.08836678162313201\n",
      "Error on this batch = 0.04005086169130744\n",
      "Error on this batch = 0.06963041514432253\n",
      "Cost on val dataset after 1026 epochs is = 0.0923945459365689\n",
      "Initial Cost on Val dataset for this epoch 1026 = 0.0923945459365689\n",
      "learning rate for this epoch =  0.088345241881953\n",
      "Error on this batch = 0.04003315959457807\n",
      "Error on this batch = 0.06960919351096302\n",
      "Cost on val dataset after 1027 epochs is = 0.09238355039660776\n",
      "Initial Cost on Val dataset for this epoch 1027 = 0.09238355039660776\n",
      "learning rate for this epoch =  0.0883237283671761\n",
      "Error on this batch = 0.04001548788810699\n",
      "Error on this batch = 0.0695880013844728\n",
      "Cost on val dataset after 1028 epochs is = 0.09237257452529901\n",
      "Initial Cost on Val dataset for this epoch 1028 = 0.09237257452529901\n",
      "learning rate for this epoch =  0.0883022410213782\n",
      "Error on this batch = 0.03999784641470977\n",
      "Error on this batch = 0.06956683861878364\n",
      "Cost on val dataset after 1029 epochs is = 0.09236161826822067\n",
      "Initial Cost on Val dataset for this epoch 1029 = 0.09236161826822067\n",
      "learning rate for this epoch =  0.08828077978731765\n",
      "Error on this batch = 0.03998023501813266\n",
      "Error on this batch = 0.06954570506856002\n",
      "Cost on val dataset after 1030 epochs is = 0.09235068157112068\n",
      "Initial Cost on Val dataset for this epoch 1030 = 0.09235068157112068\n",
      "learning rate for this epoch =  0.08825934460793343\n",
      "Error on this batch = 0.039962653543057974\n",
      "Error on this batch = 0.06952460058919878\n",
      "Cost on val dataset after 1031 epochs is = 0.09233976437991707\n",
      "Initial Cost on Val dataset for this epoch 1031 = 0.09233976437991707\n",
      "learning rate for this epoch =  0.08823793542634452\n",
      "Error on this batch = 0.039945101835108805\n",
      "Error on this batch = 0.06950352503682905\n",
      "Cost on val dataset after 1032 epochs is = 0.0923288666406984\n",
      "Initial Cost on Val dataset for this epoch 1032 = 0.0923288666406984\n",
      "learning rate for this epoch =  0.08821655218584905\n",
      "Error on this batch = 0.039927579740854\n",
      "Error on this batch = 0.06948247826831208\n",
      "Cost on val dataset after 1033 epochs is = 0.09231798829972375\n",
      "Initial Cost on Val dataset for this epoch 1033 = 0.09231798829972375\n",
      "learning rate for this epoch =  0.08819519482992363\n",
      "Error on this batch = 0.03991008710781276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06946146014124097\n",
      "Cost on val dataset after 1034 epochs is = 0.09230712930342323\n",
      "Initial Cost on Val dataset for this epoch 1034 = 0.09230712930342323\n",
      "learning rate for this epoch =  0.08817386330222259\n",
      "Error on this batch = 0.03989262378445911\n",
      "Error on this batch = 0.06944047051394049\n",
      "Cost on val dataset after 1035 epochs is = 0.09229628959839808\n",
      "Initial Cost on Val dataset for this epoch 1035 = 0.09229628959839808\n",
      "learning rate for this epoch =  0.08815255754657725\n",
      "Error on this batch = 0.03987518962022612\n",
      "Error on this batch = 0.0694195092454669\n",
      "Cost on val dataset after 1036 epochs is = 0.09228546913142123\n",
      "Initial Cost on Val dataset for this epoch 1036 = 0.09228546913142123\n",
      "learning rate for this epoch =  0.08813127750699522\n",
      "Error on this batch = 0.03985778446551016\n",
      "Error on this batch = 0.06939857619560746\n",
      "Cost on val dataset after 1037 epochs is = 0.0922746678494374\n",
      "Initial Cost on Val dataset for this epoch 1037 = 0.0922746678494374\n",
      "learning rate for this epoch =  0.08811002312765961\n",
      "Error on this batch = 0.039840408171674634\n",
      "Error on this batch = 0.06937767122488048\n",
      "Cost on val dataset after 1038 epochs is = 0.09226388569956373\n",
      "Initial Cost on Val dataset for this epoch 1038 = 0.09226388569956373\n",
      "learning rate for this epoch =  0.08808879435292839\n",
      "Error on this batch = 0.03982306059105404\n",
      "Error on this batch = 0.06935679419453454\n",
      "Cost on val dataset after 1039 epochs is = 0.09225312262908998\n",
      "Initial Cost on Val dataset for this epoch 1039 = 0.09225312262908998\n",
      "learning rate for this epoch =  0.08806759112733367\n",
      "Error on this batch = 0.03980574157695719\n",
      "Error on this batch = 0.06933594496654853\n",
      "Cost on val dataset after 1040 epochs is = 0.09224237858547903\n",
      "Initial Cost on Val dataset for this epoch 1040 = 0.09224237858547903\n",
      "learning rate for this epoch =  0.0880464133955809\n",
      "Error on this batch = 0.039788450983671\n",
      "Error on this batch = 0.06931512340363107\n",
      "Cost on val dataset after 1041 epochs is = 0.09223165351636739\n",
      "Initial Cost on Val dataset for this epoch 1041 = 0.09223165351636739\n",
      "learning rate for this epoch =  0.08802526110254827\n",
      "Error on this batch = 0.0397711886664634\n",
      "Error on this batch = 0.06929432936922013\n",
      "Cost on val dataset after 1042 epochs is = 0.09222094736956546\n",
      "Initial Cost on Val dataset for this epoch 1042 = 0.09222094736956546\n",
      "learning rate for this epoch =  0.0880041341932859\n",
      "Error on this batch = 0.039753954481586556\n",
      "Error on this batch = 0.06927356272748254\n",
      "Cost on val dataset after 1043 epochs is = 0.09221026009305817\n",
      "Initial Cost on Val dataset for this epoch 1043 = 0.09221026009305817\n",
      "learning rate for this epoch =  0.08798303261301525\n",
      "Error on this batch = 0.03973674828627976\n",
      "Error on this batch = 0.06925282334331367\n",
      "Cost on val dataset after 1044 epochs is = 0.09219959163500543\n",
      "Initial Cost on Val dataset for this epoch 1044 = 0.09219959163500543\n",
      "learning rate for this epoch =  0.08796195630712837\n",
      "Error on this batch = 0.03971956993877198\n",
      "Error on this batch = 0.06923211108233673\n",
      "Cost on val dataset after 1045 epochs is = 0.09218894194374254\n",
      "Initial Cost on Val dataset for this epoch 1045 = 0.09218894194374254\n",
      "learning rate for this epoch =  0.08794090522118717\n",
      "Error on this batch = 0.039702419298284525\n",
      "Error on this batch = 0.0692114258109024\n",
      "Cost on val dataset after 1046 epochs is = 0.09217831096778081\n",
      "Initial Cost on Val dataset for this epoch 1046 = 0.09217831096778081\n",
      "learning rate for this epoch =  0.08791987930092278\n",
      "Error on this batch = 0.03968529622503329\n",
      "Error on this batch = 0.06919076739608818\n",
      "Cost on val dataset after 1047 epochs is = 0.09216769865580801\n",
      "Initial Cost on Val dataset for this epoch 1047 = 0.09216769865580801\n",
      "learning rate for this epoch =  0.08789887849223484\n",
      "Error on this batch = 0.03966820058023085\n",
      "Error on this batch = 0.06917013570569779\n",
      "Cost on val dataset after 1048 epochs is = 0.0921571049566889\n",
      "Initial Cost on Val dataset for this epoch 1048 = 0.0921571049566889\n",
      "learning rate for this epoch =  0.08787790274119082\n",
      "Error on this batch = 0.03965113222608863\n",
      "Error on this batch = 0.06914953060826068\n",
      "Cost on val dataset after 1049 epochs is = 0.09214652981946572\n",
      "Initial Cost on Val dataset for this epoch 1049 = 0.09214652981946572\n",
      "learning rate for this epoch =  0.08785695199402538\n",
      "Error on this batch = 0.0396340910258185\n",
      "Error on this batch = 0.06912895197303112\n",
      "Cost on val dataset after 1050 epochs is = 0.0921359731933589\n",
      "Initial Cost on Val dataset for this epoch 1050 = 0.0921359731933589\n",
      "learning rate for this epoch =  0.08783602619713961\n",
      "Error on this batch = 0.03961707684363444\n",
      "Error on this batch = 0.0691083996699877\n",
      "Cost on val dataset after 1051 epochs is = 0.0921254350277674\n",
      "Initial Cost on Val dataset for this epoch 1051 = 0.0921254350277674\n",
      "learning rate for this epoch =  0.08781512529710042\n",
      "Error on this batch = 0.03960008954475397\n",
      "Error on this batch = 0.06908787356983269\n",
      "Cost on val dataset after 1052 epochs is = 0.0921149152722694\n",
      "Initial Cost on Val dataset for this epoch 1052 = 0.0921149152722694\n",
      "learning rate for this epoch =  0.08779424924063986\n",
      "Error on this batch = 0.03958312899539947\n",
      "Error on this batch = 0.06906737354399094\n",
      "Cost on val dataset after 1053 epochs is = 0.09210441387662274\n",
      "Initial Cost on Val dataset for this epoch 1053 = 0.09210441387662274\n",
      "learning rate for this epoch =  0.08777339797465443\n",
      "Error on this batch = 0.03956619506279915\n",
      "Error on this batch = 0.06904689946460936\n",
      "Cost on val dataset after 1054 epochs is = 0.0920939307907656\n",
      "Initial Cost on Val dataset for this epoch 1054 = 0.0920939307907656\n",
      "learning rate for this epoch =  0.08775257144620446\n",
      "Error on this batch = 0.039549287615188\n",
      "Error on this batch = 0.06902645120455608\n",
      "Cost on val dataset after 1055 epochs is = 0.092083465964817\n",
      "Initial Cost on Val dataset for this epoch 1055 = 0.092083465964817\n",
      "learning rate for this epoch =  0.08773176960251337\n",
      "Error on this batch = 0.03953240652180846\n",
      "Error on this batch = 0.06900602863741953\n",
      "Cost on val dataset after 1056 epochs is = 0.0920730193490772\n",
      "Initial Cost on Val dataset for this epoch 1056 = 0.0920730193490772\n",
      "learning rate for this epoch =  0.08771099239096714\n",
      "Error on this batch = 0.03951555165291101\n",
      "Error on this batch = 0.06898563163750747\n",
      "Cost on val dataset after 1057 epochs is = 0.0920625908940286\n",
      "Initial Cost on Val dataset for this epoch 1057 = 0.0920625908940286\n",
      "learning rate for this epoch =  0.08769023975911351\n",
      "Error on this batch = 0.039498722879754554\n",
      "Error on this batch = 0.0689652600798462\n",
      "Cost on val dataset after 1058 epochs is = 0.09205218055033597\n",
      "Initial Cost on Val dataset for this epoch 1058 = 0.09205218055033597\n",
      "learning rate for this epoch =  0.08766951165466147\n",
      "Error on this batch = 0.03948192007460648\n",
      "Error on this batch = 0.06894491384017946\n",
      "Cost on val dataset after 1059 epochs is = 0.09204178826884704\n",
      "Initial Cost on Val dataset for this epoch 1059 = 0.09204178826884704\n",
      "learning rate for this epoch =  0.08764880802548045\n",
      "Error on this batch = 0.03946514311074284\n",
      "Error on this batch = 0.06892459279496752\n",
      "Cost on val dataset after 1060 epochs is = 0.0920314140005933\n",
      "Initial Cost on Val dataset for this epoch 1060 = 0.0920314140005933\n",
      "learning rate for this epoch =  0.08762812881959987\n",
      "Error on this batch = 0.03944839186244804\n",
      "Error on this batch = 0.06890429682138612\n",
      "Cost on val dataset after 1061 epochs is = 0.09202105769679013\n",
      "Initial Cost on Val dataset for this epoch 1061 = 0.09202105769679013\n",
      "learning rate for this epoch =  0.08760747398520836\n",
      "Error on this batch = 0.03943166620501464\n",
      "Error on this batch = 0.06888402579732533\n",
      "Cost on val dataset after 1062 epochs is = 0.09201071930883768\n",
      "Initial Cost on Val dataset for this epoch 1062 = 0.09201071930883768\n",
      "learning rate for this epoch =  0.08758684347065314\n",
      "Error on this batch = 0.03941496601474276\n",
      "Error on this batch = 0.06886377960138845\n",
      "Cost on val dataset after 1063 epochs is = 0.09200039878832117\n",
      "Initial Cost on Val dataset for this epoch 1063 = 0.09200039878832117\n",
      "learning rate for this epoch =  0.08756623722443944\n",
      "Error on this batch = 0.03939829116893942\n",
      "Error on this batch = 0.06884355811289095\n",
      "Cost on val dataset after 1064 epochs is = 0.09199009608701146\n",
      "Initial Cost on Val dataset for this epoch 1064 = 0.09199009608701146\n",
      "learning rate for this epoch =  0.08754565519522983\n",
      "Error on this batch = 0.0393816415459178\n",
      "Error on this batch = 0.06882336121185915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1065 epochs is = 0.0919798111568656\n",
      "Initial Cost on Val dataset for this epoch 1065 = 0.0919798111568656\n",
      "learning rate for this epoch =  0.08752509733184359\n",
      "Error on this batch = 0.03936501702499607\n",
      "Error on this batch = 0.06880318877902909\n",
      "Cost on val dataset after 1066 epochs is = 0.09196954395002725\n",
      "Initial Cost on Val dataset for this epoch 1066 = 0.09196954395002725\n",
      "learning rate for this epoch =  0.0875045635832561\n",
      "Error on this batch = 0.03934841748649636\n",
      "Error on this batch = 0.06878304069584525\n",
      "Cost on val dataset after 1067 epochs is = 0.09195929441882714\n",
      "Initial Cost on Val dataset for this epoch 1067 = 0.09195929441882714\n",
      "learning rate for this epoch =  0.08748405389859822\n",
      "Error on this batch = 0.03933184281174341\n",
      "Error on this batch = 0.06876291684445915\n",
      "Cost on val dataset after 1068 epochs is = 0.09194906251578362\n",
      "Initial Cost on Val dataset for this epoch 1068 = 0.09194906251578362\n",
      "learning rate for this epoch =  0.08746356822715562\n",
      "Error on this batch = 0.039315292883063\n",
      "Error on this batch = 0.06874281710772814\n",
      "Cost on val dataset after 1069 epochs is = 0.091938848193603\n",
      "Initial Cost on Val dataset for this epoch 1069 = 0.091938848193603\n",
      "learning rate for this epoch =  0.08744310651836827\n",
      "Error on this batch = 0.03929876758378037\n",
      "Error on this batch = 0.06872274136921394\n",
      "Cost on val dataset after 1070 epochs is = 0.0919286514051801\n",
      "Initial Cost on Val dataset for this epoch 1070 = 0.0919286514051801\n",
      "learning rate for this epoch =  0.08742266872182974\n",
      "Error on this batch = 0.039282266798218377\n",
      "Error on this batch = 0.06870268951318126\n",
      "Cost on val dataset after 1071 epochs is = 0.0919184721035985\n",
      "Initial Cost on Val dataset for this epoch 1071 = 0.0919184721035985\n",
      "learning rate for this epoch =  0.08740225478728658\n",
      "Error on this batch = 0.039265790411695554\n",
      "Error on this batch = 0.06868266142459631\n",
      "Cost on val dataset after 1072 epochs is = 0.09190831024213114\n",
      "Initial Cost on Val dataset for this epoch 1072 = 0.09190831024213114\n",
      "learning rate for this epoch =  0.0873818646646378\n",
      "Error on this batch = 0.039249338310524025\n",
      "Error on this batch = 0.06866265698912542\n",
      "Cost on val dataset after 1073 epochs is = 0.09189816577424054\n",
      "Initial Cost on Val dataset for this epoch 1073 = 0.09189816577424054\n",
      "learning rate for this epoch =  0.08736149830393418\n",
      "Error on this batch = 0.0392329103820071\n",
      "Error on this batch = 0.0686426760931333\n",
      "Cost on val dataset after 1074 epochs is = 0.09188803865357924\n",
      "Initial Cost on Val dataset for this epoch 1074 = 0.09188803865357924\n",
      "learning rate for this epoch =  0.0873411556553777\n",
      "Error on this batch = 0.03921650651443701\n",
      "Error on this batch = 0.06862271862368173\n",
      "Cost on val dataset after 1075 epochs is = 0.09187792883399014\n",
      "Initial Cost on Val dataset for this epoch 1075 = 0.09187792883399014\n",
      "learning rate for this epoch =  0.087320836669321\n",
      "Error on this batch = 0.03920012659709227\n",
      "Error on this batch = 0.06860278446852776\n",
      "Cost on val dataset after 1076 epochs is = 0.09186783626950681\n",
      "Initial Cost on Val dataset for this epoch 1076 = 0.09186783626950681\n",
      "learning rate for this epoch =  0.08730054129626662\n",
      "Error on this batch = 0.03918377052023497\n",
      "Error on this batch = 0.06858287351612213\n",
      "Cost on val dataset after 1077 epochs is = 0.09185776091435384\n",
      "Initial Cost on Val dataset for this epoch 1077 = 0.09185776091435384\n",
      "learning rate for this epoch =  0.08728026948686665\n",
      "Error on this batch = 0.039167438175107885\n",
      "Error on this batch = 0.06856298565560769\n",
      "Cost on val dataset after 1078 epochs is = 0.09184770272294707\n",
      "Initial Cost on Val dataset for this epoch 1078 = 0.09184770272294707\n",
      "learning rate for this epoch =  0.0872600211919219\n",
      "Error on this batch = 0.03915112945393158\n",
      "Error on this batch = 0.06854312077681753\n",
      "Cost on val dataset after 1079 epochs is = 0.09183766164989389\n",
      "Initial Cost on Val dataset for this epoch 1079 = 0.09183766164989389\n",
      "learning rate for this epoch =  0.08723979636238147\n",
      "Error on this batch = 0.03913484424990114\n",
      "Error on this batch = 0.06852327877027332\n",
      "Cost on val dataset after 1080 epochs is = 0.09182763764999353\n",
      "Initial Cost on Val dataset for this epoch 1080 = 0.09182763764999353\n",
      "learning rate for this epoch =  0.08721959494934213\n",
      "Error on this batch = 0.039118582457183075\n",
      "Error on this batch = 0.06850345952718355\n",
      "Cost on val dataset after 1081 epochs is = 0.09181763067823714\n",
      "Initial Cost on Val dataset for this epoch 1081 = 0.09181763067823714\n",
      "learning rate for this epoch =  0.0871994169040477\n",
      "Error on this batch = 0.03910234397091168\n",
      "Error on this batch = 0.06848366293944164\n",
      "Cost on val dataset after 1082 epochs is = 0.09180764068980819\n",
      "Initial Cost on Val dataset for this epoch 1082 = 0.09180764068980819\n",
      "learning rate for this epoch =  0.08717926217788849\n",
      "Error on this batch = 0.03908612868718576\n",
      "Error on this batch = 0.06846388889962417\n",
      "Cost on val dataset after 1083 epochs is = 0.09179766764008249\n",
      "Initial Cost on Val dataset for this epoch 1083 = 0.09179766764008249\n",
      "learning rate for this epoch =  0.0871591307224008\n",
      "Error on this batch = 0.039069936503064756\n",
      "Error on this batch = 0.06844413730098886\n",
      "Cost on val dataset after 1084 epochs is = 0.0917877114846284\n",
      "Initial Cost on Val dataset for this epoch 1084 = 0.0917877114846284\n",
      "learning rate for this epoch =  0.08713902248926618\n",
      "Error on this batch = 0.03905376731656503\n",
      "Error on this batch = 0.06842440803747285\n",
      "Cost on val dataset after 1085 epochs is = 0.09177777217920703\n",
      "Initial Cost on Val dataset for this epoch 1085 = 0.09177777217920703\n",
      "learning rate for this epoch =  0.08711893743031107\n",
      "Error on this batch = 0.03903762102665602\n",
      "Error on this batch = 0.0684047010036905\n",
      "Cost on val dataset after 1086 epochs is = 0.09176784967977222\n",
      "Initial Cost on Val dataset for this epoch 1086 = 0.09176784967977222\n",
      "learning rate for this epoch =  0.08709887549750603\n",
      "Error on this batch = 0.03902149753325613\n",
      "Error on this batch = 0.0683850160949316\n",
      "Cost on val dataset after 1087 epochs is = 0.09175794394247079\n",
      "Initial Cost on Val dataset for this epoch 1087 = 0.09175794394247079\n",
      "learning rate for this epoch =  0.08707883664296534\n",
      "Error on this batch = 0.03900539673722848\n",
      "Error on this batch = 0.06836535320715921\n",
      "Cost on val dataset after 1088 epochs is = 0.09174805492364238\n",
      "Initial Cost on Val dataset for this epoch 1088 = 0.09174805492364238\n",
      "learning rate for this epoch =  0.08705882081894635\n",
      "Error on this batch = 0.03898931854037685\n",
      "Error on this batch = 0.06834571223700775\n",
      "Cost on val dataset after 1089 epochs is = 0.0917381825798197\n",
      "Initial Cost on Val dataset for this epoch 1089 = 0.0917381825798197\n",
      "learning rate for this epoch =  0.08703882797784893\n",
      "Error on this batch = 0.038973262845441135\n",
      "Error on this batch = 0.06832609308178075\n",
      "Cost on val dataset after 1090 epochs is = 0.09172832686772843\n",
      "Initial Cost on Val dataset for this epoch 1090 = 0.09172832686772843\n",
      "learning rate for this epoch =  0.08701885807221492\n",
      "Error on this batch = 0.038957229556092876\n",
      "Error on this batch = 0.06830649563944881\n",
      "Cost on val dataset after 1091 epochs is = 0.09171848774428724\n",
      "cost initial= 0.09172832686772843 , cost final=0.09171848774428724 , change in cost= -9.839123441185427e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 50 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 1091\n",
      "The training time = 146.514sec\n",
      "The training accuracy is = 93.937%\n",
      "The validation accuracy is = 89.436%\n",
      "The test accuracy is = 87.969%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 100 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.370728911030039\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.363770892805095\n",
      "Error on this batch = 0.48067879758586357\n",
      "Cost on val dataset after 2 epochs is = 0.4802318170924747\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4802318170924747\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.479842758856616\n",
      "Error on this batch = 0.47966407883254564\n",
      "Cost on val dataset after 3 epochs is = 0.47927062800767084\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47927062800767084\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.47884417322346323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4787282769517532\n",
      "Cost on val dataset after 4 epochs is = 0.47824564889975324\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.47824564889975324\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.4777848800488793\n",
      "Error on this batch = 0.47770924976589857\n",
      "Cost on val dataset after 5 epochs is = 0.47709144120701924\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.47709144120701924\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4765945876337596\n",
      "Error on this batch = 0.4765494042482638\n",
      "Cost on val dataset after 6 epochs is = 0.4757397611061292\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4757397611061292\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.475199805630595\n",
      "Error on this batch = 0.4751879256101107\n",
      "Cost on val dataset after 7 epochs is = 0.47410113223493877\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.47410113223493877\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4735058211038954\n",
      "Error on this batch = 0.4735499116307421\n",
      "Cost on val dataset after 8 epochs is = 0.472047399083848\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.472047399083848\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4713778960238949\n",
      "Error on this batch = 0.4715369478113701\n",
      "Cost on val dataset after 9 epochs is = 0.4693869837272503\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4693869837272503\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.46861618865571253\n",
      "Error on this batch = 0.4690117439247193\n",
      "Cost on val dataset after 10 epochs is = 0.46584126588197455\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.46584126588197455\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.46493235476781425\n",
      "Error on this batch = 0.4657681639211792\n",
      "Cost on val dataset after 11 epochs is = 0.4610741375666753\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4610741375666753\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4599783433030107\n",
      "Error on this batch = 0.4615071146151465\n",
      "Cost on val dataset after 12 epochs is = 0.45482226446235235\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.45482226446235235\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.45348764352657017\n",
      "Error on this batch = 0.45590628181357146\n",
      "Cost on val dataset after 13 epochs is = 0.4469406097375683\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4469406097375683\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4453773444099979\n",
      "Error on this batch = 0.44874959220882693\n",
      "Cost on val dataset after 14 epochs is = 0.43739331089450806\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.43739331089450806\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4357808341994803\n",
      "Error on this batch = 0.440053193384169\n",
      "Cost on val dataset after 15 epochs is = 0.4265749950714816\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4265749950714816\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.42525810295305483\n",
      "Error on this batch = 0.4302420203988283\n",
      "Cost on val dataset after 16 epochs is = 0.4152972452295895\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4152972452295895\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4146149133937853\n",
      "Error on this batch = 0.42002080164665173\n",
      "Cost on val dataset after 17 epochs is = 0.40425965620782445\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.40425965620782445\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4043986797227748\n",
      "Error on this batch = 0.40998380575070115\n",
      "Cost on val dataset after 18 epochs is = 0.393740234901034\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.393740234901034\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.3947039063516128\n",
      "Error on this batch = 0.40039816421656016\n",
      "Cost on val dataset after 19 epochs is = 0.3836835866058639\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.3836835866058639\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.3853212415768353\n",
      "Error on this batch = 0.3912893586469578\n",
      "Cost on val dataset after 20 epochs is = 0.37393747235826674\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.37393747235826674\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.3759856531087897\n",
      "Error on this batch = 0.3825847027260326\n",
      "Cost on val dataset after 21 epochs is = 0.36438027073349943\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.36438027073349943\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.3665046109085726\n",
      "Error on this batch = 0.37418289510517455\n",
      "Cost on val dataset after 22 epochs is = 0.35495362451780443\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.35495362451780443\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.3567920924227019\n",
      "Error on this batch = 0.3659856073609785\n",
      "Cost on val dataset after 23 epochs is = 0.34566377928052405\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.34566377928052405\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.34686698693594586\n",
      "Error on this batch = 0.3579210361739119\n",
      "Cost on val dataset after 24 epochs is = 0.3365657723287254\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.3365657723287254\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.3368280127850001\n",
      "Error on this batch = 0.34995602893543265\n",
      "Cost on val dataset after 25 epochs is = 0.3277319457748633\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.3277319457748633\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.32681021986570585\n",
      "Error on this batch = 0.3420911988178588\n",
      "Cost on val dataset after 26 epochs is = 0.319221293095659\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.319221293095659\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.3169440827488775\n",
      "Error on this batch = 0.3343467417398063\n",
      "Cost on val dataset after 27 epochs is = 0.3110664800190103\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.3110664800190103\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.30733452695148333\n",
      "Error on this batch = 0.3267504027338844\n",
      "Cost on val dataset after 28 epochs is = 0.30327769997832726\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.30327769997832726\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.298057844652173\n",
      "Error on this batch = 0.31933171170904606\n",
      "Cost on val dataset after 29 epochs is = 0.2958524139334724\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.2958524139334724\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.2891658948466859\n",
      "Error on this batch = 0.3121202679413458\n",
      "Cost on val dataset after 30 epochs is = 0.28878319811616293\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.28878319811616293\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.2806907946506973\n",
      "Error on this batch = 0.3051449469785089\n",
      "Cost on val dataset after 31 epochs is = 0.2820617564386109\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.2820617564386109\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.2726484221031019\n",
      "Error on this batch = 0.29843252985834207\n",
      "Cost on val dataset after 32 epochs is = 0.27567999902652063\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.27567999902652063\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.2650412436901205\n",
      "Error on this batch = 0.2920057466392179\n",
      "Cost on val dataset after 33 epochs is = 0.2696296162276538\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.2696296162276538\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.25786120047370126\n",
      "Error on this batch = 0.28588140981588395\n",
      "Cost on val dataset after 34 epochs is = 0.26390128880955344\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.26390128880955344\n",
      "learning rate for this epoch =  0.20706193828327601\n",
      "Error on this batch = 0.25109288372398103\n",
      "Error on this batch = 0.28006930346818865\n",
      "Cost on val dataset after 35 epochs is = 0.2584841846335774\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.2584841846335774\n",
      "learning rate for this epoch =  0.20556680845025985\n",
      "Error on this batch = 0.2447167006674939\n",
      "Error on this batch = 0.27457209132402977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 36 epochs is = 0.2533659223580663\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.2533659223580663\n",
      "learning rate for this epoch =  0.20412414523193154\n",
      "Error on this batch = 0.238711536932313\n",
      "Error on this batch = 0.2693860788508927\n",
      "Cost on val dataset after 37 epochs is = 0.2485328835588622\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.2485328835588622\n",
      "learning rate for this epoch =  0.2027307249193849\n",
      "Error on this batch = 0.233056573570794\n",
      "Error on this batch = 0.26450245283255475\n",
      "Cost on val dataset after 38 epochs is = 0.24397066476137078\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.24397066476137078\n",
      "learning rate for this epoch =  0.20138360231828867\n",
      "Error on this batch = 0.2277322009504202\n",
      "Error on this batch = 0.2599086389855709\n",
      "Cost on val dataset after 39 epochs is = 0.23966450807873055\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.23966450807873055\n",
      "learning rate for this epoch =  0.20008008009612496\n",
      "Error on this batch = 0.22272020204683793\n",
      "Error on this batch = 0.2555895469859843\n",
      "Cost on val dataset after 40 epochs is = 0.23559963649044724\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.23559963649044724\n",
      "learning rate for this epoch =  0.19881768219176266\n",
      "Error on this batch = 0.2180034867206912\n",
      "Error on this batch = 0.25152860393262527\n",
      "Cost on val dataset after 41 epochs is = 0.23176148730197074\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.23176148730197074\n",
      "learning rate for this epoch =  0.19759413066220238\n",
      "Error on this batch = 0.2135656584910171\n",
      "Error on this batch = 0.24770856345532838\n",
      "Cost on val dataset after 42 epochs is = 0.2281358687021009\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.2281358687021009\n",
      "learning rate for this epoch =  0.1964073254502565\n",
      "Error on this batch = 0.2093906248182994\n",
      "Error on this batch = 0.24411211675173344\n",
      "Cost on val dataset after 43 epochs is = 0.22470906815490901\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.22470906815490901\n",
      "learning rate for this epoch =  0.19525532664475806\n",
      "Error on this batch = 0.2054623636737709\n",
      "Error on this batch = 0.24072234083348043\n",
      "Cost on val dataset after 44 epochs is = 0.22146793252709576\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.22146793252709576\n",
      "learning rate for this epoch =  0.19413633887611162\n",
      "Error on this batch = 0.20176486974366484\n",
      "Error on this batch = 0.23752301542367732\n",
      "Cost on val dataset after 45 epochs is = 0.218399929544623\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.218399929544623\n",
      "learning rate for this epoch =  0.19304869754804485\n",
      "Error on this batch = 0.19828224477354894\n",
      "Error on this batch = 0.23449883377504338\n",
      "Cost on val dataset after 46 epochs is = 0.21549319341035916\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.21549319341035916\n",
      "learning rate for this epoch =  0.19199085665396748\n",
      "Error on this batch = 0.1949988723626575\n",
      "Error on this batch = 0.23163552811545324\n",
      "Cost on val dataset after 47 epochs is = 0.21273655470051608\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.21273655470051608\n",
      "learning rate for this epoch =  0.1909613779654767\n",
      "Error on this batch = 0.1918996194225195\n",
      "Error on this batch = 0.22891992767979644\n",
      "Cost on val dataset after 48 epochs is = 0.2101195545592473\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.2101195545592473\n",
      "learning rate for this epoch =  0.18995892141289814\n",
      "Error on this batch = 0.1889700218527882\n",
      "Error on this batch = 0.22633996539291734\n",
      "Cost on val dataset after 49 epochs is = 0.2076324441519232\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.2076324441519232\n",
      "learning rate for this epoch =  0.1889822365046136\n",
      "Error on this batch = 0.18619643030624616\n",
      "Error on this batch = 0.22388464743442554\n",
      "Cost on val dataset after 50 epochs is = 0.20526617131036312\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.20526617131036312\n",
      "learning rate for this epoch =  0.1880301546543197\n",
      "Error on this batch = 0.18356610725273537\n",
      "Error on this batch = 0.2215439978410836\n",
      "Cost on val dataset after 51 epochs is = 0.2030123568905061\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.2030123568905061\n",
      "learning rate for this epoch =  0.18710158230410626\n",
      "Error on this batch = 0.1810672768609169\n",
      "Error on this batch = 0.2193089880400556\n",
      "Cost on val dataset after 52 epochs is = 0.20086326351768255\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.20086326351768255\n",
      "learning rate for this epoch =  0.1861954947469912\n",
      "Error on this batch = 0.1786891347907742\n",
      "Error on this batch = 0.21717145894904896\n",
      "Cost on val dataset after 53 epochs is = 0.19881175922765884\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.19881175922765884\n",
      "learning rate for this epoch =  0.18531093056582568\n",
      "Error on this batch = 0.17642182706601856\n",
      "Error on this batch = 0.21512404121290496\n",
      "Cost on val dataset after 54 epochs is = 0.1968512781628266\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.1968512781628266\n",
      "learning rate for this epoch =  0.18444698661672027\n",
      "Error on this batch = 0.17425640710638055\n",
      "Error on this batch = 0.21316007738864298\n",
      "Cost on val dataset after 55 epochs is = 0.19497578006571661\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.19497578006571661\n",
      "learning rate for this epoch =  0.1836028134946796\n",
      "Error on this batch = 0.1721847788036391\n",
      "Error on this batch = 0.2112735484871849\n",
      "Cost on val dataset after 56 epochs is = 0.1931797099005366\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.1931797099005366\n",
      "learning rate for this epoch =  0.18277761142725618\n",
      "Error on this batch = 0.17019963192865534\n",
      "Error on this batch = 0.20945900621960145\n",
      "Cost on val dataset after 57 epochs is = 0.19145795856772718\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.19145795856772718\n",
      "learning rate for this epoch =  0.18197062654897384\n",
      "Error on this batch = 0.1682943745672349\n",
      "Error on this batch = 0.2077115115360176\n",
      "Cost on val dataset after 58 epochs is = 0.1898058253727849\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.1898058253727849\n",
      "learning rate for this epoch =  0.1811811475152165\n",
      "Error on this batch = 0.16646306589749146\n",
      "Error on this batch = 0.20602657953022377\n",
      "Cost on val dataset after 59 epochs is = 0.18821898267033874\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.18821898267033874\n",
      "learning rate for this epoch =  0.180408502419387\n",
      "Error on this batch = 0.16470035150780177\n",
      "Error on this batch = 0.2044001304558344\n",
      "Cost on val dataset after 60 epochs is = 0.18669344292148193\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.18669344292148193\n",
      "learning rate for this epoch =  0.17965205598154213\n",
      "Error on this batch = 0.1630014026089211\n",
      "Error on this batch = 0.20282844641012696\n",
      "Cost on val dataset after 61 epochs is = 0.18522552826723243\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.18522552826723243\n",
      "learning rate for this epoch =  0.1789112069805131\n",
      "Error on this batch = 0.16136185988028953\n",
      "Error on this batch = 0.2013081331482607\n",
      "Cost on val dataset after 62 epochs is = 0.18381184262384548\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.18381184262384548\n",
      "learning rate for this epoch =  0.1781853859048144\n",
      "Error on this batch = 0.15977778226269948\n",
      "Error on this batch = 0.19983608646165668\n",
      "Cost on val dataset after 63 epochs is = 0.18244924623762604\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.18244924623762604\n",
      "learning rate for this epoch =  0.17747405280050266\n",
      "Error on this batch = 0.15824560072240548\n",
      "Error on this batch = 0.19840946256652117\n",
      "Cost on val dataset after 64 epochs is = 0.1811348325905737\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.1811348325905737\n",
      "learning rate for this epoch =  0.17677669529663687\n",
      "Error on this batch = 0.15676207682713372\n",
      "Error on this batch = 0.1970256519852165\n",
      "Cost on val dataset after 65 epochs is = 0.1798659075180016\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.1798659075180016\n",
      "learning rate for this epoch =  0.1760928267911618\n",
      "Error on this batch = 0.15532426586203213\n",
      "Error on this batch = 0.19568225645296497\n",
      "Cost on val dataset after 66 epochs is = 0.1786399703810307\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.1786399703810307\n",
      "learning rate for this epoch =  0.17542198478193427\n",
      "Error on this batch = 0.1539294841507801\n",
      "Error on this batch = 0.19437706843753105\n",
      "Cost on val dataset after 67 epochs is = 0.17745469712755943\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.17745469712755943\n",
      "learning rate for this epoch =  0.1747637293292756\n",
      "Error on this batch = 0.15257528021763386\n",
      "Error on this batch = 0.19310805291501582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 68 epochs is = 0.17630792507276774\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.17630792507276774\n",
      "learning rate for this epoch =  0.1741176416378927\n",
      "Error on this batch = 0.15125940941885968\n",
      "Error on this batch = 0.19187333109752353\n",
      "Cost on val dataset after 69 epochs is = 0.17519763923279572\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.17519763923279572\n",
      "learning rate for this epoch =  0.1734833227472955\n",
      "Error on this batch = 0.14997981167913602\n",
      "Error on this batch = 0.190671165856325\n",
      "Cost on val dataset after 70 epochs is = 0.17412196005168065\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.17412196005168065\n",
      "learning rate for this epoch =  0.1728603923209705\n",
      "Error on this batch = 0.1487345919849273\n",
      "Error on this batch = 0.18949994862623581\n",
      "Cost on val dataset after 71 epochs is = 0.17307913237087885\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.17307913237087885\n",
      "learning rate for this epoch =  0.17224848752556968\n",
      "Error on this batch = 0.14752200330904133\n",
      "Error on this batch = 0.18835818761290476\n",
      "Cost on val dataset after 72 epochs is = 0.1720675155018553\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.1720675155018553\n",
      "learning rate for this epoch =  0.17164726199225983\n",
      "Error on this batch = 0.1463404316661608\n",
      "Error on this batch = 0.18724449715467195\n",
      "Cost on val dataset after 73 epochs is = 0.17108557427451276\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.17108557427451276\n",
      "learning rate for this epoch =  0.17105638485316074\n",
      "Error on this batch = 0.14518838302637244\n",
      "Error on this batch = 0.18615758811502758\n",
      "Cost on val dataset after 74 epochs is = 0.1701318709470048\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.1701318709470048\n",
      "learning rate for this epoch =  0.1704755398464977\n",
      "Error on this batch = 0.14406447184135052\n",
      "Error on this batch = 0.18509625920110848\n",
      "Cost on val dataset after 75 epochs is = 0.16920505787518125\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.16920505787518125\n",
      "learning rate for this epoch =  0.16990442448471224\n",
      "Error on this batch = 0.14296741096496848\n",
      "Error on this batch = 0.1840593891188428\n",
      "Cost on val dataset after 76 epochs is = 0.16830387085213075\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.16830387085213075\n",
      "learning rate for this epoch =  0.16934274928032858\n",
      "Error on this batch = 0.14189600277603892\n",
      "Error on this batch = 0.18304592948705994\n",
      "Cost on val dataset after 77 epochs is = 0.1674271230397038\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.1674271230397038\n",
      "learning rate for this epoch =  0.16879023702486318\n",
      "Error on this batch = 0.14084913133515245\n",
      "Error on this batch = 0.18205489844185815\n",
      "Cost on val dataset after 78 epochs is = 0.16657369942431405\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.16657369942431405\n",
      "learning rate for this epoch =  0.16824662211650757\n",
      "Error on this batch = 0.13982575542989717\n",
      "Error on this batch = 0.18108537486943185\n",
      "Cost on val dataset after 79 epochs is = 0.16574255173861935\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.16574255173861935\n",
      "learning rate for this epoch =  0.1677116499327062\n",
      "Error on this batch = 0.13882490238293485\n",
      "Error on this batch = 0.18013649321098243\n",
      "Cost on val dataset after 80 epochs is = 0.16493269379884856\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.16493269379884856\n",
      "learning rate for this epoch =  0.1671850762441055\n",
      "Error on this batch = 0.13784566251543967\n",
      "Error on this batch = 0.1792074387877264\n",
      "Cost on val dataset after 81 epochs is = 0.16414319721458925\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.16414319721458925\n",
      "learning rate for this epoch =  0.16666666666666666\n",
      "Error on this batch = 0.13688718417431506\n",
      "Error on this batch = 0.17829744359773603\n",
      "Cost on val dataset after 82 epochs is = 0.16337318743386484\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.16337318743386484\n",
      "learning rate for this epoch =  0.16615619614902008\n",
      "Error on this batch = 0.13594866924549687\n",
      "Error on this batch = 0.17740578253966324\n",
      "Cost on val dataset after 83 epochs is = 0.16262184009140274\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.16262184009140274\n",
      "learning rate for this epoch =  0.16565344849239508\n",
      "Error on this batch = 0.1350293690876767\n",
      "Error on this batch = 0.17653177002147988\n",
      "Cost on val dataset after 84 epochs is = 0.16188837763224057\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.16188837763224057\n",
      "learning rate for this epoch =  0.16515821590069035\n",
      "Error on this batch = 0.1341285808311091\n",
      "Error on this batch = 0.17567475691532378\n",
      "Cost on val dataset after 85 epochs is = 0.1611720661863528\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.1611720661863528\n",
      "learning rate for this epoch =  0.164670298558459\n",
      "Error on this batch = 0.13324564399498\n",
      "Error on this batch = 0.17483412782243624\n",
      "Cost on val dataset after 86 epochs is = 0.1604722126729211\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.1604722126729211\n",
      "learning rate for this epoch =  0.16418950423477013\n",
      "Error on this batch = 0.1323799373842913\n",
      "Error on this batch = 0.17400929861502193\n",
      "Cost on val dataset after 87 epochs is = 0.1597881621153106\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.1597881621153106\n",
      "learning rate for this epoch =  0.16371564791108048\n",
      "Error on this batch = 0.13153087623352774\n",
      "Error on this batch = 0.17319971422465957\n",
      "Cost on val dataset after 88 epochs is = 0.1591192951498562\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.1591192951498562\n",
      "learning rate for this epoch =  0.16324855143140263\n",
      "Error on this batch = 0.13069790956967392\n",
      "Error on this batch = 0.17240484664962175\n",
      "Cost on val dataset after 89 epochs is = 0.1584650257132713\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1584650257132713\n",
      "learning rate for this epoch =  0.1627880431731981\n",
      "Error on this batch = 0.12988051777158102\n",
      "Error on this batch = 0.17162419315609945\n",
      "Cost on val dataset after 90 epochs is = 0.1578247988949438\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.1578247988949438\n",
      "learning rate for this epoch =  0.16233395773754944\n",
      "Error on this batch = 0.12907821030637406\n",
      "Error on this batch = 0.1708572746508513\n",
      "Cost on val dataset after 91 epochs is = 0.15719808894162335\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.15719808894162335\n",
      "learning rate for this epoch =  0.16188613565728216\n",
      "Error on this batch = 0.12829052362664567\n",
      "Error on this batch = 0.17010363420517977\n",
      "Cost on val dataset after 92 epochs is = 0.15658439740307936\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.15658439740307936\n",
      "learning rate for this epoch =  0.161444423121811\n",
      "Error on this batch = 0.12751701921470165\n",
      "Error on this batch = 0.1693628357123677\n",
      "Cost on val dataset after 93 epochs is = 0.15598325140825237\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.15598325140825237\n",
      "learning rate for this epoch =  0.16100867171758368\n",
      "Error on this batch = 0.12675728176218726\n",
      "Error on this batch = 0.16863446266277204\n",
      "Cost on val dataset after 94 epochs is = 0.15539420206225524\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.15539420206225524\n",
      "learning rate for this epoch =  0.160578738183079\n",
      "Error on this batch = 0.12601091747510348\n",
      "Error on this batch = 0.16791811702266066\n",
      "Cost on val dataset after 95 epochs is = 0.1548168229553294\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.1548168229553294\n",
      "learning rate for this epoch =  0.16015448417739933\n",
      "Error on this batch = 0.1252775524955818\n",
      "Error on this batch = 0.1672134182045961\n",
      "Cost on val dataset after 96 epochs is = 0.15425070877554056\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.15425070877554056\n",
      "learning rate for this epoch =  0.1597357760615681\n",
      "Error on this batch = 0.12455683143287619\n",
      "Error on this batch = 0.1665200021187146\n",
      "Cost on val dataset after 97 epochs is = 0.153695474017613\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.153695474017613\n",
      "learning rate for this epoch =  0.15932248469171095\n",
      "Error on this batch = 0.12384841599690093\n",
      "Error on this batch = 0.16583752029562845\n",
      "Cost on val dataset after 98 epochs is = 0.15315075178086737\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.15315075178086737\n",
      "learning rate for this epoch =  0.15891448522335927\n",
      "Error on this batch = 0.1231519837283273\n",
      "Error on this batch = 0.1651656390729049\n",
      "Cost on val dataset after 99 epochs is = 0.15261619264975096\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.15261619264975096\n",
      "learning rate for this epoch =  0.15851165692617153\n",
      "Error on this batch = 0.12246722681979189\n",
      "Error on this batch = 0.1645040388381536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 100 epochs is = 0.1520914636509267\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.1520914636509267\n",
      "learning rate for this epoch =  0.15811388300841897\n",
      "Error on this batch = 0.12179385102318711\n",
      "Error on this batch = 0.16385241332269865\n",
      "Cost on val dataset after 101 epochs is = 0.15157624728133715\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.15157624728133715\n",
      "learning rate for this epoch =  0.1577210504506286\n",
      "Error on this batch = 0.12113157463833028\n",
      "Error on this batch = 0.16321046894063387\n",
      "Cost on val dataset after 102 epochs is = 0.15107024060206975\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.15107024060206975\n",
      "learning rate for this epoch =  0.1573330498478208\n",
      "Error on this batch = 0.12048012757855965\n",
      "Error on this batch = 0.1625779241687749\n",
      "Cost on val dataset after 103 epochs is = 0.1505731543932366\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.1505731543932366\n",
      "learning rate for this epoch =  0.15694977525981785\n",
      "Error on this batch = 0.11983925050900403\n",
      "Error on this batch = 0.1619545089636327\n",
      "Cost on val dataset after 104 epochs is = 0.15008471236543644\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.15008471236543644\n",
      "learning rate for this epoch =  0.15657112406913673\n",
      "Error on this batch = 0.11920869405342979\n",
      "Error on this batch = 0.16133996421206453\n",
      "Cost on val dataset after 105 epochs is = 0.14960465042369664\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.14960465042369664\n",
      "learning rate for this epoch =  0.1561969968460128\n",
      "Error on this batch = 0.11858821806569977\n",
      "Error on this batch = 0.16073404121270685\n",
      "Cost on val dataset after 106 epochs is = 0.14913271598010236\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.14913271598010236\n",
      "learning rate for this epoch =  0.15582729722013278\n",
      "Error on this batch = 0.11797759096199081\n",
      "Error on this batch = 0.1601365011856797\n",
      "Cost on val dataset after 107 epochs is = 0.1486686673116011\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.1486686673116011\n",
      "learning rate for this epoch =  0.15546193175868359\n",
      "Error on this batch = 0.1173765891100185\n",
      "Error on this batch = 0.15954711480837927\n",
      "Cost on val dataset after 108 epochs is = 0.1482122729597372\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.1482122729597372\n",
      "learning rate for this epoch =  0.15510080985034994\n",
      "Error on this batch = 0.11678499627161688\n",
      "Error on this batch = 0.15896566177544905\n",
      "Cost on val dataset after 109 epochs is = 0.14776331116931332\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.14776331116931332\n",
      "learning rate for this epoch =  0.1547438435949191\n",
      "Error on this batch = 0.11620260309511864\n",
      "Error on this batch = 0.15839193038125568\n",
      "Cost on val dataset after 110 epochs is = 0.14732156936320226\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.14732156936320226\n",
      "learning rate for this epoch =  0.1543909476981724\n",
      "Error on this batch = 0.11562920665408397\n",
      "Error on this batch = 0.1578257171233903\n",
      "Cost on val dataset after 111 epochs is = 0.1468868436507419\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.1468868436507419\n",
      "learning rate for this epoch =  0.15404203937176525\n",
      "Error on this batch = 0.11506461002903452\n",
      "Error on this batch = 0.15726682632588193\n",
      "Cost on val dataset after 112 epochs is = 0.14645893836733784\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.14645893836733784\n",
      "learning rate for this epoch =  0.1536970382378161\n",
      "Error on this batch = 0.11450862192896243\n",
      "Error on this batch = 0.15671506978094812\n",
      "Cost on val dataset after 113 epochs is = 0.14603766564307855\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.14603766564307855\n",
      "learning rate for this epoch =  0.15335586623794323\n",
      "Error on this batch = 0.11396105634950583\n",
      "Error on this batch = 0.15617026640822623\n",
      "Cost on val dataset after 114 epochs is = 0.14562284499833092\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.14562284499833092\n",
      "learning rate for this epoch =  0.1530184475465045\n",
      "Error on this batch = 0.11342173226481234\n",
      "Error on this batch = 0.15563224193052505\n",
      "Cost on val dataset after 115 epochs is = 0.1452143029644364\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.1452143029644364\n",
      "learning rate for this epoch =  0.15268470848781107\n",
      "Error on this batch = 0.11289047335024321\n",
      "Error on this batch = 0.15510082856522175\n",
      "Cost on val dataset after 116 epochs is = 0.14481187272777044\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.14481187272777044\n",
      "learning rate for this epoch =  0.1523545774571\n",
      "Error on this batch = 0.11236710773321404\n",
      "Error on this batch = 0.15457586473049786\n",
      "Cost on val dataset after 117 epochs is = 0.14441539379555318\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.14441539379555318\n",
      "learning rate for this epoch =  0.15202798484506466\n",
      "Error on this batch = 0.11185146776960853\n",
      "Error on this batch = 0.15405719476567029\n",
      "Cost on val dataset after 118 epochs is = 0.14402471168192305\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.14402471168192305\n",
      "learning rate for this epoch =  0.15170486296575364\n",
      "Error on this batch = 0.11134338984335092\n",
      "Error on this batch = 0.15354466866492142\n",
      "Cost on val dataset after 119 epochs is = 0.14363967761289215\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.14363967761289215\n",
      "learning rate for this epoch =  0.1513851459876605\n",
      "Error on this batch = 0.11084271418686895\n",
      "Error on this batch = 0.1530381418237815\n",
      "Cost on val dataset after 120 epochs is = 0.1432601482489054\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.1432601482489054\n",
      "learning rate for this epoch =  0.1510687698678384\n",
      "Error on this batch = 0.11034928472032768\n",
      "Error on this batch = 0.15253747479775046\n",
      "Cost on val dataset after 121 epochs is = 0.1428859854238178\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.1428859854238178\n",
      "learning rate for this epoch =  0.15075567228888181\n",
      "Error on this batch = 0.10986294890766245\n",
      "Error on this batch = 0.15204253307248544\n",
      "Cost on val dataset after 122 epochs is = 0.14251705589919167\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.14251705589919167\n",
      "learning rate for this epoch =  0.1504457925986288\n",
      "Error on this batch = 0.10938355762758274\n",
      "Error on this batch = 0.15155318684500654\n",
      "Cost on val dataset after 123 epochs is = 0.14215323113289488\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.14215323113289488\n",
      "learning rate for this epoch =  0.15013907175244492\n",
      "Error on this batch = 0.10891096505786127\n",
      "Error on this batch = 0.15106931081540467\n",
      "Cost on val dataset after 124 epochs is = 0.14179438706105443\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.14179438706105443\n",
      "learning rate for this epoch =  0.1498354522579582\n",
      "Error on this batch = 0.108445028571359\n",
      "Error on this batch = 0.15059078398855685\n",
      "Cost on val dataset after 125 epochs is = 0.1414404038924879\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.1414404038924879\n",
      "learning rate for this epoch =  0.14953487812212204\n",
      "Error on this batch = 0.10798560864236954\n",
      "Error on this batch = 0.15011748948538156\n",
      "Cost on val dataset after 126 epochs is = 0.1410911659147975\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.1410911659147975\n",
      "learning rate for this epoch =  0.14923729480049114\n",
      "Error on this batch = 0.10753256876199271\n",
      "Error on this batch = 0.14964931436318393\n",
      "Cost on val dataset after 127 epochs is = 0.1407465613113697\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.1407465613113697\n",
      "learning rate for this epoch =  0.14894264914859962\n",
      "Error on this batch = 0.10708577536136783\n",
      "Error on this batch = 0.14918614944466405\n",
      "Cost on val dataset after 128 epochs is = 0.14040648198857697\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.14040648198857697\n",
      "learning rate for this epoch =  0.14865088937534013\n",
      "Error on this batch = 0.1066450977417103\n",
      "Error on this batch = 0.1487278891551791\n",
      "Cost on val dataset after 129 epochs is = 0.14007082341252647\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.14007082341252647\n",
      "learning rate for this epoch =  0.14836196499824542\n",
      "Error on this batch = 0.10621040801020364\n",
      "Error on this batch = 0.14827443136786733\n",
      "Cost on val dataset after 130 epochs is = 0.13973948445474751\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.13973948445474751\n",
      "learning rate for this epoch =  0.14807582680058123\n",
      "Error on this batch = 0.10578158102089781\n",
      "Error on this batch = 0.14782567725626167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 131 epochs is = 0.13941236724625145\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.13941236724625145\n",
      "learning rate for this epoch =  0.14779242679016388\n",
      "Error on this batch = 0.10535849431985927\n",
      "Error on this batch = 0.14738153115403305\n",
      "Cost on val dataset after 132 epochs is = 0.139089377039436\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.139089377039436\n",
      "learning rate for this epoch =  0.1475117181598202\n",
      "Error on this batch = 0.10494102809390367\n",
      "Error on this batch = 0.1469419004215231\n",
      "Cost on val dataset after 133 epochs is = 0.1387704220773431\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.1387704220773431\n",
      "learning rate for this epoch =  0.147233655249413\n",
      "Error on this batch = 0.10452906512232256\n",
      "Error on this batch = 0.1465066953187384\n",
      "Cost on val dataset after 134 epochs is = 0.13845541346981355\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.13845541346981355\n",
      "learning rate for this epoch =  0.1469581935093583\n",
      "Error on this batch = 0.10412249073108817\n",
      "Error on this batch = 0.1460758288844931\n",
      "Cost on val dataset after 135 epochs is = 0.13814426507610986\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.13814426507610986\n",
      "learning rate for this epoch =  0.14668528946556555\n",
      "Error on this batch = 0.10372119274908688\n",
      "Error on this batch = 0.14564921682140158\n",
      "Cost on val dataset after 136 epochs is = 0.13783689339361227\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.13783689339361227\n",
      "learning rate for this epoch =  0.14641490068573487\n",
      "Error on this batch = 0.10332506146599338\n",
      "Error on this batch = 0.14522677738643489\n",
      "Cost on val dataset after 137 epochs is = 0.13753321745221492\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.13753321745221492\n",
      "learning rate for this epoch =  0.14614698574694937\n",
      "Error on this batch = 0.10293398959145204\n",
      "Error on this batch = 0.14480843128676793\n",
      "Cost on val dataset after 138 epochs is = 0.13723315871407746\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.13723315871407746\n",
      "learning rate for this epoch =  0.145881504204504\n",
      "Error on this batch = 0.10254787221528154\n",
      "Error on this batch = 0.14439410158065652\n",
      "Cost on val dataset after 139 epochs is = 0.13693664097840869\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.13693664097840869\n",
      "learning rate for this epoch =  0.14561841656191457\n",
      "Error on this batch = 0.10216660676846345\n",
      "Error on this batch = 0.14398371358309525\n",
      "Cost on val dataset after 140 epochs is = 0.13664359029098103\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.13664359029098103\n",
      "learning rate for this epoch =  0.14535768424205484\n",
      "Error on this batch = 0.10179009298471516\n",
      "Error on this batch = 0.14357719477601777\n",
      "Cost on val dataset after 141 epochs is = 0.1363539348580941\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.1363539348580941\n",
      "learning rate for this epoch =  0.14509926955937089\n",
      "Error on this batch = 0.10141823286248258\n",
      "Error on this batch = 0.14317447472281322\n",
      "Cost on val dataset after 142 epochs is = 0.13606760496472486\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.13606760496472486\n",
      "learning rate for this epoch =  0.1448431356931257\n",
      "Error on this batch = 0.10105093062722009\n",
      "Error on this batch = 0.1427754849869411\n",
      "Cost on val dataset after 143 epochs is = 0.1357845328966182\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.1357845328966182\n",
      "learning rate for this epoch =  0.14458924666162856\n",
      "Error on this batch = 0.10068809269385096\n",
      "Error on this batch = 0.14238015905443893\n",
      "Cost on val dataset after 144 epochs is = 0.13550465286608923\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.13550465286608923\n",
      "learning rate for this epoch =  0.14433756729740646\n",
      "Error on this batch = 0.10032962762932819\n",
      "Error on this batch = 0.14198843226012484\n",
      "Cost on val dataset after 145 epochs is = 0.1352279009413213\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.1352279009413213\n",
      "learning rate for this epoch =  0.14408806322327672\n",
      "Error on this batch = 0.0999754461152339\n",
      "Error on this batch = 0.14160024171730765\n",
      "Cost on val dataset after 146 epochs is = 0.13495421497896062\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.13495421497896062\n",
      "learning rate for this epoch =  0.14384070082928266\n",
      "Error on this batch = 0.0996254609103755\n",
      "Error on this batch = 0.1412155262508256\n",
      "Cost on val dataset after 147 epochs is = 0.13468353455981855\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.13468353455981855\n",
      "learning rate for this epoch =  0.1435954472504545\n",
      "Error on this batch = 0.09927958681335167\n",
      "Error on this batch = 0.14083422633324325\n",
      "Cost on val dataset after 148 epochs is = 0.1344158009275065\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.1344158009275065\n",
      "learning rate for this epoch =  0.1433522703453617\n",
      "Error on this batch = 0.09893774062507422\n",
      "Error on this batch = 0.14045628402404428\n",
      "Cost on val dataset after 149 epochs is = 0.13415095692983925\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.13415095692983925\n",
      "learning rate for this epoch =  0.1431111386754225\n",
      "Error on this batch = 0.09859984111124385\n",
      "Error on this batch = 0.14008164291166617\n",
      "Cost on val dataset after 150 epochs is = 0.13388894696285203\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.13388894696285203\n",
      "learning rate for this epoch =  0.14287202148493997\n",
      "Error on this batch = 0.0982658089647862\n",
      "Error on this batch = 0.13971024805823018\n",
      "Cost on val dataset after 151 epochs is = 0.13362971691728806\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.13362971691728806\n",
      "learning rate for this epoch =  0.14263488868183333\n",
      "Error on this batch = 0.09793556676826327\n",
      "Error on this batch = 0.13934204594682714\n",
      "Cost on val dataset after 152 epochs is = 0.13337321412742142\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.13337321412742142\n",
      "learning rate for this epoch =  0.14239971081903682\n",
      "Error on this batch = 0.09760903895628062\n",
      "Error on this batch = 0.13897698443122689\n",
      "Cost on val dataset after 153 epochs is = 0.13311938732208828\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.13311938732208828\n",
      "learning rate for this epoch =  0.14216645907653844\n",
      "Error on this batch = 0.09728615177791632\n",
      "Error on this batch = 0.13861501268788584\n",
      "Cost on val dataset after 154 epochs is = 0.13286818657780866\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.13286818657780866\n",
      "learning rate for this epoch =  0.14193510524403224\n",
      "Error on this batch = 0.09696683325920129\n",
      "Error on this batch = 0.13825608117013327\n",
      "Cost on val dataset after 155 epochs is = 0.13261956327388713\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.13261956327388713\n",
      "learning rate for this epoch =  0.1417056217041599\n",
      "Error on this batch = 0.09665101316568322\n",
      "Error on this batch = 0.1379001415644241\n",
      "Cost on val dataset after 156 epochs is = 0.13237347004938838\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.13237347004938838\n",
      "learning rate for this epoch =  0.14147798141631754\n",
      "Error on this batch = 0.09633862296510852\n",
      "Error on this batch = 0.13754714674855045\n",
      "Cost on val dataset after 157 epochs is = 0.13212986076188996\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.13212986076188996\n",
      "learning rate for this epoch =  0.14125215790100537\n",
      "Error on this batch = 0.09602959579025785\n",
      "Error on this batch = 0.13719705075171085\n",
      "Cost on val dataset after 158 epochs is = 0.13188869044792\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.13188869044792\n",
      "learning rate for this epoch =  0.14102812522469854\n",
      "Error on this batch = 0.09572386640197122\n",
      "Error on this batch = 0.13684980871634186\n",
      "Cost on val dataset after 159 epochs is = 0.1316499152849945\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.1316499152849945\n",
      "learning rate for this epoch =  0.1408058579852188\n",
      "Error on this batch = 0.09542137115239914\n",
      "Error on this batch = 0.13650537686162018\n",
      "Cost on val dataset after 160 epochs is = 0.1314134925551727\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.1314134925551727\n",
      "learning rate for this epoch =  0.14058533129758727\n",
      "Error on this batch = 0.0951220479485149\n",
      "Error on this batch = 0.1361637124485506\n",
      "Cost on val dataset after 161 epochs is = 0.13117938061005446\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.13117938061005446\n",
      "learning rate for this epoch =  0.14036652078033962\n",
      "Error on this batch = 0.09482583621592339\n",
      "Error on this batch = 0.1358247737465576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 162 epochs is = 0.1309475388371484\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.1309475388371484\n",
      "learning rate for this epoch =  0.14014940254228575\n",
      "Error on this batch = 0.09453267686300006\n",
      "Error on this batch = 0.1354885200015047\n",
      "Cost on val dataset after 163 epochs is = 0.13071792762754408\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.13071792762754408\n",
      "learning rate for this epoch =  0.13993395316969692\n",
      "Error on this batch = 0.09424251224539187\n",
      "Error on this batch = 0.13515491140506847\n",
      "Cost on val dataset after 164 epochs is = 0.13049050834482376\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.13049050834482376\n",
      "learning rate for this epoch =  0.13972014971390403\n",
      "Error on this batch = 0.09395528613091166\n",
      "Error on this batch = 0.13482390906539887\n",
      "Cost on val dataset after 165 epochs is = 0.13026524329515562\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.13026524329515562\n",
      "learning rate for this epoch =  0.13950796967929133\n",
      "Error on this batch = 0.0936709436648541\n",
      "Error on this batch = 0.13449547497900122\n",
      "Cost on val dataset after 166 epochs is = 0.13004209569851155\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.13004209569851155\n",
      "learning rate for this epoch =  0.13929739101167085\n",
      "Error on this batch = 0.0933894313357608\n",
      "Error on this batch = 0.13416957200377816\n",
      "Cost on val dataset after 167 epochs is = 0.12982102966095707\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.12982102966095707\n",
      "learning rate for this epoch =  0.13908839208702292\n",
      "Error on this batch = 0.09311069694165951\n",
      "Error on this batch = 0.13384616383317435\n",
      "Cost on val dataset after 168 epochs is = 0.12960201014796363\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.12960201014796363\n",
      "learning rate for this epoch =  0.13888095170058953\n",
      "Error on this batch = 0.09283468955679997\n",
      "Error on this batch = 0.13352521497136827\n",
      "Cost on val dataset after 169 epochs is = 0.12938500295869643\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.12938500295869643\n",
      "learning rate for this epoch =  0.1386750490563073\n",
      "Error on this batch = 0.09256135949890824\n",
      "Error on this batch = 0.13320669070946026\n",
      "Cost on val dataset after 170 epochs is = 0.1291699747012336\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.1291699747012336\n",
      "learning rate for this epoch =  0.13847066375656708\n",
      "Error on this batch = 0.0922906582969777\n",
      "Error on this batch = 0.1328905571026071\n",
      "Cost on val dataset after 171 epochs is = 0.12895689276867472\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.12895689276867472\n",
      "learning rate for this epoch =  0.1382677757922894\n",
      "Error on this batch = 0.09202253865961392\n",
      "Error on this batch = 0.13257678094805708\n",
      "Cost on val dataset after 172 epochs is = 0.12874572531609974\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.12874572531609974\n",
      "learning rate for this epoch =  0.1380663655333028\n",
      "Error on this batch = 0.09175695444394834\n",
      "Error on this batch = 0.1322653297640412\n",
      "Cost on val dataset after 173 epochs is = 0.12853644123834068\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.12853644123834068\n",
      "learning rate for this epoch =  0.13786641371901512\n",
      "Error on this batch = 0.0914938606251335\n",
      "Error on this batch = 0.13195617176947938\n",
      "Cost on val dataset after 174 epochs is = 0.12832901014853085\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.12832901014853085\n",
      "learning rate for this epoch =  0.13766790144936686\n",
      "Error on this batch = 0.09123321326643152\n",
      "Error on this batch = 0.13164927586446182\n",
      "Cost on val dataset after 175 epochs is = 0.12812340235739886\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.12812340235739886\n",
      "learning rate for this epoch =  0.1374708101760565\n",
      "Error on this batch = 0.09097496948990383\n",
      "Error on this batch = 0.13134461161146793\n",
      "Cost on val dataset after 176 epochs is = 0.12791958885327528\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.12791958885327528\n",
      "learning rate for this epoch =  0.1372751216940281\n",
      "Error on this batch = 0.09071908744771104\n",
      "Error on this batch = 0.13104214921728718\n",
      "Cost on val dataset after 177 epochs is = 0.12771754128278232\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.12771754128278232\n",
      "learning rate for this epoch =  0.1370808181332119\n",
      "Error on this batch = 0.09046552629402797\n",
      "Error on this batch = 0.13074185951560854\n",
      "Cost on val dataset after 178 epochs is = 0.12751723193217826\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.12751723193217826\n",
      "learning rate for this epoch =  0.13688788195050916\n",
      "Error on this batch = 0.09021424615757809\n",
      "Error on this batch = 0.1304437139502454\n",
      "Cost on val dataset after 179 epochs is = 0.1273186337093301\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.1273186337093301\n",
      "learning rate for this epoch =  0.13669629592201246\n",
      "Error on this batch = 0.08996520811479047\n",
      "Error on this batch = 0.13014768455896622\n",
      "Cost on val dataset after 180 epochs is = 0.1271217201262884\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.1271217201262884\n",
      "learning rate for this epoch =  0.13650604313545334\n",
      "Error on this batch = 0.08971837416358046\n",
      "Error on this batch = 0.12985374395790097\n",
      "Cost on val dataset after 181 epochs is = 0.12692646528244048\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.12692646528244048\n",
      "learning rate for this epoch =  0.13631710698286975\n",
      "Error on this batch = 0.0894737071977539\n",
      "Error on this batch = 0.12956186532649627\n",
      "Cost on val dataset after 182 epochs is = 0.1267328438482193\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.1267328438482193\n",
      "learning rate for this epoch =  0.1361294711534851\n",
      "Error on this batch = 0.08923117098203381\n",
      "Error on this batch = 0.12927202239299207\n",
      "Cost on val dataset after 183 epochs is = 0.1265408310493458\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.1265408310493458\n",
      "learning rate for this epoch =  0.13594311962679215\n",
      "Error on this batch = 0.08899073012770738\n",
      "Error on this batch = 0.1289841894203949\n",
      "Cost on val dataset after 184 epochs is = 0.1263504026515837\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.1263504026515837\n",
      "learning rate for this epoch =  0.13575803666583477\n",
      "Error on this batch = 0.08875235006888943\n",
      "Error on this batch = 0.12869834119292378\n",
      "Cost on val dataset after 185 epochs is = 0.12616153494598809\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.12616153494598809\n",
      "learning rate for this epoch =  0.13557420681068058\n",
      "Error on this batch = 0.08851599703939822\n",
      "Error on this batch = 0.12841445300290533\n",
      "Cost on val dataset after 186 epochs is = 0.1259742047346279\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.1259742047346279\n",
      "learning rate for this epoch =  0.13539161487207826\n",
      "Error on this batch = 0.08828163805023827\n",
      "Error on this batch = 0.12813250063809645\n",
      "Cost on val dataset after 187 epochs is = 0.1257883893167646\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.1257883893167646\n",
      "learning rate for this epoch =  0.13521024592529318\n",
      "Error on this batch = 0.08804924086768397\n",
      "Error on this batch = 0.1278524603694135\n",
      "Cost on val dataset after 188 epochs is = 0.12560406647547068\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.12560406647547068\n",
      "learning rate for this epoch =  0.1350300853041159\n",
      "Error on this batch = 0.08781877399195694\n",
      "Error on this batch = 0.12757430893904823\n",
      "Cost on val dataset after 189 epochs is = 0.1254212144646705\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.1254212144646705\n",
      "learning rate for this epoch =  0.13485111859503687\n",
      "Error on this batch = 0.08759020663649014\n",
      "Error on this batch = 0.1272980235489508\n",
      "Cost on val dataset after 190 epochs is = 0.12523981199658915\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.12523981199658915\n",
      "learning rate for this epoch =  0.13467333163158285\n",
      "Error on this batch = 0.08736350870776988\n",
      "Error on this batch = 0.12702358184966245\n",
      "Cost on val dataset after 191 epochs is = 0.1250598382295932\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.1250598382295932\n",
      "learning rate for this epoch =  0.13449671048880912\n",
      "Error on this batch = 0.08713865078574731\n",
      "Error on this batch = 0.12675096192947993\n",
      "Cost on val dataset after 192 epochs is = 0.12488127275641034\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.12488127275641034\n",
      "learning rate for this epoch =  0.13432124147794275\n",
      "Error on this batch = 0.08691560410481029\n",
      "Error on this batch = 0.12648014230393562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 193 epochs is = 0.12470409559271328\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.12470409559271328\n",
      "learning rate for this epoch =  0.1341469111411715\n",
      "Error on this batch = 0.08669434053530578\n",
      "Error on this batch = 0.12621110190557708\n",
      "Cost on val dataset after 194 epochs is = 0.1245282871660557\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.1245282871660557\n",
      "learning rate for this epoch =  0.13397370624657456\n",
      "Error on this batch = 0.08647483256560286\n",
      "Error on this batch = 0.12594382007403188\n",
      "Cost on val dataset after 195 epochs is = 0.12435382830514706\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.12435382830514706\n",
      "learning rate for this epoch =  0.13380161378318955\n",
      "Error on this batch = 0.08625705328468598\n",
      "Error on this batch = 0.12567827654634287\n",
      "Cost on val dataset after 196 epochs is = 0.12418070022945499\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.12418070022945499\n",
      "learning rate for this epoch =  0.1336306209562122\n",
      "Error on this batch = 0.0860409763652678\n",
      "Error on this batch = 0.1254144514475604\n",
      "Cost on val dataset after 197 epochs is = 0.1240088845391234\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.1240088845391234\n",
      "learning rate for this epoch =  0.13346071518232402\n",
      "Error on this batch = 0.08582657604741087\n",
      "Error on this batch = 0.1251523252815796\n",
      "Cost on val dataset after 198 epochs is = 0.12383836320519546\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.12383836320519546\n",
      "learning rate for this epoch =  0.13329188408514428\n",
      "Error on this batch = 0.08561382712264708\n",
      "Error on this batch = 0.12489187892220985\n",
      "Cost on val dataset after 199 epochs is = 0.1236691185601309\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.1236691185601309\n",
      "learning rate for this epoch =  0.13312411549080203\n",
      "Error on this batch = 0.08540270491858351\n",
      "Error on this batch = 0.12463309360446508\n",
      "Cost on val dataset after 200 epochs is = 0.12350113328860753\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.12350113328860753\n",
      "learning rate for this epoch =  0.13295739742362472\n",
      "Error on this batch = 0.08519318528398355\n",
      "Error on this batch = 0.1243759509160647\n",
      "Cost on val dataset after 201 epochs is = 0.12333439041859741\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.12333439041859741\n",
      "learning rate for this epoch =  0.13279171810193946\n",
      "Error on this batch = 0.08498524457431202\n",
      "Error on this batch = 0.12412043278913495\n",
      "Cost on val dataset after 202 epochs is = 0.12316887331270805\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.12316887331270805\n",
      "learning rate for this epoch =  0.13262706593398382\n",
      "Error on this batch = 0.08477885963773257\n",
      "Error on this batch = 0.12386652149210071\n",
      "Cost on val dataset after 203 epochs is = 0.12300456565977984\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.12300456565977984\n",
      "learning rate for this epoch =  0.13246342951392248\n",
      "Error on this batch = 0.08457400780154588\n",
      "Error on this batch = 0.12361419962175965\n",
      "Cost on val dataset after 204 epochs is = 0.12284145146673124\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.12284145146673124\n",
      "learning rate for this epoch =  0.13230079761796648\n",
      "Error on this batch = 0.08437066685905763\n",
      "Error on this batch = 0.12336345009552989\n",
      "Cost on val dataset after 205 epochs is = 0.12267951505064313\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.12267951505064313\n",
      "learning rate for this epoch =  0.13213915920059222\n",
      "Error on this batch = 0.08416881505686431\n",
      "Error on this batch = 0.12311425614386397\n",
      "Cost on val dataset after 206 epochs is = 0.12251874103107457\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.12251874103107457\n",
      "learning rate for this epoch =  0.13197850339085695\n",
      "Error on this batch = 0.08396843108254594\n",
      "Error on this batch = 0.12286660130282136\n",
      "Cost on val dataset after 207 epochs is = 0.12235911432260242\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.12235911432260242\n",
      "learning rate for this epoch =  0.1318188194888078\n",
      "Error on this batch = 0.08376949405275369\n",
      "Error on this batch = 0.12262046940679376\n",
      "Cost on val dataset after 208 epochs is = 0.12220062012757676\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.12220062012757676\n",
      "learning rate for this epoch =  0.13166009696198164\n",
      "Error on this batch = 0.08357198350168227\n",
      "Error on this batch = 0.12237584458137643\n",
      "Cost on val dataset after 209 epochs is = 0.12204324392908598\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.12204324392908598\n",
      "learning rate for this epoch =  0.1315023254419931\n",
      "Error on this batch = 0.08337587936991504\n",
      "Error on this batch = 0.12213271123638018\n",
      "Cost on val dataset after 210 epochs is = 0.1218869714841239\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.1218869714841239\n",
      "learning rate for this epoch =  0.1313454947212079\n",
      "Error on this batch = 0.08318116199363114\n",
      "Error on this batch = 0.12189105405897906\n",
      "Cost on val dataset after 211 epochs is = 0.12173178881695275\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.12173178881695275\n",
      "learning rate for this epoch =  0.13118959474949932\n",
      "Error on this batch = 0.08298781209416418\n",
      "Error on this batch = 0.1216508580069889\n",
      "Cost on val dataset after 212 epochs is = 0.12157768221265533\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.12157768221265533\n",
      "learning rate for this epoch =  0.1310346156310848\n",
      "Error on this batch = 0.08279581076790116\n",
      "Error on this batch = 0.12141210830227298\n",
      "Cost on val dataset after 213 epochs is = 0.12142463821087045\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.12142463821087045\n",
      "learning rate for this epoch =  0.13088054762144102\n",
      "Error on this batch = 0.08260513947651152\n",
      "Error on this batch = 0.12117479042427015\n",
      "Cost on val dataset after 214 epochs is = 0.1212726435997058\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.1212726435997058\n",
      "learning rate for this epoch =  0.13072738112429463\n",
      "Error on this batch = 0.08241578003749613\n",
      "Error on this batch = 0.12093889010364314\n",
      "Cost on val dataset after 215 epochs is = 0.12112168540982214\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.12112168540982214\n",
      "learning rate for this epoch =  0.1305751066886864\n",
      "Error on this batch = 0.0822277146150453\n",
      "Error on this batch = 0.12070439331604334\n",
      "Cost on val dataset after 216 epochs is = 0.1209717509086838\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.1209717509086838\n",
      "learning rate for this epoch =  0.13042371500610728\n",
      "Error on this batch = 0.08204092571119677\n",
      "Error on this batch = 0.12047128627598962\n",
      "Cost on val dataset after 217 epochs is = 0.12082282759496984\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.12082282759496984\n",
      "learning rate for this epoch =  0.13027319690770342\n",
      "Error on this batch = 0.08185539615728317\n",
      "Error on this batch = 0.12023955543085892\n",
      "Cost on val dataset after 218 epochs is = 0.12067490319314104\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.12067490319314104\n",
      "learning rate for this epoch =  0.13012354336154894\n",
      "Error on this batch = 0.08167110910565972\n",
      "Error on this batch = 0.12000918745498687\n",
      "Cost on val dataset after 219 epochs is = 0.1205279656481574\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.1205279656481574\n",
      "learning rate for this epoch =  0.12997474546998408\n",
      "Error on this batch = 0.08148804802170281\n",
      "Error on this batch = 0.11978016924387618\n",
      "Cost on val dataset after 220 epochs is = 0.12038200312034167\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.12038200312034167\n",
      "learning rate for this epoch =  0.12982679446701692\n",
      "Error on this batch = 0.08130619667607009\n",
      "Error on this batch = 0.11955248790851225\n",
      "Cost on val dataset after 221 epochs is = 0.1202370039803844\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.1202370039803844\n",
      "learning rate for this epoch =  0.12967968171578698\n",
      "Error on this batch = 0.08112553913721325\n",
      "Error on this batch = 0.11932613076978403\n",
      "Cost on val dataset after 222 epochs is = 0.12009295680448595\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.12009295680448595\n",
      "learning rate for this epoch =  0.12953339870608896\n",
      "Error on this batch = 0.08094605976413487\n",
      "Error on this batch = 0.1191010853530098\n",
      "Cost on val dataset after 223 epochs is = 0.11994985036963061\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.11994985036963061\n",
      "learning rate for this epoch =  0.12938793705195484\n",
      "Error on this batch = 0.0807677431993807\n",
      "Error on this batch = 0.11887733938256698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 224 epochs is = 0.11980767364899003\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.11980767364899003\n",
      "learning rate for this epoch =  0.12924328848929265\n",
      "Error on this batch = 0.08059057436225889\n",
      "Error on this batch = 0.11865488077662534\n",
      "Cost on val dataset after 225 epochs is = 0.11966641580745065\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.11966641580745065\n",
      "learning rate for this epoch =  0.12909944487358055\n",
      "Error on this batch = 0.08041453844227882\n",
      "Error on this batch = 0.1184336976419835\n",
      "Cost on val dataset after 226 epochs is = 0.11952606619726189\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.11952606619726189\n",
      "learning rate for this epoch =  0.1289563981776146\n",
      "Error on this batch = 0.08023962089280079\n",
      "Error on this batch = 0.11821377826900857\n",
      "Cost on val dataset after 227 epochs is = 0.11938661435380152\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.11938661435380152\n",
      "learning rate for this epoch =  0.12881414048930848\n",
      "Error on this batch = 0.08006580742488957\n",
      "Error on this batch = 0.11799511112667833\n",
      "Cost on val dataset after 228 epochs is = 0.11924804999145415\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.11924804999145415\n",
      "learning rate for this epoch =  0.1286726640095442\n",
      "Error on this batch = 0.07989308400136431\n",
      "Error on this batch = 0.11777768485772688\n",
      "Cost on val dataset after 229 epochs is = 0.11911036299959973\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.11911036299959973\n",
      "learning rate for this epoch =  0.12853196105007209\n",
      "Error on this batch = 0.07972143683103747\n",
      "Error on this batch = 0.11756148827389311\n",
      "Cost on val dataset after 230 epochs is = 0.11897354343870861\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.11897354343870861\n",
      "learning rate for this epoch =  0.12839202403145872\n",
      "Error on this batch = 0.07955085236313582\n",
      "Error on this batch = 0.11734651035127262\n",
      "Cost on val dataset after 231 epochs is = 0.11883758153654005\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.11883758153654005\n",
      "learning rate for this epoch =  0.12825284548108173\n",
      "Error on this batch = 0.0793813172818974\n",
      "Error on this batch = 0.11713274022577348\n",
      "Cost on val dataset after 232 epochs is = 0.11870246768444057\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.11870246768444057\n",
      "learning rate for this epoch =  0.1281144180311698\n",
      "Error on this batch = 0.0792128185013369\n",
      "Error on this batch = 0.11692016718867562\n",
      "Cost on val dataset after 233 epochs is = 0.1185681924337399\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.1185681924337399\n",
      "learning rate for this epoch =  0.12797673441688712\n",
      "Error on this batch = 0.07904534316017393\n",
      "Error on this batch = 0.1167087806822945\n",
      "Cost on val dataset after 234 epochs is = 0.11843474649224124\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.11843474649224124\n",
      "learning rate for this epoch =  0.12783978747446093\n",
      "Error on this batch = 0.07887887861691803\n",
      "Error on this batch = 0.1164985702957499\n",
      "Cost on val dataset after 235 epochs is = 0.11830212072080253\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.11830212072080253\n",
      "learning rate for this epoch =  0.12770357013935066\n",
      "Error on this batch = 0.07871341244510405\n",
      "Error on this batch = 0.11628952576083883\n",
      "Cost on val dataset after 236 epochs is = 0.11817030613000688\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.11817030613000688\n",
      "learning rate for this epoch =  0.12756807544445822\n",
      "Error on this batch = 0.07854893242867289\n",
      "Error on this batch = 0.11608163694801447\n",
      "Cost on val dataset after 237 epochs is = 0.11803929387691932\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.11803929387691932\n",
      "learning rate for this epoch =  0.1274332965183777\n",
      "Error on this batch = 0.0783854265574917\n",
      "Error on this batch = 0.11587489386247019\n",
      "Cost on val dataset after 238 epochs is = 0.11790907526192657\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.11790907526192657\n",
      "learning rate for this epoch =  0.12729922658368395\n",
      "Error on this batch = 0.07822288302300831\n",
      "Error on this batch = 0.11566928664032929\n",
      "Cost on val dataset after 239 epochs is = 0.11777964172565855\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.11777964172565855\n",
      "learning rate for this epoch =  0.12716585895525878\n",
      "Error on this batch = 0.07806129021403495\n",
      "Error on this batch = 0.11546480554494112\n",
      "Cost on val dataset after 240 epochs is = 0.11765098484598838\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.11765098484598838\n",
      "learning rate for this epoch =  0.12703318703865368\n",
      "Error on this batch = 0.0779006367126564\n",
      "Error on this batch = 0.1152614409632826\n",
      "Cost on val dataset after 241 epochs is = 0.11752309633510914\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.11752309633510914\n",
      "learning rate for this epoch =  0.12690120432848842\n",
      "Error on this batch = 0.07774091129025759\n",
      "Error on this batch = 0.11505918340246624\n",
      "Cost on val dataset after 242 epochs is = 0.11739596803668469\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.11739596803668469\n",
      "learning rate for this epoch =  0.12676990440688446\n",
      "Error on this batch = 0.07758210290366649\n",
      "Error on this batch = 0.11485802348635399\n",
      "Cost on val dataset after 243 epochs is = 0.1172695919230729\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.1172695919230729\n",
      "learning rate for this epoch =  0.12663928094193208\n",
      "Error on this batch = 0.07742420069140753\n",
      "Error on this batch = 0.11465795195227702\n",
      "Cost on val dataset after 244 epochs is = 0.11714396009261892\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.11714396009261892\n",
      "learning rate for this epoch =  0.12650932768619078\n",
      "Error on this batch = 0.07726719397006188\n",
      "Error on this batch = 0.11445895964786088\n",
      "Cost on val dataset after 245 epochs is = 0.1170190647670167\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.1170190647670167\n",
      "learning rate for this epoch =  0.12638003847522164\n",
      "Error on this batch = 0.0771110722307301\n",
      "Error on this batch = 0.11426103752795624\n",
      "Cost on val dataset after 246 epochs is = 0.11689489828873662\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.11689489828873662\n",
      "learning rate for this epoch =  0.1262514072261512\n",
      "Error on this batch = 0.0769558251355936\n",
      "Error on this batch = 0.114064176651674\n",
      "Cost on val dataset after 247 epochs is = 0.11677145311851728\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.11677145311851728\n",
      "learning rate for this epoch =  0.12612342793626585\n",
      "Error on this batch = 0.07680144251457104\n",
      "Error on this batch = 0.11386836817952511\n",
      "Cost on val dataset after 248 epochs is = 0.11664872183292047\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.11664872183292047\n",
      "learning rate for this epoch =  0.1259960946816361\n",
      "Error on this batch = 0.0766479143620664\n",
      "Error on this batch = 0.11367360337066339\n",
      "Cost on val dataset after 249 epochs is = 0.11652669712194631\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.11652669712194631\n",
      "learning rate for this epoch =  0.12586940161576976\n",
      "Error on this batch = 0.07649523083380488\n",
      "Error on this batch = 0.11347987358023154\n",
      "Cost on val dataset after 250 epochs is = 0.11640537178670783\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.11640537178670783\n",
      "learning rate for this epoch =  0.12574334296829354\n",
      "Error on this batch = 0.07634338224375395\n",
      "Error on this batch = 0.11328717025680864\n",
      "Cost on val dataset after 251 epochs is = 0.11628473873716297\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.11628473873716297\n",
      "learning rate for this epoch =  0.1256179130436622\n",
      "Error on this batch = 0.07619235906112598\n",
      "Error on this batch = 0.11309548493995852\n",
      "Cost on val dataset after 252 epochs is = 0.11616479098990261\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.11616479098990261\n",
      "learning rate for this epoch =  0.12549310621989482\n",
      "Error on this batch = 0.07604215190745955\n",
      "Error on this batch = 0.11290480925787803\n",
      "Cost on val dataset after 253 epochs is = 0.11604552166599286\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.11604552166599286\n",
      "learning rate for this epoch =  0.125368916947337\n",
      "Error on this batch = 0.07589275155377685\n",
      "Error on this batch = 0.11271513492514319\n",
      "Cost on val dataset after 254 epochs is = 0.11592692398887043\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.11592692398887043\n",
      "learning rate for this epoch =  0.12524533974744914\n",
      "Error on this batch = 0.0757441489178141\n",
      "Error on this batch = 0.11252645374055266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 255 epochs is = 0.11580899128228916\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.11580899128228916\n",
      "learning rate for this epoch =  0.12512236921161915\n",
      "Error on this batch = 0.0755963350613228\n",
      "Error on this batch = 0.1123387575850667\n",
      "Cost on val dataset after 256 epochs is = 0.11569171696831704\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.11569171696831704\n",
      "learning rate for this epoch =  0.125\n",
      "Error on this batch = 0.07544930118743873\n",
      "Error on this batch = 0.11215203841983996\n",
      "Cost on val dataset after 257 epochs is = 0.11557509456538176\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.11557509456538176\n",
      "learning rate for this epoch =  0.12487822684037092\n",
      "Error on this batch = 0.07530303863811691\n",
      "Error on this batch = 0.11196628828434638\n",
      "Cost on val dataset after 258 epochs is = 0.11545911768636377\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.11545911768636377\n",
      "learning rate for this epoch =  0.12475704452702165\n",
      "Error on this batch = 0.07515753889162995\n",
      "Error on this batch = 0.11178149929459476\n",
      "Cost on val dataset after 259 epochs is = 0.11534378003673534\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.11534378003673534\n",
      "learning rate for this epoch =  0.12463644791965951\n",
      "Error on this batch = 0.07501279356012754\n",
      "Error on this batch = 0.11159766364143271\n",
      "Cost on val dataset after 260 epochs is = 0.11522907541274482\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.11522907541274482\n",
      "learning rate for this epoch =  0.12451643194233865\n",
      "Error on this batch = 0.07486879438725529\n",
      "Error on this batch = 0.1114147735889371\n",
      "Cost on val dataset after 261 epochs is = 0.11511499769964464\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.11511499769964464\n",
      "learning rate for this epoch =  0.12439699158241055\n",
      "Error on this batch = 0.0747255332458306\n",
      "Error on this batch = 0.11123282147288899\n",
      "Cost on val dataset after 262 epochs is = 0.1150015408699614\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.1150015408699614\n",
      "learning rate for this epoch =  0.12427812188949586\n",
      "Error on this batch = 0.07458300213557414\n",
      "Error on this batch = 0.11105179969933109\n",
      "Cost on val dataset after 263 epochs is = 0.11488869898180833\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.11488869898180833\n",
      "learning rate for this epoch =  0.1241598179744767\n",
      "Error on this batch = 0.0744411931808943\n",
      "Error on this batch = 0.11087170074320507\n",
      "Cost on val dataset after 264 epochs is = 0.11477646617723729\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.11477646617723729\n",
      "learning rate for this epoch =  0.12404207500850907\n",
      "Error on this batch = 0.07430009862872394\n",
      "Error on this batch = 0.11069251714706697\n",
      "Cost on val dataset after 265 epochs is = 0.11466483668063056\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.11466483668063056\n",
      "learning rate for this epoch =  0.12392488822205483\n",
      "Error on this batch = 0.07415971084640699\n",
      "Error on this batch = 0.11051424151987782\n",
      "Cost on val dataset after 266 epochs is = 0.1145538047971307\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.1145538047971307\n",
      "learning rate for this epoch =  0.12380825290393263\n",
      "Error on this batch = 0.07402002231963366\n",
      "Error on this batch = 0.1103368665358677\n",
      "Cost on val dataset after 267 epochs is = 0.11444336491110786\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.11444336491110786\n",
      "learning rate for this epoch =  0.12369216440038802\n",
      "Error on this batch = 0.07388102565042264\n",
      "Error on this batch = 0.11016038493347022\n",
      "Cost on val dataset after 268 epochs is = 0.11433351148466313\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.11433351148466313\n",
      "learning rate for this epoch =  0.1235766181141811\n",
      "Error on this batch = 0.07374271355514898\n",
      "Error on this batch = 0.10998478951432525\n",
      "Cost on val dataset after 269 epochs is = 0.1142242390561677\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.1142242390561677\n",
      "learning rate for this epoch =  0.12346160950369273\n",
      "Error on this batch = 0.07360507886261612\n",
      "Error on this batch = 0.10981007314234756\n",
      "Cost on val dataset after 270 epochs is = 0.1141155422388359\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.1141155422388359\n",
      "learning rate for this epoch =  0.12334713408204756\n",
      "Error on this batch = 0.07346811451217092\n",
      "Error on this batch = 0.10963622874285817\n",
      "Cost on val dataset after 271 epochs is = 0.11400741571933222\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.11400741571933222\n",
      "learning rate for this epoch =  0.12323318741625437\n",
      "Error on this batch = 0.07333181355186008\n",
      "Error on this batch = 0.10946324930177678\n",
      "Cost on val dataset after 272 epochs is = 0.1138998542564106\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.1138998542564106\n",
      "learning rate for this epoch =  0.12311976512636309\n",
      "Error on this batch = 0.07319616913662749\n",
      "Error on this batch = 0.10929112786487187\n",
      "Cost on val dataset after 273 epochs is = 0.113792852679586\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.113792852679586\n",
      "learning rate for this epoch =  0.12300686288463769\n",
      "Error on this batch = 0.0730611745265504\n",
      "Error on this batch = 0.10911985753706638\n",
      "Cost on val dataset after 274 epochs is = 0.11368640588783659\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.11368640588783659\n",
      "learning rate for this epoch =  0.12289447641474543\n",
      "Error on this batch = 0.0729268230851139\n",
      "Error on this batch = 0.10894943148179635\n",
      "Cost on val dataset after 275 epochs is = 0.11358050884833619\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.11358050884833619\n",
      "learning rate for this epoch =  0.12278260149096118\n",
      "Error on this batch = 0.07279310827752287\n",
      "Error on this batch = 0.1087798429204198\n",
      "Cost on val dataset after 276 epochs is = 0.11347515659521593\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.11347515659521593\n",
      "learning rate for this epoch =  0.12267123393738709\n",
      "Error on this batch = 0.07266002366904946\n",
      "Error on this batch = 0.10861108513167328\n",
      "Cost on val dataset after 277 epochs is = 0.11337034422835504\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.11337034422835504\n",
      "learning rate for this epoch =  0.12256036962718717\n",
      "Error on this batch = 0.0725275629234163\n",
      "Error on this batch = 0.1084431514511738\n",
      "Cost on val dataset after 278 epochs is = 0.11326606691219902\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.11326606691219902\n",
      "learning rate for this epoch =  0.12245000448183609\n",
      "Error on this batch = 0.07239571980121338\n",
      "Error on this batch = 0.10827603527096351\n",
      "Cost on val dataset after 279 epochs is = 0.11316231987460487\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.11316231987460487\n",
      "learning rate for this epoch =  0.12234013447038239\n",
      "Error on this batch = 0.07226448815834872\n",
      "Error on this batch = 0.10810973003909423\n",
      "Cost on val dataset after 280 epochs is = 0.11305909840571332\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.11305909840571332\n",
      "learning rate for this epoch =  0.12223075560872526\n",
      "Error on this batch = 0.07213386194453111\n",
      "Error on this batch = 0.1079442292592504\n",
      "Cost on val dataset after 281 epochs is = 0.11295639785684626\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.11295639785684626\n",
      "learning rate for this epoch =  0.12212186395890517\n",
      "Error on this batch = 0.0720038352017847\n",
      "Error on this batch = 0.10777952649040672\n",
      "Cost on val dataset after 282 epochs is = 0.1128542136394294\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.1128542136394294\n",
      "learning rate for this epoch =  0.12201345562840739\n",
      "Error on this batch = 0.07187440206299404\n",
      "Error on this batch = 0.10761561534651921\n",
      "Cost on val dataset after 283 epochs is = 0.11275254122393938\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.11275254122393938\n",
      "learning rate for this epoch =  0.12190552676947876\n",
      "Error on this batch = 0.07174555675047986\n",
      "Error on this batch = 0.10745248949624685\n",
      "Cost on val dataset after 284 epochs is = 0.11265137613887473\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.11265137613887473\n",
      "learning rate for this epoch =  0.12179807357845675\n",
      "Error on this batch = 0.07161729357460296\n",
      "Error on this batch = 0.10729014266270148\n",
      "Cost on val dataset after 285 epochs is = 0.11255071396974964\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.11255071396974964\n",
      "learning rate for this epoch =  0.12169109229511134\n",
      "Error on this batch = 0.07148960693239798\n",
      "Error on this batch = 0.10712856862322406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 286 epochs is = 0.11245055035811069\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.11245055035811069\n",
      "learning rate for this epoch =  0.12158457920199858\n",
      "Error on this batch = 0.07136249130623389\n",
      "Error on this batch = 0.10696776120918486\n",
      "Cost on val dataset after 287 epochs is = 0.11235088100057516\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.11235088100057516\n",
      "learning rate for this epoch =  0.1214785306238262\n",
      "Error on this batch = 0.07123594126250225\n",
      "Error on this batch = 0.10680771430580538\n",
      "Cost on val dataset after 288 epochs is = 0.11225170164789094\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.11225170164789094\n",
      "learning rate for this epoch =  0.12137294292683086\n",
      "Error on this batch = 0.07110995145033171\n",
      "Error on this batch = 0.10664842185200073\n",
      "Cost on val dataset after 289 epochs is = 0.11215300810401718\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.11215300810401718\n",
      "learning rate for this epoch =  0.12126781251816648\n",
      "Error on this batch = 0.0709845166003285\n",
      "Error on this batch = 0.10648987784023894\n",
      "Cost on val dataset after 290 epochs is = 0.11205479622522511\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.11205479622522511\n",
      "learning rate for this epoch =  0.121163135845304\n",
      "Error on this batch = 0.07085963152334188\n",
      "Error on this batch = 0.10633207631641733\n",
      "Cost on val dataset after 291 epochs is = 0.11195706191921871\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.11195706191921871\n",
      "learning rate for this epoch =  0.12105890939544156\n",
      "Error on this batch = 0.07073529110925436\n",
      "Error on this batch = 0.10617501137975208\n",
      "Cost on val dataset after 292 epochs is = 0.1118598011442746\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.1118598011442746\n",
      "learning rate for this epoch =  0.1209551296949258\n",
      "Error on this batch = 0.07061149032579593\n",
      "Error on this batch = 0.10601867718268082\n",
      "Cost on val dataset after 293 epochs is = 0.11176300990840043\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.11176300990840043\n",
      "learning rate for this epoch =  0.12085179330868305\n",
      "Error on this batch = 0.07048822421738146\n",
      "Error on this batch = 0.10586306793077563\n",
      "Cost on val dataset after 294 epochs is = 0.11166668426851178\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.11166668426851178\n",
      "learning rate for this epoch =  0.12074889683966107\n",
      "Error on this batch = 0.07036548790397118\n",
      "Error on this batch = 0.10570817788266482\n",
      "Cost on val dataset after 295 epochs is = 0.11157082032962659\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.11157082032962659\n",
      "learning rate for this epoch =  0.12064643692828043\n",
      "Error on this batch = 0.07024327657995313\n",
      "Error on this batch = 0.10555400134996276\n",
      "Cost on val dataset after 296 epochs is = 0.11147541424407693\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.11147541424407693\n",
      "learning rate for this epoch =  0.120544410251896\n",
      "Error on this batch = 0.07012158551304747\n",
      "Error on this batch = 0.10540053269720517\n",
      "Cost on val dataset after 297 epochs is = 0.11138046221073757\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.11138046221073757\n",
      "learning rate for this epoch =  0.12044281352426756\n",
      "Error on this batch = 0.07000041004323183\n",
      "Error on this batch = 0.10524776634178906\n",
      "Cost on val dataset after 298 epochs is = 0.11128596047427106\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.11128596047427106\n",
      "learning rate for this epoch =  0.12034164349504001\n",
      "Error on this batch = 0.06987974558168733\n",
      "Error on this batch = 0.10509569675391617\n",
      "Cost on val dataset after 299 epochs is = 0.11119190532438865\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.11119190532438865\n",
      "learning rate for this epoch =  0.12024089694923273\n",
      "Error on this batch = 0.06975958760976445\n",
      "Error on this batch = 0.10494431845653784\n",
      "Cost on val dataset after 300 epochs is = 0.11109829309512674\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.11109829309512674\n",
      "learning rate for this epoch =  0.12014057070673773\n",
      "Error on this batch = 0.06963993167796868\n",
      "Error on this batch = 0.10479362602530123\n",
      "Cost on val dataset after 301 epochs is = 0.11100512016413855\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.11100512016413855\n",
      "learning rate for this epoch =  0.1200406616218266\n",
      "Error on this batch = 0.06952077340496492\n",
      "Error on this batch = 0.10464361408849435\n",
      "Cost on val dataset after 302 epochs is = 0.11091238295200057\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.11091238295200057\n",
      "learning rate for this epoch =  0.11994116658266626\n",
      "Error on this batch = 0.06940210847660044\n",
      "Error on this batch = 0.10449427732699024\n",
      "Cost on val dataset after 303 epochs is = 0.11082007792153327\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.11082007792153327\n",
      "learning rate for this epoch =  0.1198420825108428\n",
      "Error on this batch = 0.06928393264494581\n",
      "Error on this batch = 0.10434561047418833\n",
      "Cost on val dataset after 304 epochs is = 0.1107282015771361\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.1107282015771361\n",
      "learning rate for this epoch =  0.11974340636089367\n",
      "Error on this batch = 0.06916624172735328\n",
      "Error on this batch = 0.10419760831595241\n",
      "Cost on val dataset after 305 epochs is = 0.11063675046413562\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.11063675046413562\n",
      "learning rate for this epoch =  0.11964513511984808\n",
      "Error on this batch = 0.06904903160553183\n",
      "Error on this batch = 0.10405026569054421\n",
      "Cost on val dataset after 306 epochs is = 0.11054572116814755\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.11054572116814755\n",
      "learning rate for this epoch =  0.11954726580677509\n",
      "Error on this batch = 0.06893229822463916\n",
      "Error on this batch = 0.10390357748855206\n",
      "Cost on val dataset after 307 epochs is = 0.11045511031445135\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.11045511031445135\n",
      "learning rate for this epoch =  0.11944979547233951\n",
      "Error on this batch = 0.06881603759238906\n",
      "Error on this batch = 0.10375753865281336\n",
      "Cost on val dataset after 308 epochs is = 0.11036491456737771\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.11036491456737771\n",
      "learning rate for this epoch =  0.1193527211983654\n",
      "Error on this batch = 0.06870024577817456\n",
      "Error on this batch = 0.10361214417833058\n",
      "Cost on val dataset after 309 epochs is = 0.11027513062970808\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.11027513062970808\n",
      "learning rate for this epoch =  0.11925604009740705\n",
      "Error on this batch = 0.06858491891220574\n",
      "Error on this batch = 0.10346738911218023\n",
      "Cost on val dataset after 310 epochs is = 0.11018575524208662\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.11018575524208662\n",
      "learning rate for this epoch =  0.11915974931232703\n",
      "Error on this batch = 0.06847005318466214\n",
      "Error on this batch = 0.1033232685534136\n",
      "Cost on val dataset after 311 epochs is = 0.11009678518244342\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.11009678518244342\n",
      "learning rate for this epoch =  0.1190638460158816\n",
      "Error on this batch = 0.068355644844859\n",
      "Error on this batch = 0.10317977765294951\n",
      "Cost on val dataset after 312 epochs is = 0.11000821726542943\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.11000821726542943\n",
      "learning rate for this epoch =  0.11896832741031306\n",
      "Error on this batch = 0.0682416902004271\n",
      "Error on this batch = 0.10303691161345802\n",
      "Cost on val dataset after 313 epochs is = 0.10992004834186257\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.10992004834186257\n",
      "learning rate for this epoch =  0.11887319072694875\n",
      "Error on this batch = 0.06812818561650523\n",
      "Error on this batch = 0.10289466568923512\n",
      "Cost on val dataset after 314 epochs is = 0.10983227529818444\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.10983227529818444\n",
      "learning rate for this epoch =  0.11877843322580707\n",
      "Error on this batch = 0.06801512751494554\n",
      "Error on this batch = 0.10275303518606745\n",
      "Cost on val dataset after 315 epochs is = 0.10974489505592784\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.10974489505592784\n",
      "learning rate for this epoch =  0.11868405219520976\n",
      "Error on this batch = 0.06790251237353041\n",
      "Error on this batch = 0.1026120154610872\n",
      "Cost on val dataset after 316 epochs is = 0.10965790457119465\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.10965790457119465\n",
      "learning rate for this epoch =  0.11859004495140096\n",
      "Error on this batch = 0.0677903367252013\n",
      "Error on this batch = 0.10247160192261694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 317 epochs is = 0.10957130083414365\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.10957130083414365\n",
      "learning rate for this epoch =  0.11849640883817222\n",
      "Error on this batch = 0.06767859715729818\n",
      "Error on this batch = 0.10233179003000346\n",
      "Cost on val dataset after 318 epochs is = 0.10948508086848825\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.10948508086848825\n",
      "learning rate for this epoch =  0.11840314122649412\n",
      "Error on this batch = 0.06756729031080998\n",
      "Error on this batch = 0.1021925752934413\n",
      "Cost on val dataset after 319 epochs is = 0.10939924173100386\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.10939924173100386\n",
      "learning rate for this epoch =  0.11831023951415345\n",
      "Error on this batch = 0.06745641287963457\n",
      "Error on this batch = 0.10205395327378515\n",
      "Cost on val dataset after 320 epochs is = 0.10931378051104451\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.10931378051104451\n",
      "learning rate for this epoch =  0.11821770112539698\n",
      "Error on this batch = 0.06734596160984899\n",
      "Error on this batch = 0.10191591958235108\n",
      "Cost on val dataset after 321 epochs is = 0.10922869433006883\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.10922869433006883\n",
      "learning rate for this epoch =  0.11812552351058042\n",
      "Error on this batch = 0.06723593329898822\n",
      "Error on this batch = 0.10177846988070695\n",
      "Cost on val dataset after 322 epochs is = 0.10914398034117462\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.10914398034117462\n",
      "learning rate for this epoch =  0.11803370414582362\n",
      "Error on this batch = 0.06712632479533323\n",
      "Error on this batch = 0.10164159988045106\n",
      "Cost on val dataset after 323 epochs is = 0.10905963572864241\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.10905963572864241\n",
      "learning rate for this epoch =  0.11794224053267104\n",
      "Error on this batch = 0.06701713299720698\n",
      "Error on this batch = 0.10150530534298004\n",
      "Cost on val dataset after 324 epochs is = 0.10897565770748745\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.10897565770748745\n",
      "learning rate for this epoch =  0.11785113019775793\n",
      "Error on this batch = 0.06690835485227822\n",
      "Error on this batch = 0.10136958207924504\n",
      "Cost on val dataset after 325 epochs is = 0.10889204352301983\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.10889204352301983\n",
      "learning rate for this epoch =  0.11776037069248181\n",
      "Error on this batch = 0.06679998735687302\n",
      "Error on this batch = 0.10123442594949665\n",
      "Cost on val dataset after 326 epochs is = 0.10880879045041274\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.10880879045041274\n",
      "learning rate for this epoch =  0.11766995959267931\n",
      "Error on this batch = 0.0666920275552928\n",
      "Error on this batch = 0.1010998328630189\n",
      "Cost on val dataset after 327 epochs is = 0.10872589579427884\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.10872589579427884\n",
      "learning rate for this epoch =  0.11757989449830816\n",
      "Error on this batch = 0.06658447253913956\n",
      "Error on this batch = 0.10096579877785145\n",
      "Cost on val dataset after 328 epochs is = 0.10864335688825404\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.10864335688825404\n",
      "learning rate for this epoch =  0.11749017303313421\n",
      "Error on this batch = 0.06647731944664657\n",
      "Error on this batch = 0.1008323197005011\n",
      "Cost on val dataset after 329 epochs is = 0.1085611710945888\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.1085611710945888\n",
      "learning rate for this epoch =  0.11740079284442367\n",
      "Error on this batch = 0.06637056546201553\n",
      "Error on this batch = 0.10069939168564229\n",
      "Cost on val dataset after 330 epochs is = 0.10847933580374702\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.10847933580374702\n",
      "learning rate for this epoch =  0.11731175160264\n",
      "Error on this batch = 0.06626420781475856\n",
      "Error on this batch = 0.10056701083580614\n",
      "Cost on val dataset after 331 epochs is = 0.10839784843401185\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.10839784843401185\n",
      "learning rate for this epoch =  0.11722304700114572\n",
      "Error on this batch = 0.06615824377904564\n",
      "Error on this batch = 0.1004351733010596\n",
      "Cost on val dataset after 332 epochs is = 0.10831670643109839\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.10831670643109839\n",
      "learning rate for this epoch =  0.11713467675590904\n",
      "Error on this batch = 0.06605267067305651\n",
      "Error on this batch = 0.10030387527867303\n",
      "Cost on val dataset after 333 epochs is = 0.10823590726777355\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.10823590726777355\n",
      "learning rate for this epoch =  0.11704663860521486\n",
      "Error on this batch = 0.06594748585833701\n",
      "Error on this batch = 0.10017311301277804\n",
      "Cost on val dataset after 334 epochs is = 0.10815544844348211\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.10815544844348211\n",
      "learning rate for this epoch =  0.1169589303093807\n",
      "Error on this batch = 0.06584268673915937\n",
      "Error on this batch = 0.10004288279401476\n",
      "Cost on val dataset after 335 epochs is = 0.10807532748397963\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.10807532748397963\n",
      "learning rate for this epoch =  0.11687154965047665\n",
      "Error on this batch = 0.06573827076188629\n",
      "Error on this batch = 0.09991318095916903\n",
      "Cost on val dataset after 336 epochs is = 0.10799554194097129\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.10799554194097129\n",
      "learning rate for this epoch =  0.11678449443205002\n",
      "Error on this batch = 0.0656342354143383\n",
      "Error on this batch = 0.09978400389080004\n",
      "Cost on val dataset after 337 epochs is = 0.10791608939175737\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.10791608939175737\n",
      "learning rate for this epoch =  0.11669776247885426\n",
      "Error on this batch = 0.06553057822516445\n",
      "Error on this batch = 0.09965534801685795\n",
      "Cost on val dataset after 338 epochs is = 0.10783696743888423\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.10783696743888423\n",
      "learning rate for this epoch =  0.1166113516365818\n",
      "Error on this batch = 0.0654272967632157\n",
      "Error on this batch = 0.09952720981029249\n",
      "Cost on val dataset after 339 epochs is = 0.10775817370980154\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.10775817370980154\n",
      "learning rate for this epoch =  0.1165252597716015\n",
      "Error on this batch = 0.06532438863692092\n",
      "Error on this batch = 0.09939958578865216\n",
      "Cost on val dataset after 340 epochs is = 0.10767970585652493\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.10767970585652493\n",
      "learning rate for this epoch =  0.11643948477069971\n",
      "Error on this batch = 0.06522185149366554\n",
      "Error on this batch = 0.0992724725136749\n",
      "Cost on val dataset after 341 epochs is = 0.10760156155530444\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.10760156155530444\n",
      "learning rate for this epoch =  0.11635402454082565\n",
      "Error on this batch = 0.06511968301917213\n",
      "Error on this batch = 0.09914586659086976\n",
      "Cost on val dataset after 342 epochs is = 0.10752373850629837\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.10752373850629837\n",
      "learning rate for this epoch =  0.1162688770088405\n",
      "Error on this batch = 0.06501788093688296\n",
      "Error on this batch = 0.09901976466909058\n",
      "Cost on val dataset after 343 epochs is = 0.10744623443325217\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.10744623443325217\n",
      "learning rate for this epoch =  0.11618404012127041\n",
      "Error on this batch = 0.06491644300734474\n",
      "Error on this batch = 0.09889416344010163\n",
      "Cost on val dataset after 344 epochs is = 0.10736904708318301\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.10736904708318301\n",
      "learning rate for this epoch =  0.11609951184406334\n",
      "Error on this batch = 0.06481536702759458\n",
      "Error on this batch = 0.0987690596381352\n",
      "Cost on val dataset after 345 epochs is = 0.10729217422606883\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.10729217422606883\n",
      "learning rate for this epoch =  0.11601529016234945\n",
      "Error on this batch = 0.06471465083054782\n",
      "Error on this batch = 0.09864445003944215\n",
      "Cost on val dataset after 346 epochs is = 0.10721561365454271\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.10721561365454271\n",
      "learning rate for this epoch =  0.11593137308020533\n",
      "Error on this batch = 0.06461429228438728\n",
      "Error on this batch = 0.09852033146183505\n",
      "Cost on val dataset after 347 epochs is = 0.10713936318359198\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.10713936318359198\n",
      "learning rate for this epoch =  0.11584775862042163\n",
      "Error on this batch = 0.06451428929195373\n",
      "Error on this batch = 0.09839670076422471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 348 epochs is = 0.10706342065026185\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.10706342065026185\n",
      "learning rate for this epoch =  0.11576444482427425\n",
      "Error on this batch = 0.06441463979013755\n",
      "Error on this batch = 0.09827355484614987\n",
      "Cost on val dataset after 349 epochs is = 0.10698778391336378\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.10698778391336378\n",
      "learning rate for this epoch =  0.11568142975129903\n",
      "Error on this batch = 0.06431534174927196\n",
      "Error on this batch = 0.0981508906473012\n",
      "Cost on val dataset after 350 epochs is = 0.1069124508531883\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.1069124508531883\n",
      "learning rate for this epoch =  0.11559871147906978\n",
      "Error on this batch = 0.06421639317252716\n",
      "Error on this batch = 0.098028705147039\n",
      "Cost on val dataset after 351 epochs is = 0.10683741937122232\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.10683741937122232\n",
      "learning rate for this epoch =  0.11551628810297963\n",
      "Error on this batch = 0.06411779209530559\n",
      "Error on this batch = 0.09790699536390558\n",
      "Cost on val dataset after 352 epochs is = 0.10676268738987026\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.10676268738987026\n",
      "learning rate for this epoch =  0.11543415773602565\n",
      "Error on this batch = 0.06401953658463874\n",
      "Error on this batch = 0.09778575835513229\n",
      "Cost on val dataset after 353 epochs is = 0.10668825285217992\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.10668825285217992\n",
      "learning rate for this epoch =  0.11535231850859669\n",
      "Error on this batch = 0.06392162473858462\n",
      "Error on this batch = 0.09766499121614189\n",
      "Cost on val dataset after 354 epochs is = 0.10661411372157213\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.10661411372157213\n",
      "learning rate for this epoch =  0.11527076856826429\n",
      "Error on this batch = 0.06382405468562698\n",
      "Error on this batch = 0.09754469108004621\n",
      "Cost on val dataset after 355 epochs is = 0.10654026798157444\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.10654026798157444\n",
      "learning rate for this epoch =  0.1151895060795769\n",
      "Error on this batch = 0.06372682458407551\n",
      "Error on this batch = 0.09742485511713948\n",
      "Cost on val dataset after 356 epochs is = 0.10646671363555862\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.10646671363555862\n",
      "learning rate for this epoch =  0.11510852922385682\n",
      "Error on this batch = 0.06362993262146763\n",
      "Error on this batch = 0.0973054805343882\n",
      "Cost on val dataset after 357 epochs is = 0.10639344870648233\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.10639344870648233\n",
      "learning rate for this epoch =  0.11502783619900045\n",
      "Error on this batch = 0.06353337701397142\n",
      "Error on this batch = 0.09718656457491705\n",
      "Cost on val dataset after 358 epochs is = 0.10632047123663403\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.10632047123663403\n",
      "learning rate for this epoch =  0.11494742521928122\n",
      "Error on this batch = 0.06343715600579068\n",
      "Error on this batch = 0.0970681045174917\n",
      "Cost on val dataset after 359 epochs is = 0.10624777928738194\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.10624777928738194\n",
      "learning rate for this epoch =  0.11486729451515557\n",
      "Error on this batch = 0.06334126786857101\n",
      "Error on this batch = 0.09695009767599899\n",
      "Cost on val dataset after 360 epochs is = 0.10617537093892655\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.10617537093892655\n",
      "learning rate for this epoch =  0.11478744233307164\n",
      "Error on this batch = 0.06324571090080842\n",
      "Error on this batch = 0.09683254139892405\n",
      "Cost on val dataset after 361 epochs is = 0.10610324429005648\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.10610324429005648\n",
      "learning rate for this epoch =  0.11470786693528087\n",
      "Error on this batch = 0.06315048342725922\n",
      "Error on this batch = 0.0967154330688259\n",
      "Cost on val dataset after 362 epochs is = 0.10603139745790803\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.10603139745790803\n",
      "learning rate for this epoch =  0.11462856659965227\n",
      "Error on this batch = 0.06305558379835283\n",
      "Error on this batch = 0.0965987701018106\n",
      "Cost on val dataset after 363 epochs is = 0.10595982857772798\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.10595982857772798\n",
      "learning rate for this epoch =  0.11454953961948931\n",
      "Error on this batch = 0.06296101038960616\n",
      "Error on this batch = 0.09648254994700306\n",
      "Cost on val dataset after 364 epochs is = 0.10588853580263978\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.10588853580263978\n",
      "learning rate for this epoch =  0.11447078430334955\n",
      "Error on this batch = 0.06286676160104111\n",
      "Error on this batch = 0.09636677008601761\n",
      "Cost on val dataset after 365 epochs is = 0.10581751730341307\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.10581751730341307\n",
      "learning rate for this epoch =  0.11439229897486693\n",
      "Error on this batch = 0.0627728358566044\n",
      "Error on this batch = 0.09625142803242763\n",
      "Cost on val dataset after 366 epochs is = 0.10574677126823648\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.10574677126823648\n",
      "learning rate for this epoch =  0.11431408197257639\n",
      "Error on this batch = 0.0626792316035905\n",
      "Error on this batch = 0.0961365213312347\n",
      "Cost on val dataset after 367 epochs is = 0.10567629590249339\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.10567629590249339\n",
      "learning rate for this epoch =  0.11423613164974125\n",
      "Error on this batch = 0.06258594731206749\n",
      "Error on this batch = 0.09602204755833718\n",
      "Cost on val dataset after 368 epochs is = 0.10560608942854115\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.10560608942854115\n",
      "learning rate for this epoch =  0.11415844637418282\n",
      "Error on this batch = 0.06249298147430658\n",
      "Error on this batch = 0.0959080043199991\n",
      "Cost on val dataset after 369 epochs is = 0.10553615008549326\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.10553615008549326\n",
      "learning rate for this epoch =  0.11408102452811265\n",
      "Error on this batch = 0.06240033260421502\n",
      "Error on this batch = 0.09579438925231927\n",
      "Cost on val dataset after 370 epochs is = 0.10546647612900432\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.10546647612900432\n",
      "learning rate for this epoch =  0.11400386450796704\n",
      "Error on this batch = 0.062307999236772584\n",
      "Error on this batch = 0.09568120002070077\n",
      "Cost on val dataset after 371 epochs is = 0.10539706583105878\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.10539706583105878\n",
      "learning rate for this epoch =  0.11392696472424395\n",
      "Error on this batch = 0.06221597992747256\n",
      "Error on this batch = 0.09556843431932185\n",
      "Cost on val dataset after 372 epochs is = 0.1053279174797616\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.1053279174797616\n",
      "learning rate for this epoch =  0.11385032360134212\n",
      "Error on this batch = 0.06212427325176664\n",
      "Error on this batch = 0.09545608987060757\n",
      "Cost on val dataset after 373 epochs is = 0.10525902937913278\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.10525902937913278\n",
      "learning rate for this epoch =  0.11377393957740255\n",
      "Error on this batch = 0.06203287780451446\n",
      "Error on this batch = 0.09534416442470298\n",
      "Cost on val dataset after 374 epochs is = 0.10519039984890435\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.10519039984890435\n",
      "learning rate for this epoch =  0.11369781110415222\n",
      "Error on this batch = 0.06194179219943798\n",
      "Error on this batch = 0.09523265575894818\n",
      "Cost on val dataset after 375 epochs is = 0.10512202722432022\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.10512202722432022\n",
      "learning rate for this epoch =  0.11362193664674994\n",
      "Error on this batch = 0.06185101506858055\n",
      "Error on this batch = 0.09512156167735533\n",
      "Cost on val dataset after 376 epochs is = 0.10505390985593914\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.10505390985593914\n",
      "learning rate for this epoch =  0.11354631468363437\n",
      "Error on this batch = 0.061760545061771685\n",
      "Error on this batch = 0.09501088001008767\n",
      "Cost on val dataset after 377 epochs is = 0.1049860461094402\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.1049860461094402\n",
      "learning rate for this epoch =  0.1134709437063741\n",
      "Error on this batch = 0.06167038084609687\n",
      "Error on this batch = 0.09490060861294154\n",
      "Cost on val dataset after 378 epochs is = 0.10491843436543129\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.10491843436543129\n",
      "learning rate for this epoch =  0.11339582221952002\n",
      "Error on this batch = 0.06158052110537333\n",
      "Error on this batch = 0.09479074536683045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 379 epochs is = 0.10485107301926028\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.10485107301926028\n",
      "learning rate for this epoch =  0.11332094874045952\n",
      "Error on this batch = 0.061490964539631605\n",
      "Error on this batch = 0.09468128817727282\n",
      "Cost on val dataset after 380 epochs is = 0.10478396048082896\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.10478396048082896\n",
      "learning rate for this epoch =  0.1132463217992727\n",
      "Error on this batch = 0.06140170986460351\n",
      "Error on this batch = 0.09457223497388231\n",
      "Cost on val dataset after 381 epochs is = 0.10471709517440966\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.10471709517440966\n",
      "learning rate for this epoch =  0.11317193993859079\n",
      "Error on this batch = 0.0613127558112163\n",
      "Error on this batch = 0.09446358370986206\n",
      "Cost on val dataset after 382 epochs is = 0.10465047553846464\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.10465047553846464\n",
      "learning rate for this epoch =  0.11309780171345626\n",
      "Error on this batch = 0.06122410112509334\n",
      "Error on this batch = 0.09435533236150206\n",
      "Cost on val dataset after 383 epochs is = 0.10458410002546799\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.10458410002546799\n",
      "learning rate for this epoch =  0.11302390569118509\n",
      "Error on this batch = 0.06113574456606213\n",
      "Error on this batch = 0.09424747892768068\n",
      "Cost on val dataset after 384 epochs is = 0.10451796710173043\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.10451796710173043\n",
      "learning rate for this epoch =  0.11295025045123061\n",
      "Error on this batch = 0.06104768490766881\n",
      "Error on this batch = 0.09414002142936996\n",
      "Cost on val dataset after 385 epochs is = 0.10445207524722655\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.10445207524722655\n",
      "learning rate for this epoch =  0.11287683458504956\n",
      "Error on this batch = 0.06095992093670018\n",
      "Error on this batch = 0.09403295790914537\n",
      "Cost on val dataset after 386 epochs is = 0.10438642295542468\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.10438642295542468\n",
      "learning rate for this epoch =  0.11280365669596971\n",
      "Error on this batch = 0.060872451452713125\n",
      "Error on this batch = 0.09392628643069958\n",
      "Cost on val dataset after 387 epochs is = 0.10432100873311954\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.10432100873311954\n",
      "learning rate for this epoch =  0.11273071539905938\n",
      "Error on this batch = 0.0607852752675718\n",
      "Error on this batch = 0.09382000507836079\n",
      "Cost on val dataset after 388 epochs is = 0.10425583110026708\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.10425583110026708\n",
      "learning rate for this epoch =  0.11265800932099873\n",
      "Error on this batch = 0.06069839120499223\n",
      "Error on this batch = 0.09371411195661607\n",
      "Cost on val dataset after 389 epochs is = 0.1041908885898223\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.1041908885898223\n",
      "learning rate for this epoch =  0.11258553709995278\n",
      "Error on this batch = 0.060611798100095406\n",
      "Error on this batch = 0.09360860518963897\n",
      "Cost on val dataset after 390 epochs is = 0.1041261797475794\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.1041261797475794\n",
      "learning rate for this epoch =  0.11251329738544609\n",
      "Error on this batch = 0.06052549479896815\n",
      "Error on this batch = 0.09350348292082253\n",
      "Cost on val dataset after 391 epochs is = 0.10406170313201425\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.10406170313201425\n",
      "learning rate for this epoch =  0.11244128883823923\n",
      "Error on this batch = 0.06043948015823235\n",
      "Error on this batch = 0.09339874331231701\n",
      "Cost on val dataset after 392 epochs is = 0.1039974573141298\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.1039974573141298\n",
      "learning rate for this epoch =  0.11236951013020673\n",
      "Error on this batch = 0.06035375304462276\n",
      "Error on this batch = 0.09329438454457323\n",
      "Cost on val dataset after 393 epochs is = 0.10393344087730354\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.10393344087730354\n",
      "learning rate for this epoch =  0.11229795994421696\n",
      "Error on this batch = 0.06026831233457312\n",
      "Error on this batch = 0.0931904048158906\n",
      "Cost on val dataset after 394 epochs is = 0.10386965241713768\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.10386965241713768\n",
      "learning rate for this epoch =  0.11222663697401325\n",
      "Error on this batch = 0.06018315691381121\n",
      "Error on this batch = 0.09308680234197121\n",
      "Cost on val dataset after 395 epochs is = 0.10380609054131158\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.10380609054131158\n",
      "learning rate for this epoch =  0.11215553992409688\n",
      "Error on this batch = 0.0600982856769625\n",
      "Error on this batch = 0.0929835753554789\n",
      "Cost on val dataset after 396 epochs is = 0.10374275386943672\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.10374275386943672\n",
      "learning rate for this epoch =  0.11208466750961145\n",
      "Error on this batch = 0.06001369752716278\n",
      "Error on this batch = 0.09288072210560433\n",
      "Cost on val dataset after 397 epochs is = 0.10367964103291405\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.10367964103291405\n",
      "learning rate for this epoch =  0.11201401845622891\n",
      "Error on this batch = 0.05992939137567985\n",
      "Error on this batch = 0.09277824085763532\n",
      "Cost on val dataset after 398 epochs is = 0.10361675067479341\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.10361675067479341\n",
      "learning rate for this epoch =  0.11194359150003692\n",
      "Error on this batch = 0.05984536614154411\n",
      "Error on this batch = 0.0926761298925333\n",
      "Cost on val dataset after 399 epochs is = 0.10355408144963597\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.10355408144963597\n",
      "learning rate for this epoch =  0.11187338538742793\n",
      "Error on this batch = 0.05976162075118834\n",
      "Error on this batch = 0.09257438750651524\n",
      "Cost on val dataset after 400 epochs is = 0.10349163202337813\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.10349163202337813\n",
      "learning rate for this epoch =  0.11180339887498948\n",
      "Error on this batch = 0.05967815413809688\n",
      "Error on this batch = 0.09247301201064176\n",
      "Cost on val dataset after 401 epochs is = 0.10342940107319835\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.10342940107319835\n",
      "learning rate for this epoch =  0.11173363072939616\n",
      "Error on this batch = 0.05959496524246369\n",
      "Error on this batch = 0.09237200173041087\n",
      "Cost on val dataset after 402 epochs is = 0.10336738728738604\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.10336738728738604\n",
      "learning rate for this epoch =  0.11166407972730269\n",
      "Error on this batch = 0.059512053010859996\n",
      "Error on this batch = 0.09227135500535802\n",
      "Cost on val dataset after 403 epochs is = 0.10330558936521253\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.10330558936521253\n",
      "learning rate for this epoch =  0.1115947446552388\n",
      "Error on this batch = 0.059429416395911136\n",
      "Error on this batch = 0.09217107018866165\n",
      "Cost on val dataset after 404 epochs is = 0.1032440060168046\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.1032440060168046\n",
      "learning rate for this epoch =  0.11152562430950505\n",
      "Error on this batch = 0.059347054355982753\n",
      "Error on this batch = 0.09207114564675538\n",
      "Cost on val dataset after 405 epochs is = 0.10318263596301988\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.10318263596301988\n",
      "learning rate for this epoch =  0.11145671749607033\n",
      "Error on this batch = 0.05926496585487627\n",
      "Error on this batch = 0.09197157975894582\n",
      "Cost on val dataset after 406 epochs is = 0.10312147793532456\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.10312147793532456\n",
      "learning rate for this epoch =  0.1113880230304705\n",
      "Error on this batch = 0.05918314986153393\n",
      "Error on this batch = 0.09187237091703672\n",
      "Cost on val dataset after 407 epochs is = 0.10306053067567322\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.10306053067567322\n",
      "learning rate for this epoch =  0.11131953973770842\n",
      "Error on this batch = 0.05910160534975289\n",
      "Error on this batch = 0.09177351752495914\n",
      "Cost on val dataset after 408 epochs is = 0.1029997929363908\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.1029997929363908\n",
      "learning rate for this epoch =  0.11125126645215519\n",
      "Error on this batch = 0.05902033129790873\n",
      "Error on this batch = 0.09167501799840778\n",
      "Cost on val dataset after 409 epochs is = 0.10293926348005632\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.10293926348005632\n",
      "learning rate for this epoch =  0.11118320201745278\n",
      "Error on this batch = 0.058939326688688516\n",
      "Error on this batch = 0.09157687076448344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 410 epochs is = 0.10287894107938934\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.10287894107938934\n",
      "learning rate for this epoch =  0.11111534528641788\n",
      "Error on this batch = 0.05885859050883257\n",
      "Error on this batch = 0.09147907426134182\n",
      "Cost on val dataset after 411 epochs is = 0.10281882451713764\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.10281882451713764\n",
      "learning rate for this epoch =  0.11104769512094681\n",
      "Error on this batch = 0.05877812174888618\n",
      "Error on this batch = 0.091381626937848\n",
      "Cost on val dataset after 412 epochs is = 0.10275891258596727\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.10275891258596727\n",
      "learning rate for this epoch =  0.11098025039192183\n",
      "Error on this batch = 0.05869791940295971\n",
      "Error on this batch = 0.09128452725323782\n",
      "Cost on val dataset after 413 epochs is = 0.10269920408835466\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.10269920408835466\n",
      "learning rate for this epoch =  0.11091300997911864\n",
      "Error on this batch = 0.05861798246849847\n",
      "Error on this batch = 0.09118777367678466\n",
      "Cost on val dataset after 414 epochs is = 0.10263969783648039\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.10263969783648039\n",
      "learning rate for this epoch =  0.11084597277111498\n",
      "Error on this batch = 0.05853830994606114\n",
      "Error on this batch = 0.0910913646874729\n",
      "Cost on val dataset after 415 epochs is = 0.10258039265212485\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.10258039265212485\n",
      "learning rate for this epoch =  0.11077913766520031\n",
      "Error on this batch = 0.05845890083910744\n",
      "Error on this batch = 0.09099529877367735\n",
      "Cost on val dataset after 416 epochs is = 0.10252128736656588\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.10252128736656588\n",
      "learning rate for this epoch =  0.11071250356728685\n",
      "Error on this batch = 0.05837975415379465\n",
      "Error on this batch = 0.09089957443284878\n",
      "Cost on val dataset after 417 epochs is = 0.10246238082047812\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.10246238082047812\n",
      "learning rate for this epoch =  0.11064606939182157\n",
      "Error on this batch = 0.058300868898782804\n",
      "Error on this batch = 0.09080419017120558\n",
      "Cost on val dataset after 418 epochs is = 0.10240367186383409\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.10240367186383409\n",
      "learning rate for this epoch =  0.11057983406169934\n",
      "Error on this batch = 0.058222244085048704\n",
      "Error on this batch = 0.09070914450343179\n",
      "Cost on val dataset after 419 epochs is = 0.10234515935580724\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.10234515935580724\n",
      "learning rate for this epoch =  0.11051379650817714\n",
      "Error on this batch = 0.05814387872570841\n",
      "Error on this batch = 0.09061443595238078\n",
      "Cost on val dataset after 420 epochs is = 0.10228684216467612\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.10228684216467612\n",
      "learning rate for this epoch =  0.11044795567078942\n",
      "Error on this batch = 0.05806577183584845\n",
      "Error on this batch = 0.09052006304878538\n",
      "Cost on val dataset after 421 epochs is = 0.1022287191677311\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.1022287191677311\n",
      "learning rate for this epoch =  0.1103823104972644\n",
      "Error on this batch = 0.057987922432365106\n",
      "Error on this batch = 0.09042602433097412\n",
      "Cost on val dataset after 422 epochs is = 0.10217078925118164\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.10217078925118164\n",
      "learning rate for this epoch =  0.11031685994344151\n",
      "Error on this batch = 0.057910329533812255\n",
      "Error on this batch = 0.09033231834459306\n",
      "Cost on val dataset after 423 epochs is = 0.10211305131006616\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.10211305131006616\n",
      "learning rate for this epoch =  0.11025160297318981\n",
      "Error on this batch = 0.057832992160257175\n",
      "Error on this batch = 0.0902389436423343\n",
      "Cost on val dataset after 424 epochs is = 0.10205550424816257\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.10205550424816257\n",
      "learning rate for this epoch =  0.11018653855832754\n",
      "Error on this batch = 0.05775590933314453\n",
      "Error on this batch = 0.09014589878366998\n",
      "Cost on val dataset after 425 epochs is = 0.10199814697790105\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.10199814697790105\n",
      "learning rate for this epoch =  0.11012166567854233\n",
      "Error on this batch = 0.057679080075167914\n",
      "Error on this batch = 0.09005318233459257\n",
      "Cost on val dataset after 426 epochs is = 0.10194097842027763\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.10194097842027763\n",
      "learning rate for this epoch =  0.11005698332131283\n",
      "Error on this batch = 0.05760250341014972\n",
      "Error on this batch = 0.08996079286736107\n",
      "Cost on val dataset after 427 epochs is = 0.10188399750476967\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.10188399750476967\n",
      "learning rate for this epoch =  0.10999249048183099\n",
      "Error on this batch = 0.05752617836292807\n",
      "Error on this batch = 0.08986872896025318\n",
      "Cost on val dataset after 428 epochs is = 0.10182720316925255\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.10182720316925255\n",
      "learning rate for this epoch =  0.10992818616292545\n",
      "Error on this batch = 0.05745010395925146\n",
      "Error on this batch = 0.08977698919732341\n",
      "Cost on val dataset after 429 epochs is = 0.10177059435991748\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.10177059435991748\n",
      "learning rate for this epoch =  0.10986406937498579\n",
      "Error on this batch = 0.05737427922568086\n",
      "Error on this batch = 0.0896855721681671\n",
      "Cost on val dataset after 430 epochs is = 0.10171417003119108\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.10171417003119108\n",
      "learning rate for this epoch =  0.10980013913588772\n",
      "Error on this batch = 0.05729870318949889\n",
      "Error on this batch = 0.08959447646769046\n",
      "Cost on val dataset after 431 epochs is = 0.10165792914565575\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.10165792914565575\n",
      "learning rate for this epoch =  0.10973639447091926\n",
      "Error on this batch = 0.05722337487862584\n",
      "Error on this batch = 0.08950370069588644\n",
      "Cost on val dataset after 432 epochs is = 0.10160187067397163\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.10160187067397163\n",
      "learning rate for this epoch =  0.10967283441270771\n",
      "Error on this batch = 0.05714829332154308\n",
      "Error on this batch = 0.08941324345761632\n",
      "Cost on val dataset after 433 epochs is = 0.10154599359479932\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.10154599359479932\n",
      "learning rate for this epoch =  0.10960945800114749\n",
      "Error on this batch = 0.0570734575472226\n",
      "Error on this batch = 0.08932310336239771\n",
      "Cost on val dataset after 434 epochs is = 0.10149029689472429\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.10149029689472429\n",
      "learning rate for this epoch =  0.10954626428332909\n",
      "Error on this batch = 0.05699886658506364\n",
      "Error on this batch = 0.08923327902419756\n",
      "Cost on val dataset after 435 epochs is = 0.10143477956818181\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.10143477956818181\n",
      "learning rate for this epoch =  0.10948325231346849\n",
      "Error on this batch = 0.056924519464835455\n",
      "Error on this batch = 0.08914376906123188\n",
      "Cost on val dataset after 436 epochs is = 0.10137944061738338\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.10137944061738338\n",
      "learning rate for this epoch =  0.1094204211528378\n",
      "Error on this batch = 0.05685041521662654\n",
      "Error on this batch = 0.08905457209577085\n",
      "Cost on val dataset after 437 epochs is = 0.10132427905224405\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.10132427905224405\n",
      "learning rate for this epoch =  0.1093577698696965\n",
      "Error on this batch = 0.05677655287079971\n",
      "Error on this batch = 0.08896568675394964\n",
      "Cost on val dataset after 438 epochs is = 0.10126929389031056\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.10126929389031056\n",
      "learning rate for this epoch =  0.1092952975392236\n",
      "Error on this batch = 0.05670293145795345\n",
      "Error on this batch = 0.08887711166558541\n",
      "Cost on val dataset after 439 epochs is = 0.10121448415669058\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.10121448415669058\n",
      "learning rate for this epoch =  0.10923300324345062\n",
      "Error on this batch = 0.056629550008888786\n",
      "Error on this batch = 0.08878884546399989\n",
      "Cost on val dataset after 440 epochs is = 0.10115984888398301\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.10115984888398301\n",
      "learning rate for this epoch =  0.10917088607119531\n",
      "Error on this batch = 0.056556407554581946\n",
      "Error on this batch = 0.08870088678584777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 441 epochs is = 0.10110538711220882\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.10110538711220882\n",
      "learning rate for this epoch =  0.1091089451179962\n",
      "Error on this batch = 0.056483503126162446\n",
      "Error on this batch = 0.08861323427095105\n",
      "Cost on val dataset after 442 epochs is = 0.10105109788874292\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.10105109788874292\n",
      "learning rate for this epoch =  0.10904717948604793\n",
      "Error on this batch = 0.056410835754896346\n",
      "Error on this batch = 0.08852588656213893\n",
      "Cost on val dataset after 443 epochs is = 0.10099698026824695\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.10099698026824695\n",
      "learning rate for this epoch =  0.10898558828413735\n",
      "Error on this batch = 0.056338404472175085\n",
      "Error on this batch = 0.08843884230509376\n",
      "Cost on val dataset after 444 epochs is = 0.10094303331260256\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.10094303331260256\n",
      "learning rate for this epoch =  0.10892417062758035\n",
      "Error on this batch = 0.056266208309508674\n",
      "Error on this batch = 0.08835210014820245\n",
      "Cost on val dataset after 445 epochs is = 0.1008892560908457\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.1008892560908457\n",
      "learning rate for this epoch =  0.10886292563815944\n",
      "Error on this batch = 0.05619424629852426\n",
      "Error on this batch = 0.0882656587424141\n",
      "Cost on val dataset after 446 epochs is = 0.10083564767910137\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.10083564767910137\n",
      "learning rate for this epoch =  0.10880185244406208\n",
      "Error on this batch = 0.056122517470969024\n",
      "Error on this batch = 0.08817951674110301\n",
      "Cost on val dataset after 447 epochs is = 0.10078220716051936\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.10078220716051936\n",
      "learning rate for this epoch =  0.10874095017981981\n",
      "Error on this batch = 0.05605102085871783\n",
      "Error on this batch = 0.08809367279993775\n",
      "Cost on val dataset after 448 epochs is = 0.10072893362521027\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.10072893362521027\n",
      "learning rate for this epoch =  0.10868021798624786\n",
      "Error on this batch = 0.055979755493784956\n",
      "Error on this batch = 0.08800812557675577\n",
      "Cost on val dataset after 449 epochs is = 0.10067582617018243\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.10067582617018243\n",
      "learning rate for this epoch =  0.10861965501038574\n",
      "Error on this batch = 0.05590872040834029\n",
      "Error on this batch = 0.08792287373144418\n",
      "Cost on val dataset after 450 epochs is = 0.10062288389927943\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.10062288389927943\n",
      "learning rate for this epoch =  0.10855926040543842\n",
      "Error on this batch = 0.05583791463472938\n",
      "Error on this batch = 0.08783791592582581\n",
      "Cost on val dataset after 451 epochs is = 0.10057010592311783\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.10057010592311783\n",
      "learning rate for this epoch =  0.1084990333307181\n",
      "Error on this batch = 0.05576733720549738\n",
      "Error on this batch = 0.08775325082355155\n",
      "Cost on val dataset after 452 epochs is = 0.10051749135902603\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.10051749135902603\n",
      "learning rate for this epoch =  0.10843897295158678\n",
      "Error on this batch = 0.05569698715341694\n",
      "Error on this batch = 0.0876688770899982\n",
      "Cost on val dataset after 453 epochs is = 0.1004650393309831\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.1004650393309831\n",
      "learning rate for this epoch =  0.10837907843939941\n",
      "Error on this batch = 0.05562686351151926\n",
      "Error on this batch = 0.0875847933921722\n",
      "Cost on val dataset after 454 epochs is = 0.10041274896955833\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.10041274896955833\n",
      "learning rate for this epoch =  0.10831934897144786\n",
      "Error on this batch = 0.05555696531312911\n",
      "Error on this batch = 0.08750099839861929\n",
      "Cost on val dataset after 455 epochs is = 0.10036061941185155\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.10036061941185155\n",
      "learning rate for this epoch =  0.10825978373090529\n",
      "Error on this batch = 0.05548729159190252\n",
      "Error on this batch = 0.08741749077933962\n",
      "Cost on val dataset after 456 epochs is = 0.1003086498014332\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.1003086498014332\n",
      "learning rate for this epoch =  0.10820038190677136\n",
      "Error on this batch = 0.05541784138186815\n",
      "Error on this batch = 0.0873342692057092\n",
      "Cost on val dataset after 457 epochs is = 0.10025683928828556\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.10025683928828556\n",
      "learning rate for this epoch =  0.10814114269381797\n",
      "Error on this batch = 0.055348613717471365\n",
      "Error on this batch = 0.08725133235040668\n",
      "Cost on val dataset after 458 epochs is = 0.10020518702874412\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.10020518702874412\n",
      "learning rate for this epoch =  0.10808206529253567\n",
      "Error on this batch = 0.05527960763362123\n",
      "Error on this batch = 0.08716867888734627\n",
      "Cost on val dataset after 459 epochs is = 0.10015369218543917\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.10015369218543917\n",
      "learning rate for this epoch =  0.10802314890908067\n",
      "Error on this batch = 0.055210822165740046\n",
      "Error on this batch = 0.08708630749161636\n",
      "Cost on val dataset after 460 epochs is = 0.10010235392723812\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.10010235392723812\n",
      "learning rate for this epoch =  0.10796439275522242\n",
      "Error on this batch = 0.055142256349815816\n",
      "Error on this batch = 0.08700421683942387\n",
      "Cost on val dataset after 461 epochs is = 0.10005117142918814\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.10005117142918814\n",
      "learning rate for this epoch =  0.10790579604829184\n",
      "Error on this batch = 0.05507390922245674\n",
      "Error on this batch = 0.08692240560804473\n",
      "Cost on val dataset after 462 epochs is = 0.10000014387245887\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.10000014387245887\n",
      "learning rate for this epoch =  0.10784735801113018\n",
      "Error on this batch = 0.055005779820948314\n",
      "Error on this batch = 0.08684087247577976\n",
      "Cost on val dataset after 463 epochs is = 0.099949270444286\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.099949270444286\n",
      "learning rate for this epoch =  0.10778907787203826\n",
      "Error on this batch = 0.054937867183312304\n",
      "Error on this batch = 0.08675961612191672\n",
      "Cost on val dataset after 464 epochs is = 0.09989855033791487\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.09989855033791487\n",
      "learning rate for this epoch =  0.1077309548647265\n",
      "Error on this batch = 0.054870170348368025\n",
      "Error on this batch = 0.08667863522669801\n",
      "Cost on val dataset after 465 epochs is = 0.09984798275254445\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.09984798275254445\n",
      "learning rate for this epoch =  0.10767298822826553\n",
      "Error on this batch = 0.05480268835579543\n",
      "Error on this batch = 0.08659792847129424\n",
      "Cost on val dataset after 466 epochs is = 0.09979756689327193\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.09979756689327193\n",
      "learning rate for this epoch =  0.10761517720703706\n",
      "Error on this batch = 0.054735420246199824\n",
      "Error on this batch = 0.08651749453778351\n",
      "Cost on val dataset after 467 epochs is = 0.09974730197103734\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.09974730197103734\n",
      "learning rate for this epoch =  0.10755752105068565\n",
      "Error on this batch = 0.05466836506117846\n",
      "Error on this batch = 0.0864373321091365\n",
      "Cost on val dataset after 468 epochs is = 0.0996971872025688\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.0996971872025688\n",
      "learning rate for this epoch =  0.1075000190140709\n",
      "Error on this batch = 0.054601521843388526\n",
      "Error on this batch = 0.0863574398692075\n",
      "Cost on val dataset after 469 epochs is = 0.09964722181032791\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.09964722181032791\n",
      "learning rate for this epoch =  0.10744267035722005\n",
      "Error on this batch = 0.054534889636616575\n",
      "Error on this batch = 0.086277816502731\n",
      "Cost on val dataset after 470 epochs is = 0.09959740502245583\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.09959740502245583\n",
      "learning rate for this epoch =  0.10738547434528128\n",
      "Error on this batch = 0.05446846748584933\n",
      "Error on this batch = 0.08619846069532397\n",
      "Cost on val dataset after 471 epochs is = 0.09954773607271931\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.09954773607271931\n",
      "learning rate for this epoch =  0.10732843024847744\n",
      "Error on this batch = 0.05440225443734553\n",
      "Error on this batch = 0.08611937113349404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 472 epochs is = 0.09949821420045747\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.09949821420045747\n",
      "learning rate for this epoch =  0.10727153734206031\n",
      "Error on this batch = 0.05433624953870902\n",
      "Error on this batch = 0.0860405465046533\n",
      "Cost on val dataset after 473 epochs is = 0.09944883865052873\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.09944883865052873\n",
      "learning rate for this epoch =  0.1072147949062655\n",
      "Error on this batch = 0.05427045183896258\n",
      "Error on this batch = 0.08596198549713761\n",
      "Cost on val dataset after 474 epochs is = 0.09939960867325832\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.09939960867325832\n",
      "learning rate for this epoch =  0.10715820222626746\n",
      "Error on this batch = 0.05420486038862296\n",
      "Error on this batch = 0.08588368680023177\n",
      "Cost on val dataset after 475 epochs is = 0.099350523524386\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.099350523524386\n",
      "learning rate for this epoch =  0.1071017585921356\n",
      "Error on this batch = 0.05413947423977631\n",
      "Error on this batch = 0.08580564910419995\n",
      "Cost on val dataset after 476 epochs is = 0.0993015824650145\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.0993015824650145\n",
      "learning rate for this epoch =  0.1070454632987902\n",
      "Error on this batch = 0.05407429244615445\n",
      "Error on this batch = 0.08572787110032191\n",
      "Cost on val dataset after 477 epochs is = 0.09925278476155798\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.09925278476155798\n",
      "learning rate for this epoch =  0.10698931564595948\n",
      "Error on this batch = 0.05400931406321172\n",
      "Error on this batch = 0.08565035148093467\n",
      "Cost on val dataset after 478 epochs is = 0.09920412968569144\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.09920412968569144\n",
      "learning rate for this epoch =  0.1069333149381366\n",
      "Error on this batch = 0.05394453814820214\n",
      "Error on this batch = 0.08557308893947922\n",
      "Cost on val dataset after 479 epochs is = 0.09915561651430015\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.09915561651430015\n",
      "learning rate for this epoch =  0.10687746048453738\n",
      "Error on this batch = 0.05387996376025713\n",
      "Error on this batch = 0.08549608217055323\n",
      "Cost on val dataset after 480 epochs is = 0.09910724452942989\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.09910724452942989\n",
      "learning rate for this epoch =  0.10682175159905852\n",
      "Error on this batch = 0.05381558996046337\n",
      "Error on this batch = 0.08541932986996843\n",
      "Cost on val dataset after 481 epochs is = 0.09905901301823754\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.09905901301823754\n",
      "learning rate for this epoch =  0.1067661876002362\n",
      "Error on this batch = 0.05375141581194089\n",
      "Error on this batch = 0.08534283073481348\n",
      "Cost on val dataset after 482 epochs is = 0.09901092127294227\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.09901092127294227\n",
      "learning rate for this epoch =  0.1067107678112051\n",
      "Error on this batch = 0.05368744037992123\n",
      "Error on this batch = 0.08526658346352207\n",
      "Cost on val dataset after 483 epochs is = 0.09896296859077713\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.09896296859077713\n",
      "learning rate for this epoch =  0.10665549155965787\n",
      "Error on this batch = 0.053623662731825644\n",
      "Error on this batch = 0.08519058675594574\n",
      "Cost on val dataset after 484 epochs is = 0.09891515427394167\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.09891515427394167\n",
      "learning rate for this epoch =  0.10660035817780521\n",
      "Error on this batch = 0.05356008193734324\n",
      "Error on this batch = 0.08511483931343189\n",
      "Cost on val dataset after 485 epochs is = 0.09886747762955439\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.09886747762955439\n",
      "learning rate for this epoch =  0.10654536700233612\n",
      "Error on this batch = 0.05349669706850893\n",
      "Error on this batch = 0.08503933983890667\n",
      "Cost on val dataset after 486 epochs is = 0.09881993796960659\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.09881993796960659\n",
      "learning rate for this epoch =  0.10649051737437876\n",
      "Error on this batch = 0.053433507199781245\n",
      "Error on this batch = 0.08496408703696215\n",
      "Cost on val dataset after 487 epochs is = 0.09877253461091628\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.09877253461091628\n",
      "learning rate for this epoch =  0.10643580863946162\n",
      "Error on this batch = 0.05337051140811973\n",
      "Error on this batch = 0.08488907961394869\n",
      "Cost on val dataset after 488 epochs is = 0.09872526687508336\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.09872526687508336\n",
      "learning rate for this epoch =  0.10638124014747533\n",
      "Error on this batch = 0.05330770877306206\n",
      "Error on this batch = 0.08481431627807146\n",
      "Cost on val dataset after 489 epochs is = 0.09867813408844466\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.09867813408844466\n",
      "learning rate for this epoch =  0.1063268112526345\n",
      "Error on this batch = 0.0532450983768006\n",
      "Error on this batch = 0.0847397957394913\n",
      "Cost on val dataset after 490 epochs is = 0.09863113558203059\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.09863113558203059\n",
      "learning rate for this epoch =  0.10627252131344038\n",
      "Error on this batch = 0.05318267930425869\n",
      "Error on this batch = 0.08466551671042986\n",
      "Cost on val dataset after 491 epochs is = 0.09858427069152183\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.09858427069152183\n",
      "learning rate for this epoch =  0.10621836969264359\n",
      "Error on this batch = 0.053120450643166034\n",
      "Error on this batch = 0.08459147790527888\n",
      "Cost on val dataset after 492 epochs is = 0.09853753875720728\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.09853753875720728\n",
      "learning rate for this epoch =  0.10616435575720744\n",
      "Error on this batch = 0.05305841148413361\n",
      "Error on this batch = 0.0845176780407132\n",
      "Cost on val dataset after 493 epochs is = 0.09849093912394255\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.09849093912394255\n",
      "learning rate for this epoch =  0.1061104788782716\n",
      "Error on this batch = 0.05299656092072788\n",
      "Error on this batch = 0.08444411583580749\n",
      "Cost on val dataset after 494 epochs is = 0.09844447114110925\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.09844447114110925\n",
      "learning rate for this epoch =  0.10605673843111615\n",
      "Error on this batch = 0.05293489804954437\n",
      "Error on this batch = 0.0843707900121568\n",
      "Cost on val dataset after 495 epochs is = 0.0983981341625753\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.0983981341625753\n",
      "learning rate for this epoch =  0.10600313379512592\n",
      "Error on this batch = 0.05287342197027991\n",
      "Error on this batch = 0.0842976992940003\n",
      "Cost on val dataset after 496 epochs is = 0.09835192754665596\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.09835192754665596\n",
      "learning rate for this epoch =  0.10594966435375541\n",
      "Error on this batch = 0.0528121317858047\n",
      "Error on this batch = 0.08422484240834799\n",
      "Cost on val dataset after 497 epochs is = 0.09830585065607582\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.09830585065607582\n",
      "learning rate for this epoch =  0.10589632949449389\n",
      "Error on this batch = 0.05275102660223288\n",
      "Error on this batch = 0.08415221808511093\n",
      "Cost on val dataset after 498 epochs is = 0.09825990285793168\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.09825990285793168\n",
      "learning rate for this epoch =  0.10584312860883092\n",
      "Error on this batch = 0.05269010552899232\n",
      "Error on this batch = 0.08407982505723391\n",
      "Cost on val dataset after 499 epochs is = 0.09821408352365632\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.09821408352365632\n",
      "learning rate for this epoch =  0.10579006109222232\n",
      "Error on this batch = 0.052629367678893486\n",
      "Error on this batch = 0.08400766206083045\n",
      "Cost on val dataset after 500 epochs is = 0.09816839202898338\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.09816839202898338\n",
      "learning rate for this epoch =  0.10573712634405641\n",
      "Error on this batch = 0.05256881216819686\n",
      "Error on this batch = 0.08393572783532084\n",
      "Cost on val dataset after 501 epochs is = 0.09812282775391311\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.09812282775391311\n",
      "learning rate for this epoch =  0.1056843237676206\n",
      "Error on this batch = 0.05250843811667967\n",
      "Error on this batch = 0.08386402112357175\n",
      "Cost on val dataset after 502 epochs is = 0.09807739008267904\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.09807739008267904\n",
      "learning rate for this epoch =  0.10563165277006838\n",
      "Error on this batch = 0.052448244647701085\n",
      "Error on this batch = 0.08379254067203797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 503 epochs is = 0.09803207840371585\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.09803207840371585\n",
      "learning rate for this epoch =  0.10557911276238661\n",
      "Error on this batch = 0.05238823088826632\n",
      "Error on this batch = 0.08372128523090547\n",
      "Cost on val dataset after 504 epochs is = 0.09798689210962809\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.09798689210962809\n",
      "learning rate for this epoch =  0.10552670315936317\n",
      "Error on this batch = 0.0523283959690895\n",
      "Error on this batch = 0.08365025355423658\n",
      "Cost on val dataset after 505 epochs is = 0.09794183059716018\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.09794183059716018\n",
      "learning rate for this epoch =  0.105474423379555\n",
      "Error on this batch = 0.05226873902465508\n",
      "Error on this batch = 0.08357944440011565\n",
      "Cost on val dataset after 506 epochs is = 0.0978968932671671\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.0978968932671671\n",
      "learning rate for this epoch =  0.10542227284525636\n",
      "Error on this batch = 0.052209259193278096\n",
      "Error on this batch = 0.0835088565307958\n",
      "Cost on val dataset after 507 epochs is = 0.09785207952458669\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.09785207952458669\n",
      "learning rate for this epoch =  0.10537025098246748\n",
      "Error on this batch = 0.052149955617162846\n",
      "Error on this batch = 0.08343848871284658\n",
      "Cost on val dataset after 508 epochs is = 0.09780738877841244\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.09780738877841244\n",
      "learning rate for this epoch =  0.10531835722086355\n",
      "Error on this batch = 0.05209082744246038\n",
      "Error on this batch = 0.08336833971730172\n",
      "Cost on val dataset after 509 epochs is = 0.09776282044166786\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.09776282044166786\n",
      "learning rate for this epoch =  0.10526659099376405\n",
      "Error on this batch = 0.05203187381932416\n",
      "Error on this batch = 0.08329840831980713\n",
      "Cost on val dataset after 510 epochs is = 0.09771837393138158\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.09771837393138158\n",
      "learning rate for this epoch =  0.10521495173810227\n",
      "Error on this batch = 0.051973093901964716\n",
      "Error on this batch = 0.08322869330076861\n",
      "Cost on val dataset after 511 epochs is = 0.09767404866856393\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.09767404866856393\n",
      "learning rate for this epoch =  0.10516343889439533\n",
      "Error on this batch = 0.05191448684870232\n",
      "Error on this batch = 0.08315919344549944\n",
      "Cost on val dataset after 512 epochs is = 0.0976298440781843\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.0976298440781843\n",
      "learning rate for this epoch =  0.10511205190671433\n",
      "Error on this batch = 0.051856051822018454\n",
      "Error on this batch = 0.08308990754436697\n",
      "Cost on val dataset after 513 epochs is = 0.0975857595891497\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.0975857595891497\n",
      "learning rate for this epoch =  0.10506079022265488\n",
      "Error on this batch = 0.0517977879886055\n",
      "Error on this batch = 0.08302083439293842\n",
      "Cost on val dataset after 514 epochs is = 0.0975417946342846\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.0975417946342846\n",
      "learning rate for this epoch =  0.10500965329330811\n",
      "Error on this batch = 0.05173969451941504\n",
      "Error on this batch = 0.08295197279212527\n",
      "Cost on val dataset after 515 epochs is = 0.09749794865031165\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.09749794865031165\n",
      "learning rate for this epoch =  0.10495864057323148\n",
      "Error on this batch = 0.05168177058970417\n",
      "Error on this batch = 0.08288332154832645\n",
      "Cost on val dataset after 516 epochs is = 0.09745422107783365\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.09745422107783365\n",
      "learning rate for this epoch =  0.10490775152042053\n",
      "Error on this batch = 0.0516240153790806\n",
      "Error on this batch = 0.0828148794735694\n",
      "Cost on val dataset after 517 epochs is = 0.09741061136131642\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.09741061136131642\n",
      "learning rate for this epoch =  0.10485698559628044\n",
      "Error on this batch = 0.051566428071545836\n",
      "Error on this batch = 0.08274664538564952\n",
      "Cost on val dataset after 518 epochs is = 0.09736711894907317\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.09736711894907317\n",
      "learning rate for this epoch =  0.10480634226559798\n",
      "Error on this batch = 0.05150900785553669\n",
      "Error on this batch = 0.08267861810826668\n",
      "Cost on val dataset after 519 epochs is = 0.09732374329324939\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.09732374329324939\n",
      "learning rate for this epoch =  0.10475582099651397\n",
      "Error on this batch = 0.05145175392396519\n",
      "Error on this batch = 0.08261079647115988\n",
      "Cost on val dataset after 520 epochs is = 0.09728048384980918\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.09728048384980918\n",
      "learning rate for this epoch =  0.10470542126049572\n",
      "Error on this batch = 0.05139466547425669\n",
      "Error on this batch = 0.08254317931023857\n",
      "Cost on val dataset after 521 epochs is = 0.09723734007852258\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.09723734007852258\n",
      "learning rate for this epoch =  0.10465514253230984\n",
      "Error on this batch = 0.051337741708386356\n",
      "Error on this batch = 0.08247576546771117\n",
      "Cost on val dataset after 522 epochs is = 0.09719431144295386\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.09719431144295386\n",
      "learning rate for this epoch =  0.10460498428999554\n",
      "Error on this batch = 0.05128098183291373\n",
      "Error on this batch = 0.08240855379221017\n",
      "Cost on val dataset after 523 epochs is = 0.09715139741045062\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.09715139741045062\n",
      "learning rate for this epoch =  0.10455494601483782\n",
      "Error on this batch = 0.05122438505901584\n",
      "Error on this batch = 0.08234154313891383\n",
      "Cost on val dataset after 524 epochs is = 0.09710859745213439\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.09710859745213439\n",
      "learning rate for this epoch =  0.10450502719134125\n",
      "Error on this batch = 0.051167950602518206\n",
      "Error on this batch = 0.0822747323696639\n",
      "Cost on val dataset after 525 epochs is = 0.09706591104289168\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.09706591104289168\n",
      "learning rate for this epoch =  0.10445522730720382\n",
      "Error on this batch = 0.05111167768392437\n",
      "Error on this batch = 0.08220812035307958\n",
      "Cost on val dataset after 526 epochs is = 0.0970233376613661\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.0970233376613661\n",
      "learning rate for this epoch =  0.10440554585329116\n",
      "Error on this batch = 0.05105556552844359\n",
      "Error on this batch = 0.08214170596466716\n",
      "Cost on val dataset after 527 epochs is = 0.09698087678995168\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.09698087678995168\n",
      "learning rate for this epoch =  0.10435598232361096\n",
      "Error on this batch = 0.05099961336601657\n",
      "Error on this batch = 0.08207548808692522\n",
      "Cost on val dataset after 528 epochs is = 0.09693852791478659\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.09693852791478659\n",
      "learning rate for this epoch =  0.10430653621528765\n",
      "Error on this batch = 0.050943820431339826\n",
      "Error on this batch = 0.08200946560944558\n",
      "Cost on val dataset after 529 epochs is = 0.09689629052574802\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.09689629052574802\n",
      "learning rate for this epoch =  0.10425720702853739\n",
      "Error on this batch = 0.050888185963887785\n",
      "Error on this batch = 0.08194363742900912\n",
      "Cost on val dataset after 530 epochs is = 0.09685416411644786\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.09685416411644786\n",
      "learning rate for this epoch =  0.10420799426664315\n",
      "Error on this batch = 0.05083270920793364\n",
      "Error on this batch = 0.08187800244967679\n",
      "Cost on val dataset after 531 epochs is = 0.09681214818422892\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.09681214818422892\n",
      "learning rate for this epoch =  0.10415889743593033\n",
      "Error on this batch = 0.05077738941256795\n",
      "Error on this batch = 0.08181255958287591\n",
      "Cost on val dataset after 532 epochs is = 0.09677024223016219\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.09677024223016219\n",
      "learning rate for this epoch =  0.10410991604574225\n",
      "Error on this batch = 0.05072222583171592\n",
      "Error on this batch = 0.08174730774748074\n",
      "Cost on val dataset after 533 epochs is = 0.09672844575904453\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.09672844575904453\n",
      "learning rate for this epoch =  0.10406104960841617\n",
      "Error on this batch = 0.050667217724152634\n",
      "Error on this batch = 0.08168224586988825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 534 epochs is = 0.09668675827939725\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.09668675827939725\n",
      "learning rate for this epoch =  0.1040122976392594\n",
      "Error on this batch = 0.05061236435351666\n",
      "Error on this batch = 0.08161737288408795\n",
      "Cost on val dataset after 535 epochs is = 0.09664517930346496\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.09664517930346496\n",
      "learning rate for this epoch =  0.10396365965652576\n",
      "Error on this batch = 0.050557664988322044\n",
      "Error on this batch = 0.08155268773172686\n",
      "Cost on val dataset after 536 epochs is = 0.09660370834721553\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.09660370834721553\n",
      "learning rate for this epoch =  0.10391513518139214\n",
      "Error on this batch = 0.0505031189019683\n",
      "Error on this batch = 0.08148818936216821\n",
      "Cost on val dataset after 537 epochs is = 0.09656234493033995\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.09656234493033995\n",
      "learning rate for this epoch =  0.10386672373793533\n",
      "Error on this batch = 0.050448725372748984\n",
      "Error on this batch = 0.08142387673254495\n",
      "Cost on val dataset after 538 epochs is = 0.09652108857625319\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.09652108857625319\n",
      "learning rate for this epoch =  0.10381842485310916\n",
      "Error on this batch = 0.050394483683858536\n",
      "Error on this batch = 0.08135974880780741\n",
      "Cost on val dataset after 539 epochs is = 0.09647993881209514\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.09647993881209514\n",
      "learning rate for this epoch =  0.10377023805672174\n",
      "Error on this batch = 0.0503403931233973\n",
      "Error on this batch = 0.0812958045607652\n",
      "Cost on val dataset after 540 epochs is = 0.09643889516873211\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.09643889516873211\n",
      "learning rate for this epoch =  0.10372216288141306\n",
      "Error on this batch = 0.050286452984375014\n",
      "Error on this batch = 0.08123204297212326\n",
      "Cost on val dataset after 541 epochs is = 0.09639795718075861\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.09639795718075861\n",
      "learning rate for this epoch =  0.10367419886263263\n",
      "Error on this batch = 0.05023266256471271\n",
      "Error on this batch = 0.08116846303051248\n",
      "Cost on val dataset after 542 epochs is = 0.09635712438649953\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.09635712438649953\n",
      "learning rate for this epoch =  0.10362634553861746\n",
      "Error on this batch = 0.05017902116724292\n",
      "Error on this batch = 0.08110506373251405\n",
      "Cost on val dataset after 543 epochs is = 0.09631639632801221\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.09631639632801221\n",
      "learning rate for this epoch =  0.10357860245037034\n",
      "Error on this batch = 0.05012552809970833\n",
      "Error on this batch = 0.08104184408267863\n",
      "Cost on val dataset after 544 epochs is = 0.09627577255108925\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.09627577255108925\n",
      "learning rate for this epoch =  0.10353096914163801\n",
      "Error on this batch = 0.05007218267475889\n",
      "Error on this batch = 0.0809788030935394\n",
      "Cost on val dataset after 545 epochs is = 0.09623525260526089\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.09623525260526089\n",
      "learning rate for this epoch =  0.10348344515888994\n",
      "Error on this batch = 0.05001898420994742\n",
      "Error on this batch = 0.08091593978561971\n",
      "Cost on val dataset after 546 epochs is = 0.09619483604379783\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.09619483604379783\n",
      "learning rate for this epoch =  0.10343603005129703\n",
      "Error on this batch = 0.049965932027723564\n",
      "Error on this batch = 0.0808532531874349\n",
      "Cost on val dataset after 547 epochs is = 0.09615452242371393\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.09615452242371393\n",
      "learning rate for this epoch =  0.1033887233707106\n",
      "Error on this batch = 0.04991302545542643\n",
      "Error on this batch = 0.08079074233548912\n",
      "Cost on val dataset after 548 epochs is = 0.096114311305769\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.096114311305769\n",
      "learning rate for this epoch =  0.10334152467164161\n",
      "Error on this batch = 0.04986026382527569\n",
      "Error on this batch = 0.0807284062742661\n",
      "Cost on val dataset after 549 epochs is = 0.09607420225447134\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.09607420225447134\n",
      "learning rate for this epoch =  0.10329443351124007\n",
      "Error on this batch = 0.04980764647436127\n",
      "Error on this batch = 0.08066624405621507\n",
      "Cost on val dataset after 550 epochs is = 0.09603419483808039\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.09603419483808039\n",
      "learning rate for this epoch =  0.10324744944927464\n",
      "Error on this batch = 0.049755172744631614\n",
      "Error on this batch = 0.08060425474173144\n",
      "Cost on val dataset after 551 epochs is = 0.09599428862860887\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.09599428862860887\n",
      "learning rate for this epoch =  0.10320057204811232\n",
      "Error on this batch = 0.04970284198288065\n",
      "Error on this batch = 0.08054243739913224\n",
      "Cost on val dataset after 552 epochs is = 0.09595448320182512\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.09595448320182512\n",
      "learning rate for this epoch =  0.10315380087269863\n",
      "Error on this batch = 0.049650653540733336\n",
      "Error on this batch = 0.08048079110462669\n",
      "Cost on val dataset after 553 epochs is = 0.09591477813725477\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.09591477813725477\n",
      "learning rate for this epoch =  0.10310713549053749\n",
      "Error on this batch = 0.04959860677462991\n",
      "Error on this batch = 0.0804193149422823\n",
      "Cost on val dataset after 554 epochs is = 0.09587517301818226\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.09587517301818226\n",
      "learning rate for this epoch =  0.10306057547167191\n",
      "Error on this batch = 0.049546701045809056\n",
      "Error on this batch = 0.08035800800398576\n",
      "Cost on val dataset after 555 epochs is = 0.09583566743165205\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.09583566743165205\n",
      "learning rate for this epoch =  0.1030141203886643\n",
      "Error on this batch = 0.04949493572028945\n",
      "Error on this batch = 0.08029686938940002\n",
      "Cost on val dataset after 556 epochs is = 0.09579626096846913\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.09579626096846913\n",
      "learning rate for this epoch =  0.10296776981657725\n",
      "Error on this batch = 0.0494433101688504\n",
      "Error on this batch = 0.08023589820591658\n",
      "Cost on val dataset after 557 epochs is = 0.09575695322319941\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.09575695322319941\n",
      "learning rate for this epoch =  0.10292152333295448\n",
      "Error on this batch = 0.049391823767011386\n",
      "Error on this batch = 0.08017509356860397\n",
      "Cost on val dataset after 558 epochs is = 0.09571774379416921\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.09571774379416921\n",
      "learning rate for this epoch =  0.10287538051780193\n",
      "Error on this batch = 0.04934047589500998\n",
      "Error on this batch = 0.08011445460015221\n",
      "Cost on val dataset after 559 epochs is = 0.09567863228346447\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.09567863228346447\n",
      "learning rate for this epoch =  0.10282934095356899\n",
      "Error on this batch = 0.049289265937779304\n",
      "Error on this batch = 0.08005398043081352\n",
      "Cost on val dataset after 560 epochs is = 0.09563961829692919\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.09563961829692919\n",
      "learning rate for this epoch =  0.10278340422512992\n",
      "Error on this batch = 0.04923819328492388\n",
      "Error on this batch = 0.07999367019833957\n",
      "Cost on val dataset after 561 epochs is = 0.09560070144416316\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.09560070144416316\n",
      "learning rate for this epoch =  0.10273756991976561\n",
      "Error on this batch = 0.04918725733069474\n",
      "Error on this batch = 0.07993352304791534\n",
      "Cost on val dataset after 562 epochs is = 0.0955618813385191\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.0955618813385191\n",
      "learning rate for this epoch =  0.10269183762714515\n",
      "Error on this batch = 0.04913645747396338\n",
      "Error on this batch = 0.0798735381320898\n",
      "Cost on val dataset after 563 epochs is = 0.09552315759709906\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.09552315759709906\n",
      "learning rate for this epoch =  0.10264620693930798\n",
      "Error on this batch = 0.04908579311819491\n",
      "Error on this batch = 0.0798137146107038\n",
      "Cost on val dataset after 564 epochs is = 0.09548452984074975\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.09548452984074975\n",
      "learning rate for this epoch =  0.10260067745064594\n",
      "Error on this batch = 0.04903526367142003\n",
      "Error on this batch = 0.0797540516508151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 565 epochs is = 0.09544599769405729\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.09544599769405729\n",
      "learning rate for this epoch =  0.10255524875788552\n",
      "Error on this batch = 0.0489848685462063\n",
      "Error on this batch = 0.079694548426621\n",
      "Cost on val dataset after 566 epochs is = 0.09540756078534124\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.09540756078534124\n",
      "learning rate for this epoch =  0.10250992046007043\n",
      "Error on this batch = 0.04893460715962851\n",
      "Error on this batch = 0.07963520411937848\n",
      "Cost on val dataset after 567 epochs is = 0.09536921874664708\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.09536921874664708\n",
      "learning rate for this epoch =  0.10246469215854406\n",
      "Error on this batch = 0.04888447893323813\n",
      "Error on this batch = 0.07957601791732241\n",
      "Cost on val dataset after 568 epochs is = 0.09533097121373846\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.09533097121373846\n",
      "learning rate for this epoch =  0.10241956345693246\n",
      "Error on this batch = 0.04883448329303193\n",
      "Error on this batch = 0.07951698901558187\n",
      "Cost on val dataset after 569 epochs is = 0.09529281782608795\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.09529281782608795\n",
      "learning rate for this epoch =  0.1023745339611271\n",
      "Error on this batch = 0.04878461966942016\n",
      "Error on this batch = 0.07945811661609452\n",
      "Cost on val dataset after 570 epochs is = 0.09525475822686712\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.09525475822686712\n",
      "learning rate for this epoch =  0.10232960327926806\n",
      "Error on this batch = 0.04873488749719351\n",
      "Error on this batch = 0.07939939992751978\n",
      "Cost on val dataset after 571 epochs is = 0.09521679206293521\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.09521679206293521\n",
      "learning rate for this epoch =  0.10228477102172728\n",
      "Error on this batch = 0.048685286215489704\n",
      "Error on this batch = 0.07934083816515057\n",
      "Cost on val dataset after 572 epochs is = 0.09517891898482707\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.09517891898482707\n",
      "learning rate for this epoch =  0.10224003680109194\n",
      "Error on this batch = 0.048635815267759314\n",
      "Error on this batch = 0.07928243055082379\n",
      "Cost on val dataset after 573 epochs is = 0.09514113864673968\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.09514113864673968\n",
      "learning rate for this epoch =  0.10219540023214801\n",
      "Error on this batch = 0.04858647410173099\n",
      "Error on this batch = 0.07922417631283027\n",
      "Cost on val dataset after 574 epochs is = 0.09510345070651784\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.09510345070651784\n",
      "learning rate for this epoch =  0.10215086093186404\n",
      "Error on this batch = 0.04853726216937606\n",
      "Error on this batch = 0.07916607468582347\n",
      "Cost on val dataset after 575 epochs is = 0.09506585482563831\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.09506585482563831\n",
      "learning rate for this epoch =  0.10210641851937487\n",
      "Error on this batch = 0.04848817892687246\n",
      "Error on this batch = 0.0791081249107281\n",
      "Cost on val dataset after 576 epochs is = 0.09502835066919328\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.09502835066919328\n",
      "learning rate for this epoch =  0.10206207261596577\n",
      "Error on this batch = 0.048439223834568355\n",
      "Error on this batch = 0.07905032623464811\n",
      "Cost on val dataset after 577 epochs is = 0.09499093790587206\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.09499093790587206\n",
      "learning rate for this epoch =  0.10201782284505649\n",
      "Error on this batch = 0.048390396356945045\n",
      "Error on this batch = 0.07899267791077437\n",
      "Cost on val dataset after 578 epochs is = 0.09495361620794196\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.09495361620794196\n",
      "learning rate for this epoch =  0.10197366883218573\n",
      "Error on this batch = 0.04834169596257949\n",
      "Error on this batch = 0.07893517919829261\n",
      "Cost on val dataset after 579 epochs is = 0.09491638525122789\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.09491638525122789\n",
      "learning rate for this epoch =  0.1019296102049953\n",
      "Error on this batch = 0.04829312212410634\n",
      "Error on this batch = 0.07887782936229108\n",
      "Cost on val dataset after 580 epochs is = 0.09487924471509043\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.09487924471509043\n",
      "learning rate for this epoch =  0.10188564659321496\n",
      "Error on this batch = 0.048244674318179616\n",
      "Error on this batch = 0.07882062767366886\n",
      "Cost on val dataset after 581 epochs is = 0.09484219428240297\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.09484219428240297\n",
      "learning rate for this epoch =  0.10184177762864698\n",
      "Error on this batch = 0.048196352025433986\n",
      "Error on this batch = 0.0787635734090442\n",
      "Cost on val dataset after 582 epochs is = 0.0948052336395274\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.0948052336395274\n",
      "learning rate for this epoch =  0.10179800294515103\n",
      "Error on this batch = 0.04814815473044567\n",
      "Error on this batch = 0.07870666585066355\n",
      "Cost on val dataset after 583 epochs is = 0.09476836247628857\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.09476836247628857\n",
      "learning rate for this epoch =  0.10175432217862923\n",
      "Error on this batch = 0.04810008192169292\n",
      "Error on this batch = 0.07864990428631131\n",
      "Cost on val dataset after 584 epochs is = 0.09473158048594742\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.09473158048594742\n",
      "learning rate for this epoch =  0.10171073496701123\n",
      "Error on this batch = 0.048052133091516444\n",
      "Error on this batch = 0.07859328800922018\n",
      "Cost on val dataset after 585 epochs is = 0.0946948873651729\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.0946948873651729\n",
      "learning rate for this epoch =  0.10166724095023941\n",
      "Error on this batch = 0.04800430773607939\n",
      "Error on this batch = 0.07853681631798251\n",
      "Cost on val dataset after 586 epochs is = 0.0946582828140126\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.0946582828140126\n",
      "learning rate for this epoch =  0.10162383977025442\n",
      "Error on this batch = 0.047956605355327094\n",
      "Error on this batch = 0.07848048851646262\n",
      "Cost on val dataset after 587 epochs is = 0.09462176653586193\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.09462176653586193\n",
      "learning rate for this epoch =  0.10158053107098057\n",
      "Error on this batch = 0.047909025452946584\n",
      "Error on this batch = 0.07842430391371016\n",
      "Cost on val dataset after 588 epochs is = 0.09458533823743237\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.09458533823743237\n",
      "learning rate for this epoch =  0.10153731449831156\n",
      "Error on this batch = 0.04786156753632617\n",
      "Error on this batch = 0.07836826182387464\n",
      "Cost on val dataset after 589 epochs is = 0.09454899762871809\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.09454899762871809\n",
      "learning rate for this epoch =  0.1014941897000962\n",
      "Error on this batch = 0.047814231116514366\n",
      "Error on this batch = 0.0783123615661213\n",
      "Cost on val dataset after 590 epochs is = 0.09451274442296152\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.09451274442296152\n",
      "learning rate for this epoch =  0.10145115632612439\n",
      "Error on this batch = 0.04776701570817929\n",
      "Error on this batch = 0.0782566024645482\n",
      "Cost on val dataset after 591 epochs is = 0.09447657833661753\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.09447657833661753\n",
      "learning rate for this epoch =  0.10140821402811308\n",
      "Error on this batch = 0.04771992082956745\n",
      "Error on this batch = 0.07820098384810488\n",
      "Cost on val dataset after 592 epochs is = 0.0944404990893167\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.0944404990893167\n",
      "learning rate for this epoch =  0.10136536245969245\n",
      "Error on this batch = 0.04767294600246271\n",
      "Error on this batch = 0.07814550505051208\n",
      "Cost on val dataset after 593 epochs is = 0.09440450640382687\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.09440450640382687\n",
      "learning rate for this epoch =  0.10132260127639228\n",
      "Error on this batch = 0.04762609075214519\n",
      "Error on this batch = 0.07809016541018364\n",
      "Cost on val dataset after 594 epochs is = 0.09436860000601398\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.09436860000601398\n",
      "learning rate for this epoch =  0.10127993013562818\n",
      "Error on this batch = 0.047579354607350036\n",
      "Error on this batch = 0.07803496427014922\n",
      "Cost on val dataset after 595 epochs is = 0.09433277962480148\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.09433277962480148\n",
      "learning rate for this epoch =  0.10123734869668825\n",
      "Error on this batch = 0.04753273710022621\n",
      "Error on this batch = 0.07797990097797912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 596 epochs is = 0.09429704499212856\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.09429704499212856\n",
      "learning rate for this epoch =  0.10119485662071964\n",
      "Error on this batch = 0.04748623776629552\n",
      "Error on this batch = 0.07792497488571058\n",
      "Cost on val dataset after 597 epochs is = 0.09426139584290745\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.09426139584290745\n",
      "learning rate for this epoch =  0.10115245357071535\n",
      "Error on this batch = 0.04743985614441126\n",
      "Error on this batch = 0.07787018534977555\n",
      "Cost on val dataset after 598 epochs is = 0.0942258319149795\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.0942258319149795\n",
      "learning rate for this epoch =  0.10111013921150111\n",
      "Error on this batch = 0.04739359177671737\n",
      "Error on this batch = 0.07781553173093057\n",
      "Cost on val dataset after 599 epochs is = 0.09419035294907036\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.09419035294907036\n",
      "learning rate for this epoch =  0.1010679132097223\n",
      "Error on this batch = 0.04734744420860738\n",
      "Error on this batch = 0.0777610133941879\n",
      "Cost on val dataset after 600 epochs is = 0.0941549586887437\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.0941549586887437\n",
      "learning rate for this epoch =  0.10102577523383117\n",
      "Error on this batch = 0.047301412988683594\n",
      "Error on this batch = 0.0777066297087486\n",
      "Cost on val dataset after 601 epochs is = 0.09411964888035454\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.09411964888035454\n",
      "learning rate for this epoch =  0.10098372495407393\n",
      "Error on this batch = 0.04725549766871638\n",
      "Error on this batch = 0.07765238004793722\n",
      "Cost on val dataset after 602 epochs is = 0.09408442327300132\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.09408442327300132\n",
      "learning rate for this epoch =  0.10094176204247814\n",
      "Error on this batch = 0.04720969780360363\n",
      "Error on this batch = 0.07759826378913819\n",
      "Cost on val dataset after 603 epochs is = 0.09404928161847691\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.09404928161847691\n",
      "learning rate for this epoch =  0.10089988617284017\n",
      "Error on this batch = 0.047164012951330464\n",
      "Error on this batch = 0.07754428031373402\n",
      "Cost on val dataset after 604 epochs is = 0.09401422367121909\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.09401422367121909\n",
      "learning rate for this epoch =  0.10085809702071269\n",
      "Error on this batch = 0.04711844267292893\n",
      "Error on this batch = 0.07749042900704516\n",
      "Cost on val dataset after 605 epochs is = 0.09397924918826002\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.09397924918826002\n",
      "learning rate for this epoch =  0.10081639426339235\n",
      "Error on this batch = 0.04707298653243811\n",
      "Error on this batch = 0.07743670925827116\n",
      "Cost on val dataset after 606 epochs is = 0.09394435792917487\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.09394435792917487\n",
      "learning rate for this epoch =  0.10077477757990758\n",
      "Error on this batch = 0.04702764409686444\n",
      "Error on this batch = 0.07738312046043433\n",
      "Cost on val dataset after 607 epochs is = 0.0939095496560299\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.0939095496560299\n",
      "learning rate for this epoch =  0.10073324665100637\n",
      "Error on this batch = 0.04698241493614228\n",
      "Error on this batch = 0.07732966201032401\n",
      "Cost on val dataset after 608 epochs is = 0.09387482413332976\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.09387482413332976\n",
      "learning rate for this epoch =  0.10069180115914433\n",
      "Error on this batch = 0.04693729862309463\n",
      "Error on this batch = 0.07727633330844327\n",
      "Cost on val dataset after 609 epochs is = 0.09384018112796405\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.09384018112796405\n",
      "learning rate for this epoch =  0.1006504407884727\n",
      "Error on this batch = 0.046892294733394346\n",
      "Error on this batch = 0.07722313375895669\n",
      "Cost on val dataset after 610 epochs is = 0.09380562040915363\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.09380562040915363\n",
      "learning rate for this epoch =  0.10060916522482655\n",
      "Error on this batch = 0.046847402845525486\n",
      "Error on this batch = 0.07717006276964002\n",
      "Cost on val dataset after 611 epochs is = 0.09377114174839597\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.09377114174839597\n",
      "learning rate for this epoch =  0.10056797415571314\n",
      "Error on this batch = 0.04680262254074521\n",
      "Error on this batch = 0.07711711975183104\n",
      "Cost on val dataset after 612 epochs is = 0.09373674491941032\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.09373674491941032\n",
      "learning rate for this epoch =  0.10052686727030014\n",
      "Error on this batch = 0.04675795340304574\n",
      "Error on this batch = 0.07706430412038216\n",
      "Cost on val dataset after 613 epochs is = 0.09370242969808251\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.09370242969808251\n",
      "learning rate for this epoch =  0.10048584425940424\n",
      "Error on this batch = 0.04671339501911685\n",
      "Error on this batch = 0.07701161529361437\n",
      "Cost on val dataset after 614 epochs is = 0.09366819586240911\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.09366819586240911\n",
      "learning rate for this epoch =  0.10044490481547967\n",
      "Error on this batch = 0.046668946978308784\n",
      "Error on this batch = 0.07695905269327247\n",
      "Cost on val dataset after 615 epochs is = 0.09363404319244148\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.09363404319244148\n",
      "learning rate for this epoch =  0.10040404863260693\n",
      "Error on this batch = 0.04662460887259544\n",
      "Error on this batch = 0.07690661574448182\n",
      "Cost on val dataset after 616 epochs is = 0.09359997147022954\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.09359997147022954\n",
      "learning rate for this epoch =  0.10036327540648149\n",
      "Error on this batch = 0.046580380296538\n",
      "Error on this batch = 0.07685430387570634\n",
      "Cost on val dataset after 617 epochs is = 0.09356598047976546\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.09356598047976546\n",
      "learning rate for this epoch =  0.10032258483440272\n",
      "Error on this batch = 0.04653626084724902\n",
      "Error on this batch = 0.07680211651870775\n",
      "Cost on val dataset after 618 epochs is = 0.09353207000692687\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.09353207000692687\n",
      "learning rate for this epoch =  0.10028197661526282\n",
      "Error on this batch = 0.046492250124356926\n",
      "Error on this batch = 0.0767500531085062\n",
      "Cost on val dataset after 619 epochs is = 0.09349823983942053\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.09349823983942053\n",
      "learning rate for this epoch =  0.10024145044953589\n",
      "Error on this batch = 0.04644834772997088\n",
      "Error on this batch = 0.07669811308334165\n",
      "Cost on val dataset after 620 epochs is = 0.09346448976672539\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.09346448976672539\n",
      "learning rate for this epoch =  0.10020100603926707\n",
      "Error on this batch = 0.04640455326864622\n",
      "Error on this batch = 0.07664629588463696\n",
      "Cost on val dataset after 621 epochs is = 0.09343081958003618\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.09343081958003618\n",
      "learning rate for this epoch =  0.1001606430880618\n",
      "Error on this batch = 0.04636086634735035\n",
      "Error on this batch = 0.07659460095696156\n",
      "Cost on val dataset after 622 epochs is = 0.093397229072207\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.093397229072207\n",
      "learning rate for this epoch =  0.10012036130107511\n",
      "Error on this batch = 0.046317286575428974\n",
      "Error on this batch = 0.07654302774799641\n",
      "Cost on val dataset after 623 epochs is = 0.09336371803769458\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.09336371803769458\n",
      "learning rate for this epoch =  0.10008016038500113\n",
      "Error on this batch = 0.04627381356457301\n",
      "Error on this batch = 0.07649157570850004\n",
      "Cost on val dataset after 624 epochs is = 0.09333028627250267\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.09333028627250267\n",
      "learning rate for this epoch =  0.10004004004806248\n",
      "Error on this batch = 0.04623044692878582\n",
      "Error on this batch = 0.07644024429227511\n",
      "Cost on val dataset after 625 epochs is = 0.09329693357412591\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.09329693357412591\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 0.04618718628435102\n",
      "Error on this batch = 0.0763890329561365\n",
      "Cost on val dataset after 626 epochs is = 0.09326365974149431\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.09326365974149431\n",
      "learning rate for this epoch =  0.09996003995206232\n",
      "Error on this batch = 0.046144031249800876\n",
      "Error on this batch = 0.07633794115987948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 627 epochs is = 0.09323046457491825\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.09323046457491825\n",
      "learning rate for this epoch =  0.0999201596169957\n",
      "Error on this batch = 0.04610098144588509\n",
      "Error on this batch = 0.07628696836624949\n",
      "Cost on val dataset after 628 epochs is = 0.09319734787603373\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.09319734787603373\n",
      "learning rate for this epoch =  0.09988035870903386\n",
      "Error on this batch = 0.04605803649554013\n",
      "Error on this batch = 0.07623611404091199\n",
      "Cost on val dataset after 629 epochs is = 0.09316430944774816\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.09316430944774816\n",
      "learning rate for this epoch =  0.09984063694388798\n",
      "Error on this batch = 0.04601519602385912\n",
      "Error on this batch = 0.07618537765242339\n",
      "Cost on val dataset after 630 epochs is = 0.09313134909418677\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.09313134909418677\n",
      "learning rate for this epoch =  0.09980099403873664\n",
      "Error on this batch = 0.045972459658062285\n",
      "Error on this batch = 0.0761347586722027\n",
      "Cost on val dataset after 631 epochs is = 0.09309846662063952\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.09309846662063952\n",
      "learning rate for this epoch =  0.099761429712216\n",
      "Error on this batch = 0.04592982702746789\n",
      "Error on this batch = 0.07608425657450346\n",
      "Cost on val dataset after 632 epochs is = 0.09306566183350866\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.09306566183350866\n",
      "learning rate for this epoch =  0.09972194368440992\n",
      "Error on this batch = 0.04588729776346366\n",
      "Error on this batch = 0.07603387083638667\n",
      "Cost on val dataset after 633 epochs is = 0.09303293454025713\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.09303293454025713\n",
      "learning rate for this epoch =  0.09968253567684038\n",
      "Error on this batch = 0.0458448714994789\n",
      "Error on this batch = 0.07598360093769399\n",
      "Cost on val dataset after 634 epochs is = 0.09300028454935748\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.09300028454935748\n",
      "learning rate for this epoch =  0.09964320541245761\n",
      "Error on this batch = 0.04580254787095703\n",
      "Error on this batch = 0.07593344636102152\n",
      "Cost on val dataset after 635 epochs is = 0.09296771167024179\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.09296771167024179\n",
      "learning rate for this epoch =  0.09960395261563074\n",
      "Error on this batch = 0.04576032651532861\n",
      "Error on this batch = 0.07588340659169408\n",
      "Cost on val dataset after 636 epochs is = 0.09293521571325211\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.09293521571325211\n",
      "learning rate for this epoch =  0.0995647770121382\n",
      "Error on this batch = 0.045718207071985144\n",
      "Error on this batch = 0.0758334811177399\n",
      "Cost on val dataset after 637 epochs is = 0.09290279648959225\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.09290279648959225\n",
      "learning rate for this epoch =  0.0995256783291583\n",
      "Error on this batch = 0.04567618918225309\n",
      "Error on this batch = 0.07578366942986584\n",
      "Cost on val dataset after 638 epochs is = 0.09287045381128\n",
      "Initial Cost on Val dataset for this epoch 638 = 0.09287045381128\n",
      "learning rate for this epoch =  0.09948665629526\n",
      "Error on this batch = 0.045634272489368834\n",
      "Error on this batch = 0.07573397102143266\n",
      "Cost on val dataset after 639 epochs is = 0.09283818749110043\n",
      "Initial Cost on Val dataset for this epoch 639 = 0.09283818749110043\n",
      "learning rate for this epoch =  0.09944771064039355\n",
      "Error on this batch = 0.04559245663845369\n",
      "Error on this batch = 0.075684385388431\n",
      "Cost on val dataset after 640 epochs is = 0.09280599734256048\n",
      "Initial Cost on Val dataset for this epoch 640 = 0.09280599734256048\n",
      "learning rate for this epoch =  0.09940884109588133\n",
      "Error on this batch = 0.045550741276489934\n",
      "Error on this batch = 0.07563491202945744\n",
      "Cost on val dataset after 641 epochs is = 0.09277388317984407\n",
      "Initial Cost on Val dataset for this epoch 641 = 0.09277388317984407\n",
      "learning rate for this epoch =  0.09937004739440881\n",
      "Error on this batch = 0.04550912605229703\n",
      "Error on this batch = 0.0755855504456909\n",
      "Cost on val dataset after 642 epochs is = 0.09274184481776855\n",
      "Initial Cost on Val dataset for this epoch 642 = 0.09274184481776855\n",
      "learning rate for this epoch =  0.09933132927001546\n",
      "Error on this batch = 0.04546761061650862\n",
      "Error on this batch = 0.07553630014086936\n",
      "Cost on val dataset after 643 epochs is = 0.09270988207174218\n",
      "Initial Cost on Val dataset for this epoch 643 = 0.09270988207174218\n",
      "learning rate for this epoch =  0.09929268645808582\n",
      "Error on this batch = 0.045426194621549815\n",
      "Error on this batch = 0.07548716062126663\n",
      "Cost on val dataset after 644 epochs is = 0.09267799475772268\n",
      "Initial Cost on Val dataset for this epoch 644 = 0.09267799475772268\n",
      "learning rate for this epoch =  0.09925411869534059\n",
      "Error on this batch = 0.045384877721615195\n",
      "Error on this batch = 0.07543813139566957\n",
      "Cost on val dataset after 645 epochs is = 0.09264618269217689\n",
      "Initial Cost on Val dataset for this epoch 645 = 0.09264618269217689\n",
      "learning rate for this epoch =  0.0992156257198279\n",
      "Error on this batch = 0.04534365957264727\n",
      "Error on this batch = 0.07538921197535542\n",
      "Cost on val dataset after 646 epochs is = 0.0926144456920416\n",
      "Initial Cost on Val dataset for this epoch 646 = 0.0926144456920416\n",
      "learning rate for this epoch =  0.09917720727091442\n",
      "Error on this batch = 0.04530253983231544\n",
      "Error on this batch = 0.07534040187406893\n",
      "Cost on val dataset after 647 epochs is = 0.09258278357468545\n",
      "Initial Cost on Val dataset for this epoch 647 = 0.09258278357468545\n",
      "learning rate for this epoch =  0.09913886308927693\n",
      "Error on this batch = 0.045261518159995455\n",
      "Error on this batch = 0.07529170060800033\n",
      "Cost on val dataset after 648 epochs is = 0.09255119615787216\n",
      "Initial Cost on Val dataset for this epoch 648 = 0.09255119615787216\n",
      "learning rate for this epoch =  0.09910059291689342\n",
      "Error on this batch = 0.04522059421674933\n",
      "Error on this batch = 0.07524310769576292\n",
      "Cost on val dataset after 649 epochs is = 0.09251968325972484\n",
      "Initial Cost on Val dataset for this epoch 649 = 0.09251968325972484\n",
      "learning rate for this epoch =  0.09906239649703485\n",
      "Error on this batch = 0.04517976766530603\n",
      "Error on this batch = 0.07519462265837078\n",
      "Cost on val dataset after 650 epochs is = 0.0924882446986916\n",
      "Initial Cost on Val dataset for this epoch 650 = 0.0924882446986916\n",
      "learning rate for this epoch =  0.09902427357425653\n",
      "Error on this batch = 0.04513903817004211\n",
      "Error on this batch = 0.07514624501921685\n",
      "Cost on val dataset after 651 epochs is = 0.09245688029351219\n",
      "Initial Cost on Val dataset for this epoch 651 = 0.09245688029351219\n",
      "learning rate for this epoch =  0.09898622389438974\n",
      "Error on this batch = 0.04509840539696346\n",
      "Error on this batch = 0.07509797430405092\n",
      "Cost on val dataset after 652 epochs is = 0.09242558986318611\n",
      "Initial Cost on Val dataset for this epoch 652 = 0.09242558986318611\n",
      "learning rate for this epoch =  0.09894824720453346\n",
      "Error on this batch = 0.04505786901368703\n",
      "Error on this batch = 0.07504981004095777\n",
      "Cost on val dataset after 653 epochs is = 0.09239437322694176\n",
      "Initial Cost on Val dataset for this epoch 653 = 0.09239437322694176\n",
      "learning rate for this epoch =  0.09891034325304611\n",
      "Error on this batch = 0.04501742868942324\n",
      "Error on this batch = 0.07500175176033523\n",
      "Cost on val dataset after 654 epochs is = 0.09236323020420698\n",
      "Initial Cost on Val dataset for this epoch 654 = 0.09236323020420698\n",
      "learning rate for this epoch =  0.09887251178953727\n",
      "Error on this batch = 0.04497708409495884\n",
      "Error on this batch = 0.07495379899487242\n",
      "Cost on val dataset after 655 epochs is = 0.09233216061458065\n",
      "Initial Cost on Val dataset for this epoch 655 = 0.09233216061458065\n",
      "learning rate for this epoch =  0.09883475256485971\n",
      "Error on this batch = 0.04493683490264013\n",
      "Error on this batch = 0.07490595127952816\n",
      "Cost on val dataset after 656 epochs is = 0.09230116427780566\n",
      "Initial Cost on Val dataset for this epoch 656 = 0.09230116427780566\n",
      "learning rate for this epoch =  0.09879706533110119\n",
      "Error on this batch = 0.04489668078635675\n",
      "Error on this batch = 0.07485820815150912\n",
      "Cost on val dataset after 657 epochs is = 0.09227024101374315\n",
      "Initial Cost on Val dataset for this epoch 657 = 0.09227024101374315\n",
      "learning rate for this epoch =  0.09875944984157659\n",
      "Error on this batch = 0.04485662142152576\n",
      "Error on this batch = 0.07481056915024821\n",
      "Cost on val dataset after 658 epochs is = 0.09223939064234782\n",
      "Initial Cost on Val dataset for this epoch 658 = 0.09223939064234782\n",
      "learning rate for this epoch =  0.09872190585081982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04481665648507617\n",
      "Error on this batch = 0.07476303381738308\n",
      "Cost on val dataset after 659 epochs is = 0.09220861298364459\n",
      "Initial Cost on Val dataset for this epoch 659 = 0.09220861298364459\n",
      "learning rate for this epoch =  0.09868443311457611\n",
      "Error on this batch = 0.04477678565543397\n",
      "Error on this batch = 0.07471560169673441\n",
      "Cost on val dataset after 660 epochs is = 0.09217790785770649\n",
      "Initial Cost on Val dataset for this epoch 660 = 0.09217790785770649\n",
      "learning rate for this epoch =  0.09864703138979418\n",
      "Error on this batch = 0.044737008612507526\n",
      "Error on this batch = 0.07466827233428447\n",
      "Cost on val dataset after 661 epochs is = 0.09214727508463366\n",
      "Initial Cost on Val dataset for this epoch 661 = 0.09214727508463366\n",
      "learning rate for this epoch =  0.09860970043461836\n",
      "Error on this batch = 0.044697325037673145\n",
      "Error on this batch = 0.07462104527815552\n",
      "Cost on val dataset after 662 epochs is = 0.09211671448453367\n",
      "Initial Cost on Val dataset for this epoch 662 = 0.09211671448453367\n",
      "learning rate for this epoch =  0.09857244000838114\n",
      "Error on this batch = 0.04465773461376144\n",
      "Error on this batch = 0.07457392007858839\n",
      "Cost on val dataset after 663 epochs is = 0.09208622587750284\n",
      "Initial Cost on Val dataset for this epoch 663 = 0.09208622587750284\n",
      "learning rate for this epoch =  0.09853524987159529\n",
      "Error on this batch = 0.04461823702504367\n",
      "Error on this batch = 0.074526896287921\n",
      "Cost on val dataset after 664 epochs is = 0.09205580908360915\n",
      "Initial Cost on Val dataset for this epoch 664 = 0.09205580908360915\n",
      "learning rate for this epoch =  0.0984981297859465\n",
      "Error on this batch = 0.04457883195721864\n",
      "Error on this batch = 0.07447997346056696\n",
      "Cost on val dataset after 665 epochs is = 0.09202546392287561\n",
      "Initial Cost on Val dataset for this epoch 665 = 0.09202546392287561\n",
      "learning rate for this epoch =  0.09846107951428583\n",
      "Error on this batch = 0.044539519097399886\n",
      "Error on this batch = 0.07443315115299426\n",
      "Cost on val dataset after 666 epochs is = 0.0919951902152656\n",
      "Initial Cost on Val dataset for this epoch 666 = 0.0919951902152656\n",
      "learning rate for this epoch =  0.09842409882062221\n",
      "Error on this batch = 0.044500298134103264\n",
      "Error on this batch = 0.07438642892370383\n",
      "Cost on val dataset after 667 epochs is = 0.0919649877806686\n",
      "Initial Cost on Val dataset for this epoch 667 = 0.0919649877806686\n",
      "learning rate for this epoch =  0.09838718747011513\n",
      "Error on this batch = 0.04446116875723472\n",
      "Error on this batch = 0.07433980633320834\n",
      "Cost on val dataset after 668 epochs is = 0.09193485643888748\n",
      "Initial Cost on Val dataset for this epoch 668 = 0.09193485643888748\n",
      "learning rate for this epoch =  0.09835034522906724\n",
      "Error on this batch = 0.044422130658078575\n",
      "Error on this batch = 0.07429328294401107\n",
      "Cost on val dataset after 669 epochs is = 0.09190479600962678\n",
      "Initial Cost on Val dataset for this epoch 669 = 0.09190479600962678\n",
      "learning rate for this epoch =  0.09831357186491718\n",
      "Error on this batch = 0.04438318352928589\n",
      "Error on this batch = 0.07424685832058446\n",
      "Cost on val dataset after 670 epochs is = 0.09187480631248192\n",
      "Initial Cost on Val dataset for this epoch 670 = 0.09187480631248192\n",
      "learning rate for this epoch =  0.09827686714623232\n",
      "Error on this batch = 0.04434432706486339\n",
      "Error on this batch = 0.07420053202934934\n",
      "Cost on val dataset after 671 epochs is = 0.09184488716692953\n",
      "Initial Cost on Val dataset for this epoch 671 = 0.09184488716692953\n",
      "learning rate for this epoch =  0.09824023084270153\n",
      "Error on this batch = 0.04430556096016229\n",
      "Error on this batch = 0.07415430363865375\n",
      "Cost on val dataset after 672 epochs is = 0.09181503839231897\n",
      "Initial Cost on Val dataset for this epoch 672 = 0.09181503839231897\n",
      "learning rate for this epoch =  0.09820366272512825\n",
      "Error on this batch = 0.044266884911867914\n",
      "Error on this batch = 0.07410817271875192\n",
      "Cost on val dataset after 673 epochs is = 0.0917852598078645\n",
      "Initial Cost on Val dataset for this epoch 673 = 0.0917852598078645\n",
      "learning rate for this epoch =  0.0981671625654233\n",
      "Error on this batch = 0.0442282986179891\n",
      "Error on this batch = 0.07406213884178371\n",
      "Cost on val dataset after 674 epochs is = 0.0917555512326387\n",
      "Initial Cost on Val dataset for this epoch 674 = 0.0917555512326387\n",
      "learning rate for this epoch =  0.09813073013659797\n",
      "Error on this batch = 0.04418980177784811\n",
      "Error on this batch = 0.0740162015817535\n",
      "Cost on val dataset after 675 epochs is = 0.09172591248556676\n",
      "Initial Cost on Val dataset for this epoch 675 = 0.09172591248556676\n",
      "learning rate for this epoch =  0.09809436521275706\n",
      "Error on this batch = 0.04415139409207067\n",
      "Error on this batch = 0.07397036051450985\n",
      "Cost on val dataset after 676 epochs is = 0.09169634338542164\n",
      "Initial Cost on Val dataset for this epoch 676 = 0.09169634338542164\n",
      "learning rate for this epoch =  0.09805806756909202\n",
      "Error on this batch = 0.0441130752625764\n",
      "Error on this batch = 0.07392461521772485\n",
      "Cost on val dataset after 677 epochs is = 0.0916668437508202\n",
      "Initial Cost on Val dataset for this epoch 677 = 0.0916668437508202\n",
      "learning rate for this epoch =  0.09802183698187408\n",
      "Error on this batch = 0.04407484499256922\n",
      "Error on this batch = 0.07387896527087368\n",
      "Cost on val dataset after 678 epochs is = 0.09163741340022004\n",
      "Initial Cost on Val dataset for this epoch 678 = 0.09163741340022004\n",
      "learning rate for this epoch =  0.09798567322844758\n",
      "Error on this batch = 0.044036702986528294\n",
      "Error on this batch = 0.07383341025521448\n",
      "Cost on val dataset after 679 epochs is = 0.0916080521519175\n",
      "Initial Cost on Val dataset for this epoch 679 = 0.0916080521519175\n",
      "learning rate for this epoch =  0.09794957608722307\n",
      "Error on this batch = 0.043998648950198865\n",
      "Error on this batch = 0.07378794975376816\n",
      "Cost on val dataset after 680 epochs is = 0.0915787598240461\n",
      "Initial Cost on Val dataset for this epoch 680 = 0.0915787598240461\n",
      "learning rate for this epoch =  0.09791354533767088\n",
      "Error on this batch = 0.043960682590583375\n",
      "Error on this batch = 0.07374258335129856\n",
      "Cost on val dataset after 681 epochs is = 0.09154953623457598\n",
      "Initial Cost on Val dataset for this epoch 681 = 0.09154953623457598\n",
      "learning rate for this epoch =  0.09787758076031428\n",
      "Error on this batch = 0.043922803615933044\n",
      "Error on this batch = 0.07369731063429244\n",
      "Cost on val dataset after 682 epochs is = 0.09152038120131409\n",
      "Initial Cost on Val dataset for this epoch 682 = 0.09152038120131409\n",
      "learning rate for this epoch =  0.09784168213672302\n",
      "Error on this batch = 0.04388501173573909\n",
      "Error on this batch = 0.07365213119094016\n",
      "Cost on val dataset after 683 epochs is = 0.09149129454190509\n",
      "Initial Cost on Val dataset for this epoch 683 = 0.09149129454190509\n",
      "learning rate for this epoch =  0.09780584924950686\n",
      "Error on this batch = 0.04384730666072472\n",
      "Error on this batch = 0.07360704461111615\n",
      "Cost on val dataset after 684 epochs is = 0.09146227607383284\n",
      "Initial Cost on Val dataset for this epoch 684 = 0.09146227607383284\n",
      "learning rate for this epoch =  0.09777008188230901\n",
      "Error on this batch = 0.043809688102836704\n",
      "Error on this batch = 0.07356205048635961\n",
      "Cost on val dataset after 685 epochs is = 0.09143332561442277\n",
      "Initial Cost on Val dataset for this epoch 685 = 0.09143332561442277\n",
      "learning rate for this epoch =  0.09773437981979974\n",
      "Error on this batch = 0.0437721557752376\n",
      "Error on this batch = 0.07351714840985575\n",
      "Cost on val dataset after 686 epochs is = 0.09140444298084477\n",
      "Initial Cost on Val dataset for this epoch 686 = 0.09140444298084477\n",
      "learning rate for this epoch =  0.09769874284767002\n",
      "Error on this batch = 0.0437347093922978\n",
      "Error on this batch = 0.07347233797641682\n",
      "Cost on val dataset after 687 epochs is = 0.09137562799011673\n",
      "Initial Cost on Val dataset for this epoch 687 = 0.09137562799011673\n",
      "learning rate for this epoch =  0.0976631707526253\n",
      "Error on this batch = 0.04369734866958784\n",
      "Error on this batch = 0.07342761878246361\n",
      "Cost on val dataset after 688 epochs is = 0.09134688045910855\n",
      "Initial Cost on Val dataset for this epoch 688 = 0.09134688045910855\n",
      "learning rate for this epoch =  0.09762766332237903\n",
      "Error on this batch = 0.04366007332387084\n",
      "Error on this batch = 0.0733829904260073\n",
      "Cost on val dataset after 689 epochs is = 0.09131820020454703\n",
      "Initial Cost on Val dataset for this epoch 689 = 0.09131820020454703\n",
      "learning rate for this epoch =  0.09759222034564662\n",
      "Error on this batch = 0.04362288307309495\n",
      "Error on this batch = 0.07333845250663128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 690 epochs is = 0.091289587043021\n",
      "Initial Cost on Val dataset for this epoch 690 = 0.091289587043021\n",
      "learning rate for this epoch =  0.09755684161213918\n",
      "Error on this batch = 0.04358577763638607\n",
      "Error on this batch = 0.07329400462547342\n",
      "Cost on val dataset after 691 epochs is = 0.09126104079098704\n",
      "Initial Cost on Val dataset for this epoch 691 = 0.09126104079098704\n",
      "learning rate for this epoch =  0.09752152691255746\n",
      "Error on this batch = 0.04354875673404064\n",
      "Error on this batch = 0.0732496463852086\n",
      "Cost on val dataset after 692 epochs is = 0.09123256126477577\n",
      "Initial Cost on Val dataset for this epoch 692 = 0.09123256126477577\n",
      "learning rate for this epoch =  0.09748627603858566\n",
      "Error on this batch = 0.043511820087518346\n",
      "Error on this batch = 0.07320537739003158\n",
      "Cost on val dataset after 693 epochs is = 0.09120414828059853\n",
      "Initial Cost on Val dataset for this epoch 693 = 0.09120414828059853\n",
      "learning rate for this epoch =  0.09745108878288547\n",
      "Error on this batch = 0.043474967419435226\n",
      "Error on this batch = 0.07316119724563987\n",
      "Cost on val dataset after 694 epochs is = 0.09117580165455456\n",
      "Initial Cost on Val dataset for this epoch 694 = 0.09117580165455456\n",
      "learning rate for this epoch =  0.09741596493909016\n",
      "Error on this batch = 0.04343819845355659\n",
      "Error on this batch = 0.07311710555921741\n",
      "Cost on val dataset after 695 epochs is = 0.09114752120263842\n",
      "Initial Cost on Val dataset for this epoch 695 = 0.09114752120263842\n",
      "learning rate for this epoch =  0.09738090430179841\n",
      "Error on this batch = 0.04340151291479018\n",
      "Error on this batch = 0.0730731019394181\n",
      "Cost on val dataset after 696 epochs is = 0.09111930674074804\n",
      "Initial Cost on Val dataset for this epoch 696 = 0.09111930674074804\n",
      "learning rate for this epoch =  0.09734590666656863\n",
      "Error on this batch = 0.04336491052917928\n",
      "Error on this batch = 0.07302918599634999\n",
      "Cost on val dataset after 697 epochs is = 0.09109115808469301\n",
      "Initial Cost on Val dataset for this epoch 697 = 0.09109115808469301\n",
      "learning rate for this epoch =  0.09731097182991302\n",
      "Error on this batch = 0.04332839102389613\n",
      "Error on this batch = 0.07298535734155942\n",
      "Cost on val dataset after 698 epochs is = 0.09106307505020311\n",
      "Initial Cost on Val dataset for this epoch 698 = 0.09106307505020311\n",
      "learning rate for this epoch =  0.09727609958929176\n",
      "Error on this batch = 0.043291954127235084\n",
      "Error on this batch = 0.07294161558801603\n",
      "Cost on val dataset after 699 epochs is = 0.09103505745293743\n",
      "Initial Cost on Val dataset for this epoch 699 = 0.09103505745293743\n",
      "learning rate for this epoch =  0.09724128974310718\n",
      "Error on this batch = 0.04325559956860598\n",
      "Error on this batch = 0.07289796035009773\n",
      "Cost on val dataset after 700 epochs is = 0.09100710510849351\n",
      "Initial Cost on Val dataset for this epoch 700 = 0.09100710510849351\n",
      "learning rate for this epoch =  0.09720654209069819\n",
      "Error on this batch = 0.04321932707852771\n",
      "Error on this batch = 0.07285439124357597\n",
      "Cost on val dataset after 701 epochs is = 0.0909792178324168\n",
      "Initial Cost on Val dataset for this epoch 701 = 0.0909792178324168\n",
      "learning rate for this epoch =  0.09717185643233449\n",
      "Error on this batch = 0.04318313638862153\n",
      "Error on this batch = 0.07281090788560182\n",
      "Cost on val dataset after 702 epochs is = 0.09095139544021065\n",
      "Initial Cost on Val dataset for this epoch 702 = 0.09095139544021065\n",
      "learning rate for this epoch =  0.09713723256921088\n",
      "Error on this batch = 0.043147027231604594\n",
      "Error on this batch = 0.072767509894692\n",
      "Cost on val dataset after 703 epochs is = 0.09092363774734605\n",
      "Initial Cost on Val dataset for this epoch 703 = 0.09092363774734605\n",
      "learning rate for this epoch =  0.09710267030344186\n",
      "Error on this batch = 0.043110999341283665\n",
      "Error on this batch = 0.07272419689071546\n",
      "Cost on val dataset after 704 epochs is = 0.09089594456927212\n",
      "Initial Cost on Val dataset for this epoch 704 = 0.09089594456927212\n",
      "learning rate for this epoch =  0.09706816943805581\n",
      "Error on this batch = 0.0430750524525485\n",
      "Error on this batch = 0.07268096849488036\n",
      "Cost on val dataset after 705 epochs is = 0.09086831572142626\n",
      "Initial Cost on Val dataset for this epoch 705 = 0.09086831572142626\n",
      "learning rate for this epoch =  0.09703372977698975\n",
      "Error on this batch = 0.04303918630136552\n",
      "Error on this batch = 0.07263782432972142\n",
      "Cost on val dataset after 706 epochs is = 0.09084075101924494\n",
      "Initial Cost on Val dataset for this epoch 706 = 0.09084075101924494\n",
      "learning rate for this epoch =  0.09699935112508366\n",
      "Error on this batch = 0.043003400624771565\n",
      "Error on this batch = 0.0725947640190877\n",
      "Cost on val dataset after 707 epochs is = 0.0908132502781743\n",
      "Initial Cost on Val dataset for this epoch 707 = 0.0908132502781743\n",
      "learning rate for this epoch =  0.09696503328807513\n",
      "Error on this batch = 0.04296769516086733\n",
      "Error on this batch = 0.07255178718813063\n",
      "Cost on val dataset after 708 epochs is = 0.09078581331368112\n",
      "Initial Cost on Val dataset for this epoch 708 = 0.09078581331368112\n",
      "learning rate for this epoch =  0.09693077607259398\n",
      "Error on this batch = 0.04293206964881128\n",
      "Error on this batch = 0.07250889346329291\n",
      "Cost on val dataset after 709 epochs is = 0.09075843994126379\n",
      "Initial Cost on Val dataset for this epoch 709 = 0.09075843994126379\n",
      "learning rate for this epoch =  0.09689657928615694\n",
      "Error on this batch = 0.042896523828813184\n",
      "Error on this batch = 0.07246608247229709\n",
      "Cost on val dataset after 710 epochs is = 0.0907311299764634\n",
      "Initial Cost on Val dataset for this epoch 710 = 0.0907311299764634\n",
      "learning rate for this epoch =  0.09686244273716216\n",
      "Error on this batch = 0.04286105744212785\n",
      "Error on this batch = 0.0724233538441354\n",
      "Cost on val dataset after 711 epochs is = 0.09070388323487492\n",
      "Initial Cost on Val dataset for this epoch 711 = 0.09070388323487492\n",
      "learning rate for this epoch =  0.09682836623488422\n",
      "Error on this batch = 0.042825670231048926\n",
      "Error on this batch = 0.07238070720905926\n",
      "Cost on val dataset after 712 epochs is = 0.09067669953215854\n",
      "Initial Cost on Val dataset for this epoch 712 = 0.09067669953215854\n",
      "learning rate for this epoch =  0.09679434958946864\n",
      "Error on this batch = 0.04279036193890242\n",
      "Error on this batch = 0.07233814219856981\n",
      "Cost on val dataset after 713 epochs is = 0.09064957868405087\n",
      "Initial Cost on Val dataset for this epoch 713 = 0.09064957868405087\n",
      "learning rate for this epoch =  0.09676039261192684\n",
      "Error on this batch = 0.04275513231004066\n",
      "Error on this batch = 0.0722956584454086\n",
      "Cost on val dataset after 714 epochs is = 0.09062252050637642\n",
      "Initial Cost on Val dataset for this epoch 714 = 0.09062252050637642\n",
      "learning rate for this epoch =  0.09672649511413095\n",
      "Error on this batch = 0.04271998108983583\n",
      "Error on this batch = 0.07225325558354855\n",
      "Cost on val dataset after 715 epochs is = 0.09059552481505903\n",
      "Initial Cost on Val dataset for this epoch 715 = 0.09059552481505903\n",
      "learning rate for this epoch =  0.0966926569088086\n",
      "Error on this batch = 0.04268490802467385\n",
      "Error on this batch = 0.07221093324818577\n",
      "Cost on val dataset after 716 epochs is = 0.09056859142613309\n",
      "Initial Cost on Val dataset for this epoch 716 = 0.09056859142613309\n",
      "learning rate for this epoch =  0.09665887780953801\n",
      "Error on this batch = 0.04264991286194784\n",
      "Error on this batch = 0.07216869107573151\n",
      "Cost on val dataset after 717 epochs is = 0.09054172015575519\n",
      "Initial Cost on Val dataset for this epoch 717 = 0.09054172015575519\n",
      "learning rate for this epoch =  0.09662515763074277\n",
      "Error on this batch = 0.04261499535005212\n",
      "Error on this batch = 0.07212652870380469\n",
      "Cost on val dataset after 718 epochs is = 0.0905149108202155\n",
      "Initial Cost on Val dataset for this epoch 718 = 0.0905149108202155\n",
      "learning rate for this epoch =  0.09659149618768699\n",
      "Error on this batch = 0.04258015523837573\n",
      "Error on this batch = 0.07208444577122473\n",
      "Cost on val dataset after 719 epochs is = 0.09048816323594905\n",
      "Initial Cost on Val dataset for this epoch 719 = 0.09048816323594905\n",
      "learning rate for this epoch =  0.09655789329647017\n",
      "Error on this batch = 0.042545392277296125\n",
      "Error on this batch = 0.07204244191800507\n",
      "Cost on val dataset after 720 epochs is = 0.09046147721954721\n",
      "Initial Cost on Val dataset for this epoch 720 = 0.09046147721954721\n",
      "learning rate for this epoch =  0.09652434877402243\n",
      "Error on this batch = 0.04251070621817291\n",
      "Error on this batch = 0.07200051678534687\n",
      "Cost on val dataset after 721 epochs is = 0.09043485258776904\n",
      "Initial Cost on Val dataset for this epoch 721 = 0.09043485258776904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate for this epoch =  0.09649086243809947\n",
      "Error on this batch = 0.04247609681334148\n",
      "Error on this batch = 0.07195867001563326\n",
      "Cost on val dataset after 722 epochs is = 0.0904082891575526\n",
      "Initial Cost on Val dataset for this epoch 722 = 0.0904082891575526\n",
      "learning rate for this epoch =  0.09645743410727778\n",
      "Error on this batch = 0.04244156381610668\n",
      "Error on this batch = 0.07191690125242424\n",
      "Cost on val dataset after 723 epochs is = 0.09038178674602597\n",
      "Initial Cost on Val dataset for this epoch 723 = 0.09038178674602597\n",
      "learning rate for this epoch =  0.09642406360094986\n",
      "Error on this batch = 0.04240710698073641\n",
      "Error on this batch = 0.07187521014045156\n",
      "Cost on val dataset after 724 epochs is = 0.09035534517051884\n",
      "Initial Cost on Val dataset for this epoch 724 = 0.09035534517051884\n",
      "learning rate for this epoch =  0.09639075073931928\n",
      "Error on this batch = 0.04237272606245521\n",
      "Error on this batch = 0.07183359632561455\n",
      "Cost on val dataset after 725 epochs is = 0.09032896424857319\n",
      "Initial Cost on Val dataset for this epoch 725 = 0.09032896424857319\n",
      "learning rate for this epoch =  0.09635749534339606\n",
      "Error on this batch = 0.042338420817437966\n",
      "Error on this batch = 0.07179205945497606\n",
      "Cost on val dataset after 726 epochs is = 0.09030264379795451\n",
      "Initial Cost on Val dataset for this epoch 726 = 0.09030264379795451\n",
      "learning rate for this epoch =  0.0963242972349919\n",
      "Error on this batch = 0.04230419100280338\n",
      "Error on this batch = 0.07175059917675884\n",
      "Cost on val dataset after 727 epochs is = 0.09027638363666272\n",
      "Initial Cost on Val dataset for this epoch 727 = 0.09027638363666272\n",
      "learning rate for this epoch =  0.09629115623671548\n",
      "Error on this batch = 0.04227003637660758\n",
      "Error on this batch = 0.07170921514034262\n",
      "Cost on val dataset after 728 epochs is = 0.09025018358294302\n",
      "Initial Cost on Val dataset for this epoch 728 = 0.09025018358294302\n",
      "learning rate for this epoch =  0.09625807217196783\n",
      "Error on this batch = 0.042235956697837626\n",
      "Error on this batch = 0.07166790699626134\n",
      "Cost on val dataset after 729 epochs is = 0.09022404345529647\n",
      "Initial Cost on Val dataset for this epoch 729 = 0.09022404345529647\n",
      "learning rate for this epoch =  0.09622504486493763\n",
      "Error on this batch = 0.04220195172640507\n",
      "Error on this batch = 0.0716266743962009\n",
      "Cost on val dataset after 730 epochs is = 0.09019796307249077\n",
      "Initial Cost on Val dataset for this epoch 730 = 0.09019796307249077\n",
      "learning rate for this epoch =  0.09619207414059677\n",
      "Error on this batch = 0.04216802122313944\n",
      "Error on this batch = 0.0715855169929974\n",
      "Cost on val dataset after 731 epochs is = 0.09017194225357072\n",
      "Initial Cost on Val dataset for this epoch 731 = 0.09017194225357072\n",
      "learning rate for this epoch =  0.09615915982469565\n",
      "Error on this batch = 0.04213416494978167\n",
      "Error on this batch = 0.07154443444063567\n",
      "Cost on val dataset after 732 epochs is = 0.09014598081786855\n",
      "Initial Cost on Val dataset for this epoch 732 = 0.09014598081786855\n",
      "learning rate for this epoch =  0.09612630174375877\n",
      "Error on this batch = 0.04210038266897764\n",
      "Error on this batch = 0.07150342639424839\n",
      "Cost on val dataset after 733 epochs is = 0.09012007858501415\n",
      "Initial Cost on Val dataset for this epoch 733 = 0.09012007858501415\n",
      "learning rate for this epoch =  0.09609349972508012\n",
      "Error on this batch = 0.04206667414427151\n",
      "Error on this batch = 0.07146249251011537\n",
      "Cost on val dataset after 734 epochs is = 0.09009423537494533\n",
      "Initial Cost on Val dataset for this epoch 734 = 0.09009423537494533\n",
      "learning rate for this epoch =  0.09606075359671883\n",
      "Error on this batch = 0.04203303914009921\n",
      "Error on this batch = 0.07142163244566344\n",
      "Cost on val dataset after 735 epochs is = 0.09006845100791763\n",
      "Initial Cost on Val dataset for this epoch 735 = 0.09006845100791763\n",
      "learning rate for this epoch =  0.09602806318749467\n",
      "Error on this batch = 0.04199947742178178\n",
      "Error on this batch = 0.07138084585946676\n",
      "Cost on val dataset after 736 epochs is = 0.09004272530451435\n",
      "Initial Cost on Val dataset for this epoch 736 = 0.09004272530451435\n",
      "learning rate for this epoch =  0.09599542832698374\n",
      "Error on this batch = 0.04196598875551876\n",
      "Error on this batch = 0.07134013241124722\n",
      "Cost on val dataset after 737 epochs is = 0.09001705808565602\n",
      "Initial Cost on Val dataset for this epoch 737 = 0.09001705808565602\n",
      "learning rate for this epoch =  0.095962848845514\n",
      "Error on this batch = 0.041932572908381587\n",
      "Error on this batch = 0.07129949176187551\n",
      "Cost on val dataset after 738 epochs is = 0.08999144917261012\n",
      "Initial Cost on Val dataset for this epoch 738 = 0.08999144917261012\n",
      "learning rate for this epoch =  0.09593032457416101\n",
      "Error on this batch = 0.04189922964830684\n",
      "Error on this batch = 0.07125892357337253\n",
      "Cost on val dataset after 739 epochs is = 0.08996589838700048\n",
      "Initial Cost on Val dataset for this epoch 739 = 0.08996589838700048\n",
      "learning rate for this epoch =  0.09589785534474361\n",
      "Error on this batch = 0.04186595874408962\n",
      "Error on this batch = 0.07121842750891105\n",
      "Cost on val dataset after 740 epochs is = 0.08994040555081628\n",
      "Initial Cost on Val dataset for this epoch 740 = 0.08994040555081628\n",
      "learning rate for this epoch =  0.09586544098981967\n",
      "Error on this batch = 0.0418327599653768\n",
      "Error on this batch = 0.07117800323281777\n",
      "Cost on val dataset after 741 epochs is = 0.08991497048642155\n",
      "Initial Cost on Val dataset for this epoch 741 = 0.08991497048642155\n",
      "learning rate for this epoch =  0.09583308134268179\n",
      "Error on this batch = 0.041799633082660374\n",
      "Error on this batch = 0.07113765041057578\n",
      "Cost on val dataset after 742 epochs is = 0.08988959301656363\n",
      "Initial Cost on Val dataset for this epoch 742 = 0.08988959301656363\n",
      "learning rate for this epoch =  0.09580077623735313\n",
      "Error on this batch = 0.04176657786727061\n",
      "Error on this batch = 0.0710973687088272\n",
      "Cost on val dataset after 743 epochs is = 0.08986427296438222\n",
      "Initial Cost on Val dataset for this epoch 743 = 0.08986427296438222\n",
      "learning rate for this epoch =  0.09576852550858327\n",
      "Error on this batch = 0.041733594091369376\n",
      "Error on this batch = 0.07105715779537644\n",
      "Cost on val dataset after 744 epochs is = 0.08983901015341782\n",
      "Initial Cost on Val dataset for this epoch 744 = 0.08983901015341782\n",
      "learning rate for this epoch =  0.09573632899184395\n",
      "Error on this batch = 0.04170068152794336\n",
      "Error on this batch = 0.07101701733919351\n",
      "Cost on val dataset after 745 epochs is = 0.08981380440762023\n",
      "Initial Cost on Val dataset for this epoch 745 = 0.08981380440762023\n",
      "learning rate for this epoch =  0.09570418652332507\n",
      "Error on this batch = 0.04166783995079736\n",
      "Error on this batch = 0.07097694701041773\n",
      "Cost on val dataset after 746 epochs is = 0.08978865555135672\n",
      "Initial Cost on Val dataset for this epoch 746 = 0.08978865555135672\n",
      "learning rate for this epoch =  0.0956720979399305\n",
      "Error on this batch = 0.04163506913454732\n",
      "Error on this batch = 0.07093694648036179\n",
      "Cost on val dataset after 747 epochs is = 0.08976356340942003\n",
      "Initial Cost on Val dataset for this epoch 747 = 0.08976356340942003\n",
      "learning rate for this epoch =  0.0956400630792741\n",
      "Error on this batch = 0.04160236885461368\n",
      "Error on this batch = 0.07089701542151597\n",
      "Cost on val dataset after 748 epochs is = 0.08973852780703644\n",
      "Initial Cost on Val dataset for this epoch 748 = 0.08973852780703644\n",
      "learning rate for this epoch =  0.09560808177967559\n",
      "Error on this batch = 0.041569738887214526\n",
      "Error on this batch = 0.07085715350755285\n",
      "Cost on val dataset after 749 epochs is = 0.0897135485698733\n",
      "Initial Cost on Val dataset for this epoch 749 = 0.0897135485698733\n",
      "learning rate for this epoch =  0.09557615388015658\n",
      "Error on this batch = 0.04153717900935879\n",
      "Error on this batch = 0.07081736041333196\n",
      "Cost on val dataset after 750 epochs is = 0.08968862552404665\n",
      "Initial Cost on Val dataset for this epoch 750 = 0.08968862552404665\n",
      "learning rate for this epoch =  0.09554427922043668\n",
      "Error on this batch = 0.04150468899883949\n",
      "Error on this batch = 0.07077763581490512\n",
      "Cost on val dataset after 751 epochs is = 0.08966375849612848\n",
      "Initial Cost on Val dataset for this epoch 751 = 0.08966375849612848\n",
      "learning rate for this epoch =  0.0955124576409294\n",
      "Error on this batch = 0.041472268634226685\n",
      "Error on this batch = 0.07073797938952167\n",
      "Cost on val dataset after 752 epochs is = 0.08963894731315392\n",
      "Initial Cost on Val dataset for this epoch 752 = 0.08963894731315392\n",
      "learning rate for this epoch =  0.09548068898273834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04143991769486098\n",
      "Error on this batch = 0.07069839081563395\n",
      "Cost on val dataset after 753 epochs is = 0.08961419180262829\n",
      "Initial Cost on Val dataset for this epoch 753 = 0.08961419180262829\n",
      "learning rate for this epoch =  0.09544897308765321\n",
      "Error on this batch = 0.04140763596084643\n",
      "Error on this batch = 0.07065886977290335\n",
      "Cost on val dataset after 754 epochs is = 0.08958949179253375\n",
      "Initial Cost on Val dataset for this epoch 754 = 0.08958949179253375\n",
      "learning rate for this epoch =  0.09541730979814601\n",
      "Error on this batch = 0.04137542321304399\n",
      "Error on this batch = 0.07061941594220607\n",
      "Cost on val dataset after 755 epochs is = 0.08956484711133601\n",
      "Initial Cost on Val dataset for this epoch 755 = 0.08956484711133601\n",
      "learning rate for this epoch =  0.09538569895736723\n",
      "Error on this batch = 0.04134327923306444\n",
      "Error on this batch = 0.07058002900563952\n",
      "Cost on val dataset after 756 epochs is = 0.08954025758799071\n",
      "Initial Cost on Val dataset for this epoch 756 = 0.08954025758799071\n",
      "learning rate for this epoch =  0.0953541404091419\n",
      "Error on this batch = 0.0413112038032618\n",
      "Error on this batch = 0.07054070864652863\n",
      "Cost on val dataset after 757 epochs is = 0.08951572305194955\n",
      "Initial Cost on Val dataset for this epoch 757 = 0.08951572305194955\n",
      "learning rate for this epoch =  0.09532263399796595\n",
      "Error on this batch = 0.0412791967067264\n",
      "Error on this batch = 0.07050145454943238\n",
      "Cost on val dataset after 758 epochs is = 0.08949124333316641\n",
      "Initial Cost on Val dataset for this epoch 758 = 0.08949124333316641\n",
      "learning rate for this epoch =  0.09529117956900235\n",
      "Error on this batch = 0.041247257727278205\n",
      "Error on this batch = 0.07046226640015069\n",
      "Cost on val dataset after 759 epochs is = 0.08946681826210326\n",
      "Initial Cost on Val dataset for this epoch 759 = 0.08946681826210326\n",
      "learning rate for this epoch =  0.09525977696807737\n",
      "Error on this batch = 0.04121538664946004\n",
      "Error on this batch = 0.07042314388573108\n",
      "Cost on val dataset after 760 epochs is = 0.08944244766973566\n",
      "Initial Cost on Val dataset for this epoch 760 = 0.08944244766973566\n",
      "learning rate for this epoch =  0.095228426041677\n",
      "Error on this batch = 0.04118358325853081\n",
      "Error on this batch = 0.07038408669447581\n",
      "Cost on val dataset after 761 epochs is = 0.08941813138755832\n",
      "Initial Cost on Val dataset for this epoch 761 = 0.08941813138755832\n",
      "learning rate for this epoch =  0.09519712663694305\n",
      "Error on this batch = 0.04115184734045879\n",
      "Error on this batch = 0.07034509451594911\n",
      "Cost on val dataset after 762 epochs is = 0.08939386924759028\n",
      "Initial Cost on Val dataset for this epoch 762 = 0.08939386924759028\n",
      "learning rate for this epoch =  0.09516587860166968\n",
      "Error on this batch = 0.04112017868191499\n",
      "Error on this batch = 0.07030616704098423\n",
      "Cost on val dataset after 763 epochs is = 0.08936966108238015\n",
      "Initial Cost on Val dataset for this epoch 763 = 0.08936966108238015\n",
      "learning rate for this epoch =  0.09513468178429965\n",
      "Error on this batch = 0.041088577070266405\n",
      "Error on this batch = 0.07026730396169088\n",
      "Cost on val dataset after 764 epochs is = 0.08934550672501076\n",
      "Initial Cost on Val dataset for this epoch 764 = 0.08934550672501076\n",
      "learning rate for this epoch =  0.0951035360339208\n",
      "Error on this batch = 0.041057042293569455\n",
      "Error on this batch = 0.07022850497146271\n",
      "Cost on val dataset after 765 epochs is = 0.08932140600910411\n",
      "Initial Cost on Val dataset for this epoch 765 = 0.08932140600910411\n",
      "learning rate for this epoch =  0.09507244120026234\n",
      "Error on this batch = 0.04102557414056335\n",
      "Error on this batch = 0.07018976976498484\n",
      "Cost on val dataset after 766 epochs is = 0.08929735876882562\n",
      "Initial Cost on Val dataset for this epoch 766 = 0.08929735876882562\n",
      "learning rate for this epoch =  0.09504139713369145\n",
      "Error on this batch = 0.04099417240066347\n",
      "Error on this batch = 0.07015109803824122\n",
      "Cost on val dataset after 767 epochs is = 0.08927336483888863\n",
      "Initial Cost on Val dataset for this epoch 767 = 0.08927336483888863\n",
      "learning rate for this epoch =  0.09501040368520958\n",
      "Error on this batch = 0.04096283686395495\n",
      "Error on this batch = 0.07011248948852256\n",
      "Cost on val dataset after 768 epochs is = 0.08924942405455848\n",
      "Initial Cost on Val dataset for this epoch 768 = 0.08924942405455848\n",
      "learning rate for this epoch =  0.09497946070644907\n",
      "Error on this batch = 0.04093156732118608\n",
      "Error on this batch = 0.07007394381443369\n",
      "Cost on val dataset after 769 epochs is = 0.08922553625165629\n",
      "Initial Cost on Val dataset for this epoch 769 = 0.08922553625165629\n",
      "learning rate for this epoch =  0.09494856804966957\n",
      "Error on this batch = 0.04090036356376194\n",
      "Error on this batch = 0.07003546071590154\n",
      "Cost on val dataset after 770 epochs is = 0.08920170126656288\n",
      "Initial Cost on Val dataset for this epoch 770 = 0.08920170126656288\n",
      "learning rate for this epoch =  0.09491772556775467\n",
      "Error on this batch = 0.040869225383737925\n",
      "Error on this batch = 0.06999703989418257\n",
      "Cost on val dataset after 771 epochs is = 0.08917791893622228\n",
      "Initial Cost on Val dataset for this epoch 771 = 0.08917791893622228\n",
      "learning rate for this epoch =  0.09488693311420834\n",
      "Error on this batch = 0.04083815257381346\n",
      "Error on this batch = 0.06995868105187059\n",
      "Cost on val dataset after 772 epochs is = 0.08915418909814497\n",
      "Initial Cost on Val dataset for this epoch 772 = 0.08915418909814497\n",
      "learning rate for this epoch =  0.0948561905431516\n",
      "Error on this batch = 0.040807144927325734\n",
      "Error on this batch = 0.06992038389290439\n",
      "Cost on val dataset after 773 epochs is = 0.0891305115904112\n",
      "Initial Cost on Val dataset for this epoch 773 = 0.0891305115904112\n",
      "learning rate for this epoch =  0.09482549770931908\n",
      "Error on this batch = 0.040776202238243346\n",
      "Error on this batch = 0.06988214812257565\n",
      "Cost on val dataset after 774 epochs is = 0.08910688625167382\n",
      "Initial Cost on Val dataset for this epoch 774 = 0.08910688625167382\n",
      "learning rate for this epoch =  0.09479485446805574\n",
      "Error on this batch = 0.040745324301160304\n",
      "Error on this batch = 0.06984397344753612\n",
      "Cost on val dataset after 775 epochs is = 0.0890833129211612\n",
      "Initial Cost on Val dataset for this epoch 775 = 0.0890833129211612\n",
      "learning rate for this epoch =  0.09476426067531338\n",
      "Error on this batch = 0.04071451091128976\n",
      "Error on this batch = 0.06980585957580564\n",
      "Cost on val dataset after 776 epochs is = 0.08905979143867983\n",
      "Initial Cost on Val dataset for this epoch 776 = 0.08905979143867983\n",
      "learning rate for this epoch =  0.0947337161876474\n",
      "Error on this batch = 0.04068376186445804\n",
      "Error on this batch = 0.06976780621677948\n",
      "Cost on val dataset after 777 epochs is = 0.08903632164461654\n",
      "Initial Cost on Val dataset for this epoch 777 = 0.08903632164461654\n",
      "learning rate for this epoch =  0.09470322086221351\n",
      "Error on this batch = 0.04065307695709871\n",
      "Error on this batch = 0.06972981308123577\n",
      "Cost on val dataset after 778 epochs is = 0.08901290337994106\n",
      "Initial Cost on Val dataset for this epoch 778 = 0.08901290337994106\n",
      "learning rate for this epoch =  0.09467277455676439\n",
      "Error on this batch = 0.040622455986246545\n",
      "Error on this batch = 0.06969187988134304\n",
      "Cost on val dataset after 779 epochs is = 0.08898953648620772\n",
      "Initial Cost on Val dataset for this epoch 779 = 0.08898953648620772\n",
      "learning rate for this epoch =  0.0946423771296465\n",
      "Error on this batch = 0.040591898749531834\n",
      "Error on this batch = 0.06965400633066741\n",
      "Cost on val dataset after 780 epochs is = 0.0889662208055577\n",
      "Initial Cost on Val dataset for this epoch 780 = 0.0889662208055577\n",
      "learning rate for this epoch =  0.09461202843979676\n",
      "Error on this batch = 0.040561405045174616\n",
      "Error on this batch = 0.06961619214417986\n",
      "Cost on val dataset after 781 epochs is = 0.08894295618072033\n",
      "Initial Cost on Val dataset for this epoch 781 = 0.08894295618072033\n",
      "learning rate for this epoch =  0.09458172834673945\n",
      "Error on this batch = 0.040530974671979025\n",
      "Error on this batch = 0.06957843703826334\n",
      "Cost on val dataset after 782 epochs is = 0.08891974245501494\n",
      "Initial Cost on Val dataset for this epoch 782 = 0.08891974245501494\n",
      "learning rate for this epoch =  0.09455147671058287\n",
      "Error on this batch = 0.040500607429327616\n",
      "Error on this batch = 0.06954074073071977\n",
      "Cost on val dataset after 783 epochs is = 0.088896579472352\n",
      "Initial Cost on Val dataset for this epoch 783 = 0.088896579472352\n",
      "learning rate for this epoch =  0.09452127339201631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04047030311717604\n",
      "Error on this batch = 0.06950310294077687\n",
      "Cost on val dataset after 784 epochs is = 0.08887346707723427\n",
      "Initial Cost on Val dataset for this epoch 784 = 0.08887346707723427\n",
      "learning rate for this epoch =  0.0944911182523068\n",
      "Error on this batch = 0.04044006153604761\n",
      "Error on this batch = 0.06946552338909504\n",
      "Cost on val dataset after 785 epochs is = 0.08885040511475797\n",
      "Initial Cost on Val dataset for this epoch 785 = 0.08885040511475797\n",
      "learning rate for this epoch =  0.09446101115329605\n",
      "Error on this batch = 0.040409882487027884\n",
      "Error on this batch = 0.06942800179777377\n",
      "Cost on val dataset after 786 epochs is = 0.08882739343061337\n",
      "Initial Cost on Val dataset for this epoch 786 = 0.08882739343061337\n",
      "learning rate for this epoch =  0.09443095195739727\n",
      "Error on this batch = 0.04037976577175965\n",
      "Error on this batch = 0.06939053789035826\n",
      "Cost on val dataset after 787 epochs is = 0.08880443187108558\n",
      "Initial Cost on Val dataset for this epoch 787 = 0.08880443187108558\n",
      "learning rate for this epoch =  0.09440094052759214\n",
      "Error on this batch = 0.04034971119243771\n",
      "Error on this batch = 0.06935313139184567\n",
      "Cost on val dataset after 788 epochs is = 0.08878152028305504\n",
      "Initial Cost on Val dataset for this epoch 788 = 0.08878152028305504\n",
      "learning rate for this epoch =  0.09437097672742772\n",
      "Error on this batch = 0.040319718551804044\n",
      "Error on this batch = 0.06931578202869129\n",
      "Cost on val dataset after 789 epochs is = 0.08875865851399771\n",
      "Initial Cost on Val dataset for this epoch 789 = 0.08875865851399771\n",
      "learning rate for this epoch =  0.09434106042101341\n",
      "Error on this batch = 0.04028978765314269\n",
      "Error on this batch = 0.06927848952881449\n",
      "Cost on val dataset after 790 epochs is = 0.08873584641198538\n",
      "Initial Cost on Val dataset for this epoch 790 = 0.08873584641198538\n",
      "learning rate for this epoch =  0.09431119147301793\n",
      "Error on this batch = 0.040259918300275345\n",
      "Error on this batch = 0.06924125362160446\n",
      "Cost on val dataset after 791 epochs is = 0.08871308382568557\n",
      "Initial Cost on Val dataset for this epoch 791 = 0.08871308382568557\n",
      "learning rate for this epoch =  0.09428136974866627\n",
      "Error on this batch = 0.04023011029755624\n",
      "Error on this batch = 0.0692040740379261\n",
      "Cost on val dataset after 792 epochs is = 0.08869037060436133\n",
      "Initial Cost on Val dataset for this epoch 792 = 0.08869037060436133\n",
      "learning rate for this epoch =  0.09425159511373676\n",
      "Error on this batch = 0.04020036344986811\n",
      "Error on this batch = 0.06916695051012506\n",
      "Cost on val dataset after 793 epochs is = 0.08866770659787111\n",
      "Initial Cost on Val dataset for this epoch 793 = 0.08866770659787111\n",
      "learning rate for this epoch =  0.09422186743455808\n",
      "Error on this batch = 0.040170677562617385\n",
      "Error on this batch = 0.06912988277203332\n",
      "Cost on val dataset after 794 epochs is = 0.08864509165666802\n",
      "Initial Cost on Val dataset for this epoch 794 = 0.08864509165666802\n",
      "learning rate for this epoch =  0.0941921865780063\n",
      "Error on this batch = 0.04014105244173012\n",
      "Error on this batch = 0.06909287055897409\n",
      "Cost on val dataset after 795 epochs is = 0.08862252563179947\n",
      "Initial Cost on Val dataset for this epoch 795 = 0.08862252563179947\n",
      "learning rate for this epoch =  0.09416255241150198\n",
      "Error on this batch = 0.04011148789364784\n",
      "Error on this batch = 0.0690559136077667\n",
      "Cost on val dataset after 796 epochs is = 0.08860000837490625\n",
      "Initial Cost on Val dataset for this epoch 796 = 0.08860000837490625\n",
      "learning rate for this epoch =  0.09413296480300724\n",
      "Error on this batch = 0.04008198372532334\n",
      "Error on this batch = 0.06901901165673127\n",
      "Cost on val dataset after 797 epochs is = 0.08857753973822169\n",
      "Initial Cost on Val dataset for this epoch 797 = 0.08857753973822169\n",
      "learning rate for this epoch =  0.09410342362102285\n",
      "Error on this batch = 0.040052539744216915\n",
      "Error on this batch = 0.06898216444569306\n",
      "Cost on val dataset after 798 epochs is = 0.08855511957457056\n",
      "Initial Cost on Val dataset for this epoch 798 = 0.08855511957457056\n",
      "learning rate for this epoch =  0.09407392873458542\n",
      "Error on this batch = 0.04002315575829262\n",
      "Error on this batch = 0.06894537171598683\n",
      "Cost on val dataset after 799 epochs is = 0.088532747737368\n",
      "Initial Cost on Val dataset for this epoch 799 = 0.088532747737368\n",
      "learning rate for this epoch =  0.09404448001326453\n",
      "Error on this batch = 0.039993831576014466\n",
      "Error on this batch = 0.06890863321046073\n",
      "Cost on val dataset after 800 epochs is = 0.08851042408061807\n",
      "Initial Cost on Val dataset for this epoch 800 = 0.08851042408061807\n",
      "learning rate for this epoch =  0.09401507732715984\n",
      "Error on this batch = 0.03996456700634311\n",
      "Error on this batch = 0.06887194867348022\n",
      "Cost on val dataset after 801 epochs is = 0.08848814845891247\n",
      "Initial Cost on Val dataset for this epoch 801 = 0.08848814845891247\n",
      "learning rate for this epoch =  0.09398572054689833\n",
      "Error on this batch = 0.039935361858732386\n",
      "Error on this batch = 0.06883531785093147\n",
      "Cost on val dataset after 802 epochs is = 0.08846592072742879\n",
      "Initial Cost on Val dataset for this epoch 802 = 0.08846592072742879\n",
      "learning rate for this epoch =  0.09395640954363149\n",
      "Error on this batch = 0.039906215943126114\n",
      "Error on this batch = 0.06879874049022497\n",
      "Cost on val dataset after 803 epochs is = 0.08844374074192896\n",
      "Initial Cost on Val dataset for this epoch 803 = 0.08844374074192896\n",
      "learning rate for this epoch =  0.09392714418903259\n",
      "Error on this batch = 0.03987712906995502\n",
      "Error on this batch = 0.06876221634029843\n",
      "Cost on val dataset after 804 epochs is = 0.08842160835875745\n",
      "Initial Cost on Val dataset for this epoch 804 = 0.08842160835875745\n",
      "learning rate for this epoch =  0.0938979243552938\n",
      "Error on this batch = 0.03984810105013385\n",
      "Error on this batch = 0.06872574515161972\n",
      "Cost on val dataset after 805 epochs is = 0.08839952343483923\n",
      "Initial Cost on Val dataset for this epoch 805 = 0.08839952343483923\n",
      "learning rate for this epoch =  0.0938687499151236\n",
      "Error on this batch = 0.0398191316950585\n",
      "Error on this batch = 0.06868932667618984\n",
      "Cost on val dataset after 806 epochs is = 0.08837748582767785\n",
      "Initial Cost on Val dataset for this epoch 806 = 0.08837748582767785\n",
      "learning rate for this epoch =  0.09383962074174393\n",
      "Error on this batch = 0.039790220816603404\n",
      "Error on this batch = 0.06865296066754495\n",
      "Cost on val dataset after 807 epochs is = 0.0883554953953533\n",
      "Initial Cost on Val dataset for this epoch 807 = 0.0883554953953533\n",
      "learning rate for this epoch =  0.09381053670888753\n",
      "Error on this batch = 0.039761368227119176\n",
      "Error on this batch = 0.06861664688075894\n",
      "Cost on val dataset after 808 epochs is = 0.08833355199651968\n",
      "Initial Cost on Val dataset for this epoch 808 = 0.08833355199651968\n",
      "learning rate for this epoch =  0.09378149769079532\n",
      "Error on this batch = 0.039732573739430066\n",
      "Error on this batch = 0.06858038507244528\n",
      "Cost on val dataset after 809 epochs is = 0.08831165549040296\n",
      "Initial Cost on Val dataset for this epoch 809 = 0.08831165549040296\n",
      "learning rate for this epoch =  0.09375250356221361\n",
      "Error on this batch = 0.0397038371668319\n",
      "Error on this batch = 0.06854417500075885\n",
      "Cost on val dataset after 810 epochs is = 0.0882898057367985\n",
      "Initial Cost on Val dataset for this epoch 810 = 0.0882898057367985\n",
      "learning rate for this epoch =  0.09372355419839151\n",
      "Error on this batch = 0.039675158323090105\n",
      "Error on this batch = 0.06850801642539744\n",
      "Cost on val dataset after 811 epochs is = 0.08826800259606855\n",
      "Initial Cost on Val dataset for this epoch 811 = 0.08826800259606855\n",
      "learning rate for this epoch =  0.09369464947507833\n",
      "Error on this batch = 0.03964653702243766\n",
      "Error on this batch = 0.06847190910760333\n",
      "Cost on val dataset after 812 epochs is = 0.0882462459291397\n",
      "Initial Cost on Val dataset for this epoch 812 = 0.0882462459291397\n",
      "learning rate for this epoch =  0.09366578926852086\n",
      "Error on this batch = 0.039617973079573494\n",
      "Error on this batch = 0.06843585281016402\n",
      "Cost on val dataset after 813 epochs is = 0.08822453559750003\n",
      "Initial Cost on Val dataset for this epoch 813 = 0.08822453559750003\n",
      "learning rate for this epoch =  0.09363697345546085\n",
      "Error on this batch = 0.039589466309660884\n",
      "Error on this batch = 0.06839984729741354\n",
      "Cost on val dataset after 814 epochs is = 0.08820287146319652\n",
      "Initial Cost on Val dataset for this epoch 814 = 0.08820287146319652\n",
      "learning rate for this epoch =  0.09360820191313243\n",
      "Error on this batch = 0.03956101652832604\n",
      "Error on this batch = 0.06836389233523275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 815 epochs is = 0.08818125338883208\n",
      "Initial Cost on Val dataset for this epoch 815 = 0.08818125338883208\n",
      "learning rate for this epoch =  0.09357947451925948\n",
      "Error on this batch = 0.03953262355165684\n",
      "Error on this batch = 0.06832798769105017\n",
      "Cost on val dataset after 816 epochs is = 0.08815968123756283\n",
      "Initial Cost on Val dataset for this epoch 816 = 0.08815968123756283\n",
      "learning rate for this epoch =  0.09355079115205313\n",
      "Error on this batch = 0.03950428719620174\n",
      "Error on this batch = 0.06829213313384193\n",
      "Cost on val dataset after 817 epochs is = 0.08813815487309483\n",
      "Initial Cost on Val dataset for this epoch 817 = 0.08813815487309483\n",
      "learning rate for this epoch =  0.09352215169020917\n",
      "Error on this batch = 0.039476007278968786\n",
      "Error on this batch = 0.068256328434132\n",
      "Cost on val dataset after 818 epochs is = 0.08811667415968136\n",
      "Initial Cost on Val dataset for this epoch 818 = 0.08811667415968136\n",
      "learning rate for this epoch =  0.09349355601290561\n",
      "Error on this batch = 0.03944778361742489\n",
      "Error on this batch = 0.068220573363992\n",
      "Cost on val dataset after 819 epochs is = 0.08809523896211963\n",
      "Initial Cost on Val dataset for this epoch 819 = 0.08809523896211963\n",
      "learning rate for this epoch =  0.09346500399980012\n",
      "Error on this batch = 0.03941961602949511\n",
      "Error on this batch = 0.06818486769704075\n",
      "Cost on val dataset after 820 epochs is = 0.08807384914574774\n",
      "Initial Cost on Val dataset for this epoch 820 = 0.08807384914574774\n",
      "learning rate for this epoch =  0.09343649553102754\n",
      "Error on this batch = 0.03939150433356216\n",
      "Error on this batch = 0.06814921120844382\n",
      "Cost on val dataset after 821 epochs is = 0.08805250457644148\n",
      "Initial Cost on Val dataset for this epoch 821 = 0.08805250457644148\n",
      "learning rate for this epoch =  0.0934080304871974\n",
      "Error on this batch = 0.0393634483484662\n",
      "Error on this batch = 0.06811360367491269\n",
      "Cost on val dataset after 822 epochs is = 0.08803120512061102\n",
      "Initial Cost on Val dataset for this epoch 822 = 0.08803120512061102\n",
      "learning rate for this epoch =  0.09337960874939158\n",
      "Error on this batch = 0.0393354478935045\n",
      "Error on this batch = 0.06807804487470377\n",
      "Cost on val dataset after 823 epochs is = 0.08800995064519783\n",
      "Initial Cost on Val dataset for this epoch 823 = 0.08800995064519783\n",
      "learning rate for this epoch =  0.09335123019916165\n",
      "Error on this batch = 0.03930750278843154\n",
      "Error on this batch = 0.06804253458761741\n",
      "Cost on val dataset after 824 epochs is = 0.0879887410176712\n",
      "Initial Cost on Val dataset for this epoch 824 = 0.0879887410176712\n",
      "learning rate for this epoch =  0.09332289471852671\n",
      "Error on this batch = 0.039279612853458976\n",
      "Error on this batch = 0.06800707259499632\n",
      "Cost on val dataset after 825 epochs is = 0.08796757610602497\n",
      "Initial Cost on Val dataset for this epoch 825 = 0.08796757610602497\n",
      "learning rate for this epoch =  0.09329460218997072\n",
      "Error on this batch = 0.039251777909256054\n",
      "Error on this batch = 0.06797165867972421\n",
      "Cost on val dataset after 826 epochs is = 0.08794645577877423\n",
      "Initial Cost on Val dataset for this epoch 826 = 0.08794645577877423\n",
      "learning rate for this epoch =  0.09326635249644033\n",
      "Error on this batch = 0.03922399777695001\n",
      "Error on this batch = 0.06793629262622412\n",
      "Cost on val dataset after 827 epochs is = 0.08792537990495194\n",
      "Initial Cost on Val dataset for this epoch 827 = 0.08792537990495194\n",
      "learning rate for this epoch =  0.09323814552134235\n",
      "Error on this batch = 0.039196272278126526\n",
      "Error on this batch = 0.06790097422045649\n",
      "Cost on val dataset after 828 epochs is = 0.0879043483541054\n",
      "Initial Cost on Val dataset for this epoch 828 = 0.0879043483541054\n",
      "learning rate for this epoch =  0.09320998114854143\n",
      "Error on this batch = 0.03916860123483055\n",
      "Error on this batch = 0.0678657032499171\n",
      "Cost on val dataset after 829 epochs is = 0.08788336099629304\n",
      "Initial Cost on Val dataset for this epoch 829 = 0.08788336099629304\n",
      "learning rate for this epoch =  0.09318185926235777\n",
      "Error on this batch = 0.03914098446956709\n",
      "Error on this batch = 0.06783047950363494\n",
      "Cost on val dataset after 830 epochs is = 0.08786241770208086\n",
      "Initial Cost on Val dataset for this epoch 830 = 0.08786241770208086\n",
      "learning rate for this epoch =  0.09315377974756468\n",
      "Error on this batch = 0.03911342180530222\n",
      "Error on this batch = 0.06779530277216983\n",
      "Cost on val dataset after 831 epochs is = 0.08784151834253917\n",
      "Initial Cost on Val dataset for this epoch 831 = 0.08784151834253917\n",
      "learning rate for this epoch =  0.09312574248938638\n",
      "Error on this batch = 0.03908591306546421\n",
      "Error on this batch = 0.06776017284760981\n",
      "Cost on val dataset after 832 epochs is = 0.08782066278923899\n",
      "Initial Cost on Val dataset for this epoch 832 = 0.08782066278923899\n",
      "learning rate for this epoch =  0.0930977473734956\n",
      "Error on this batch = 0.03905845807394478\n",
      "Error on this batch = 0.06772508952356868\n",
      "Cost on val dataset after 833 epochs is = 0.08779985091424869\n",
      "Initial Cost on Val dataset for this epoch 833 = 0.08779985091424869\n",
      "learning rate for this epoch =  0.09306979428601131\n",
      "Error on this batch = 0.03903105665510048\n",
      "Error on this batch = 0.067690052595183\n",
      "Cost on val dataset after 834 epochs is = 0.0877790825901307\n",
      "Initial Cost on Val dataset for this epoch 834 = 0.0877790825901307\n",
      "learning rate for this epoch =  0.0930418831134965\n",
      "Error on this batch = 0.039003708633754235\n",
      "Error on this batch = 0.06765506185910918\n",
      "Cost on val dataset after 835 epochs is = 0.087758357689938\n",
      "Initial Cost on Val dataset for this epoch 835 = 0.087758357689938\n",
      "learning rate for this epoch =  0.09301401374295587\n",
      "Error on this batch = 0.03897641383519706\n",
      "Error on this batch = 0.06762011711352042\n",
      "Cost on val dataset after 836 epochs is = 0.08773767608721071\n",
      "Initial Cost on Val dataset for this epoch 836 = 0.08773767608721071\n",
      "learning rate for this epoch =  0.09298618606183358\n",
      "Error on this batch = 0.0389491720851897\n",
      "Error on this batch = 0.06758521815810353\n",
      "Cost on val dataset after 837 epochs is = 0.08771703765597284\n",
      "Initial Cost on Val dataset for this epoch 837 = 0.08771703765597284\n",
      "learning rate for this epoch =  0.09295839995801103\n",
      "Error on this batch = 0.03892198320996464\n",
      "Error on this batch = 0.06755036479405549\n",
      "Cost on val dataset after 838 epochs is = 0.08769644227072881\n",
      "Initial Cost on Val dataset for this epoch 838 = 0.08769644227072881\n",
      "learning rate for this epoch =  0.09293065531980463\n",
      "Error on this batch = 0.03889484703622809\n",
      "Error on this batch = 0.06751555682408002\n",
      "Cost on val dataset after 839 epochs is = 0.0876758898064602\n",
      "Initial Cost on Val dataset for this epoch 839 = 0.0876758898064602\n",
      "learning rate for this epoch =  0.09290295203596367\n",
      "Error on this batch = 0.038867763391162116\n",
      "Error on this batch = 0.06748079405238402\n",
      "Cost on val dataset after 840 epochs is = 0.08765538013862251\n",
      "Initial Cost on Val dataset for this epoch 840 = 0.08765538013862251\n",
      "learning rate for this epoch =  0.09287528999566799\n",
      "Error on this batch = 0.038840732102426896\n",
      "Error on this batch = 0.06744607628467378\n",
      "Cost on val dataset after 841 epochs is = 0.0876349131431418\n",
      "Initial Cost on Val dataset for this epoch 841 = 0.0876349131431418\n",
      "learning rate for this epoch =  0.09284766908852593\n",
      "Error on this batch = 0.03881375299816305\n",
      "Error on this batch = 0.06741140332815135\n",
      "Cost on val dataset after 842 epochs is = 0.08761448869641149\n",
      "Initial Cost on Val dataset for this epoch 842 = 0.08761448869641149\n",
      "learning rate for this epoch =  0.09282008920457209\n",
      "Error on this batch = 0.038786825906994116\n",
      "Error on this batch = 0.0673767749915104\n",
      "Cost on val dataset after 843 epochs is = 0.08759410667528916\n",
      "Initial Cost on Val dataset for this epoch 843 = 0.08759410667528916\n",
      "learning rate for this epoch =  0.09279255023426522\n",
      "Error on this batch = 0.03875995065802916\n",
      "Error on this batch = 0.06734219108493235\n",
      "Cost on val dataset after 844 epochs is = 0.08757376695709346\n",
      "Initial Cost on Val dataset for this epoch 844 = 0.08757376695709346\n",
      "learning rate for this epoch =  0.09276505206848605\n",
      "Error on this batch = 0.03873312708086528\n",
      "Error on this batch = 0.06730765142008233\n",
      "Cost on val dataset after 845 epochs is = 0.08755346941960086\n",
      "Initial Cost on Val dataset for this epoch 845 = 0.08755346941960086\n",
      "learning rate for this epoch =  0.09273759459853521\n",
      "Error on this batch = 0.03870635500559049\n",
      "Error on this batch = 0.06727315581010476\n",
      "Cost on val dataset after 846 epochs is = 0.08753321394104278\n",
      "Initial Cost on Val dataset for this epoch 846 = 0.08753321394104278\n",
      "learning rate for this epoch =  0.0927101777161311\n",
      "Error on this batch = 0.038679634262786575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06723870406961922\n",
      "Cost on val dataset after 847 epochs is = 0.08751300040010236\n",
      "Initial Cost on Val dataset for this epoch 847 = 0.08751300040010236\n",
      "learning rate for this epoch =  0.09268280131340775\n",
      "Error on this batch = 0.03865296468353184\n",
      "Error on this batch = 0.06720429601471622\n",
      "Cost on val dataset after 848 epochs is = 0.08749282867591164\n",
      "Initial Cost on Val dataset for this epoch 848 = 0.08749282867591164\n",
      "learning rate for this epoch =  0.09265546528291284\n",
      "Error on this batch = 0.03862634609940432\n",
      "Error on this batch = 0.0671699314629524\n",
      "Cost on val dataset after 849 epochs is = 0.0874726986480486\n",
      "Initial Cost on Val dataset for this epoch 849 = 0.0874726986480486\n",
      "learning rate for this epoch =  0.09262816951760545\n",
      "Error on this batch = 0.03859977834248471\n",
      "Error on this batch = 0.06713561023334641\n",
      "Cost on val dataset after 850 epochs is = 0.08745261019653422\n",
      "Initial Cost on Val dataset for this epoch 850 = 0.08745261019653422\n",
      "learning rate for this epoch =  0.09260091391085426\n",
      "Error on this batch = 0.03857326124535952\n",
      "Error on this batch = 0.06710133214637401\n",
      "Cost on val dataset after 851 epochs is = 0.08743256320182978\n",
      "Initial Cost on Val dataset for this epoch 851 = 0.08743256320182978\n",
      "learning rate for this epoch =  0.09257369835643524\n",
      "Error on this batch = 0.038546794641124336\n",
      "Error on this batch = 0.06706709702396363\n",
      "Cost on val dataset after 852 epochs is = 0.08741255754483403\n",
      "Initial Cost on Val dataset for this epoch 852 = 0.08741255754483403\n",
      "learning rate for this epoch =  0.09254652274852981\n",
      "Error on this batch = 0.03852037836338717\n",
      "Error on this batch = 0.06703290468949157\n",
      "Cost on val dataset after 853 epochs is = 0.08739259310688055\n",
      "Initial Cost on Val dataset for this epoch 853 = 0.08739259310688055\n",
      "learning rate for this epoch =  0.0925193869817227\n",
      "Error on this batch = 0.038494012246271574\n",
      "Error on this batch = 0.06699875496777727\n",
      "Cost on val dataset after 854 epochs is = 0.08737266976973504\n",
      "Initial Cost on Val dataset for this epoch 854 = 0.08737266976973504\n",
      "learning rate for this epoch =  0.092492290951\n",
      "Error on this batch = 0.038467696124420254\n",
      "Error on this batch = 0.06696464768507852\n",
      "Cost on val dataset after 855 epochs is = 0.08735278741559288\n",
      "Initial Cost on Val dataset for this epoch 855 = 0.08735278741559288\n",
      "learning rate for this epoch =  0.09246523455174717\n",
      "Error on this batch = 0.03844142983299828\n",
      "Error on this batch = 0.06693058266908648\n",
      "Cost on val dataset after 856 epochs is = 0.08733294592707642\n",
      "Initial Cost on Val dataset for this epoch 856 = 0.08733294592707642\n",
      "learning rate for this epoch =  0.092438217679747\n",
      "Error on this batch = 0.038415213207696794\n",
      "Error on this batch = 0.06689655974892088\n",
      "Cost on val dataset after 857 epochs is = 0.08731314518723275\n",
      "Initial Cost on Val dataset for this epoch 857 = 0.08731314518723275\n",
      "learning rate for this epoch =  0.09241124023117771\n",
      "Error on this batch = 0.03838904608473629\n",
      "Error on this batch = 0.06686257875512495\n",
      "Cost on val dataset after 858 epochs is = 0.08729338507953122\n",
      "Initial Cost on Val dataset for this epoch 858 = 0.08729338507953122\n",
      "learning rate for this epoch =  0.09238430210261095\n",
      "Error on this batch = 0.038362928300870285\n",
      "Error on this batch = 0.06682863951966056\n",
      "Cost on val dataset after 859 epochs is = 0.08727366548786109\n",
      "Initial Cost on Val dataset for this epoch 859 = 0.08727366548786109\n",
      "learning rate for this epoch =  0.09235740319100984\n",
      "Error on this batch = 0.03833685969338899\n",
      "Error on this batch = 0.06679474187590308\n",
      "Cost on val dataset after 860 epochs is = 0.08725398629652933\n",
      "Initial Cost on Val dataset for this epoch 860 = 0.08725398629652933\n",
      "learning rate for this epoch =  0.09233054339372707\n",
      "Error on this batch = 0.0383108401001226\n",
      "Error on this batch = 0.06676088565863626\n",
      "Cost on val dataset after 861 epochs is = 0.08723434739025847\n",
      "Initial Cost on Val dataset for this epoch 861 = 0.08723434739025847\n",
      "learning rate for this epoch =  0.09230372260850297\n",
      "Error on this batch = 0.03828486935944519\n",
      "Error on this batch = 0.06672707070404732\n",
      "Cost on val dataset after 862 epochs is = 0.08721474865418449\n",
      "Initial Cost on Val dataset for this epoch 862 = 0.08721474865418449\n",
      "learning rate for this epoch =  0.09227694073346356\n",
      "Error on this batch = 0.03825894731027817\n",
      "Error on this batch = 0.06669329684972156\n",
      "Cost on val dataset after 863 epochs is = 0.08719518997385474\n",
      "Initial Cost on Val dataset for this epoch 863 = 0.08719518997385474\n",
      "learning rate for this epoch =  0.09225019766711869\n",
      "Error on this batch = 0.03823307379209405\n",
      "Error on this batch = 0.06665956393463736\n",
      "Cost on val dataset after 864 epochs is = 0.08717567123522593\n",
      "Initial Cost on Val dataset for this epoch 864 = 0.08717567123522593\n",
      "learning rate for this epoch =  0.09222349330836013\n",
      "Error on this batch = 0.038207248644919874\n",
      "Error on this batch = 0.066625871799161\n",
      "Cost on val dataset after 865 epochs is = 0.08715619232466244\n",
      "Initial Cost on Val dataset for this epoch 865 = 0.08715619232466244\n",
      "learning rate for this epoch =  0.09219682755645973\n",
      "Error on this batch = 0.03818147170934104\n",
      "Error on this batch = 0.06659222028504135\n",
      "Cost on val dataset after 866 epochs is = 0.08713675312893422\n",
      "Initial Cost on Val dataset for this epoch 866 = 0.08713675312893422\n",
      "learning rate for this epoch =  0.09217020031106751\n",
      "Error on this batch = 0.03815574282650482\n",
      "Error on this batch = 0.06655860923540476\n",
      "Cost on val dataset after 867 epochs is = 0.08711735353521519\n",
      "Initial Cost on Val dataset for this epoch 867 = 0.08711735353521519\n",
      "learning rate for this epoch =  0.09214361147220981\n",
      "Error on this batch = 0.03813006183812395\n",
      "Error on this batch = 0.06652503849474962\n",
      "Cost on val dataset after 868 epochs is = 0.08709799343108154\n",
      "Initial Cost on Val dataset for this epoch 868 = 0.08709799343108154\n",
      "learning rate for this epoch =  0.09211706094028746\n",
      "Error on this batch = 0.03810442858648034\n",
      "Error on this batch = 0.06649150790894137\n",
      "Cost on val dataset after 869 epochs is = 0.08707867270451011\n",
      "Initial Cost on Val dataset for this epoch 869 = 0.08707867270451011\n",
      "learning rate for this epoch =  0.09209054861607395\n",
      "Error on this batch = 0.03807884291442841\n",
      "Error on this batch = 0.06645801732520697\n",
      "Cost on val dataset after 870 epochs is = 0.0870593912438768\n",
      "Initial Cost on Val dataset for this epoch 870 = 0.0870593912438768\n",
      "learning rate for this epoch =  0.0920640744007136\n",
      "Error on this batch = 0.03805330466539886\n",
      "Error on this batch = 0.06642456659212978\n",
      "Cost on val dataset after 871 epochs is = 0.08704014893795506\n",
      "Initial Cost on Val dataset for this epoch 871 = 0.08704014893795506\n",
      "learning rate for this epoch =  0.09203763819571976\n",
      "Error on this batch = 0.03802781368340197\n",
      "Error on this batch = 0.06639115555964412\n",
      "Cost on val dataset after 872 epochs is = 0.08702094567591466\n",
      "Initial Cost on Val dataset for this epoch 872 = 0.08702094567591466\n",
      "learning rate for this epoch =  0.09201123990297302\n",
      "Error on this batch = 0.03800236981303125\n",
      "Error on this batch = 0.06635778407903006\n",
      "Cost on val dataset after 873 epochs is = 0.0870017813473201\n",
      "Initial Cost on Val dataset for this epoch 873 = 0.0870017813473201\n",
      "learning rate for this epoch =  0.09198487942471935\n",
      "Error on this batch = 0.03797697289946667\n",
      "Error on this batch = 0.06632445200290807\n",
      "Cost on val dataset after 874 epochs is = 0.0869826558421295\n",
      "Initial Cost on Val dataset for this epoch 874 = 0.0869826558421295\n",
      "learning rate for this epoch =  0.09195855666356846\n",
      "Error on this batch = 0.03795162278847816\n",
      "Error on this batch = 0.06629115918523372\n",
      "Cost on val dataset after 875 epochs is = 0.08696356905069343\n",
      "Initial Cost on Val dataset for this epoch 875 = 0.08696356905069343\n",
      "learning rate for this epoch =  0.09193227152249185\n",
      "Error on this batch = 0.037926319326428856\n",
      "Error on this batch = 0.06625790548129225\n",
      "Cost on val dataset after 876 epochs is = 0.0869445208637535\n",
      "Initial Cost on Val dataset for this epoch 876 = 0.0869445208637535\n",
      "learning rate for this epoch =  0.09190602390482124\n",
      "Error on this batch = 0.037901062360278355\n",
      "Error on this batch = 0.0662246907476933\n",
      "Cost on val dataset after 877 epochs is = 0.08692551117244164\n",
      "Initial Cost on Val dataset for this epoch 877 = 0.08692551117244164\n",
      "learning rate for this epoch =  0.09187981371424671\n",
      "Error on this batch = 0.03787585173758593\n",
      "Error on this batch = 0.06619151484236561\n",
      "Cost on val dataset after 878 epochs is = 0.08690653986827883\n",
      "Initial Cost on Val dataset for this epoch 878 = 0.08690653986827883\n",
      "learning rate for this epoch =  0.091853640854815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.03785068730651366\n",
      "Error on this batch = 0.06615837762455161\n",
      "Cost on val dataset after 879 epochs is = 0.08688760684317419\n",
      "Initial Cost on Val dataset for this epoch 879 = 0.08688760684317419\n",
      "learning rate for this epoch =  0.09182750523092773\n",
      "Error on this batch = 0.03782556891582947\n",
      "Error on this batch = 0.06612527895480211\n",
      "Cost on val dataset after 880 epochs is = 0.08686871198942425\n",
      "Initial Cost on Val dataset for this epoch 880 = 0.08686871198942425\n",
      "learning rate for this epoch =  0.0918014067473398\n",
      "Error on this batch = 0.037800496414910026\n",
      "Error on this batch = 0.06609221869497085\n",
      "Cost on val dataset after 881 epochs is = 0.08684985519971189\n",
      "Initial Cost on Val dataset for this epoch 881 = 0.08684985519971189\n",
      "learning rate for this epoch =  0.09177534530915758\n",
      "Error on this batch = 0.037775469653743746\n",
      "Error on this batch = 0.06605919670820934\n",
      "Cost on val dataset after 882 epochs is = 0.08683103636710578\n",
      "Initial Cost on Val dataset for this epoch 882 = 0.08683103636710578\n",
      "learning rate for this epoch =  0.09174932082183727\n",
      "Error on this batch = 0.0377504884829335\n",
      "Error on this batch = 0.0660262128589613\n",
      "Cost on val dataset after 883 epochs is = 0.08681225538505946\n",
      "Initial Cost on Val dataset for this epoch 883 = 0.08681225538505946\n",
      "learning rate for this epoch =  0.09172333319118318\n",
      "Error on this batch = 0.037725552753699425\n",
      "Error on this batch = 0.06599326701295746\n",
      "Cost on val dataset after 884 epochs is = 0.08679351214741086\n",
      "Initial Cost on Val dataset for this epoch 884 = 0.08679351214741086\n",
      "learning rate for this epoch =  0.0916973823233461\n",
      "Error on this batch = 0.03770066231788144\n",
      "Error on this batch = 0.06596035903721019\n",
      "Cost on val dataset after 885 epochs is = 0.08677480654838164\n",
      "Initial Cost on Val dataset for this epoch 885 = 0.08677480654838164\n",
      "learning rate for this epoch =  0.09167146812482159\n",
      "Error on this batch = 0.037675817027941816\n",
      "Error on this batch = 0.06592748880000804\n",
      "Cost on val dataset after 886 epochs is = 0.08675613848257663\n",
      "Initial Cost on Val dataset for this epoch 886 = 0.08675613848257663\n",
      "learning rate for this epoch =  0.09164559050244833\n",
      "Error on this batch = 0.037651016736967614\n",
      "Error on this batch = 0.06589465617091046\n",
      "Cost on val dataset after 887 epochs is = 0.08673750784498334\n",
      "Initial Cost on Val dataset for this epoch 887 = 0.08673750784498334\n",
      "learning rate for this epoch =  0.09161974936340654\n",
      "Error on this batch = 0.0376262612986729\n",
      "Error on this batch = 0.06586186102074257\n",
      "Cost on val dataset after 888 epochs is = 0.08671891453097151\n",
      "Initial Cost on Val dataset for this epoch 888 = 0.08671891453097151\n",
      "learning rate for this epoch =  0.09159394461521626\n",
      "Error on this batch = 0.03760155056740105\n",
      "Error on this batch = 0.06582910322158965\n",
      "Cost on val dataset after 889 epochs is = 0.08670035843629277\n",
      "Initial Cost on Val dataset for this epoch 889 = 0.08670035843629277\n",
      "learning rate for this epoch =  0.09156817616573577\n",
      "Error on this batch = 0.037576884398126786\n",
      "Error on this batch = 0.06579638264679176\n",
      "Cost on val dataset after 890 epochs is = 0.0866818394570802\n",
      "Initial Cost on Val dataset for this epoch 890 = 0.0866818394570802\n",
      "learning rate for this epoch =  0.09154244392315995\n",
      "Error on this batch = 0.037552262646458154\n",
      "Error on this batch = 0.06576369917093862\n",
      "Cost on val dataset after 891 epochs is = 0.08666335748984816\n",
      "Initial Cost on Val dataset for this epoch 891 = 0.08666335748984816\n",
      "learning rate for this epoch =  0.09151674779601875\n",
      "Error on this batch = 0.03752768516863832\n",
      "Error on this batch = 0.06573105266986401\n",
      "Cost on val dataset after 892 epochs is = 0.08664491243149183\n",
      "Initial Cost on Val dataset for this epoch 892 = 0.08664491243149183\n",
      "learning rate for this epoch =  0.0914910876931754\n",
      "Error on this batch = 0.03750315182154735\n",
      "Error on this batch = 0.0656984430206406\n",
      "Cost on val dataset after 893 epochs is = 0.08662650417928729\n",
      "Initial Cost on Val dataset for this epoch 893 = 0.08662650417928729\n",
      "learning rate for this epoch =  0.09146546352382512\n",
      "Error on this batch = 0.03747866246270374\n",
      "Error on this batch = 0.0656658701015745\n",
      "Cost on val dataset after 894 epochs is = 0.08660813263089102\n",
      "Initial Cost on Val dataset for this epoch 894 = 0.08660813263089102\n",
      "learning rate for this epoch =  0.09143987519749323\n",
      "Error on this batch = 0.037454216950265976\n",
      "Error on this batch = 0.06563333379219999\n",
      "Cost on val dataset after 895 epochs is = 0.08658979768434004\n",
      "Initial Cost on Val dataset for this epoch 895 = 0.08658979768434004\n",
      "learning rate for this epoch =  0.09141432262403383\n",
      "Error on this batch = 0.03742981514303376\n",
      "Error on this batch = 0.06560083397327414\n",
      "Cost on val dataset after 896 epochs is = 0.08657149923805167\n",
      "Initial Cost on Val dataset for this epoch 896 = 0.08657149923805167\n",
      "learning rate for this epoch =  0.09138880571362809\n",
      "Error on this batch = 0.0374054569004492\n",
      "Error on this batch = 0.06556837052677147\n",
      "Cost on val dataset after 897 epochs is = 0.08655323719082347\n",
      "Initial Cost on Val dataset for this epoch 897 = 0.08655323719082347\n",
      "learning rate for this epoch =  0.09136332437678274\n",
      "Error on this batch = 0.03738114208259794\n",
      "Error on this batch = 0.06553594333587866\n",
      "Cost on val dataset after 898 epochs is = 0.08653501144183329\n",
      "Initial Cost on Val dataset for this epoch 898 = 0.08653501144183329\n",
      "learning rate for this epoch =  0.09133787852432855\n",
      "Error on this batch = 0.03735687055020997\n",
      "Error on this batch = 0.06550355228498903\n",
      "Cost on val dataset after 899 epochs is = 0.08651682189063921\n",
      "Initial Cost on Val dataset for this epoch 899 = 0.08651682189063921\n",
      "learning rate for this epoch =  0.09131246806741879\n",
      "Error on this batch = 0.03733264216466047\n",
      "Error on this batch = 0.06547119725969738\n",
      "Cost on val dataset after 900 epochs is = 0.08649866843717956\n",
      "Initial Cost on Val dataset for this epoch 900 = 0.08649866843717956\n",
      "learning rate for this epoch =  0.09128709291752768\n",
      "Error on this batch = 0.03730845678797042\n",
      "Error on this batch = 0.06543887814679458\n",
      "Cost on val dataset after 901 epochs is = 0.08648055098177311\n",
      "Initial Cost on Val dataset for this epoch 901 = 0.08648055098177311\n",
      "learning rate for this epoch =  0.09126175298644894\n",
      "Error on this batch = 0.03728431428280696\n",
      "Error on this batch = 0.06540659483426219\n",
      "Cost on val dataset after 902 epochs is = 0.08646246942511901\n",
      "Initial Cost on Val dataset for this epoch 902 = 0.08646246942511901\n",
      "learning rate for this epoch =  0.09123644818629414\n",
      "Error on this batch = 0.037260214512483854\n",
      "Error on this batch = 0.06537434721126703\n",
      "Cost on val dataset after 903 epochs is = 0.086444423668297\n",
      "Initial Cost on Val dataset for this epoch 903 = 0.086444423668297\n",
      "learning rate for this epoch =  0.09121117842949143\n",
      "Error on this batch = 0.03723615734096155\n",
      "Error on this batch = 0.06534213516815605\n",
      "Cost on val dataset after 904 epochs is = 0.08642641361276747\n",
      "Initial Cost on Val dataset for this epoch 904 = 0.08642641361276747\n",
      "learning rate for this epoch =  0.09118594362878382\n",
      "Error on this batch = 0.03721214263284728\n",
      "Error on this batch = 0.06530995859645071\n",
      "Cost on val dataset after 905 epochs is = 0.08640843916037175\n",
      "Initial Cost on Val dataset for this epoch 905 = 0.08640843916037175\n",
      "learning rate for this epoch =  0.09116074369722786\n",
      "Error on this batch = 0.0371881702533948\n",
      "Error on this batch = 0.06527781738884171\n",
      "Cost on val dataset after 906 epochs is = 0.08639050021333222\n",
      "Initial Cost on Val dataset for this epoch 906 = 0.08639050021333222\n",
      "learning rate for this epoch =  0.09113557854819211\n",
      "Error on this batch = 0.03716424006850417\n",
      "Error on this batch = 0.06524571143918365\n",
      "Cost on val dataset after 907 epochs is = 0.0863725966742524\n",
      "Initial Cost on Val dataset for this epoch 907 = 0.0863725966742524\n",
      "learning rate for this epoch =  0.09111044809535562\n",
      "Error on this batch = 0.03714035194472132\n",
      "Error on this batch = 0.06521364064248956\n",
      "Cost on val dataset after 908 epochs is = 0.08635472844611744\n",
      "Initial Cost on Val dataset for this epoch 908 = 0.08635472844611744\n",
      "learning rate for this epoch =  0.09108535225270664\n",
      "Error on this batch = 0.037116505749237326\n",
      "Error on this batch = 0.06518160489492558\n",
      "Cost on val dataset after 909 epochs is = 0.08633689543229402\n",
      "Initial Cost on Val dataset for this epoch 909 = 0.08633689543229402\n",
      "learning rate for this epoch =  0.09106029093454096\n",
      "Error on this batch = 0.037092701349887694\n",
      "Error on this batch = 0.06514960409380552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 910 epochs is = 0.08631909753653096\n",
      "Initial Cost on Val dataset for this epoch 910 = 0.08631909753653096\n",
      "learning rate for this epoch =  0.09103526405546067\n",
      "Error on this batch = 0.03706893861515147\n",
      "Error on this batch = 0.0651176381375854\n",
      "Cost on val dataset after 911 epochs is = 0.0863013346629591\n",
      "Initial Cost on Val dataset for this epoch 911 = 0.0863013346629591\n",
      "learning rate for this epoch =  0.09101027153037257\n",
      "Error on this batch = 0.03704521741415007\n",
      "Error on this batch = 0.06508570692585816\n",
      "Cost on val dataset after 912 epochs is = 0.08628360671609187\n",
      "Initial Cost on Val dataset for this epoch 912 = 0.08628360671609187\n",
      "learning rate for this epoch =  0.09098531327448692\n",
      "Error on this batch = 0.03702153761664605\n",
      "Error on this batch = 0.06505381035934807\n",
      "Cost on val dataset after 913 epochs is = 0.08626591360082544\n",
      "Initial Cost on Val dataset for this epoch 913 = 0.08626591360082544\n",
      "learning rate for this epoch =  0.09096038920331581\n",
      "Error on this batch = 0.03699789909304165\n",
      "Error on this batch = 0.06502194833990534\n",
      "Cost on val dataset after 914 epochs is = 0.08624825522243905\n",
      "Initial Cost on Val dataset for this epoch 914 = 0.08624825522243905\n",
      "learning rate for this epoch =  0.09093549923267195\n",
      "Error on this batch = 0.03697430171437728\n",
      "Error on this batch = 0.06499012077050077\n",
      "Cost on val dataset after 915 epochs is = 0.08623063148659514\n",
      "Initial Cost on Val dataset for this epoch 915 = 0.08623063148659514\n",
      "learning rate for this epoch =  0.0909106432786672\n",
      "Error on this batch = 0.03695074535232971\n",
      "Error on this batch = 0.06495832755522012\n",
      "Cost on val dataset after 916 epochs is = 0.08621304229933996\n",
      "Initial Cost on Val dataset for this epoch 916 = 0.08621304229933996\n",
      "learning rate for this epoch =  0.09088582125771116\n",
      "Error on this batch = 0.03692722987921024\n",
      "Error on this batch = 0.06492656859925862\n",
      "Cost on val dataset after 917 epochs is = 0.08619548756710359\n",
      "Initial Cost on Val dataset for this epoch 917 = 0.08619548756710359\n",
      "learning rate for this epoch =  0.09086103308650982\n",
      "Error on this batch = 0.03690375516796255\n",
      "Error on this batch = 0.06489484380891565\n",
      "Cost on val dataset after 918 epochs is = 0.08617796719670036\n",
      "Initial Cost on Val dataset for this epoch 918 = 0.08617796719670036\n",
      "learning rate for this epoch =  0.09083627868206413\n",
      "Error on this batch = 0.03688032109216054\n",
      "Error on this batch = 0.06486315309158894\n",
      "Cost on val dataset after 919 epochs is = 0.08616048109532916\n",
      "Initial Cost on Val dataset for this epoch 919 = 0.08616048109532916\n",
      "learning rate for this epoch =  0.09081155796166877\n",
      "Error on this batch = 0.0368569275260059\n",
      "Error on this batch = 0.0648314963557693\n",
      "Cost on val dataset after 920 epochs is = 0.08614302917057366\n",
      "Initial Cost on Val dataset for this epoch 920 = 0.08614302917057366\n",
      "learning rate for this epoch =  0.09078687084291064\n",
      "Error on this batch = 0.036833574344325694\n",
      "Error on this batch = 0.06479987351103489\n",
      "Cost on val dataset after 921 epochs is = 0.0861256113304027\n",
      "Initial Cost on Val dataset for this epoch 921 = 0.0861256113304027\n",
      "learning rate for this epoch =  0.09076221724366758\n",
      "Error on this batch = 0.03681026142256948\n",
      "Error on this batch = 0.06476828446804567\n",
      "Cost on val dataset after 922 epochs is = 0.0861082274831706\n",
      "Initial Cost on Val dataset for this epoch 922 = 0.0861082274831706\n",
      "learning rate for this epoch =  0.09073759708210706\n",
      "Error on this batch = 0.03678698863680664\n",
      "Error on this batch = 0.06473672913853783\n",
      "Cost on val dataset after 923 epochs is = 0.0860908775376173\n",
      "Initial Cost on Val dataset for this epoch 923 = 0.0860908775376173\n",
      "learning rate for this epoch =  0.09071301027668477\n",
      "Error on this batch = 0.03676375586372327\n",
      "Error on this batch = 0.06470520743531813\n",
      "Cost on val dataset after 924 epochs is = 0.08607356140286881\n",
      "Initial Cost on Val dataset for this epoch 924 = 0.08607356140286881\n",
      "learning rate for this epoch =  0.09068845674614334\n",
      "Error on this batch = 0.0367405629806191\n",
      "Error on this batch = 0.06467371927225829\n",
      "Cost on val dataset after 925 epochs is = 0.08605627898843744\n",
      "Initial Cost on Val dataset for this epoch 925 = 0.08605627898843744\n",
      "learning rate for this epoch =  0.09066393640951106\n",
      "Error on this batch = 0.036717409865404095\n",
      "Error on this batch = 0.06464226456428925\n",
      "Cost on val dataset after 926 epochs is = 0.08603903020422202\n",
      "Initial Cost on Val dataset for this epoch 926 = 0.08603903020422202\n",
      "learning rate for this epoch =  0.09063944918610045\n",
      "Error on this batch = 0.03669429639659513\n",
      "Error on this batch = 0.06461084322739549\n",
      "Cost on val dataset after 927 epochs is = 0.08602181496050817\n",
      "Initial Cost on Val dataset for this epoch 927 = 0.08602181496050817\n",
      "learning rate for this epoch =  0.0906149949955071\n",
      "Error on this batch = 0.036671222453312356\n",
      "Error on this batch = 0.06457945517860933\n",
      "Cost on val dataset after 928 epochs is = 0.08600463316796873\n",
      "Initial Cost on Val dataset for this epoch 928 = 0.08600463316796873\n",
      "learning rate for this epoch =  0.09059057375760825\n",
      "Error on this batch = 0.0366481879152754\n",
      "Error on this batch = 0.06454810033600519\n",
      "Cost on val dataset after 929 epochs is = 0.08598748473766368\n",
      "Initial Cost on Val dataset for this epoch 929 = 0.08598748473766368\n",
      "learning rate for this epoch =  0.09056618539256157\n",
      "Error on this batch = 0.03662519266279962\n",
      "Error on this batch = 0.06451677861869363\n",
      "Cost on val dataset after 930 epochs is = 0.08597036958104065\n",
      "Initial Cost on Val dataset for this epoch 930 = 0.08597036958104065\n",
      "learning rate for this epoch =  0.09054182982080389\n",
      "Error on this batch = 0.036602236576791944\n",
      "Error on this batch = 0.06448548994681576\n",
      "Cost on val dataset after 931 epochs is = 0.085953287609935\n",
      "Initial Cost on Val dataset for this epoch 931 = 0.085953287609935\n",
      "learning rate for this epoch =  0.09051750696304985\n",
      "Error on this batch = 0.03657931953874693\n",
      "Error on this batch = 0.0644542342415372\n",
      "Cost on val dataset after 932 epochs is = 0.08593623873657003\n",
      "Initial Cost on Val dataset for this epoch 932 = 0.08593623873657003\n",
      "learning rate for this epoch =  0.0904932167402907\n",
      "Error on this batch = 0.03655644143074222\n",
      "Error on this batch = 0.06442301142504228\n",
      "Cost on val dataset after 933 epochs is = 0.08591922287355722\n",
      "Initial Cost on Val dataset for this epoch 933 = 0.08591922287355722\n",
      "learning rate for this epoch =  0.09046895907379304\n",
      "Error on this batch = 0.036533602135434495\n",
      "Error on this batch = 0.06439182142052802\n",
      "Cost on val dataset after 934 epochs is = 0.08590223993389638\n",
      "Initial Cost on Val dataset for this epoch 934 = 0.08590223993389638\n",
      "learning rate for this epoch =  0.09044473388509751\n",
      "Error on this batch = 0.03651080153605456\n",
      "Error on this batch = 0.0643606641521982\n",
      "Cost on val dataset after 935 epochs is = 0.08588528983097579\n",
      "Initial Cost on Val dataset for this epoch 935 = 0.08588528983097579\n",
      "learning rate for this epoch =  0.0904205410960176\n",
      "Error on this batch = 0.03648803951640305\n",
      "Error on this batch = 0.06432953954525743\n",
      "Cost on val dataset after 936 epochs is = 0.08586837247857237\n",
      "Initial Cost on Val dataset for this epoch 936 = 0.08586837247857237\n",
      "learning rate for this epoch =  0.09039638062863838\n",
      "Error on this batch = 0.036465315960845436\n",
      "Error on this batch = 0.06429844752590494\n",
      "Cost on val dataset after 937 epochs is = 0.08585148779085178\n",
      "Initial Cost on Val dataset for this epoch 937 = 0.08585148779085178\n",
      "learning rate for this epoch =  0.09037225240531528\n",
      "Error on this batch = 0.03644263075430727\n",
      "Error on this batch = 0.06426738802132856\n",
      "Cost on val dataset after 938 epochs is = 0.08583463568236856\n",
      "Initial Cost on Val dataset for this epoch 938 = 0.08583463568236856\n",
      "learning rate for this epoch =  0.09034815634867288\n",
      "Error on this batch = 0.03641998378226922\n",
      "Error on this batch = 0.06423636095969852\n",
      "Cost on val dataset after 939 epochs is = 0.08581781606806613\n",
      "Initial Cost on Val dataset for this epoch 939 = 0.08581781606806613\n",
      "learning rate for this epoch =  0.09032409238160365\n",
      "Error on this batch = 0.03639737493076189\n",
      "Error on this batch = 0.06420536627016137\n",
      "Cost on val dataset after 940 epochs is = 0.08580102886327699\n",
      "Initial Cost on Val dataset for this epoch 940 = 0.08580102886327699\n",
      "learning rate for this epoch =  0.09030006042726675\n",
      "Error on this batch = 0.03637480408636073\n",
      "Error on this batch = 0.06417440388283355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 941 epochs is = 0.08578427398372264\n",
      "Initial Cost on Val dataset for this epoch 941 = 0.08578427398372264\n",
      "learning rate for this epoch =  0.0902760604090869\n",
      "Error on this batch = 0.03635227113618075\n",
      "Error on this batch = 0.06414347372879518\n",
      "Cost on val dataset after 942 epochs is = 0.08576755134551367\n",
      "Initial Cost on Val dataset for this epoch 942 = 0.08576755134551367\n",
      "learning rate for this epoch =  0.09025209225075301\n",
      "Error on this batch = 0.0363297759678711\n",
      "Error on this batch = 0.06411257574008372\n",
      "Cost on val dataset after 943 epochs is = 0.08575086086514978\n",
      "Initial Cost on Val dataset for this epoch 943 = 0.08575086086514978\n",
      "learning rate for this epoch =  0.09022815587621721\n",
      "Error on this batch = 0.03630731846960971\n",
      "Error on this batch = 0.06408170984968753\n",
      "Cost on val dataset after 944 epochs is = 0.08573420245951975\n",
      "Initial Cost on Val dataset for this epoch 944 = 0.08573420245951975\n",
      "learning rate for this epoch =  0.0902042512096935\n",
      "Error on this batch = 0.03628489853009769\n",
      "Error on this batch = 0.0640508759915394\n",
      "Cost on val dataset after 945 epochs is = 0.08571757604590133\n",
      "Initial Cost on Val dataset for this epoch 945 = 0.08571757604590133\n",
      "learning rate for this epoch =  0.09018037817565662\n",
      "Error on this batch = 0.0362625160385538\n",
      "Error on this batch = 0.06402007410050994\n",
      "Cost on val dataset after 946 epochs is = 0.08570098154196129\n",
      "Initial Cost on Val dataset for this epoch 946 = 0.08570098154196129\n",
      "learning rate for this epoch =  0.09015653669884087\n",
      "Error on this batch = 0.03624017088470866\n",
      "Error on this batch = 0.06398930411240109\n",
      "Cost on val dataset after 947 epochs is = 0.08568441886575526\n",
      "Initial Cost on Val dataset for this epoch 947 = 0.08568441886575526\n",
      "learning rate for this epoch =  0.09013272670423898\n",
      "Error on this batch = 0.03621786295879921\n",
      "Error on this batch = 0.0639585659639393\n",
      "Cost on val dataset after 948 epochs is = 0.08566788793572762\n",
      "Initial Cost on Val dataset for this epoch 948 = 0.08566788793572762\n",
      "learning rate for this epoch =  0.09010894811710093\n",
      "Error on this batch = 0.03619559215156273\n",
      "Error on this batch = 0.06392785959276898\n",
      "Cost on val dataset after 949 epochs is = 0.08565138867071144\n",
      "Initial Cost on Val dataset for this epoch 949 = 0.08565138867071144\n",
      "learning rate for this epoch =  0.09008520086293277\n",
      "Error on this batch = 0.03617335835423109\n",
      "Error on this batch = 0.06389718493744552\n",
      "Cost on val dataset after 950 epochs is = 0.0856349209899282\n",
      "Initial Cost on Val dataset for this epoch 950 = 0.0856349209899282\n",
      "learning rate for this epoch =  0.09006148486749553\n",
      "Error on this batch = 0.036151161458524844\n",
      "Error on this batch = 0.06386654193742843\n",
      "Cost on val dataset after 951 epochs is = 0.0856184848129877\n",
      "Initial Cost on Val dataset for this epoch 951 = 0.0856184848129877\n",
      "learning rate for this epoch =  0.09003780005680402\n",
      "Error on this batch = 0.03612900135664734\n",
      "Error on this batch = 0.06383593053307436\n",
      "Cost on val dataset after 952 epochs is = 0.08560208005988783\n",
      "Initial Cost on Val dataset for this epoch 952 = 0.08560208005988783\n",
      "learning rate for this epoch =  0.09001414635712576\n",
      "Error on this batch = 0.03610687794127874\n",
      "Error on this batch = 0.06380535066563017\n",
      "Cost on val dataset after 953 epochs is = 0.08558570665101431\n",
      "Initial Cost on Val dataset for this epoch 953 = 0.08558570665101431\n",
      "learning rate for this epoch =  0.08999052369497976\n",
      "Error on this batch = 0.03608479110556994\n",
      "Error on this batch = 0.0637748022772256\n",
      "Cost on val dataset after 954 epochs is = 0.08556936450714044\n",
      "Initial Cost on Val dataset for this epoch 954 = 0.08556936450714044\n",
      "learning rate for this epoch =  0.08996693199713549\n",
      "Error on this batch = 0.036062740743136784\n",
      "Error on this batch = 0.0637442853108662\n",
      "Cost on val dataset after 955 epochs is = 0.0855530535494268\n",
      "Initial Cost on Val dataset for this epoch 955 = 0.0855530535494268\n",
      "learning rate for this epoch =  0.08994337119061177\n",
      "Error on this batch = 0.0360407267480538\n",
      "Error on this batch = 0.06371379971042596\n",
      "Cost on val dataset after 956 epochs is = 0.0855367736994209\n",
      "Initial Cost on Val dataset for this epoch 956 = 0.0855367736994209\n",
      "learning rate for this epoch =  0.08991984120267553\n",
      "Error on this batch = 0.036018749014848306\n",
      "Error on this batch = 0.06368334542063978\n",
      "Cost on val dataset after 957 epochs is = 0.08552052487905693\n",
      "Initial Cost on Val dataset for this epoch 957 = 0.08552052487905693\n",
      "learning rate for this epoch =  0.08989634196084093\n",
      "Error on this batch = 0.03599680743849441\n",
      "Error on this batch = 0.06365292238709619\n",
      "Cost on val dataset after 958 epochs is = 0.08550430701065527\n",
      "Initial Cost on Val dataset for this epoch 958 = 0.08550430701065527\n",
      "learning rate for this epoch =  0.089872873392868\n",
      "Error on this batch = 0.03597490191440686\n",
      "Error on this batch = 0.06362253055622959\n",
      "Cost on val dataset after 959 epochs is = 0.08548812001692212\n",
      "Initial Cost on Val dataset for this epoch 959 = 0.08548812001692212\n",
      "learning rate for this epoch =  0.08984943542676176\n",
      "Error on this batch = 0.035953032338435185\n",
      "Error on this batch = 0.06359216987531259\n",
      "Cost on val dataset after 960 epochs is = 0.08547196382094908\n",
      "Initial Cost on Val dataset for this epoch 960 = 0.08547196382094908\n",
      "learning rate for this epoch =  0.08982602799077107\n",
      "Error on this batch = 0.03593119860685752\n",
      "Error on this batch = 0.06356184029244809\n",
      "Cost on val dataset after 961 epochs is = 0.08545583834621268\n",
      "Initial Cost on Val dataset for this epoch 961 = 0.08545583834621268\n",
      "learning rate for this epoch =  0.08980265101338746\n",
      "Error on this batch = 0.035909400616374876\n",
      "Error on this batch = 0.06353154175656153\n",
      "Cost on val dataset after 962 epochs is = 0.08543974351657385\n",
      "Initial Cost on Val dataset for this epoch 962 = 0.08543974351657385\n",
      "learning rate for this epoch =  0.0897793044233442\n",
      "Error on this batch = 0.03588763826410506\n",
      "Error on this batch = 0.06350127421739264\n",
      "Cost on val dataset after 963 epochs is = 0.0854236792562774\n",
      "Initial Cost on Val dataset for this epoch 963 = 0.0854236792562774\n",
      "learning rate for this epoch =  0.0897559881496152\n",
      "Error on this batch = 0.0358659114475768\n",
      "Error on this batch = 0.06347103762548752\n",
      "Cost on val dataset after 964 epochs is = 0.0854076454899515\n",
      "Initial Cost on Val dataset for this epoch 964 = 0.0854076454899515\n",
      "learning rate for this epoch =  0.08973270212141383\n",
      "Error on this batch = 0.03584422006472395\n",
      "Error on this batch = 0.06344083193219006\n",
      "Cost on val dataset after 965 epochs is = 0.08539164214260699\n",
      "Initial Cost on Val dataset for this epoch 965 = 0.08539164214260699\n",
      "learning rate for this epoch =  0.08970944626819201\n",
      "Error on this batch = 0.035822564013879746\n",
      "Error on this batch = 0.06341065708963384\n",
      "Cost on val dataset after 966 epochs is = 0.0853756691396368\n",
      "Initial Cost on Val dataset for this epoch 966 = 0.0853756691396368\n",
      "learning rate for this epoch =  0.0896862205196391\n",
      "Error on this batch = 0.03580094319377103\n",
      "Error on this batch = 0.06338051305073328\n",
      "Cost on val dataset after 967 epochs is = 0.08535972640681533\n",
      "Initial Cost on Val dataset for this epoch 967 = 0.08535972640681533\n",
      "learning rate for this epoch =  0.08966302480568086\n",
      "Error on this batch = 0.035779357503512584\n",
      "Error on this batch = 0.06335039976917521\n",
      "Cost on val dataset after 968 epochs is = 0.08534381387029764\n",
      "Initial Cost on Val dataset for this epoch 968 = 0.08534381387029764\n",
      "learning rate for this epoch =  0.08963985905647841\n",
      "Error on this batch = 0.035757806842601714\n",
      "Error on this batch = 0.06332031719941\n",
      "Cost on val dataset after 969 epochs is = 0.08532793145661882\n",
      "Initial Cost on Val dataset for this epoch 969 = 0.08532793145661882\n",
      "learning rate for this epoch =  0.08961672320242715\n",
      "Error on this batch = 0.03573629111091261\n",
      "Error on this batch = 0.06329026529664253\n",
      "Cost on val dataset after 970 epochs is = 0.0853120790926931\n",
      "Initial Cost on Val dataset for this epoch 970 = 0.0853120790926931\n",
      "learning rate for this epoch =  0.08959361717415586\n",
      "Error on this batch = 0.035714810208691085\n",
      "Error on this batch = 0.06326024401682317\n",
      "Cost on val dataset after 971 epochs is = 0.08529625670581314\n",
      "Initial Cost on Val dataset for this epoch 971 = 0.08529625670581314\n",
      "learning rate for this epoch =  0.08957054090252553\n",
      "Error on this batch = 0.03569336403654923\n",
      "Error on this batch = 0.06323025331663856\n",
      "Cost on val dataset after 972 epochs is = 0.08528046422364917\n",
      "Initial Cost on Val dataset for this epoch 972 = 0.08528046422364917\n",
      "learning rate for this epoch =  0.08954749431862849\n",
      "Error on this batch = 0.0356719524954603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.0632002931535022\n",
      "Cost on val dataset after 973 epochs is = 0.08526470157424802\n",
      "Initial Cost on Val dataset for this epoch 973 = 0.08526470157424802\n",
      "learning rate for this epoch =  0.08952447735378725\n",
      "Error on this batch = 0.03565057548675363\n",
      "Error on this batch = 0.06317036348554485\n",
      "Cost on val dataset after 974 epochs is = 0.08524896868603217\n",
      "Initial Cost on Val dataset for this epoch 974 = 0.08524896868603217\n",
      "learning rate for this epoch =  0.08950148993955362\n",
      "Error on this batch = 0.035629232912109725\n",
      "Error on this batch = 0.06314046427160486\n",
      "Cost on val dataset after 975 epochs is = 0.08523326548779898\n",
      "Initial Cost on Val dataset for this epoch 975 = 0.08523326548779898\n",
      "learning rate for this epoch =  0.08947853200770761\n",
      "Error on this batch = 0.03560792467355544\n",
      "Error on this batch = 0.06311059547121835\n",
      "Cost on val dataset after 976 epochs is = 0.08521759190871946\n",
      "Initial Cost on Val dataset for this epoch 976 = 0.08521759190871946\n",
      "learning rate for this epoch =  0.08945560349025655\n",
      "Error on this batch = 0.03558665067345942\n",
      "Error on this batch = 0.06308075704460922\n",
      "Cost on val dataset after 977 epochs is = 0.08520194787833724\n",
      "Initial Cost on Val dataset for this epoch 977 = 0.08520194787833724\n",
      "learning rate for this epoch =  0.08943270431943395\n",
      "Error on this batch = 0.03556541081452752\n",
      "Error on this batch = 0.06305094895267875\n",
      "Cost on val dataset after 978 epochs is = 0.08518633332656761\n",
      "Initial Cost on Val dataset for this epoch 978 = 0.08518633332656761\n",
      "learning rate for this epoch =  0.08940983442769869\n",
      "Error on this batch = 0.03554420499979845\n",
      "Error on this batch = 0.06302117115699545\n",
      "Cost on val dataset after 979 epochs is = 0.0851707481836962\n",
      "Initial Cost on Val dataset for this epoch 979 = 0.0851707481836962\n",
      "learning rate for this epoch =  0.08938699374773387\n",
      "Error on this batch = 0.03552303313263964\n",
      "Error on this batch = 0.06299142361978442\n",
      "Cost on val dataset after 980 epochs is = 0.08515519238037789\n",
      "Initial Cost on Val dataset for this epoch 980 = 0.08515519238037789\n",
      "learning rate for this epoch =  0.089364182212446\n",
      "Error on this batch = 0.03550189511674318\n",
      "Error on this batch = 0.0629617063039166\n",
      "Cost on val dataset after 981 epochs is = 0.08513966584763545\n",
      "Initial Cost on Val dataset for this epoch 981 = 0.08513966584763545\n",
      "learning rate for this epoch =  0.08934139975496388\n",
      "Error on this batch = 0.03548079085612207\n",
      "Error on this batch = 0.06293201917289795\n",
      "Cost on val dataset after 982 epochs is = 0.0851241685168585\n",
      "Initial Cost on Val dataset for this epoch 982 = 0.0851241685168585\n",
      "learning rate for this epoch =  0.08931864630863778\n",
      "Error on this batch = 0.035459720255106436\n",
      "Error on this batch = 0.06290236219085828\n",
      "Cost on val dataset after 983 epochs is = 0.08510870031980189\n",
      "Initial Cost on Val dataset for this epoch 983 = 0.08510870031980189\n",
      "learning rate for this epoch =  0.08929592180703835\n",
      "Error on this batch = 0.0354386832183401\n",
      "Error on this batch = 0.06287273532254002\n",
      "Cost on val dataset after 984 epochs is = 0.08509326118858442\n",
      "Initial Cost on Val dataset for this epoch 984 = 0.08509326118858442\n",
      "learning rate for this epoch =  0.08927322618395579\n",
      "Error on this batch = 0.035417679650777446\n",
      "Error on this batch = 0.0628431385332868\n",
      "Cost on val dataset after 985 epochs is = 0.0850778510556874\n",
      "Initial Cost on Val dataset for this epoch 985 = 0.0850778510556874\n",
      "learning rate for this epoch =  0.08925055937339876\n",
      "Error on this batch = 0.035396709457680225\n",
      "Error on this batch = 0.0628135717890316\n",
      "Cost on val dataset after 986 epochs is = 0.08506246985395323\n",
      "Initial Cost on Val dataset for this epoch 986 = 0.08506246985395323\n",
      "learning rate for this epoch =  0.08922792130959359\n",
      "Error on this batch = 0.035375772544614666\n",
      "Error on this batch = 0.06278403505628523\n",
      "Cost on val dataset after 987 epochs is = 0.08504711751658363\n",
      "Initial Cost on Val dataset for this epoch 987 = 0.08504711751658363\n",
      "learning rate for this epoch =  0.08920531192698324\n",
      "Error on this batch = 0.035354868817449\n",
      "Error on this batch = 0.06275452830212394\n",
      "Cost on val dataset after 988 epochs is = 0.08503179397713825\n",
      "Initial Cost on Val dataset for this epoch 988 = 0.08503179397713825\n",
      "learning rate for this epoch =  0.08918273116022643\n",
      "Error on this batch = 0.03533399818235086\n",
      "Error on this batch = 0.0627250514941774\n",
      "Cost on val dataset after 989 epochs is = 0.0850164991695329\n",
      "Initial Cost on Val dataset for this epoch 989 = 0.0850164991695329\n",
      "learning rate for this epoch =  0.08916017894419664\n",
      "Error on this batch = 0.03531316054578527\n",
      "Error on this batch = 0.06269560460061617\n",
      "Cost on val dataset after 990 epochs is = 0.0850012330280378\n",
      "Initial Cost on Val dataset for this epoch 990 = 0.0850012330280378\n",
      "learning rate for this epoch =  0.08913765521398127\n",
      "Error on this batch = 0.03529235581451261\n",
      "Error on this batch = 0.06266618759013907\n",
      "Cost on val dataset after 991 epochs is = 0.08498599548727594\n",
      "Initial Cost on Val dataset for this epoch 991 = 0.08498599548727594\n",
      "learning rate for this epoch =  0.08911515990488066\n",
      "Error on this batch = 0.03527158389558676\n",
      "Error on this batch = 0.06263680043196045\n",
      "Cost on val dataset after 992 epochs is = 0.08497078648222102\n",
      "Initial Cost on Val dataset for this epoch 992 = 0.08497078648222102\n",
      "learning rate for this epoch =  0.0890926929524072\n",
      "Error on this batch = 0.035250844696353964\n",
      "Error on this batch = 0.06260744309579681\n",
      "Cost on val dataset after 993 epochs is = 0.08495560594819565\n",
      "Initial Cost on Val dataset for this epoch 993 = 0.08495560594819565\n",
      "learning rate for this epoch =  0.08907025429228442\n",
      "Error on this batch = 0.03523013812445131\n",
      "Error on this batch = 0.06257811555185397\n",
      "Cost on val dataset after 994 epochs is = 0.08494045382086941\n",
      "Initial Cost on Val dataset for this epoch 994 = 0.08494045382086941\n",
      "learning rate for this epoch =  0.08904784386044612\n",
      "Error on this batch = 0.03520946408780594\n",
      "Error on this batch = 0.06254881777081332\n",
      "Cost on val dataset after 995 epochs is = 0.08492533003625681\n",
      "Initial Cost on Val dataset for this epoch 995 = 0.08492533003625681\n",
      "learning rate for this epoch =  0.08902546159303537\n",
      "Error on this batch = 0.035188822494634196\n",
      "Error on this batch = 0.06251954972381833\n",
      "Cost on val dataset after 996 epochs is = 0.084910234530715\n",
      "Initial Cost on Val dataset for this epoch 996 = 0.084910234530715\n",
      "learning rate for this epoch =  0.0890031074264038\n",
      "Error on this batch = 0.0351682132534413\n",
      "Error on this batch = 0.06249031138246059\n",
      "Cost on val dataset after 997 epochs is = 0.08489516724094189\n",
      "Initial Cost on Val dataset for this epoch 997 = 0.08489516724094189\n",
      "learning rate for this epoch =  0.08898078129711047\n",
      "Error on this batch = 0.03514763627302109\n",
      "Error on this batch = 0.06246110271876577\n",
      "Cost on val dataset after 998 epochs is = 0.08488012810397359\n",
      "Initial Cost on Val dataset for this epoch 998 = 0.08488012810397359\n",
      "learning rate for this epoch =  0.08895848314192122\n",
      "Error on this batch = 0.03512709146245614\n",
      "Error on this batch = 0.06243192370517941\n",
      "Cost on val dataset after 999 epochs is = 0.08486511705718243\n",
      "Initial Cost on Val dataset for this epoch 999 = 0.08486511705718243\n",
      "learning rate for this epoch =  0.08893621289780759\n",
      "Error on this batch = 0.035106578731118145\n",
      "Error on this batch = 0.062402774314552455\n",
      "Cost on val dataset after 1000 epochs is = 0.08485013403827413\n",
      "Initial Cost on Val dataset for this epoch 1000 = 0.08485013403827413\n",
      "learning rate for this epoch =  0.08891397050194613\n",
      "Error on this batch = 0.03508609798866845\n",
      "Error on this batch = 0.06237365452012654\n",
      "Cost on val dataset after 1001 epochs is = 0.08483517898528582\n",
      "Initial Cost on Val dataset for this epoch 1001 = 0.08483517898528582\n",
      "learning rate for this epoch =  0.0888917558917174\n",
      "Error on this batch = 0.03506564914505904\n",
      "Error on this batch = 0.06234456429551918\n",
      "Cost on val dataset after 1002 epochs is = 0.08482025183658318\n",
      "Initial Cost on Val dataset for this epoch 1002 = 0.08482025183658318\n",
      "learning rate for this epoch =  0.0888695690047051\n",
      "Error on this batch = 0.03504523211053371\n",
      "Error on this batch = 0.062315503614708674\n",
      "Cost on val dataset after 1003 epochs is = 0.08480535253085786\n",
      "Initial Cost on Val dataset for this epoch 1003 = 0.08480535253085786\n",
      "learning rate for this epoch =  0.08884740977869533\n",
      "Error on this batch = 0.03502484679562946\n",
      "Error on this batch = 0.06228647245201908\n",
      "Cost on val dataset after 1004 epochs is = 0.08479048100712488\n",
      "Initial Cost on Val dataset for this epoch 1004 = 0.08479048100712488\n",
      "learning rate for this epoch =  0.0888252781516756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.03500449311117833\n",
      "Error on this batch = 0.06225747078210447\n",
      "Cost on val dataset after 1005 epochs is = 0.08477563720471981\n",
      "Initial Cost on Val dataset for this epoch 1005 = 0.08477563720471981\n",
      "learning rate for this epoch =  0.08880317406183406\n",
      "Error on this batch = 0.03498417096830931\n",
      "Error on this batch = 0.062228498579933685\n",
      "Cost on val dataset after 1006 epochs is = 0.08476082106329588\n",
      "Initial Cost on Val dataset for this epoch 1006 = 0.08476082106329588\n",
      "learning rate for this epoch =  0.08878109744755859\n",
      "Error on this batch = 0.03496388027845069\n",
      "Error on this batch = 0.062199555820774285\n",
      "Cost on val dataset after 1007 epochs is = 0.08474603252282109\n",
      "Initial Cost on Val dataset for this epoch 1007 = 0.08474603252282109\n",
      "learning rate for this epoch =  0.08875904824743605\n",
      "Error on this batch = 0.03494362095333266\n",
      "Error on this batch = 0.062170642480176806\n",
      "Cost on val dataset after 1008 epochs is = 0.08473127152357518\n",
      "Initial Cost on Val dataset for this epoch 1008 = 0.08473127152357518\n",
      "learning rate for this epoch =  0.08873702640025133\n",
      "Error on this batch = 0.03492339290499008\n",
      "Error on this batch = 0.06214175853395847\n",
      "Cost on val dataset after 1009 epochs is = 0.0847165380061465\n",
      "Initial Cost on Val dataset for this epoch 1009 = 0.0847165380061465\n",
      "learning rate for this epoch =  0.08871503184498658\n",
      "Error on this batch = 0.03490319604576566\n",
      "Error on this batch = 0.0621129039581872\n",
      "Cost on val dataset after 1010 epochs is = 0.08470183191142883\n",
      "Initial Cost on Val dataset for this epoch 1010 = 0.08470183191142883\n",
      "learning rate for this epoch =  0.08869306452082039\n",
      "Error on this batch = 0.03488303028831336\n",
      "Error on this batch = 0.06208407872916487\n",
      "Cost on val dataset after 1011 epochs is = 0.08468715318061812\n",
      "Initial Cost on Val dataset for this epoch 1011 = 0.08468715318061812\n",
      "learning rate for this epoch =  0.0886711243671269\n",
      "Error on this batch = 0.03486289554560202\n",
      "Error on this batch = 0.06205528282341101\n",
      "Cost on val dataset after 1012 epochs is = 0.08467250175520921\n",
      "Initial Cost on Val dataset for this epoch 1012 = 0.08467250175520921\n",
      "learning rate for this epoch =  0.08864921132347509\n",
      "Error on this batch = 0.03484279173091928\n",
      "Error on this batch = 0.06202651621764599\n",
      "Cost on val dataset after 1013 epochs is = 0.08465787757699217\n",
      "Initial Cost on Val dataset for this epoch 1013 = 0.08465787757699217\n",
      "learning rate for this epoch =  0.0886273253296278\n",
      "Error on this batch = 0.03482271875787587\n",
      "Error on this batch = 0.06199777888877418\n",
      "Cost on val dataset after 1014 epochs is = 0.08464328058804896\n",
      "Initial Cost on Val dataset for this epoch 1014 = 0.08464328058804896\n",
      "learning rate for this epoch =  0.08860546632554109\n",
      "Error on this batch = 0.03480267654040995\n",
      "Error on this batch = 0.06196907081386711\n",
      "Cost on val dataset after 1015 epochs is = 0.08462871073074972\n",
      "Initial Cost on Val dataset for this epoch 1015 = 0.08462871073074972\n",
      "learning rate for this epoch =  0.0885836342513633\n",
      "Error on this batch = 0.03478266499279188\n",
      "Error on this batch = 0.06194039197014622\n",
      "Cost on val dataset after 1016 epochs is = 0.08461416794774916\n",
      "Initial Cost on Val dataset for this epoch 1016 = 0.08461416794774916\n",
      "learning rate for this epoch =  0.08856182904743433\n",
      "Error on this batch = 0.034762684029629246\n",
      "Error on this batch = 0.0619117423349659\n",
      "Cost on val dataset after 1017 epochs is = 0.08459965218198252\n",
      "Initial Cost on Val dataset for this epoch 1017 = 0.08459965218198252\n",
      "learning rate for this epoch =  0.08854005065428476\n",
      "Error on this batch = 0.03474273356587188\n",
      "Error on this batch = 0.061883121885796144\n",
      "Cost on val dataset after 1018 epochs is = 0.084585163376662\n",
      "Initial Cost on Val dataset for this epoch 1018 = 0.084585163376662\n",
      "learning rate for this epoch =  0.08851829901263515\n",
      "Error on this batch = 0.03472281351681757\n",
      "Error on this batch = 0.06185453060020517\n",
      "Cost on val dataset after 1019 epochs is = 0.08457070147527254\n",
      "Initial Cost on Val dataset for this epoch 1019 = 0.08457070147527254\n",
      "learning rate for this epoch =  0.08849657406339513\n",
      "Error on this batch = 0.0347029237981174\n",
      "Error on this batch = 0.06182596845584204\n",
      "Cost on val dataset after 1020 epochs is = 0.08455626642156785\n",
      "Initial Cost on Val dataset for this epoch 1020 = 0.08455626642156785\n",
      "learning rate for this epoch =  0.08847487574766279\n",
      "Error on this batch = 0.03468306432578193\n",
      "Error on this batch = 0.06179743543041931\n",
      "Cost on val dataset after 1021 epochs is = 0.08454185815956623\n",
      "Initial Cost on Val dataset for this epoch 1021 = 0.08454185815956623\n",
      "learning rate for this epoch =  0.08845320400672366\n",
      "Error on this batch = 0.034663235016187184\n",
      "Error on this batch = 0.061768931501695275\n",
      "Cost on val dataset after 1022 epochs is = 0.08452747663354632\n",
      "Initial Cost on Val dataset for this epoch 1022 = 0.08452747663354632\n",
      "learning rate for this epoch =  0.0884315587820501\n",
      "Error on this batch = 0.03464343578608103\n",
      "Error on this batch = 0.06174045664745667\n",
      "Cost on val dataset after 1023 epochs is = 0.08451312178804277\n",
      "Initial Cost on Val dataset for this epoch 1023 = 0.08451312178804277\n",
      "learning rate for this epoch =  0.08840994001530049\n",
      "Error on this batch = 0.03462366655258947\n",
      "Error on this batch = 0.06171201084550086\n",
      "Cost on val dataset after 1024 epochs is = 0.08449879356784183\n",
      "Initial Cost on Val dataset for this epoch 1024 = 0.08449879356784183\n",
      "learning rate for this epoch =  0.08838834764831843\n",
      "Error on this batch = 0.034603927233223725\n",
      "Error on this batch = 0.06168359407361848\n",
      "Cost on val dataset after 1025 epochs is = 0.08448449191797686\n",
      "Initial Cost on Val dataset for this epoch 1025 = 0.08448449191797686\n",
      "learning rate for this epoch =  0.08836678162313201\n",
      "Error on this batch = 0.0345842177458868\n",
      "Error on this batch = 0.06165520630957573\n",
      "Cost on val dataset after 1026 epochs is = 0.08447021678372357\n",
      "Initial Cost on Val dataset for this epoch 1026 = 0.08447021678372357\n",
      "learning rate for this epoch =  0.088345241881953\n",
      "Error on this batch = 0.03456453800888062\n",
      "Error on this batch = 0.061626847531096804\n",
      "Cost on val dataset after 1027 epochs is = 0.08445596811059562\n",
      "Initial Cost on Val dataset for this epoch 1027 = 0.08445596811059562\n",
      "learning rate for this epoch =  0.0883237283671761\n",
      "Error on this batch = 0.03454488794091331\n",
      "Error on this batch = 0.061598517715846415\n",
      "Cost on val dataset after 1028 epochs is = 0.0844417458443396\n",
      "Initial Cost on Val dataset for this epoch 1028 = 0.0844417458443396\n",
      "learning rate for this epoch =  0.0883022410213782\n",
      "Error on this batch = 0.03452526746110642\n",
      "Error on this batch = 0.06157021684141229\n",
      "Cost on val dataset after 1029 epochs is = 0.08442754993093025\n",
      "Initial Cost on Val dataset for this epoch 1029 = 0.08442754993093025\n",
      "learning rate for this epoch =  0.08828077978731765\n",
      "Error on this batch = 0.034505676489002574\n",
      "Error on this batch = 0.06154194488528777\n",
      "Cost on val dataset after 1030 epochs is = 0.0844133803165656\n",
      "Initial Cost on Val dataset for this epoch 1030 = 0.0844133803165656\n",
      "learning rate for this epoch =  0.08825934460793343\n",
      "Error on this batch = 0.03448611494457285\n",
      "Error on this batch = 0.061513701824854404\n",
      "Cost on val dataset after 1031 epochs is = 0.08439923694766185\n",
      "Initial Cost on Val dataset for this epoch 1031 = 0.08439923694766185\n",
      "learning rate for this epoch =  0.08823793542634452\n",
      "Error on this batch = 0.03446658274822469\n",
      "Error on this batch = 0.06148548763736485\n",
      "Cost on val dataset after 1032 epochs is = 0.08438511977084837\n",
      "Initial Cost on Val dataset for this epoch 1032 = 0.08438511977084837\n",
      "learning rate for this epoch =  0.08821655218584905\n",
      "Error on this batch = 0.03444707982080965\n",
      "Error on this batch = 0.06145730229992559\n",
      "Cost on val dataset after 1033 epochs is = 0.08437102873296239\n",
      "Initial Cost on Val dataset for this epoch 1033 = 0.08437102873296239\n",
      "learning rate for this epoch =  0.08819519482992363\n",
      "Error on this batch = 0.034427606083631206\n",
      "Error on this batch = 0.06142914578947995\n",
      "Cost on val dataset after 1034 epochs is = 0.0843569637810439\n",
      "Initial Cost on Val dataset for this epoch 1034 = 0.0843569637810439\n",
      "learning rate for this epoch =  0.08817386330222259\n",
      "Error on this batch = 0.03440816145845286\n",
      "Error on this batch = 0.06140101808279131\n",
      "Cost on val dataset after 1035 epochs is = 0.08434292486233029\n",
      "Initial Cost on Val dataset for this epoch 1035 = 0.08434292486233029\n",
      "learning rate for this epoch =  0.08815255754657725\n",
      "Error on this batch = 0.03438874586750605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.061372919156426314\n",
      "Cost on val dataset after 1036 epochs is = 0.08432891192425086\n",
      "Initial Cost on Val dataset for this epoch 1036 = 0.08432891192425086\n",
      "learning rate for this epoch =  0.08813127750699522\n",
      "Error on this batch = 0.03436935923349822\n",
      "Error on this batch = 0.06134484898673836\n",
      "Cost on val dataset after 1037 epochs is = 0.08431492491442148\n",
      "Initial Cost on Val dataset for this epoch 1037 = 0.08431492491442148\n",
      "learning rate for this epoch =  0.08811002312765961\n",
      "Error on this batch = 0.03435000147962089\n",
      "Error on this batch = 0.06131680754985125\n",
      "Cost on val dataset after 1038 epochs is = 0.08430096378063896\n",
      "Initial Cost on Val dataset for this epoch 1038 = 0.08430096378063896\n",
      "learning rate for this epoch =  0.08808879435292839\n",
      "Error on this batch = 0.03433067252955789\n",
      "Error on this batch = 0.061288794821643074\n",
      "Cost on val dataset after 1039 epochs is = 0.08428702847087562\n",
      "Initial Cost on Val dataset for this epoch 1039 = 0.08428702847087562\n",
      "learning rate for this epoch =  0.08806759112733367\n",
      "Error on this batch = 0.03431137230749317\n",
      "Error on this batch = 0.061260810777730254\n",
      "Cost on val dataset after 1040 epochs is = 0.08427311893327345\n",
      "Initial Cost on Val dataset for this epoch 1040 = 0.08427311893327345\n",
      "learning rate for this epoch =  0.0880464133955809\n",
      "Error on this batch = 0.034292100738119106\n",
      "Error on this batch = 0.06123285539345192\n",
      "Cost on val dataset after 1041 epochs is = 0.08425923511613849\n",
      "Initial Cost on Val dataset for this epoch 1041 = 0.08425923511613849\n",
      "learning rate for this epoch =  0.08802526110254827\n",
      "Error on this batch = 0.034272857746644465\n",
      "Error on this batch = 0.06120492864385449\n",
      "Cost on val dataset after 1042 epochs is = 0.0842453769679351\n",
      "Initial Cost on Val dataset for this epoch 1042 = 0.0842453769679351\n",
      "learning rate for this epoch =  0.0880041341932859\n",
      "Error on this batch = 0.03425364325880235\n",
      "Error on this batch = 0.06117703050367648\n",
      "Cost on val dataset after 1043 epochs is = 0.08423154443728016\n",
      "Initial Cost on Val dataset for this epoch 1043 = 0.08423154443728016\n",
      "learning rate for this epoch =  0.08798303261301525\n",
      "Error on this batch = 0.03423445720085813\n",
      "Error on this batch = 0.06114916094733377\n",
      "Cost on val dataset after 1044 epochs is = 0.08421773747293708\n",
      "Initial Cost on Val dataset for this epoch 1044 = 0.08421773747293708\n",
      "learning rate for this epoch =  0.08796195630712837\n",
      "Error on this batch = 0.034215299499617303\n",
      "Error on this batch = 0.0611213199489049\n",
      "Cost on val dataset after 1045 epochs is = 0.08420395602381009\n",
      "Initial Cost on Val dataset for this epoch 1045 = 0.08420395602381009\n",
      "learning rate for this epoch =  0.08794090522118717\n",
      "Error on this batch = 0.03419617008243326\n",
      "Error on this batch = 0.06109350748211703\n",
      "Cost on val dataset after 1046 epochs is = 0.08419020003893814\n",
      "Initial Cost on Val dataset for this epoch 1046 = 0.08419020003893814\n",
      "learning rate for this epoch =  0.08791987930092278\n",
      "Error on this batch = 0.034177068877214827\n",
      "Error on this batch = 0.06106572352033195\n",
      "Cost on val dataset after 1047 epochs is = 0.08417646946748907\n",
      "Initial Cost on Val dataset for this epoch 1047 = 0.08417646946748907\n",
      "learning rate for this epoch =  0.08789887849223484\n",
      "Error on this batch = 0.03415799581243384\n",
      "Error on this batch = 0.06103796803653262\n",
      "Cost on val dataset after 1048 epochs is = 0.0841627642587535\n",
      "Initial Cost on Val dataset for this epoch 1048 = 0.0841627642587535\n",
      "learning rate for this epoch =  0.08787790274119082\n",
      "Error on this batch = 0.03413895081713253\n",
      "Error on this batch = 0.06101024100330994\n",
      "Cost on val dataset after 1049 epochs is = 0.08414908436213883\n",
      "Initial Cost on Val dataset for this epoch 1049 = 0.08414908436213883\n",
      "learning rate for this epoch =  0.08785695199402538\n",
      "Error on this batch = 0.03411993382093058\n",
      "Error on this batch = 0.06098254239285008\n",
      "Cost on val dataset after 1050 epochs is = 0.08413542972716322\n",
      "Initial Cost on Val dataset for this epoch 1050 = 0.08413542972716322\n",
      "learning rate for this epoch =  0.08783602619713961\n",
      "Error on this batch = 0.03410094475403235\n",
      "Error on this batch = 0.06095487217692197\n",
      "Cost on val dataset after 1051 epochs is = 0.0841218003034495\n",
      "Initial Cost on Val dataset for this epoch 1051 = 0.0841218003034495\n",
      "learning rate for this epoch =  0.08781512529710042\n",
      "Error on this batch = 0.03408198354723361\n",
      "Error on this batch = 0.0609272303268656\n",
      "Cost on val dataset after 1052 epochs is = 0.08410819604071912\n",
      "Initial Cost on Val dataset for this epoch 1052 = 0.08410819604071912\n",
      "learning rate for this epoch =  0.08779424924063986\n",
      "Error on this batch = 0.03406305013192815\n",
      "Error on this batch = 0.060899616813580186\n",
      "Cost on val dataset after 1053 epochs is = 0.084094616888786\n",
      "Initial Cost on Val dataset for this epoch 1053 = 0.084094616888786\n",
      "learning rate for this epoch =  0.08777339797465443\n",
      "Error on this batch = 0.034044144440114325\n",
      "Error on this batch = 0.0608720316075133\n",
      "Cost on val dataset after 1054 epochs is = 0.0840810627975505\n",
      "Initial Cost on Val dataset for this epoch 1054 = 0.0840810627975505\n",
      "learning rate for this epoch =  0.08775257144620446\n",
      "Error on this batch = 0.034025266404401115\n",
      "Error on this batch = 0.06084447467865011\n",
      "Cost on val dataset after 1055 epochs is = 0.08406753371699328\n",
      "Initial Cost on Val dataset for this epoch 1055 = 0.08406753371699328\n",
      "learning rate for this epoch =  0.08773176960251337\n",
      "Error on this batch = 0.03400641595801418\n",
      "Error on this batch = 0.0608169459965033\n",
      "Cost on val dataset after 1056 epochs is = 0.0840540295971693\n",
      "Initial Cost on Val dataset for this epoch 1056 = 0.0840540295971693\n",
      "learning rate for this epoch =  0.08771099239096714\n",
      "Error on this batch = 0.03398759303480155\n",
      "Error on this batch = 0.06078944553010338\n",
      "Cost on val dataset after 1057 epochs is = 0.08404055038820173\n",
      "Initial Cost on Val dataset for this epoch 1057 = 0.08404055038820173\n",
      "learning rate for this epoch =  0.08769023975911351\n",
      "Error on this batch = 0.03396879756923899\n",
      "Error on this batch = 0.060761973247989286\n",
      "Cost on val dataset after 1058 epochs is = 0.08402709604027571\n",
      "Initial Cost on Val dataset for this epoch 1058 = 0.08402709604027571\n",
      "learning rate for this epoch =  0.08766951165466147\n",
      "Error on this batch = 0.033950029496435205\n",
      "Error on this batch = 0.06073452911819992\n",
      "Cost on val dataset after 1059 epochs is = 0.0840136665036327\n",
      "Initial Cost on Val dataset for this epoch 1059 = 0.0840136665036327\n",
      "learning rate for this epoch =  0.08764880802548045\n",
      "Error on this batch = 0.033931288752136676\n",
      "Error on this batch = 0.06070711310826582\n",
      "Cost on val dataset after 1060 epochs is = 0.08400026172856408\n",
      "Initial Cost on Val dataset for this epoch 1060 = 0.08400026172856408\n",
      "learning rate for this epoch =  0.08762812881959987\n",
      "Error on this batch = 0.03391257527273224\n",
      "Error on this batch = 0.060679725185201434\n",
      "Cost on val dataset after 1061 epochs is = 0.0839868816654055\n",
      "Initial Cost on Val dataset for this epoch 1061 = 0.0839868816654055\n",
      "learning rate for this epoch =  0.08760747398520836\n",
      "Error on this batch = 0.03389388899525727\n",
      "Error on this batch = 0.06065236531549801\n",
      "Cost on val dataset after 1062 epochs is = 0.08397352626453072\n",
      "Initial Cost on Val dataset for this epoch 1062 = 0.08397352626453072\n",
      "learning rate for this epoch =  0.08758684347065314\n",
      "Error on this batch = 0.03387522985739763\n",
      "Error on this batch = 0.06062503346511698\n",
      "Cost on val dataset after 1063 epochs is = 0.08396019547634591\n",
      "Initial Cost on Val dataset for this epoch 1063 = 0.08396019547634591\n",
      "learning rate for this epoch =  0.08756623722443944\n",
      "Error on this batch = 0.03385659779749326\n",
      "Error on this batch = 0.060597729599483736\n",
      "Cost on val dataset after 1064 epochs is = 0.08394688925128366\n",
      "Initial Cost on Val dataset for this epoch 1064 = 0.08394688925128366\n",
      "learning rate for this epoch =  0.08754565519522983\n",
      "Error on this batch = 0.03383799275454139\n",
      "Error on this batch = 0.06057045368348219\n",
      "Cost on val dataset after 1065 epochs is = 0.08393360753979735\n",
      "Initial Cost on Val dataset for this epoch 1065 = 0.08393360753979735\n",
      "learning rate for this epoch =  0.08752509733184359\n",
      "Error on this batch = 0.03381941466819945\n",
      "Error on this batch = 0.060543205681449656\n",
      "Cost on val dataset after 1066 epochs is = 0.08392035029235528\n",
      "Initial Cost on Val dataset for this epoch 1066 = 0.08392035029235528\n",
      "learning rate for this epoch =  0.0875045635832561\n",
      "Error on this batch = 0.033800863478787586\n",
      "Error on this batch = 0.06051598555717248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1067 epochs is = 0.0839071174594351\n",
      "Initial Cost on Val dataset for this epoch 1067 = 0.0839071174594351\n",
      "learning rate for this epoch =  0.08748405389859822\n",
      "Error on this batch = 0.03378233912729079\n",
      "Error on this batch = 0.060488793273882076\n",
      "Cost on val dataset after 1068 epochs is = 0.08389390899151827\n",
      "Initial Cost on Val dataset for this epoch 1068 = 0.08389390899151827\n",
      "learning rate for this epoch =  0.08746356822715562\n",
      "Error on this batch = 0.03376384155536074\n",
      "Error on this batch = 0.06046162879425156\n",
      "Cost on val dataset after 1069 epochs is = 0.08388072483908446\n",
      "Initial Cost on Val dataset for this epoch 1069 = 0.08388072483908446\n",
      "learning rate for this epoch =  0.08744310651836827\n",
      "Error on this batch = 0.033745370705317156\n",
      "Error on this batch = 0.06043449208039295\n",
      "Cost on val dataset after 1070 epochs is = 0.08386756495260618\n",
      "Initial Cost on Val dataset for this epoch 1070 = 0.08386756495260618\n",
      "learning rate for this epoch =  0.08742266872182974\n",
      "Error on this batch = 0.0337269265201489\n",
      "Error on this batch = 0.06040738309385496\n",
      "Cost on val dataset after 1071 epochs is = 0.08385442928254341\n",
      "Initial Cost on Val dataset for this epoch 1071 = 0.08385442928254341\n",
      "learning rate for this epoch =  0.08740225478728658\n",
      "Error on this batch = 0.03370850894351455\n",
      "Error on this batch = 0.06038030179562133\n",
      "Cost on val dataset after 1072 epochs is = 0.08384131777933838\n",
      "Initial Cost on Val dataset for this epoch 1072 = 0.08384131777933838\n",
      "learning rate for this epoch =  0.0873818646646378\n",
      "Error on this batch = 0.03369011791974273\n",
      "Error on this batch = 0.06035324814610954\n",
      "Cost on val dataset after 1073 epochs is = 0.08382823039341049\n",
      "Initial Cost on Val dataset for this epoch 1073 = 0.08382823039341049\n",
      "learning rate for this epoch =  0.08736149830393418\n",
      "Error on this batch = 0.03367175339383187\n",
      "Error on this batch = 0.06032622210517055\n",
      "Cost on val dataset after 1074 epochs is = 0.08381516707515106\n",
      "Initial Cost on Val dataset for this epoch 1074 = 0.08381516707515106\n",
      "learning rate for this epoch =  0.0873411556553777\n",
      "Error on this batch = 0.03365341531144977\n",
      "Error on this batch = 0.06029922363208848\n",
      "Cost on val dataset after 1075 epochs is = 0.08380212777491865\n",
      "Initial Cost on Val dataset for this epoch 1075 = 0.08380212777491865\n",
      "learning rate for this epoch =  0.087320836669321\n",
      "Error on this batch = 0.03363510361893256\n",
      "Error on this batch = 0.06027225268558128\n",
      "Cost on val dataset after 1076 epochs is = 0.08378911244303397\n",
      "Initial Cost on Val dataset for this epoch 1076 = 0.08378911244303397\n",
      "learning rate for this epoch =  0.08730054129626662\n",
      "Error on this batch = 0.0336168182632835\n",
      "Error on this batch = 0.06024530922380185\n",
      "Cost on val dataset after 1077 epochs is = 0.08377612102977539\n",
      "Initial Cost on Val dataset for this epoch 1077 = 0.08377612102977539\n",
      "learning rate for this epoch =  0.08728026948686665\n",
      "Error on this batch = 0.03359855919217122\n",
      "Error on this batch = 0.060218393204339596\n",
      "Cost on val dataset after 1078 epochs is = 0.08376315348537428\n",
      "Initial Cost on Val dataset for this epoch 1078 = 0.08376315348537428\n",
      "learning rate for this epoch =  0.0872600211919219\n",
      "Error on this batch = 0.03358032635392753\n",
      "Error on this batch = 0.06019150458422253\n",
      "Cost on val dataset after 1079 epochs is = 0.08375020976001042\n",
      "Initial Cost on Val dataset for this epoch 1079 = 0.08375020976001042\n",
      "learning rate for this epoch =  0.08723979636238147\n",
      "Error on this batch = 0.033562119697544975\n",
      "Error on this batch = 0.0601646433199201\n",
      "Cost on val dataset after 1080 epochs is = 0.08373728980380787\n",
      "Initial Cost on Val dataset for this epoch 1080 = 0.08373728980380787\n",
      "learning rate for this epoch =  0.08721959494934213\n",
      "Error on this batch = 0.033543939172673974\n",
      "Error on this batch = 0.06013780936734625\n",
      "Cost on val dataset after 1081 epochs is = 0.08372439356683059\n",
      "Initial Cost on Val dataset for this epoch 1081 = 0.08372439356683059\n",
      "learning rate for this epoch =  0.0871994169040477\n",
      "Error on this batch = 0.03352578472961949\n",
      "Error on this batch = 0.06011100268186331\n",
      "Cost on val dataset after 1082 epochs is = 0.08371152099907848\n",
      "Initial Cost on Val dataset for this epoch 1082 = 0.08371152099907848\n",
      "learning rate for this epoch =  0.08717926217788849\n",
      "Error on this batch = 0.033507656319337324\n",
      "Error on this batch = 0.06008422321828594\n",
      "Cost on val dataset after 1083 epochs is = 0.08369867205048348\n",
      "Initial Cost on Val dataset for this epoch 1083 = 0.08369867205048348\n",
      "learning rate for this epoch =  0.0871591307224008\n",
      "Error on this batch = 0.033489553893430106\n",
      "Error on this batch = 0.06005747093088616\n",
      "Cost on val dataset after 1084 epochs is = 0.08368584667090559\n",
      "Initial Cost on Val dataset for this epoch 1084 = 0.08368584667090559\n",
      "learning rate for this epoch =  0.08713902248926618\n",
      "Error on this batch = 0.03347147740414296\n",
      "Error on this batch = 0.0600307457733984\n",
      "Cost on val dataset after 1085 epochs is = 0.08367304481012958\n",
      "Initial Cost on Val dataset for this epoch 1085 = 0.08367304481012958\n",
      "learning rate for this epoch =  0.08711893743031107\n",
      "Error on this batch = 0.03345342680435852\n",
      "Error on this batch = 0.06000404769902506\n",
      "Cost on val dataset after 1086 epochs is = 0.08366026641786116\n",
      "Initial Cost on Val dataset for this epoch 1086 = 0.08366026641786116\n",
      "learning rate for this epoch =  0.08709887549750603\n",
      "Error on this batch = 0.03343540204759202\n",
      "Error on this batch = 0.05997737666044291\n",
      "Cost on val dataset after 1087 epochs is = 0.0836475114437239\n",
      "Initial Cost on Val dataset for this epoch 1087 = 0.0836475114437239\n",
      "learning rate for this epoch =  0.08707883664296534\n",
      "Error on this batch = 0.03341740308798557\n",
      "Error on this batch = 0.05995073260980943\n",
      "Cost on val dataset after 1088 epochs is = 0.08363477983725595\n",
      "Initial Cost on Val dataset for this epoch 1088 = 0.08363477983725595\n",
      "learning rate for this epoch =  0.08705882081894635\n",
      "Error on this batch = 0.033399429880302506\n",
      "Error on this batch = 0.05992411549877004\n",
      "Cost on val dataset after 1089 epochs is = 0.08362207154790709\n",
      "Initial Cost on Val dataset for this epoch 1089 = 0.08362207154790709\n",
      "learning rate for this epoch =  0.08703882797784893\n",
      "Error on this batch = 0.03338148237992097\n",
      "Error on this batch = 0.05989752527846541\n",
      "Cost on val dataset after 1090 epochs is = 0.08360938652503584\n",
      "Initial Cost on Val dataset for this epoch 1090 = 0.08360938652503584\n",
      "learning rate for this epoch =  0.08701885807221492\n",
      "Error on this batch = 0.03336356054282768\n",
      "Error on this batch = 0.059870961899539346\n",
      "Cost on val dataset after 1091 epochs is = 0.0835967247179069\n",
      "Initial Cost on Val dataset for this epoch 1091 = 0.0835967247179069\n",
      "learning rate for this epoch =  0.08699891105472762\n",
      "Error on this batch = 0.03334566432561087\n",
      "Error on this batch = 0.059844425312147155\n",
      "Cost on val dataset after 1092 epochs is = 0.08358408607568839\n",
      "Initial Cost on Val dataset for this epoch 1092 = 0.08358408607568839\n",
      "learning rate for this epoch =  0.08697898687821116\n",
      "Error on this batch = 0.03332779368545324\n",
      "Error on this batch = 0.059817915465964176\n",
      "Cost on val dataset after 1093 epochs is = 0.08357147054744983\n",
      "Initial Cost on Val dataset for this epoch 1093 = 0.08357147054744983\n",
      "learning rate for this epoch =  0.08695908549563003\n",
      "Error on this batch = 0.03330994858012451\n",
      "Error on this batch = 0.05979143231019487\n",
      "Cost on val dataset after 1094 epochs is = 0.08355887808215975\n",
      "Initial Cost on Val dataset for this epoch 1094 = 0.08355887808215975\n",
      "learning rate for this epoch =  0.08693920686008848\n",
      "Error on this batch = 0.03329212896797364\n",
      "Error on this batch = 0.05976497579358217\n",
      "Cost on val dataset after 1095 epochs is = 0.08354630862868383\n",
      "Initial Cost on Val dataset for this epoch 1095 = 0.08354630862868383\n",
      "learning rate for this epoch =  0.08691935092482998\n",
      "Error on this batch = 0.03327433480792088\n",
      "Error on this batch = 0.05973854586441718\n",
      "Cost on val dataset after 1096 epochs is = 0.08353376213578291\n",
      "Initial Cost on Val dataset for this epoch 1096 = 0.08353376213578291\n",
      "learning rate for this epoch =  0.08689951764323674\n",
      "Error on this batch = 0.03325656605944946\n",
      "Error on this batch = 0.059712142470549234\n",
      "Cost on val dataset after 1097 epochs is = 0.08352123855211162\n",
      "Initial Cost on Val dataset for this epoch 1097 = 0.08352123855211162\n",
      "learning rate for this epoch =  0.08687970696882906\n",
      "Error on this batch = 0.033238822682597084\n",
      "Error on this batch = 0.05968576555939622\n",
      "Cost on val dataset after 1098 epochs is = 0.08350873782621661\n",
      "Initial Cost on Val dataset for this epoch 1098 = 0.08350873782621661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate for this epoch =  0.08685991885526495\n",
      "Error on this batch = 0.03322110463794709\n",
      "Error on this batch = 0.05965941507795528\n",
      "Cost on val dataset after 1099 epochs is = 0.08349625990653549\n",
      "Initial Cost on Val dataset for this epoch 1099 = 0.08349625990653549\n",
      "learning rate for this epoch =  0.08684015325633943\n",
      "Error on this batch = 0.03320341188661948\n",
      "Error on this batch = 0.05963309097281366\n",
      "Cost on val dataset after 1100 epochs is = 0.08348380474139559\n",
      "Initial Cost on Val dataset for this epoch 1100 = 0.08348380474139559\n",
      "learning rate for this epoch =  0.08682041012598414\n",
      "Error on this batch = 0.03318574439026177\n",
      "Error on this batch = 0.059606793190159844\n",
      "Cost on val dataset after 1101 epochs is = 0.08347137227901312\n",
      "Initial Cost on Val dataset for this epoch 1101 = 0.08347137227901312\n",
      "learning rate for this epoch =  0.08680068941826673\n",
      "Error on this batch = 0.033168102111039446\n",
      "Error on this batch = 0.0595805216757951\n",
      "Cost on val dataset after 1102 epochs is = 0.08345896246749232\n",
      "Initial Cost on Val dataset for this epoch 1102 = 0.08345896246749232\n",
      "learning rate for this epoch =  0.08678099108739035\n",
      "Error on this batch = 0.033150485011626325\n",
      "Error on this batch = 0.059554276375145036\n",
      "Cost on val dataset after 1103 epochs is = 0.083446575254825\n",
      "Initial Cost on Val dataset for this epoch 1103 = 0.083446575254825\n",
      "learning rate for this epoch =  0.08676131508769315\n",
      "Error on this batch = 0.033132893055194935\n",
      "Error on this batch = 0.05952805723327148\n",
      "Cost on val dataset after 1104 epochs is = 0.08343421058889\n",
      "Initial Cost on Val dataset for this epoch 1104 = 0.08343421058889\n",
      "learning rate for this epoch =  0.08674166137364775\n",
      "Error on this batch = 0.03311532620540633\n",
      "Error on this batch = 0.05950186419488448\n",
      "Cost on val dataset after 1105 epochs is = 0.08342186841745314\n",
      "Initial Cost on Val dataset for this epoch 1105 = 0.08342186841745314\n",
      "learning rate for this epoch =  0.0867220298998607\n",
      "Error on this batch = 0.03309778442640015\n",
      "Error on this batch = 0.059475697204354604\n",
      "Cost on val dataset after 1106 epochs is = 0.08340954868816698\n",
      "Initial Cost on Val dataset for this epoch 1106 = 0.08340954868816698\n",
      "learning rate for this epoch =  0.08670242062107203\n",
      "Error on this batch = 0.0330802676827842\n",
      "Error on this batch = 0.059449556205725375\n",
      "Cost on val dataset after 1107 epochs is = 0.08339725134857111\n",
      "Initial Cost on Val dataset for this epoch 1107 = 0.08339725134857111\n",
      "learning rate for this epoch =  0.08668283349215462\n",
      "Error on this batch = 0.033062775939624194\n",
      "Error on this batch = 0.059423441142725596\n",
      "Cost on val dataset after 1108 epochs is = 0.08338497634609238\n",
      "Initial Cost on Val dataset for this epoch 1108 = 0.08338497634609238\n",
      "learning rate for this epoch =  0.08666326846811381\n",
      "Error on this batch = 0.03304530916243322\n",
      "Error on this batch = 0.05939735195878221\n",
      "Cost on val dataset after 1109 epochs is = 0.0833727236280455\n",
      "Initial Cost on Val dataset for this epoch 1109 = 0.0833727236280455\n",
      "learning rate for this epoch =  0.08664372550408686\n",
      "Error on this batch = 0.03302786731716112\n",
      "Error on this batch = 0.05937128859703305\n",
      "Cost on val dataset after 1110 epochs is = 0.08336049314163346\n",
      "Initial Cost on Val dataset for this epoch 1110 = 0.08336049314163346\n",
      "learning rate for this epoch =  0.0866242045553424\n",
      "Error on this batch = 0.03301045037018376\n",
      "Error on this batch = 0.05934525100033955\n",
      "Cost on val dataset after 1111 epochs is = 0.08334828483394865\n",
      "Initial Cost on Val dataset for this epoch 1111 = 0.08334828483394865\n",
      "learning rate for this epoch =  0.08660470557727994\n",
      "Error on this batch = 0.03299305828829244\n",
      "Error on this batch = 0.05931923911129992\n",
      "Cost on val dataset after 1112 epochs is = 0.08333609865197351\n",
      "Initial Cost on Val dataset for this epoch 1112 = 0.08333609865197351\n",
      "learning rate for this epoch =  0.08658522852542944\n",
      "Error on this batch = 0.03297569103868289\n",
      "Error on this batch = 0.05929325287226206\n",
      "Cost on val dataset after 1113 epochs is = 0.08332393454258208\n",
      "Initial Cost on Val dataset for this epoch 1113 = 0.08332393454258208\n",
      "learning rate for this epoch =  0.0865657733554507\n",
      "Error on this batch = 0.03295834858894455\n",
      "Error on this batch = 0.05926729222533654\n",
      "Cost on val dataset after 1114 epochs is = 0.08331179245254097\n",
      "Initial Cost on Val dataset for this epoch 1114 = 0.08331179245254097\n",
      "learning rate for this epoch =  0.08654634002313295\n",
      "Error on this batch = 0.03294103090704963\n",
      "Error on this batch = 0.0592413571124098\n",
      "Cost on val dataset after 1115 epochs is = 0.08329967232851111\n",
      "Initial Cost on Val dataset for this epoch 1115 = 0.08329967232851111\n",
      "learning rate for this epoch =  0.08652692848439436\n",
      "Error on this batch = 0.03292373796134214\n",
      "Error on this batch = 0.059215447475157286\n",
      "Cost on val dataset after 1116 epochs is = 0.08328757411704929\n",
      "Initial Cost on Val dataset for this epoch 1116 = 0.08328757411704929\n",
      "learning rate for this epoch =  0.08650753869528147\n",
      "Error on this batch = 0.03290646972052706\n",
      "Error on this batch = 0.05918956325505648\n",
      "Cost on val dataset after 1117 epochs is = 0.08327549776460992\n",
      "Initial Cost on Val dataset for this epoch 1117 = 0.08327549776460992\n",
      "learning rate for this epoch =  0.08648817061196874\n",
      "Error on this batch = 0.032889226153659364\n",
      "Error on this batch = 0.059163704393400136\n",
      "Cost on val dataset after 1118 epochs is = 0.08326344321754708\n",
      "Initial Cost on Val dataset for this epoch 1118 = 0.08326344321754708\n",
      "learning rate for this epoch =  0.08646882419075813\n",
      "Error on this batch = 0.03287200723013318\n",
      "Error on this batch = 0.05913787083130925\n",
      "Cost on val dataset after 1119 epochs is = 0.08325141042211663\n",
      "Initial Cost on Val dataset for this epoch 1119 = 0.08325141042211663\n",
      "learning rate for this epoch =  0.08644949938807851\n",
      "Error on this batch = 0.032854812919670795\n",
      "Error on this batch = 0.059112062509746155\n",
      "Cost on val dataset after 1120 epochs is = 0.08323939932447848\n",
      "Initial Cost on Val dataset for this epoch 1120 = 0.08323939932447848\n",
      "learning rate for this epoch =  0.08643019616048525\n",
      "Error on this batch = 0.03283764319231196\n",
      "Error on this batch = 0.05908627936952758\n",
      "Cost on val dataset after 1121 epochs is = 0.08322740987069889\n",
      "Initial Cost on Val dataset for this epoch 1121 = 0.08322740987069889\n",
      "learning rate for this epoch =  0.0864109144646597\n",
      "Error on this batch = 0.03282049801840306\n",
      "Error on this batch = 0.05906052135133752\n",
      "Cost on val dataset after 1122 epochs is = 0.0832154420067532\n",
      "Initial Cost on Val dataset for this epoch 1122 = 0.0832154420067532\n",
      "learning rate for this epoch =  0.08639165425740875\n",
      "Error on this batch = 0.0328033773685863\n",
      "Error on this batch = 0.05903478839574012\n",
      "Cost on val dataset after 1123 epochs is = 0.08320349567852846\n",
      "Initial Cost on Val dataset for this epoch 1123 = 0.08320349567852846\n",
      "learning rate for this epoch =  0.08637241549566431\n",
      "Error on this batch = 0.032786281213789306\n",
      "Error on this batch = 0.059009080443192474\n",
      "Cost on val dataset after 1124 epochs is = 0.08319157083182617\n",
      "Initial Cost on Val dataset for this epoch 1124 = 0.08319157083182617\n",
      "learning rate for this epoch =  0.08635319813648287\n",
      "Error on this batch = 0.032769209525214234\n",
      "Error on this batch = 0.0589833974340572\n",
      "Cost on val dataset after 1125 epochs is = 0.0831796674123654\n",
      "Initial Cost on Val dataset for this epoch 1125 = 0.0831796674123654\n",
      "learning rate for this epoch =  0.08633400213704505\n",
      "Error on this batch = 0.03275216227432757\n",
      "Error on this batch = 0.0589577393086152\n",
      "Cost on val dataset after 1126 epochs is = 0.08316778536578585\n",
      "Initial Cost on Val dataset for this epoch 1126 = 0.08316778536578585\n",
      "learning rate for this epoch =  0.08631482745465505\n",
      "Error on this batch = 0.032735139432849614\n",
      "Error on this batch = 0.05893210600707789\n",
      "Cost on val dataset after 1127 epochs is = 0.08315592463765102\n",
      "Initial Cost on Val dataset for this epoch 1127 = 0.08315592463765102\n",
      "learning rate for this epoch =  0.08629567404674027\n",
      "Error on this batch = 0.03271814097274432\n",
      "Error on this batch = 0.05890649746959961\n",
      "Cost on val dataset after 1128 epochs is = 0.08314408517345162\n",
      "Initial Cost on Val dataset for this epoch 1128 = 0.08314408517345162\n",
      "learning rate for this epoch =  0.0862765418708508\n",
      "Error on this batch = 0.032701166866209046\n",
      "Error on this batch = 0.05888091363628981\n",
      "Cost on val dataset after 1129 epochs is = 0.08313226691860898\n",
      "Initial Cost on Val dataset for this epoch 1129 = 0.08313226691860898\n",
      "learning rate for this epoch =  0.08625743088465897\n",
      "Error on this batch = 0.03268421708566472\n",
      "Error on this batch = 0.05885535444722497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1130 epochs is = 0.08312046981847872\n",
      "Initial Cost on Val dataset for this epoch 1130 = 0.08312046981847872\n",
      "learning rate for this epoch =  0.0862383410459589\n",
      "Error on this batch = 0.03266729160374576\n",
      "Error on this batch = 0.05882981984246053\n",
      "Cost on val dataset after 1131 epochs is = 0.0831086938183544\n",
      "Initial Cost on Val dataset for this epoch 1131 = 0.0831086938183544\n",
      "learning rate for this epoch =  0.08621927231266602\n",
      "Error on this batch = 0.03265039039329053\n",
      "Error on this batch = 0.058804309762042505\n",
      "Cost on val dataset after 1132 epochs is = 0.0830969388634713\n",
      "Initial Cost on Val dataset for this epoch 1132 = 0.0830969388634713\n",
      "learning rate for this epoch =  0.08620022464281663\n",
      "Error on this batch = 0.03263351342733173\n",
      "Error on this batch = 0.05877882414601903\n",
      "Cost on val dataset after 1133 epochs is = 0.08308520489901049\n",
      "Initial Cost on Val dataset for this epoch 1133 = 0.08308520489901049\n",
      "learning rate for this epoch =  0.08618119799456743\n",
      "Error on this batch = 0.03261666067908694\n",
      "Error on this batch = 0.05875336293445156\n",
      "Cost on val dataset after 1134 epochs is = 0.08307349187010257\n",
      "Initial Cost on Val dataset for this epoch 1134 = 0.08307349187010257\n",
      "learning rate for this epoch =  0.0861621923261951\n",
      "Error on this batch = 0.03259983212194943\n",
      "Error on this batch = 0.058727926067426085\n",
      "Cost on val dataset after 1135 epochs is = 0.08306179972183206\n",
      "Initial Cost on Val dataset for this epoch 1135 = 0.08306179972183206\n",
      "learning rate for this epoch =  0.08614320759609581\n",
      "Error on this batch = 0.03258302772947913\n",
      "Error on this batch = 0.05870251348506399\n",
      "Cost on val dataset after 1136 epochs is = 0.08305012839924135\n",
      "Initial Cost on Val dataset for this epoch 1136 = 0.08305012839924135\n",
      "learning rate for this epoch =  0.08612424376278484\n",
      "Error on this batch = 0.0325662474753936\n",
      "Error on this batch = 0.05867712512753272\n",
      "Cost on val dataset after 1137 epochs is = 0.08303847784733522\n",
      "Initial Cost on Val dataset for this epoch 1137 = 0.08303847784733522\n",
      "learning rate for this epoch =  0.08610530078489602\n",
      "Error on this batch = 0.03254949133355954\n",
      "Error on this batch = 0.05865176093505625\n",
      "Cost on val dataset after 1138 epochs is = 0.08302684801108508\n",
      "Initial Cost on Val dataset for this epoch 1138 = 0.08302684801108508\n",
      "learning rate for this epoch =  0.08608637862118143\n",
      "Error on this batch = 0.03253275927798408\n",
      "Error on this batch = 0.05862642084792539\n",
      "Cost on val dataset after 1139 epochs is = 0.08301523883543344\n",
      "Initial Cost on Val dataset for this epoch 1139 = 0.08301523883543344\n",
      "learning rate for this epoch =  0.08606747723051081\n",
      "Error on this batch = 0.03251605128280664\n",
      "Error on this batch = 0.05860110480650765\n",
      "Cost on val dataset after 1140 epochs is = 0.08300365026529848\n",
      "Initial Cost on Val dataset for this epoch 1140 = 0.08300365026529848\n",
      "learning rate for this epoch =  0.08604859657187126\n",
      "Error on this batch = 0.03249936732229066\n",
      "Error on this batch = 0.05857581275125714\n",
      "Cost on val dataset after 1141 epochs is = 0.08299208224557861\n",
      "Initial Cost on Val dataset for this epoch 1141 = 0.08299208224557861\n",
      "learning rate for this epoch =  0.0860297366043667\n",
      "Error on this batch = 0.03248270737081577\n",
      "Error on this batch = 0.05855054462272414\n",
      "Cost on val dataset after 1142 epochs is = 0.08298053472115716\n",
      "Initial Cost on Val dataset for this epoch 1142 = 0.08298053472115716\n",
      "learning rate for this epoch =  0.08601089728721749\n",
      "Error on this batch = 0.03246607140287011\n",
      "Error on this batch = 0.0585253003615642\n",
      "Cost on val dataset after 1143 epochs is = 0.08296900763690712\n",
      "Initial Cost on Val dataset for this epoch 1143 = 0.08296900763690712\n",
      "learning rate for this epoch =  0.08599207857975999\n",
      "Error on this batch = 0.03244945939304279\n",
      "Error on this batch = 0.05850007990854735\n",
      "Cost on val dataset after 1144 epochs is = 0.08295750093769594\n",
      "Initial Cost on Val dataset for this epoch 1144 = 0.08295750093769594\n",
      "learning rate for this epoch =  0.08597328044144606\n",
      "Error on this batch = 0.03243287131601656\n",
      "Error on this batch = 0.05847488320456675\n",
      "Cost on val dataset after 1145 epochs is = 0.0829460145683904\n",
      "Initial Cost on Val dataset for this epoch 1145 = 0.0829460145683904\n",
      "learning rate for this epoch =  0.08595450283184279\n",
      "Error on this batch = 0.03241630714656091\n",
      "Error on this batch = 0.05844971019064722\n",
      "Cost on val dataset after 1146 epochs is = 0.0829345484738614\n",
      "Initial Cost on Val dataset for this epoch 1146 = 0.0829345484738614\n",
      "learning rate for this epoch =  0.08593574571063191\n",
      "Error on this batch = 0.032399766859525\n",
      "Error on this batch = 0.05842456080795365\n",
      "Cost on val dataset after 1147 epochs is = 0.08292310259898908\n",
      "Initial Cost on Val dataset for this epoch 1147 = 0.08292310259898908\n",
      "learning rate for this epoch =  0.08591700903760942\n",
      "Error on this batch = 0.03238325042983125\n",
      "Error on this batch = 0.058399434997798726\n",
      "Cost on val dataset after 1148 epochs is = 0.08291167688866762\n",
      "Initial Cost on Val dataset for this epoch 1148 = 0.08291167688866762\n",
      "learning rate for this epoch =  0.0858982927726852\n",
      "Error on this batch = 0.03236675783246873\n",
      "Error on this batch = 0.05837433270165089\n",
      "Cost on val dataset after 1149 epochs is = 0.08290027128781048\n",
      "Initial Cost on Val dataset for this epoch 1149 = 0.08290027128781048\n",
      "learning rate for this epoch =  0.08587959687588255\n",
      "Error on this batch = 0.032350289042487136\n",
      "Error on this batch = 0.058349253861141606\n",
      "Cost on val dataset after 1150 epochs is = 0.08288888574135535\n",
      "Initial Cost on Val dataset for this epoch 1150 = 0.08288888574135535\n",
      "learning rate for this epoch =  0.08586092130733781\n",
      "Error on this batch = 0.03233384403499072\n",
      "Error on this batch = 0.058324198418072515\n",
      "Cost on val dataset after 1151 epochs is = 0.08287752019426921\n",
      "Initial Cost on Val dataset for this epoch 1151 = 0.08287752019426921\n",
      "learning rate for this epoch =  0.0858422660272999\n",
      "Error on this batch = 0.032317422785132645\n",
      "Error on this batch = 0.058299166314422515\n",
      "Cost on val dataset after 1152 epochs is = 0.0828661745915535\n",
      "Initial Cost on Val dataset for this epoch 1152 = 0.0828661745915535\n",
      "learning rate for this epoch =  0.08582363099612991\n",
      "Error on this batch = 0.03230102526810943\n",
      "Error on this batch = 0.05827415749235419\n",
      "Cost on val dataset after 1153 epochs is = 0.08285484887824934\n",
      "Initial Cost on Val dataset for this epoch 1153 = 0.08285484887824934\n",
      "learning rate for this epoch =  0.08580501617430071\n",
      "Error on this batch = 0.03228465145915556\n",
      "Error on this batch = 0.05824917189422021\n",
      "Cost on val dataset after 1154 epochs is = 0.08284354299944263\n",
      "Initial Cost on Val dataset for this epoch 1154 = 0.08284354299944263\n",
      "learning rate for this epoch =  0.08578642152239652\n",
      "Error on this batch = 0.032268301333538627\n",
      "Error on this batch = 0.0582242094625693\n",
      "Cost on val dataset after 1155 epochs is = 0.08283225690026923\n",
      "Initial Cost on Val dataset for this epoch 1155 = 0.08283225690026923\n",
      "learning rate for this epoch =  0.08576784700111252\n",
      "Error on this batch = 0.03225197486655426\n",
      "Error on this batch = 0.05819927014015219\n",
      "Cost on val dataset after 1156 epochs is = 0.08282099052592014\n",
      "Initial Cost on Val dataset for this epoch 1156 = 0.08282099052592014\n",
      "learning rate for this epoch =  0.08574929257125441\n",
      "Error on this batch = 0.0322356720335217\n",
      "Error on this batch = 0.05817435386992689\n",
      "Cost on val dataset after 1157 epochs is = 0.08280974382164677\n",
      "Initial Cost on Val dataset for this epoch 1157 = 0.08280974382164677\n",
      "learning rate for this epoch =  0.08573075819373804\n",
      "Error on this batch = 0.032219392809779306\n",
      "Error on this batch = 0.058149460595064005\n",
      "Cost on val dataset after 1158 epochs is = 0.08279851673276617\n",
      "Initial Cost on Val dataset for this epoch 1158 = 0.08279851673276617\n",
      "learning rate for this epoch =  0.085712243829589\n",
      "Error on this batch = 0.032203137170680296\n",
      "Error on this batch = 0.058124590258951586\n",
      "Cost on val dataset after 1159 epochs is = 0.08278730920466612\n",
      "Initial Cost on Val dataset for this epoch 1159 = 0.08278730920466612\n",
      "learning rate for this epoch =  0.08569374943994214\n",
      "Error on this batch = 0.03218690509158897\n",
      "Error on this batch = 0.058099742805199875\n",
      "Cost on val dataset after 1160 epochs is = 0.0827761211828104\n",
      "Initial Cost on Val dataset for this epoch 1160 = 0.0827761211828104\n",
      "learning rate for this epoch =  0.0856752749860413\n",
      "Error on this batch = 0.032170696547876784\n",
      "Error on this batch = 0.05807491817764543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1161 epochs is = 0.08276495261274412\n",
      "Initial Cost on Val dataset for this epoch 1161 = 0.08276495261274412\n",
      "learning rate for this epoch =  0.08565682042923882\n",
      "Error on this batch = 0.032154511514918986\n",
      "Error on this batch = 0.05805011632035546\n",
      "Cost on val dataset after 1162 epochs is = 0.08275380344009876\n",
      "Initial Cost on Val dataset for this epoch 1162 = 0.08275380344009876\n",
      "learning rate for this epoch =  0.08563838573099518\n",
      "Error on this batch = 0.032138349968091035\n",
      "Error on this batch = 0.058025337177631364\n",
      "Cost on val dataset after 1163 epochs is = 0.08274267361059734\n",
      "Initial Cost on Val dataset for this epoch 1163 = 0.08274267361059734\n",
      "learning rate for this epoch =  0.08561997085287859\n",
      "Error on this batch = 0.032122211882765817\n",
      "Error on this batch = 0.05800058069401241\n",
      "Cost on val dataset after 1164 epochs is = 0.08273156307005963\n",
      "Initial Cost on Val dataset for this epoch 1164 = 0.08273156307005963\n",
      "learning rate for this epoch =  0.08560157575656459\n",
      "Error on this batch = 0.0321060972343105\n",
      "Error on this batch = 0.0579758468142788\n",
      "Cost on val dataset after 1165 epochs is = 0.08272047176440747\n",
      "Initial Cost on Val dataset for this epoch 1165 = 0.08272047176440747\n",
      "learning rate for this epoch =  0.08558320040383566\n",
      "Error on this batch = 0.03209000599808388\n",
      "Error on this batch = 0.05795113548345471\n",
      "Cost on val dataset after 1166 epochs is = 0.0827093996396696\n",
      "Initial Cost on Val dataset for this epoch 1166 = 0.0827093996396696\n",
      "learning rate for this epoch =  0.08556484475658087\n",
      "Error on this batch = 0.032073938149433934\n",
      "Error on this batch = 0.05792644664681088\n",
      "Cost on val dataset after 1167 epochs is = 0.08269834664198691\n",
      "Initial Cost on Val dataset for this epoch 1167 = 0.08269834664198691\n",
      "learning rate for this epoch =  0.08554650877679544\n",
      "Error on this batch = 0.032057893663695505\n",
      "Error on this batch = 0.05790178024986704\n",
      "Cost on val dataset after 1168 epochs is = 0.08268731271761758\n",
      "Initial Cost on Val dataset for this epoch 1168 = 0.08268731271761758\n",
      "learning rate for this epoch =  0.08552819242658037\n",
      "Error on this batch = 0.032041872516188105\n",
      "Error on this batch = 0.05787713623839398\n",
      "Cost on val dataset after 1169 epochs is = 0.08267629781294193\n",
      "Initial Cost on Val dataset for this epoch 1169 = 0.08267629781294193\n",
      "learning rate for this epoch =  0.08550989566814209\n",
      "Error on this batch = 0.032025874682214066\n",
      "Error on this batch = 0.05785251455841541\n",
      "Cost on val dataset after 1170 epochs is = 0.08266530187446763\n",
      "Initial Cost on Val dataset for this epoch 1170 = 0.08266530187446763\n",
      "learning rate for this epoch =  0.08549161846379197\n",
      "Error on this batch = 0.032009900137056804\n",
      "Error on this batch = 0.05782791515620943\n",
      "Cost on val dataset after 1171 epochs is = 0.08265432484883455\n",
      "Initial Cost on Val dataset for this epoch 1171 = 0.08265432484883455\n",
      "learning rate for this epoch =  0.08547336077594611\n",
      "Error on this batch = 0.03199394885597929\n",
      "Error on this batch = 0.05780333797830998\n",
      "Cost on val dataset after 1172 epochs is = 0.08264336668281964\n",
      "Initial Cost on Val dataset for this epoch 1172 = 0.08264336668281964\n",
      "learning rate for this epoch =  0.08545512256712481\n",
      "Error on this batch = 0.031978020814222595\n",
      "Error on this batch = 0.05777878297150766\n",
      "Cost on val dataset after 1173 epochs is = 0.08263242732334192\n",
      "Initial Cost on Val dataset for this epoch 1173 = 0.08263242732334192\n",
      "learning rate for this epoch =  0.08543690379995225\n",
      "Error on this batch = 0.03196211598700472\n",
      "Error on this batch = 0.057754250082850664\n",
      "Cost on val dataset after 1174 epochs is = 0.08262150671746737\n",
      "Initial Cost on Val dataset for this epoch 1174 = 0.08262150671746737\n",
      "learning rate for this epoch =  0.08541870443715613\n",
      "Error on this batch = 0.03194623434951967\n",
      "Error on this batch = 0.05772973925964514\n",
      "Cost on val dataset after 1175 epochs is = 0.08261060481241352\n",
      "Initial Cost on Val dataset for this epoch 1175 = 0.08261060481241352\n",
      "learning rate for this epoch =  0.08540052444156727\n",
      "Error on this batch = 0.0319303758769364\n",
      "Error on this batch = 0.057705250449455486\n",
      "Cost on val dataset after 1176 epochs is = 0.08259972155555435\n",
      "Initial Cost on Val dataset for this epoch 1176 = 0.08259972155555435\n",
      "learning rate for this epoch =  0.0853823637761192\n",
      "Error on this batch = 0.031914540544398344\n",
      "Error on this batch = 0.057680783600104285\n",
      "Cost on val dataset after 1177 epochs is = 0.0825888568944249\n",
      "Initial Cost on Val dataset for this epoch 1177 = 0.0825888568944249\n",
      "learning rate for this epoch =  0.08536422240384793\n",
      "Error on this batch = 0.03189872832702266\n",
      "Error on this batch = 0.057656338659672124\n",
      "Cost on val dataset after 1178 epochs is = 0.08257801077672598\n",
      "Initial Cost on Val dataset for this epoch 1178 = 0.08257801077672598\n",
      "learning rate for this epoch =  0.08534610028789137\n",
      "Error on this batch = 0.03188293919989995\n",
      "Error on this batch = 0.05763191557649689\n",
      "Cost on val dataset after 1179 epochs is = 0.0825671831503286\n",
      "Initial Cost on Val dataset for this epoch 1179 = 0.0825671831503286\n",
      "learning rate for this epoch =  0.08532799739148918\n",
      "Error on this batch = 0.03186717313809412\n",
      "Error on this batch = 0.05760751429917317\n",
      "Cost on val dataset after 1180 epochs is = 0.08255637396327874\n",
      "Initial Cost on Val dataset for this epoch 1180 = 0.08255637396327874\n",
      "learning rate for this epoch =  0.0853099136779822\n",
      "Error on this batch = 0.031851430116642036\n",
      "Error on this batch = 0.05758313477655109\n",
      "Cost on val dataset after 1181 epochs is = 0.08254558316380146\n",
      "Initial Cost on Val dataset for this epoch 1181 = 0.08254558316380146\n",
      "learning rate for this epoch =  0.08529184911081227\n",
      "Error on this batch = 0.03183571011055381\n",
      "Error on this batch = 0.057558776957735154\n",
      "Cost on val dataset after 1182 epochs is = 0.08253481070030563\n",
      "Initial Cost on Val dataset for this epoch 1182 = 0.08253481070030563\n",
      "learning rate for this epoch =  0.08527380365352172\n",
      "Error on this batch = 0.031820013094812895\n",
      "Error on this batch = 0.05753444079208271\n",
      "Cost on val dataset after 1183 epochs is = 0.08252405652138796\n",
      "Initial Cost on Val dataset for this epoch 1183 = 0.08252405652138796\n",
      "learning rate for this epoch =  0.08525577726975313\n",
      "Error on this batch = 0.03180433904437638\n",
      "Error on this batch = 0.05751012622920215\n",
      "Cost on val dataset after 1184 epochs is = 0.08251332057583748\n",
      "Initial Cost on Val dataset for this epoch 1184 = 0.08251332057583748\n",
      "learning rate for this epoch =  0.08523776992324884\n",
      "Error on this batch = 0.0317886879341754\n",
      "Error on this batch = 0.05748583321895108\n",
      "Cost on val dataset after 1185 epochs is = 0.08250260281263959\n",
      "Initial Cost on Val dataset for this epoch 1185 = 0.08250260281263959\n",
      "learning rate for this epoch =  0.08521978157785072\n",
      "Error on this batch = 0.03177305973911584\n",
      "Error on this batch = 0.05746156171143401\n",
      "Cost on val dataset after 1186 epochs is = 0.0824919031809802\n",
      "Initial Cost on Val dataset for this epoch 1186 = 0.0824919031809802\n",
      "learning rate for this epoch =  0.08520181219749971\n",
      "Error on this batch = 0.03175745443407879\n",
      "Error on this batch = 0.057437311656999966\n",
      "Cost on val dataset after 1187 epochs is = 0.08248122163024985\n",
      "Initial Cost on Val dataset for this epoch 1187 = 0.08248122163024985\n",
      "learning rate for this epoch =  0.08518386174623557\n",
      "Error on this batch = 0.03174187199392162\n",
      "Error on this batch = 0.05741308300623991\n",
      "Cost on val dataset after 1188 epochs is = 0.08247055811004751\n",
      "Initial Cost on Val dataset for this epoch 1188 = 0.08247055811004751\n",
      "learning rate for this epoch =  0.0851659301881964\n",
      "Error on this batch = 0.03172631239347864\n",
      "Error on this batch = 0.05738887570998394\n",
      "Cost on val dataset after 1189 epochs is = 0.08245991257018474\n",
      "Initial Cost on Val dataset for this epoch 1189 = 0.08245991257018474\n",
      "learning rate for this epoch =  0.0851480174876184\n",
      "Error on this batch = 0.031710775607562136\n",
      "Error on this batch = 0.05736468971929805\n",
      "Cost on val dataset after 1190 epochs is = 0.08244928496068914\n",
      "Initial Cost on Val dataset for this epoch 1190 = 0.08244928496068914\n",
      "learning rate for this epoch =  0.08513012360883546\n",
      "Error on this batch = 0.03169526161096362\n",
      "Error on this batch = 0.05734052498548108\n",
      "Cost on val dataset after 1191 epochs is = 0.08243867523180844\n",
      "Initial Cost on Val dataset for this epoch 1191 = 0.08243867523180844\n",
      "learning rate for this epoch =  0.08511224851627883\n",
      "Error on this batch = 0.03167977037845489\n",
      "Error on this batch = 0.05731638146006115\n",
      "Cost on val dataset after 1192 epochs is = 0.0824280833340139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost on Val dataset for this epoch 1192 = 0.0824280833340139\n",
      "learning rate for this epoch =  0.08509439217447677\n",
      "Error on this batch = 0.03166430188478931\n",
      "Error on this batch = 0.05729225909479205\n",
      "Cost on val dataset after 1193 epochs is = 0.08241750921800405\n",
      "Initial Cost on Val dataset for this epoch 1193 = 0.08241750921800405\n",
      "learning rate for this epoch =  0.08507655454805418\n",
      "Error on this batch = 0.03164885610470324\n",
      "Error on this batch = 0.05726815784164934\n",
      "Cost on val dataset after 1194 epochs is = 0.08240695283470806\n",
      "Initial Cost on Val dataset for this epoch 1194 = 0.08240695283470806\n",
      "learning rate for this epoch =  0.08505873560173234\n",
      "Error on this batch = 0.03163343301291743\n",
      "Error on this batch = 0.05724407765282646\n",
      "Cost on val dataset after 1195 epochs is = 0.08239641413528927\n",
      "Initial Cost on Val dataset for this epoch 1195 = 0.08239641413528927\n",
      "learning rate for this epoch =  0.08504093530032843\n",
      "Error on this batch = 0.031618032584138575\n",
      "Error on this batch = 0.057220018480730356\n",
      "Cost on val dataset after 1196 epochs is = 0.0823858930711484\n",
      "Initial Cost on Val dataset for this epoch 1196 = 0.0823858930711484\n",
      "learning rate for this epoch =  0.08502315360875533\n",
      "Error on this batch = 0.03160265479306088\n",
      "Error on this batch = 0.05719598027797719\n",
      "Cost on val dataset after 1197 epochs is = 0.0823753895939268\n",
      "Initial Cost on Val dataset for this epoch 1197 = 0.0823753895939268\n",
      "learning rate for this epoch =  0.08500539049202116\n",
      "Error on this batch = 0.0315872996143677\n",
      "Error on this batch = 0.05717196299738781\n",
      "Cost on val dataset after 1198 epochs is = 0.08236490365550979\n",
      "Initial Cost on Val dataset for this epoch 1198 = 0.08236490365550979\n",
      "learning rate for this epoch =  0.08498764591522903\n",
      "Error on this batch = 0.03157196702273333\n",
      "Error on this batch = 0.05714796659198296\n",
      "Cost on val dataset after 1199 epochs is = 0.08235443520802938\n",
      "Initial Cost on Val dataset for this epoch 1199 = 0.08235443520802938\n",
      "learning rate for this epoch =  0.08496991984357669\n",
      "Error on this batch = 0.03155665699282466\n",
      "Error on this batch = 0.05712399101497843\n",
      "Cost on val dataset after 1200 epochs is = 0.08234398420386768\n",
      "Initial Cost on Val dataset for this epoch 1200 = 0.08234398420386768\n",
      "learning rate for this epoch =  0.08495221224235612\n",
      "Error on this batch = 0.031541369499303126\n",
      "Error on this batch = 0.057100036219780013\n",
      "Cost on val dataset after 1201 epochs is = 0.08233355059565942\n",
      "Initial Cost on Val dataset for this epoch 1201 = 0.08233355059565942\n",
      "learning rate for this epoch =  0.08493452307695332\n",
      "Error on this batch = 0.03152610451682649\n",
      "Error on this batch = 0.0570761021599784\n",
      "Cost on val dataset after 1202 epochs is = 0.08232313433629496\n",
      "Initial Cost on Val dataset for this epoch 1202 = 0.08232313433629496\n",
      "learning rate for this epoch =  0.08491685231284785\n",
      "Error on this batch = 0.03151086202005081\n",
      "Error on this batch = 0.05705218878934368\n",
      "Cost on val dataset after 1203 epochs is = 0.08231273537892292\n",
      "Initial Cost on Val dataset for this epoch 1203 = 0.08231273537892292\n",
      "learning rate for this epoch =  0.08489919991561257\n",
      "Error on this batch = 0.03149564198363237\n",
      "Error on this batch = 0.057028296061820076\n",
      "Cost on val dataset after 1204 epochs is = 0.08230235367695293\n",
      "Initial Cost on Val dataset for this epoch 1204 = 0.08230235367695293\n",
      "learning rate for this epoch =  0.08488156585091333\n",
      "Error on this batch = 0.03148044438222963\n",
      "Error on this batch = 0.05700442393152014\n",
      "Cost on val dataset after 1205 epochs is = 0.08229198918405808\n",
      "Initial Cost on Val dataset for this epoch 1205 = 0.08229198918405808\n",
      "learning rate for this epoch =  0.0848639500845086\n",
      "Error on this batch = 0.03146526919050538\n",
      "Error on this batch = 0.0569805723527193\n",
      "Cost on val dataset after 1206 epochs is = 0.08228164185417727\n",
      "Initial Cost on Val dataset for this epoch 1206 = 0.08228164185417727\n",
      "learning rate for this epoch =  0.08484635258224914\n",
      "Error on this batch = 0.031450116383128675\n",
      "Error on this batch = 0.05695674127984967\n",
      "Cost on val dataset after 1207 epochs is = 0.08227131164151784\n",
      "Initial Cost on Val dataset for this epoch 1207 = 0.08227131164151784\n",
      "learning rate for this epoch =  0.08482877331007768\n",
      "Error on this batch = 0.03143498593477688\n",
      "Error on this batch = 0.05693293066749437\n",
      "Cost on val dataset after 1208 epochs is = 0.08226099850055758\n",
      "Initial Cost on Val dataset for this epoch 1208 = 0.08226099850055758\n",
      "learning rate for this epoch =  0.08481121223402864\n",
      "Error on this batch = 0.03141987782013793\n",
      "Error on this batch = 0.05690914047038139\n",
      "Cost on val dataset after 1209 epochs is = 0.08225070238604716\n",
      "Initial Cost on Val dataset for this epoch 1209 = 0.08225070238604716\n",
      "learning rate for this epoch =  0.08479366932022776\n",
      "Error on this batch = 0.03140479201391224\n",
      "Error on this batch = 0.05688537064337726\n",
      "Cost on val dataset after 1210 epochs is = 0.08224042325301197\n",
      "Initial Cost on Val dataset for this epoch 1210 = 0.08224042325301197\n",
      "learning rate for this epoch =  0.08477614453489178\n",
      "Error on this batch = 0.03138972849081496\n",
      "Error on this batch = 0.056861621141481\n",
      "Cost on val dataset after 1211 epochs is = 0.0822301610567543\n",
      "Initial Cost on Val dataset for this epoch 1211 = 0.0822301610567543\n",
      "learning rate for this epoch =  0.08475863784432815\n",
      "Error on this batch = 0.03137468722557801\n",
      "Error on this batch = 0.05683789191981761\n",
      "Cost on val dataset after 1212 epochs is = 0.08221991575285528\n",
      "Initial Cost on Val dataset for this epoch 1212 = 0.08221991575285528\n",
      "learning rate for this epoch =  0.08474114921493468\n",
      "Error on this batch = 0.03135966819295232\n",
      "Error on this batch = 0.056814182933631656\n",
      "Cost on val dataset after 1213 epochs is = 0.08220968729717656\n",
      "Initial Cost on Val dataset for this epoch 1213 = 0.08220968729717656\n",
      "learning rate for this epoch =  0.08472367861319927\n",
      "Error on this batch = 0.031344671367709846\n",
      "Error on this batch = 0.05679049413828079\n",
      "Cost on val dataset after 1214 epochs is = 0.08219947564586222\n",
      "Initial Cost on Val dataset for this epoch 1214 = 0.08219947564586222\n",
      "learning rate for this epoch =  0.0847062260056995\n",
      "Error on this batch = 0.031329696724645764\n",
      "Error on this batch = 0.05676682548922907\n",
      "Cost on val dataset after 1215 epochs is = 0.08218928075534028\n",
      "Initial Cost on Val dataset for this epoch 1215 = 0.08218928075534028\n",
      "learning rate for this epoch =  0.08468879135910246\n",
      "Error on this batch = 0.03131474423858059\n",
      "Error on this batch = 0.05674317694204035\n",
      "Cost on val dataset after 1216 epochs is = 0.08217910258232443\n",
      "Initial Cost on Val dataset for this epoch 1216 = 0.08217910258232443\n",
      "learning rate for this epoch =  0.08467137464016429\n",
      "Error on this batch = 0.0312998138843623\n",
      "Error on this batch = 0.056719548452371565\n",
      "Cost on val dataset after 1217 epochs is = 0.08216894108381535\n",
      "Initial Cost on Val dataset for this epoch 1217 = 0.08216894108381535\n",
      "learning rate for this epoch =  0.08465397581572995\n",
      "Error on this batch = 0.03128490563686834\n",
      "Error on this batch = 0.05669593997596588\n",
      "Cost on val dataset after 1218 epochs is = 0.08215879621710219\n",
      "Initial Cost on Val dataset for this epoch 1218 = 0.08215879621710219\n",
      "learning rate for this epoch =  0.08463659485273294\n",
      "Error on this batch = 0.03127001947100784\n",
      "Error on this batch = 0.056672351468645916\n",
      "Cost on val dataset after 1219 epochs is = 0.08214866793976386\n",
      "Initial Cost on Val dataset for this epoch 1219 = 0.08214866793976386\n",
      "learning rate for this epoch =  0.0846192317181949\n",
      "Error on this batch = 0.03125515536172365\n",
      "Error on this batch = 0.05664878288630687\n",
      "Cost on val dataset after 1220 epochs is = 0.08213855620967037\n",
      "Initial Cost on Val dataset for this epoch 1220 = 0.08213855620967037\n",
      "learning rate for this epoch =  0.08460188637922533\n",
      "Error on this batch = 0.03124031328399428\n",
      "Error on this batch = 0.05662523418490961\n",
      "Cost on val dataset after 1221 epochs is = 0.08212846098498372\n",
      "Initial Cost on Val dataset for this epoch 1221 = 0.08212846098498372\n",
      "learning rate for this epoch =  0.08458455880302138\n",
      "Error on this batch = 0.031225493212836044\n",
      "Error on this batch = 0.05660170532047377\n",
      "Cost on val dataset after 1222 epochs is = 0.08211838222415925\n",
      "Initial Cost on Val dataset for this epoch 1222 = 0.08211838222415925\n",
      "learning rate for this epoch =  0.08456724895686739\n",
      "Error on this batch = 0.03121069512330499\n",
      "Error on this batch = 0.0565781962490707\n",
      "Cost on val dataset after 1223 epochs is = 0.08210831988594637\n",
      "Initial Cost on Val dataset for this epoch 1223 = 0.08210831988594637\n",
      "learning rate for this epoch =  0.08454995680813471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.031195918990498842\n",
      "Error on this batch = 0.056554706926816606\n",
      "Cost on val dataset after 1224 epochs is = 0.08209827392938956\n",
      "Initial Cost on Val dataset for this epoch 1224 = 0.08209827392938956\n",
      "learning rate for this epoch =  0.08453268232428135\n",
      "Error on this batch = 0.031181164789558992\n",
      "Error on this batch = 0.05653123730986552\n",
      "Cost on val dataset after 1225 epochs is = 0.0820882443138293\n",
      "Initial Cost on Val dataset for this epoch 1225 = 0.0820882443138293\n",
      "learning rate for this epoch =  0.08451542547285165\n",
      "Error on this batch = 0.031166432495672344\n",
      "Error on this batch = 0.05650778735440229\n",
      "Cost on val dataset after 1226 epochs is = 0.08207823099890256\n",
      "Initial Cost on Val dataset for this epoch 1226 = 0.08207823099890256\n",
      "learning rate for this epoch =  0.08449818622147606\n",
      "Error on this batch = 0.031151722084073165\n",
      "Error on this batch = 0.05648435701663568\n",
      "Cost on val dataset after 1227 epochs is = 0.08206823394454364\n",
      "Initial Cost on Val dataset for this epoch 1227 = 0.08206823394454364\n",
      "learning rate for this epoch =  0.08448096453787077\n",
      "Error on this batch = 0.03113703353004488\n",
      "Error on this batch = 0.05646094625279126\n",
      "Cost on val dataset after 1228 epochs is = 0.0820582531109847\n",
      "Initial Cost on Val dataset for this epoch 1228 = 0.0820582531109847\n",
      "learning rate for this epoch =  0.08446376038983743\n",
      "Error on this batch = 0.03112236680892192\n",
      "Error on this batch = 0.05643755501910462\n",
      "Cost on val dataset after 1229 epochs is = 0.08204828845875617\n",
      "Initial Cost on Val dataset for this epoch 1229 = 0.08204828845875617\n",
      "learning rate for this epoch =  0.08444657374526286\n",
      "Error on this batch = 0.03110772189609133\n",
      "Error on this batch = 0.05641418327181434\n",
      "Cost on val dataset after 1230 epochs is = 0.08203833994868735\n",
      "Initial Cost on Val dataset for this epoch 1230 = 0.08203833994868735\n",
      "learning rate for this epoch =  0.08442940457211878\n",
      "Error on this batch = 0.031093098766994554\n",
      "Error on this batch = 0.05639083096715506\n",
      "Cost on val dataset after 1231 epochs is = 0.08202840754190657\n",
      "Initial Cost on Val dataset for this epoch 1231 = 0.08202840754190657\n",
      "learning rate for this epoch =  0.0844122528384615\n",
      "Error on this batch = 0.031078497397128972\n",
      "Error on this batch = 0.05636749806135073\n",
      "Cost on val dataset after 1232 epochs is = 0.08201849119984153\n",
      "Initial Cost on Val dataset for this epoch 1232 = 0.08201849119984153\n",
      "learning rate for this epoch =  0.08439511851243159\n",
      "Error on this batch = 0.031063917762049514\n",
      "Error on this batch = 0.0563441845106076\n",
      "Cost on val dataset after 1233 epochs is = 0.08200859088421966\n",
      "Initial Cost on Val dataset for this epoch 1233 = 0.08200859088421966\n",
      "learning rate for this epoch =  0.08437800156225363\n",
      "Error on this batch = 0.031049359837370206\n",
      "Error on this batch = 0.056320890271107635\n",
      "Cost on val dataset after 1234 epochs is = 0.08199870655706795\n",
      "Initial Cost on Val dataset for this epoch 1234 = 0.08199870655706795\n",
      "learning rate for this epoch =  0.08436090195623593\n",
      "Error on this batch = 0.031034823598765575\n",
      "Error on this batch = 0.056297615299001666\n",
      "Cost on val dataset after 1235 epochs is = 0.08198883818071322\n",
      "Initial Cost on Val dataset for this epoch 1235 = 0.08198883818071322\n",
      "learning rate for this epoch =  0.08434381966277021\n",
      "Error on this batch = 0.03102030902197206\n",
      "Error on this batch = 0.056274359550402706\n",
      "Cost on val dataset after 1236 epochs is = 0.08197898571778207\n",
      "cost initial= 0.08198883818071322 , cost final=0.08197898571778207 , change in cost= -9.852462931142503e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 100 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 1236\n",
      "The training time = 249.345sec\n",
      "The training accuracy is = 95.719%\n",
      "The validation accuracy is = 90.769%\n",
      "The test accuracy is = 89.631%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []\n",
    "\n",
    "lr0=0.5\n",
    "\n",
    "for i in range(len(arch_test)):\n",
    "    theta = theta_init(n, r, [arch_test[i]], 'normal')\n",
    "    #print(theta[0].shape, theta[1].shape, theta[2].shape)\n",
    "    print(\"Training the network with {} hidden layer with {} units\".format(len([arch_test[i]]), arch_test[i]))\n",
    "    print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "    for j in range(len(theta)):\n",
    "        print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "\n",
    "    start = time.time()\n",
    "    epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr0, 'sigmoid', 'adaptive')\n",
    "    epochs.append(epoch)\n",
    "    train_time.append(time.time()-start)\n",
    "    train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "    valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "    test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "    print(\"\\n------------------------------------------------------------------------------\")\n",
    "    print(\"The stats for number of units in the hidden layer = {} are as below:\".format(arch_test[i]))\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"The number of epochs = {}\".format(epochs[-1]))\n",
    "    print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "    print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "    print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "    print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "    print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph for 100 hidden units with different adaptive strategy\n",
    "#lr0=1.5\n",
    "data = [' ', '1.5/ep^1/2',' ','1.5/ep^1/3',' ', '1.5/ep^1/4', ' ','0.5/ep^1/2', ' ', '0.5/ep^1/3']\n",
    "train_acc = [94.15, 96.5, 97.18, 90, 95.72]\n",
    "valid_acc =[90.72, 91.69, 92, 86.72, 90.77]\n",
    "test_acc = [89.34, 90.23, 90.54, 85.91, 89.63]\n",
    "epoch = [1189, 782, 602, 2014, 1236]\n",
    "tt=[240, 158, 118, 404, 250]\n",
    "x = [0,1,2, 3, 4]\n",
    "fig, ax = plt.subplots()\n",
    "color = 'k'\n",
    "ax.plot(x, train_acc, marker='o', label='train accuracy')\n",
    "ax.plot(x, valid_acc, marker='o', label='validation acc')\n",
    "ax.plot(x, test_acc, marker='o', label='test accuracy')\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_xlabel(\"Adaptive Learning Rate Degradation Policy\")\n",
    "ax.set_ylabel(\"Accuracy(%)\", color=color)\n",
    "ax.tick_params(axis='y', labelcolor=color, labelsize=12)\n",
    "ax.legend()\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Number of Epochs\")\n",
    "ax2.plot(x, epoch, marker='o', color='m',label='Epochs')\n",
    "ax2.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "\n",
    "plt.title(\"Accuracy, Epochs and Train Time Comparison with\\n different adaptive policy for learning rate\")\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/partc/comp_diff_adapt_policy.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------Plotting Graphs for Part C - Adaptive LR - One Hidden Layer ------------------\")\n",
    "\n",
    "plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy)\n",
    "plot_epoch(arch_test, epochs, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D - Implementation of ReLU activation for Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with Sigmoid activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with Sigmoid activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.1084319069066533\n",
      "learning rate for this epoch =  1.5\n",
      "Error on this batch = 3.105085413414887\n",
      "Error on this batch = 0.4823481805754147\n",
      "Cost on val dataset after 2 epochs is = 0.4809383266898471\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4809383266898471\n",
      "learning rate for this epoch =  1.2613446228805718\n",
      "Error on this batch = 0.48039747864428967\n",
      "Error on this batch = 0.48118250278903046\n",
      "Cost on val dataset after 3 epochs is = 0.48076510420032326\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48076510420032326\n",
      "learning rate for this epoch =  1.139753528477389\n",
      "Error on this batch = 0.4809767671584032\n",
      "Error on this batch = 0.4810991593707293\n",
      "Cost on val dataset after 4 epochs is = 0.4807049036174829\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4807049036174829\n",
      "learning rate for this epoch =  1.0606601717798212\n",
      "Error on this batch = 0.4809149775234909\n",
      "Error on this batch = 0.48102222156703706\n",
      "Cost on val dataset after 5 epochs is = 0.48064816133383925\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48064816133383925\n",
      "learning rate for this epoch =  1.003110457464633\n",
      "Error on this batch = 0.48083957090943175\n",
      "Error on this batch = 0.4809504862080865\n",
      "Cost on val dataset after 6 epochs is = 0.48059165100390044\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.48059165100390044\n",
      "learning rate for this epoch =  0.9584146563694087\n",
      "Error on this batch = 0.48076743168841907\n",
      "Error on this batch = 0.48088068919093274\n",
      "Cost on val dataset after 7 epochs is = 0.4805339343038334\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4805339343038334\n",
      "learning rate for this epoch =  0.9221822294268966\n",
      "Error on this batch = 0.4806962058067773\n",
      "Error on this batch = 0.4808105714999462\n",
      "Cost on val dataset after 8 epochs is = 0.4804738885321809\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4804738885321809\n",
      "learning rate for this epoch =  0.8919053362520408\n",
      "Error on this batch = 0.4806239085031565\n",
      "Error on this batch = 0.480738390673351\n",
      "Cost on val dataset after 9 epochs is = 0.4804104785814625\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4804104785814625\n",
      "learning rate for this epoch =  0.8660254037844387\n",
      "Error on this batch = 0.48054896421595106\n",
      "Error on this batch = 0.48066259983397513\n",
      "Cost on val dataset after 10 epochs is = 0.4803426485393613\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4803426485393613\n",
      "learning rate for this epoch =  0.8435119877855236\n",
      "Error on this batch = 0.48046994436026863\n",
      "Error on this batch = 0.4805816642789172\n",
      "Cost on val dataset after 11 epochs is = 0.48026924470647564\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48026924470647564\n",
      "learning rate for this epoch =  0.8236507301641687\n",
      "Error on this batch = 0.4803854058684975\n",
      "Error on this batch = 0.4804939312353676\n",
      "Cost on val dataset after 12 epochs is = 0.4801889446358353\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4801889446358353\n",
      "learning rate for this epoch =  0.8059274488676564\n",
      "Error on this batch = 0.48029377297081083\n",
      "Error on this batch = 0.4803975127180964\n",
      "Cost on val dataset after 13 epochs is = 0.4801001786444272\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4801001786444272\n",
      "learning rate for this epoch =  0.7899605817718899\n",
      "Error on this batch = 0.48019322707042195\n",
      "Error on this batch = 0.48029015802157193\n",
      "Cost on val dataset after 14 epochs is = 0.4800010326579071\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4800010326579071\n",
      "learning rate for this epoch =  0.7754597309357558\n",
      "Error on this batch = 0.48008158283894053\n",
      "Error on this batch = 0.48016909625821386\n",
      "Cost on val dataset after 15 epochs is = 0.4798891196665044\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4798891196665044\n",
      "learning rate for this epoch =  0.7621991222319221\n",
      "Error on this batch = 0.4799561309647524\n",
      "Error on this batch = 0.48003082648926\n",
      "Cost on val dataset after 16 epochs is = 0.4797614023136\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4797614023136\n",
      "learning rate for this epoch =  0.75\n",
      "Error on this batch = 0.47981342362453094\n",
      "Error on this batch = 0.47987082431853095\n",
      "Cost on val dataset after 17 epochs is = 0.47961394034989313\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.47961394034989313\n",
      "learning rate for this epoch =  0.7387185907581786\n",
      "Error on this batch = 0.47964896782394384\n",
      "Error on this batch = 0.4796831174961065\n",
      "Cost on val dataset after 18 epochs is = 0.4794415215203677\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.4794415215203677\n",
      "learning rate for this epoch =  0.7282376575609851\n",
      "Error on this batch = 0.4794567712653195\n",
      "Error on this batch = 0.47945965441399396\n",
      "Cost on val dataset after 19 epochs is = 0.47923710830876276\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.47923710830876276\n",
      "learning rate for this epoch =  0.718460438165362\n",
      "Error on this batch = 0.47922864835615686\n",
      "Error on this batch = 0.4791893391374339\n",
      "Cost on val dataset after 20 epochs is = 0.4789909871701474\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4789909871701474\n",
      "learning rate for this epoch =  0.7093062067523819\n",
      "Error on this batch = 0.47895312617146946\n",
      "Error on this batch = 0.47885651733600215\n",
      "Cost on val dataset after 21 epochs is = 0.4786894251151548\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.4786894251151548\n",
      "learning rate for this epoch =  0.7007069665923001\n",
      "Error on this batch = 0.4786136629847361\n",
      "Error on this batch = 0.47843853664541675\n",
      "Cost on val dataset after 22 epochs is = 0.4783124904574098\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4783124904574098\n",
      "learning rate for this epoch =  0.6926049464161539\n",
      "Error on this batch = 0.4781856473085571\n",
      "Error on this batch = 0.4779017151702556\n",
      "Cost on val dataset after 23 epochs is = 0.47783042755386407\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.47783042755386407\n",
      "learning rate for this epoch =  0.6849506782450969\n",
      "Error on this batch = 0.4776311678773496\n",
      "Error on this batch = 0.47719455026337515\n",
      "Cost on val dataset after 24 epochs is = 0.47719752063783816\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.47719752063783816\n",
      "learning rate for this epoch =  0.6777015027073837\n",
      "Error on this batch = 0.4768896314083462\n",
      "Error on this batch = 0.47623627527704204\n",
      "Cost on val dataset after 25 epochs is = 0.4763417844028367\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4763417844028367\n",
      "learning rate for this epoch =  0.6708203932499369\n",
      "Error on this batch = 0.47586078095918966\n",
      "Error on this batch = 0.4748986566892511\n",
      "Cost on val dataset after 26 epochs is = 0.47514907354503927\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.47514907354503927\n",
      "learning rate for this epoch =  0.6642750214037211\n",
      "Error on this batch = 0.47437570305513904\n",
      "Error on this batch = 0.4729840708836802\n",
      "Cost on val dataset after 27 epochs is = 0.4734472174242071\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.4734472174242071\n",
      "learning rate for this epoch =  0.6580370064762463\n",
      "Error on this batch = 0.4721615130333366\n",
      "Error on this batch = 0.47023363692686077\n",
      "Cost on val dataset after 28 epochs is = 0.4710303918047466\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4710303918047466\n",
      "learning rate for this epoch =  0.6520813079174872\n",
      "Error on this batch = 0.4688735503711655\n",
      "Error on this batch = 0.4664837734155142\n",
      "Cost on val dataset after 29 epochs is = 0.46782396035317886\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.46782396035317886\n",
      "learning rate for this epoch =  0.646385729188359\n",
      "Error on this batch = 0.464420347512774\n",
      "Error on this batch = 0.4620230453620053\n",
      "Cost on val dataset after 30 epochs is = 0.4640975041736982\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.4640975041736982\n",
      "learning rate for this epoch =  0.640930509594351\n",
      "Error on this batch = 0.4594323552533642\n",
      "Error on this batch = 0.4575445662104838\n",
      "Cost on val dataset after 31 epochs is = 0.46019804176239043\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.46019804176239043\n",
      "learning rate for this epoch =  0.6356979861225325\n",
      "Error on this batch = 0.45473822501509714\n",
      "Error on this batch = 0.4533952620904232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 0.45605264014794716\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.45605264014794716\n",
      "learning rate for this epoch =  0.6306723114402859\n",
      "Error on this batch = 0.45045095197689905\n",
      "Error on this batch = 0.4492656944832173\n",
      "Cost on val dataset after 33 epochs is = 0.4512489477382301\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.4512489477382301\n",
      "learning rate for this epoch =  0.625839217291726\n",
      "Error on this batch = 0.44620261038716974\n",
      "Error on this batch = 0.4445782195589397\n",
      "Cost on val dataset after 34 epochs is = 0.44564184837313564\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.44564184837313564\n",
      "learning rate for this epoch =  0.621185814849828\n",
      "Error on this batch = 0.44184765805803033\n",
      "Error on this batch = 0.4391761139884083\n",
      "Cost on val dataset after 35 epochs is = 0.4396755454545706\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.4396755454545706\n",
      "learning rate for this epoch =  0.6167004253507795\n",
      "Error on this batch = 0.43751842362258375\n",
      "Error on this batch = 0.43339692929782714\n",
      "Cost on val dataset after 36 epochs is = 0.43380657785499216\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.43380657785499216\n",
      "learning rate for this epoch =  0.6123724356957946\n",
      "Error on this batch = 0.43313165927666447\n",
      "Error on this batch = 0.42753902038092984\n",
      "Cost on val dataset after 37 epochs is = 0.428199088219367\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.428199088219367\n",
      "learning rate for this epoch =  0.6081921747581548\n",
      "Error on this batch = 0.42851802948604745\n",
      "Error on this batch = 0.42171627463488437\n",
      "Cost on val dataset after 38 epochs is = 0.42281576067601845\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.42281576067601845\n",
      "learning rate for this epoch =  0.604150806954866\n",
      "Error on this batch = 0.4236346216512159\n",
      "Error on this batch = 0.4158791311853209\n",
      "Cost on val dataset after 39 epochs is = 0.4175423356098994\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.4175423356098994\n",
      "learning rate for this epoch =  0.6002402402883749\n",
      "Error on this batch = 0.4185321245206267\n",
      "Error on this batch = 0.4099625552572762\n",
      "Cost on val dataset after 40 epochs is = 0.41232628199435456\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.41232628199435456\n",
      "learning rate for this epoch =  0.596453046575288\n",
      "Error on this batch = 0.4133296964611071\n",
      "Error on this batch = 0.4040094113851611\n",
      "Cost on val dataset after 41 epochs is = 0.40719259099711286\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.40719259099711286\n",
      "learning rate for this epoch =  0.5927823919866072\n",
      "Error on this batch = 0.40815218728572333\n",
      "Error on this batch = 0.3981072902898363\n",
      "Cost on val dataset after 42 epochs is = 0.40213827909818267\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.40213827909818267\n",
      "learning rate for this epoch =  0.5892219763507696\n",
      "Error on this batch = 0.4030044606550379\n",
      "Error on this batch = 0.39225870150581715\n",
      "Cost on val dataset after 43 epochs is = 0.39705839759751577\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.39705839759751577\n",
      "learning rate for this epoch =  0.5857659799342742\n",
      "Error on this batch = 0.39770477424615536\n",
      "Error on this batch = 0.38634735918633895\n",
      "Cost on val dataset after 44 epochs is = 0.3917557374575257\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.3917557374575257\n",
      "learning rate for this epoch =  0.5824090166283349\n",
      "Error on this batch = 0.3919012340874029\n",
      "Error on this batch = 0.380179173349732\n",
      "Cost on val dataset after 45 epochs is = 0.38596625198064816\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.38596625198064816\n",
      "learning rate for this epoch =  0.5791460926441345\n",
      "Error on this batch = 0.3850848529976513\n",
      "Error on this batch = 0.3735166650417161\n",
      "Cost on val dataset after 46 epochs is = 0.37937553642267074\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.37937553642267074\n",
      "learning rate for this epoch =  0.5759725699619024\n",
      "Error on this batch = 0.37660423093820755\n",
      "Error on this batch = 0.3661305985269003\n",
      "Cost on val dataset after 47 epochs is = 0.37175429696876977\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.37175429696876977\n",
      "learning rate for this epoch =  0.57288413389643\n",
      "Error on this batch = 0.3659809496404307\n",
      "Error on this batch = 0.3580445632621336\n",
      "Cost on val dataset after 48 epochs is = 0.3633458024531504\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.3633458024531504\n",
      "learning rate for this epoch =  0.5698767642386945\n",
      "Error on this batch = 0.3538637916730755\n",
      "Error on this batch = 0.34973818500022263\n",
      "Cost on val dataset after 49 epochs is = 0.3547868816934913\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.3547868816934913\n",
      "learning rate for this epoch =  0.5669467095138409\n",
      "Error on this batch = 0.3419446898682101\n",
      "Error on this batch = 0.3415692806797354\n",
      "Cost on val dataset after 50 epochs is = 0.3463149857216181\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.3463149857216181\n",
      "learning rate for this epoch =  0.564090463962959\n",
      "Error on this batch = 0.33097983354059485\n",
      "Error on this batch = 0.33342860334937685\n",
      "Cost on val dataset after 51 epochs is = 0.3377450253593379\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.3377450253593379\n",
      "learning rate for this epoch =  0.5613047469123187\n",
      "Error on this batch = 0.3206018054466264\n",
      "Error on this batch = 0.32510228681141234\n",
      "Cost on val dataset after 52 epochs is = 0.32889425673191014\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.32889425673191014\n",
      "learning rate for this epoch =  0.5585864842409736\n",
      "Error on this batch = 0.31035493069132525\n",
      "Error on this batch = 0.31652276450463523\n",
      "Cost on val dataset after 53 epochs is = 0.31976867325829733\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.31976867325829733\n",
      "learning rate for this epoch =  0.555932791697477\n",
      "Error on this batch = 0.30013148871872597\n",
      "Error on this batch = 0.30780207226611145\n",
      "Cost on val dataset after 54 epochs is = 0.31055414233165135\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.31055414233165135\n",
      "learning rate for this epoch =  0.5533409598501609\n",
      "Error on this batch = 0.2901363196841551\n",
      "Error on this batch = 0.29914701547272915\n",
      "Cost on val dataset after 55 epochs is = 0.30149661641234865\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.30149661641234865\n",
      "learning rate for this epoch =  0.5508084404840388\n",
      "Error on this batch = 0.2806620006389762\n",
      "Error on this batch = 0.29074057151887195\n",
      "Cost on val dataset after 56 epochs is = 0.2927697381204093\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.2927697381204093\n",
      "learning rate for this epoch =  0.5483328342817686\n",
      "Error on this batch = 0.2718969199393825\n",
      "Error on this batch = 0.2826737459114457\n",
      "Cost on val dataset after 57 epochs is = 0.28442243079760865\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.28442243079760865\n",
      "learning rate for this epoch =  0.5459118796469214\n",
      "Error on this batch = 0.26386889792617435\n",
      "Error on this batch = 0.27494780744574726\n",
      "Cost on val dataset after 58 epochs is = 0.2764128057666802\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.2764128057666802\n",
      "learning rate for this epoch =  0.5435434425456495\n",
      "Error on this batch = 0.25648734200037315\n",
      "Error on this batch = 0.2675188973979935\n",
      "Cost on val dataset after 59 epochs is = 0.26867149584264016\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.26867149584264016\n",
      "learning rate for this epoch =  0.541225507258161\n",
      "Error on this batch = 0.2496160281637356\n",
      "Error on this batch = 0.260335897816397\n",
      "Cost on val dataset after 60 epochs is = 0.26114240919408965\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.26114240919408965\n",
      "learning rate for this epoch =  0.5389561679446264\n",
      "Error on this batch = 0.24311671458837603\n",
      "Error on this batch = 0.2533526862345671\n",
      "Cost on val dataset after 61 epochs is = 0.25379608845632556\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.25379608845632556\n",
      "learning rate for this epoch =  0.5367336209415393\n",
      "Error on this batch = 0.23686389320039256\n",
      "Error on this batch = 0.24653278890344493\n",
      "Cost on val dataset after 62 epochs is = 0.2466322644825372\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.2466322644825372\n",
      "learning rate for this epoch =  0.5345561577144432\n",
      "Error on this batch = 0.23075762742590147\n",
      "Error on this batch = 0.2398584508693501\n",
      "Cost on val dataset after 63 epochs is = 0.23967864194622907\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.23967864194622907\n",
      "learning rate for this epoch =  0.532422158401508\n",
      "Error on this batch = 0.22474178341285808\n",
      "Error on this batch = 0.23333798237833356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 64 epochs is = 0.23298313644249063\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.23298313644249063\n",
      "learning rate for this epoch =  0.5303300858899106\n",
      "Error on this batch = 0.21881528826658056\n",
      "Error on this batch = 0.227001141762519\n",
      "Cost on val dataset after 65 epochs is = 0.22659852818519619\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.22659852818519619\n",
      "learning rate for this epoch =  0.5282784803734853\n",
      "Error on this batch = 0.2130221696171912\n",
      "Error on this batch = 0.2208823137722314\n",
      "Cost on val dataset after 66 epochs is = 0.22056638172768317\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.22056638172768317\n",
      "learning rate for this epoch =  0.5262659543458028\n",
      "Error on this batch = 0.20742334919948568\n",
      "Error on this batch = 0.21500305130109731\n",
      "Cost on val dataset after 67 epochs is = 0.21490882571508194\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.21490882571508194\n",
      "learning rate for this epoch =  0.5242911879878268\n",
      "Error on this batch = 0.20206927393166432\n",
      "Error on this batch = 0.20936551002529552\n",
      "Cost on val dataset after 68 epochs is = 0.209629592938142\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.209629592938142\n",
      "learning rate for this epoch =  0.522352924913678\n",
      "Error on this batch = 0.1969875147032716\n",
      "Error on this batch = 0.20395761257220094\n",
      "Cost on val dataset after 69 epochs is = 0.20471946177971825\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.20471946177971825\n",
      "learning rate for this epoch =  0.5204499682418865\n",
      "Error on this batch = 0.1921842771061388\n",
      "Error on this batch = 0.19876285564644158\n",
      "Cost on val dataset after 70 epochs is = 0.20016148816322332\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.20016148816322332\n",
      "learning rate for this epoch =  0.5185811769629115\n",
      "Error on this batch = 0.18765172036338512\n",
      "Error on this batch = 0.19376826082106666\n",
      "Cost on val dataset after 71 epochs is = 0.19593446444372697\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.19593446444372697\n",
      "learning rate for this epoch =  0.5167454625767091\n",
      "Error on this batch = 0.1833750596513519\n",
      "Error on this batch = 0.18896813287520148\n",
      "Cost on val dataset after 72 epochs is = 0.19201495455520204\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.19201495455520204\n",
      "learning rate for this epoch =  0.5149417859767794\n",
      "Error on this batch = 0.17933739143457467\n",
      "Error on this batch = 0.1843641607391574\n",
      "Cost on val dataset after 73 epochs is = 0.18837860243734106\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.18837860243734106\n",
      "learning rate for this epoch =  0.5131691545594822\n",
      "Error on this batch = 0.17552237013276492\n",
      "Error on this batch = 0.17996324385816104\n",
      "Cost on val dataset after 74 epochs is = 0.1850011224018073\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.1850011224018073\n",
      "learning rate for this epoch =  0.5114266195394931\n",
      "Error on this batch = 0.17191541130407578\n",
      "Error on this batch = 0.17577432141677854\n",
      "Cost on val dataset after 75 epochs is = 0.18185908557933445\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.18185908557933445\n",
      "learning rate for this epoch =  0.5097132734541368\n",
      "Error on this batch = 0.16850397636272405\n",
      "Error on this batch = 0.17180521631140672\n",
      "Cost on val dataset after 76 epochs is = 0.17893048748969828\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.17893048748969828\n",
      "learning rate for this epoch =  0.5080282478409857\n",
      "Error on this batch = 0.16527729897476562\n",
      "Error on this batch = 0.16806022592419345\n",
      "Cost on val dataset after 77 epochs is = 0.1761950797315672\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.1761950797315672\n",
      "learning rate for this epoch =  0.5063707110745895\n",
      "Error on this batch = 0.16222581723030222\n",
      "Error on this batch = 0.16453882999002978\n",
      "Cost on val dataset after 78 epochs is = 0.17363449270957051\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.17363449270957051\n",
      "learning rate for this epoch =  0.5047398663495227\n",
      "Error on this batch = 0.1593405402666328\n",
      "Error on this batch = 0.1612355004366886\n",
      "Cost on val dataset after 79 epochs is = 0.1712322093418629\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.1712322093418629\n",
      "learning rate for this epoch =  0.5031349497981186\n",
      "Error on this batch = 0.15661253059018482\n",
      "Error on this batch = 0.15814033022344048\n",
      "Cost on val dataset after 80 epochs is = 0.16897345386404175\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.16897345386404175\n",
      "learning rate for this epoch =  0.5015552287323165\n",
      "Error on this batch = 0.15403260295354684\n",
      "Error on this batch = 0.1552401107555174\n",
      "Cost on val dataset after 81 epochs is = 0.16684504397929173\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.16684504397929173\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 0.1515912525010305\n",
      "Error on this batch = 0.15251953625203654\n",
      "Cost on val dataset after 82 epochs is = 0.1648352341936303\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.1648352341936303\n",
      "learning rate for this epoch =  0.49846858844706027\n",
      "Error on this batch = 0.14927876051375727\n",
      "Error on this batch = 0.14996231906482124\n",
      "Cost on val dataset after 83 epochs is = 0.1629335628527869\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.1629335628527869\n",
      "learning rate for this epoch =  0.4969603454771852\n",
      "Error on this batch = 0.14708539903548368\n",
      "Error on this batch = 0.14755210430798704\n",
      "Cost on val dataset after 84 epochs is = 0.1611307072900504\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.1611307072900504\n",
      "learning rate for this epoch =  0.4954746477020711\n",
      "Error on this batch = 0.14500166056692898\n",
      "Error on this batch = 0.14527314945004746\n",
      "Cost on val dataset after 85 epochs is = 0.15941834867056862\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.15941834867056862\n",
      "learning rate for this epoch =  0.494010895675377\n",
      "Error on this batch = 0.14301846125210632\n",
      "Error on this batch = 0.14311078094515853\n",
      "Cost on val dataset after 86 epochs is = 0.15778904781826358\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.15778904781826358\n",
      "learning rate for this epoch =  0.4925685127043104\n",
      "Error on this batch = 0.14112729140839522\n",
      "Error on this batch = 0.1410516620541983\n",
      "Cost on val dataset after 87 epochs is = 0.1562361334947706\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.1562361334947706\n",
      "learning rate for this epoch =  0.4911469437332414\n",
      "Error on this batch = 0.1393203073382994\n",
      "Error on this batch = 0.13908391264384665\n",
      "Cost on val dataset after 88 epochs is = 0.15475360430010907\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.15475360430010907\n",
      "learning rate for this epoch =  0.48974565429420786\n",
      "Error on this batch = 0.13759037050638742\n",
      "Error on this batch = 0.13719712022240482\n",
      "Cost on val dataset after 89 epochs is = 0.1533360444948039\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1533360444948039\n",
      "learning rate for this epoch =  0.48836412951959424\n",
      "Error on this batch = 0.13593104549148344\n",
      "Error on this batch = 0.13538227633756833\n",
      "Cost on val dataset after 90 epochs is = 0.15197855297754903\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.15197855297754903\n",
      "learning rate for this epoch =  0.4870018732126484\n",
      "Error on this batch = 0.13433656902665678\n",
      "Error on this batch = 0.13363166614172592\n",
      "Cost on val dataset after 91 epochs is = 0.15067668381269134\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.15067668381269134\n",
      "learning rate for this epoch =  0.4856584069718464\n",
      "Error on this batch = 0.1328018010738919\n",
      "Error on this batch = 0.13193873261692388\n",
      "Cost on val dataset after 92 epochs is = 0.14942639630622145\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.14942639630622145\n",
      "learning rate for this epoch =  0.48433326936543303\n",
      "Error on this batch = 0.13132216665839308\n",
      "Error on this batch = 0.13029793124228647\n",
      "Cost on val dataset after 93 epochs is = 0.14822401265682683\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.14822401265682683\n",
      "learning rate for this epoch =  0.48302601515275106\n",
      "Error on this batch = 0.12989359486025343\n",
      "Error on this batch = 0.1287045860694805\n",
      "Cost on val dataset after 94 epochs is = 0.1470661815015367\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.1470661815015367\n",
      "learning rate for this epoch =  0.48173621454923704\n",
      "Error on this batch = 0.1285124592726133\n",
      "Error on this batch = 0.12715475433196877\n",
      "Cost on val dataset after 95 epochs is = 0.14594984605977757\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.14594984605977757\n",
      "learning rate for this epoch =  0.48046345253219797\n",
      "Error on this batch = 0.12717552252509334\n",
      "Error on this batch = 0.12564510379652893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 96 epochs is = 0.1448722159368305\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.1448722159368305\n",
      "learning rate for this epoch =  0.47920732818470435\n",
      "Error on this batch = 0.12587988617927037\n",
      "Error on this batch = 0.12417280493681077\n",
      "Cost on val dataset after 97 epochs is = 0.1438307419264598\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.1438307419264598\n",
      "learning rate for this epoch =  0.4779674540751329\n",
      "Error on this batch = 0.12462294641071239\n",
      "Error on this batch = 0.1227354385088559\n",
      "Cost on val dataset after 98 epochs is = 0.14282309334825377\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.14282309334825377\n",
      "learning rate for this epoch =  0.4767434556700778\n",
      "Error on this batch = 0.1234023553410642\n",
      "Error on this batch = 0.12133091808815052\n",
      "Cost on val dataset after 99 epochs is = 0.1418471375843856\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.1418471375843856\n",
      "learning rate for this epoch =  0.4755349707785146\n",
      "Error on this batch = 0.12221598759266002\n",
      "Error on this batch = 0.11995742646501478\n",
      "Cost on val dataset after 100 epochs is = 0.1409009215631355\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.1409009215631355\n",
      "learning rate for this epoch =  0.4743416490252569\n",
      "Error on this batch = 0.12106191152177898\n",
      "Error on this batch = 0.11861336439830406\n",
      "Cost on val dataset after 101 epochs is = 0.13998265498879872\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.13998265498879872\n",
      "learning rate for this epoch =  0.47316315135188575\n",
      "Error on this batch = 0.11993836457097815\n",
      "Error on this batch = 0.11729731003007317\n",
      "Cost on val dataset after 102 epochs is = 0.13909069515062153\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.13909069515062153\n",
      "learning rate for this epoch =  0.4719991495434624\n",
      "Error on this batch = 0.11884373221204332\n",
      "Error on this batch = 0.11600798721718081\n",
      "Cost on val dataset after 103 epochs is = 0.13822353316439415\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.13822353316439415\n",
      "learning rate for this epoch =  0.4708493257794535\n",
      "Error on this batch = 0.11777652999671709\n",
      "Error on this batch = 0.11474424110166478\n",
      "Cost on val dataset after 104 epochs is = 0.13737978151415042\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.13737978151415042\n",
      "learning rate for this epoch =  0.46971337220741016\n",
      "Error on this batch = 0.11673538827797413\n",
      "Error on this batch = 0.11350501938811623\n",
      "Cost on val dataset after 105 epochs is = 0.1365581627715221\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.1365581627715221\n",
      "learning rate for this epoch =  0.4685909905380384\n",
      "Error on this batch = 0.11571903920727643\n",
      "Error on this batch = 0.11228935799511373\n",
      "Cost on val dataset after 106 epochs is = 0.13575749937906656\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.13575749937906656\n",
      "learning rate for this epoch =  0.4674818916603984\n",
      "Error on this batch = 0.11472630565538508\n",
      "Error on this batch = 0.11109636997420605\n",
      "Cost on val dataset after 107 epochs is = 0.13497670439283432\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.13497670439283432\n",
      "learning rate for this epoch =  0.46638579527605073\n",
      "Error on this batch = 0.11375609174909873\n",
      "Error on this batch = 0.10992523682250624\n",
      "Cost on val dataset after 108 epochs is = 0.13421477308925178\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.13421477308925178\n",
      "learning rate for this epoch =  0.4653024295510498\n",
      "Error on this batch = 0.112807374764965\n",
      "Error on this batch = 0.10877520153590135\n",
      "Cost on val dataset after 109 epochs is = 0.13347077535206342\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.13347077535206342\n",
      "learning rate for this epoch =  0.4642315307847573\n",
      "Error on this batch = 0.11187919817197127\n",
      "Error on this batch = 0.10764556294518567\n",
      "Cost on val dataset after 110 epochs is = 0.13274384876611656\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.13274384876611656\n",
      "learning rate for this epoch =  0.46317284309451723\n",
      "Error on this batch = 0.11097066566439635\n",
      "Error on this batch = 0.10653567103683446\n",
      "Cost on val dataset after 111 epochs is = 0.1320331923554129\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.1320331923554129\n",
      "learning rate for this epoch =  0.46212611811529575\n",
      "Error on this batch = 0.11008093606801948\n",
      "Error on this batch = 0.10544492307718713\n",
      "Cost on val dataset after 112 epochs is = 0.13133806091228398\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.13133806091228398\n",
      "learning rate for this epoch =  0.4610911147134483\n",
      "Error on this batch = 0.10920921903253678\n",
      "Error on this batch = 0.10437276043106099\n",
      "Cost on val dataset after 113 epochs is = 0.13065775987212677\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.13065775987212677\n",
      "learning rate for this epoch =  0.4600675987138297\n",
      "Error on this batch = 0.10835477143693117\n",
      "Error on this batch = 0.10331866599526386\n",
      "Cost on val dataset after 114 epochs is = 0.1299916406935346\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.1299916406935346\n",
      "learning rate for this epoch =  0.4590553426395135\n",
      "Error on this batch = 0.10751689443233757\n",
      "Error on this batch = 0.1022821621608956\n",
      "Cost on val dataset after 115 epochs is = 0.12933909670696764\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.12933909670696764\n",
      "learning rate for this epoch =  0.4580541254634332\n",
      "Error on this batch = 0.10669493103202266\n",
      "Error on this batch = 0.10126280918713701\n",
      "Cost on val dataset after 116 epochs is = 0.12869955939676747\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.12869955939676747\n",
      "learning rate for this epoch =  0.4570637323713\n",
      "Error on this batch = 0.10588826413714174\n",
      "Error on this batch = 0.10026020382832666\n",
      "Cost on val dataset after 117 epochs is = 0.1280724950820051\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.1280724950820051\n",
      "learning rate for this epoch =  0.456083954535194\n",
      "Error on this batch = 0.10509631486841305\n",
      "Error on this batch = 0.09927397802162893\n",
      "Cost on val dataset after 118 epochs is = 0.1274574019620209\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.1274574019620209\n",
      "learning rate for this epoch =  0.45511458889726086\n",
      "Error on this batch = 0.10431854106567034\n",
      "Error on this batch = 0.09830379742858308\n",
      "Cost on val dataset after 119 epochs is = 0.126853807493037\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.126853807493037\n",
      "learning rate for this epoch =  0.4541554379629815\n",
      "Error on this batch = 0.10355443582437665\n",
      "Error on this batch = 0.097349359639096\n",
      "Cost on val dataset after 120 epochs is = 0.12626126606308594\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.12626126606308594\n",
      "learning rate for this epoch =  0.4532063096035152\n",
      "Error on this batch = 0.1028035259611261\n",
      "Error on this batch = 0.09641039189228107\n",
      "Cost on val dataset after 121 epochs is = 0.1256793569336697\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.1256793569336697\n",
      "learning rate for this epoch =  0.45226701686664544\n",
      "Error on this batch = 0.10206537033500475\n",
      "Error on this batch = 0.09548664823848575\n",
      "Cost on val dataset after 122 epochs is = 0.12510768241793385\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.12510768241793385\n",
      "learning rate for this epoch =  0.4513373777958864\n",
      "Error on this batch = 0.10133955799160008\n",
      "Error on this batch = 0.09457790614860441\n",
      "Cost on val dataset after 123 epochs is = 0.12454586626666417\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.12454586626666417\n",
      "learning rate for this epoch =  0.4504172152573348\n",
      "Error on this batch = 0.10062570613402574\n",
      "Error on this batch = 0.09368396265576251\n",
      "Cost on val dataset after 124 epochs is = 0.1239935522351462\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.1239935522351462\n",
      "learning rate for this epoch =  0.4495063567738745\n",
      "Error on this batch = 0.09992345795474722\n",
      "Error on this batch = 0.09280463017763839\n",
      "Cost on val dataset after 125 epochs is = 0.12345040280599422\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.12345040280599422\n",
      "learning rate for this epoch =  0.44860463436636616\n",
      "Error on this batch = 0.09923248038027342\n",
      "Error on this batch = 0.09193973220649182\n",
      "Cost on val dataset after 126 epochs is = 0.12291609804551527\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.12291609804551527\n",
      "learning rate for this epoch =  0.4477118844014734\n",
      "Error on this batch = 0.09855246178787845\n",
      "Error on this batch = 0.09108909906557926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 127 epochs is = 0.12239033457398986\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.12239033457398986\n",
      "learning rate for this epoch =  0.44682794744579885\n",
      "Error on this batch = 0.09788310975151866\n",
      "Error on this batch = 0.09025256391754814\n",
      "Cost on val dataset after 128 epochs is = 0.12187282463323747\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.12187282463323747\n",
      "learning rate for this epoch =  0.4459526681260204\n",
      "Error on this batch = 0.09722414886610337\n",
      "Error on this batch = 0.08942995917880771\n",
      "Cost on val dataset after 129 epochs is = 0.12136329523775888\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.12136329523775888\n",
      "learning rate for this epoch =  0.4450858949947362\n",
      "Error on this batch = 0.096575318688313\n",
      "Error on this batch = 0.08862111345158971\n",
      "Cost on val dataset after 130 epochs is = 0.12086148739836512\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.12086148739836512\n",
      "learning rate for this epoch =  0.4442274804017437\n",
      "Error on this batch = 0.09593637182064761\n",
      "Error on this batch = 0.08782584904002617\n",
      "Cost on val dataset after 131 epochs is = 0.12036715540936088\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.12036715540936088\n",
      "learning rate for this epoch =  0.4433772803704916\n",
      "Error on this batch = 0.09530707215486754\n",
      "Error on this batch = 0.0870439800741854\n",
      "Cost on val dataset after 132 epochs is = 0.1198800661919786\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.1198800661919786\n",
      "learning rate for this epoch =  0.4425351544794606\n",
      "Error on this batch = 0.09468719328221999\n",
      "Error on this batch = 0.08627531123063516\n",
      "Cost on val dataset after 133 epochs is = 0.1193999986878931\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.1193999986878931\n",
      "learning rate for this epoch =  0.441700965748239\n",
      "Error on this batch = 0.09407651707103801\n",
      "Error on this batch = 0.08551963701167953\n",
      "Cost on val dataset after 134 epochs is = 0.11892674329736358\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.11892674329736358\n",
      "learning rate for this epoch =  0.44087458052807493\n",
      "Error on this batch = 0.09347483240734543\n",
      "Error on this batch = 0.08477674152812718\n",
      "Cost on val dataset after 135 epochs is = 0.11846010135696618\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.11846010135696618\n",
      "learning rate for this epoch =  0.4400558683966967\n",
      "Error on this batch = 0.09288193409078078\n",
      "Error on this batch = 0.08404639872127401\n",
      "Cost on val dataset after 136 epochs is = 0.11799988465210308\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.11799988465210308\n",
      "learning rate for this epoch =  0.4392447020572046\n",
      "Error on this batch = 0.09229762187622295\n",
      "Error on this batch = 0.08332837295699999\n",
      "Cost on val dataset after 137 epochs is = 0.11754591495959262\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.11754591495959262\n",
      "learning rate for this epoch =  0.43844095724084814\n",
      "Error on this batch = 0.0917216996507576\n",
      "Error on this batch = 0.0826224199265432\n",
      "Cost on val dataset after 138 epochs is = 0.11709802361573565\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.11709802361573565\n",
      "learning rate for this epoch =  0.437644512613512\n",
      "Error on this batch = 0.09115397473589155\n",
      "Error on this batch = 0.08192828779275774\n",
      "Cost on val dataset after 139 epochs is = 0.11665605110537061\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.11665605110537061\n",
      "learning rate for this epoch =  0.4368552496857437\n",
      "Error on this batch = 0.09059425730603433\n",
      "Error on this batch = 0.0812457185259322\n",
      "Cost on val dataset after 140 epochs is = 0.11621984666761333\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.11621984666761333\n",
      "learning rate for this epoch =  0.4360730527261645\n",
      "Error on this batch = 0.09004235991603114\n",
      "Error on this batch = 0.08057444937838952\n",
      "Cost on val dataset after 141 epochs is = 0.11578926791426879\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.11578926791426879\n",
      "learning rate for this epoch =  0.4352978086781127\n",
      "Error on this batch = 0.08949809713271986\n",
      "Error on this batch = 0.0799142144513807\n",
      "Cost on val dataset after 142 epochs is = 0.11536418045732044\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.11536418045732044\n",
      "learning rate for this epoch =  0.43452940707937715\n",
      "Error on this batch = 0.0889612852678141\n",
      "Error on this batch = 0.07926474631091619\n",
      "Cost on val dataset after 143 epochs is = 0.1149444575424718\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.1149444575424718\n",
      "learning rate for this epoch =  0.4337677399848857\n",
      "Error on this batch = 0.0884317422115681\n",
      "Error on this batch = 0.07862577761116846\n",
      "Cost on val dataset after 144 epochs is = 0.1145299796864298\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.1145299796864298\n",
      "learning rate for this epoch =  0.43301270189221935\n",
      "Error on this batch = 0.08790928736832303\n",
      "Error on this batch = 0.07799704268522371\n",
      "Cost on val dataset after 145 epochs is = 0.11412063431646738\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.11412063431646738\n",
      "learning rate for this epoch =  0.43226418966983016\n",
      "Error on this batch = 0.08739374169586092\n",
      "Error on this batch = 0.07737827906374307\n",
      "Cost on val dataset after 146 epochs is = 0.11371631541173763\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.11371631541173763\n",
      "learning rate for this epoch =  0.431522102487848\n",
      "Error on this batch = 0.08688492785024682\n",
      "Error on this batch = 0.07676922888309189\n",
      "Cost on val dataset after 147 epochs is = 0.11331692314676924\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.11331692314676924\n",
      "learning rate for this epoch =  0.4307863417513635\n",
      "Error on this batch = 0.08638267043637023\n",
      "Error on this batch = 0.07616964014631843\n",
      "Cost on val dataset after 148 epochs is = 0.11292236353846302\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.11292236353846302\n",
      "learning rate for this epoch =  0.43005681103608506\n",
      "Error on this batch = 0.08588679636168074\n",
      "Error on this batch = 0.0755792678035552\n",
      "Cost on val dataset after 149 epochs is = 0.112532548098634\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.112532548098634\n",
      "learning rate for this epoch =  0.4293334160262675\n",
      "Error on this batch = 0.0853971352867675\n",
      "Error on this batch = 0.07499787462338302\n",
      "Cost on val dataset after 150 epochs is = 0.11214739349460598\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.11214739349460598\n",
      "learning rate for this epoch =  0.4286160644548199\n",
      "Error on this batch = 0.08491352016174612\n",
      "Error on this batch = 0.07442523183363843\n",
      "Cost on val dataset after 151 epochs is = 0.11176682122048837\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.11176682122048837\n",
      "learning rate for this epoch =  0.4279046660455\n",
      "Error on this batch = 0.08443578783230576\n",
      "Error on this batch = 0.07386111951898654\n",
      "Cost on val dataset after 152 epochs is = 0.11139075728151022\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.11139075728151022\n",
      "learning rate for this epoch =  0.4271991324571105\n",
      "Error on this batch = 0.08396377969427726\n",
      "Error on this batch = 0.07330532677295545\n",
      "Cost on val dataset after 153 epochs is = 0.11101913189316812\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.11101913189316812\n",
      "learning rate for this epoch =  0.42649937722961534\n",
      "Error on this batch = 0.08349734237130434\n",
      "Error on this batch = 0.07275765161338317\n",
      "Cost on val dataset after 154 epochs is = 0.11065187919603099\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.11065187919603099\n",
      "learning rate for this epoch =  0.4258053157320967\n",
      "Error on this batch = 0.08303632838722132\n",
      "Error on this batch = 0.07221790068148427\n",
      "Cost on val dataset after 155 epochs is = 0.11028893698596548\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.11028893698596548\n",
      "learning rate for this epoch =  0.4251168651124797\n",
      "Error on this batch = 0.08258059680354798\n",
      "Error on this batch = 0.07168588875501633\n",
      "Cost on val dataset after 156 epochs is = 0.10993024645845037\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.10993024645845037\n",
      "learning rate for this epoch =  0.4244339442489526\n",
      "Error on this batch = 0.0821300137934108\n",
      "Error on this batch = 0.07116143811434625\n",
      "Cost on val dataset after 157 epochs is = 0.10957575196471397\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.10957575196471397\n",
      "learning rate for this epoch =  0.4237564737030161\n",
      "Error on this batch = 0.08168445312624685\n",
      "Error on this batch = 0.07064437780580622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 158 epochs is = 0.10922540077679248\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.10922540077679248\n",
      "learning rate for this epoch =  0.42308437567409557\n",
      "Error on this batch = 0.08124379654262176\n",
      "Error on this batch = 0.07013454284909947\n",
      "Cost on val dataset after 159 epochs is = 0.10887914285837016\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.10887914285837016\n",
      "learning rate for this epoch =  0.4224175739556564\n",
      "Error on this batch = 0.08080793400492528\n",
      "Error on this batch = 0.06963177343456776\n",
      "Cost on val dataset after 160 epochs is = 0.1085369306384507\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.1085369306384507\n",
      "learning rate for this epoch =  0.4217559938927618\n",
      "Error on this batch = 0.08037676381693025\n",
      "Error on this batch = 0.06913591415213875\n",
      "Cost on val dataset after 161 epochs is = 0.10819871878548647\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.10819871878548647\n",
      "learning rate for this epoch =  0.42109956234101886\n",
      "Error on this batch = 0.07995019261247227\n",
      "Error on this batch = 0.06864681328733584\n",
      "Cost on val dataset after 162 epochs is = 0.10786446398045857\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.10786446398045857\n",
      "learning rate for this epoch =  0.42044820762685725\n",
      "Error on this batch = 0.07952813522012198\n",
      "Error on this batch = 0.06816432221166428\n",
      "Cost on val dataset after 163 epochs is = 0.10753412468842445\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.10753412468842445\n",
      "learning rate for this epoch =  0.41980185950909077\n",
      "Error on this batch = 0.07911051441610967\n",
      "Error on this batch = 0.0676882948858748\n",
      "Cost on val dataset after 164 epochs is = 0.10720766092909076\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.10720766092909076\n",
      "learning rate for this epoch =  0.41916044914171213\n",
      "Error on this batch = 0.07869726058158427\n",
      "Error on this batch = 0.06721858748588755\n",
      "Cost on val dataset after 165 epochs is = 0.10688503404789941\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.10688503404789941\n",
      "learning rate for this epoch =  0.418523909037874\n",
      "Error on this batch = 0.07828831128242372\n",
      "Error on this batch = 0.06675505815322023\n",
      "Cost on val dataset after 166 epochs is = 0.10656620648984731\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.10656620648984731\n",
      "learning rate for this epoch =  0.4178921730350126\n",
      "Error on this batch = 0.07788361079038135\n",
      "Error on this batch = 0.06629756686508573\n",
      "Cost on val dataset after 167 epochs is = 0.1062511415787374\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.1062511415787374\n",
      "learning rate for this epoch =  0.4172651762610688\n",
      "Error on this batch = 0.07748310956361795\n",
      "Error on this batch = 0.06584597541416273\n",
      "Cost on val dataset after 168 epochs is = 0.10593980330477791\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.10593980330477791\n",
      "learning rate for this epoch =  0.4166428551017686\n",
      "Error on this batch = 0.07708676370299992\n",
      "Error on this batch = 0.06540014748445439\n",
      "Cost on val dataset after 169 epochs is = 0.10563215612342373\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.10563215612342373\n",
      "learning rate for this epoch =  0.41602514716892186\n",
      "Error on this batch = 0.07669453439832272\n",
      "Error on this batch = 0.06495994880753111\n",
      "Cost on val dataset after 170 epochs is = 0.10532816476813466\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.10532816476813466\n",
      "learning rate for this epoch =  0.4154119912697013\n",
      "Error on this batch = 0.07630638737618947\n",
      "Error on this batch = 0.06452524738259517\n",
      "Cost on val dataset after 171 epochs is = 0.10502779407936268\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.10502779407936268\n",
      "learning rate for this epoch =  0.41480332737686826\n",
      "Error on this batch = 0.07592229235890803\n",
      "Error on this batch = 0.06409591374394395\n",
      "Cost on val dataset after 172 epochs is = 0.10473100885162899\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.10473100885162899\n",
      "learning rate for this epoch =  0.4141990965999084\n",
      "Error on this batch = 0.07554222254163967\n",
      "Error on this batch = 0.06367182126026616\n",
      "Cost on val dataset after 173 epochs is = 0.10443777370005602\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.10443777370005602\n",
      "learning rate for this epoch =  0.4135992411570453\n",
      "Error on this batch = 0.07516615409322443\n",
      "Error on this batch = 0.06325284645152696\n",
      "Cost on val dataset after 174 epochs is = 0.10414805294722404\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.10414805294722404\n",
      "learning rate for this epoch =  0.4130037043481005\n",
      "Error on this batch = 0.07479406568463251\n",
      "Error on this batch = 0.06283886931076622\n",
      "Cost on val dataset after 175 epochs is = 0.10386181053074692\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.10386181053074692\n",
      "learning rate for this epoch =  0.4124124305281695\n",
      "Error on this batch = 0.07442593804780227\n",
      "Error on this batch = 0.06242977361977523\n",
      "Cost on val dataset after 176 epochs is = 0.10357900993153159\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.10357900993153159\n",
      "learning rate for this epoch =  0.41182536508208434\n",
      "Error on this batch = 0.07406175356664836\n",
      "Error on this batch = 0.062025447249215784\n",
      "Cost on val dataset after 177 epochs is = 0.10329961412230336\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.10329961412230336\n",
      "learning rate for this epoch =  0.41124245439963575\n",
      "Error on this batch = 0.07370149590118065\n",
      "Error on this batch = 0.06162578243522452\n",
      "Cost on val dataset after 178 epochs is = 0.10302358553565377\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.10302358553565377\n",
      "learning rate for this epoch =  0.41066364585152754\n",
      "Error on this batch = 0.07334514964488974\n",
      "Error on this batch = 0.06123067602586755\n",
      "Cost on val dataset after 179 epochs is = 0.10275088605058966\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.10275088605058966\n",
      "learning rate for this epoch =  0.41008888776603736\n",
      "Error on this batch = 0.07299270001478769\n",
      "Error on this batch = 0.0608400296919718\n",
      "Cost on val dataset after 180 epochs is = 0.10248147699633539\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.10248147699633539\n",
      "learning rate for this epoch =  0.40951812940636\n",
      "Error on this batch = 0.07264413257272224\n",
      "Error on this batch = 0.06045375009787181\n",
      "Cost on val dataset after 181 epochs is = 0.1022153191719538\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.1022153191719538\n",
      "learning rate for this epoch =  0.40895132094860925\n",
      "Error on this batch = 0.07229943297582991\n",
      "Error on this batch = 0.06007174902850441\n",
      "Cost on val dataset after 182 epochs is = 0.10195237288020177\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.10195237288020177\n",
      "learning rate for this epoch =  0.40838841346045524\n",
      "Error on this batch = 0.07195858675329729\n",
      "Error on this batch = 0.05969394347009159\n",
      "Cost on val dataset after 183 epochs is = 0.10169259797392367\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.10169259797392367\n",
      "learning rate for this epoch =  0.40782935888037647\n",
      "Error on this batch = 0.07162157910602318\n",
      "Error on this batch = 0.059320255642408413\n",
      "Cost on val dataset after 184 epochs is = 0.10143595391320283\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.10143595391320283\n",
      "learning rate for this epoch =  0.40727410999750435\n",
      "Error on this batch = 0.07128839472537839\n",
      "Error on this batch = 0.05895061298137284\n",
      "Cost on val dataset after 185 epochs is = 0.10118239983144342\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.10118239983144342\n",
      "learning rate for this epoch =  0.40672262043204177\n",
      "Error on this batch = 0.07095901762710552\n",
      "Error on this batch = 0.0585849480714386\n",
      "Cost on val dataset after 186 epochs is = 0.10093189460854043\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.10093189460854043\n",
      "learning rate for this epoch =  0.40617484461623476\n",
      "Error on this batch = 0.07063343099651272\n",
      "Error on this batch = 0.058223198528043064\n",
      "Cost on val dataset after 187 epochs is = 0.10068439694931552\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.10068439694931552\n",
      "learning rate for this epoch =  0.4056307377758796\n",
      "Error on this batch = 0.07031161704150722\n",
      "Error on this batch = 0.05786530683116526\n",
      "Cost on val dataset after 188 epochs is = 0.10043986546545537\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.10043986546545537\n",
      "learning rate for this epoch =  0.4050902559123477\n",
      "Error on this batch = 0.06999355685064411\n",
      "Error on this batch = 0.057511220111887626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 189 epochs is = 0.10019825875928214\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.10019825875928214\n",
      "learning rate for this epoch =  0.40455335578511065\n",
      "Error on this batch = 0.06967923025417809\n",
      "Error on this batch = 0.05716088989471988\n",
      "Cost on val dataset after 190 epochs is = 0.09995953550781092\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.09995953550781092\n",
      "learning rate for this epoch =  0.4040199948947485\n",
      "Error on this batch = 0.06936861568700722\n",
      "Error on this batch = 0.056814271799322615\n",
      "Cost on val dataset after 191 epochs is = 0.09972365454570228\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.09972365454570228\n",
      "learning rate for this epoch =  0.4034901314664274\n",
      "Error on this batch = 0.069061690053291\n",
      "Error on this batch = 0.05647132520613868\n",
      "Cost on val dataset after 192 epochs is = 0.0994905749458856\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.0994905749458856\n",
      "learning rate for this epoch =  0.4029637244338282\n",
      "Error on this batch = 0.06875842859330906\n",
      "Error on this batch = 0.05613201289128012\n",
      "Cost on val dataset after 193 epochs is = 0.09926025609680816\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.09926025609680816\n",
      "learning rate for this epoch =  0.4024407334235145\n",
      "Error on this batch = 0.06845880475371943\n",
      "Error on this batch = 0.055796300636793424\n",
      "Cost on val dataset after 194 epochs is = 0.09903265777543645\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.09903265777543645\n",
      "learning rate for this epoch =  0.4019211187397237\n",
      "Error on this batch = 0.06816279006271617\n",
      "Error on this batch = 0.055464156823105175\n",
      "Cost on val dataset after 195 epochs is = 0.09880774021529802\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.09880774021529802\n",
      "learning rate for this epoch =  0.40140484134956866\n",
      "Error on this batch = 0.0678703540116509\n",
      "Error on this batch = 0.0551355520109979\n",
      "Cost on val dataset after 196 epochs is = 0.09858546416899118\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.09858546416899118\n",
      "learning rate for this epoch =  0.4008918628686366\n",
      "Error on this batch = 0.06758146394447645\n",
      "Error on this batch = 0.05481045852084702\n",
      "Cost on val dataset after 197 epochs is = 0.09836579096470516\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.09836579096470516\n",
      "learning rate for this epoch =  0.40038214554697205\n",
      "Error on this batch = 0.06729608495593155\n",
      "Error on this batch = 0.05448885001703044\n",
      "Cost on val dataset after 198 epochs is = 0.0981486825563823\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.0981486825563823\n",
      "learning rate for this epoch =  0.3998756522554328\n",
      "Error on this batch = 0.06701417979877425\n",
      "Error on this batch = 0.05417070110538012\n",
      "Cost on val dataset after 199 epochs is = 0.09793410156722021\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.09793410156722021\n",
      "learning rate for this epoch =  0.3993723464724061\n",
      "Error on this batch = 0.06673570879965958\n",
      "Error on this batch = 0.05385598695125885\n",
      "Cost on val dataset after 200 epochs is = 0.09772201132626127\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.09772201132626127\n",
      "learning rate for this epoch =  0.39887219227087417\n",
      "Error on this batch = 0.06646062978252944\n",
      "Error on this batch = 0.05354468292531269\n",
      "Cost on val dataset after 201 epochs is = 0.09751237589785743\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.09751237589785743\n",
      "learning rate for this epoch =  0.3983751543058184\n",
      "Error on this batch = 0.06618889799770632\n",
      "Error on this batch = 0.053236764283178854\n",
      "Cost on val dataset after 202 epochs is = 0.09730516010383704\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.09730516010383704\n",
      "learning rate for this epoch =  0.39788119780195147\n",
      "Error on this batch = 0.0659204660543273\n",
      "Error on this batch = 0.05293220588444223\n",
      "Cost on val dataset after 203 epochs is = 0.09710032953824617\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.09710032953824617\n",
      "learning rate for this epoch =  0.39739028854176744\n",
      "Error on this batch = 0.06565528385336424\n",
      "Error on this batch = 0.05263098195497067\n",
      "Cost on val dataset after 204 epochs is = 0.09689785057459585\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.09689785057459585\n",
      "learning rate for this epoch =  0.39690239285389944\n",
      "Error on this batch = 0.06539329851827645\n",
      "Error on this batch = 0.05233306589546473\n",
      "Cost on val dataset after 205 epochs is = 0.096697690365618\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.096697690365618\n",
      "learning rate for this epoch =  0.39641747760177665\n",
      "Error on this batch = 0.0651344543203473\n",
      "Error on this batch = 0.052038430137691195\n",
      "Cost on val dataset after 206 epochs is = 0.09649981683562205\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.09649981683562205\n",
      "learning rate for this epoch =  0.3959355101725709\n",
      "Error on this batch = 0.06487869259595261\n",
      "Error on this batch = 0.05174704604848632\n",
      "Cost on val dataset after 207 epochs is = 0.09630419866564222\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.09630419866564222\n",
      "learning rate for this epoch =  0.39545645846642347\n",
      "Error on this batch = 0.06462595165338045\n",
      "Error on this batch = 0.05145888388027421\n",
      "Cost on val dataset after 208 epochs is = 0.09611080527167065\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.09611080527167065\n",
      "learning rate for this epoch =  0.39498029088594494\n",
      "Error on this batch = 0.06437616666733756\n",
      "Error on this batch = 0.0511739127655944\n",
      "Cost on val dataset after 209 epochs is = 0.09591960677637422\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.09591960677637422\n",
      "learning rate for this epoch =  0.3945069763259793\n",
      "Error on this batch = 0.0641292695599058\n",
      "Error on this batch = 0.050892100752013815\n",
      "Cost on val dataset after 210 epochs is = 0.09573057397478676\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.09573057397478676\n",
      "learning rate for this epoch =  0.39403648416362375\n",
      "Error on this batch = 0.06388518886742416\n",
      "Error on this batch = 0.050613414872835\n",
      "Cost on val dataset after 211 epochs is = 0.09554367829454662\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.09554367829454662\n",
      "learning rate for this epoch =  0.39356878424849795\n",
      "Error on this batch = 0.06364384959354054\n",
      "Error on this batch = 0.05033782124822325\n",
      "Cost on val dataset after 212 epochs is = 0.09535889175130748\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.09535889175130748\n",
      "learning rate for this epoch =  0.39310384689325434\n",
      "Error on this batch = 0.06340517304949149\n",
      "Error on this batch = 0.050065285210760264\n",
      "Cost on val dataset after 213 epochs is = 0.09517618689998687\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.09517618689998687\n",
      "learning rate for this epoch =  0.39264164286432307\n",
      "Error on this batch = 0.06316907668351579\n",
      "Error on this batch = 0.049795771448985934\n",
      "Cost on val dataset after 214 epochs is = 0.09499553678253622\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.09499553678253622\n",
      "learning rate for this epoch =  0.3921821433728839\n",
      "Error on this batch = 0.06293547390219154\n",
      "Error on this batch = 0.049529244162204056\n",
      "Cost on val dataset after 215 epochs is = 0.09481691487292197\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.09481691487292197\n",
      "learning rate for this epoch =  0.3917253200660592\n",
      "Error on this batch = 0.06270427388740929\n",
      "Error on this batch = 0.04926566721968845\n",
      "Cost on val dataset after 216 epochs is = 0.09464029502001216\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.09464029502001216\n",
      "learning rate for this epoch =  0.39127114501832183\n",
      "Error on this batch = 0.06247538141365126\n",
      "Error on this batch = 0.049005004317426284\n",
      "Cost on val dataset after 217 epochs is = 0.09446565138907588\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.09446565138907588\n",
      "learning rate for this epoch =  0.39081959072311023\n",
      "Error on this batch = 0.06224869667123015\n",
      "Error on this batch = 0.048747219125675256\n",
      "Cost on val dataset after 218 epochs is = 0.0942929584026377\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.0942929584026377\n",
      "learning rate for this epoch =  0.39037063008464684\n",
      "Error on this batch = 0.06202411510211649\n",
      "Error on this batch = 0.04849227542089666\n",
      "Cost on val dataset after 219 epochs is = 0.09412219068149441\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.09412219068149441\n",
      "learning rate for this epoch =  0.3899242364099523\n",
      "Error on this batch = 0.061801527255899026\n",
      "Error on this batch = 0.04824013719607366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 220 epochs is = 0.09395332298680392\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.09395332298680392\n",
      "learning rate for this epoch =  0.38948038340105073\n",
      "Error on this batch = 0.061580818674193426\n",
      "Error on this batch = 0.04799076874405847\n",
      "Cost on val dataset after 221 epochs is = 0.09378633016429239\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.09378633016429239\n",
      "learning rate for this epoch =  0.3890390451473609\n",
      "Error on this batch = 0.0613618698123426\n",
      "Error on this batch = 0.047744134709435004\n",
      "Cost on val dataset after 222 epochs is = 0.09362118709178965\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.09362118709178965\n",
      "learning rate for this epoch =  0.3886001961182669\n",
      "Error on this batch = 0.061144556007420164\n",
      "Error on this batch = 0.04750020010546164\n",
      "Cost on val dataset after 223 epochs is = 0.09345786863147312\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.09345786863147312\n",
      "learning rate for this epoch =  0.3881638111558645\n",
      "Error on this batch = 0.060928747501250616\n",
      "Error on this batch = 0.04725893029397822\n",
      "Cost on val dataset after 224 epochs is = 0.09329634958834951\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.09329634958834951\n",
      "learning rate for this epoch =  0.3877298654678779\n",
      "Error on this batch = 0.06071430952631932\n",
      "Error on this batch = 0.04702029092771754\n",
      "Cost on val dataset after 225 epochs is = 0.09313660467659804\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.09313660467659804\n",
      "learning rate for this epoch =  0.3872983346207417\n",
      "Error on this batch = 0.06050110246104727\n",
      "Error on this batch = 0.04678424785621572\n",
      "Cost on val dataset after 226 epochs is = 0.09297860849539996\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.09297860849539996\n",
      "learning rate for this epoch =  0.3868691945328438\n",
      "Error on this batch = 0.06028898205901686\n",
      "Error on this batch = 0.046550766998405074\n",
      "Cost on val dataset after 227 epochs is = 0.09282233551575031\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.09282233551575031\n",
      "learning rate for this epoch =  0.3864424214679254\n",
      "Error on this batch = 0.060077799754533964\n",
      "Error on this batch = 0.046319814186894515\n",
      "Cost on val dataset after 228 epochs is = 0.0926677600794637\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.0926677600794637\n",
      "learning rate for this epoch =  0.3860179920286326\n",
      "Error on this batch = 0.059867403044686046\n",
      "Error on this batch = 0.04609135499076908\n",
      "Cost on val dataset after 229 epochs is = 0.09251485641113176\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.09251485641113176\n",
      "learning rate for this epoch =  0.38559588315021626\n",
      "Error on this batch = 0.059657635946191306\n",
      "Error on this batch = 0.04586535452532436\n",
      "Cost on val dataset after 230 epochs is = 0.09236359864317806\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.09236359864317806\n",
      "learning rate for this epoch =  0.38517607209437615\n",
      "Error on this batch = 0.05944833952428386\n",
      "Error on this batch = 0.04564177725833992\n",
      "Cost on val dataset after 231 epochs is = 0.09221396085341504\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.09221396085341504\n",
      "learning rate for this epoch =  0.3847585364432452\n",
      "Error on this batch = 0.05923935249109052\n",
      "Error on this batch = 0.04542058682315387\n",
      "Cost on val dataset after 232 epochs is = 0.09206591711369758\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.09206591711369758\n",
      "learning rate for this epoch =  0.38434325409350933\n",
      "Error on this batch = 0.05903051187281043\n",
      "Error on this batch = 0.04520174584882618\n",
      "Cost on val dataset after 233 epochs is = 0.09191944154746297\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.09191944154746297\n",
      "learning rate for this epoch =  0.38393020325066135\n",
      "Error on this batch = 0.05882165374872841\n",
      "Error on this batch = 0.04498521581703166\n",
      "Cost on val dataset after 234 epochs is = 0.0917745083932332\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.0917745083932332\n",
      "learning rate for this epoch =  0.38351936242338275\n",
      "Error on this batch = 0.058612614070667625\n",
      "Error on this batch = 0.044770956954022674\n",
      "Cost on val dataset after 235 epochs is = 0.09163109207062001\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.09163109207062001\n",
      "learning rate for this epoch =  0.383110710418052\n",
      "Error on this batch = 0.05840322957861652\n",
      "Error on this batch = 0.044558928164148484\n",
      "Cost on val dataset after 236 epochs is = 0.0914891672450844\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.0914891672450844\n",
      "learning rate for this epoch =  0.38270422633337464\n",
      "Error on this batch = 0.05819333883632801\n",
      "Error on this batch = 0.044349087009169265\n",
      "Cost on val dataset after 237 epochs is = 0.09134870888771118\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.09134870888771118\n",
      "learning rate for this epoch =  0.38229988955513305\n",
      "Error on this batch = 0.057982783418757684\n",
      "Error on this batch = 0.04414138973516267\n",
      "Cost on val dataset after 238 epochs is = 0.09120969232657222\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.09120969232657222\n",
      "learning rate for this epoch =  0.3818976797510519\n",
      "Error on this batch = 0.05777140929007759\n",
      "Error on this batch = 0.04393579134641058\n",
      "Cost on val dataset after 239 epochs is = 0.09107209328685432\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.09107209328685432\n",
      "learning rate for this epoch =  0.38149757686577634\n",
      "Error on this batch = 0.057559068415283327\n",
      "Error on this batch = 0.04373224572347703\n",
      "Cost on val dataset after 240 epochs is = 0.09093588791775696\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.09093588791775696\n",
      "learning rate for this epoch =  0.38109956111596105\n",
      "Error on this batch = 0.05734562064861194\n",
      "Error on this batch = 0.043530705780902415\n",
      "Cost on val dataset after 241 epochs is = 0.09080105280514934\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.09080105280514934\n",
      "learning rate for this epoch =  0.3807036129854653\n",
      "Error on this batch = 0.05713093593665397\n",
      "Error on this batch = 0.043331123658631114\n",
      "Cost on val dataset after 242 epochs is = 0.09066756497001902\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.09066756497001902\n",
      "learning rate for this epoch =  0.3803097132206534\n",
      "Error on this batch = 0.05691489686190318\n",
      "Error on this batch = 0.04313345094046822\n",
      "Cost on val dataset after 243 epochs is = 0.0905354018537578\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.0905354018537578\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.05669740153263657\n",
      "Error on this batch = 0.04293763889245947\n",
      "Cost on val dataset after 244 epochs is = 0.09040454129223448\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.09040454129223448\n",
      "learning rate for this epoch =  0.3795279830585723\n",
      "Error on this batch = 0.056478366797116736\n",
      "Error on this batch = 0.04274363871398735\n",
      "Cost on val dataset after 245 epochs is = 0.09027496148133453\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.09027496148133453\n",
      "learning rate for this epoch =  0.3791401154256649\n",
      "Error on this batch = 0.056257731724626885\n",
      "Error on this batch = 0.04255140179443865\n",
      "Cost on val dataset after 246 epochs is = 0.09014664093716439\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.09014664093716439\n",
      "learning rate for this epoch =  0.3787542216784535\n",
      "Error on this batch = 0.05603546125427639\n",
      "Error on this batch = 0.04236087996840108\n",
      "Cost on val dataset after 247 epochs is = 0.09001955845440263\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.09001955845440263\n",
      "learning rate for this epoch =  0.3783702838087975\n",
      "Error on this batch = 0.05581154986756112\n",
      "Error on this batch = 0.042172025762425305\n",
      "Cost on val dataset after 248 epochs is = 0.08989369306632478\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.08989369306632478\n",
      "learning rate for this epoch =  0.3779882840449083\n",
      "Error on this batch = 0.05558602509632639\n",
      "Error on this batch = 0.04198479262644798\n",
      "Cost on val dataset after 249 epochs is = 0.0897690240098468\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.0897690240098468\n",
      "learning rate for this epoch =  0.37760820484730934\n",
      "Error on this batch = 0.055358950639237854\n",
      "Error on this batch = 0.04179913514310151\n",
      "Cost on val dataset after 250 epochs is = 0.08964553069853569\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.08964553069853569\n",
      "learning rate for this epoch =  0.37723002890488067\n",
      "Error on this batch = 0.055130428833111075\n",
      "Error on this batch = 0.04161500920848022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 251 epochs is = 0.0895231927059505\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.0895231927059505\n",
      "learning rate for this epoch =  0.37685373913098663\n",
      "Error on this batch = 0.054900602216620034\n",
      "Error on this batch = 0.04143237217865885\n",
      "Cost on val dataset after 252 epochs is = 0.08940198976093558\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.08940198976093558\n",
      "learning rate for this epoch =  0.3764793186596844\n",
      "Error on this batch = 0.05466965393834377\n",
      "Error on this batch = 0.04125118297749813\n",
      "Cost on val dataset after 253 epochs is = 0.08928190175562367\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.08928190175562367\n",
      "learning rate for this epoch =  0.37610675084201106\n",
      "Error on this batch = 0.054437806802264045\n",
      "Error on this batch = 0.041071402163073804\n",
      "Cost on val dataset after 254 epochs is = 0.08916290876597377\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.08916290876597377\n",
      "learning rate for this epoch =  0.37573601924234745\n",
      "Error on this batch = 0.05420532081216978\n",
      "Error on this batch = 0.04089299195235968\n",
      "Cost on val dataset after 255 epochs is = 0.08904499108372502\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.08904499108372502\n",
      "learning rate for this epoch =  0.3753671076348574\n",
      "Error on this batch = 0.05397248916868501\n",
      "Error on this batch = 0.04071591620638628\n",
      "Cost on val dataset after 256 epochs is = 0.0889281292577619\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.0889281292577619\n",
      "learning rate for this epoch =  0.375\n",
      "Error on this batch = 0.05373963278157559\n",
      "Error on this batch = 0.04054014038068626\n",
      "Cost on val dataset after 257 epochs is = 0.08881230414213158\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.08881230414213158\n",
      "learning rate for this epoch =  0.37463468052111276\n",
      "Error on this batch = 0.053507093474914065\n",
      "Error on this batch = 0.04036563144808841\n",
      "Cost on val dataset after 258 epochs is = 0.0886974969473967\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.0886974969473967\n",
      "learning rate for this epoch =  0.3742711335810649\n",
      "Error on this batch = 0.0532752261707375\n",
      "Error on this batch = 0.04019235780251939\n",
      "Cost on val dataset after 259 epochs is = 0.08858368929170363\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.08858368929170363\n",
      "learning rate for this epoch =  0.37390934375897855\n",
      "Error on this batch = 0.05304439042489728\n",
      "Error on this batch = 0.04002028915319632\n",
      "Cost on val dataset after 260 epochs is = 0.08847086324792493\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.08847086324792493\n",
      "learning rate for this epoch =  0.37354929582701596\n",
      "Error on this batch = 0.05281494174564598\n",
      "Error on this batch = 0.03984939641836915\n",
      "Cost on val dataset after 261 epochs is = 0.08835900138350462\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.08835900138350462\n",
      "learning rate for this epoch =  0.3731909747472316\n",
      "Error on this batch = 0.052587223143769804\n",
      "Error on this batch = 0.03967965162666952\n",
      "Cost on val dataset after 262 epochs is = 0.08824808679016712\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.08824808679016712\n",
      "learning rate for this epoch =  0.37283436566848754\n",
      "Error on this batch = 0.052361557340589115\n",
      "Error on this batch = 0.039511027832350734\n",
      "Cost on val dataset after 263 epochs is = 0.08813810310139558\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.08813810310139558\n",
      "learning rate for this epoch =  0.3724794539234301\n",
      "Error on this batch = 0.052138240000326616\n",
      "Error on this batch = 0.03934349904854281\n",
      "Cost on val dataset after 264 epochs is = 0.08802903449647059\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.08802903449647059\n",
      "learning rate for this epoch =  0.3721262250255272\n",
      "Error on this batch = 0.05191753426449247\n",
      "Error on this batch = 0.03917704020040544\n",
      "Cost on val dataset after 265 epochs is = 0.08792086569080113\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.08792086569080113\n",
      "learning rate for this epoch =  0.3717746646661645\n",
      "Error on this batch = 0.05169966675972282\n",
      "Error on this batch = 0.0390116270980119\n",
      "Cost on val dataset after 266 epochs is = 0.08781358191319324\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.08781358191319324\n",
      "learning rate for this epoch =  0.37142475871179786\n",
      "Error on this batch = 0.05148482513985753\n",
      "Error on this batch = 0.03884723642713444\n",
      "Cost on val dataset after 267 epochs is = 0.0877071688715105\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.0877071688715105\n",
      "learning rate for this epoch =  0.37107649320116404\n",
      "Error on this batch = 0.05127315712004117\n",
      "Error on this batch = 0.0386838457549344\n",
      "Cost on val dataset after 268 epochs is = 0.08760161270882466\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.08760161270882466\n",
      "learning rate for this epoch =  0.3707298543425433\n",
      "Error on this batch = 0.051064770874782006\n",
      "Error on this batch = 0.03852143354690656\n",
      "Cost on val dataset after 269 epochs is = 0.08749689995259607\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.08749689995259607\n",
      "learning rate for this epoch =  0.3703848285110782\n",
      "Error on this batch = 0.050859736609115413\n",
      "Error on this batch = 0.038359979191234246\n",
      "Cost on val dataset after 270 epochs is = 0.08739301745964591\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.08739301745964591\n",
      "learning rate for this epoch =  0.3700414022461427\n",
      "Error on this batch = 0.05065808907436479\n",
      "Error on this batch = 0.038199463026883096\n",
      "Cost on val dataset after 271 epochs is = 0.08728995235968935\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.08728995235968935\n",
      "learning rate for this epoch =  0.3696995622487631\n",
      "Error on this batch = 0.05045983078615738\n",
      "Error on this batch = 0.03803986637218295\n",
      "Cost on val dataset after 272 epochs is = 0.08718769200001641\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.08718769200001641\n",
      "learning rate for this epoch =  0.3693592953790893\n",
      "Error on this batch = 0.05026493570856447\n",
      "Error on this batch = 0.03788117155120586\n",
      "Cost on val dataset after 273 epochs is = 0.08708622389356789\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.08708622389356789\n",
      "learning rate for this epoch =  0.3690205886539131\n",
      "Error on this batch = 0.05007335318934951\n",
      "Error on this batch = 0.037723361915848935\n",
      "Cost on val dataset after 274 epochs is = 0.08698553567219987\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.08698553567219987\n",
      "learning rate for this epoch =  0.3686834292442363\n",
      "Error on this batch = 0.04988501196185879\n",
      "Error on this batch = 0.037566421862103176\n",
      "Cost on val dataset after 275 epochs is = 0.08688561504640774\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.08688561504640774\n",
      "learning rate for this epoch =  0.36834780447288357\n",
      "Error on this batch = 0.04969982406408219\n",
      "Error on this batch = 0.03741033683948142\n",
      "Cost on val dataset after 276 epochs is = 0.08678644977223059\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.08678644977223059\n",
      "learning rate for this epoch =  0.3680137018121613\n",
      "Error on this batch = 0.04951768856083698\n",
      "Error on this batch = 0.03725509335296482\n",
      "Cost on val dataset after 277 epochs is = 0.08668802762551962\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.08668802762551962\n",
      "learning rate for this epoch =  0.3676811088815615\n",
      "Error on this batch = 0.049338494988051027\n",
      "Error on this batch = 0.03710067895708667\n",
      "Cost on val dataset after 278 epochs is = 0.086590336383268\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.086590336383268\n",
      "learning rate for this epoch =  0.3673500134455082\n",
      "Error on this batch = 0.0491621264670674\n",
      "Error on this batch = 0.0369470822418985\n",
      "Cost on val dataset after 279 epochs is = 0.0864933638112926\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.0864933638112926\n",
      "learning rate for this epoch =  0.36702040341114717\n",
      "Error on this batch = 0.048988462461039876\n",
      "Error on this batch = 0.03679429281055336\n",
      "Cost on val dataset after 280 epochs is = 0.08639709765726412\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.08639709765726412\n",
      "learning rate for this epoch =  0.3666922668261758\n",
      "Error on this batch = 0.04881738116482368\n",
      "Error on this batch = 0.03664230124810118\n",
      "Cost on val dataset after 281 epochs is = 0.08630152564792025\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.08630152564792025\n",
      "learning rate for this epoch =  0.3663655918767155\n",
      "Error on this batch = 0.04864876153470956\n",
      "Error on this batch = 0.03649109908083195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 282 epochs is = 0.08620663548928892\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.08620663548928892\n",
      "learning rate for this epoch =  0.3660403668852222\n",
      "Error on this batch = 0.0484824849755191\n",
      "Error on this batch = 0.03634067872515958\n",
      "Cost on val dataset after 283 epochs is = 0.08611241486890042\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.08611241486890042\n",
      "learning rate for this epoch =  0.3657165803084363\n",
      "Error on this batch = 0.048318436710623275\n",
      "Error on this batch = 0.036191033424655454\n",
      "Cost on val dataset after 284 epochs is = 0.08601885145927621\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.08601885145927621\n",
      "learning rate for this epoch =  0.36539422073537026\n",
      "Error on this batch = 0.048156506865928254\n",
      "Error on this batch = 0.036042157173487056\n",
      "Cost on val dataset after 285 epochs is = 0.08592593292242341\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.08592593292242341\n",
      "learning rate for this epoch =  0.36507327688533403\n",
      "Error on this batch = 0.047996591302219525\n",
      "Error on this batch = 0.03589404462427899\n",
      "Cost on val dataset after 286 epochs is = 0.0858336469155947\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.0858336469155947\n",
      "learning rate for this epoch =  0.3647537376059957\n",
      "Error on this batch = 0.04783859223175583\n",
      "Error on this batch = 0.03574669097838877\n",
      "Cost on val dataset after 287 epochs is = 0.08574198109912516\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.08574198109912516\n",
      "learning rate for this epoch =  0.3644355918714786\n",
      "Error on this batch = 0.04768241865482951\n",
      "Error on this batch = 0.03560009185687812\n",
      "Cost on val dataset after 288 epochs is = 0.08565092314764819\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.08565092314764819\n",
      "learning rate for this epoch =  0.36411882878049256\n",
      "Error on this batch = 0.04752798665026529\n",
      "Error on this batch = 0.0354542431511456\n",
      "Cost on val dataset after 289 epochs is = 0.08556046076631695\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.08556046076631695\n",
      "learning rate for this epoch =  0.36380343755449945\n",
      "Error on this batch = 0.04737521955060554\n",
      "Error on this batch = 0.03530914085332231\n",
      "Cost on val dataset after 290 epochs is = 0.08547058171372783\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.08547058171372783\n",
      "learning rate for this epoch =  0.36348940753591197\n",
      "Error on this batch = 0.04722404802815669\n",
      "Error on this batch = 0.035164780868114684\n",
      "Cost on val dataset after 291 epochs is = 0.0853812738329764\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.0853812738329764\n",
      "learning rate for this epoch =  0.3631767281863247\n",
      "Error on this batch = 0.04707441011237311\n",
      "Error on this batch = 0.03502115880974053\n",
      "Cost on val dataset after 292 epochs is = 0.08529252509163986\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.08529252509163986\n",
      "learning rate for this epoch =  0.3628653890847774\n",
      "Error on this batch = 0.046926251152565754\n",
      "Error on this batch = 0.034878269789786934\n",
      "Cost on val dataset after 293 epochs is = 0.0852043236305007\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.0852043236305007\n",
      "learning rate for this epoch =  0.36255537992604914\n",
      "Error on this batch = 0.04677952373311488\n",
      "Error on this batch = 0.034736108203997584\n",
      "Cost on val dataset after 294 epochs is = 0.08511665781959146\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.08511665781959146\n",
      "learning rate for this epoch =  0.36224669051898317\n",
      "Error on this batch = 0.046634187541799474\n",
      "Error on this batch = 0.03459466752787575\n",
      "Cost on val dataset after 295 epochs is = 0.08502951631881063\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.08502951631881063\n",
      "learning rate for this epoch =  0.3619393107848413\n",
      "Error on this batch = 0.04649020918613983\n",
      "Error on this batch = 0.03445394013226706\n",
      "Cost on val dataset after 296 epochs is = 0.08494288813913206\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.08494288813913206\n",
      "learning rate for this epoch =  0.361633230755688\n",
      "Error on this batch = 0.04634756194833738\n",
      "Error on this batch = 0.034313917130487634\n",
      "Cost on val dataset after 297 epochs is = 0.0848567626995081\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.0848567626995081\n",
      "learning rate for this epoch =  0.36132844057280267\n",
      "Error on this batch = 0.04620622546690013\n",
      "Error on this batch = 0.03417458826791597\n",
      "Cost on val dataset after 298 epochs is = 0.0847711298741115\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.0847711298741115\n",
      "learning rate for this epoch =  0.36102493048512\n",
      "Error on this batch = 0.04606618533254005\n",
      "Error on this batch = 0.03403594186324342\n",
      "Cost on val dataset after 299 epochs is = 0.0846859800246542\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.0846859800246542\n",
      "learning rate for this epoch =  0.3607226908476982\n",
      "Error on this batch = 0.04592743258733295\n",
      "Error on this batch = 0.03389796480791406\n",
      "Cost on val dataset after 300 epochs is = 0.08460130401313423\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.08460130401313423\n",
      "learning rate for this epoch =  0.3604217121202132\n",
      "Error on this batch = 0.04578996311909727\n",
      "Error on this batch = 0.03376064262697727\n",
      "Cost on val dataset after 301 epochs is = 0.08451709319137082\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.08451709319137082\n",
      "learning rate for this epoch =  0.3601219848654798\n",
      "Error on this batch = 0.04565377694695839\n",
      "Error on this batch = 0.03362395960102155\n",
      "Cost on val dataset after 302 epochs is = 0.08443333936489496\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.08443333936489496\n",
      "learning rate for this epoch =  0.35982349974799877\n",
      "Error on this batch = 0.04551887739855903\n",
      "Error on this batch = 0.03348789894548085\n",
      "Cost on val dataset after 303 epochs is = 0.08435003472996311\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.08435003472996311\n",
      "learning rate for this epoch =  0.35952624753252843\n",
      "Error on this batch = 0.045385270183872985\n",
      "Error on this batch = 0.033352443040770174\n",
      "Cost on val dataset after 304 epochs is = 0.08426717178349112\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.08426717178349112\n",
      "learning rate for this epoch =  0.359230219082681\n",
      "Error on this batch = 0.0452529623748122\n",
      "Error on this batch = 0.033217573704649464\n",
      "Cost on val dataset after 305 epochs is = 0.08418474320650882\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.08418474320650882\n",
      "learning rate for this epoch =  0.3589354053595442\n",
      "Error on this batch = 0.045121961303786595\n",
      "Error on this batch = 0.033083272496989745\n",
      "Cost on val dataset after 306 epochs is = 0.08410274172237772\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.08410274172237772\n",
      "learning rate for this epoch =  0.35864179742032526\n",
      "Error on this batch = 0.04499227339836466\n",
      "Error on this batch = 0.03294952104660394\n",
      "Cost on val dataset after 307 epochs is = 0.08402115993169981\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.08402115993169981\n",
      "learning rate for this epoch =  0.3583493864170186\n",
      "Error on this batch = 0.04486390297369368\n",
      "Error on this batch = 0.03281630138973461\n",
      "Cost on val dataset after 308 epochs is = 0.08393999012686487\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.08393999012686487\n",
      "learning rate for this epoch =  0.35805816359509623\n",
      "Error on this batch = 0.04473685100997457\n",
      "Error on this batch = 0.03268359630981329\n",
      "Cost on val dataset after 309 epochs is = 0.08385922409087465\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.08385922409087465\n",
      "learning rate for this epoch =  0.35776812029222116\n",
      "Error on this batch = 0.044611113949585106\n",
      "Error on this batch = 0.032551389667864195\n",
      "Cost on val dataset after 310 epochs is = 0.08377885288771837\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.08377885288771837\n",
      "learning rate for this epoch =  0.3574792479369811\n",
      "Error on this batch = 0.04448668255764633\n",
      "Error on this batch = 0.03241966671215768\n",
      "Cost on val dataset after 311 epochs is = 0.0836988666552745\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.0836988666552745\n",
      "learning rate for this epoch =  0.3571915380476448\n",
      "Error on this batch = 0.044363540900630216\n",
      "Error on this batch = 0.03228841435434086\n",
      "Cost on val dataset after 312 epochs is = 0.08361925441630642\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.08361925441630642\n",
      "learning rate for this epoch =  0.3569049822309392\n",
      "Error on this batch = 0.04424166550889634\n",
      "Error on this batch = 0.03215762139745674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 313 epochs is = 0.08354000392804453\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.08354000392804453\n",
      "learning rate for this epoch =  0.3566195721808463\n",
      "Error on this batch = 0.044121024798713326\n",
      "Error on this batch = 0.032027278699490305\n",
      "Cost on val dataset after 314 epochs is = 0.08346110159507782\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.08346110159507782\n",
      "learning rate for this epoch =  0.3563352996774212\n",
      "Error on this batch = 0.04400157883424301\n",
      "Error on this batch = 0.03189737925512114\n",
      "Cost on val dataset after 315 epochs is = 0.08338253247239205\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.08338253247239205\n",
      "learning rate for this epoch =  0.3560521565856293\n",
      "Error on this batch = 0.04388327950632478\n",
      "Error on this batch = 0.031767918179207336\n",
      "Cost on val dataset after 316 epochs is = 0.08330428038375581\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.08330428038375581\n",
      "learning rate for this epoch =  0.3557701348542029\n",
      "Error on this batch = 0.04376607118892572\n",
      "Error on this batch = 0.03163889257916228\n",
      "Cost on val dataset after 317 epochs is = 0.08322632817387436\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.08322632817387436\n",
      "learning rate for this epoch =  0.3554892265145167\n",
      "Error on this batch = 0.043649891903291244\n",
      "Error on this batch = 0.03151030131051612\n",
      "Cost on val dataset after 318 epochs is = 0.08314865810019258\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.08314865810019258\n",
      "learning rate for this epoch =  0.35520942367948233\n",
      "Error on this batch = 0.04353467497428193\n",
      "Error on this batch = 0.03138214462061208\n",
      "Cost on val dataset after 319 epochs is = 0.08307125235269222\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.08307125235269222\n",
      "learning rate for this epoch =  0.35493071854246033\n",
      "Error on this batch = 0.0434203511071135\n",
      "Error on this batch = 0.031254423698650204\n",
      "Cost on val dataset after 320 epochs is = 0.08299409366994055\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.08299409366994055\n",
      "learning rate for this epoch =  0.35465310337619094\n",
      "Error on this batch = 0.04330685075393049\n",
      "Error on this batch = 0.031127140164169113\n",
      "Cost on val dataset after 321 epochs is = 0.08291716600091634\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.08291716600091634\n",
      "learning rate for this epoch =  0.35437657053174126\n",
      "Error on this batch = 0.04319410658967119\n",
      "Error on this batch = 0.031000295537754543\n",
      "Cost on val dataset after 322 epochs is = 0.08284045514928029\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.08284045514928029\n",
      "learning rate for this epoch =  0.3541011124374709\n",
      "Error on this batch = 0.043082055887395845\n",
      "Error on this batch = 0.03087389074432096\n",
      "Cost on val dataset after 323 epochs is = 0.08276394933353749\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.08276394933353749\n",
      "learning rate for this epoch =  0.3538267215980131\n",
      "Error on this batch = 0.04297064258355272\n",
      "Error on this batch = 0.03074792569848509\n",
      "Cost on val dataset after 324 epochs is = 0.08268763960462591\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.08268763960462591\n",
      "learning rate for this epoch =  0.3535533905932738\n",
      "Error on this batch = 0.04285981885628387\n",
      "Error on this batch = 0.030622399012629573\n",
      "Cost on val dataset after 325 epochs is = 0.08261152008067425\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.08261152008067425\n",
      "learning rate for this epoch =  0.35328111207744545\n",
      "Error on this batch = 0.0427495460998852\n",
      "Error on this batch = 0.030497307852494555\n",
      "Cost on val dataset after 326 epochs is = 0.08253558798319333\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.08253558798319333\n",
      "learning rate for this epoch =  0.35300987877803797\n",
      "Error on this batch = 0.04263979525436058\n",
      "Error on this batch = 0.03037264794549797\n",
      "Cost on val dataset after 327 epochs is = 0.08245984348454452\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.08245984348454452\n",
      "learning rate for this epoch =  0.3527396834949245\n",
      "Error on this batch = 0.04253054652571048\n",
      "Error on this batch = 0.0302484137273517\n",
      "Cost on val dataset after 328 epochs is = 0.08238428939809324\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.08238428939809324\n",
      "learning rate for this epoch =  0.3524705190994026\n",
      "Error on this batch = 0.042421788596157785\n",
      "Error on this batch = 0.030124598596587587\n",
      "Cost on val dataset after 329 epochs is = 0.08230893075650113\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.08230893075650113\n",
      "learning rate for this epoch =  0.352202378533271\n",
      "Error on this batch = 0.042313517464459105\n",
      "Error on this batch = 0.030001195236851\n",
      "Cost on val dataset after 330 epochs is = 0.08223377432889752\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.08223377432889752\n",
      "learning rate for this epoch =  0.35193525480792004\n",
      "Error on this batch = 0.04220573507156454\n",
      "Error on this batch = 0.029878195964129044\n",
      "Cost on val dataset after 331 epochs is = 0.08215882812505305\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.08215882812505305\n",
      "learning rate for this epoch =  0.35166914100343716\n",
      "Error on this batch = 0.04209844785882671\n",
      "Error on this batch = 0.029755593059726162\n",
      "Cost on val dataset after 332 epochs is = 0.08208410092640275\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.08208410092640275\n",
      "learning rate for this epoch =  0.3514040302677271\n",
      "Error on this batch = 0.04199166538125461\n",
      "Error on this batch = 0.02963337905797353\n",
      "Cost on val dataset after 333 epochs is = 0.08200960187254508\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.08200960187254508\n",
      "learning rate for this epoch =  0.3511399158156446\n",
      "Error on this batch = 0.04188539906490334\n",
      "Error on this batch = 0.02951154696811803\n",
      "Cost on val dataset after 334 epochs is = 0.08193534012012937\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.08193534012012937\n",
      "learning rate for this epoch =  0.3508767909281421\n",
      "Error on this batch = 0.041779661162602115\n",
      "Error on this batch = 0.029390090420521132\n",
      "Cost on val dataset after 335 epochs is = 0.08186132458059488\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.08186132458059488\n",
      "learning rate for this epoch =  0.35061464895142996\n",
      "Error on this batch = 0.04167446393109741\n",
      "Error on this batch = 0.0292690037366783\n",
      "Cost on val dataset after 336 epochs is = 0.08178756373500798\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.08178756373500798\n",
      "learning rate for this epoch =  0.35035348329615007\n",
      "Error on this batch = 0.04156981902823358\n",
      "Error on this batch = 0.029148281929799933\n",
      "Cost on val dataset after 337 epochs is = 0.08171406551855201\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.08171406551855201\n",
      "learning rate for this epoch =  0.35009328743656276\n",
      "Error on this batch = 0.04146573711188875\n",
      "Error on this batch = 0.029027920647520716\n",
      "Cost on val dataset after 338 epochs is = 0.08164083726387908\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.08164083726387908\n",
      "learning rate for this epoch =  0.3498340549097454\n",
      "Error on this batch = 0.04136222761247447\n",
      "Error on this batch = 0.02890791607091317\n",
      "Cost on val dataset after 339 epochs is = 0.08156788569111184\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.08156788569111184\n",
      "learning rate for this epoch =  0.3495757793148045\n",
      "Error on this batch = 0.04125929864656684\n",
      "Error on this batch = 0.028788264784801464\n",
      "Cost on val dataset after 340 epochs is = 0.08149521693228037\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.08149521693228037\n",
      "learning rate for this epoch =  0.3493184543120991\n",
      "Error on this batch = 0.04115695703909369\n",
      "Error on this batch = 0.028668963633903487\n",
      "Cost on val dataset after 341 epochs is = 0.08142283657891695\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.08142283657891695\n",
      "learning rate for this epoch =  0.34906207362247693\n",
      "Error on this batch = 0.04105520842397744\n",
      "Error on this batch = 0.02855000957804167\n",
      "Cost on val dataset after 342 epochs is = 0.08135074974301613\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.08135074974301613\n",
      "learning rate for this epoch =  0.3488066310265215\n",
      "Error on this batch = 0.04095405739702791\n",
      "Error on this batch = 0.02843139955792525\n",
      "Cost on val dataset after 343 epochs is = 0.08127896112330396\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.08127896112330396\n",
      "learning rate for this epoch =  0.3485521203638112\n",
      "Error on this batch = 0.04085350769932106\n",
      "Error on this batch = 0.028313130381074275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 344 epochs is = 0.08120747507054149\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.08120747507054149\n",
      "learning rate for this epoch =  0.34829853553219003\n",
      "Error on this batch = 0.04075356241371434\n",
      "Error on this batch = 0.028195198635477876\n",
      "Cost on val dataset after 345 epochs is = 0.08113629564728628\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.08113629564728628\n",
      "learning rate for this epoch =  0.3480458704870483\n",
      "Error on this batch = 0.040654224161210284\n",
      "Error on this batch = 0.028077600636626527\n",
      "Cost on val dataset after 346 epochs is = 0.08106542667906957\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.08106542667906957\n",
      "learning rate for this epoch =  0.347794119240616\n",
      "Error on this batch = 0.04055549528743105\n",
      "Error on this batch = 0.027960332411650184\n",
      "Cost on val dataset after 347 epochs is = 0.0809948717952785\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.0809948717952785\n",
      "learning rate for this epoch =  0.3475432758612649\n",
      "Error on this batch = 0.04045737803246425\n",
      "Error on this batch = 0.027843389722425522\n",
      "Cost on val dataset after 348 epochs is = 0.0809246344591404\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.0809246344591404\n",
      "learning rate for this epoch =  0.34729333447282273\n",
      "Error on this batch = 0.040359874679806666\n",
      "Error on this batch = 0.027726768127683935\n",
      "Cost on val dataset after 349 epochs is = 0.08085471798708624\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.08085471798708624\n",
      "learning rate for this epoch =  0.3470442892538971\n",
      "Error on this batch = 0.04026298768211293\n",
      "Error on this batch = 0.027610463082366598\n",
      "Cost on val dataset after 350 epochs is = 0.08078512555842693\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.08078512555842693\n",
      "learning rate for this epoch =  0.34679613443720936\n",
      "Error on this batch = 0.040166719763013045\n",
      "Error on this batch = 0.02749447007076932\n",
      "Cost on val dataset after 351 epochs is = 0.08071586021672042\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.08071586021672042\n",
      "learning rate for this epoch =  0.3465488643089389\n",
      "Error on this batch = 0.04007107399544171\n",
      "Error on this batch = 0.027378784768452156\n",
      "Cost on val dataset after 352 epochs is = 0.08064692486445765\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.08064692486445765\n",
      "learning rate for this epoch =  0.34630247320807694\n",
      "Error on this batch = 0.03997605385777237\n",
      "Error on this batch = 0.027263403226533013\n",
      "Cost on val dataset after 353 epochs is = 0.08057832225277553\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.08057832225277553\n",
      "learning rate for this epoch =  0.34605695552579\n",
      "Error on this batch = 0.039881663269602775\n",
      "Error on this batch = 0.027148322070921573\n",
      "Cost on val dataset after 354 epochs is = 0.08051005496784736\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.08051005496784736\n",
      "learning rate for this epoch =  0.3458123057047929\n",
      "Error on this batch = 0.03978790660932629\n",
      "Error on this batch = 0.02703353870835541\n",
      "Cost on val dataset after 355 epochs is = 0.08044212541543895\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.08044212541543895\n",
      "learning rate for this epoch =  0.3455685182387307\n",
      "Error on this batch = 0.039694788715677866\n",
      "Error on this batch = 0.026919051530831687\n",
      "Cost on val dataset after 356 epochs is = 0.08037453580489361\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.08037453580489361\n",
      "learning rate for this epoch =  0.3453255876715705\n",
      "Error on this batch = 0.039602314875294184\n",
      "Error on this batch = 0.026804860110215316\n",
      "Cost on val dataset after 357 epochs is = 0.08030728813355775\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.08030728813355775\n",
      "learning rate for this epoch =  0.3450835085970013\n",
      "Error on this batch = 0.039510490798022366\n",
      "Error on this batch = 0.026690965375438674\n",
      "Cost on val dataset after 358 epochs is = 0.08024038417241716\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.08024038417241716\n",
      "learning rate for this epoch =  0.34484227565784364\n",
      "Error on this batch = 0.03941932258129308\n",
      "Error on this batch = 0.026577369765745283\n",
      "Cost on val dataset after 359 epochs is = 0.08017382545350854\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.08017382545350854\n",
      "learning rate for this epoch =  0.34460188354546667\n",
      "Error on this batch = 0.039328816664406664\n",
      "Error on this batch = 0.02646407735479152\n",
      "Cost on val dataset after 360 epochs is = 0.08010761325952222\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.08010761325952222\n",
      "learning rate for this epoch =  0.34436232699921493\n",
      "Error on this batch = 0.03923897977312197\n",
      "Error on this batch = 0.026351093941997323\n",
      "Cost on val dataset after 361 epochs is = 0.08004174861592615\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.08004174861592615\n",
      "learning rate for this epoch =  0.3441236008058426\n",
      "Error on this batch = 0.03914981885455426\n",
      "Error on this batch = 0.026238427109213928\n",
      "Cost on val dataset after 362 epochs is = 0.07997623228591481\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.07997623228591481\n",
      "learning rate for this epoch =  0.34388569979895683\n",
      "Error on this batch = 0.03906134100213499\n",
      "Error on this batch = 0.026126086242424847\n",
      "Cost on val dataset after 363 epochs is = 0.07991106476850768\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.07991106476850768\n",
      "learning rate for this epoch =  0.3436486188584679\n",
      "Error on this batch = 0.03897355337031173\n",
      "Error on this batch = 0.026014082519704336\n",
      "Cost on val dataset after 364 epochs is = 0.07984624630016986\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.07984624630016986\n",
      "learning rate for this epoch =  0.3434123529100486\n",
      "Error on this batch = 0.03888646307879972\n",
      "Error on this batch = 0.025902428867928942\n",
      "Cost on val dataset after 365 epochs is = 0.07978177686037818\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.07978177686037818\n",
      "learning rate for this epoch =  0.3431768969246008\n",
      "Error on this batch = 0.038800077106547246\n",
      "Error on this batch = 0.025791139891701117\n",
      "Cost on val dataset after 366 epochs is = 0.07971765618158543\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.07971765618158543\n",
      "learning rate for this epoch =  0.3429422459177292\n",
      "Error on this batch = 0.0387144021761321\n",
      "Error on this batch = 0.025680231778559142\n",
      "Cost on val dataset after 367 epochs is = 0.07965388376402321\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.07965388376402321\n",
      "learning rate for this epoch =  0.3427083949492237\n",
      "Error on this batch = 0.03862944463002816\n",
      "Error on this batch = 0.02556972218480291\n",
      "Cost on val dataset after 368 epochs is = 0.0795904588957133\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.0795904588957133\n",
      "learning rate for this epoch =  0.34247533912254846\n",
      "Error on this batch = 0.03854521030101164\n",
      "Error on this batch = 0.02545963010617812\n",
      "Cost on val dataset after 369 epochs is = 0.07952738067792132\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.07952738067792132\n",
      "learning rate for this epoch =  0.342243073584338\n",
      "Error on this batch = 0.03846170437983779\n",
      "Error on this batch = 0.025349975737275505\n",
      "Cost on val dataset after 370 epochs is = 0.0794646480560864\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.0794646480560864\n",
      "learning rate for this epoch =  0.3420115935239011\n",
      "Error on this batch = 0.038378931284124465\n",
      "Error on this batch = 0.02524078032288302\n",
      "Cost on val dataset after 371 epochs is = 0.07940225985600291\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.07940225985600291\n",
      "learning rate for this epoch =  0.34178089417273183\n",
      "Error on this batch = 0.03829689453303479\n",
      "Error on this batch = 0.025132066003758845\n",
      "Cost on val dataset after 372 epochs is = 0.07934021482473512\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.07934021482473512\n",
      "learning rate for this epoch =  0.34155097080402635\n",
      "Error on this batch = 0.03821559663277275\n",
      "Error on this batch = 0.02502385565846579\n",
      "Cost on val dataset after 373 epochs is = 0.07927851167542896\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.07927851167542896\n",
      "learning rate for this epoch =  0.3413218187322076\n",
      "Error on this batch = 0.03813503897802086\n",
      "Error on this batch = 0.02491617274211978\n",
      "Cost on val dataset after 374 epochs is = 0.07921714913487699\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.07921714913487699\n",
      "learning rate for this epoch =  0.3410934333124567\n",
      "Error on this batch = 0.038055221774211175\n",
      "Error on this batch = 0.024809041122248104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 375 epochs is = 0.07915612599241216\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.07915612599241216\n",
      "learning rate for this epoch =  0.34086580994024984\n",
      "Error on this batch = 0.03797614398491737\n",
      "Error on this batch = 0.024702484911506128\n",
      "Cost on val dataset after 376 epochs is = 0.0790954411484812\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.0790954411484812\n",
      "learning rate for this epoch =  0.34063894405090306\n",
      "Error on this batch = 0.03789780330770626\n",
      "Error on this batch = 0.024596528296819298\n",
      "Cost on val dataset after 377 epochs is = 0.07903509366109525\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.07903509366109525\n",
      "learning rate for this epoch =  0.3404128311191223\n",
      "Error on this batch = 0.03782019618055187\n",
      "Error on this batch = 0.024491195364629702\n",
      "Cost on val dataset after 378 epochs is = 0.07897508278829228\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.07897508278829228\n",
      "learning rate for this epoch =  0.3401874666585601\n",
      "Error on this batch = 0.037743317819483604\n",
      "Error on this batch = 0.02438650992232609\n",
      "Cost on val dataset after 379 epochs is = 0.07891540802478109\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.07891540802478109\n",
      "learning rate for this epoch =  0.3399628462213785\n",
      "Error on this batch = 0.03766716228662497\n",
      "Error on this batch = 0.02428249531658843\n",
      "Cost on val dataset after 380 epochs is = 0.07885606913107543\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.07885606913107543\n",
      "learning rate for this epoch =  0.3397389653978181\n",
      "Error on this batch = 0.03759172258630291\n",
      "Error on this batch = 0.024179174250214503\n",
      "Cost on val dataset after 381 epochs is = 0.07879706615366593\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.07879706615366593\n",
      "learning rate for this epoch =  0.3395158198157724\n",
      "Error on this batch = 0.03751699078558738\n",
      "Error on this batch = 0.02407656859993138\n",
      "Cost on val dataset after 382 epochs is = 0.07873839943510896\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.07873839943510896\n",
      "learning rate for this epoch =  0.3392934051403688\n",
      "Error on this batch = 0.037442958154552126\n",
      "Error on this batch = 0.02397469923862944\n",
      "Cost on val dataset after 383 epochs is = 0.07868006961331642\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.07868006961331642\n",
      "learning rate for this epoch =  0.33907171707355527\n",
      "Error on this batch = 0.037369615320799035\n",
      "Error on this batch = 0.023873585866286278\n",
      "Cost on val dataset after 384 epochs is = 0.07862207760978626\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.07862207760978626\n",
      "learning rate for this epoch =  0.33885075135369186\n",
      "Error on this batch = 0.03729695243238466\n",
      "Error on this batch = 0.02377324685447976\n",
      "Cost on val dataset after 385 epochs is = 0.07856442460698679\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.07856442460698679\n",
      "learning rate for this epoch =  0.3386305037551487\n",
      "Error on this batch = 0.037224959323221014\n",
      "Error on this batch = 0.023673699109736077\n",
      "Cost on val dataset after 386 epochs is = 0.07850711201556512\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.07850711201556512\n",
      "learning rate for this epoch =  0.3384109700879091\n",
      "Error on this batch = 0.037153625675247305\n",
      "Error on this batch = 0.02357495796095313\n",
      "Cost on val dataset after 387 epochs is = 0.0784501414324519\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.0784501414324519\n",
      "learning rate for this epoch =  0.33819214619717813\n",
      "Error on this batch = 0.03708294117212173\n",
      "Error on this batch = 0.02347703707573764\n",
      "Cost on val dataset after 388 epochs is = 0.07839351459124724\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.07839351459124724\n",
      "learning rate for this epoch =  0.3379740279629962\n",
      "Error on this batch = 0.037012895639786374\n",
      "Error on this batch = 0.023379948409667565\n",
      "Cost on val dataset after 389 epochs is = 0.0783372333064684\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.0783372333064684\n",
      "learning rate for this epoch =  0.33775661129985834\n",
      "Error on this batch = 0.036943479169944435\n",
      "Error on this batch = 0.023283702191250234\n",
      "Cost on val dataset after 390 epochs is = 0.07828129941329605\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.07828129941329605\n",
      "learning rate for this epoch =  0.3375398921563383\n",
      "Error on this batch = 0.0368746822232037\n",
      "Error on this batch = 0.023188306943724674\n",
      "Cost on val dataset after 391 epochs is = 0.07822571470437165\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.07822571470437165\n",
      "learning rate for this epoch =  0.3373238665147177\n",
      "Error on this batch = 0.03680649570935003\n",
      "Error on this batch = 0.023093769542933178\n",
      "Cost on val dataset after 392 epochs is = 0.07817048086497232\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.07817048086497232\n",
      "learning rate for this epoch =  0.33710853039062016\n",
      "Error on this batch = 0.03673891104291311\n",
      "Error on this batch = 0.023000095308383824\n",
      "Cost on val dataset after 393 epochs is = 0.07811559940754913\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.07811559940754913\n",
      "learning rate for this epoch =  0.3368938798326509\n",
      "Error on this batch = 0.03667192017288395\n",
      "Error on this batch = 0.02290728812250257\n",
      "Cost on val dataset after 394 epochs is = 0.0780610716061854\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.0780610716061854\n",
      "learning rate for this epoch =  0.33667991092203975\n",
      "Error on this batch = 0.03660551558616639\n",
      "Error on this batch = 0.0228153505711299\n",
      "Cost on val dataset after 395 epochs is = 0.07800689843106337\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.07800689843106337\n",
      "learning rate for this epoch =  0.33646661977229064\n",
      "Error on this batch = 0.036539690285119567\n",
      "Error on this batch = 0.022724284096759997\n",
      "Cost on val dataset after 396 epochs is = 0.07795308048257027\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.07795308048257027\n",
      "learning rate for this epoch =  0.33625400252883436\n",
      "Error on this batch = 0.036474437740393086\n",
      "Error on this batch = 0.022634089155044272\n",
      "Cost on val dataset after 397 epochs is = 0.07789961792429317\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.07789961792429317\n",
      "learning rate for this epoch =  0.33604205536868675\n",
      "Error on this batch = 0.036409751821176964\n",
      "Error on this batch = 0.02254476536482693\n",
      "Cost on val dataset after 398 epochs is = 0.07784651041390593\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.07784651041390593\n",
      "learning rate for this epoch =  0.3358307745001108\n",
      "Error on this batch = 0.03634562670595807\n",
      "Error on this batch = 0.02245631164250849\n",
      "Cost on val dataset after 399 epochs is = 0.07779375703090127\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.07779375703090127\n",
      "learning rate for this epoch =  0.3356201561622838\n",
      "Error on this batch = 0.03628205677785051\n",
      "Error on this batch = 0.02236872631279765\n",
      "Cost on val dataset after 400 epochs is = 0.07774135620031551\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.07774135620031551\n",
      "learning rate for this epoch =  0.33541019662496846\n",
      "Error on this batch = 0.03621903650947794\n",
      "Error on this batch = 0.022282007189765134\n",
      "Cost on val dataset after 401 epochs is = 0.07768930561205763\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.07768930561205763\n",
      "learning rate for this epoch =  0.33520089218818844\n",
      "Error on this batch = 0.036156560343146536\n",
      "Error on this batch = 0.022196151624328544\n",
      "Cost on val dataset after 402 epochs is = 0.077637602136196\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.077637602136196\n",
      "learning rate for this epoch =  0.33499223918190807\n",
      "Error on this batch = 0.03609462257257504\n",
      "Error on this batch = 0.022111156516611816\n",
      "Cost on val dataset after 403 epochs is = 0.0775862417355476\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.0775862417355476\n",
      "learning rate for this epoch =  0.3347842339657164\n",
      "Error on this batch = 0.03603321723266364\n",
      "Error on this batch = 0.022027018293795934\n",
      "Cost on val dataset after 404 epochs is = 0.0775352193781036\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.0775352193781036\n",
      "learning rate for this epoch =  0.3345768729285152\n",
      "Error on this batch = 0.03597233800363449\n",
      "Error on this batch = 0.021943732855936912\n",
      "Cost on val dataset after 405 epochs is = 0.0774845289531313\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.0774845289531313\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.03591197813534188\n",
      "Error on this batch = 0.021861295493704497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 406 epochs is = 0.07743416319611043\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.07743416319611043\n",
      "learning rate for this epoch =  0.3341640690914115\n",
      "Error on this batch = 0.03585213039663882\n",
      "Error on this batch = 0.021779700783133245\n",
      "Cost on val dataset after 407 epochs is = 0.07738411362886483\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.07738411362886483\n",
      "learning rate for this epoch =  0.33395861921312525\n",
      "Error on this batch = 0.035792787053447676\n",
      "Error on this batch = 0.021698942463402537\n",
      "Cost on val dataset after 408 epochs is = 0.07733437052219436\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.07733437052219436\n",
      "learning rate for this epoch =  0.33375379935646554\n",
      "Error on this batch = 0.035733939877688206\n",
      "Error on this batch = 0.02161901330454051\n",
      "Cost on val dataset after 409 epochs is = 0.07728492288883662\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.07728492288883662\n",
      "learning rate for this epoch =  0.3335496060523584\n",
      "Error on this batch = 0.035675580187561125\n",
      "Error on this batch = 0.02153990497292501\n",
      "Cost on val dataset after 410 epochs is = 0.07723575851452429\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.07723575851452429\n",
      "learning rate for this epoch =  0.33334603585925365\n",
      "Error on this batch = 0.03561769891797776\n",
      "Error on this batch = 0.021461607903593007\n",
      "Cost on val dataset after 411 epochs is = 0.07718686403409755\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.07718686403409755\n",
      "learning rate for this epoch =  0.33314308536284043\n",
      "Error on this batch = 0.03556028671827535\n",
      "Error on this batch = 0.0213841111895985\n",
      "Cost on val dataset after 412 epochs is = 0.07713822505795409\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.07713822505795409\n",
      "learning rate for this epoch =  0.3329407511757655\n",
      "Error on this batch = 0.03550333407287061\n",
      "Error on this batch = 0.021307402499755376\n",
      "Cost on val dataset after 413 epochs is = 0.07708982635152802\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.07708982635152802\n",
      "learning rate for this epoch =  0.33273902993735593\n",
      "Error on this batch = 0.03544683143927273\n",
      "Error on this batch = 0.021231468036699407\n",
      "Cost on val dataset after 414 epochs is = 0.0770416520670385\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.0770416520670385\n",
      "learning rate for this epoch =  0.33253791831334495\n",
      "Error on this batch = 0.03539076939697793\n",
      "Error on this batch = 0.02115629254686124\n",
      "Cost on val dataset after 415 epochs is = 0.07699368602265898\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.07699368602265898\n",
      "learning rate for this epoch =  0.33233741299560093\n",
      "Error on this batch = 0.0353351388002429\n",
      "Error on this batch = 0.021081859392236845\n",
      "Cost on val dataset after 416 epochs is = 0.07694591201989284\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.07694591201989284\n",
      "learning rate for this epoch =  0.33213751070186054\n",
      "Error on this batch = 0.03527993092760307\n",
      "Error on this batch = 0.021008150690508078\n",
      "Cost on val dataset after 417 epochs is = 0.07689831418581894\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.07689831418581894\n",
      "learning rate for this epoch =  0.3319382081754647\n",
      "Error on this batch = 0.0352251376212457\n",
      "Error on this batch = 0.020935147525118526\n",
      "Cost on val dataset after 418 epochs is = 0.07685087732356986\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.07685087732356986\n",
      "learning rate for this epoch =  0.331739502185098\n",
      "Error on this batch = 0.03517075140992527\n",
      "Error on this batch = 0.020862830220732435\n",
      "Cost on val dataset after 419 epochs is = 0.07680358725248353\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.07680358725248353\n",
      "learning rate for this epoch =  0.33154138952453144\n",
      "Error on this batch = 0.03511676560996283\n",
      "Error on this batch = 0.02079117867284671\n",
      "Cost on val dataset after 420 epochs is = 0.07675643111922317\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.07675643111922317\n",
      "learning rate for this epoch =  0.3313438670123683\n",
      "Error on this batch = 0.03506317439993802\n",
      "Error on this batch = 0.02072017271419159\n",
      "Cost on val dataset after 421 epochs is = 0.07670939766294149\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.07670939766294149\n",
      "learning rate for this epoch =  0.3311469314917932\n",
      "Error on this batch = 0.03500997286590552\n",
      "Error on this batch = 0.020649792495997975\n",
      "Cost on val dataset after 422 epochs is = 0.07666247742110377\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.07666247742110377\n",
      "learning rate for this epoch =  0.3309505798303245\n",
      "Error on this batch = 0.03495715701529799\n",
      "Error on this batch = 0.020580018860079687\n",
      "Cost on val dataset after 423 epochs is = 0.07661566286743153\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.07661566286743153\n",
      "learning rate for this epoch =  0.33075480891956943\n",
      "Error on this batch = 0.034904723759071415\n",
      "Error on this batch = 0.02051083367840838\n",
      "Cost on val dataset after 424 epochs is = 0.07656894847891509\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.07656894847891509\n",
      "learning rate for this epoch =  0.33055961567498265\n",
      "Error on this batch = 0.03485267086306182\n",
      "Error on this batch = 0.020442220140338137\n",
      "Cost on val dataset after 425 epochs is = 0.07652233073424836\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.07652233073424836\n",
      "learning rate for this epoch =  0.330364997035627\n",
      "Error on this batch = 0.03480099687089993\n",
      "Error on this batch = 0.020374162973257493\n",
      "Cost on val dataset after 426 epochs is = 0.07647580805069977\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.07647580805069977\n",
      "learning rate for this epoch =  0.33017094996393853\n",
      "Error on this batch = 0.034749701002100356\n",
      "Error on this batch = 0.02030664858924333\n",
      "Cost on val dataset after 427 epochs is = 0.07642938066988854\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.07642938066988854\n",
      "learning rate for this epoch =  0.32997747144549294\n",
      "Error on this batch = 0.03469878303002759\n",
      "Error on this batch = 0.020239665157193994\n",
      "Cost on val dataset after 428 epochs is = 0.07638305050495656\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.07638305050495656\n",
      "learning rate for this epoch =  0.32978455848877636\n",
      "Error on this batch = 0.03464824314525888\n",
      "Error on this batch = 0.020173202605973734\n",
      "Cost on val dataset after 429 epochs is = 0.07633682096223332\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.07633682096223332\n",
      "learning rate for this epoch =  0.3295922081249574\n",
      "Error on this batch = 0.03459808181035105\n",
      "Error on this batch = 0.020107252568645616\n",
      "Cost on val dataset after 430 epochs is = 0.07629069674988605\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.07629069674988605\n",
      "learning rate for this epoch =  0.3294004174076632\n",
      "Error on this batch = 0.03454829961213569\n",
      "Error on this batch = 0.020041808280602803\n",
      "Cost on val dataset after 431 epochs is = 0.07624468368454973\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.07624468368454973\n",
      "learning rate for this epoch =  0.3292091834127578\n",
      "Error on this batch = 0.03449889711741751\n",
      "Error on this batch = 0.019976864445365523\n",
      "Cost on val dataset after 432 epochs is = 0.07619878850489109\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.07619878850489109\n",
      "learning rate for this epoch =  0.32901850323812315\n",
      "Error on this batch = 0.03444987473737121\n",
      "Error on this batch = 0.01991241708127369\n",
      "Cost on val dataset after 433 epochs is = 0.07615301869880342\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.07615301869880342\n",
      "learning rate for this epoch =  0.3288283740034425\n",
      "Error on this batch = 0.034401232605093625\n",
      "Error on this batch = 0.019848463360694502\n",
      "Cost on val dataset after 434 epochs is = 0.07610738234871688\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.07610738234871688\n",
      "learning rate for this epoch =  0.32863879284998726\n",
      "Error on this batch = 0.03435297046976082\n",
      "Error on this batch = 0.01978500145112501\n",
      "Cost on val dataset after 435 epochs is = 0.07606188799752235\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.07606188799752235\n",
      "learning rate for this epoch =  0.32844975694040546\n",
      "Error on this batch = 0.03430508760975952\n",
      "Error on this batch = 0.019722030365101482\n",
      "Cost on val dataset after 436 epochs is = 0.0760165445359516\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.0760165445359516\n",
      "learning rate for this epoch =  0.3282612634585134\n",
      "Error on this batch = 0.034257582766098596\n",
      "Error on this batch = 0.019659549823436255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 437 epochs is = 0.07597136111096957\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.07597136111096957\n",
      "learning rate for this epoch =  0.3280733096090895\n",
      "Error on this batch = 0.03421045409643084\n",
      "Error on this batch = 0.019597560134192806\n",
      "Cost on val dataset after 438 epochs is = 0.07592634705381178\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.07592634705381178\n",
      "learning rate for this epoch =  0.32788589261767076\n",
      "Error on this batch = 0.03416369914918122\n",
      "Error on this batch = 0.019536062088087572\n",
      "Cost on val dataset after 439 epochs is = 0.0758815118256989\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.0758815118256989\n",
      "learning rate for this epoch =  0.3276990097303519\n",
      "Error on this batch = 0.03411731485661171\n",
      "Error on this batch = 0.019475056869708178\n",
      "Cost on val dataset after 440 epochs is = 0.07583686497893145\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.07583686497893145\n",
      "learning rate for this epoch =  0.3275126582135859\n",
      "Error on this batch = 0.03407129754516068\n",
      "Error on this batch = 0.01941454598304098\n",
      "Cost on val dataset after 441 epochs is = 0.07579241613094696\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.07579241613094696\n",
      "learning rate for this epoch =  0.3273268353539886\n",
      "Error on this batch = 0.03402564296107157\n",
      "Error on this batch = 0.01935453118926055\n",
      "Cost on val dataset after 442 epochs is = 0.07574817494895396\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.07574817494895396\n",
      "learning rate for this epoch =  0.3271415384581438\n",
      "Error on this batch = 0.03398034630914199\n",
      "Error on this batch = 0.01929501445448544\n",
      "Cost on val dataset after 443 epochs is = 0.0757041511428925\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.0757041511428925\n",
      "learning rate for this epoch =  0.32695676485241204\n",
      "Error on this batch = 0.0339354023023598\n",
      "Error on this batch = 0.019235997905184817\n",
      "Cost on val dataset after 444 epochs is = 0.07566035446466347\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.07566035446466347\n",
      "learning rate for this epoch =  0.32677251188274103\n",
      "Error on this batch = 0.03389080522021063\n",
      "Error on this batch = 0.019177483789068465\n",
      "Cost on val dataset after 445 epochs is = 0.07561679471178749\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.07561679471178749\n",
      "learning rate for this epoch =  0.3265887769144783\n",
      "Error on this batch = 0.033846548973515155\n",
      "Error on this batch = 0.01911947443955715\n",
      "Cost on val dataset after 446 epochs is = 0.07557348173387488\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.07557348173387488\n",
      "learning rate for this epoch =  0.32640555733218624\n",
      "Error on this batch = 0.03380262717376018\n",
      "Error on this batch = 0.019061972242264625\n",
      "Cost on val dataset after 447 epochs is = 0.07553042544049036\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.07553042544049036\n",
      "learning rate for this epoch =  0.32622285053945943\n",
      "Error on this batch = 0.03375903320500367\n",
      "Error on this batch = 0.019004979602293654\n",
      "Cost on val dataset after 448 epochs is = 0.0754876358091747\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.0754876358091747\n",
      "learning rate for this epoch =  0.3260406539587436\n",
      "Error on this batch = 0.03371576029654974\n",
      "Error on this batch = 0.018948498911524305\n",
      "Cost on val dataset after 449 epochs is = 0.07544512289253033\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.07544512289253033\n",
      "learning rate for this epoch =  0.32585896503115724\n",
      "Error on this batch = 0.03367280159469917\n",
      "Error on this batch = 0.018892532515430008\n",
      "Cost on val dataset after 450 epochs is = 0.07540289682339256\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.07540289682339256\n",
      "learning rate for this epoch =  0.3256777812163153\n",
      "Error on this batch = 0.033630150231983305\n",
      "Error on this batch = 0.018837082679277098\n",
      "Cost on val dataset after 451 epochs is = 0.07536096781719424\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.07536096781719424\n",
      "learning rate for this epoch =  0.3254970999921543\n",
      "Error on this batch = 0.03358779939239009\n",
      "Error on this batch = 0.018782151553831443\n",
      "Cost on val dataset after 452 epochs is = 0.07531934617069452\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.07531934617069452\n",
      "learning rate for this epoch =  0.32531691885476033\n",
      "Error on this batch = 0.03354574237119852\n",
      "Error on this batch = 0.01872774114090198\n",
      "Cost on val dataset after 453 epochs is = 0.07527804225629196\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.07527804225629196\n",
      "learning rate for this epoch =  0.32513723531819827\n",
      "Error on this batch = 0.033503972628162314\n",
      "Error on this batch = 0.018673853259191815\n",
      "Cost on val dataset after 454 epochs is = 0.07523706651118726\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.07523706651118726\n",
      "learning rate for this epoch =  0.3249580469143436\n",
      "Error on this batch = 0.033462483832934986\n",
      "Error on this batch = 0.01862048951100452\n",
      "Cost on val dataset after 455 epochs is = 0.07519642942071221\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.07519642942071221\n",
      "learning rate for this epoch =  0.32477935119271584\n",
      "Error on this batch = 0.033421269901817235\n",
      "Error on this batch = 0.01856765125037318\n",
      "Cost on val dataset after 456 epochs is = 0.07515614149521174\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.07515614149521174\n",
      "learning rate for this epoch =  0.32460114572031407\n",
      "Error on this batch = 0.03338032502513771\n",
      "Error on this batch = 0.018515339553154524\n",
      "Cost on val dataset after 457 epochs is = 0.07511621323996488\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.07511621323996488\n",
      "learning rate for this epoch =  0.3244234280814539\n",
      "Error on this batch = 0.033339643684853065\n",
      "Error on this batch = 0.018463555189576035\n",
      "Cost on val dataset after 458 epochs is = 0.07507665511776798\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.07507665511776798\n",
      "learning rate for this epoch =  0.324246195877607\n",
      "Error on this batch = 0.03329922066226837\n",
      "Error on this batch = 0.018412298599652998\n",
      "Cost on val dataset after 459 epochs is = 0.07503747750398572\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.07503747750398572\n",
      "learning rate for this epoch =  0.324069446727242\n",
      "Error on this batch = 0.033259051036126\n",
      "Error on this batch = 0.018361569871822653\n",
      "Cost on val dataset after 460 epochs is = 0.07499869063410425\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.07499869063410425\n",
      "learning rate for this epoch =  0.32389317826566727\n",
      "Error on this batch = 0.03321913017167614\n",
      "Error on this batch = 0.018311368725077933\n",
      "Cost on val dataset after 461 epochs is = 0.07496030454409233\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.07496030454409233\n",
      "learning rate for this epoch =  0.32371738814487555\n",
      "Error on this batch = 0.03317945370170495\n",
      "Error on this batch = 0.018261694494833416\n",
      "Cost on val dataset after 462 epochs is = 0.07492232900418075\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.07492232900418075\n",
      "learning rate for this epoch =  0.3235420740333905\n",
      "Error on this batch = 0.03314001750083665\n",
      "Error on this batch = 0.018212546122713565\n",
      "Cost on val dataset after 463 epochs is = 0.0748847734469916\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.0748847734469916\n",
      "learning rate for this epoch =  0.3233672336161148\n",
      "Error on this batch = 0.03310081765471881\n",
      "Error on this batch = 0.0181639221504153\n",
      "Cost on val dataset after 464 epochs is = 0.07484764689126622\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.07484764689126622\n",
      "learning rate for this epoch =  0.3231928645941795\n",
      "Error on this batch = 0.03306185042592324\n",
      "Error on this batch = 0.018115820717752387\n",
      "Cost on val dataset after 465 epochs is = 0.07481095786272762\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.07481095786272762\n",
      "learning rate for this epoch =  0.3230189646847966\n",
      "Error on this batch = 0.03302311221852925\n",
      "Error on this batch = 0.01806823956492983\n",
      "Cost on val dataset after 466 epochs is = 0.0747747143138473\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.0747747143138473\n",
      "learning rate for this epoch =  0.3228455316211112\n",
      "Error on this batch = 0.032984599543386325\n",
      "Error on this batch = 0.018021176039017046\n",
      "Cost on val dataset after 467 epochs is = 0.07473892354444135\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.07473892354444135\n",
      "learning rate for this epoch =  0.32267256315205695\n",
      "Error on this batch = 0.03294630898597504\n",
      "Error on this batch = 0.017974627104488907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 468 epochs is = 0.0747035921250827\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.0747035921250827\n",
      "learning rate for this epoch =  0.3225000570422127\n",
      "Error on this batch = 0.03290823717859911\n",
      "Error on this batch = 0.017928589357588513\n",
      "Cost on val dataset after 469 epochs is = 0.07466872582527245\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.07466872582527245\n",
      "learning rate for this epoch =  0.32232801107166015\n",
      "Error on this batch = 0.032870380778361026\n",
      "Error on this batch = 0.01788305904414689\n",
      "Cost on val dataset after 470 epochs is = 0.07463432954816626\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.07463432954816626\n",
      "learning rate for this epoch =  0.32215642303584385\n",
      "Error on this batch = 0.03283273645201765\n",
      "Error on this batch = 0.017838032080384286\n",
      "Cost on val dataset after 471 epochs is = 0.07460040727341115\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.07460040727341115\n",
      "learning rate for this epoch =  0.3219852907454323\n",
      "Error on this batch = 0.03279530086840736\n",
      "Error on this batch = 0.017793504076131648\n",
      "Cost on val dataset after 472 epochs is = 0.07456696200932904\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.07456696200932904\n",
      "learning rate for this epoch =  0.32181461202618095\n",
      "Error on this batch = 0.03275807069871624\n",
      "Error on this batch = 0.017749470359858504\n",
      "Cost on val dataset after 473 epochs is = 0.07453399575531627\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.07453399575531627\n",
      "learning rate for this epoch =  0.32164438471879647\n",
      "Error on this batch = 0.03272104262443564\n",
      "Error on this batch = 0.017705926004883295\n",
      "Cost on val dataset after 474 epochs is = 0.07450150947493626\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.07450150947493626\n",
      "learning rate for this epoch =  0.3214746066788024\n",
      "Error on this batch = 0.032684213352485995\n",
      "Error on this batch = 0.01766286585617267\n",
      "Cost on val dataset after 475 epochs is = 0.0744695030797946\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.0744695030797946\n",
      "learning rate for this epoch =  0.3213052757764068\n",
      "Error on this batch = 0.032647579636659\n",
      "Error on this batch = 0.017620284557204324\n",
      "Cost on val dataset after 476 epochs is = 0.0744379754239307\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.0744379754239307\n",
      "learning rate for this epoch =  0.3211363898963706\n",
      "Error on this batch = 0.03261113830427959\n",
      "Error on this batch = 0.017578176576460772\n",
      "Cost on val dataset after 477 epochs is = 0.07440692430815472\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.07440692430815472\n",
      "learning rate for this epoch =  0.32096794693787845\n",
      "Error on this batch = 0.032574886286813425\n",
      "Error on this batch = 0.017536536233228883\n",
      "Cost on val dataset after 478 epochs is = 0.0743763464935177\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.0743763464935177\n",
      "learning rate for this epoch =  0.32079994481440977\n",
      "Error on this batch = 0.03253882065304521\n",
      "Error on this batch = 0.017495357722485397\n",
      "Cost on val dataset after 479 epochs is = 0.07434623772293948\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.07434623772293948\n",
      "learning rate for this epoch =  0.3206323814536121\n",
      "Error on this batch = 0.0325029386434226\n",
      "Error on this batch = 0.017454635138743145\n",
      "Cost on val dataset after 480 epochs is = 0.0743165927499283\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.0743165927499283\n",
      "learning rate for this epoch =  0.3204652547971755\n",
      "Error on this batch = 0.03246723770418737\n",
      "Error on this batch = 0.01741436249880538\n",
      "Cost on val dataset after 481 epochs is = 0.07428740537330887\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.07428740537330887\n",
      "learning rate for this epoch =  0.3202985628007086\n",
      "Error on this batch = 0.03243171551999081\n",
      "Error on this batch = 0.017374533763422042\n",
      "Cost on val dataset after 482 epochs is = 0.07425866847692467\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.07425866847692467\n",
      "learning rate for this epoch =  0.32013230343361526\n",
      "Error on this batch = 0.032396370043799624\n",
      "Error on this batch = 0.017335142857862508\n",
      "Cost on val dataset after 483 epochs is = 0.07423037407338168\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.07423037407338168\n",
      "learning rate for this epoch =  0.3199664746789736\n",
      "Error on this batch = 0.03236119952303219\n",
      "Error on this batch = 0.017296183691414554\n",
      "Cost on val dataset after 484 epochs is = 0.07420251335104436\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.07420251335104436\n",
      "learning rate for this epoch =  0.31980107453341566\n",
      "Error on this batch = 0.03232620252101326\n",
      "Error on this batch = 0.01725765017579703\n",
      "Cost on val dataset after 485 epochs is = 0.07417507672366486\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.07417507672366486\n",
      "learning rate for this epoch =  0.3196361010070084\n",
      "Error on this batch = 0.03229137793299118\n",
      "Error on this batch = 0.01721953624243891\n",
      "Cost on val dataset after 486 epochs is = 0.07414805388220978\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.07414805388220978\n",
      "learning rate for this epoch =  0.31947155212313627\n",
      "Error on this batch = 0.032256724996119646\n",
      "Error on this batch = 0.01718183585853849\n",
      "Cost on val dataset after 487 epochs is = 0.074121433848629\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.074121433848629\n",
      "learning rate for this epoch =  0.31930742591838485\n",
      "Error on this batch = 0.032222243292965795\n",
      "Error on this batch = 0.01714454304178076\n",
      "Cost on val dataset after 488 epochs is = 0.07409520503147694\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.07409520503147694\n",
      "learning rate for this epoch =  0.31914372044242595\n",
      "Error on this batch = 0.03218793274826302\n",
      "Error on this batch = 0.01710765187356353\n",
      "Cost on val dataset after 489 epochs is = 0.07406935528343242\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.07406935528343242\n",
      "learning rate for this epoch =  0.3189804337579035\n",
      "Error on this batch = 0.03215379361878465\n",
      "Error on this batch = 0.017071156510570496\n",
      "Cost on val dataset after 490 epochs is = 0.07404387196086083\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.07404387196086083\n",
      "learning rate for this epoch =  0.3188175639403211\n",
      "Error on this batch = 0.032119826476370544\n",
      "Error on this batch = 0.017035051194532483\n",
      "Cost on val dataset after 491 epochs is = 0.07401874198561129\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.07401874198561129\n",
      "learning rate for this epoch =  0.31865510907793076\n",
      "Error on this batch = 0.03208603218429614\n",
      "Error on this batch = 0.016999330260040458\n",
      "Cost on val dataset after 492 epochs is = 0.07399395190923731\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.07399395190923731\n",
      "learning rate for this epoch =  0.3184930672716223\n",
      "Error on this batch = 0.032052411867330585\n",
      "Error on this batch = 0.016963988140313992\n",
      "Cost on val dataset after 493 epochs is = 0.07396948797976946\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.07396948797976946\n",
      "learning rate for this epoch =  0.31833143663481483\n",
      "Error on this batch = 0.03201896687598764\n",
      "Error on this batch = 0.016929019370884636\n",
      "Cost on val dataset after 494 epochs is = 0.07394533621105641\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.07394533621105641\n",
      "learning rate for this epoch =  0.31817021529334844\n",
      "Error on this batch = 0.03198569874562679\n",
      "Error on this batch = 0.016894418591222295\n",
      "Cost on val dataset after 495 epochs is = 0.07392148245453112\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.07392148245453112\n",
      "learning rate for this epoch =  0.31800940138537775\n",
      "Error on this batch = 0.031952609151209274\n",
      "Error on this batch = 0.01686018054440984\n",
      "Cost on val dataset after 496 epochs is = 0.07389791247306646\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.07389791247306646\n",
      "learning rate for this epoch =  0.31784899306126624\n",
      "Error on this batch = 0.03191969985864717\n",
      "Error on this batch = 0.01682630007505039\n",
      "Cost on val dataset after 497 epochs is = 0.07387461201637092\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.07387461201637092\n",
      "learning rate for this epoch =  0.31768898848348165\n",
      "Error on this batch = 0.03188697267379885\n",
      "Error on this batch = 0.016792772125668837\n",
      "Cost on val dataset after 498 epochs is = 0.07385156689716234\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.07385156689716234\n",
      "learning rate for this epoch =  0.31752938582649276\n",
      "Error on this batch = 0.03185442939025148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.016759591731935832\n",
      "Cost on val dataset after 499 epochs is = 0.0738287630671622\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.0738287630671622\n",
      "learning rate for this epoch =  0.31737018327666694\n",
      "Error on this batch = 0.03182207173708436\n",
      "Error on this batch = 0.016726754017095363\n",
      "Cost on val dataset after 500 epochs is = 0.07380618669179863\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.07380618669179863\n",
      "learning rate for this epoch =  0.3172113790321692\n",
      "Error on this batch = 0.031789901327819434\n",
      "Error on this batch = 0.016694254186009505\n",
      "Cost on val dataset after 501 epochs is = 0.0737838242224041\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.0737838242224041\n",
      "learning rate for this epoch =  0.3170529713028618\n",
      "Error on this batch = 0.03175791961173336\n",
      "Error on this batch = 0.016662087519243217\n",
      "Cost on val dataset after 502 epochs is = 0.0737616624646629\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.0737616624646629\n",
      "learning rate for this epoch =  0.31689495831020514\n",
      "Error on this batch = 0.03172612782862725\n",
      "Error on this batch = 0.016630249367596696\n",
      "Cost on val dataset after 503 epochs is = 0.07373968864210499\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.07373968864210499\n",
      "learning rate for this epoch =  0.31673733828715983\n",
      "Error on this batch = 0.031694526968027346\n",
      "Error on this batch = 0.016598735147451398\n",
      "Cost on val dataset after 504 epochs is = 0.07371789045355885\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.07371789045355885\n",
      "learning rate for this epoch =  0.31658010947808957\n",
      "Error on this batch = 0.031663117733628794\n",
      "Error on this batch = 0.016567540337232876\n",
      "Cost on val dataset after 505 epochs is = 0.07369625612365684\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.07369625612365684\n",
      "learning rate for this epoch =  0.316423270138665\n",
      "Error on this batch = 0.03163190051360235\n",
      "Error on this batch = 0.016536660475210595\n",
      "Cost on val dataset after 506 epochs is = 0.07367477444572128\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.07367477444572128\n",
      "learning rate for this epoch =  0.3162668185357691\n",
      "Error on this batch = 0.031600875357172216\n",
      "Error on this batch = 0.016506091158759267\n",
      "Cost on val dataset after 507 epochs is = 0.07365343481662523\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.07365343481662523\n",
      "learning rate for this epoch =  0.31611075294740243\n",
      "Error on this batch = 0.031570041957653575\n",
      "Error on this batch = 0.01647582804510366\n",
      "Cost on val dataset after 508 epochs is = 0.07363222726350155\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.07363222726350155\n",
      "learning rate for this epoch =  0.3159550716625907\n",
      "Error on this batch = 0.03153939964192359\n",
      "Error on this batch = 0.016445866853466308\n",
      "Cost on val dataset after 509 epochs is = 0.07361114246244306\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.07361114246244306\n",
      "learning rate for this epoch =  0.31579977298129214\n",
      "Error on this batch = 0.0315089473661007\n",
      "Error on this batch = 0.01641620336844241\n",
      "Cost on val dataset after 510 epochs is = 0.07359017174957914\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.07359017174957914\n",
      "learning rate for this epoch =  0.31564485521430685\n",
      "Error on this batch = 0.03147868371703436\n",
      "Error on this batch = 0.016386833444343437\n",
      "Cost on val dataset after 511 epochs is = 0.07356930712511332\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.07356930712511332\n",
      "learning rate for this epoch =  0.315490316683186\n",
      "Error on this batch = 0.031448606919066105\n",
      "Error on this batch = 0.01635775301018671\n",
      "Cost on val dataset after 512 epochs is = 0.07354854125105219\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.07354854125105219\n",
      "learning rate for this epoch =  0.31533615572014295\n",
      "Error on this batch = 0.031418714845419894\n",
      "Error on this batch = 0.016328958074963568\n",
      "Cost on val dataset after 513 epochs is = 0.07352786744344872\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.07352786744344872\n",
      "learning rate for this epoch =  0.3151823706679647\n",
      "Error on this batch = 0.03138900503351266\n",
      "Error on this batch = 0.016300444732797886\n",
      "Cost on val dataset after 514 epochs is = 0.07350727966001588\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.07350727966001588\n",
      "learning rate for this epoch =  0.3150289598799243\n",
      "Error on this batch = 0.03135947470344757\n",
      "Error on this batch = 0.0162722091676065\n",
      "Cost on val dataset after 515 epochs is = 0.07348677248395505\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.07348677248395505\n",
      "learning rate for this epoch =  0.3148759217196945\n",
      "Error on this batch = 0.0313301207789551\n",
      "Error on this batch = 0.016244247656894726\n",
      "Cost on val dataset after 516 epochs is = 0.07346634110478845\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.07346634110478845\n",
      "learning rate for this epoch =  0.3147232545612616\n",
      "Error on this batch = 0.03130093991007943\n",
      "Error on this batch = 0.016216556574358793\n",
      "Cost on val dataset after 517 epochs is = 0.07344598129690265\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.07344598129690265\n",
      "learning rate for this epoch =  0.3145709567888413\n",
      "Error on this batch = 0.0312719284969613\n",
      "Error on this batch = 0.016189132391020943\n",
      "Cost on val dataset after 518 epochs is = 0.0734256893964085\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.0734256893964085\n",
      "learning rate for this epoch =  0.31441902679679395\n",
      "Error on this batch = 0.031243082714138636\n",
      "Error on this batch = 0.016161971674686953\n",
      "Cost on val dataset after 519 epochs is = 0.07340546227681544\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.07340546227681544\n",
      "learning rate for this epoch =  0.3142674629895419\n",
      "Error on this batch = 0.03121439853486651\n",
      "Error on this batch = 0.01613507108758733\n",
      "Cost on val dataset after 520 epochs is = 0.07338529732391201\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.07338529732391201\n",
      "learning rate for this epoch =  0.3141162637814871\n",
      "Error on this batch = 0.03118587175504359\n",
      "Error on this batch = 0.016108427382137434\n",
      "Cost on val dataset after 521 epochs is = 0.07336519241014727\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.07336519241014727\n",
      "learning rate for this epoch =  0.3139654275969295\n",
      "Error on this batch = 0.031157498016415885\n",
      "Error on this batch = 0.016082037394826602\n",
      "Cost on val dataset after 522 epochs is = 0.0733451458687267\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.0733451458687267\n",
      "learning rate for this epoch =  0.3138149528699866\n",
      "Error on this batch = 0.03112927282880979\n",
      "Error on this batch = 0.016055898038316866\n",
      "Cost on val dataset after 523 epochs is = 0.07332515646756999\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.07332515646756999\n",
      "learning rate for this epoch =  0.31366483804451345\n",
      "Error on this batch = 0.03110119159121857\n",
      "Error on this batch = 0.016030006291898893\n",
      "Cost on val dataset after 524 epochs is = 0.07330522338323141\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.07330522338323141\n",
      "learning rate for this epoch =  0.31351508157402375\n",
      "Error on this batch = 0.031073249611628554\n",
      "Error on this batch = 0.016004359190510308\n",
      "Cost on val dataset after 525 epochs is = 0.07328534617485247\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.07328534617485247\n",
      "learning rate for this epoch =  0.31336568192161146\n",
      "Error on this batch = 0.031045442125521672\n",
      "Error on this batch = 0.015978953812572635\n",
      "Cost on val dataset after 526 epochs is = 0.07326552475820104\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.07326552475820104\n",
      "learning rate for this epoch =  0.31321663755987345\n",
      "Error on this batch = 0.03101776431302791\n",
      "Error on this batch = 0.01595378726694227\n",
      "Cost on val dataset after 527 epochs is = 0.07324575937984636\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.07324575937984636\n",
      "learning rate for this epoch =  0.3130679469708329\n",
      "Error on this batch = 0.030990211314725055\n",
      "Error on this batch = 0.015928856679300725\n",
      "Cost on val dataset after 528 epochs is = 0.07322605059152357\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.07322605059152357\n",
      "learning rate for this epoch =  0.312919608645863\n",
      "Error on this batch = 0.030962778246093964\n",
      "Error on this batch = 0.015904159178326306\n",
      "Cost on val dataset after 529 epochs is = 0.07320639922474977\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.07320639922474977\n",
      "learning rate for this epoch =  0.3127716210856122\n",
      "Error on this batch = 0.030935460210636655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.015879691881995072\n",
      "Cost on val dataset after 530 epochs is = 0.07318680636576291\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.07318680636576291\n",
      "learning rate for this epoch =  0.3126239827999295\n",
      "Error on this batch = 0.03090825231165257\n",
      "Error on this batch = 0.015855451884351463\n",
      "Cost on val dataset after 531 epochs is = 0.07316727333086416\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.07316727333086416\n",
      "learning rate for this epoch =  0.312476692307791\n",
      "Error on this batch = 0.030881149662650067\n",
      "Error on this batch = 0.01583143624306901\n",
      "Cost on val dataset after 532 epochs is = 0.07314780164224793\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.07314780164224793\n",
      "learning rate for this epoch =  0.31232974813722675\n",
      "Error on this batch = 0.030854147396343512\n",
      "Error on this batch = 0.015807641968089373\n",
      "Cost on val dataset after 533 epochs is = 0.07312839300440312\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.07312839300440312\n",
      "learning rate for this epoch =  0.3121831488252485\n",
      "Error on this batch = 0.030827240672159723\n",
      "Error on this batch = 0.015784066011583615\n",
      "Cost on val dataset after 534 epochs is = 0.07310904928116178\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.07310904928116178\n",
      "learning rate for this epoch =  0.3120368929177782\n",
      "Error on this batch = 0.030800424682149156\n",
      "Error on this batch = 0.015760705259424905\n",
      "Cost on val dataset after 535 epochs is = 0.07308977247345701\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.07308977247345701\n",
      "learning rate for this epoch =  0.3118909789695773\n",
      "Error on this batch = 0.030773694655172268\n",
      "Error on this batch = 0.01573755652429883\n",
      "Cost on val dataset after 536 epochs is = 0.07307056469783087\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.07307056469783087\n",
      "learning rate for this epoch =  0.3117454055441764\n",
      "Error on this batch = 0.030747045859212684\n",
      "Error on this batch = 0.01571461654050723\n",
      "Cost on val dataset after 537 epochs is = 0.07305142816570678\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.07305142816570678\n",
      "learning rate for this epoch =  0.311600171213806\n",
      "Error on this batch = 0.030720473601657475\n",
      "Error on this batch = 0.015691881960449697\n",
      "Cost on val dataset after 538 epochs is = 0.0730323651634101\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.0730323651634101\n",
      "learning rate for this epoch =  0.3114552745593275\n",
      "Error on this batch = 0.030693973227382924\n",
      "Error on this batch = 0.01566934935269455\n",
      "Cost on val dataset after 539 epochs is = 0.07301337803288648\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.07301337803288648\n",
      "learning rate for this epoch =  0.3113107141701652\n",
      "Error on this batch = 0.030667540114492988\n",
      "Error on this batch = 0.015647015201485235\n",
      "Cost on val dataset after 540 epochs is = 0.07299446915303466\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.07299446915303466\n",
      "learning rate for this epoch =  0.3111664886442392\n",
      "Error on this batch = 0.030641169667576396\n",
      "Error on this batch = 0.01562487590747199\n",
      "Cost on val dataset after 541 epochs is = 0.07297564092153806\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.07297564092153806\n",
      "learning rate for this epoch =  0.3110225965878979\n",
      "Error on this batch = 0.03061485730837644\n",
      "Error on this batch = 0.015602927789417347\n",
      "Cost on val dataset after 542 epochs is = 0.07295689573705273\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.07295689573705273\n",
      "learning rate for this epoch =  0.31087903661585237\n",
      "Error on this batch = 0.03058859846380324\n",
      "Error on this batch = 0.015581167086602635\n",
      "Cost on val dataset after 543 epochs is = 0.07293823598159112\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.07293823598159112\n",
      "learning rate for this epoch =  0.310735807351111\n",
      "Error on this batch = 0.030562388551257667\n",
      "Error on this batch = 0.015559589961664781\n",
      "Cost on val dataset after 544 epochs is = 0.07291966400293232\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.07291966400293232\n",
      "learning rate for this epoch =  0.310592907424914\n",
      "Error on this batch = 0.03053622296127826\n",
      "Error on this batch = 0.015538192503620768\n",
      "Cost on val dataset after 545 epochs is = 0.07290118209689549\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.07290118209689549\n",
      "learning rate for this epoch =  0.31045033547666984\n",
      "Error on this batch = 0.03051009703756066\n",
      "Error on this batch = 0.01551697073089253\n",
      "Cost on val dataset after 546 epochs is = 0.07288279248933453\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.07288279248933453\n",
      "learning rate for this epoch =  0.3103080901538911\n",
      "Error on this batch = 0.03048400605443216\n",
      "Error on this batch = 0.015495920594227011\n",
      "Cost on val dataset after 547 epochs is = 0.07286449731775112\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.07286449731775112\n",
      "learning rate for this epoch =  0.3101661701121318\n",
      "Error on this batch = 0.030457945191888342\n",
      "Error on this batch = 0.015475037979510666\n",
      "Cost on val dataset after 548 epochs is = 0.07284629861248154\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.07284629861248154\n",
      "learning rate for this epoch =  0.31002457401492484\n",
      "Error on this batch = 0.030431909508311726\n",
      "Error on this batch = 0.015454318710599404\n",
      "Cost on val dataset after 549 epochs is = 0.07282819827748804\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.07282819827748804\n",
      "learning rate for this epoch =  0.3098833005337202\n",
      "Error on this batch = 0.030405893910994176\n",
      "Error on this batch = 0.015433758552415274\n",
      "Cost on val dataset after 550 epochs is = 0.07281019807087687\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.07281019807087687\n",
      "learning rate for this epoch =  0.3097423483478239\n",
      "Error on this batch = 0.030379893124575893\n",
      "Error on this batch = 0.015413353214688834\n",
      "Cost on val dataset after 551 epochs is = 0.07279229958537062\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.07279229958537062\n",
      "learning rate for this epoch =  0.30960171614433696\n",
      "Error on this batch = 0.03035390165749741\n",
      "Error on this batch = 0.01539309835683898\n",
      "Cost on val dataset after 552 epochs is = 0.07277450422907188\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.07277450422907188\n",
      "learning rate for this epoch =  0.30946140261809585\n",
      "Error on this batch = 0.03032791376654063\n",
      "Error on this batch = 0.015372989594566138\n",
      "Cost on val dataset after 553 epochs is = 0.07275681320696721\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.07275681320696721\n",
      "learning rate for this epoch =  0.3093214064716125\n",
      "Error on this batch = 0.030301923419516374\n",
      "Error on this batch = 0.015353022508776236\n",
      "Cost on val dataset after 554 epochs is = 0.07273922750372054\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.07273922750372054\n",
      "learning rate for this epoch =  0.30918172641501573\n",
      "Error on this batch = 0.030275924256145254\n",
      "Error on this batch = 0.015333192657441213\n",
      "Cost on val dataset after 555 epochs is = 0.07272174786838755\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.07272174786838755\n",
      "learning rate for this epoch =  0.3090423611659929\n",
      "Error on this batch = 0.030249909547180875\n",
      "Error on this batch = 0.015313495590925538\n",
      "Cost on val dataset after 556 epochs is = 0.07270437480173418\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.07270437480173418\n",
      "learning rate for this epoch =  0.30890330944973177\n",
      "Error on this batch = 0.030223872151843776\n",
      "Error on this batch = 0.015293926871166295\n",
      "Cost on val dataset after 557 epochs is = 0.07268710854685519\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.07268710854685519\n",
      "learning rate for this epoch =  0.3087645699988635\n",
      "Error on this batch = 0.030197804473674175\n",
      "Error on this batch = 0.015274482094885139\n",
      "Cost on val dataset after 558 epochs is = 0.07266994908375249\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.07266994908375249\n",
      "learning rate for this epoch =  0.3086261415534058\n",
      "Error on this batch = 0.03017169841496955\n",
      "Error on this batch = 0.015255156920744938\n",
      "Cost on val dataset after 559 epochs is = 0.07265289612844356\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.07265289612844356\n",
      "learning rate for this epoch =  0.308488022860707\n",
      "Error on this batch = 0.030145545330046417\n",
      "Error on this batch = 0.015235947100056522\n",
      "Cost on val dataset after 560 epochs is = 0.07263594913702387\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.07263594913702387\n",
      "learning rate for this epoch =  0.30835021267538976\n",
      "Error on this batch = 0.030119335977647228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.015216848510315\n",
      "Cost on val dataset after 561 epochs is = 0.07261910731490903\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.07261910731490903\n",
      "learning rate for this epoch =  0.3082127097592968\n",
      "Error on this batch = 0.030093060472893427\n",
      "Error on this batch = 0.015197857190526907\n",
      "Cost on val dataset after 562 epochs is = 0.0726023696312355\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.0726023696312355\n",
      "learning rate for this epoch =  0.3080755128814354\n",
      "Error on this batch = 0.030066708239254322\n",
      "Error on this batch = 0.015178969377011287\n",
      "Cost on val dataset after 563 epochs is = 0.07258573483812308\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.07258573483812308\n",
      "learning rate for this epoch =  0.30793862081792395\n",
      "Error on this batch = 0.030040267961047116\n",
      "Error on this batch = 0.015160181538147065\n",
      "Cost on val dataset after 564 epochs is = 0.07256920149420756\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.07256920149420756\n",
      "learning rate for this epoch =  0.3078020323519378\n",
      "Error on this batch = 0.030013727536998217\n",
      "Error on this batch = 0.015141490406422821\n",
      "Cost on val dataset after 565 epochs is = 0.07255276799156703\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.07255276799156703\n",
      "learning rate for this epoch =  0.30766574627365656\n",
      "Error on this batch = 0.02998707403537415\n",
      "Error on this batch = 0.015122893006140642\n",
      "Cost on val dataset after 566 epochs is = 0.07253643258490963\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.07253643258490963\n",
      "learning rate for this epoch =  0.30752976138021126\n",
      "Error on this batch = 0.029960293651130496\n",
      "Error on this batch = 0.01510438667524056\n",
      "Cost on val dataset after 567 epochs is = 0.0725201934216886\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.0725201934216886\n",
      "learning rate for this epoch =  0.30739407647563216\n",
      "Error on this batch = 0.029933371665434066\n",
      "Error on this batch = 0.015085969079943109\n",
      "Cost on val dataset after 568 epochs is = 0.07250404857168567\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.07250404857168567\n",
      "learning rate for this epoch =  0.3072586903707974\n",
      "Error on this batch = 0.029906292407794455\n",
      "Error on this batch = 0.015067638221238362\n",
      "Cost on val dataset after 569 epochs is = 0.07248799605457039\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.07248799605457039\n",
      "learning rate for this epoch =  0.3071236018833813\n",
      "Error on this batch = 0.02987903922090851\n",
      "Error on this batch = 0.015049392432656506\n",
      "Cost on val dataset after 570 epochs is = 0.07247203386401437\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.07247203386401437\n",
      "learning rate for this epoch =  0.3069888098378042\n",
      "Error on this batch = 0.029851594428188577\n",
      "Error on this batch = 0.015031230369205156\n",
      "Cost on val dataset after 571 epochs is = 0.07245615998711558\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.07245615998711558\n",
      "learning rate for this epoch =  0.30685431306518185\n",
      "Error on this batch = 0.029823939303826322\n",
      "Error on this batch = 0.015013150987819652\n",
      "Cost on val dataset after 572 epochs is = 0.07244037241816631\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.07244037241816631\n",
      "learning rate for this epoch =  0.3067201104032758\n",
      "Error on this batch = 0.029796054045150396\n",
      "Error on this batch = 0.014995153520109127\n",
      "Cost on val dataset after 573 epochs is = 0.07242466916616291\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.07242466916616291\n",
      "learning rate for this epoch =  0.30658620069644404\n",
      "Error on this batch = 0.02976791774697668\n",
      "Error on this batch = 0.014977237438569562\n",
      "Cost on val dataset after 574 epochs is = 0.0724090482558876\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.0724090482558876\n",
      "learning rate for this epoch =  0.3064525827955921\n",
      "Error on this batch = 0.029739508377629526\n",
      "Error on this batch = 0.014959402417749616\n",
      "Cost on val dataset after 575 epochs is = 0.07239350772286651\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.07239350772286651\n",
      "learning rate for this epoch =  0.30631925555812456\n",
      "Error on this batch = 0.029710802756331516\n",
      "Error on this batch = 0.014941648292088225\n",
      "Cost on val dataset after 576 epochs is = 0.07237804560299074\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.07237804560299074\n",
      "learning rate for this epoch =  0.3061862178478973\n",
      "Error on this batch = 0.029681776531714534\n",
      "Error on this batch = 0.014923975012286254\n",
      "Cost on val dataset after 577 epochs is = 0.07236265991805368\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.07236265991805368\n",
      "learning rate for this epoch =  0.30605346853516946\n",
      "Error on this batch = 0.029652404161291158\n",
      "Error on this batch = 0.014906382602132109\n",
      "Cost on val dataset after 578 epochs is = 0.07234734865886784\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.07234734865886784\n",
      "learning rate for this epoch =  0.3059210064965572\n",
      "Error on this batch = 0.029622658891834013\n",
      "Error on this batch = 0.014888871117676082\n",
      "Cost on val dataset after 579 epochs is = 0.07233210976795511\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.07233210976795511\n",
      "learning rate for this epoch =  0.3057888306149859\n",
      "Error on this batch = 0.029592512740732994\n",
      "Error on this batch = 0.014871440610550195\n",
      "Cost on val dataset after 580 epochs is = 0.0723169411240223\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.0723169411240223\n",
      "learning rate for this epoch =  0.3056569397796449\n",
      "Error on this batch = 0.029561936478529924\n",
      "Error on this batch = 0.014854091097060965\n",
      "Cost on val dataset after 581 epochs is = 0.0723018405305167\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.0723018405305167\n",
      "learning rate for this epoch =  0.30552533288594097\n",
      "Error on this batch = 0.029530899612957913\n",
      "Error on this batch = 0.014836822534451698\n",
      "Cost on val dataset after 582 epochs is = 0.07228680571048601\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.07228680571048601\n",
      "learning rate for this epoch =  0.3053940088354531\n",
      "Error on this batch = 0.029499370374935854\n",
      "Error on this batch = 0.01481963480543475\n",
      "Cost on val dataset after 583 epochs is = 0.07227183430973157\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.07227183430973157\n",
      "learning rate for this epoch =  0.3052629665358877\n",
      "Error on this batch = 0.029467315707083594\n",
      "Error on this batch = 0.014802527711738378\n",
      "Cost on val dataset after 584 epochs is = 0.07225692390984323\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.07225692390984323\n",
      "learning rate for this epoch =  0.3051322049010337\n",
      "Error on this batch = 0.029434701255430726\n",
      "Error on this batch = 0.014785500976997917\n",
      "Cost on val dataset after 585 epochs is = 0.07224207205214966\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.07224207205214966\n",
      "learning rate for this epoch =  0.3050017228507182\n",
      "Error on this batch = 0.02940149136509635\n",
      "Error on this batch = 0.014768554258854696\n",
      "Cost on val dataset after 586 epochs is = 0.07222727627293733\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.07222727627293733\n",
      "learning rate for this epoch =  0.3048715193107633\n",
      "Error on this batch = 0.029367649080822008\n",
      "Error on this batch = 0.014751687169623717\n",
      "Cost on val dataset after 587 epochs is = 0.07221253414952256\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.07221253414952256\n",
      "learning rate for this epoch =  0.3047415932129417\n",
      "Error on this batch = 0.02933313615335811\n",
      "Error on this batch = 0.01473489930437813\n",
      "Cost on val dataset after 588 epochs is = 0.07219784335596412\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.07219784335596412\n",
      "learning rate for this epoch =  0.3046119434949347\n",
      "Error on this batch = 0.029297913052843683\n",
      "Error on this batch = 0.01471819027480957\n",
      "Cost on val dataset after 589 epochs is = 0.0721832017264372\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.0721832017264372\n",
      "learning rate for this epoch =  0.3044825691002886\n",
      "Error on this batch = 0.029261938990495777\n",
      "Error on this batch = 0.014701559746803703\n",
      "Cost on val dataset after 590 epochs is = 0.07216860732362892\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.07216860732362892\n",
      "learning rate for this epoch =  0.3043534689783732\n",
      "Error on this batch = 0.02922517195015308\n",
      "Error on this batch = 0.014685007479365169\n",
      "Cost on val dataset after 591 epochs is = 0.07215405850902\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.07215405850902\n",
      "learning rate for this epoch =  0.30422464208433925\n",
      "Error on this batch = 0.029187568731511817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.014668533362381256\n",
      "Cost on val dataset after 592 epochs is = 0.0721395540116439\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.0721395540116439\n",
      "learning rate for this epoch =  0.3040960873790774\n",
      "Error on this batch = 0.029149085007265027\n",
      "Error on this batch = 0.014652137450757139\n",
      "Cost on val dataset after 593 epochs is = 0.07212509299189349\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.07212509299189349\n",
      "learning rate for this epoch =  0.3039678038291769\n",
      "Error on this batch = 0.029109675396817827\n",
      "Error on this batch = 0.014635819992699835\n",
      "Cost on val dataset after 594 epochs is = 0.07211067509718314\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.07211067509718314\n",
      "learning rate for this epoch =  0.3038397904068846\n",
      "Error on this batch = 0.0290692935598053\n",
      "Error on this batch = 0.014619581450358377\n",
      "Cost on val dataset after 595 epochs is = 0.07209630050675156\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.07209630050675156\n",
      "learning rate for this epoch =  0.30371204609006475\n",
      "Error on this batch = 0.029027892313282316\n",
      "Error on this batch = 0.014603422511603566\n",
      "Cost on val dataset after 596 epochs is = 0.07208196996355679\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.07208196996355679\n",
      "learning rate for this epoch =  0.3035845698621589\n",
      "Error on this batch = 0.02898542377717405\n",
      "Error on this batch = 0.014587344092392382\n",
      "Cost on val dataset after 597 epochs is = 0.07206768479200633\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.07206768479200633\n",
      "learning rate for this epoch =  0.3034573607121461\n",
      "Error on this batch = 0.028941839553347323\n",
      "Error on this batch = 0.014571347329836391\n",
      "Cost on val dataset after 598 epochs is = 0.07205344690110209\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.07205344690110209\n",
      "learning rate for this epoch =  0.3033304176345033\n",
      "Error on this batch = 0.028897090944455046\n",
      "Error on this batch = 0.014555433566707729\n",
      "Cost on val dataset after 599 epochs is = 0.07203925877338356\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.07203925877338356\n",
      "learning rate for this epoch =  0.3032037396291669\n",
      "Error on this batch = 0.028851129219469866\n",
      "Error on this batch = 0.014539604328608824\n",
      "Cost on val dataset after 600 epochs is = 0.0720251234407542\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.0720251234407542\n",
      "learning rate for this epoch =  0.30307732570149354\n",
      "Error on this batch = 0.028803905933507276\n",
      "Error on this batch = 0.014523861295361807\n",
      "Cost on val dataset after 601 epochs is = 0.07201104444882472\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.07201104444882472\n",
      "learning rate for this epoch =  0.3029511748622218\n",
      "Error on this batch = 0.028755373310069405\n",
      "Error on this batch = 0.014508206268323396\n",
      "Cost on val dataset after 602 epochs is = 0.07199702581177116\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.07199702581177116\n",
      "learning rate for this epoch =  0.30282528612743437\n",
      "Error on this batch = 0.028705484694143957\n",
      "Error on this batch = 0.014492641135310394\n",
      "Cost on val dataset after 603 epochs is = 0.07198307195987846\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.07198307195987846\n",
      "learning rate for this epoch =  0.30269965851852054\n",
      "Error on this batch = 0.02865419508456946\n",
      "Error on this batch = 0.014477167834656577\n",
      "Cost on val dataset after 604 epochs is = 0.07196918768193702\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.07196918768193702\n",
      "learning rate for this epoch =  0.30257429106213807\n",
      "Error on this batch = 0.02860146175362649\n",
      "Error on this batch = 0.014461788319656102\n",
      "Cost on val dataset after 605 epochs is = 0.07195537806450603\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.07195537806450603\n",
      "learning rate for this epoch =  0.3024491827901771\n",
      "Error on this batch = 0.028547244960807138\n",
      "Error on this batch = 0.014446504524326581\n",
      "Cost on val dataset after 606 epochs is = 0.071941648429793\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.071941648429793\n",
      "learning rate for this epoch =  0.3023243327397227\n",
      "Error on this batch = 0.028491508766024635\n",
      "Error on this batch = 0.014431318331089953\n",
      "Cost on val dataset after 607 epochs is = 0.07192800427356631\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.07192800427356631\n",
      "learning rate for this epoch =  0.3021997399530191\n",
      "Error on this batch = 0.028434221945004428\n",
      "Error on this batch = 0.014416231540656715\n",
      "Cost on val dataset after 608 epochs is = 0.07191445120415059\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.07191445120415059\n",
      "learning rate for this epoch =  0.302075403477433\n",
      "Error on this batch = 0.028375359006113234\n",
      "Error on this batch = 0.014401245844133492\n",
      "Cost on val dataset after 609 epochs is = 0.07190099488319557\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.07190099488319557\n",
      "learning rate for this epoch =  0.3019513223654181\n",
      "Error on this batch = 0.02831490130330825\n",
      "Error on this batch = 0.014386362797170194\n",
      "Cost on val dataset after 610 epochs is = 0.07188764096857458\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.07188764096857458\n",
      "learning rate for this epoch =  0.30182749567447964\n",
      "Error on this batch = 0.028252838234144376\n",
      "Error on this batch = 0.014371583795824918\n",
      "Cost on val dataset after 611 epochs is = 0.07187439505948476\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.07187439505948476\n",
      "learning rate for this epoch =  0.3017039224671394\n",
      "Error on this batch = 0.028189168504845725\n",
      "Error on this batch = 0.014356910053751728\n",
      "Cost on val dataset after 612 epochs is = 0.0718612626435953\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.0718612626435953\n",
      "learning rate for this epoch =  0.3015806018109004\n",
      "Error on this batch = 0.02812390143641531\n",
      "Error on this batch = 0.014342342580301906\n",
      "Cost on val dataset after 613 epochs is = 0.07184824904593312\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.07184824904593312\n",
      "learning rate for this epoch =  0.3014575327782127\n",
      "Error on this batch = 0.02805705827684994\n",
      "Error on this batch = 0.014327882159165988\n",
      "Cost on val dataset after 614 epochs is = 0.071835359379108\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.071835359379108\n",
      "learning rate for this epoch =  0.301334714446439\n",
      "Error on this batch = 0.027988673475145446\n",
      "Error on this batch = 0.01431352932726584\n",
      "Cost on val dataset after 615 epochs is = 0.07182259849446751\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.07182259849446751\n",
      "learning rate for this epoch =  0.3012121458978208\n",
      "Error on this batch = 0.027918795863526837\n",
      "Error on this batch = 0.014299284353726061\n",
      "Cost on val dataset after 616 epochs is = 0.0718099709338362\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.0718099709338362\n",
      "learning rate for this epoch =  0.30108982621944447\n",
      "Error on this batch = 0.027847489686037986\n",
      "Error on this batch = 0.01428514721891033\n",
      "Cost on val dataset after 617 epochs is = 0.07179748088163604\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.07179748088163604\n",
      "learning rate for this epoch =  0.3009677545032082\n",
      "Error on this batch = 0.027774835405288714\n",
      "Error on this batch = 0.014271117593694514\n",
      "Cost on val dataset after 618 epochs is = 0.07178513211740621\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.07178513211740621\n",
      "learning rate for this epoch =  0.30084592984578845\n",
      "Error on this batch = 0.027700930215937117\n",
      "Error on this batch = 0.014257194819364034\n",
      "Cost on val dataset after 619 epochs is = 0.07177292796903689\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.07177292796903689\n",
      "learning rate for this epoch =  0.3007243513486077\n",
      "Error on this batch = 0.027625888194561243\n",
      "Error on this batch = 0.014243377888758228\n",
      "Cost on val dataset after 620 epochs is = 0.0717608712673963\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.0717608712673963\n",
      "learning rate for this epoch =  0.3006030181178012\n",
      "Error on this batch = 0.027549840022008852\n",
      "Error on this batch = 0.0142296654295318\n",
      "Cost on val dataset after 621 epochs is = 0.07174896430344133\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.07174896430344133\n",
      "learning rate for this epoch =  0.3004819292641854\n",
      "Error on this batch = 0.02747293222684892\n",
      "Error on this batch = 0.01421605569064393\n",
      "Cost on val dataset after 622 epochs is = 0.07173720878933362\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.07173720878933362\n",
      "learning rate for this epoch =  0.30036108390322536\n",
      "Error on this batch = 0.02739532591741109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.014202546533397007\n",
      "Cost on val dataset after 623 epochs is = 0.07172560582548695\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.07172560582548695\n",
      "learning rate for this epoch =  0.3002404811550034\n",
      "Error on this batch = 0.027317194994606858\n",
      "Error on this batch = 0.01418913542849878\n",
      "Cost on val dataset after 624 epochs is = 0.07171415587579175\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.07171415587579175\n",
      "learning rate for this epoch =  0.30012012014418743\n",
      "Error on this batch = 0.02723872386698094\n",
      "Error on this batch = 0.014175819460677735\n",
      "Cost on val dataset after 625 epochs is = 0.07170285875343176\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.07170285875343176\n",
      "learning rate for this epoch =  0.3\n",
      "Error on this batch = 0.027160104721123554\n",
      "Error on this batch = 0.014162595342307054\n",
      "Cost on val dataset after 626 epochs is = 0.07169171361965865\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.07169171361965865\n",
      "learning rate for this epoch =  0.29988011985618696\n",
      "Error on this batch = 0.027081534431888574\n",
      "Error on this batch = 0.014149459437256902\n",
      "Cost on val dataset after 627 epochs is = 0.07168071899756552\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.07168071899756552\n",
      "learning rate for this epoch =  0.2997604788509871\n",
      "Error on this batch = 0.027003211224637527\n",
      "Error on this batch = 0.014136407795779174\n",
      "Cost on val dataset after 628 epochs is = 0.07166987280227419\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.07166987280227419\n",
      "learning rate for this epoch =  0.2996410761271016\n",
      "Error on this batch = 0.026925331222836454\n",
      "Error on this batch = 0.014123436200640218\n",
      "Cost on val dataset after 629 epochs is = 0.07165917238803518\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.07165917238803518\n",
      "learning rate for this epoch =  0.29952191083166396\n",
      "Error on this batch = 0.026848085026158965\n",
      "Error on this batch = 0.014110540223982771\n",
      "Cost on val dataset after 630 epochs is = 0.07164861461159773\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.07164861461159773\n",
      "learning rate for this epoch =  0.2994029821162099\n",
      "Error on this batch = 0.026771654465140262\n",
      "Error on this batch = 0.014097715293582107\n",
      "Cost on val dataset after 631 epochs is = 0.07163819590995348\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.07163819590995348\n",
      "learning rate for this epoch =  0.299284289136648\n",
      "Error on this batch = 0.026696209667992448\n",
      "Error on this batch = 0.014084956766346314\n",
      "Cost on val dataset after 632 epochs is = 0.07162791238934489\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.07162791238934489\n",
      "learning rate for this epoch =  0.29916583105322975\n",
      "Error on this batch = 0.026621906554408447\n",
      "Error on this batch = 0.014072260006198087\n",
      "Cost on val dataset after 633 epochs is = 0.07161775992142076\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.07161775992142076\n",
      "learning rate for this epoch =  0.29904760703052113\n",
      "Error on this batch = 0.026548884842259576\n",
      "Error on this batch = 0.01405962046296548\n",
      "Cost on val dataset after 634 epochs is = 0.07160773424176442\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.07160773424176442\n",
      "learning rate for this epoch =  0.29892961623737285\n",
      "Error on this batch = 0.026477266619141814\n",
      "Error on this batch = 0.014047033748679117\n",
      "Cost on val dataset after 635 epochs is = 0.07159783104581681\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.07159783104581681\n",
      "learning rate for this epoch =  0.29881185784689224\n",
      "Error on this batch = 0.02640715549526229\n",
      "Error on this batch = 0.014034495707769934\n",
      "Cost on val dataset after 636 epochs is = 0.07158804607749464\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.07158804607749464\n",
      "learning rate for this epoch =  0.2986943310364146\n",
      "Error on this batch = 0.026338636320603636\n",
      "Error on this batch = 0.014022002478080428\n",
      "Cost on val dataset after 637 epochs is = 0.07157837520651855\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.07157837520651855\n",
      "learning rate for this epoch =  0.2985770349874749\n",
      "Error on this batch = 0.02627177542050973\n",
      "Error on this batch = 0.014009550540294576\n",
      "Cost on val dataset after 638 epochs is = 0.07156881449150937\n",
      "Initial Cost on Val dataset for this epoch 638 = 0.07156881449150937\n",
      "learning rate for this epoch =  0.29845996888578\n",
      "Error on this batch = 0.026206621281788803\n",
      "Error on this batch = 0.013997136754271286\n",
      "Cost on val dataset after 639 epochs is = 0.07155936022713068\n",
      "Initial Cost on Val dataset for this epoch 639 = 0.07155936022713068\n",
      "learning rate for this epoch =  0.29834313192118067\n",
      "Error on this batch = 0.02614320560709479\n",
      "Error on this batch = 0.013984758381723363\n",
      "Cost on val dataset after 640 epochs is = 0.07155000897479168\n",
      "Initial Cost on Val dataset for this epoch 640 = 0.07155000897479168\n",
      "learning rate for this epoch =  0.298226523287644\n",
      "Error on this batch = 0.026081544648726585\n",
      "Error on this batch = 0.01397241309560906\n",
      "Cost on val dataset after 641 epochs is = 0.07154075757754032\n",
      "Initial Cost on Val dataset for this epoch 641 = 0.07154075757754032\n",
      "learning rate for this epoch =  0.29811014218322646\n",
      "Error on this batch = 0.026021640733277843\n",
      "Error on this batch = 0.013960098977401851\n",
      "Cost on val dataset after 642 epochs is = 0.07153160316066731\n",
      "Initial Cost on Val dataset for this epoch 642 = 0.07153160316066731\n",
      "learning rate for this epoch =  0.2979939878100464\n",
      "Error on this batch = 0.025963483894442328\n",
      "Error on this batch = 0.013947814504010447\n",
      "Cost on val dataset after 643 epochs is = 0.0715225431201604\n",
      "Initial Cost on Val dataset for this epoch 643 = 0.0715225431201604\n",
      "learning rate for this epoch =  0.29787805937425743\n",
      "Error on this batch = 0.025907053541128967\n",
      "Error on this batch = 0.013935558526503265\n",
      "Cost on val dataset after 644 epochs is = 0.07151357510148779\n",
      "cost initial= 0.0715225431201604 , cost final=0.07151357510148779 , change in cost= -8.968018672617095e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with Sigmoid are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with Sigmoid is = 644\n",
      "The training time with Sigmoid is = 170.986sec\n",
      "The training accuracy with Sigmoid is = 97.285%\n",
      "The validation accuracy with Sigmoid is = 91.846%\n",
      "The test accuracy with Sigmoid is = 90.708%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=1.5\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'sigmoid', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with Sigmoid are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with Sigmoid is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with Sigmoid is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with Sigmoid is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with Sigmoid is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with Sigmoid is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with ReLU activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with ReLU activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.26701228540996\n",
      "Error on this batch = 3.2685168044042814\n",
      "Error on this batch = 0.4996673061852154\n",
      "Cost on val dataset after 2 epochs is = 0.49953592365448296\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.49953592365448296\n",
      "Error on this batch = 0.4995624888696448\n",
      "Error on this batch = 0.49771228058770534\n",
      "Cost on val dataset after 3 epochs is = 0.48770395180711484\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48770395180711484\n",
      "Error on this batch = 0.48590435229364864\n",
      "Error on this batch = 0.4844095017717498\n",
      "Cost on val dataset after 4 epochs is = 0.4829962758941105\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4829962758941105\n",
      "Error on this batch = 0.48198045154742886\n",
      "Error on this batch = 0.4814112339709867\n",
      "Cost on val dataset after 5 epochs is = 0.4810394833569399\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4810394833569399\n",
      "Error on this batch = 0.48029357564040737\n",
      "Error on this batch = 0.479835596767896\n",
      "Cost on val dataset after 6 epochs is = 0.4794286732477114\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4794286732477114\n",
      "Error on this batch = 0.4785326521294485\n",
      "Error on this batch = 0.47743800343794696\n",
      "Cost on val dataset after 7 epochs is = 0.47622182671657115\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.47622182671657115\n",
      "Error on this batch = 0.47406241235619734\n",
      "Error on this batch = 0.4699766621549989\n",
      "Cost on val dataset after 8 epochs is = 0.46516256905543896\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.46516256905543896\n",
      "Error on this batch = 0.45679539564439886\n",
      "Error on this batch = 0.44859298773298806\n",
      "Cost on val dataset after 9 epochs is = 0.4434192080474046\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4434192080474046\n",
      "Error on this batch = 0.43022405228506866\n",
      "Error on this batch = 0.42103155526587915\n",
      "Cost on val dataset after 10 epochs is = 0.4197793909623293\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4197793909623293\n",
      "Error on this batch = 0.40456329220657367\n",
      "Error on this batch = 0.3934190550380836\n",
      "Cost on val dataset after 11 epochs is = 0.3911787659676683\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.3911787659676683\n",
      "Error on this batch = 0.37281453457530633\n",
      "Error on this batch = 0.36074477619004996\n",
      "Cost on val dataset after 12 epochs is = 0.35300111959140906\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.35300111959140906\n",
      "Error on this batch = 0.3381941352266166\n",
      "Error on this batch = 0.32644251885789616\n",
      "Cost on val dataset after 13 epochs is = 0.3207817723276397\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.3207817723276397\n",
      "Error on this batch = 0.2977979320382746\n",
      "Error on this batch = 0.30127918809602533\n",
      "Cost on val dataset after 14 epochs is = 0.29979500846097734\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.29979500846097734\n",
      "Error on this batch = 0.2918204200059148\n",
      "Error on this batch = 0.2793077287043002\n",
      "Cost on val dataset after 15 epochs is = 0.2765038414297078\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.2765038414297078\n",
      "Error on this batch = 0.2669611057990093\n",
      "Error on this batch = 0.25977623275765527\n",
      "Cost on val dataset after 16 epochs is = 0.25585011971784954\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.25585011971784954\n",
      "Error on this batch = 0.2428550203860656\n",
      "Error on this batch = 0.2407592583059089\n",
      "Cost on val dataset after 17 epochs is = 0.25253407585649007\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.25253407585649007\n",
      "Error on this batch = 0.23464722341759583\n",
      "Error on this batch = 0.2368502016371366\n",
      "Cost on val dataset after 18 epochs is = 0.23753067305268297\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.23753067305268297\n",
      "Error on this batch = 0.22031652904905907\n",
      "Error on this batch = 0.22026349665371162\n",
      "Cost on val dataset after 19 epochs is = 0.22719061725121906\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.22719061725121906\n",
      "Error on this batch = 0.2083635314215937\n",
      "Error on this batch = 0.20739491732942952\n",
      "Cost on val dataset after 20 epochs is = 0.21319495694131965\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.21319495694131965\n",
      "Error on this batch = 0.19561747924049028\n",
      "Error on this batch = 0.20836900892618673\n",
      "Cost on val dataset after 21 epochs is = 0.21178986514372006\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.21178986514372006\n",
      "Error on this batch = 0.19166096975308933\n",
      "Error on this batch = 0.19885457094910786\n",
      "Cost on val dataset after 22 epochs is = 0.20370284162606334\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.20370284162606334\n",
      "Error on this batch = 0.18512040434163418\n",
      "Error on this batch = 0.1865072169051043\n",
      "Cost on val dataset after 23 epochs is = 0.19853105949620217\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.19853105949620217\n",
      "Error on this batch = 0.17844211745910193\n",
      "Error on this batch = 0.2013117114542105\n",
      "Cost on val dataset after 24 epochs is = 0.20068549513783418\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.20068549513783418\n",
      "Error on this batch = 0.17776322120686117\n",
      "Error on this batch = 0.1963182821972601\n",
      "Cost on val dataset after 25 epochs is = 0.18491722061226762\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.18491722061226762\n",
      "Error on this batch = 0.1687922310893149\n",
      "Error on this batch = 0.19409149372875356\n",
      "Cost on val dataset after 26 epochs is = 0.18046800618241549\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.18046800618241549\n",
      "Error on this batch = 0.16560805347151317\n",
      "Error on this batch = 0.18363892782533672\n",
      "Cost on val dataset after 27 epochs is = 0.18351220150347858\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.18351220150347858\n",
      "Error on this batch = 0.16474552125913278\n",
      "Error on this batch = 0.17749835430172195\n",
      "Cost on val dataset after 28 epochs is = 0.187423471911141\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.187423471911141\n",
      "Error on this batch = 0.16922669690439038\n",
      "Error on this batch = 0.1715328743290786\n",
      "Cost on val dataset after 29 epochs is = 0.17852115616732822\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.17852115616732822\n",
      "Error on this batch = 0.15994819381063244\n",
      "Error on this batch = 0.1684808624186812\n",
      "Cost on val dataset after 30 epochs is = 0.17696324117340234\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.17696324117340234\n",
      "Error on this batch = 0.15787438605116175\n",
      "Error on this batch = 0.16372058996684682\n",
      "Cost on val dataset after 31 epochs is = 0.17568418385044574\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.17568418385044574\n",
      "Error on this batch = 0.1557844317948807\n",
      "Error on this batch = 0.16000596911050594\n",
      "Cost on val dataset after 32 epochs is = 0.174159788956462\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.174159788956462\n",
      "Error on this batch = 0.15355817205507458\n",
      "Error on this batch = 0.15634680426882838\n",
      "Cost on val dataset after 33 epochs is = 0.1735826400319437\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.1735826400319437\n",
      "Error on this batch = 0.15194879607627207\n",
      "Error on this batch = 0.1527196637459968\n",
      "Cost on val dataset after 34 epochs is = 0.17244638052035255\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.17244638052035255\n",
      "Error on this batch = 0.14964992372512018\n",
      "Error on this batch = 0.15060350152871474\n",
      "Cost on val dataset after 35 epochs is = 0.1687772964229743\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.1687772964229743\n",
      "Error on this batch = 0.14733344777464777\n",
      "Error on this batch = 0.14881682880211386\n",
      "Cost on val dataset after 36 epochs is = 0.17123232498527305\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.17123232498527305\n",
      "Error on this batch = 0.1453945284759074\n",
      "Error on this batch = 0.14837873024636236\n",
      "Cost on val dataset after 37 epochs is = 0.17021727815911034\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.17021727815911034\n",
      "Error on this batch = 0.14351018864366819\n",
      "Error on this batch = 0.14808502781041433\n",
      "Cost on val dataset after 38 epochs is = 0.16969994372308603\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.16969994372308603\n",
      "Error on this batch = 0.1418036509558942\n",
      "Error on this batch = 0.14814321022838264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 39 epochs is = 0.16942247031865043\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.16942247031865043\n",
      "Error on this batch = 0.13995539606637375\n",
      "Error on this batch = 0.14791038889566935\n",
      "Cost on val dataset after 40 epochs is = 0.16929722401971833\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.16929722401971833\n",
      "Error on this batch = 0.1385138557490346\n",
      "Error on this batch = 0.1486228809326434\n",
      "Cost on val dataset after 41 epochs is = 0.1689208767653947\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.1689208767653947\n",
      "Error on this batch = 0.13704762693183814\n",
      "Error on this batch = 0.14800888776817372\n",
      "Cost on val dataset after 42 epochs is = 0.16854724435679688\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.16854724435679688\n",
      "Error on this batch = 0.1357615102395488\n",
      "Error on this batch = 0.14829988618202009\n",
      "Cost on val dataset after 43 epochs is = 0.16817351245498705\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.16817351245498705\n",
      "Error on this batch = 0.13472708880197634\n",
      "Error on this batch = 0.1468111151166948\n",
      "Cost on val dataset after 44 epochs is = 0.1679068369980956\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.1679068369980956\n",
      "Error on this batch = 0.1334070026972708\n",
      "Error on this batch = 0.14636591218714887\n",
      "Cost on val dataset after 45 epochs is = 0.16728283535243704\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.16728283535243704\n",
      "Error on this batch = 0.13277511135651363\n",
      "Error on this batch = 0.14530125685972045\n",
      "Cost on val dataset after 46 epochs is = 0.1667847971799609\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.1667847971799609\n",
      "Error on this batch = 0.13187767263347855\n",
      "Error on this batch = 0.14455894329903743\n",
      "Cost on val dataset after 47 epochs is = 0.16625598007096454\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.16625598007096454\n",
      "Error on this batch = 0.1313279169619288\n",
      "Error on this batch = 0.14325890178117792\n",
      "Cost on val dataset after 48 epochs is = 0.1656943203942405\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.1656943203942405\n",
      "Error on this batch = 0.13069124977253962\n",
      "Error on this batch = 0.14616341261963198\n",
      "Cost on val dataset after 49 epochs is = 0.16528261978835157\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.16528261978835157\n",
      "Error on this batch = 0.12997570697190503\n",
      "Error on this batch = 0.14234539473265034\n",
      "Cost on val dataset after 50 epochs is = 0.1652019687828014\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.1652019687828014\n",
      "Error on this batch = 0.129949194902904\n",
      "Error on this batch = 0.14206343785061948\n",
      "Cost on val dataset after 51 epochs is = 0.1650594534155557\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.1650594534155557\n",
      "Error on this batch = 0.12899740109452115\n",
      "Error on this batch = 0.1404740445889825\n",
      "Cost on val dataset after 52 epochs is = 0.16494913461864755\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.16494913461864755\n",
      "Error on this batch = 0.12799795468359448\n",
      "Error on this batch = 0.137888910190291\n",
      "Cost on val dataset after 53 epochs is = 0.16521739975071437\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.16521739975071437\n",
      "Error on this batch = 0.12695515550418052\n",
      "Error on this batch = 0.13794356168403263\n",
      "Cost on val dataset after 54 epochs is = 0.16524832233647188\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.16524832233647188\n",
      "Error on this batch = 0.12655893717221608\n",
      "Error on this batch = 0.14243763058855\n",
      "Cost on val dataset after 55 epochs is = 0.16512933390398654\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.16512933390398654\n",
      "Error on this batch = 0.12570258881272142\n",
      "Error on this batch = 0.1448421523885004\n",
      "Cost on val dataset after 56 epochs is = 0.16542666662334388\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.16542666662334388\n",
      "Error on this batch = 0.12518997279632824\n",
      "Error on this batch = 0.14835203706188502\n",
      "Cost on val dataset after 57 epochs is = 0.165350031344515\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.165350031344515\n",
      "Error on this batch = 0.12413211616626374\n",
      "Error on this batch = 0.148286466944433\n",
      "Cost on val dataset after 58 epochs is = 0.16523486490394582\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.16523486490394582\n",
      "Error on this batch = 0.1236892652583526\n",
      "Error on this batch = 0.1311661255355379\n",
      "Cost on val dataset after 59 epochs is = 0.16469178176123683\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.16469178176123683\n",
      "Error on this batch = 0.12388140895937394\n",
      "Error on this batch = 0.1351163526316248\n",
      "Cost on val dataset after 60 epochs is = 0.16566368466272005\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.16566368466272005\n",
      "Error on this batch = 0.12427681706506578\n",
      "Error on this batch = 0.1299877505415914\n",
      "Cost on val dataset after 61 epochs is = 0.176569771235098\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.176569771235098\n",
      "Error on this batch = 0.13925762642079362\n",
      "Error on this batch = 0.14447287991765856\n",
      "Cost on val dataset after 62 epochs is = 0.1669638463539249\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.1669638463539249\n",
      "Error on this batch = 0.12318455657044759\n",
      "Error on this batch = 0.13024880864595992\n",
      "Cost on val dataset after 63 epochs is = 0.16807659282530826\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.16807659282530826\n",
      "Error on this batch = 0.12365446323596002\n",
      "Error on this batch = 0.1321237777549872\n",
      "Cost on val dataset after 64 epochs is = 0.16757356679817248\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.16757356679817248\n",
      "Error on this batch = 0.1219908668148295\n",
      "Error on this batch = 0.14144741734727673\n",
      "Cost on val dataset after 65 epochs is = 0.16973886413200517\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.16973886413200517\n",
      "Error on this batch = 0.12239352439880015\n",
      "Error on this batch = 0.14367638529372687\n",
      "Cost on val dataset after 66 epochs is = 0.16868262723178942\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.16868262723178942\n",
      "Error on this batch = 0.1238927174749638\n",
      "Error on this batch = 0.13795922929753576\n",
      "Cost on val dataset after 67 epochs is = 0.17203628089350514\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.17203628089350514\n",
      "Error on this batch = 0.12060507545115468\n",
      "Error on this batch = 0.13657147693414584\n",
      "Cost on val dataset after 68 epochs is = 0.17211467507166997\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.17211467507166997\n",
      "Error on this batch = 0.1221382257403603\n",
      "Error on this batch = 0.14040147667579359\n",
      "Cost on val dataset after 69 epochs is = 0.17085895181601737\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.17085895181601737\n",
      "Error on this batch = 0.11988561171117679\n",
      "Error on this batch = 0.13181691844330762\n",
      "Cost on val dataset after 70 epochs is = 0.18334575489190444\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.18334575489190444\n",
      "Error on this batch = 0.1389611836431534\n",
      "Error on this batch = 0.12924006641537303\n",
      "Cost on val dataset after 71 epochs is = 0.16913508654046727\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.16913508654046727\n",
      "Error on this batch = 0.11909275140558762\n",
      "Error on this batch = 0.12680384544045872\n",
      "Cost on val dataset after 72 epochs is = 0.17169298591346957\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.17169298591346957\n",
      "Error on this batch = 0.12072035846401886\n",
      "Error on this batch = 0.1288185863886703\n",
      "Cost on val dataset after 73 epochs is = 0.16969856895022256\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.16969856895022256\n",
      "Error on this batch = 0.12128915736562386\n",
      "Error on this batch = 0.13044408747909167\n",
      "Cost on val dataset after 74 epochs is = 0.19580773481587538\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.19580773481587538\n",
      "Error on this batch = 0.14257096285518397\n",
      "Error on this batch = 0.13934938303935082\n",
      "Cost on val dataset after 75 epochs is = 0.16923328238545687\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.16923328238545687\n",
      "Error on this batch = 0.1184506638157136\n",
      "Error on this batch = 0.12661541649087277\n",
      "Cost on val dataset after 76 epochs is = 0.1722662839977095\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.1722662839977095\n",
      "Error on this batch = 0.12291118677109665\n",
      "Error on this batch = 0.12856586299252631\n",
      "Cost on val dataset after 77 epochs is = 0.1710630985500331\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.1710630985500331\n",
      "Error on this batch = 0.12404932713491991\n",
      "Error on this batch = 0.12610081716921404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 78 epochs is = 0.17571191690667734\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.17571191690667734\n",
      "Error on this batch = 0.12684773142167607\n",
      "Error on this batch = 0.14105368736740845\n",
      "Cost on val dataset after 79 epochs is = 0.17071996580169274\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.17071996580169274\n",
      "Error on this batch = 0.11937390539726508\n",
      "Error on this batch = 0.13520875869920382\n",
      "Cost on val dataset after 80 epochs is = 0.17359984904281298\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.17359984904281298\n",
      "Error on this batch = 0.11890805646444118\n",
      "Error on this batch = 0.12930286749541028\n",
      "Cost on val dataset after 81 epochs is = 0.18206433762599006\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.18206433762599006\n",
      "Error on this batch = 0.12500100063738714\n",
      "Error on this batch = 0.13833093866411575\n",
      "Cost on val dataset after 82 epochs is = 0.17296344275606637\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.17296344275606637\n",
      "Error on this batch = 0.11766013357344346\n",
      "Error on this batch = 0.15183750089211953\n",
      "Cost on val dataset after 83 epochs is = 0.17510192814410602\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.17510192814410602\n",
      "Error on this batch = 0.11997286591654933\n",
      "Error on this batch = 0.13423090242565758\n",
      "Cost on val dataset after 84 epochs is = 0.18997354429502808\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.18997354429502808\n",
      "Error on this batch = 0.1299139570942231\n",
      "Error on this batch = 0.12456430987591668\n",
      "Cost on val dataset after 85 epochs is = 0.174961225727428\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.174961225727428\n",
      "Error on this batch = 0.12304462398694697\n",
      "Error on this batch = 0.124896005881625\n",
      "Cost on val dataset after 86 epochs is = 0.17494215919947212\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.17494215919947212\n",
      "Error on this batch = 0.11932908052539981\n",
      "Error on this batch = 0.15159862395192047\n",
      "Cost on val dataset after 87 epochs is = 0.17322979178357215\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.17322979178357215\n",
      "Error on this batch = 0.12375052671289517\n",
      "Error on this batch = 0.14468348183037105\n",
      "Cost on val dataset after 88 epochs is = 0.17295024113080507\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.17295024113080507\n",
      "Error on this batch = 0.11936646106625481\n",
      "Error on this batch = 0.1367604440650226\n",
      "Cost on val dataset after 89 epochs is = 0.18660273015969053\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.18660273015969053\n",
      "Error on this batch = 0.132507391889365\n",
      "Error on this batch = 0.13069647343348725\n",
      "Cost on val dataset after 90 epochs is = 0.17928728265885124\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.17928728265885124\n",
      "Error on this batch = 0.13514513360534827\n",
      "Error on this batch = 0.1378144399021261\n",
      "Cost on val dataset after 91 epochs is = 0.18001635701237018\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.18001635701237018\n",
      "Error on this batch = 0.11813392340859476\n",
      "Error on this batch = 0.14418849727722194\n",
      "Cost on val dataset after 92 epochs is = 0.17900294445481466\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.17900294445481466\n",
      "Error on this batch = 0.1196078034023842\n",
      "Error on this batch = 0.12523290325106115\n",
      "Cost on val dataset after 93 epochs is = 0.1830140470223026\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.1830140470223026\n",
      "Error on this batch = 0.13356172680299122\n",
      "Error on this batch = 0.14015517994582213\n",
      "Cost on val dataset after 94 epochs is = 0.17814298784361732\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.17814298784361732\n",
      "Error on this batch = 0.11814250394758741\n",
      "Error on this batch = 0.13394867260836005\n",
      "Cost on val dataset after 95 epochs is = 0.16940886289482524\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.16940886289482524\n",
      "Error on this batch = 0.11442132994030303\n",
      "Error on this batch = 0.12621813100184062\n",
      "Cost on val dataset after 96 epochs is = 0.18191212106586643\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.18191212106586643\n",
      "Error on this batch = 0.11976038659275692\n",
      "Error on this batch = 0.1276379526515926\n",
      "Cost on val dataset after 97 epochs is = 0.1777290561675612\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.1777290561675612\n",
      "Error on this batch = 0.11437347556961924\n",
      "Error on this batch = 0.1351801752276384\n",
      "Cost on val dataset after 98 epochs is = 0.18153205317815388\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.18153205317815388\n",
      "Error on this batch = 0.12533286075606992\n",
      "Error on this batch = 0.13556750030268594\n",
      "Cost on val dataset after 99 epochs is = 0.18041789826890536\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.18041789826890536\n",
      "Error on this batch = 0.12567282957789433\n",
      "Error on this batch = 0.1228767476969735\n",
      "Cost on val dataset after 100 epochs is = 0.1781989578864622\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.1781989578864622\n",
      "Error on this batch = 0.11531151383253685\n",
      "Error on this batch = 0.1245992763925922\n",
      "Cost on val dataset after 101 epochs is = 0.17775215082802495\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.17775215082802495\n",
      "Error on this batch = 0.12003033322692991\n",
      "Error on this batch = 0.12169793751384685\n",
      "Cost on val dataset after 102 epochs is = 0.1845131223539782\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.1845131223539782\n",
      "Error on this batch = 0.12282093911434318\n",
      "Error on this batch = 0.12032771067021823\n",
      "Cost on val dataset after 103 epochs is = 0.16934006324014814\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.16934006324014814\n",
      "Error on this batch = 0.11276460101103732\n",
      "Error on this batch = 0.12460488762319369\n",
      "Cost on val dataset after 104 epochs is = 0.1967180002514632\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.1967180002514632\n",
      "Error on this batch = 0.13728407439772583\n",
      "Error on this batch = 0.13406262109751169\n",
      "Cost on val dataset after 105 epochs is = 0.18146475557486239\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.18146475557486239\n",
      "Error on this batch = 0.13176638076290734\n",
      "Error on this batch = 0.14004603492753195\n",
      "Cost on val dataset after 106 epochs is = 0.17155052904243176\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.17155052904243176\n",
      "Error on this batch = 0.12030557252767832\n",
      "Error on this batch = 0.11836321905055922\n",
      "Cost on val dataset after 107 epochs is = 0.1879873477985425\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.1879873477985425\n",
      "Error on this batch = 0.12151097168440124\n",
      "Error on this batch = 0.1210528167226523\n",
      "Cost on val dataset after 108 epochs is = 0.18625761017032164\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.18625761017032164\n",
      "Error on this batch = 0.12586803061987736\n",
      "Error on this batch = 0.11703140061036962\n",
      "Cost on val dataset after 109 epochs is = 0.17753549289615944\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.17753549289615944\n",
      "Error on this batch = 0.11106784139892482\n",
      "Error on this batch = 0.11352228644862494\n",
      "Cost on val dataset after 110 epochs is = 0.17598927049558652\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.17598927049558652\n",
      "Error on this batch = 0.11269765405378177\n",
      "Error on this batch = 0.12311914228128369\n",
      "Cost on val dataset after 111 epochs is = 0.1748293704237185\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.1748293704237185\n",
      "Error on this batch = 0.11394262232766524\n",
      "Error on this batch = 0.11788134323394703\n",
      "Cost on val dataset after 112 epochs is = 0.1744610957674858\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.1744610957674858\n",
      "Error on this batch = 0.11514834387033517\n",
      "Error on this batch = 0.11306197685808178\n",
      "Cost on val dataset after 113 epochs is = 0.17225135398465558\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.17225135398465558\n",
      "Error on this batch = 0.11262024593738262\n",
      "Error on this batch = 0.11308481084132335\n",
      "Cost on val dataset after 114 epochs is = 0.1719762743657983\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.1719762743657983\n",
      "Error on this batch = 0.11089839257253634\n",
      "Error on this batch = 0.11525515388953551\n",
      "Cost on val dataset after 115 epochs is = 0.1790696085900021\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.1790696085900021\n",
      "Error on this batch = 0.11407893246587492\n",
      "Error on this batch = 0.1200738136742579\n",
      "Cost on val dataset after 116 epochs is = 0.17748823054897792\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.17748823054897792\n",
      "Error on this batch = 0.1086632289404945\n",
      "Error on this batch = 0.11505073821969763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 117 epochs is = 0.17346832830303358\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.17346832830303358\n",
      "Error on this batch = 0.11640368143605823\n",
      "Error on this batch = 0.1252202280535558\n",
      "Cost on val dataset after 118 epochs is = 0.19386412373853096\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.19386412373853096\n",
      "Error on this batch = 0.1278755761306083\n",
      "Error on this batch = 0.11812837024460882\n",
      "Cost on val dataset after 119 epochs is = 0.18220522012941595\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.18220522012941595\n",
      "Error on this batch = 0.13018862368046252\n",
      "Error on this batch = 0.11387555085776868\n",
      "Cost on val dataset after 120 epochs is = 0.17128109480563278\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.17128109480563278\n",
      "Error on this batch = 0.1099070224880412\n",
      "Error on this batch = 0.11506330262544885\n",
      "Cost on val dataset after 121 epochs is = 0.17258227473435384\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.17258227473435384\n",
      "Error on this batch = 0.10974196772201833\n",
      "Error on this batch = 0.11085437728472927\n",
      "Cost on val dataset after 122 epochs is = 0.17208506168719315\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.17208506168719315\n",
      "Error on this batch = 0.11512641642812962\n",
      "Error on this batch = 0.11466947827154284\n",
      "Cost on val dataset after 123 epochs is = 0.17052837913589525\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.17052837913589525\n",
      "Error on this batch = 0.10783875965361876\n",
      "Error on this batch = 0.11130765269692347\n",
      "Cost on val dataset after 124 epochs is = 0.17899729896038324\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.17899729896038324\n",
      "Error on this batch = 0.1110768357834062\n",
      "Error on this batch = 0.16798186923857208\n",
      "Cost on val dataset after 125 epochs is = 0.17774769224869166\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.17774769224869166\n",
      "Error on this batch = 0.1122395889658972\n",
      "Error on this batch = 0.11761214204574393\n",
      "Cost on val dataset after 126 epochs is = 0.1745716839246355\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.1745716839246355\n",
      "Error on this batch = 0.1215116901171915\n",
      "Error on this batch = 0.1471356618849174\n",
      "Cost on val dataset after 127 epochs is = 0.1741514132114221\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.1741514132114221\n",
      "Error on this batch = 0.10842851539599718\n",
      "Error on this batch = 0.111532883506445\n",
      "Cost on val dataset after 128 epochs is = 0.17655398845786363\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.17655398845786363\n",
      "Error on this batch = 0.11439660568851226\n",
      "Error on this batch = 0.11828561664177775\n",
      "Cost on val dataset after 129 epochs is = 0.17762236229905723\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.17762236229905723\n",
      "Error on this batch = 0.11265380593381856\n",
      "Error on this batch = 0.1225562573791068\n",
      "Cost on val dataset after 130 epochs is = 0.17345677865558762\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.17345677865558762\n",
      "Error on this batch = 0.10553993989935478\n",
      "Error on this batch = 0.15301112158117178\n",
      "Cost on val dataset after 131 epochs is = 0.17694395897670556\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.17694395897670556\n",
      "Error on this batch = 0.11365207176665897\n",
      "Error on this batch = 0.13026504615388826\n",
      "Cost on val dataset after 132 epochs is = 0.1808425469267667\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.1808425469267667\n",
      "Error on this batch = 0.12453209193144016\n",
      "Error on this batch = 0.1221216979773822\n",
      "Cost on val dataset after 133 epochs is = 0.1752341307781077\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.1752341307781077\n",
      "Error on this batch = 0.10878085173751068\n",
      "Error on this batch = 0.12838475421438986\n",
      "Cost on val dataset after 134 epochs is = 0.18867162238997875\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.18867162238997875\n",
      "Error on this batch = 0.13501410693485358\n",
      "Error on this batch = 0.13144073858968547\n",
      "Cost on val dataset after 135 epochs is = 0.1822957516537747\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.1822957516537747\n",
      "Error on this batch = 0.13224390599954916\n",
      "Error on this batch = 0.12956636346838526\n",
      "Cost on val dataset after 136 epochs is = 0.17071193663648243\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.17071193663648243\n",
      "Error on this batch = 0.10750770774190066\n",
      "Error on this batch = 0.12111887379084924\n",
      "Cost on val dataset after 137 epochs is = 0.17225296801435247\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.17225296801435247\n",
      "Error on this batch = 0.10174857967508714\n",
      "Error on this batch = 0.11966125621538976\n",
      "Cost on val dataset after 138 epochs is = 0.17854216095386954\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.17854216095386954\n",
      "Error on this batch = 0.10484361496108133\n",
      "Error on this batch = 0.11918780572096185\n",
      "Cost on val dataset after 139 epochs is = 0.18285507049597607\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.18285507049597607\n",
      "Error on this batch = 0.11176431889978879\n",
      "Error on this batch = 0.13057368392523955\n",
      "Cost on val dataset after 140 epochs is = 0.17887595566959524\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.17887595566959524\n",
      "Error on this batch = 0.12249422692226762\n",
      "Error on this batch = 0.12898944685806332\n",
      "Cost on val dataset after 141 epochs is = 0.17418431406687288\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.17418431406687288\n",
      "Error on this batch = 0.10430077935429473\n",
      "Error on this batch = 0.12553218298996682\n",
      "Cost on val dataset after 142 epochs is = 0.17937085299131267\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.17937085299131267\n",
      "Error on this batch = 0.10755249969472111\n",
      "Error on this batch = 0.11988999569679713\n",
      "Cost on val dataset after 143 epochs is = 0.18027262848666145\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.18027262848666145\n",
      "Error on this batch = 0.10619931396920987\n",
      "Error on this batch = 0.12221583587970643\n",
      "Cost on val dataset after 144 epochs is = 0.17892132541973643\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.17892132541973643\n",
      "Error on this batch = 0.1108760832283965\n",
      "Error on this batch = 0.11649224507225878\n",
      "Cost on val dataset after 145 epochs is = 0.17739854054414772\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.17739854054414772\n",
      "Error on this batch = 0.10737651441522462\n",
      "Error on this batch = 0.14234613144562666\n",
      "Cost on val dataset after 146 epochs is = 0.17210387374116626\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.17210387374116626\n",
      "Error on this batch = 0.10934666013766034\n",
      "Error on this batch = 0.13463989729012846\n",
      "Cost on val dataset after 147 epochs is = 0.17584846002278495\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.17584846002278495\n",
      "Error on this batch = 0.10219188486682079\n",
      "Error on this batch = 0.1185459077504379\n",
      "Cost on val dataset after 148 epochs is = 0.18085976405511664\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.18085976405511664\n",
      "Error on this batch = 0.11426063793429717\n",
      "Error on this batch = 0.13388868406127383\n",
      "Cost on val dataset after 149 epochs is = 0.1823854524189169\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.1823854524189169\n",
      "Error on this batch = 0.10968311031053361\n",
      "Error on this batch = 0.12974638058310256\n",
      "Cost on val dataset after 150 epochs is = 0.18075416720252305\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.18075416720252305\n",
      "Error on this batch = 0.10296282800008999\n",
      "Error on this batch = 0.11852606721020185\n",
      "Cost on val dataset after 151 epochs is = 0.1779190327720155\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.1779190327720155\n",
      "Error on this batch = 0.11001527121404632\n",
      "Error on this batch = 0.1297596659499184\n",
      "Cost on val dataset after 152 epochs is = 0.1859781397603947\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.1859781397603947\n",
      "Error on this batch = 0.1142801993201116\n",
      "Error on this batch = 0.11437167803708077\n",
      "Cost on val dataset after 153 epochs is = 0.18542354675539047\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.18542354675539047\n",
      "Error on this batch = 0.11618520363435597\n",
      "Error on this batch = 0.13635095524534233\n",
      "Cost on val dataset after 154 epochs is = 0.17655170229084952\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.17655170229084952\n",
      "Error on this batch = 0.10663801813703132\n",
      "Error on this batch = 0.1173780521700668\n",
      "Cost on val dataset after 155 epochs is = 0.17832110188774963\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.17832110188774963\n",
      "Error on this batch = 0.10810070885033418\n",
      "Error on this batch = 0.13157979831951924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 156 epochs is = 0.18718531452443748\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.18718531452443748\n",
      "Error on this batch = 0.1189928592192255\n",
      "Error on this batch = 0.14599252671989046\n",
      "Cost on val dataset after 157 epochs is = 0.17791917162362486\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.17791917162362486\n",
      "Error on this batch = 0.10747070376954404\n",
      "Error on this batch = 0.12292514827130865\n",
      "Cost on val dataset after 158 epochs is = 0.1788417500628872\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.1788417500628872\n",
      "Error on this batch = 0.1107768016917987\n",
      "Error on this batch = 0.1365454641442829\n",
      "Cost on val dataset after 159 epochs is = 0.17595817524919286\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.17595817524919286\n",
      "Error on this batch = 0.10979328859866513\n",
      "Error on this batch = 0.12722488990327632\n",
      "Cost on val dataset after 160 epochs is = 0.17807830946931144\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.17807830946931144\n",
      "Error on this batch = 0.11174078067181699\n",
      "Error on this batch = 0.11390407382648121\n",
      "Cost on val dataset after 161 epochs is = 0.1802279810831117\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.1802279810831117\n",
      "Error on this batch = 0.11142759360518849\n",
      "Error on this batch = 0.12760660837078144\n",
      "Cost on val dataset after 162 epochs is = 0.17967264942425604\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.17967264942425604\n",
      "Error on this batch = 0.10688833568249102\n",
      "Error on this batch = 0.11641053400404758\n",
      "Cost on val dataset after 163 epochs is = 0.17851145496409693\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.17851145496409693\n",
      "Error on this batch = 0.10272279192381245\n",
      "Error on this batch = 0.10669289943360853\n",
      "Cost on val dataset after 164 epochs is = 0.1846291562171486\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.1846291562171486\n",
      "Error on this batch = 0.1232852762197124\n",
      "Error on this batch = 0.11169039143762383\n",
      "Cost on val dataset after 165 epochs is = 0.17895173404344125\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.17895173404344125\n",
      "Error on this batch = 0.10406313864192694\n",
      "Error on this batch = 0.1114996858835751\n",
      "Cost on val dataset after 166 epochs is = 0.17547751692230423\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.17547751692230423\n",
      "Error on this batch = 0.10216794436203702\n",
      "Error on this batch = 0.11468513661732711\n",
      "Cost on val dataset after 167 epochs is = 0.18594910729455638\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.18594910729455638\n",
      "Error on this batch = 0.11893813047659371\n",
      "Error on this batch = 0.10876468125794161\n",
      "Cost on val dataset after 168 epochs is = 0.18000344725172956\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.18000344725172956\n",
      "Error on this batch = 0.11260044214055238\n",
      "Error on this batch = 0.12830440969289977\n",
      "Cost on val dataset after 169 epochs is = 0.17416421089464845\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.17416421089464845\n",
      "Error on this batch = 0.10449010234377169\n",
      "Error on this batch = 0.1139084023889003\n",
      "Cost on val dataset after 170 epochs is = 0.17462061746386467\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.17462061746386467\n",
      "Error on this batch = 0.1030993650824615\n",
      "Error on this batch = 0.11474510039025063\n",
      "Cost on val dataset after 171 epochs is = 0.1730434574577181\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.1730434574577181\n",
      "Error on this batch = 0.10125302497449258\n",
      "Error on this batch = 0.13231713849867305\n",
      "Cost on val dataset after 172 epochs is = 0.17381778838648837\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.17381778838648837\n",
      "Error on this batch = 0.10318687501719208\n",
      "Error on this batch = 0.125717160662856\n",
      "Cost on val dataset after 173 epochs is = 0.21824961706132032\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.21824961706132032\n",
      "Error on this batch = 0.1671089187244643\n",
      "Error on this batch = 0.14977188873579306\n",
      "Cost on val dataset after 174 epochs is = 0.173108575460026\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.173108575460026\n",
      "Error on this batch = 0.1030359602344229\n",
      "Error on this batch = 0.12577671343193558\n",
      "Cost on val dataset after 175 epochs is = 0.17935435655722612\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.17935435655722612\n",
      "Error on this batch = 0.10832317007368664\n",
      "Error on this batch = 0.11211076051710613\n",
      "Cost on val dataset after 176 epochs is = 0.17030224525802015\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.17030224525802015\n",
      "Error on this batch = 0.10387233081994411\n",
      "Error on this batch = 0.11260590406127709\n",
      "Cost on val dataset after 177 epochs is = 0.1794002227939851\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.1794002227939851\n",
      "Error on this batch = 0.11728983389304752\n",
      "Error on this batch = 0.1254415909451433\n",
      "Cost on val dataset after 178 epochs is = 0.16928994197835961\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.16928994197835961\n",
      "Error on this batch = 0.10270561386986385\n",
      "Error on this batch = 0.13302503333328933\n",
      "Cost on val dataset after 179 epochs is = 0.17277570993308797\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.17277570993308797\n",
      "Error on this batch = 0.10038552555778718\n",
      "Error on this batch = 0.11335370078657082\n",
      "Cost on val dataset after 180 epochs is = 0.16935990451579583\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.16935990451579583\n",
      "Error on this batch = 0.10256605073117062\n",
      "Error on this batch = 0.1099905842813492\n",
      "Cost on val dataset after 181 epochs is = 0.17128516558352494\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.17128516558352494\n",
      "Error on this batch = 0.10243852742472427\n",
      "Error on this batch = 0.10506424271484685\n",
      "Cost on val dataset after 182 epochs is = 0.16958997334615442\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.16958997334615442\n",
      "Error on this batch = 0.1060275999272085\n",
      "Error on this batch = 0.12562381569321293\n",
      "Cost on val dataset after 183 epochs is = 0.18761209508422425\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.18761209508422425\n",
      "Error on this batch = 0.11094075725196449\n",
      "Error on this batch = 0.11444572941608097\n",
      "Cost on val dataset after 184 epochs is = 0.17406894993936198\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.17406894993936198\n",
      "Error on this batch = 0.10530360783318875\n",
      "Error on this batch = 0.11406034059418747\n",
      "Cost on val dataset after 185 epochs is = 0.1795459182518405\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.1795459182518405\n",
      "Error on this batch = 0.10807399102091868\n",
      "Error on this batch = 0.10506899298725093\n",
      "Cost on val dataset after 186 epochs is = 0.17310726745190771\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.17310726745190771\n",
      "Error on this batch = 0.11082681285737506\n",
      "Error on this batch = 0.10580513743367588\n",
      "Cost on val dataset after 187 epochs is = 0.17953162941414127\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.17953162941414127\n",
      "Error on this batch = 0.1043301670781231\n",
      "Error on this batch = 0.11274925028398763\n",
      "Cost on val dataset after 188 epochs is = 0.1703123963635118\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.1703123963635118\n",
      "Error on this batch = 0.10250901878095764\n",
      "Error on this batch = 0.10918582257714196\n",
      "Cost on val dataset after 189 epochs is = 0.176372311084773\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.176372311084773\n",
      "Error on this batch = 0.10462088346019512\n",
      "Error on this batch = 0.11732534306197671\n",
      "Cost on val dataset after 190 epochs is = 0.18126290089540661\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.18126290089540661\n",
      "Error on this batch = 0.09949869091943997\n",
      "Error on this batch = 0.10682545904972646\n",
      "Cost on val dataset after 191 epochs is = 0.18117592069693256\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.18117592069693256\n",
      "Error on this batch = 0.10851152800943542\n",
      "Error on this batch = 0.10569609510846517\n",
      "Cost on val dataset after 192 epochs is = 0.16996593037962485\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.16996593037962485\n",
      "Error on this batch = 0.10309749323257006\n",
      "Error on this batch = 0.11372408888153071\n",
      "Cost on val dataset after 193 epochs is = 0.18219359936104867\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.18219359936104867\n",
      "Error on this batch = 0.10798445686245998\n",
      "Error on this batch = 0.11623001473184368\n",
      "Cost on val dataset after 194 epochs is = 0.17622237054042414\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.17622237054042414\n",
      "Error on this batch = 0.10339560595728134\n",
      "Error on this batch = 0.1049907816549473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 195 epochs is = 0.17449404572403232\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.17449404572403232\n",
      "Error on this batch = 0.09961967025986612\n",
      "Error on this batch = 0.10628889814059007\n",
      "Cost on val dataset after 196 epochs is = 0.18053805279680393\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.18053805279680393\n",
      "Error on this batch = 0.10466983703835636\n",
      "Error on this batch = 0.13434426509760916\n",
      "Cost on val dataset after 197 epochs is = 0.1695872873587634\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.1695872873587634\n",
      "Error on this batch = 0.09724940967225475\n",
      "Error on this batch = 0.13835654007544942\n",
      "Cost on val dataset after 198 epochs is = 0.17294476031317735\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.17294476031317735\n",
      "Error on this batch = 0.10350448993562802\n",
      "Error on this batch = 0.11310556077806831\n",
      "Cost on val dataset after 199 epochs is = 0.1693269712509956\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.1693269712509956\n",
      "Error on this batch = 0.09740320078201119\n",
      "Error on this batch = 0.12006396451798917\n",
      "Cost on val dataset after 200 epochs is = 0.17222513419071042\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.17222513419071042\n",
      "Error on this batch = 0.09555670924476381\n",
      "Error on this batch = 0.17092716251757487\n",
      "Cost on val dataset after 201 epochs is = 0.18633936595852987\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.18633936595852987\n",
      "Error on this batch = 0.10239151532056098\n",
      "Error on this batch = 0.1028960208111429\n",
      "Cost on val dataset after 202 epochs is = 0.18029936828079038\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.18029936828079038\n",
      "Error on this batch = 0.103762493407955\n",
      "Error on this batch = 0.1044530918020358\n",
      "Cost on val dataset after 203 epochs is = 0.18058044523898803\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.18058044523898803\n",
      "Error on this batch = 0.10863720254060936\n",
      "Error on this batch = 0.10814984741334566\n",
      "Cost on val dataset after 204 epochs is = 0.17313476412335774\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.17313476412335774\n",
      "Error on this batch = 0.09674446422156432\n",
      "Error on this batch = 0.12479678194801565\n",
      "Cost on val dataset after 205 epochs is = 0.185088249281674\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.185088249281674\n",
      "Error on this batch = 0.10394582588779258\n",
      "Error on this batch = 0.11245906187379817\n",
      "Cost on val dataset after 206 epochs is = 0.1746708918140481\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.1746708918140481\n",
      "Error on this batch = 0.09534351671497636\n",
      "Error on this batch = 0.11167061646041879\n",
      "Cost on val dataset after 207 epochs is = 0.1745529738373718\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.1745529738373718\n",
      "Error on this batch = 0.09086357582061115\n",
      "Error on this batch = 0.09662649064670042\n",
      "Cost on val dataset after 208 epochs is = 0.2052275183571205\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.2052275183571205\n",
      "Error on this batch = 0.14013419064398172\n",
      "Error on this batch = 0.12717286952807524\n",
      "Cost on val dataset after 209 epochs is = 0.17545016144587486\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.17545016144587486\n",
      "Error on this batch = 0.0935397028049031\n",
      "Error on this batch = 0.10248647129402644\n",
      "Cost on val dataset after 210 epochs is = 0.1761619102373865\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.1761619102373865\n",
      "Error on this batch = 0.10417941912069072\n",
      "Error on this batch = 0.1074085908649309\n",
      "Cost on val dataset after 211 epochs is = 0.17302939400869738\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.17302939400869738\n",
      "Error on this batch = 0.09495347892102578\n",
      "Error on this batch = 0.10468225818450357\n",
      "Cost on val dataset after 212 epochs is = 0.1790619204070177\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.1790619204070177\n",
      "Error on this batch = 0.0913322378056148\n",
      "Error on this batch = 0.1264431062275235\n",
      "Cost on val dataset after 213 epochs is = 0.18118330529474103\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.18118330529474103\n",
      "Error on this batch = 0.11239777226967171\n",
      "Error on this batch = 0.15682819983515534\n",
      "Cost on val dataset after 214 epochs is = 0.17537688842184318\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.17537688842184318\n",
      "Error on this batch = 0.10169794603926956\n",
      "Error on this batch = 0.10307428415535831\n",
      "Cost on val dataset after 215 epochs is = 0.17496421865086004\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.17496421865086004\n",
      "Error on this batch = 0.09178257336064057\n",
      "Error on this batch = 0.12177789382220276\n",
      "Cost on val dataset after 216 epochs is = 0.18913083714242765\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.18913083714242765\n",
      "Error on this batch = 0.10863485017320479\n",
      "Error on this batch = 0.12901627709808972\n",
      "Cost on val dataset after 217 epochs is = 0.18224353360017925\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.18224353360017925\n",
      "Error on this batch = 0.09919458579292531\n",
      "Error on this batch = 0.1252189934384821\n",
      "Cost on val dataset after 218 epochs is = 0.1918758916375385\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.1918758916375385\n",
      "Error on this batch = 0.10424125879714619\n",
      "Error on this batch = 0.09886390063569993\n",
      "Cost on val dataset after 219 epochs is = 0.1767378295512222\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.1767378295512222\n",
      "Error on this batch = 0.09614381692438469\n",
      "Error on this batch = 0.10922073434960769\n",
      "Cost on val dataset after 220 epochs is = 0.17587791401312822\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.17587791401312822\n",
      "Error on this batch = 0.09674272305971346\n",
      "Error on this batch = 0.10353719800516703\n",
      "Cost on val dataset after 221 epochs is = 0.18753302975733863\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.18753302975733863\n",
      "Error on this batch = 0.09781992380629202\n",
      "Error on this batch = 0.10986844624909531\n",
      "Cost on val dataset after 222 epochs is = 0.19662424369960765\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.19662424369960765\n",
      "Error on this batch = 0.10917370421081429\n",
      "Error on this batch = 0.110401462801562\n",
      "Cost on val dataset after 223 epochs is = 0.18096839172575221\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.18096839172575221\n",
      "Error on this batch = 0.0951478136286368\n",
      "Error on this batch = 0.09700586337027858\n",
      "Cost on val dataset after 224 epochs is = 0.17925345267441226\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.17925345267441226\n",
      "Error on this batch = 0.0930773931289822\n",
      "Error on this batch = 0.11388573091053235\n",
      "Cost on val dataset after 225 epochs is = 0.18930376261553197\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.18930376261553197\n",
      "Error on this batch = 0.09994841420347562\n",
      "Error on this batch = 0.10900341356751915\n",
      "Cost on val dataset after 226 epochs is = 0.18038698743493697\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.18038698743493697\n",
      "Error on this batch = 0.09487012363219607\n",
      "Error on this batch = 0.17240606286581603\n",
      "Cost on val dataset after 227 epochs is = 0.20819260550416702\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.20819260550416702\n",
      "Error on this batch = 0.13091319553874375\n",
      "Error on this batch = 0.10911482036173265\n",
      "Cost on val dataset after 228 epochs is = 0.1761116415895558\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.1761116415895558\n",
      "Error on this batch = 0.09273410211564166\n",
      "Error on this batch = 0.10508822257668213\n",
      "Cost on val dataset after 229 epochs is = 0.17817539188435583\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.17817539188435583\n",
      "Error on this batch = 0.09397261379774427\n",
      "Error on this batch = 0.12326729082714274\n",
      "Cost on val dataset after 230 epochs is = 0.1785289890125556\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.1785289890125556\n",
      "Error on this batch = 0.089371055837961\n",
      "Error on this batch = 0.11266102207540657\n",
      "Cost on val dataset after 231 epochs is = 0.1813839339364583\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.1813839339364583\n",
      "Error on this batch = 0.09209779290121092\n",
      "Error on this batch = 0.1272216647542524\n",
      "Cost on val dataset after 232 epochs is = 0.18672962826791512\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.18672962826791512\n",
      "Error on this batch = 0.10237808239069343\n",
      "Error on this batch = 0.10560045409441923\n",
      "Cost on val dataset after 233 epochs is = 0.1870963552225391\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.1870963552225391\n",
      "Error on this batch = 0.1035714865998603\n",
      "Error on this batch = 0.10335937600252729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 234 epochs is = 0.17429785607283532\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.17429785607283532\n",
      "Error on this batch = 0.09809026155885338\n",
      "Error on this batch = 0.09450238606390665\n",
      "Cost on val dataset after 235 epochs is = 0.17967461893166084\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.17967461893166084\n",
      "Error on this batch = 0.087674179861969\n",
      "Error on this batch = 0.09929369805021868\n",
      "Cost on val dataset after 236 epochs is = 0.17779162329875192\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.17779162329875192\n",
      "Error on this batch = 0.10371088181869258\n",
      "Error on this batch = 0.10253702009543765\n",
      "Cost on val dataset after 237 epochs is = 0.18007990872230972\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.18007990872230972\n",
      "Error on this batch = 0.0915985214088185\n",
      "Error on this batch = 0.10425594746781824\n",
      "Cost on val dataset after 238 epochs is = 0.180206124419515\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.180206124419515\n",
      "Error on this batch = 0.10249378132595528\n",
      "Error on this batch = 0.11937029282418195\n",
      "Cost on val dataset after 239 epochs is = 0.18655419801233586\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.18655419801233586\n",
      "Error on this batch = 0.09747661405636253\n",
      "Error on this batch = 0.10200571707945379\n",
      "Cost on val dataset after 240 epochs is = 0.18097734010522276\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.18097734010522276\n",
      "Error on this batch = 0.09249854848916933\n",
      "Error on this batch = 0.09866592440168886\n",
      "Cost on val dataset after 241 epochs is = 0.17851169469140946\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.17851169469140946\n",
      "Error on this batch = 0.1030149590408628\n",
      "Error on this batch = 0.17479399260537076\n",
      "Cost on val dataset after 242 epochs is = 0.18309697611667483\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.18309697611667483\n",
      "Error on this batch = 0.09409082338560833\n",
      "Error on this batch = 0.1048876742490148\n",
      "Cost on val dataset after 243 epochs is = 0.18868148647664446\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.18868148647664446\n",
      "Error on this batch = 0.10180043008890946\n",
      "Error on this batch = 0.10131768367858576\n",
      "Cost on val dataset after 244 epochs is = 0.17820709390494718\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.17820709390494718\n",
      "Error on this batch = 0.10650531037245697\n",
      "Error on this batch = 0.09564512593746212\n",
      "Cost on val dataset after 245 epochs is = 0.1798583153784549\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.1798583153784549\n",
      "Error on this batch = 0.09773124667219411\n",
      "Error on this batch = 0.1268999933726215\n",
      "Cost on val dataset after 246 epochs is = 0.19640472809641496\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.19640472809641496\n",
      "Error on this batch = 0.11569633075553248\n",
      "Error on this batch = 0.10028567135444519\n",
      "Cost on val dataset after 247 epochs is = 0.17698151832897763\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.17698151832897763\n",
      "Error on this batch = 0.09806304222098236\n",
      "Error on this batch = 0.10152403088696894\n",
      "Cost on val dataset after 248 epochs is = 0.18753478391761338\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.18753478391761338\n",
      "Error on this batch = 0.09715540605143595\n",
      "Error on this batch = 0.09420789371182554\n",
      "Cost on val dataset after 249 epochs is = 0.2025183840744634\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.2025183840744634\n",
      "Error on this batch = 0.10669520841649416\n",
      "Error on this batch = 0.12423720456030832\n",
      "Cost on val dataset after 250 epochs is = 0.1881471043536681\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.1881471043536681\n",
      "Error on this batch = 0.11322184648316583\n",
      "Error on this batch = 0.11136389499514217\n",
      "Cost on val dataset after 251 epochs is = 0.1786533756992465\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.1786533756992465\n",
      "Error on this batch = 0.0948238780993029\n",
      "Error on this batch = 0.10109717199919672\n",
      "Cost on val dataset after 252 epochs is = 0.18628321537183762\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.18628321537183762\n",
      "Error on this batch = 0.10350384712019656\n",
      "Error on this batch = 0.09991320063989914\n",
      "Cost on val dataset after 253 epochs is = 0.2037738284037904\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.2037738284037904\n",
      "Error on this batch = 0.1292131513459614\n",
      "Error on this batch = 0.10205510196107806\n",
      "Cost on val dataset after 254 epochs is = 0.18201785107716834\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.18201785107716834\n",
      "Error on this batch = 0.09777553516976491\n",
      "Error on this batch = 0.0985619543013763\n",
      "Cost on val dataset after 255 epochs is = 0.18087160405968272\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.18087160405968272\n",
      "Error on this batch = 0.09602026435462012\n",
      "Error on this batch = 0.11418468562253466\n",
      "Cost on val dataset after 256 epochs is = 0.18578938512788512\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.18578938512788512\n",
      "Error on this batch = 0.10538681490124557\n",
      "Error on this batch = 0.09373807269439903\n",
      "Cost on val dataset after 257 epochs is = 0.18401228188564328\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.18401228188564328\n",
      "Error on this batch = 0.10279982457109857\n",
      "Error on this batch = 0.09392785233231035\n",
      "Cost on val dataset after 258 epochs is = 0.2050504767320963\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.2050504767320963\n",
      "Error on this batch = 0.15565107379543483\n",
      "Error on this batch = 0.10640317141173097\n",
      "Cost on val dataset after 259 epochs is = 0.18426433332844497\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.18426433332844497\n",
      "Error on this batch = 0.09869815514044468\n",
      "Error on this batch = 0.09874911732581237\n",
      "Cost on val dataset after 260 epochs is = 0.17728948200824143\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.17728948200824143\n",
      "Error on this batch = 0.10207626931802427\n",
      "Error on this batch = 0.09476486114648715\n",
      "Cost on val dataset after 261 epochs is = 0.1800074929262845\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.1800074929262845\n",
      "Error on this batch = 0.09398996626151597\n",
      "Error on this batch = 0.10834135275505194\n",
      "Cost on val dataset after 262 epochs is = 0.18412510593223\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.18412510593223\n",
      "Error on this batch = 0.0975501231007835\n",
      "Error on this batch = 0.10600789770857919\n",
      "Cost on val dataset after 263 epochs is = 0.19604823044368938\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.19604823044368938\n",
      "Error on this batch = 0.1035443537404192\n",
      "Error on this batch = 0.0978883994997154\n",
      "Cost on val dataset after 264 epochs is = 0.18694098788012936\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.18694098788012936\n",
      "Error on this batch = 0.09975221688811797\n",
      "Error on this batch = 0.10036931094814376\n",
      "Cost on val dataset after 265 epochs is = 0.17663837073380512\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.17663837073380512\n",
      "Error on this batch = 0.09085355571430659\n",
      "Error on this batch = 0.11677873452120015\n",
      "Cost on val dataset after 266 epochs is = 0.1776431747531004\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.1776431747531004\n",
      "Error on this batch = 0.09102873271897238\n",
      "Error on this batch = 0.09691365727488567\n",
      "Cost on val dataset after 267 epochs is = 0.18171645167961356\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.18171645167961356\n",
      "Error on this batch = 0.10189107938305501\n",
      "Error on this batch = 0.1063952757508211\n",
      "Cost on val dataset after 268 epochs is = 0.19824300496460004\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.19824300496460004\n",
      "Error on this batch = 0.10588876335152168\n",
      "Error on this batch = 0.10433961420293247\n",
      "Cost on val dataset after 269 epochs is = 0.18320014966779785\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.18320014966779785\n",
      "Error on this batch = 0.09784760868421412\n",
      "Error on this batch = 0.09857564650222095\n",
      "Cost on val dataset after 270 epochs is = 0.19685751089967807\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.19685751089967807\n",
      "Error on this batch = 0.1057396213582366\n",
      "Error on this batch = 0.0936859876555716\n",
      "Cost on val dataset after 271 epochs is = 0.18194752537410647\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.18194752537410647\n",
      "Error on this batch = 0.09242554474547292\n",
      "Error on this batch = 0.1049288892609242\n",
      "Cost on val dataset after 272 epochs is = 0.1796547868946359\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.1796547868946359\n",
      "Error on this batch = 0.0913478490377717\n",
      "Error on this batch = 0.11203531549341342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 273 epochs is = 0.1794032568299026\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.1794032568299026\n",
      "Error on this batch = 0.10749155355626704\n",
      "Error on this batch = 0.10251263570190541\n",
      "Cost on val dataset after 274 epochs is = 0.17443228207858222\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.17443228207858222\n",
      "Error on this batch = 0.09746134937219916\n",
      "Error on this batch = 0.0951351759673259\n",
      "Cost on val dataset after 275 epochs is = 0.18846918583324468\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.18846918583324468\n",
      "Error on this batch = 0.10441632118530335\n",
      "Error on this batch = 0.11398850836894439\n",
      "Cost on val dataset after 276 epochs is = 0.1955207179650935\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.1955207179650935\n",
      "Error on this batch = 0.10907498686185164\n",
      "Error on this batch = 0.10518829377802938\n",
      "Cost on val dataset after 277 epochs is = 0.19844719739477001\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.19844719739477001\n",
      "Error on this batch = 0.10519266706349151\n",
      "Error on this batch = 0.1198662636248942\n",
      "Cost on val dataset after 278 epochs is = 0.18739264929310934\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.18739264929310934\n",
      "Error on this batch = 0.09476801697030968\n",
      "Error on this batch = 0.10494446848241568\n",
      "Cost on val dataset after 279 epochs is = 0.17999835326284877\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.17999835326284877\n",
      "Error on this batch = 0.09531045138993388\n",
      "Error on this batch = 0.11504370504280191\n",
      "Cost on val dataset after 280 epochs is = 0.18607506922873318\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.18607506922873318\n",
      "Error on this batch = 0.10116963282901065\n",
      "Error on this batch = 0.0985641657015973\n",
      "Cost on val dataset after 281 epochs is = 0.1873522854494281\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.1873522854494281\n",
      "Error on this batch = 0.09177434500245277\n",
      "Error on this batch = 0.10432808529340357\n",
      "Cost on val dataset after 282 epochs is = 0.1833087468741768\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.1833087468741768\n",
      "Error on this batch = 0.09013305247824611\n",
      "Error on this batch = 0.1468809132526506\n",
      "Cost on val dataset after 283 epochs is = 0.1795411597006791\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.1795411597006791\n",
      "Error on this batch = 0.09240871529590504\n",
      "Error on this batch = 0.10476759876319028\n",
      "Cost on val dataset after 284 epochs is = 0.1840085071357173\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.1840085071357173\n",
      "Error on this batch = 0.0907905289752202\n",
      "Error on this batch = 0.10652192010949499\n",
      "Cost on val dataset after 285 epochs is = 0.19420057994182122\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.19420057994182122\n",
      "Error on this batch = 0.11055587411946553\n",
      "Error on this batch = 0.1182769505445696\n",
      "Cost on val dataset after 286 epochs is = 0.1915760292564086\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.1915760292564086\n",
      "Error on this batch = 0.1015907235972108\n",
      "Error on this batch = 0.10222379210850342\n",
      "Cost on val dataset after 287 epochs is = 0.17996525632008795\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.17996525632008795\n",
      "Error on this batch = 0.09236320691556026\n",
      "Error on this batch = 0.09969071916311403\n",
      "Cost on val dataset after 288 epochs is = 0.19255956156275045\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.19255956156275045\n",
      "Error on this batch = 0.0946290845541811\n",
      "Error on this batch = 0.11441389767519632\n",
      "Cost on val dataset after 289 epochs is = 0.17986037018823353\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.17986037018823353\n",
      "Error on this batch = 0.08742184601144842\n",
      "Error on this batch = 0.10067659651450651\n",
      "Cost on val dataset after 290 epochs is = 0.18789855511696663\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.18789855511696663\n",
      "Error on this batch = 0.08837138542415642\n",
      "Error on this batch = 0.12013223062054486\n",
      "Cost on val dataset after 291 epochs is = 0.17918263583467642\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.17918263583467642\n",
      "Error on this batch = 0.09680004568000605\n",
      "Error on this batch = 0.10211069559473575\n",
      "Cost on val dataset after 292 epochs is = 0.18029562327103818\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.18029562327103818\n",
      "Error on this batch = 0.08931817600504932\n",
      "Error on this batch = 0.10898985428163212\n",
      "Cost on val dataset after 293 epochs is = 0.18458888278835978\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.18458888278835978\n",
      "Error on this batch = 0.09589968291798746\n",
      "Error on this batch = 0.10171969271312166\n",
      "Cost on val dataset after 294 epochs is = 0.17657045559541684\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.17657045559541684\n",
      "Error on this batch = 0.09430991878066732\n",
      "Error on this batch = 0.10668643698016843\n",
      "Cost on val dataset after 295 epochs is = 0.18968106460374223\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.18968106460374223\n",
      "Error on this batch = 0.093370653754695\n",
      "Error on this batch = 0.10288102810406027\n",
      "Cost on val dataset after 296 epochs is = 0.1824750856443414\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.1824750856443414\n",
      "Error on this batch = 0.08509130439734952\n",
      "Error on this batch = 0.1041568906354662\n",
      "Cost on val dataset after 297 epochs is = 0.19689900870331176\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.19689900870331176\n",
      "Error on this batch = 0.11305500431331708\n",
      "Error on this batch = 0.10829571709999034\n",
      "Cost on val dataset after 298 epochs is = 0.18143225975692115\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.18143225975692115\n",
      "Error on this batch = 0.09036023330557275\n",
      "Error on this batch = 0.10332168428570061\n",
      "Cost on val dataset after 299 epochs is = 0.18358540733179826\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.18358540733179826\n",
      "Error on this batch = 0.09516135501970578\n",
      "Error on this batch = 0.12251978635111582\n",
      "Cost on val dataset after 300 epochs is = 0.18720057881608873\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.18720057881608873\n",
      "Error on this batch = 0.08890698186273435\n",
      "Error on this batch = 0.12159990322265214\n",
      "Cost on val dataset after 301 epochs is = 0.18873503323077084\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.18873503323077084\n",
      "Error on this batch = 0.08560666762449731\n",
      "Error on this batch = 0.10410143311703575\n",
      "Cost on val dataset after 302 epochs is = 0.18190670494412856\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.18190670494412856\n",
      "Error on this batch = 0.09514849137102506\n",
      "Error on this batch = 0.1295361001830946\n",
      "Cost on val dataset after 303 epochs is = 0.18079769925052794\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.18079769925052794\n",
      "Error on this batch = 0.09531038777162638\n",
      "Error on this batch = 0.13103745352276008\n",
      "Cost on val dataset after 304 epochs is = 0.1852415604360591\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.1852415604360591\n",
      "Error on this batch = 0.09629964471530343\n",
      "Error on this batch = 0.10979518416686534\n",
      "Cost on val dataset after 305 epochs is = 0.177478100671987\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.177478100671987\n",
      "Error on this batch = 0.08427222643544337\n",
      "Error on this batch = 0.10331557804857477\n",
      "Cost on val dataset after 306 epochs is = 0.20571678005091668\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.20571678005091668\n",
      "Error on this batch = 0.11142020387808507\n",
      "Error on this batch = 0.11096207334791078\n",
      "Cost on val dataset after 307 epochs is = 0.18310297559739552\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.18310297559739552\n",
      "Error on this batch = 0.09397902874041454\n",
      "Error on this batch = 0.12197631978345257\n",
      "Cost on val dataset after 308 epochs is = 0.1804337260466381\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.1804337260466381\n",
      "Error on this batch = 0.09449971996097709\n",
      "Error on this batch = 0.11009230967534027\n",
      "Cost on val dataset after 309 epochs is = 0.19046142856677364\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.19046142856677364\n",
      "Error on this batch = 0.090801265362817\n",
      "Error on this batch = 0.11230066173852687\n",
      "Cost on val dataset after 310 epochs is = 0.1840098864714981\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.1840098864714981\n",
      "Error on this batch = 0.09030368133332217\n",
      "Error on this batch = 0.11227708063469588\n",
      "Cost on val dataset after 311 epochs is = 0.19357152052545223\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.19357152052545223\n",
      "Error on this batch = 0.10602872583374877\n",
      "Error on this batch = 0.10737598359209596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 312 epochs is = 0.17745305592385946\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.17745305592385946\n",
      "Error on this batch = 0.08428816211299502\n",
      "Error on this batch = 0.11273997619902507\n",
      "Cost on val dataset after 313 epochs is = 0.1804739172412748\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.1804739172412748\n",
      "Error on this batch = 0.08304988101485355\n",
      "Error on this batch = 0.10522286634663366\n",
      "Cost on val dataset after 314 epochs is = 0.18813899999682443\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.18813899999682443\n",
      "Error on this batch = 0.09495436408939505\n",
      "Error on this batch = 0.11879314876921768\n",
      "Cost on val dataset after 315 epochs is = 0.18522791484243786\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.18522791484243786\n",
      "Error on this batch = 0.09062374329351788\n",
      "Error on this batch = 0.11513873697792758\n",
      "Cost on val dataset after 316 epochs is = 0.181985623355961\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.181985623355961\n",
      "Error on this batch = 0.10113353004973887\n",
      "Error on this batch = 0.10666613317071537\n",
      "Cost on val dataset after 317 epochs is = 0.1833497294247392\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.1833497294247392\n",
      "Error on this batch = 0.0885873489809396\n",
      "Error on this batch = 0.1304051139940453\n",
      "Cost on val dataset after 318 epochs is = 0.18575028205564445\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.18575028205564445\n",
      "Error on this batch = 0.08683650134665528\n",
      "Error on this batch = 0.1164198054934757\n",
      "Cost on val dataset after 319 epochs is = 0.18249187526352306\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.18249187526352306\n",
      "Error on this batch = 0.09415515820069446\n",
      "Error on this batch = 0.12022018247001842\n",
      "Cost on val dataset after 320 epochs is = 0.1848229992325809\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.1848229992325809\n",
      "Error on this batch = 0.10886314203441545\n",
      "Error on this batch = 0.10499236423766639\n",
      "Cost on val dataset after 321 epochs is = 0.21146117768664113\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.21146117768664113\n",
      "Error on this batch = 0.10943871906991084\n",
      "Error on this batch = 0.11331207659945172\n",
      "Cost on val dataset after 322 epochs is = 0.18318191252889296\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.18318191252889296\n",
      "Error on this batch = 0.09408712380761003\n",
      "Error on this batch = 0.11160573178945056\n",
      "Cost on val dataset after 323 epochs is = 0.19012905029627764\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.19012905029627764\n",
      "Error on this batch = 0.09412489221133656\n",
      "Error on this batch = 0.10707678629288409\n",
      "Cost on val dataset after 324 epochs is = 0.18244916523653223\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.18244916523653223\n",
      "Error on this batch = 0.09719876282901585\n",
      "Error on this batch = 0.12301433481604462\n",
      "Cost on val dataset after 325 epochs is = 0.1841375051193123\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.1841375051193123\n",
      "Error on this batch = 0.08425644233894383\n",
      "Error on this batch = 0.14331078509375753\n",
      "Cost on val dataset after 326 epochs is = 0.18872592848638278\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.18872592848638278\n",
      "Error on this batch = 0.09141645809571472\n",
      "Error on this batch = 0.113976058123613\n",
      "Cost on val dataset after 327 epochs is = 0.18718513256666847\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.18718513256666847\n",
      "Error on this batch = 0.09576920379646708\n",
      "Error on this batch = 0.11929591224946673\n",
      "Cost on val dataset after 328 epochs is = 0.1869321383464582\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.1869321383464582\n",
      "Error on this batch = 0.09572055994614231\n",
      "Error on this batch = 0.12223331636329272\n",
      "Cost on val dataset after 329 epochs is = 0.19857626171150766\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.19857626171150766\n",
      "Error on this batch = 0.10809997128898925\n",
      "Error on this batch = 0.10375286065719337\n",
      "Cost on val dataset after 330 epochs is = 0.1876158457697307\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.1876158457697307\n",
      "Error on this batch = 0.10990809895288552\n",
      "Error on this batch = 0.12798479088531775\n",
      "Cost on val dataset after 331 epochs is = 0.17861538690069595\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.17861538690069595\n",
      "Error on this batch = 0.08847004414507864\n",
      "Error on this batch = 0.11517973553109463\n",
      "Cost on val dataset after 332 epochs is = 0.18104168223793884\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.18104168223793884\n",
      "Error on this batch = 0.08372423045631415\n",
      "Error on this batch = 0.10861512477751958\n",
      "Cost on val dataset after 333 epochs is = 0.17938799954533227\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.17938799954533227\n",
      "Error on this batch = 0.0873146812302263\n",
      "Error on this batch = 0.10803417265097931\n",
      "Cost on val dataset after 334 epochs is = 0.18743074662018622\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.18743074662018622\n",
      "Error on this batch = 0.09634985705822455\n",
      "Error on this batch = 0.14539816312112058\n",
      "Cost on val dataset after 335 epochs is = 0.1842102414053513\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.1842102414053513\n",
      "Error on this batch = 0.09318839279799963\n",
      "Error on this batch = 0.10673642444859155\n",
      "Cost on val dataset after 336 epochs is = 0.20543012033431768\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.20543012033431768\n",
      "Error on this batch = 0.14377856908800302\n",
      "Error on this batch = 0.10210310280927141\n",
      "Cost on val dataset after 337 epochs is = 0.18554669290959025\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.18554669290959025\n",
      "Error on this batch = 0.09232186955677761\n",
      "Error on this batch = 0.1352214067822908\n",
      "Cost on val dataset after 338 epochs is = 0.18269718392978412\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.18269718392978412\n",
      "Error on this batch = 0.09333294186074036\n",
      "Error on this batch = 0.11222938148767364\n",
      "Cost on val dataset after 339 epochs is = 0.18504230313827422\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.18504230313827422\n",
      "Error on this batch = 0.09693577811123197\n",
      "Error on this batch = 0.13175685377024338\n",
      "Cost on val dataset after 340 epochs is = 0.210509862824322\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.210509862824322\n",
      "Error on this batch = 0.10387940725969368\n",
      "Error on this batch = 0.12228176594937505\n",
      "Cost on val dataset after 341 epochs is = 0.19393095951209166\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.19393095951209166\n",
      "Error on this batch = 0.1036269520951029\n",
      "Error on this batch = 0.12278098837416647\n",
      "Cost on val dataset after 342 epochs is = 0.18468190947057628\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.18468190947057628\n",
      "Error on this batch = 0.08866863992240302\n",
      "Error on this batch = 0.10032774640398437\n",
      "Cost on val dataset after 343 epochs is = 0.18806835754340065\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.18806835754340065\n",
      "Error on this batch = 0.10810178402570418\n",
      "Error on this batch = 0.11606576504762041\n",
      "Cost on val dataset after 344 epochs is = 0.18309835720065742\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.18309835720065742\n",
      "Error on this batch = 0.09488806168936278\n",
      "Error on this batch = 0.0987378252689355\n",
      "Cost on val dataset after 345 epochs is = 0.198535440641378\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.198535440641378\n",
      "Error on this batch = 0.11464374449846186\n",
      "Error on this batch = 0.16110240002044462\n",
      "Cost on val dataset after 346 epochs is = 0.1885493955748992\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.1885493955748992\n",
      "Error on this batch = 0.10436590248046099\n",
      "Error on this batch = 0.11320556671670957\n",
      "Cost on val dataset after 347 epochs is = 0.1906601284744528\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.1906601284744528\n",
      "Error on this batch = 0.09742809076921198\n",
      "Error on this batch = 0.11064925801371683\n",
      "Cost on val dataset after 348 epochs is = 0.1824377226998552\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.1824377226998552\n",
      "Error on this batch = 0.08864884392649018\n",
      "Error on this batch = 0.11545712132797899\n",
      "Cost on val dataset after 349 epochs is = 0.20649209825848688\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.20649209825848688\n",
      "Error on this batch = 0.124853382826245\n",
      "Error on this batch = 0.11524023377726099\n",
      "Cost on val dataset after 350 epochs is = 0.1783231977479405\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.1783231977479405\n",
      "Error on this batch = 0.08902569887318267\n",
      "Error on this batch = 0.09579821905626736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 351 epochs is = 0.19102907526778762\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.19102907526778762\n",
      "Error on this batch = 0.10162905823296604\n",
      "Error on this batch = 0.11582360389696343\n",
      "Cost on val dataset after 352 epochs is = 0.18109399800277226\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.18109399800277226\n",
      "Error on this batch = 0.09512541846009903\n",
      "Error on this batch = 0.12689898972613353\n",
      "Cost on val dataset after 353 epochs is = 0.18891022198013185\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.18891022198013185\n",
      "Error on this batch = 0.0958284056140854\n",
      "Error on this batch = 0.11720381076938685\n",
      "Cost on val dataset after 354 epochs is = 0.19779009763539143\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.19779009763539143\n",
      "Error on this batch = 0.11025598618762623\n",
      "Error on this batch = 0.09904606257822077\n",
      "Cost on val dataset after 355 epochs is = 0.17873214136228385\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.17873214136228385\n",
      "Error on this batch = 0.08846532631515934\n",
      "Error on this batch = 0.09784887618302021\n",
      "Cost on val dataset after 356 epochs is = 0.1849352312749278\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.1849352312749278\n",
      "Error on this batch = 0.08929652392328005\n",
      "Error on this batch = 0.11491621002134722\n",
      "Cost on val dataset after 357 epochs is = 0.18085007340667097\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.18085007340667097\n",
      "Error on this batch = 0.0922076122776927\n",
      "Error on this batch = 0.11292898623178035\n",
      "Cost on val dataset after 358 epochs is = 0.19124669088057558\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.19124669088057558\n",
      "Error on this batch = 0.10177926033870593\n",
      "Error on this batch = 0.10115649006629149\n",
      "Cost on val dataset after 359 epochs is = 0.18581668652345418\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.18581668652345418\n",
      "Error on this batch = 0.0938669777509264\n",
      "Error on this batch = 0.11227398264574717\n",
      "Cost on val dataset after 360 epochs is = 0.17910212390753452\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.17910212390753452\n",
      "Error on this batch = 0.09224859592572353\n",
      "Error on this batch = 0.10606944418565897\n",
      "Cost on val dataset after 361 epochs is = 0.18331690316958932\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.18331690316958932\n",
      "Error on this batch = 0.09278742691575156\n",
      "Error on this batch = 0.10064690412035462\n",
      "Cost on val dataset after 362 epochs is = 0.1772904265930365\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.1772904265930365\n",
      "Error on this batch = 0.08789771566854801\n",
      "Error on this batch = 0.1363638740859551\n",
      "Cost on val dataset after 363 epochs is = 0.17911322088387957\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.17911322088387957\n",
      "Error on this batch = 0.08635001543452127\n",
      "Error on this batch = 0.10801612945499209\n",
      "Cost on val dataset after 364 epochs is = 0.17873293979655064\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.17873293979655064\n",
      "Error on this batch = 0.08989451142394195\n",
      "Error on this batch = 0.11252754098241784\n",
      "Cost on val dataset after 365 epochs is = 0.1917427954151467\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.1917427954151467\n",
      "Error on this batch = 0.08930375168491042\n",
      "Error on this batch = 0.10520308161714902\n",
      "Cost on val dataset after 366 epochs is = 0.20469524683220636\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.20469524683220636\n",
      "Error on this batch = 0.13605873241842398\n",
      "Error on this batch = 0.10546715243135003\n",
      "Cost on val dataset after 367 epochs is = 0.18233535996178094\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.18233535996178094\n",
      "Error on this batch = 0.09486020358459538\n",
      "Error on this batch = 0.11259575773439899\n",
      "Cost on val dataset after 368 epochs is = 0.17896238623429203\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.17896238623429203\n",
      "Error on this batch = 0.08540815098890037\n",
      "Error on this batch = 0.10063382322510364\n",
      "Cost on val dataset after 369 epochs is = 0.1856680416960754\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.1856680416960754\n",
      "Error on this batch = 0.09626500572318689\n",
      "Error on this batch = 0.11256907297840343\n",
      "Cost on val dataset after 370 epochs is = 0.1850930917774457\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.1850930917774457\n",
      "Error on this batch = 0.09399501870148891\n",
      "Error on this batch = 0.10589239602537262\n",
      "Cost on val dataset after 371 epochs is = 0.18064779379731388\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.18064779379731388\n",
      "Error on this batch = 0.08186972673201208\n",
      "Error on this batch = 0.11118643040956251\n",
      "Cost on val dataset after 372 epochs is = 0.18108542166469102\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.18108542166469102\n",
      "Error on this batch = 0.08740280109476693\n",
      "Error on this batch = 0.1195884394861535\n",
      "Cost on val dataset after 373 epochs is = 0.17952542960065285\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.17952542960065285\n",
      "Error on this batch = 0.08989216261015442\n",
      "Error on this batch = 0.10365984689584287\n",
      "Cost on val dataset after 374 epochs is = 0.1825508895740592\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.1825508895740592\n",
      "Error on this batch = 0.08930506964249185\n",
      "Error on this batch = 0.1023219581662392\n",
      "Cost on val dataset after 375 epochs is = 0.18295745593212331\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.18295745593212331\n",
      "Error on this batch = 0.0927877302512482\n",
      "Error on this batch = 0.10305437128995092\n",
      "Cost on val dataset after 376 epochs is = 0.17980548267087523\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.17980548267087523\n",
      "Error on this batch = 0.09076686737109689\n",
      "Error on this batch = 0.12059879704578975\n",
      "Cost on val dataset after 377 epochs is = 0.18397661117187508\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.18397661117187508\n",
      "Error on this batch = 0.0857587913407088\n",
      "Error on this batch = 0.10900967383449132\n",
      "Cost on val dataset after 378 epochs is = 0.18412443736037307\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.18412443736037307\n",
      "Error on this batch = 0.08794283533926202\n",
      "Error on this batch = 0.11066076140295796\n",
      "Cost on val dataset after 379 epochs is = 0.19446875395307509\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.19446875395307509\n",
      "Error on this batch = 0.10429203929759806\n",
      "Error on this batch = 0.1033945926611061\n",
      "Cost on val dataset after 380 epochs is = 0.18482415193305474\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.18482415193305474\n",
      "Error on this batch = 0.09035589288253608\n",
      "Error on this batch = 0.09899128571536242\n",
      "Cost on val dataset after 381 epochs is = 0.1772321428987628\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.1772321428987628\n",
      "Error on this batch = 0.10459683474381755\n",
      "Error on this batch = 0.10167641251298036\n",
      "Cost on val dataset after 382 epochs is = 0.18798929753138932\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.18798929753138932\n",
      "Error on this batch = 0.09086211060786809\n",
      "Error on this batch = 0.10638557809633409\n",
      "Cost on val dataset after 383 epochs is = 0.1812754581651456\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.1812754581651456\n",
      "Error on this batch = 0.08183577235234829\n",
      "Error on this batch = 0.1235609842893989\n",
      "Cost on val dataset after 384 epochs is = 0.18873737482605016\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.18873737482605016\n",
      "Error on this batch = 0.08309329141660209\n",
      "Error on this batch = 0.10736331927112268\n",
      "Cost on val dataset after 385 epochs is = 0.18289995513705176\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.18289995513705176\n",
      "Error on this batch = 0.07862092158787258\n",
      "Error on this batch = 0.10207072830447128\n",
      "Cost on val dataset after 386 epochs is = 0.19722653911378446\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.19722653911378446\n",
      "Error on this batch = 0.08969596282897428\n",
      "Error on this batch = 0.10181456326678333\n",
      "Cost on val dataset after 387 epochs is = 0.19239298540946873\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.19239298540946873\n",
      "Error on this batch = 0.08576305855979573\n",
      "Error on this batch = 0.12217153719884706\n",
      "Cost on val dataset after 388 epochs is = 0.17668799672948393\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.17668799672948393\n",
      "Error on this batch = 0.08137837484134576\n",
      "Error on this batch = 0.11271193478198102\n",
      "Cost on val dataset after 389 epochs is = 0.1867636238321101\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.1867636238321101\n",
      "Error on this batch = 0.08046638143485212\n",
      "Error on this batch = 0.09994732798402918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 390 epochs is = 0.18062297647130054\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.18062297647130054\n",
      "Error on this batch = 0.07822642873154605\n",
      "Error on this batch = 0.10667117393795493\n",
      "Cost on val dataset after 391 epochs is = 0.18067176283797287\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.18067176283797287\n",
      "Error on this batch = 0.08224742651117581\n",
      "Error on this batch = 0.0977666783807314\n",
      "Cost on val dataset after 392 epochs is = 0.18234079497319683\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.18234079497319683\n",
      "Error on this batch = 0.07406342620465947\n",
      "Error on this batch = 0.10537613755826979\n",
      "Cost on val dataset after 393 epochs is = 0.1807730977333731\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.1807730977333731\n",
      "Error on this batch = 0.07716312483841568\n",
      "Error on this batch = 0.10354323421747444\n",
      "Cost on val dataset after 394 epochs is = 0.17945029795989317\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.17945029795989317\n",
      "Error on this batch = 0.07665956301748907\n",
      "Error on this batch = 0.09540621035175739\n",
      "Cost on val dataset after 395 epochs is = 0.1836758811024297\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.1836758811024297\n",
      "Error on this batch = 0.08123348712445604\n",
      "Error on this batch = 0.12898042473161084\n",
      "Cost on val dataset after 396 epochs is = 0.18384780540675438\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.18384780540675438\n",
      "Error on this batch = 0.07859012955701249\n",
      "Error on this batch = 0.09805868438925629\n",
      "Cost on val dataset after 397 epochs is = 0.1844490223479065\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.1844490223479065\n",
      "Error on this batch = 0.08052192682906885\n",
      "Error on this batch = 0.14286056864836172\n",
      "Cost on val dataset after 398 epochs is = 0.18147550033393847\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.18147550033393847\n",
      "Error on this batch = 0.08184431700652056\n",
      "Error on this batch = 0.09264785105976107\n",
      "Cost on val dataset after 399 epochs is = 0.18955163780398213\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.18955163780398213\n",
      "Error on this batch = 0.09037596824178405\n",
      "Error on this batch = 0.11230976440161797\n",
      "Cost on val dataset after 400 epochs is = 0.18425261386651173\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.18425261386651173\n",
      "Error on this batch = 0.0793275428596325\n",
      "Error on this batch = 0.10789485719924108\n",
      "Cost on val dataset after 401 epochs is = 0.18088966926467856\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.18088966926467856\n",
      "Error on this batch = 0.07726448048634282\n",
      "Error on this batch = 0.12628513987482842\n",
      "Cost on val dataset after 402 epochs is = 0.18239143852824397\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.18239143852824397\n",
      "Error on this batch = 0.0750545496120386\n",
      "Error on this batch = 0.10469851510185976\n",
      "Cost on val dataset after 403 epochs is = 0.18545292954917575\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.18545292954917575\n",
      "Error on this batch = 0.09375371717229523\n",
      "Error on this batch = 0.13037153074487676\n",
      "Cost on val dataset after 404 epochs is = 0.18082629996673955\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.18082629996673955\n",
      "Error on this batch = 0.07771946993926776\n",
      "Error on this batch = 0.10495107113804003\n",
      "Cost on val dataset after 405 epochs is = 0.18327796120532133\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.18327796120532133\n",
      "Error on this batch = 0.08657723418158197\n",
      "Error on this batch = 0.09506571923218055\n",
      "Cost on val dataset after 406 epochs is = 0.19122910097001766\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.19122910097001766\n",
      "Error on this batch = 0.08473340295700613\n",
      "Error on this batch = 0.12019032445542367\n",
      "Cost on val dataset after 407 epochs is = 0.18450158573188288\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.18450158573188288\n",
      "Error on this batch = 0.08141602076536847\n",
      "Error on this batch = 0.11338619531907401\n",
      "Cost on val dataset after 408 epochs is = 0.19967091256928657\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.19967091256928657\n",
      "Error on this batch = 0.11902414867898518\n",
      "Error on this batch = 0.1091396879441069\n",
      "Cost on val dataset after 409 epochs is = 0.18567604566683524\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.18567604566683524\n",
      "Error on this batch = 0.07605435817387196\n",
      "Error on this batch = 0.09571221694478689\n",
      "Cost on val dataset after 410 epochs is = 0.1840135722169253\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.1840135722169253\n",
      "Error on this batch = 0.07359528258970167\n",
      "Error on this batch = 0.1068862568566158\n",
      "Cost on val dataset after 411 epochs is = 0.18458546242947801\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.18458546242947801\n",
      "Error on this batch = 0.07174256196186723\n",
      "Error on this batch = 0.09996356131558579\n",
      "Cost on val dataset after 412 epochs is = 0.18885191183979386\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.18885191183979386\n",
      "Error on this batch = 0.07454419105714151\n",
      "Error on this batch = 0.1065519124881153\n",
      "Cost on val dataset after 413 epochs is = 0.1780973049811389\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.1780973049811389\n",
      "Error on this batch = 0.08117933873405664\n",
      "Error on this batch = 0.10324418181264744\n",
      "Cost on val dataset after 414 epochs is = 0.1875559809041019\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.1875559809041019\n",
      "Error on this batch = 0.08514560890304321\n",
      "Error on this batch = 0.1049797791226052\n",
      "Cost on val dataset after 415 epochs is = 0.1794728899335728\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.1794728899335728\n",
      "Error on this batch = 0.0802313182645051\n",
      "Error on this batch = 0.09887371870299554\n",
      "Cost on val dataset after 416 epochs is = 0.18346326706157057\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.18346326706157057\n",
      "Error on this batch = 0.0706379176655145\n",
      "Error on this batch = 0.12184648573110402\n",
      "Cost on val dataset after 417 epochs is = 0.18538153414202738\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.18538153414202738\n",
      "Error on this batch = 0.07331232166237912\n",
      "Error on this batch = 0.10412148158323184\n",
      "Cost on val dataset after 418 epochs is = 0.18526066895475027\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.18526066895475027\n",
      "Error on this batch = 0.0908071717151494\n",
      "Error on this batch = 0.09552170645347255\n",
      "Cost on val dataset after 419 epochs is = 0.19323639092904404\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.19323639092904404\n",
      "Error on this batch = 0.08697579251071433\n",
      "Error on this batch = 0.10477729045724139\n",
      "Cost on val dataset after 420 epochs is = 0.17956379437644623\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.17956379437644623\n",
      "Error on this batch = 0.08045123700404769\n",
      "Error on this batch = 0.10000330875222488\n",
      "Cost on val dataset after 421 epochs is = 0.18890636132680896\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.18890636132680896\n",
      "Error on this batch = 0.08266387573386937\n",
      "Error on this batch = 0.13953563165248642\n",
      "Cost on val dataset after 422 epochs is = 0.18054801793395517\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.18054801793395517\n",
      "Error on this batch = 0.07885915276156862\n",
      "Error on this batch = 0.10891350902352123\n",
      "Cost on val dataset after 423 epochs is = 0.1854785067589337\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.1854785067589337\n",
      "Error on this batch = 0.0696566500480926\n",
      "Error on this batch = 0.1061425300485593\n",
      "Cost on val dataset after 424 epochs is = 0.18747328511600392\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.18747328511600392\n",
      "Error on this batch = 0.08457638415618032\n",
      "Error on this batch = 0.11708141325126134\n",
      "Cost on val dataset after 425 epochs is = 0.18410990123127027\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.18410990123127027\n",
      "Error on this batch = 0.07383675394370019\n",
      "Error on this batch = 0.11848870913935437\n",
      "Cost on val dataset after 426 epochs is = 0.1810087911948453\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.1810087911948453\n",
      "Error on this batch = 0.07244499365035087\n",
      "Error on this batch = 0.10267255968239038\n",
      "Cost on val dataset after 427 epochs is = 0.18651068154589817\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.18651068154589817\n",
      "Error on this batch = 0.07418399162508711\n",
      "Error on this batch = 0.0962292098303303\n",
      "Cost on val dataset after 428 epochs is = 0.1988323934377848\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.1988323934377848\n",
      "Error on this batch = 0.10552560699198235\n",
      "Error on this batch = 0.1152378601711268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 429 epochs is = 0.21807814019541405\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.21807814019541405\n",
      "Error on this batch = 0.12773954439119006\n",
      "Error on this batch = 0.09129091717468249\n",
      "Cost on val dataset after 430 epochs is = 0.1878991437613099\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.1878991437613099\n",
      "Error on this batch = 0.08594863668853148\n",
      "Error on this batch = 0.11481649322994539\n",
      "Cost on val dataset after 431 epochs is = 0.1857191001969691\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.1857191001969691\n",
      "Error on this batch = 0.0833179632745729\n",
      "Error on this batch = 0.10499757084464628\n",
      "Cost on val dataset after 432 epochs is = 0.18496264290704742\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.18496264290704742\n",
      "Error on this batch = 0.07821998716864223\n",
      "Error on this batch = 0.10643340062010452\n",
      "Cost on val dataset after 433 epochs is = 0.1838953435533727\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.1838953435533727\n",
      "Error on this batch = 0.07650351702347934\n",
      "Error on this batch = 0.0999678174529248\n",
      "Cost on val dataset after 434 epochs is = 0.18094542497794897\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.18094542497794897\n",
      "Error on this batch = 0.07455245853207323\n",
      "Error on this batch = 0.09701077509332554\n",
      "Cost on val dataset after 435 epochs is = 0.18419692373749844\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.18419692373749844\n",
      "Error on this batch = 0.07563235278200602\n",
      "Error on this batch = 0.18872784099365789\n",
      "Cost on val dataset after 436 epochs is = 0.1882641342917854\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.1882641342917854\n",
      "Error on this batch = 0.1033160590297944\n",
      "Error on this batch = 0.13141963882076055\n",
      "Cost on val dataset after 437 epochs is = 0.18189905653909286\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.18189905653909286\n",
      "Error on this batch = 0.08277704600027784\n",
      "Error on this batch = 0.10269161907446794\n",
      "Cost on val dataset after 438 epochs is = 0.183988561643243\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.183988561643243\n",
      "Error on this batch = 0.07786497042985482\n",
      "Error on this batch = 0.10664309485411348\n",
      "Cost on val dataset after 439 epochs is = 0.1889750448775892\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.1889750448775892\n",
      "Error on this batch = 0.07527684084031196\n",
      "Error on this batch = 0.11399874659682264\n",
      "Cost on val dataset after 440 epochs is = 0.18592194541931734\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.18592194541931734\n",
      "Error on this batch = 0.08286830997011337\n",
      "Error on this batch = 0.13815950762731088\n",
      "Cost on val dataset after 441 epochs is = 0.2035447763092571\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.2035447763092571\n",
      "Error on this batch = 0.1280260662708755\n",
      "Error on this batch = 0.11420236131581973\n",
      "Cost on val dataset after 442 epochs is = 0.18567307043728914\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.18567307043728914\n",
      "Error on this batch = 0.0721139520277044\n",
      "Error on this batch = 0.11244294868124426\n",
      "Cost on val dataset after 443 epochs is = 0.18884022091384403\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.18884022091384403\n",
      "Error on this batch = 0.07824703380882513\n",
      "Error on this batch = 0.12034347921247995\n",
      "Cost on val dataset after 444 epochs is = 0.18573748174813973\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.18573748174813973\n",
      "Error on this batch = 0.08677871193839844\n",
      "Error on this batch = 0.1354841427955932\n",
      "Cost on val dataset after 445 epochs is = 0.18424893444617063\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.18424893444617063\n",
      "Error on this batch = 0.08545962780889464\n",
      "Error on this batch = 0.12219538549475767\n",
      "Cost on val dataset after 446 epochs is = 0.18569884744691864\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.18569884744691864\n",
      "Error on this batch = 0.06978368842464484\n",
      "Error on this batch = 0.11161649316182981\n",
      "Cost on val dataset after 447 epochs is = 0.1855473731061703\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.1855473731061703\n",
      "Error on this batch = 0.06851316134787071\n",
      "Error on this batch = 0.09953036720863408\n",
      "Cost on val dataset after 448 epochs is = 0.1831012006113891\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.1831012006113891\n",
      "Error on this batch = 0.07310732315077806\n",
      "Error on this batch = 0.11095191484763821\n",
      "Cost on val dataset after 449 epochs is = 0.1838315496099366\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.1838315496099366\n",
      "Error on this batch = 0.0674841945130897\n",
      "Error on this batch = 0.1080246501927245\n",
      "Cost on val dataset after 450 epochs is = 0.18600445354661002\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.18600445354661002\n",
      "Error on this batch = 0.07609406407175939\n",
      "Error on this batch = 0.1340269290994494\n",
      "Cost on val dataset after 451 epochs is = 0.1806816642029258\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.1806816642029258\n",
      "Error on this batch = 0.0820411718249152\n",
      "Error on this batch = 0.12467620551113004\n",
      "Cost on val dataset after 452 epochs is = 0.18653815303252516\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.18653815303252516\n",
      "Error on this batch = 0.07583350272167395\n",
      "Error on this batch = 0.10457215260176979\n",
      "Cost on val dataset after 453 epochs is = 0.1918264299245881\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.1918264299245881\n",
      "Error on this batch = 0.08934074461582746\n",
      "Error on this batch = 0.12576585940620624\n",
      "Cost on val dataset after 454 epochs is = 0.18466740726611117\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.18466740726611117\n",
      "Error on this batch = 0.07188990167252995\n",
      "Error on this batch = 0.12846511518982434\n",
      "Cost on val dataset after 455 epochs is = 0.18163746365167682\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.18163746365167682\n",
      "Error on this batch = 0.07177994292962872\n",
      "Error on this batch = 0.10118452619282046\n",
      "Cost on val dataset after 456 epochs is = 0.1832325032842372\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.1832325032842372\n",
      "Error on this batch = 0.06882084603611631\n",
      "Error on this batch = 0.1056160084270732\n",
      "Cost on val dataset after 457 epochs is = 0.18646353798886134\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.18646353798886134\n",
      "Error on this batch = 0.07172755376062914\n",
      "Error on this batch = 0.10132596181072462\n",
      "Cost on val dataset after 458 epochs is = 0.18794559074361558\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.18794559074361558\n",
      "Error on this batch = 0.07522139618463608\n",
      "Error on this batch = 0.1287011825365062\n",
      "Cost on val dataset after 459 epochs is = 0.2001898396168063\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.2001898396168063\n",
      "Error on this batch = 0.09134800503568967\n",
      "Error on this batch = 0.11667211741908627\n",
      "Cost on val dataset after 460 epochs is = 0.18529497161686243\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.18529497161686243\n",
      "Error on this batch = 0.0737506183265082\n",
      "Error on this batch = 0.11763238598206861\n",
      "Cost on val dataset after 461 epochs is = 0.184010776640553\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.184010776640553\n",
      "Error on this batch = 0.07933386054105551\n",
      "Error on this batch = 0.09481073377607668\n",
      "Cost on val dataset after 462 epochs is = 0.18463932435169197\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.18463932435169197\n",
      "Error on this batch = 0.07545295250117903\n",
      "Error on this batch = 0.10539512379279685\n",
      "Cost on val dataset after 463 epochs is = 0.19110476964312267\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.19110476964312267\n",
      "Error on this batch = 0.09969999165830984\n",
      "Error on this batch = 0.11100327667980225\n",
      "Cost on val dataset after 464 epochs is = 0.1830809815597496\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.1830809815597496\n",
      "Error on this batch = 0.07706433317122657\n",
      "Error on this batch = 0.1510952451245039\n",
      "Cost on val dataset after 465 epochs is = 0.1818078317724453\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.1818078317724453\n",
      "Error on this batch = 0.07115669718736317\n",
      "Error on this batch = 0.13554513521565065\n",
      "Cost on val dataset after 466 epochs is = 0.1848998166150292\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.1848998166150292\n",
      "Error on this batch = 0.07223133774830957\n",
      "Error on this batch = 0.11111049244677734\n",
      "Cost on val dataset after 467 epochs is = 0.1897878028806877\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.1897878028806877\n",
      "Error on this batch = 0.08789516989436497\n",
      "Error on this batch = 0.11367017050736795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 468 epochs is = 0.18715747111741401\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.18715747111741401\n",
      "Error on this batch = 0.08038194422658816\n",
      "Error on this batch = 0.11672068828325463\n",
      "Cost on val dataset after 469 epochs is = 0.19244529590231196\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.19244529590231196\n",
      "Error on this batch = 0.07935803201597902\n",
      "Error on this batch = 0.11461609106186388\n",
      "Cost on val dataset after 470 epochs is = 0.18557663396731497\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.18557663396731497\n",
      "Error on this batch = 0.07529887900944263\n",
      "Error on this batch = 0.11949101214387783\n",
      "Cost on val dataset after 471 epochs is = 0.18734820879042796\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.18734820879042796\n",
      "Error on this batch = 0.07558552763738677\n",
      "Error on this batch = 0.10164068102228954\n",
      "Cost on val dataset after 472 epochs is = 0.19583924268536101\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.19583924268536101\n",
      "Error on this batch = 0.09147223546258564\n",
      "Error on this batch = 0.10526702558434291\n",
      "Cost on val dataset after 473 epochs is = 0.18582534856917649\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.18582534856917649\n",
      "Error on this batch = 0.07584716105620125\n",
      "Error on this batch = 0.10401110414181314\n",
      "Cost on val dataset after 474 epochs is = 0.18319373537689385\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.18319373537689385\n",
      "Error on this batch = 0.07447480676637758\n",
      "Error on this batch = 0.13168926100357958\n",
      "Cost on val dataset after 475 epochs is = 0.1857158147130894\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.1857158147130894\n",
      "Error on this batch = 0.07925379887143573\n",
      "Error on this batch = 0.12086333205339189\n",
      "Cost on val dataset after 476 epochs is = 0.19372878254067655\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.19372878254067655\n",
      "Error on this batch = 0.08047813282141876\n",
      "Error on this batch = 0.11325406812817726\n",
      "Cost on val dataset after 477 epochs is = 0.1867236636411478\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.1867236636411478\n",
      "Error on this batch = 0.07927078917318442\n",
      "Error on this batch = 0.1264340644530339\n",
      "Cost on val dataset after 478 epochs is = 0.19534990968321553\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.19534990968321553\n",
      "Error on this batch = 0.09761788935180703\n",
      "Error on this batch = 0.09968104162168569\n",
      "Cost on val dataset after 479 epochs is = 0.18787387545555562\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.18787387545555562\n",
      "Error on this batch = 0.07417717502169599\n",
      "Error on this batch = 0.09850310421443702\n",
      "Cost on val dataset after 480 epochs is = 0.19422211511964788\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.19422211511964788\n",
      "Error on this batch = 0.07414907955677656\n",
      "Error on this batch = 0.13594721213712482\n",
      "Cost on val dataset after 481 epochs is = 0.18399559913007563\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.18399559913007563\n",
      "Error on this batch = 0.0893566393613646\n",
      "Error on this batch = 0.1370083949162222\n",
      "Cost on val dataset after 482 epochs is = 0.18874095674064573\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.18874095674064573\n",
      "Error on this batch = 0.08479478249220357\n",
      "Error on this batch = 0.09862267446904391\n",
      "Cost on val dataset after 483 epochs is = 0.1828092509600108\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.1828092509600108\n",
      "Error on this batch = 0.07095961016153945\n",
      "Error on this batch = 0.13292557952066425\n",
      "Cost on val dataset after 484 epochs is = 0.18401076390151236\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.18401076390151236\n",
      "Error on this batch = 0.07095242062501861\n",
      "Error on this batch = 0.11427712011710565\n",
      "Cost on val dataset after 485 epochs is = 0.20003299247049644\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.20003299247049644\n",
      "Error on this batch = 0.08953591287589546\n",
      "Error on this batch = 0.12541913215923337\n",
      "Cost on val dataset after 486 epochs is = 0.19373941420051286\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.19373941420051286\n",
      "Error on this batch = 0.07733010512664297\n",
      "Error on this batch = 0.13888591963576477\n",
      "Cost on val dataset after 487 epochs is = 0.19178491094432415\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.19178491094432415\n",
      "Error on this batch = 0.07103017447899916\n",
      "Error on this batch = 0.10201125650251523\n",
      "Cost on val dataset after 488 epochs is = 0.18852841586257782\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.18852841586257782\n",
      "Error on this batch = 0.07772275641575692\n",
      "Error on this batch = 0.10416347500481042\n",
      "Cost on val dataset after 489 epochs is = 0.18471180808374724\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.18471180808374724\n",
      "Error on this batch = 0.0736041818103098\n",
      "Error on this batch = 0.1006158819290641\n",
      "Cost on val dataset after 490 epochs is = 0.17958047888586443\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.17958047888586443\n",
      "Error on this batch = 0.07996202146009836\n",
      "Error on this batch = 0.0983937959625476\n",
      "Cost on val dataset after 491 epochs is = 0.18955327237288952\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.18955327237288952\n",
      "Error on this batch = 0.0731199982450694\n",
      "Error on this batch = 0.1257934290450639\n",
      "Cost on val dataset after 492 epochs is = 0.18607638858393488\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.18607638858393488\n",
      "Error on this batch = 0.06833736739076689\n",
      "Error on this batch = 0.1470321935426174\n",
      "Cost on val dataset after 493 epochs is = 0.2227602124477442\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.2227602124477442\n",
      "Error on this batch = 0.13885841156538117\n",
      "Error on this batch = 0.10044809399774703\n",
      "Cost on val dataset after 494 epochs is = 0.18793881184082908\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.18793881184082908\n",
      "Error on this batch = 0.06887650749597818\n",
      "Error on this batch = 0.12301465169185369\n",
      "Cost on val dataset after 495 epochs is = 0.18742583011960015\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.18742583011960015\n",
      "Error on this batch = 0.08074318152099993\n",
      "Error on this batch = 0.12942965919596397\n",
      "Cost on val dataset after 496 epochs is = 0.1906091520273335\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.1906091520273335\n",
      "Error on this batch = 0.07982828173504318\n",
      "Error on this batch = 0.11132479570176633\n",
      "Cost on val dataset after 497 epochs is = 0.18323195653162672\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.18323195653162672\n",
      "Error on this batch = 0.07444322043331048\n",
      "Error on this batch = 0.11008120188314495\n",
      "Cost on val dataset after 498 epochs is = 0.18357550189440444\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.18357550189440444\n",
      "Error on this batch = 0.07769667147975359\n",
      "Error on this batch = 0.09570766907605442\n",
      "Cost on val dataset after 499 epochs is = 0.18800742898178732\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.18800742898178732\n",
      "Error on this batch = 0.07506874948337282\n",
      "Error on this batch = 0.10976232505325804\n",
      "Cost on val dataset after 500 epochs is = 0.18740929257756878\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.18740929257756878\n",
      "Error on this batch = 0.07841902557391374\n",
      "Error on this batch = 0.11188767125047505\n",
      "Cost on val dataset after 501 epochs is = 0.19511635315211284\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.19511635315211284\n",
      "Error on this batch = 0.08877463245496114\n",
      "Error on this batch = 0.12806942064224694\n",
      "Cost on val dataset after 502 epochs is = 0.1933549668102585\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.1933549668102585\n",
      "Error on this batch = 0.08235691514547702\n",
      "Error on this batch = 0.12246289999565443\n",
      "Cost on val dataset after 503 epochs is = 0.18905508930790796\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.18905508930790796\n",
      "Error on this batch = 0.07734051542137813\n",
      "Error on this batch = 0.10757123565559713\n",
      "Cost on val dataset after 504 epochs is = 0.195768307390941\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.195768307390941\n",
      "Error on this batch = 0.08571393324367893\n",
      "Error on this batch = 0.10963045800067239\n",
      "Cost on val dataset after 505 epochs is = 0.1875994795275428\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.1875994795275428\n",
      "Error on this batch = 0.0757878882645793\n",
      "Error on this batch = 0.13161863369764668\n",
      "Cost on val dataset after 506 epochs is = 0.18455388201366346\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.18455388201366346\n",
      "Error on this batch = 0.07878522651951982\n",
      "Error on this batch = 0.10623337700047905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 507 epochs is = 0.18844576796160353\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.18844576796160353\n",
      "Error on this batch = 0.07346388485028872\n",
      "Error on this batch = 0.11365981826940895\n",
      "Cost on val dataset after 508 epochs is = 0.19341953867948988\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.19341953867948988\n",
      "Error on this batch = 0.07796382074689119\n",
      "Error on this batch = 0.11404982339326925\n",
      "Cost on val dataset after 509 epochs is = 0.19951344863388817\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.19951344863388817\n",
      "Error on this batch = 0.08498632211280882\n",
      "Error on this batch = 0.08870500805694148\n",
      "Cost on val dataset after 510 epochs is = 0.18957565513756594\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.18957565513756594\n",
      "Error on this batch = 0.08067559448526877\n",
      "Error on this batch = 0.11244229585706723\n",
      "Cost on val dataset after 511 epochs is = 0.19609619209850068\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.19609619209850068\n",
      "Error on this batch = 0.08250451060025003\n",
      "Error on this batch = 0.12836045943381\n",
      "Cost on val dataset after 512 epochs is = 0.18139917705183514\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.18139917705183514\n",
      "Error on this batch = 0.07256361217390993\n",
      "Error on this batch = 0.09910488694084357\n",
      "Cost on val dataset after 513 epochs is = 0.18998392789509708\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.18998392789509708\n",
      "Error on this batch = 0.09199322885118504\n",
      "Error on this batch = 0.09472628815197943\n",
      "Cost on val dataset after 514 epochs is = 0.18436675872384792\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.18436675872384792\n",
      "Error on this batch = 0.07821376024526658\n",
      "Error on this batch = 0.12612075038317075\n",
      "Cost on val dataset after 515 epochs is = 0.19081197216850787\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.19081197216850787\n",
      "Error on this batch = 0.08122461711829207\n",
      "Error on this batch = 0.10398274308568609\n",
      "Cost on val dataset after 516 epochs is = 0.1877114179364911\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.1877114179364911\n",
      "Error on this batch = 0.08781504299237672\n",
      "Error on this batch = 0.1164696970001391\n",
      "Cost on val dataset after 517 epochs is = 0.19101733881775682\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.19101733881775682\n",
      "Error on this batch = 0.08384166734932348\n",
      "Error on this batch = 0.1437747600635103\n",
      "Cost on val dataset after 518 epochs is = 0.19108728837255365\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.19108728837255365\n",
      "Error on this batch = 0.08171271852978176\n",
      "Error on this batch = 0.11102819352672373\n",
      "Cost on val dataset after 519 epochs is = 0.1872411385870599\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.1872411385870599\n",
      "Error on this batch = 0.07911211223972753\n",
      "Error on this batch = 0.10001035766815004\n",
      "Cost on val dataset after 520 epochs is = 0.1922734229611957\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.1922734229611957\n",
      "Error on this batch = 0.08311028143002488\n",
      "Error on this batch = 0.1021887810799611\n",
      "Cost on val dataset after 521 epochs is = 0.18867614385030038\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.18867614385030038\n",
      "Error on this batch = 0.08155797224621136\n",
      "Error on this batch = 0.09812090199179661\n",
      "Cost on val dataset after 522 epochs is = 0.19194766929036586\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.19194766929036586\n",
      "Error on this batch = 0.08705817071665975\n",
      "Error on this batch = 0.0988930551167962\n",
      "Cost on val dataset after 523 epochs is = 0.1903947225694346\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.1903947225694346\n",
      "Error on this batch = 0.07508406236995133\n",
      "Error on this batch = 0.11104817408756411\n",
      "Cost on val dataset after 524 epochs is = 0.190826797046878\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.190826797046878\n",
      "Error on this batch = 0.09480455354106418\n",
      "Error on this batch = 0.1780770629515353\n",
      "Cost on val dataset after 525 epochs is = 0.1959532746315026\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.1959532746315026\n",
      "Error on this batch = 0.08043608268586044\n",
      "Error on this batch = 0.1017056021047253\n",
      "Cost on val dataset after 526 epochs is = 0.18429033813022852\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.18429033813022852\n",
      "Error on this batch = 0.08303243863736155\n",
      "Error on this batch = 0.11136524850292866\n",
      "Cost on val dataset after 527 epochs is = 0.19510120685517648\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.19510120685517648\n",
      "Error on this batch = 0.08002488323150012\n",
      "Error on this batch = 0.0907179122306304\n",
      "Cost on val dataset after 528 epochs is = 0.19348735607091586\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.19348735607091586\n",
      "Error on this batch = 0.0780425777281782\n",
      "Error on this batch = 0.09484437310617125\n",
      "Cost on val dataset after 529 epochs is = 0.18577839326115322\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.18577839326115322\n",
      "Error on this batch = 0.08356884196307691\n",
      "Error on this batch = 0.12408090356301114\n",
      "Cost on val dataset after 530 epochs is = 0.18608636559169833\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.18608636559169833\n",
      "Error on this batch = 0.08321447259776987\n",
      "Error on this batch = 0.10714467700137327\n",
      "Cost on val dataset after 531 epochs is = 0.18876689332854624\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.18876689332854624\n",
      "Error on this batch = 0.07637956100985897\n",
      "Error on this batch = 0.11670566716732571\n",
      "Cost on val dataset after 532 epochs is = 0.19434815489441748\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.19434815489441748\n",
      "Error on this batch = 0.08235164766296295\n",
      "Error on this batch = 0.11436626709904715\n",
      "Cost on val dataset after 533 epochs is = 0.19120545932468552\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.19120545932468552\n",
      "Error on this batch = 0.07614157731897733\n",
      "Error on this batch = 0.11175370669114262\n",
      "Cost on val dataset after 534 epochs is = 0.1916193441451634\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.1916193441451634\n",
      "Error on this batch = 0.07223484042978041\n",
      "Error on this batch = 0.17116016390216107\n",
      "Cost on val dataset after 535 epochs is = 0.20335967297623603\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.20335967297623603\n",
      "Error on this batch = 0.10459896634301458\n",
      "Error on this batch = 0.11523852500203095\n",
      "Cost on val dataset after 536 epochs is = 0.19350959424441352\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.19350959424441352\n",
      "Error on this batch = 0.07566611691328273\n",
      "Error on this batch = 0.1219169308655374\n",
      "Cost on val dataset after 537 epochs is = 0.19229751107025084\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.19229751107025084\n",
      "Error on this batch = 0.07558623980184632\n",
      "Error on this batch = 0.1119727718813663\n",
      "Cost on val dataset after 538 epochs is = 0.18676319441273231\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.18676319441273231\n",
      "Error on this batch = 0.07808921174828491\n",
      "Error on this batch = 0.11568737061126841\n",
      "Cost on val dataset after 539 epochs is = 0.19834216974545363\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.19834216974545363\n",
      "Error on this batch = 0.08455993992735021\n",
      "Error on this batch = 0.10748390004400532\n",
      "Cost on val dataset after 540 epochs is = 0.18547919182556025\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.18547919182556025\n",
      "Error on this batch = 0.07394506795484647\n",
      "Error on this batch = 0.09459758742378263\n",
      "Cost on val dataset after 541 epochs is = 0.189333900687369\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.189333900687369\n",
      "Error on this batch = 0.08004849780042501\n",
      "Error on this batch = 0.08812490122207756\n",
      "Cost on val dataset after 542 epochs is = 0.1906257000517744\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.1906257000517744\n",
      "Error on this batch = 0.07596684597201417\n",
      "Error on this batch = 0.1296976684968716\n",
      "Cost on val dataset after 543 epochs is = 0.1878544169115487\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.1878544169115487\n",
      "Error on this batch = 0.08251842586348451\n",
      "Error on this batch = 0.11780922962474391\n",
      "Cost on val dataset after 544 epochs is = 0.20365104519081795\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.20365104519081795\n",
      "Error on this batch = 0.10415360750166362\n",
      "Error on this batch = 0.09365255389282733\n",
      "Cost on val dataset after 545 epochs is = 0.18526360200876674\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.18526360200876674\n",
      "Error on this batch = 0.07594562296099469\n",
      "Error on this batch = 0.1153392104068702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 546 epochs is = 0.18760145720109836\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.18760145720109836\n",
      "Error on this batch = 0.08332368074778053\n",
      "Error on this batch = 0.13243846844889368\n",
      "Cost on val dataset after 547 epochs is = 0.19236317280144394\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.19236317280144394\n",
      "Error on this batch = 0.08600428553824506\n",
      "Error on this batch = 0.154725736090612\n",
      "Cost on val dataset after 548 epochs is = 0.19430680504111023\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.19430680504111023\n",
      "Error on this batch = 0.07940968861643072\n",
      "Error on this batch = 0.11180328510863316\n",
      "Cost on val dataset after 549 epochs is = 0.1892831142243044\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.1892831142243044\n",
      "Error on this batch = 0.08260105590834652\n",
      "Error on this batch = 0.13580293351964443\n",
      "Cost on val dataset after 550 epochs is = 0.1931692623137227\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.1931692623137227\n",
      "Error on this batch = 0.08575956745971151\n",
      "Error on this batch = 0.10272368879882723\n",
      "Cost on val dataset after 551 epochs is = 0.20698675947076975\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.20698675947076975\n",
      "Error on this batch = 0.09394710481212137\n",
      "Error on this batch = 0.10756276845040275\n",
      "Cost on val dataset after 552 epochs is = 0.19234647863310106\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.19234647863310106\n",
      "Error on this batch = 0.08585747070696327\n",
      "Error on this batch = 0.10102334626159686\n",
      "Cost on val dataset after 553 epochs is = 0.19270674540623528\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.19270674540623528\n",
      "Error on this batch = 0.08498956165729632\n",
      "Error on this batch = 0.10680899648892635\n",
      "Cost on val dataset after 554 epochs is = 0.19115630714058182\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.19115630714058182\n",
      "Error on this batch = 0.08276042166974971\n",
      "Error on this batch = 0.11196050631782063\n",
      "Cost on val dataset after 555 epochs is = 0.19312354417115402\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.19312354417115402\n",
      "Error on this batch = 0.08602117718314124\n",
      "Error on this batch = 0.11175115361161796\n",
      "Cost on val dataset after 556 epochs is = 0.1951649778150966\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.1951649778150966\n",
      "Error on this batch = 0.0954543241918511\n",
      "Error on this batch = 0.10621944129327744\n",
      "Cost on val dataset after 557 epochs is = 0.20069171852637493\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.20069171852637493\n",
      "Error on this batch = 0.09862998383183534\n",
      "Error on this batch = 0.08764142964428878\n",
      "Cost on val dataset after 558 epochs is = 0.1911443978130939\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.1911443978130939\n",
      "Error on this batch = 0.07971457687655667\n",
      "Error on this batch = 0.11310587530579333\n",
      "Cost on val dataset after 559 epochs is = 0.19302938386821494\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.19302938386821494\n",
      "Error on this batch = 0.08235600898622558\n",
      "Error on this batch = 0.1021841417003045\n",
      "Cost on val dataset after 560 epochs is = 0.18619755224573575\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.18619755224573575\n",
      "Error on this batch = 0.0747814903968693\n",
      "Error on this batch = 0.10290586695613946\n",
      "Cost on val dataset after 561 epochs is = 0.19387837600373733\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.19387837600373733\n",
      "Error on this batch = 0.07621846196905742\n",
      "Error on this batch = 0.11488132917704327\n",
      "Cost on val dataset after 562 epochs is = 0.18923614505792105\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.18923614505792105\n",
      "Error on this batch = 0.08608599077006918\n",
      "Error on this batch = 0.10409421128294107\n",
      "Cost on val dataset after 563 epochs is = 0.19017924020911833\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.19017924020911833\n",
      "Error on this batch = 0.0858601492191392\n",
      "Error on this batch = 0.12049502629470542\n",
      "Cost on val dataset after 564 epochs is = 0.19643176370505522\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.19643176370505522\n",
      "Error on this batch = 0.08178263278619965\n",
      "Error on this batch = 0.09103367781655998\n",
      "Cost on val dataset after 565 epochs is = 0.19266211622750998\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.19266211622750998\n",
      "Error on this batch = 0.0913029566643262\n",
      "Error on this batch = 0.11666404717366981\n",
      "Cost on val dataset after 566 epochs is = 0.1924646631909867\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.1924646631909867\n",
      "Error on this batch = 0.09120147413871213\n",
      "Error on this batch = 0.173249694850456\n",
      "Cost on val dataset after 567 epochs is = 0.23336846847400092\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.23336846847400092\n",
      "Error on this batch = 0.11520209442261341\n",
      "Error on this batch = 0.08866261874622038\n",
      "Cost on val dataset after 568 epochs is = 0.20102593659440343\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.20102593659440343\n",
      "Error on this batch = 0.10420797721522122\n",
      "Error on this batch = 0.09059341802148367\n",
      "Cost on val dataset after 569 epochs is = 0.1949743436121152\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.1949743436121152\n",
      "Error on this batch = 0.0929247135925354\n",
      "Error on this batch = 0.10368305930031971\n",
      "Cost on val dataset after 570 epochs is = 0.18910228639435672\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.18910228639435672\n",
      "Error on this batch = 0.07541399172558269\n",
      "Error on this batch = 0.11627410720491846\n",
      "Cost on val dataset after 571 epochs is = 0.19320099050209638\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.19320099050209638\n",
      "Error on this batch = 0.07568549718376524\n",
      "Error on this batch = 0.0887531050267758\n",
      "Cost on val dataset after 572 epochs is = 0.19313757252807237\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.19313757252807237\n",
      "Error on this batch = 0.08478760346047778\n",
      "Error on this batch = 0.14466280676910365\n",
      "Cost on val dataset after 573 epochs is = 0.19726264193887952\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.19726264193887952\n",
      "Error on this batch = 0.08903015738595055\n",
      "Error on this batch = 0.11169958667123522\n",
      "Cost on val dataset after 574 epochs is = 0.18979214995461252\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.18979214995461252\n",
      "Error on this batch = 0.07766438716652935\n",
      "Error on this batch = 0.10029506415769335\n",
      "Cost on val dataset after 575 epochs is = 0.19762809738882306\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.19762809738882306\n",
      "Error on this batch = 0.08429701054913157\n",
      "Error on this batch = 0.11701917015626068\n",
      "Cost on val dataset after 576 epochs is = 0.1920497261142635\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.1920497261142635\n",
      "Error on this batch = 0.08491559469186168\n",
      "Error on this batch = 0.10914259478264411\n",
      "Cost on val dataset after 577 epochs is = 0.19291195010797976\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.19291195010797976\n",
      "Error on this batch = 0.09118699901016535\n",
      "Error on this batch = 0.08597009670474465\n",
      "Cost on val dataset after 578 epochs is = 0.20231012502201387\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.20231012502201387\n",
      "Error on this batch = 0.08242277922728387\n",
      "Error on this batch = 0.100572056271884\n",
      "Cost on val dataset after 579 epochs is = 0.19169966894731658\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.19169966894731658\n",
      "Error on this batch = 0.08087002767512626\n",
      "Error on this batch = 0.10394964804039472\n",
      "Cost on val dataset after 580 epochs is = 0.20993142725364078\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.20993142725364078\n",
      "Error on this batch = 0.09421605342792122\n",
      "Error on this batch = 0.09609211754073407\n",
      "Cost on val dataset after 581 epochs is = 0.19242388612895003\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.19242388612895003\n",
      "Error on this batch = 0.0805874413683613\n",
      "Error on this batch = 0.08450441609552879\n",
      "Cost on val dataset after 582 epochs is = 0.19403517865535458\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.19403517865535458\n",
      "Error on this batch = 0.08153429795719891\n",
      "Error on this batch = 0.1007051388871023\n",
      "Cost on val dataset after 583 epochs is = 0.18869619084608424\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.18869619084608424\n",
      "Error on this batch = 0.07063137084371164\n",
      "Error on this batch = 0.08959556411951156\n",
      "Cost on val dataset after 584 epochs is = 0.20142637526799861\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.20142637526799861\n",
      "Error on this batch = 0.09727102320678714\n",
      "Error on this batch = 0.10452973113691365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 585 epochs is = 0.1927852739560482\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.1927852739560482\n",
      "Error on this batch = 0.08562932994680543\n",
      "Error on this batch = 0.10858216012020919\n",
      "Cost on val dataset after 586 epochs is = 0.18980390209928616\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.18980390209928616\n",
      "Error on this batch = 0.07461452873602144\n",
      "Error on this batch = 0.09970625740849627\n",
      "Cost on val dataset after 587 epochs is = 0.1947691097592097\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.1947691097592097\n",
      "Error on this batch = 0.08991001331261284\n",
      "Error on this batch = 0.09080280991130098\n",
      "Cost on val dataset after 588 epochs is = 0.21387490926157776\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.21387490926157776\n",
      "Error on this batch = 0.10436199146950419\n",
      "Error on this batch = 0.09250930237003374\n",
      "Cost on val dataset after 589 epochs is = 0.19862635308374307\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.19862635308374307\n",
      "Error on this batch = 0.0857682809337216\n",
      "Error on this batch = 0.11685270987256811\n",
      "Cost on val dataset after 590 epochs is = 0.21221505322804016\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.21221505322804016\n",
      "Error on this batch = 0.10436863089290216\n",
      "Error on this batch = 0.11929679591844027\n",
      "Cost on val dataset after 591 epochs is = 0.19627638082614923\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.19627638082614923\n",
      "Error on this batch = 0.09581029232609382\n",
      "Error on this batch = 0.08817307498395119\n",
      "Cost on val dataset after 592 epochs is = 0.19144526473209297\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.19144526473209297\n",
      "Error on this batch = 0.08166098680709538\n",
      "Error on this batch = 0.09846545290923037\n",
      "Cost on val dataset after 593 epochs is = 0.19653548514526503\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.19653548514526503\n",
      "Error on this batch = 0.08551637214725315\n",
      "Error on this batch = 0.09781530318902285\n",
      "Cost on val dataset after 594 epochs is = 0.19178819562222957\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.19178819562222957\n",
      "Error on this batch = 0.07502861973197048\n",
      "Error on this batch = 0.09249425247026061\n",
      "Cost on val dataset after 595 epochs is = 0.20400294308152658\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.20400294308152658\n",
      "Error on this batch = 0.10023720333750401\n",
      "Error on this batch = 0.09377058881445147\n",
      "Cost on val dataset after 596 epochs is = 0.2021767619469064\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.2021767619469064\n",
      "Error on this batch = 0.09249567797514165\n",
      "Error on this batch = 0.09866346003363306\n",
      "Cost on val dataset after 597 epochs is = 0.20122995268801502\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.20122995268801502\n",
      "Error on this batch = 0.10055373547447165\n",
      "Error on this batch = 0.09593226280819238\n",
      "Cost on val dataset after 598 epochs is = 0.20239040596676328\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.20239040596676328\n",
      "Error on this batch = 0.08193013763704436\n",
      "Error on this batch = 0.11189388469040676\n",
      "Cost on val dataset after 599 epochs is = 0.20968941267261593\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.20968941267261593\n",
      "Error on this batch = 0.10154062844049022\n",
      "Error on this batch = 0.08541595592904258\n",
      "Cost on val dataset after 600 epochs is = 0.19668838806497707\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.19668838806497707\n",
      "Error on this batch = 0.08152456790682716\n",
      "Error on this batch = 0.15024446504744748\n",
      "Cost on val dataset after 601 epochs is = 0.19579174705810556\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.19579174705810556\n",
      "Error on this batch = 0.08212582667033441\n",
      "Error on this batch = 0.1172551004391095\n",
      "Cost on val dataset after 602 epochs is = 0.20289273226519203\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.20289273226519203\n",
      "Error on this batch = 0.08110362647773314\n",
      "Error on this batch = 0.09168846908063111\n",
      "Cost on val dataset after 603 epochs is = 0.1979601362496347\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.1979601362496347\n",
      "Error on this batch = 0.08805839108898038\n",
      "Error on this batch = 0.133598849933755\n",
      "Cost on val dataset after 604 epochs is = 0.1970442108404819\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.1970442108404819\n",
      "Error on this batch = 0.0788177665055015\n",
      "Error on this batch = 0.09616736907431125\n",
      "Cost on val dataset after 605 epochs is = 0.21687386622556182\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.21687386622556182\n",
      "Error on this batch = 0.09091928644974212\n",
      "Error on this batch = 0.10479537514030643\n",
      "Cost on val dataset after 606 epochs is = 0.19205282780077385\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.19205282780077385\n",
      "Error on this batch = 0.07384899693467999\n",
      "Error on this batch = 0.12902321422060092\n",
      "Cost on val dataset after 607 epochs is = 0.19885529161984342\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.19885529161984342\n",
      "Error on this batch = 0.077797955524674\n",
      "Error on this batch = 0.09282618849409748\n",
      "Cost on val dataset after 608 epochs is = 0.20400347255000684\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.20400347255000684\n",
      "Error on this batch = 0.08309817067585888\n",
      "Error on this batch = 0.10781180359179343\n",
      "Cost on val dataset after 609 epochs is = 0.19048818510564886\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.19048818510564886\n",
      "Error on this batch = 0.07263390652642374\n",
      "Error on this batch = 0.09561505550248126\n",
      "Cost on val dataset after 610 epochs is = 0.19200477123726226\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.19200477123726226\n",
      "Error on this batch = 0.0755272298638504\n",
      "Error on this batch = 0.11153817023746902\n",
      "Cost on val dataset after 611 epochs is = 0.19582750136837856\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.19582750136837856\n",
      "Error on this batch = 0.07448562113353535\n",
      "Error on this batch = 0.10470450957271207\n",
      "Cost on val dataset after 612 epochs is = 0.20595726457845234\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.20595726457845234\n",
      "Error on this batch = 0.08533483164316691\n",
      "Error on this batch = 0.09928033766448836\n",
      "Cost on val dataset after 613 epochs is = 0.1985885355970172\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.1985885355970172\n",
      "Error on this batch = 0.08500708262423866\n",
      "Error on this batch = 0.09296920582493928\n",
      "Cost on val dataset after 614 epochs is = 0.212273468635497\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.212273468635497\n",
      "Error on this batch = 0.11129133132665013\n",
      "Error on this batch = 0.09251789264699793\n",
      "Cost on val dataset after 615 epochs is = 0.19979316704209252\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.19979316704209252\n",
      "Error on this batch = 0.0838733266887794\n",
      "Error on this batch = 0.09106156119600613\n",
      "Cost on val dataset after 616 epochs is = 0.2246244331587469\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.2246244331587469\n",
      "Error on this batch = 0.10120461065294728\n",
      "Error on this batch = 0.09364818240688712\n",
      "Cost on val dataset after 617 epochs is = 0.19746874519608273\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.19746874519608273\n",
      "Error on this batch = 0.08980360750529066\n",
      "Error on this batch = 0.09774399885151348\n",
      "Cost on val dataset after 618 epochs is = 0.1969880170183708\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.1969880170183708\n",
      "Error on this batch = 0.0781973793396218\n",
      "Error on this batch = 0.10361687889876926\n",
      "Cost on val dataset after 619 epochs is = 0.19128685810590423\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.19128685810590423\n",
      "Error on this batch = 0.08324065905886772\n",
      "Error on this batch = 0.0946410280319688\n",
      "Cost on val dataset after 620 epochs is = 0.204251644388671\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.204251644388671\n",
      "Error on this batch = 0.07752364238185105\n",
      "Error on this batch = 0.09507602705082785\n",
      "Cost on val dataset after 621 epochs is = 0.22036963490556538\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.22036963490556538\n",
      "Error on this batch = 0.11786649857367504\n",
      "Error on this batch = 0.09619780267371025\n",
      "Cost on val dataset after 622 epochs is = 0.19401486409944038\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.19401486409944038\n",
      "Error on this batch = 0.06891513431978111\n",
      "Error on this batch = 0.10860786546250996\n",
      "Cost on val dataset after 623 epochs is = 0.1950084809529125\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.1950084809529125\n",
      "Error on this batch = 0.07050232849805331\n",
      "Error on this batch = 0.09068279307970667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 624 epochs is = 0.18844865548028575\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.18844865548028575\n",
      "Error on this batch = 0.06897053535988774\n",
      "Error on this batch = 0.09554740289652959\n",
      "Cost on val dataset after 625 epochs is = 0.1908480190175003\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.1908480190175003\n",
      "Error on this batch = 0.06718357634576698\n",
      "Error on this batch = 0.11991811304792746\n",
      "Cost on val dataset after 626 epochs is = 0.2057493477321587\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.2057493477321587\n",
      "Error on this batch = 0.09478914851797184\n",
      "Error on this batch = 0.10334368041375687\n",
      "Cost on val dataset after 627 epochs is = 0.1953246746951714\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.1953246746951714\n",
      "Error on this batch = 0.0841185855753606\n",
      "Error on this batch = 0.13819261396735144\n",
      "Cost on val dataset after 628 epochs is = 0.19471060795074593\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.19471060795074593\n",
      "Error on this batch = 0.07365516934348552\n",
      "Error on this batch = 0.0963103750576505\n",
      "Cost on val dataset after 629 epochs is = 0.18938562197527256\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.18938562197527256\n",
      "Error on this batch = 0.06802975814217288\n",
      "Error on this batch = 0.10195652677296156\n",
      "Cost on val dataset after 630 epochs is = 0.18725565969918914\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.18725565969918914\n",
      "Error on this batch = 0.06682949466286159\n",
      "Error on this batch = 0.09913794609767727\n",
      "Cost on val dataset after 631 epochs is = 0.19297679988154975\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.19297679988154975\n",
      "Error on this batch = 0.06975570661870158\n",
      "Error on this batch = 0.10167166619484604\n",
      "Cost on val dataset after 632 epochs is = 0.19398778820240525\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.19398778820240525\n",
      "Error on this batch = 0.07754797280794172\n",
      "Error on this batch = 0.09251253103828738\n",
      "Cost on val dataset after 633 epochs is = 0.1931826444722959\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.1931826444722959\n",
      "Error on this batch = 0.08905089786547853\n",
      "Error on this batch = 0.10800918050405191\n",
      "Cost on val dataset after 634 epochs is = 0.1959946498103746\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.1959946498103746\n",
      "Error on this batch = 0.07766846526069125\n",
      "Error on this batch = 0.09596356582311423\n",
      "Cost on val dataset after 635 epochs is = 0.19324402888380326\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.19324402888380326\n",
      "Error on this batch = 0.10091699712339487\n",
      "Error on this batch = 0.10336930750219135\n",
      "Cost on val dataset after 636 epochs is = 0.19147738747104634\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.19147738747104634\n",
      "Error on this batch = 0.06631576586076628\n",
      "Error on this batch = 0.09219851478430552\n",
      "Cost on val dataset after 637 epochs is = 0.19246329693087652\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.19246329693087652\n",
      "Error on this batch = 0.07878980956240976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a4a48a88c907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_class_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-48ff9c56ec0b>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(mini_batch, X_valid, valid_class_enc, theta, lr, act_fn, lr_mode, cost_fn)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#Backward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#Theta Update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-0bb1905ca34a>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(fm, Y_b, theta, batch_size, act_fn, cost_fn)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mderiv_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'softplus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mderiv_softplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.6\n",
    "theta = theta_init(arch, 'uniform')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'relu', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'relu'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'relu'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'relu'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with ReLU are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with ReLU is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with ReLU is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with ReLU is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with ReLU is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with ReLU is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with SoftPlus activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with SoftPlus activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.28396125009747\n",
      "learning rate for this epoch =  0.6\n",
      "Error on this batch = 3.299332606831042\n",
      "Error on this batch = 0.48046714236879146\n",
      "Cost on val dataset after 2 epochs is = 0.48015313989335623\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48015313989335623\n",
      "learning rate for this epoch =  0.5045378491522288\n",
      "Error on this batch = 0.4803573418193883\n",
      "Error on this batch = 0.4800857965810846\n",
      "Cost on val dataset after 3 epochs is = 0.47935118216244477\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47935118216244477\n",
      "learning rate for this epoch =  0.4559014113909555\n",
      "Error on this batch = 0.4796120968500499\n",
      "Error on this batch = 0.47909629203916504\n",
      "Cost on val dataset after 4 epochs is = 0.47821151941857476\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.47821151941857476\n",
      "learning rate for this epoch =  0.42426406871192845\n",
      "Error on this batch = 0.478520359167879\n",
      "Error on this batch = 0.4775196763852671\n",
      "Cost on val dataset after 5 epochs is = 0.4760110628484433\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4760110628484433\n",
      "learning rate for this epoch =  0.40124418298585324\n",
      "Error on this batch = 0.4765181756126063\n",
      "Error on this batch = 0.473764198193189\n",
      "Cost on val dataset after 6 epochs is = 0.46754000524374306\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.46754000524374306\n",
      "learning rate for this epoch =  0.38336586254776345\n",
      "Error on this batch = 0.46902541706977646\n",
      "Error on this batch = 0.46164266486383837\n",
      "Cost on val dataset after 7 epochs is = 0.4534958587663454\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4534958587663454\n",
      "learning rate for this epoch =  0.3688728917707586\n",
      "Error on this batch = 0.4582424788171892\n",
      "Error on this batch = 0.4381250196906282\n",
      "Cost on val dataset after 8 epochs is = 0.4261898558138839\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4261898558138839\n",
      "learning rate for this epoch =  0.35676213450081634\n",
      "Error on this batch = 0.43358758116075297\n",
      "Error on this batch = 0.40237907259891237\n",
      "Cost on val dataset after 9 epochs is = 0.3955955031643565\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.3955955031643565\n",
      "learning rate for this epoch =  0.34641016151377546\n",
      "Error on this batch = 0.4034762487318176\n",
      "Error on this batch = 0.3672735121821971\n",
      "Cost on val dataset after 10 epochs is = 0.35311670944367407\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.35311670944367407\n",
      "learning rate for this epoch =  0.33740479511420945\n",
      "Error on this batch = 0.35454176351682587\n",
      "Error on this batch = 0.3207635252302927\n",
      "Cost on val dataset after 11 epochs is = 0.3051179587585634\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.3051179587585634\n",
      "learning rate for this epoch =  0.32946029206566746\n",
      "Error on this batch = 0.29554976338616423\n",
      "Error on this batch = 0.27636904811706114\n",
      "Cost on val dataset after 12 epochs is = 0.2650173152074029\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.2650173152074029\n",
      "learning rate for this epoch =  0.32237097954706256\n",
      "Error on this batch = 0.25024034023729663\n",
      "Error on this batch = 0.23511791752640157\n",
      "Cost on val dataset after 13 epochs is = 0.23586128398660822\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.23586128398660822\n",
      "learning rate for this epoch =  0.315984232708756\n",
      "Error on this batch = 0.219852438836435\n",
      "Error on this batch = 0.20730296115532312\n",
      "Cost on val dataset after 14 epochs is = 0.21567184131247347\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.21567184131247347\n",
      "learning rate for this epoch =  0.31018389237430233\n",
      "Error on this batch = 0.1992345184669125\n",
      "Error on this batch = 0.1830369702704054\n",
      "Cost on val dataset after 15 epochs is = 0.20077636971955284\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.20077636971955284\n",
      "learning rate for this epoch =  0.30487964889276886\n",
      "Error on this batch = 0.18338523291138287\n",
      "Error on this batch = 0.1664074608848041\n",
      "Cost on val dataset after 16 epochs is = 0.1894009213349263\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.1894009213349263\n",
      "learning rate for this epoch =  0.3\n",
      "Error on this batch = 0.17239072074710593\n",
      "Error on this batch = 0.156105952568238\n",
      "Cost on val dataset after 17 epochs is = 0.18033447551574106\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.18033447551574106\n",
      "learning rate for this epoch =  0.2954874363032714\n",
      "Error on this batch = 0.16484740804950676\n",
      "Error on this batch = 0.1485595498242252\n",
      "Cost on val dataset after 18 epochs is = 0.1728865141084296\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.1728865141084296\n",
      "learning rate for this epoch =  0.29129506302439406\n",
      "Error on this batch = 0.1587513321124054\n",
      "Error on this batch = 0.14278764467923866\n",
      "Cost on val dataset after 19 epochs is = 0.1667031579035976\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.1667031579035976\n",
      "learning rate for this epoch =  0.2873841752661448\n",
      "Error on this batch = 0.15330513420151717\n",
      "Error on this batch = 0.1381938970080863\n",
      "Cost on val dataset after 20 epochs is = 0.16155041091726133\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.16155041091726133\n",
      "learning rate for this epoch =  0.28372248270095274\n",
      "Error on this batch = 0.14848372722143371\n",
      "Error on this batch = 0.1342734202742093\n",
      "Cost on val dataset after 21 epochs is = 0.15722803506502828\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.15722803506502828\n",
      "learning rate for this epoch =  0.28028278663692\n",
      "Error on this batch = 0.14434717978995035\n",
      "Error on this batch = 0.13069147377184467\n",
      "Cost on val dataset after 22 epochs is = 0.1535403888343946\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.1535403888343946\n",
      "learning rate for this epoch =  0.27704197856646157\n",
      "Error on this batch = 0.14082668755447483\n",
      "Error on this batch = 0.12732858907935787\n",
      "Cost on val dataset after 23 epochs is = 0.15032526431958446\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.15032526431958446\n",
      "learning rate for this epoch =  0.27398027129803876\n",
      "Error on this batch = 0.13778461756950908\n",
      "Error on this batch = 0.12415720954311557\n",
      "Cost on val dataset after 24 epochs is = 0.14747048188978595\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.14747048188978595\n",
      "learning rate for this epoch =  0.27108060108295345\n",
      "Error on this batch = 0.13509405287514667\n",
      "Error on this batch = 0.12115855703461925\n",
      "Cost on val dataset after 25 epochs is = 0.14490345707217203\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.14490345707217203\n",
      "learning rate for this epoch =  0.2683281572999747\n",
      "Error on this batch = 0.1326724901232593\n",
      "Error on this batch = 0.1183211778670401\n",
      "Cost on val dataset after 26 epochs is = 0.14257499860936998\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.14257499860936998\n",
      "learning rate for this epoch =  0.2657100085614884\n",
      "Error on this batch = 0.1304718447297448\n",
      "Error on this batch = 0.11564185724436372\n",
      "Cost on val dataset after 27 epochs is = 0.14044957686272028\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.14044957686272028\n",
      "learning rate for this epoch =  0.2632148025904985\n",
      "Error on this batch = 0.12845747693286266\n",
      "Error on this batch = 0.11311699014199608\n",
      "Cost on val dataset after 28 epochs is = 0.13850079329358742\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.13850079329358742\n",
      "learning rate for this epoch =  0.26083252316699485\n",
      "Error on this batch = 0.12659706165179976\n",
      "Error on this batch = 0.1107383686874994\n",
      "Cost on val dataset after 29 epochs is = 0.13670834904812537\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.13670834904812537\n",
      "learning rate for this epoch =  0.2585542916753436\n",
      "Error on this batch = 0.12485863713531099\n",
      "Error on this batch = 0.10849386131582034\n",
      "Cost on val dataset after 30 epochs is = 0.1350554101546688\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.1350554101546688\n",
      "learning rate for this epoch =  0.2563722038377404\n",
      "Error on this batch = 0.12321278882976203\n",
      "Error on this batch = 0.10636812573901498\n",
      "Cost on val dataset after 31 epochs is = 0.13352676340016714\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.13352676340016714\n",
      "learning rate for this epoch =  0.254279194449013\n",
      "Error on this batch = 0.12163446748404855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.10434430334406755\n",
      "Cost on val dataset after 32 epochs is = 0.1321078508185103\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.1321078508185103\n",
      "learning rate for this epoch =  0.2522689245761144\n",
      "Error on this batch = 0.12010243912140457\n",
      "Error on this batch = 0.10240658915659272\n",
      "Cost on val dataset after 33 epochs is = 0.13078434640530417\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.13078434640530417\n",
      "learning rate for this epoch =  0.2503356869166904\n",
      "Error on this batch = 0.1185979305801395\n",
      "Error on this batch = 0.10054073869378925\n",
      "Cost on val dataset after 34 epochs is = 0.12954234627349512\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.12954234627349512\n",
      "learning rate for this epoch =  0.2484743259399312\n",
      "Error on this batch = 0.11710430282875446\n",
      "Error on this batch = 0.09873357957564027\n",
      "Cost on val dataset after 35 epochs is = 0.12836908324647928\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.12836908324647928\n",
      "learning rate for this epoch =  0.2466801701403118\n",
      "Error on this batch = 0.11560823868777818\n",
      "Error on this batch = 0.09697378875548505\n",
      "Cost on val dataset after 36 epochs is = 0.1272536865663435\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.1272536865663435\n",
      "learning rate for this epoch =  0.24494897427831783\n",
      "Error on this batch = 0.11410251060372348\n",
      "Error on this batch = 0.09525340076602415\n",
      "Cost on val dataset after 37 epochs is = 0.12618769861709725\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.12618769861709725\n",
      "learning rate for this epoch =  0.2432768699032619\n",
      "Error on this batch = 0.11258959787427636\n",
      "Error on this batch = 0.0935685205482417\n",
      "Cost on val dataset after 38 epochs is = 0.12516520962898317\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.12516520962898317\n",
      "learning rate for this epoch =  0.24166032278194638\n",
      "Error on this batch = 0.11108427107099918\n",
      "Error on this batch = 0.09191849972660754\n",
      "Cost on val dataset after 39 epochs is = 0.1241825225712256\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.1241825225712256\n",
      "learning rate for this epoch =  0.24009609611534996\n",
      "Error on this batch = 0.1096127522560502\n",
      "Error on this batch = 0.09030408979676921\n",
      "Cost on val dataset after 40 epochs is = 0.12323747228879682\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.12323747228879682\n",
      "learning rate for this epoch =  0.23858121863011517\n",
      "Error on this batch = 0.1082068269112596\n",
      "Error on this batch = 0.08872572450681719\n",
      "Cost on val dataset after 41 epochs is = 0.12232870226661874\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.12232870226661874\n",
      "learning rate for this epoch =  0.23711295679464287\n",
      "Error on this batch = 0.10689410635435664\n",
      "Error on this batch = 0.08718268137259218\n",
      "Cost on val dataset after 42 epochs is = 0.12145516605278639\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.12145516605278639\n",
      "learning rate for this epoch =  0.2356887905403078\n",
      "Error on this batch = 0.10568969767713485\n",
      "Error on this batch = 0.08567316562871127\n",
      "Cost on val dataset after 43 epochs is = 0.1206160014640861\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.1206160014640861\n",
      "learning rate for this epoch =  0.23430639197370967\n",
      "Error on this batch = 0.10459465099567103\n",
      "Error on this batch = 0.08419542412190686\n",
      "Cost on val dataset after 44 epochs is = 0.11981090874938179\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.11981090874938179\n",
      "learning rate for this epoch =  0.23296360665133395\n",
      "Error on this batch = 0.10360066020773992\n",
      "Error on this batch = 0.08275102077194493\n",
      "Cost on val dataset after 45 epochs is = 0.11904119942412938\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.11904119942412938\n",
      "learning rate for this epoch =  0.23165843705765382\n",
      "Error on this batch = 0.1026957661601399\n",
      "Error on this batch = 0.08134957839675779\n",
      "Cost on val dataset after 46 epochs is = 0.11831000066121722\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.11831000066121722\n",
      "learning rate for this epoch =  0.23038902798476096\n",
      "Error on this batch = 0.10186318857611397\n",
      "Error on this batch = 0.07999839693461802\n",
      "Cost on val dataset after 47 epochs is = 0.11761016430704509\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.11761016430704509\n",
      "learning rate for this epoch =  0.229153653558572\n",
      "Error on this batch = 0.10106417960305361\n",
      "Error on this batch = 0.07870424538385644\n",
      "Cost on val dataset after 48 epochs is = 0.1169200169326275\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.1169200169326275\n",
      "learning rate for this epoch =  0.22795070569547776\n",
      "Error on this batch = 0.10027008032062819\n",
      "Error on this batch = 0.07747470260709406\n",
      "Cost on val dataset after 49 epochs is = 0.11624377575904511\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.11624377575904511\n",
      "learning rate for this epoch =  0.2267786838055363\n",
      "Error on this batch = 0.09949357895359012\n",
      "Error on this batch = 0.07629769100633686\n",
      "Cost on val dataset after 50 epochs is = 0.11558893756838584\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.11558893756838584\n",
      "learning rate for this epoch =  0.2256361855851836\n",
      "Error on this batch = 0.09873866245312568\n",
      "Error on this batch = 0.07516303196210916\n",
      "Cost on val dataset after 51 epochs is = 0.11495674315918232\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.11495674315918232\n",
      "learning rate for this epoch =  0.22452189876492748\n",
      "Error on this batch = 0.09800170672101154\n",
      "Error on this batch = 0.07406381673870248\n",
      "Cost on val dataset after 52 epochs is = 0.11434692623101808\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.11434692623101808\n",
      "learning rate for this epoch =  0.22343459369638943\n",
      "Error on this batch = 0.09727820635913852\n",
      "Error on this batch = 0.07299493750836522\n",
      "Cost on val dataset after 53 epochs is = 0.11375889497817063\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.11375889497817063\n",
      "learning rate for this epoch =  0.2223731166789908\n",
      "Error on this batch = 0.09656432661151775\n",
      "Error on this batch = 0.07195233405067906\n",
      "Cost on val dataset after 54 epochs is = 0.11319192836315346\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.11319192836315346\n",
      "learning rate for this epoch =  0.22133638394006433\n",
      "Error on this batch = 0.09585713301846753\n",
      "Error on this batch = 0.07093268920148296\n",
      "Cost on val dataset after 55 epochs is = 0.11264519500438945\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.11264519500438945\n",
      "learning rate for this epoch =  0.2203233761936155\n",
      "Error on this batch = 0.09515454448730097\n",
      "Error on this batch = 0.06993348158264343\n",
      "Cost on val dataset after 56 epochs is = 0.11211773991901341\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.11211773991901341\n",
      "learning rate for this epoch =  0.21933313371270743\n",
      "Error on this batch = 0.09445521124613543\n",
      "Error on this batch = 0.06895310955221286\n",
      "Cost on val dataset after 57 epochs is = 0.11160852240924206\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.11160852240924206\n",
      "learning rate for this epoch =  0.21836475185876858\n",
      "Error on this batch = 0.09375836397824577\n",
      "Error on this batch = 0.06799076072471343\n",
      "Cost on val dataset after 58 epochs is = 0.1111165063824915\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.1111165063824915\n",
      "learning rate for this epoch =  0.21741737701825978\n",
      "Error on this batch = 0.09306365931759224\n",
      "Error on this batch = 0.06704606739848978\n",
      "Cost on val dataset after 59 epochs is = 0.11064073530525036\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.11064073530525036\n",
      "learning rate for this epoch =  0.2164902029032644\n",
      "Error on this batch = 0.09237104246309376\n",
      "Error on this batch = 0.0661188286109663\n",
      "Cost on val dataset after 60 epochs is = 0.11018036116103726\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.11018036116103726\n",
      "learning rate for this epoch =  0.21558246717785054\n",
      "Error on this batch = 0.09168064974910628\n",
      "Error on this batch = 0.06520892788740765\n",
      "Cost on val dataset after 61 epochs is = 0.10973465843137317\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.10973465843137317\n",
      "learning rate for this epoch =  0.2146934483766157\n",
      "Error on this batch = 0.09099276696496236\n",
      "Error on this batch = 0.06431639028569176\n",
      "Cost on val dataset after 62 epochs is = 0.10930305387971036\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.10930305387971036\n",
      "learning rate for this epoch =  0.21382246308577726\n",
      "Error on this batch = 0.0903078352726564\n",
      "Error on this batch = 0.06344148235073253\n",
      "Cost on val dataset after 63 epochs is = 0.10888516714969734\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.10888516714969734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate for this epoch =  0.21296886336060317\n",
      "Error on this batch = 0.08962646828125856\n",
      "Error on this batch = 0.06258478346947928\n",
      "Cost on val dataset after 64 epochs is = 0.10848083478438392\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.10848083478438392\n",
      "learning rate for this epoch =  0.21213203435596423\n",
      "Error on this batch = 0.08894943361236536\n",
      "Error on this batch = 0.06174718748375312\n",
      "Cost on val dataset after 65 epochs is = 0.10809009175983073\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.10809009175983073\n",
      "learning rate for this epoch =  0.21131139214939415\n",
      "Error on this batch = 0.08827756772508064\n",
      "Error on this batch = 0.06092981812505838\n",
      "Cost on val dataset after 66 epochs is = 0.10771309556793335\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.10771309556793335\n",
      "learning rate for this epoch =  0.21050638173832112\n",
      "Error on this batch = 0.0876116225170163\n",
      "Error on this batch = 0.060133858310809564\n",
      "Cost on val dataset after 67 epochs is = 0.10734998743594827\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.10734998743594827\n",
      "learning rate for this epoch =  0.20971647519513073\n",
      "Error on this batch = 0.08695207555593022\n",
      "Error on this batch = 0.05936030058873287\n",
      "Cost on val dataset after 68 epochs is = 0.10700070133867737\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.10700070133867737\n",
      "learning rate for this epoch =  0.2089411699654712\n",
      "Error on this batch = 0.08629896825514621\n",
      "Error on this batch = 0.05860963196636419\n",
      "Cost on val dataset after 69 epochs is = 0.10666477000793316\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.10666477000793316\n",
      "learning rate for this epoch =  0.2081799872967546\n",
      "Error on this batch = 0.08565184134574672\n",
      "Error on this batch = 0.057881495069528825\n",
      "Cost on val dataset after 70 epochs is = 0.10634122679056954\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.10634122679056954\n",
      "learning rate for this epoch =  0.2074324707851646\n",
      "Error on this batch = 0.08500976591222116\n",
      "Error on this batch = 0.05717443943541287\n",
      "Cost on val dataset after 71 epochs is = 0.10602869847857371\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.10602869847857371\n",
      "learning rate for this epoch =  0.2066981850306836\n",
      "Error on this batch = 0.084371370444062\n",
      "Error on this batch = 0.05648593360692518\n",
      "Cost on val dataset after 72 epochs is = 0.10572566492564144\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.10572566492564144\n",
      "learning rate for this epoch =  0.20597671439071177\n",
      "Error on this batch = 0.08373480363931114\n",
      "Error on this batch = 0.055812702952853746\n",
      "Cost on val dataset after 73 epochs is = 0.10543071502863097\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.10543071502863097\n",
      "learning rate for this epoch =  0.20526766182379289\n",
      "Error on this batch = 0.08309768840475477\n",
      "Error on this batch = 0.05515121926872664\n",
      "Cost on val dataset after 74 epochs is = 0.10514266316086067\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.10514266316086067\n",
      "learning rate for this epoch =  0.20457064781579723\n",
      "Error on this batch = 0.08245709525533551\n",
      "Error on this batch = 0.05449814165256397\n",
      "Cost on val dataset after 75 epochs is = 0.10486057312354746\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.10486057312354746\n",
      "learning rate for this epoch =  0.2038853093816547\n",
      "Error on this batch = 0.08180952854096084\n",
      "Error on this batch = 0.05385082679696217\n",
      "Cost on val dataset after 76 epochs is = 0.10458381724044695\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.10458381724044695\n",
      "learning rate for this epoch =  0.20321129913639427\n",
      "Error on this batch = 0.08115106406046806\n",
      "Error on this batch = 0.05320826981207308\n",
      "Cost on val dataset after 77 epochs is = 0.1043122215462824\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.1043122215462824\n",
      "learning rate for this epoch =  0.2025482844298358\n",
      "Error on this batch = 0.08047797213365279\n",
      "Error on this batch = 0.052572352696975216\n",
      "Cost on val dataset after 78 epochs is = 0.10404619865218709\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.10404619865218709\n",
      "learning rate for this epoch =  0.20189594653980908\n",
      "Error on this batch = 0.07978807775262196\n",
      "Error on this batch = 0.05194789442421922\n",
      "Cost on val dataset after 79 epochs is = 0.10378663849971952\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.10378663849971952\n",
      "learning rate for this epoch =  0.20125397991924746\n",
      "Error on this batch = 0.0790823035219342\n",
      "Error on this batch = 0.05134011090823622\n",
      "Cost on val dataset after 80 epochs is = 0.10353459944199453\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.10353459944199453\n",
      "learning rate for this epoch =  0.20062209149292662\n",
      "Error on this batch = 0.07836553334978057\n",
      "Error on this batch = 0.050752459886375105\n",
      "Cost on val dataset after 81 epochs is = 0.10329135130277478\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.10329135130277478\n",
      "learning rate for this epoch =  0.19999999999999998\n",
      "Error on this batch = 0.07764816786662553\n",
      "Error on this batch = 0.050188801925269706\n",
      "Cost on val dataset after 82 epochs is = 0.10305817872469797\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.10305817872469797\n",
      "learning rate for this epoch =  0.19938743537882408\n",
      "Error on this batch = 0.07694628686804109\n",
      "Error on this batch = 0.0496555415969108\n",
      "Cost on val dataset after 83 epochs is = 0.10283466445426198\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.10283466445426198\n",
      "learning rate for this epoch =  0.1987841381908741\n",
      "Error on this batch = 0.07627090845457364\n",
      "Error on this batch = 0.04915774087245278\n",
      "Cost on val dataset after 84 epochs is = 0.10261799226273445\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.10261799226273445\n",
      "learning rate for this epoch =  0.19818985908082842\n",
      "Error on this batch = 0.07561621424439731\n",
      "Error on this batch = 0.048694864215163815\n",
      "Cost on val dataset after 85 epochs is = 0.10240527950958835\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.10240527950958835\n",
      "learning rate for this epoch =  0.1976043582701508\n",
      "Error on this batch = 0.07496643086390992\n",
      "Error on this batch = 0.04826280340428543\n",
      "Cost on val dataset after 86 epochs is = 0.10219533578902115\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.10219533578902115\n",
      "learning rate for this epoch =  0.19702740508172414\n",
      "Error on this batch = 0.0743078604622047\n",
      "Error on this batch = 0.047857599597175976\n",
      "Cost on val dataset after 87 epochs is = 0.10198839485446526\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.10198839485446526\n",
      "learning rate for this epoch =  0.19645877749329657\n",
      "Error on this batch = 0.0736325818086403\n",
      "Error on this batch = 0.04747643204803882\n",
      "Cost on val dataset after 88 epochs is = 0.10178530105574536\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.10178530105574536\n",
      "learning rate for this epoch =  0.19589826171768313\n",
      "Error on this batch = 0.07293738277246115\n",
      "Error on this batch = 0.04711714855856462\n",
      "Cost on val dataset after 89 epochs is = 0.10158696006710369\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.10158696006710369\n",
      "learning rate for this epoch =  0.1953456518078377\n",
      "Error on this batch = 0.0722219012163967\n",
      "Error on this batch = 0.04677799445944439\n",
      "Cost on val dataset after 90 epochs is = 0.10139413484840448\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.10139413484840448\n",
      "learning rate for this epoch =  0.19480074928505933\n",
      "Error on this batch = 0.07148734670953422\n",
      "Error on this batch = 0.04645759896639273\n",
      "Cost on val dataset after 91 epochs is = 0.10120743732342474\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.10120743732342474\n",
      "learning rate for this epoch =  0.19426336278873857\n",
      "Error on this batch = 0.07073589329782193\n",
      "Error on this batch = 0.04615497517500036\n",
      "Cost on val dataset after 92 epochs is = 0.1010273907602785\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.1010273907602785\n",
      "learning rate for this epoch =  0.1937333077461732\n",
      "Error on this batch = 0.06997045966481645\n",
      "Error on this batch = 0.045869462823942844\n",
      "Cost on val dataset after 93 epochs is = 0.10085450212899734\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.10085450212899734\n",
      "learning rate for this epoch =  0.19321040606110043\n",
      "Error on this batch = 0.06919463424140064\n",
      "Error on this batch = 0.04560060849663653\n",
      "Cost on val dataset after 94 epochs is = 0.10068931012582781\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.10068931012582781\n",
      "learning rate for this epoch =  0.1926944858196948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06841258971054139\n",
      "Error on this batch = 0.04534799120614217\n",
      "Cost on val dataset after 95 epochs is = 0.1005323838088031\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.1005323838088031\n",
      "learning rate for this epoch =  0.1921853810128792\n",
      "Error on this batch = 0.06762888709166365\n",
      "Error on this batch = 0.04511102424869412\n",
      "Cost on val dataset after 96 epochs is = 0.1003842609329091\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.1003842609329091\n",
      "learning rate for this epoch =  0.19168293127388172\n",
      "Error on this batch = 0.06684812082045732\n",
      "Error on this batch = 0.04488879404139251\n",
      "Cost on val dataset after 97 epochs is = 0.10024533817393907\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.10024533817393907\n",
      "learning rate for this epoch =  0.19118698163005315\n",
      "Error on this batch = 0.06607443319167944\n",
      "Error on this batch = 0.04468000316295303\n",
      "Cost on val dataset after 98 epochs is = 0.10011574687832497\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.10011574687832497\n",
      "learning rate for this epoch =  0.19069738226803112\n",
      "Error on this batch = 0.065311019855547\n",
      "Error on this batch = 0.04448304549102534\n",
      "Cost on val dataset after 99 epochs is = 0.09999525269747747\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.09999525269747747\n",
      "learning rate for this epoch =  0.19021398831140582\n",
      "Error on this batch = 0.06455979802336934\n",
      "Error on this batch = 0.04429617652830682\n",
      "Cost on val dataset after 100 epochs is = 0.0998832014482479\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.0998832014482479\n",
      "learning rate for this epoch =  0.18973665961010275\n",
      "Error on this batch = 0.06382135534358013\n",
      "Error on this batch = 0.044117703949690446\n",
      "Cost on val dataset after 101 epochs is = 0.09977851170663007\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.09977851170663007\n",
      "learning rate for this epoch =  0.1892652605407543\n",
      "Error on this batch = 0.0630951579986507\n",
      "Error on this batch = 0.043946137398085394\n",
      "Cost on val dataset after 102 epochs is = 0.09967970793760668\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.09967970793760668\n",
      "learning rate for this epoch =  0.18879965981738495\n",
      "Error on this batch = 0.06237987344003955\n",
      "Error on this batch = 0.043780277131841495\n",
      "Cost on val dataset after 103 epochs is = 0.09958500003615506\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.09958500003615506\n",
      "learning rate for this epoch =  0.1883397303117814\n",
      "Error on this batch = 0.06167364775869968\n",
      "Error on this batch = 0.04361925189333312\n",
      "Cost on val dataset after 104 epochs is = 0.09949242688210715\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.09949242688210715\n",
      "learning rate for this epoch =  0.18788534888296407\n",
      "Error on this batch = 0.06097426757240628\n",
      "Error on this batch = 0.04346252460963847\n",
      "Cost on val dataset after 105 epochs is = 0.0994000719002277\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.0994000719002277\n",
      "learning rate for this epoch =  0.18743639621521535\n",
      "Error on this batch = 0.06027924990641669\n",
      "Error on this batch = 0.043309876731466995\n",
      "Cost on val dataset after 106 epochs is = 0.09930632806275012\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.09930632806275012\n",
      "learning rate for this epoch =  0.18699275666415935\n",
      "Error on this batch = 0.05958594985512566\n",
      "Error on this batch = 0.043161370285235715\n",
      "Cost on val dataset after 107 epochs is = 0.09921015991893267\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.09921015991893267\n",
      "learning rate for this epoch =  0.18655431811042028\n",
      "Error on this batch = 0.0588917193188753\n",
      "Error on this batch = 0.04301728183735978\n",
      "Cost on val dataset after 108 epochs is = 0.09911130184376199\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.09911130184376199\n",
      "learning rate for this epoch =  0.18612097182041992\n",
      "Error on this batch = 0.05819405184301662\n",
      "Error on this batch = 0.042878005881372305\n",
      "Cost on val dataset after 109 epochs is = 0.09901034646467785\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.09901034646467785\n",
      "learning rate for this epoch =  0.1856926123139029\n",
      "Error on this batch = 0.05749063037513514\n",
      "Error on this batch = 0.04274392811699952\n",
      "Cost on val dataset after 110 epochs is = 0.09890870249649825\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.09890870249649825\n",
      "learning rate for this epoch =  0.18526913723780689\n",
      "Error on this batch = 0.056779305951212805\n",
      "Error on this batch = 0.04261527286374195\n",
      "Cost on val dataset after 111 epochs is = 0.09880842205833253\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.09880842205833253\n",
      "learning rate for this epoch =  0.1848504472461183\n",
      "Error on this batch = 0.05605817115047101\n",
      "Error on this batch = 0.04249194815130825\n",
      "Cost on val dataset after 112 epochs is = 0.09871190017126423\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.09871190017126423\n",
      "learning rate for this epoch =  0.1844364458853793\n",
      "Error on this batch = 0.05532588696227432\n",
      "Error on this batch = 0.042373446065359636\n",
      "Cost on val dataset after 113 epochs is = 0.09862144217391687\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.09862144217391687\n",
      "learning rate for this epoch =  0.18402703948553187\n",
      "Error on this batch = 0.05458220811657183\n",
      "Error on this batch = 0.04225887552890477\n",
      "Cost on val dataset after 114 epochs is = 0.09853873425577346\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.09853873425577346\n",
      "learning rate for this epoch =  0.18362213705580538\n",
      "Error on this batch = 0.053828383314096034\n",
      "Error on this batch = 0.04214716524431534\n",
      "Cost on val dataset after 115 epochs is = 0.09846437620042993\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.09846437620042993\n",
      "learning rate for this epoch =  0.18322165018537329\n",
      "Error on this batch = 0.05306716032167025\n",
      "Error on this batch = 0.042037360081695035\n",
      "Cost on val dataset after 116 epochs is = 0.09839773856388365\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.09839773856388365\n",
      "learning rate for this epoch =  0.18282549294852\n",
      "Error on this batch = 0.05230265698860176\n",
      "Error on this batch = 0.04192884290541126\n",
      "Cost on val dataset after 117 epochs is = 0.098337312146008\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.098337312146008\n",
      "learning rate for this epoch =  0.1824335818140776\n",
      "Error on this batch = 0.05154065027496516\n",
      "Error on this batch = 0.04182138227837513\n",
      "Cost on val dataset after 118 epochs is = 0.09828144772084496\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.09828144772084496\n",
      "learning rate for this epoch =  0.18204583555890436\n",
      "Error on this batch = 0.050789091372571614\n",
      "Error on this batch = 0.04171505127898136\n",
      "Cost on val dataset after 119 epochs is = 0.09822912734557908\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.09822912734557908\n",
      "learning rate for this epoch =  0.1816621751851926\n",
      "Error on this batch = 0.05005779381948292\n",
      "Error on this batch = 0.041610095263212354\n",
      "Cost on val dataset after 120 epochs is = 0.09818031160966187\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.09818031160966187\n",
      "learning rate for this epoch =  0.18128252384140608\n",
      "Error on this batch = 0.04935670103035895\n",
      "Error on this batch = 0.04150678300300298\n",
      "Cost on val dataset after 121 epochs is = 0.09813562342423598\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.09813562342423598\n",
      "learning rate for this epoch =  0.18090680674665816\n",
      "Error on this batch = 0.04869334789738117\n",
      "Error on this batch = 0.04140527670631671\n",
      "Cost on val dataset after 122 epochs is = 0.09809557966889143\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.09809557966889143\n",
      "learning rate for this epoch =  0.18053495111835455\n",
      "Error on this batch = 0.04807066200679781\n",
      "Error on this batch = 0.04130557103997525\n",
      "Cost on val dataset after 123 epochs is = 0.09805979346945294\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.09805979346945294\n",
      "learning rate for this epoch =  0.1801668861029339\n",
      "Error on this batch = 0.047485880159343255\n",
      "Error on this batch = 0.04120750747630554\n",
      "Cost on val dataset after 124 epochs is = 0.0980263376136913\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.0980263376136913\n",
      "learning rate for this epoch =  0.17980254270954982\n",
      "Error on this batch = 0.04693068275408907\n",
      "Error on this batch = 0.04111080717470411\n",
      "Cost on val dataset after 125 epochs is = 0.09799117509874136\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.09799117509874136\n",
      "learning rate for this epoch =  0.17944185374654648\n",
      "Error on this batch = 0.04639216775366603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04101506116395503\n",
      "Cost on val dataset after 126 epochs is = 0.09794768679686619\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.09794768679686619\n",
      "learning rate for this epoch =  0.17908475376058935\n",
      "Error on this batch = 0.04585434481343254\n",
      "Error on this batch = 0.04091967329995286\n",
      "Cost on val dataset after 127 epochs is = 0.09788700994686296\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.09788700994686296\n",
      "learning rate for this epoch =  0.17873117897831953\n",
      "Error on this batch = 0.045300577141981276\n",
      "Error on this batch = 0.0408238173706268\n",
      "Cost on val dataset after 128 epochs is = 0.09780061280686961\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.09780061280686961\n",
      "learning rate for this epoch =  0.17838106725040817\n",
      "Error on this batch = 0.04471807822468664\n",
      "Error on this batch = 0.040726499020713076\n",
      "Cost on val dataset after 129 epochs is = 0.0976853539037743\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.0976853539037743\n",
      "learning rate for this epoch =  0.1780343579978945\n",
      "Error on this batch = 0.04410394987325465\n",
      "Error on this batch = 0.040626782343408115\n",
      "Cost on val dataset after 130 epochs is = 0.09754716765324134\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.09754716765324134\n",
      "learning rate for this epoch =  0.17769099216069748\n",
      "Error on this batch = 0.043467865274114635\n",
      "Error on this batch = 0.04052414441114218\n",
      "Cost on val dataset after 131 epochs is = 0.09739829944042148\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.09739829944042148\n",
      "learning rate for this epoch =  0.17735091214819665\n",
      "Error on this batch = 0.04282677274809183\n",
      "Error on this batch = 0.04041880297300818\n",
      "Cost on val dataset after 132 epochs is = 0.09725014856770743\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.09725014856770743\n",
      "learning rate for this epoch =  0.17701406179178425\n",
      "Error on this batch = 0.04219613823257543\n",
      "Error on this batch = 0.040311830238440205\n",
      "Cost on val dataset after 133 epochs is = 0.0971085718127101\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.0971085718127101\n",
      "learning rate for this epoch =  0.1766803862992956\n",
      "Error on this batch = 0.041585627649499975\n",
      "Error on this batch = 0.04020492364461757\n",
      "Cost on val dataset after 134 epochs is = 0.09697331221211437\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.09697331221211437\n",
      "learning rate for this epoch =  0.17634983221122996\n",
      "Error on this batch = 0.040999469846572455\n",
      "Error on this batch = 0.040099644941977285\n",
      "Cost on val dataset after 135 epochs is = 0.09683963288963686\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.09683963288963686\n",
      "learning rate for this epoch =  0.17602234735867867\n",
      "Error on this batch = 0.040438992617235325\n",
      "Error on this batch = 0.03999596473659915\n",
      "Cost on val dataset after 136 epochs is = 0.09670240266646729\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.09670240266646729\n",
      "learning rate for this epoch =  0.17569788082288185\n",
      "Error on this batch = 0.039907229677106415\n",
      "Error on this batch = 0.039891297563758324\n",
      "Cost on val dataset after 137 epochs is = 0.09656038843319915\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.09656038843319915\n",
      "learning rate for this epoch =  0.17537638289633925\n",
      "Error on this batch = 0.039409790415340415\n",
      "Error on this batch = 0.039782307231794996\n",
      "Cost on val dataset after 138 epochs is = 0.09641605403145323\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.09641605403145323\n",
      "learning rate for this epoch =  0.1750578050454048\n",
      "Error on this batch = 0.03894907111858342\n",
      "Error on this batch = 0.03966790543271878\n",
      "Cost on val dataset after 139 epochs is = 0.09627272536553431\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.09627272536553431\n",
      "learning rate for this epoch =  0.17474209987429748\n",
      "Error on this batch = 0.03852160045811596\n",
      "Error on this batch = 0.039549752871208724\n",
      "Cost on val dataset after 140 epochs is = 0.09613266595299425\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.09613266595299425\n",
      "learning rate for this epoch =  0.17442922109046577\n",
      "Error on this batch = 0.038120490043135564\n",
      "Error on this batch = 0.03943094153934292\n",
      "Cost on val dataset after 141 epochs is = 0.09599663130307215\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.09599663130307215\n",
      "learning rate for this epoch =  0.17411912347124506\n",
      "Error on this batch = 0.03773924263919568\n",
      "Error on this batch = 0.03931475620251046\n",
      "Cost on val dataset after 142 epochs is = 0.09586497994333398\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.09586497994333398\n",
      "learning rate for this epoch =  0.17381176283175084\n",
      "Error on this batch = 0.037376121971204025\n",
      "Error on this batch = 0.039203405429275966\n",
      "Cost on val dataset after 143 epochs is = 0.09573890442888693\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.09573890442888693\n",
      "learning rate for this epoch =  0.17350709599395428\n",
      "Error on this batch = 0.03703400516547614\n",
      "Error on this batch = 0.03909678960674457\n",
      "Cost on val dataset after 144 epochs is = 0.0956201656935234\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.0956201656935234\n",
      "learning rate for this epoch =  0.17320508075688773\n",
      "Error on this batch = 0.036712868492122366\n",
      "Error on this batch = 0.038991795472090265\n",
      "Cost on val dataset after 145 epochs is = 0.09551053923418683\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.09551053923418683\n",
      "learning rate for this epoch =  0.17290567586793207\n",
      "Error on this batch = 0.03640308064217708\n",
      "Error on this batch = 0.03888325750800472\n",
      "Cost on val dataset after 146 epochs is = 0.0954110603861697\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.0954110603861697\n",
      "learning rate for this epoch =  0.1726088409951392\n",
      "Error on this batch = 0.036087929671464056\n",
      "Error on this batch = 0.038768485918717135\n",
      "Cost on val dataset after 147 epochs is = 0.09532127867804202\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.09532127867804202\n",
      "learning rate for this epoch =  0.1723145367005454\n",
      "Error on this batch = 0.035757468086025715\n",
      "Error on this batch = 0.038649608142655854\n",
      "Cost on val dataset after 148 epochs is = 0.09523972085298832\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.09523972085298832\n",
      "learning rate for this epoch =  0.172022724414434\n",
      "Error on this batch = 0.03541471059358167\n",
      "Error on this batch = 0.03852997540057854\n",
      "Cost on val dataset after 149 epochs is = 0.09516509239488939\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.09516509239488939\n",
      "learning rate for this epoch =  0.171733366410507\n",
      "Error on this batch = 0.0350672171214604\n",
      "Error on this batch = 0.03841193879516444\n",
      "Cost on val dataset after 150 epochs is = 0.09509667794403434\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.09509667794403434\n",
      "learning rate for this epoch =  0.17144642578192795\n",
      "Error on this batch = 0.03472118267158321\n",
      "Error on this batch = 0.03829702429643216\n",
      "Cost on val dataset after 151 epochs is = 0.09503410091549774\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.09503410091549774\n",
      "learning rate for this epoch =  0.1711618664182\n",
      "Error on this batch = 0.034380772055304244\n",
      "Error on this batch = 0.038186198806662554\n",
      "Cost on val dataset after 152 epochs is = 0.09497705442833075\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.09497705442833075\n",
      "learning rate for this epoch =  0.1708796529828442\n",
      "Error on this batch = 0.03404858997125983\n",
      "Error on this batch = 0.038079996794162824\n",
      "Cost on val dataset after 153 epochs is = 0.09492515122654985\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.09492515122654985\n",
      "learning rate for this epoch =  0.17059975089184612\n",
      "Error on this batch = 0.033726116894987744\n",
      "Error on this batch = 0.03797863919975338\n",
      "Cost on val dataset after 154 epochs is = 0.09487786615189707\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.09487786615189707\n",
      "learning rate for this epoch =  0.17032212629283866\n",
      "Error on this batch = 0.0334140325903745\n",
      "Error on this batch = 0.037882144827609314\n",
      "Cost on val dataset after 155 epochs is = 0.09483452975164026\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.09483452975164026\n",
      "learning rate for this epoch =  0.17004674604499187\n",
      "Error on this batch = 0.03311244052764775\n",
      "Error on this batch = 0.03779041173264246\n",
      "Cost on val dataset after 156 epochs is = 0.09479435122162747\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.09479435122162747\n",
      "learning rate for this epoch =  0.16977357769958104\n",
      "Error on this batch = 0.032821017199862454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.037703260147842636\n",
      "Cost on val dataset after 157 epochs is = 0.0947564660527291\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.0947564660527291\n",
      "learning rate for this epoch =  0.16950258948120644\n",
      "Error on this batch = 0.032539116403830025\n",
      "Error on this batch = 0.03762044160545364\n",
      "Cost on val dataset after 158 epochs is = 0.09472000826697088\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.09472000826697088\n",
      "learning rate for this epoch =  0.16923375026963824\n",
      "Error on this batch = 0.032265861288964255\n",
      "Error on this batch = 0.03754162754133115\n",
      "Cost on val dataset after 159 epochs is = 0.09468420024478322\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.09468420024478322\n",
      "learning rate for this epoch =  0.16896702958226256\n",
      "Error on this batch = 0.03200025946624348\n",
      "Error on this batch = 0.03746639511759581\n",
      "Cost on val dataset after 160 epochs is = 0.0946484421915136\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.0946484421915136\n",
      "learning rate for this epoch =  0.16870239755710473\n",
      "Error on this batch = 0.03174136910793141\n",
      "Error on this batch = 0.03739422565271571\n",
      "Cost on val dataset after 161 epochs is = 0.0946123821900179\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.0946123821900179\n",
      "learning rate for this epoch =  0.16843982493640752\n",
      "Error on this batch = 0.03148851016922353\n",
      "Error on this batch = 0.03732451873572265\n",
      "Cost on val dataset after 162 epochs is = 0.09457596347304438\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.09457596347304438\n",
      "learning rate for this epoch =  0.1681792830507429\n",
      "Error on this batch = 0.031241462018503485\n",
      "Error on this batch = 0.03725661059639562\n",
      "Cost on val dataset after 163 epochs is = 0.09453945782097134\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.09453945782097134\n",
      "learning rate for this epoch =  0.1679207438036363\n",
      "Error on this batch = 0.031000567101005322\n",
      "Error on this batch = 0.037189785682217966\n",
      "Cost on val dataset after 164 epochs is = 0.09450347357454794\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.09450347357454794\n",
      "learning rate for this epoch =  0.16766417965668484\n",
      "Error on this batch = 0.030766699184014104\n",
      "Error on this batch = 0.03712328605406892\n",
      "Cost on val dataset after 165 epochs is = 0.09446887036823189\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.09446887036823189\n",
      "learning rate for this epoch =  0.1674095636151496\n",
      "Error on this batch = 0.03054107039927263\n",
      "Error on this batch = 0.0370563370174442\n",
      "Cost on val dataset after 166 epochs is = 0.09443643412402909\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.09443643412402909\n",
      "learning rate for this epoch =  0.16715686921400502\n",
      "Error on this batch = 0.030324700143652385\n",
      "Error on this batch = 0.036988213963987264\n",
      "Cost on val dataset after 167 epochs is = 0.09440621366599557\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.09440621366599557\n",
      "learning rate for this epoch =  0.16690607050442752\n",
      "Error on this batch = 0.030117280215856256\n",
      "Error on this batch = 0.03691836071261557\n",
      "Cost on val dataset after 168 epochs is = 0.09437713654407782\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.09437713654407782\n",
      "learning rate for this epoch =  0.16665714204070745\n",
      "Error on this batch = 0.029916702515124235\n",
      "Error on this batch = 0.036846472801266364\n",
      "Cost on val dataset after 169 epochs is = 0.09434816588231179\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.09434816588231179\n",
      "learning rate for this epoch =  0.16641005886756874\n",
      "Error on this batch = 0.029722407103131437\n",
      "Error on this batch = 0.03677238576426633\n",
      "Cost on val dataset after 170 epochs is = 0.09431944872335522\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.09431944872335522\n",
      "learning rate for this epoch =  0.1661647965078805\n",
      "Error on this batch = 0.029537166374812546\n",
      "Error on this batch = 0.036696004445681406\n",
      "Cost on val dataset after 171 epochs is = 0.09429130091109676\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.09429130091109676\n",
      "learning rate for this epoch =  0.1659213309507473\n",
      "Error on this batch = 0.02936190939371054\n",
      "Error on this batch = 0.036617565312830065\n",
      "Cost on val dataset after 172 epochs is = 0.09426333813813857\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.09426333813813857\n",
      "learning rate for this epoch =  0.16567963863996335\n",
      "Error on this batch = 0.029194518467647465\n",
      "Error on this batch = 0.036537689938697805\n",
      "Cost on val dataset after 173 epochs is = 0.09423471868255492\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.09423471868255492\n",
      "learning rate for this epoch =  0.16543969646281814\n",
      "Error on this batch = 0.02903241537716689\n",
      "Error on this batch = 0.03645714209915358\n",
      "Cost on val dataset after 174 epochs is = 0.09420459894192795\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.09420459894192795\n",
      "learning rate for this epoch =  0.1652014817392402\n",
      "Error on this batch = 0.02887372474447939\n",
      "Error on this batch = 0.03637663229203362\n",
      "Cost on val dataset after 175 epochs is = 0.09417235749621335\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.09417235749621335\n",
      "learning rate for this epoch =  0.1649649722112678\n",
      "Error on this batch = 0.028717300749812123\n",
      "Error on this batch = 0.03629672559979917\n",
      "Cost on val dataset after 176 epochs is = 0.09413763698809757\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.09413763698809757\n",
      "learning rate for this epoch =  0.16473014603283373\n",
      "Error on this batch = 0.028562546058866174\n",
      "Error on this batch = 0.0362178010953861\n",
      "Cost on val dataset after 177 epochs is = 0.09410031000216337\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.09410031000216337\n",
      "learning rate for this epoch =  0.16449698175985428\n",
      "Error on this batch = 0.028409269010281672\n",
      "Error on this batch = 0.03614003793497771\n",
      "Cost on val dataset after 178 epochs is = 0.09406042224191792\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.09406042224191792\n",
      "learning rate for this epoch =  0.164265458340611\n",
      "Error on this batch = 0.0282575729079828\n",
      "Error on this batch = 0.03606342845748329\n",
      "Cost on val dataset after 179 epochs is = 0.09401814496936907\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.09401814496936907\n",
      "learning rate for this epoch =  0.16403555510641493\n",
      "Error on this batch = 0.028107744696347442\n",
      "Error on this batch = 0.03598782489108234\n",
      "Cost on val dataset after 180 epochs is = 0.0939737566588\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.0939737566588\n",
      "learning rate for this epoch =  0.163807251762544\n",
      "Error on this batch = 0.02796013973170869\n",
      "Error on this batch = 0.0359130162567163\n",
      "Cost on val dataset after 181 epochs is = 0.09392764372333948\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.09392764372333948\n",
      "learning rate for this epoch =  0.1635805283794437\n",
      "Error on this batch = 0.027815088014712552\n",
      "Error on this batch = 0.03583881136316745\n",
      "Cost on val dataset after 182 epochs is = 0.09388028860399222\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.09388028860399222\n",
      "learning rate for this epoch =  0.1633553653841821\n",
      "Error on this batch = 0.027672849166045937\n",
      "Error on this batch = 0.0357650926034999\n",
      "Cost on val dataset after 183 epochs is = 0.09383223401725616\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.09383223401725616\n",
      "learning rate for this epoch =  0.16313174355215057\n",
      "Error on this batch = 0.02753361714013544\n",
      "Error on this batch = 0.035691822648211254\n",
      "Cost on val dataset after 184 epochs is = 0.09378404312575535\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.09378404312575535\n",
      "learning rate for this epoch =  0.16290964399900174\n",
      "Error on this batch = 0.027397550254211814\n",
      "Error on this batch = 0.03561901707940963\n",
      "Cost on val dataset after 185 epochs is = 0.09373627156206653\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.09373627156206653\n",
      "learning rate for this epoch =  0.1626890481728167\n",
      "Error on this batch = 0.027264800697643886\n",
      "Error on this batch = 0.03554670947870125\n",
      "Cost on val dataset after 186 epochs is = 0.09368944816059417\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.09368944816059417\n",
      "learning rate for this epoch =  0.1624699378464939\n",
      "Error on this batch = 0.027135530358069943\n",
      "Error on this batch = 0.03547492770880741\n",
      "Cost on val dataset after 187 epochs is = 0.09364405895300651\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.09364405895300651\n",
      "learning rate for this epoch =  0.16225229511035183\n",
      "Error on this batch = 0.027009909203181907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.035403687617094594\n",
      "Cost on val dataset after 188 epochs is = 0.09360053594192663\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.09360053594192663\n",
      "learning rate for this epoch =  0.16203610236493907\n",
      "Error on this batch = 0.026888096126812245\n",
      "Error on this batch = 0.035333002477572775\n",
      "Cost on val dataset after 189 epochs is = 0.0935592535045018\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.0935592535045018\n",
      "learning rate for this epoch =  0.16182134231404424\n",
      "Error on this batch = 0.02677020444139574\n",
      "Error on this batch = 0.035262902651171116\n",
      "Cost on val dataset after 190 epochs is = 0.09352053176853066\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.09352053176853066\n",
      "learning rate for this epoch =  0.1616079979578994\n",
      "Error on this batch = 0.026656257106231648\n",
      "Error on this batch = 0.03519345786768918\n",
      "Cost on val dataset after 191 epochs is = 0.09348464356273628\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.09348464356273628\n",
      "learning rate for this epoch =  0.16139605258657097\n",
      "Error on this batch = 0.026546140289168622\n",
      "Error on this batch = 0.03512479346574253\n",
      "Cost on val dataset after 192 epochs is = 0.09345182120339326\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.09345182120339326\n",
      "learning rate for this epoch =  0.16118548977353128\n",
      "Error on this batch = 0.026439567081999717\n",
      "Error on this batch = 0.03505709255354378\n",
      "Cost on val dataset after 193 epochs is = 0.09342226035555014\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.09342226035555014\n",
      "learning rate for this epoch =  0.1609762933694058\n",
      "Error on this batch = 0.026336064177332853\n",
      "Error on this batch = 0.03499057953360075\n",
      "Cost on val dataset after 194 epochs is = 0.09339611954145648\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.09339611954145648\n",
      "learning rate for this epoch =  0.16076844749588948\n",
      "Error on this batch = 0.02623499061207661\n",
      "Error on this batch = 0.03492548703159374\n",
      "Cost on val dataset after 195 epochs is = 0.09337351538784235\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.09337351538784235\n",
      "learning rate for this epoch =  0.16056193653982745\n",
      "Error on this batch = 0.026135588434209545\n",
      "Error on this batch = 0.03486201602496174\n",
      "Cost on val dataset after 196 epochs is = 0.09335451530228989\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.09335451530228989\n",
      "learning rate for this epoch =  0.16035674514745463\n",
      "Error on this batch = 0.026037053353689582\n",
      "Error on this batch = 0.03480030376410663\n",
      "Cost on val dataset after 197 epochs is = 0.0933391303971883\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.0933391303971883\n",
      "learning rate for this epoch =  0.1601528582187888\n",
      "Error on this batch = 0.02593860573183501\n",
      "Error on this batch = 0.03474041214697617\n",
      "Cost on val dataset after 198 epochs is = 0.09332731154335047\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.09332731154335047\n",
      "learning rate for this epoch =  0.15995026090217312\n",
      "Error on this batch = 0.02583954457987042\n",
      "Error on this batch = 0.034682340663245326\n",
      "Cost on val dataset after 199 epochs is = 0.09331895050536625\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.09331895050536625\n",
      "learning rate for this epoch =  0.15974893858896244\n",
      "Error on this batch = 0.025739278920327166\n",
      "Error on this batch = 0.034626057666544474\n",
      "Cost on val dataset after 200 epochs is = 0.0933138868155394\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.0933138868155394\n",
      "learning rate for this epoch =  0.15954887690834965\n",
      "Error on this batch = 0.02563734368669437\n",
      "Error on this batch = 0.034571537366885834\n",
      "Cost on val dataset after 201 epochs is = 0.09331191975693556\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.09331191975693556\n",
      "learning rate for this epoch =  0.15935006172232735\n",
      "Error on this batch = 0.025533412290530372\n",
      "Error on this batch = 0.03451878991327772\n",
      "Cost on val dataset after 202 epochs is = 0.09331282346611175\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.09331282346611175\n",
      "learning rate for this epoch =  0.1591524791207806\n",
      "Error on this batch = 0.025427313273750397\n",
      "Error on this batch = 0.0344678764567763\n",
      "Cost on val dataset after 203 epochs is = 0.09331636181287928\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.09331636181287928\n",
      "learning rate for this epoch =  0.15895611541670698\n",
      "Error on this batch = 0.025319049854402788\n",
      "Error on this batch = 0.03441890673655946\n",
      "Cost on val dataset after 204 epochs is = 0.09332229881269387\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.09332229881269387\n",
      "learning rate for this epoch =  0.15876095714155977\n",
      "Error on this batch = 0.025208815303429246\n",
      "Error on this batch = 0.034372020881168315\n",
      "Cost on val dataset after 205 epochs is = 0.09333040012526848\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.09333040012526848\n",
      "learning rate for this epoch =  0.15856699104071065\n",
      "Error on this batch = 0.025096995960947343\n",
      "Error on this batch = 0.03432735876728005\n",
      "Cost on val dataset after 206 epochs is = 0.09334042141782276\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.09334042141782276\n",
      "learning rate for this epoch =  0.15837420406902836\n",
      "Error on this batch = 0.02498415491861972\n",
      "Error on this batch = 0.03428502008261227\n",
      "Cost on val dataset after 207 epochs is = 0.0933520794373421\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.0933520794373421\n",
      "learning rate for this epoch =  0.15818258338656938\n",
      "Error on this batch = 0.024870989283375073\n",
      "Error on this batch = 0.034245018173388105\n",
      "Cost on val dataset after 208 epochs is = 0.09336500056611069\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.09336500056611069\n",
      "learning rate for this epoch =  0.157992116354378\n",
      "Error on this batch = 0.024758249790485548\n",
      "Error on this batch = 0.03420723337256538\n",
      "Cost on val dataset after 209 epochs is = 0.0933786379872725\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.0933786379872725\n",
      "learning rate for this epoch =  0.15780279053039173\n",
      "Error on this batch = 0.024646604002381303\n",
      "Error on this batch = 0.03417137817995748\n",
      "Cost on val dataset after 210 epochs is = 0.0933921455743962\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.0933921455743962\n",
      "learning rate for this epoch =  0.1576145936654495\n",
      "Error on this batch = 0.02453642551168026\n",
      "Error on this batch = 0.03413699405135916\n",
      "Cost on val dataset after 211 epochs is = 0.09340422480950057\n",
      "cost initial= 0.0933921455743962 , cost final=0.09340422480950057 , change in cost= 1.2079235104378583e-05\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with softplus are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with softplus is = 211\n",
      "The training time with softplus is = 89.693sec\n",
      "The training accuracy with softplus is = 94.968%\n",
      "The validation accuracy with softplus is = 89.795%\n",
      "The test accuracy with softplus is = 87.908%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.6\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'softplus', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'softplus'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'softplus'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'softplus'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with softplus are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with softplus is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with softplus is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with softplus is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with softplus is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with softplus is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Plotting Graphs for Part D - ReLU of 2 Hidden Layer ARCH ------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"------------------Plotting Graphs for Part D - ReLU of 2 Hidden Layer ARCH ------------------\")\n",
    "x=[0,1,2]\n",
    "data = [' ','ReLU', ' ' ,' ' ,' ','Sigmoid', ' ',' ',' ','Softplus']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy and Epochs for Neural Network [100,100]\")\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Activation Function\")\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend()\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "ax1.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/partd/comp_diff_act.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F - Binary Cross Entropy With ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[]\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "test_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part F-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with ReLU activation and Cross Entropy------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part F-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with ReLU activation and Cross Entropy------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 17.901383893296945\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 17.89721578625675\n",
      "Error on this batch = 4.604033332206689\n",
      "Cost on val dataset after 2 epochs is = 4.171266974682238\n",
      "Initial Cost on Val dataset for this epoch 2 = 4.171266974682238\n",
      "learning rate for this epoch =  0.08408964152537146\n",
      "Error on this batch = 4.157265536554206\n",
      "Error on this batch = 3.474939642069099\n",
      "Cost on val dataset after 3 epochs is = 2.8478910470909926\n",
      "Initial Cost on Val dataset for this epoch 3 = 2.8478910470909926\n",
      "learning rate for this epoch =  0.07598356856515927\n",
      "Error on this batch = 2.774500042844477\n",
      "Error on this batch = 2.6790828682956356\n",
      "Cost on val dataset after 4 epochs is = 2.2040228179440255\n",
      "Initial Cost on Val dataset for this epoch 4 = 2.2040228179440255\n",
      "learning rate for this epoch =  0.07071067811865475\n",
      "Error on this batch = 2.1155773816588574\n",
      "Error on this batch = 2.2881330181942445\n",
      "Cost on val dataset after 5 epochs is = 1.8861889088055086\n",
      "Initial Cost on Val dataset for this epoch 5 = 1.8861889088055086\n",
      "learning rate for this epoch =  0.0668740304976422\n",
      "Error on this batch = 1.754164818806454\n",
      "Error on this batch = 2.015463651966893\n",
      "Cost on val dataset after 6 epochs is = 1.699219783334616\n",
      "Initial Cost on Val dataset for this epoch 6 = 1.699219783334616\n",
      "learning rate for this epoch =  0.06389431042462725\n",
      "Error on this batch = 1.5305504698600063\n",
      "Error on this batch = 1.8336445271220867\n",
      "Cost on val dataset after 7 epochs is = 1.5817035213588488\n",
      "Initial Cost on Val dataset for this epoch 7 = 1.5817035213588488\n",
      "learning rate for this epoch =  0.06147881529512644\n",
      "Error on this batch = 1.393411534253587\n",
      "Error on this batch = 1.7177173762148914\n",
      "Cost on val dataset after 8 epochs is = 1.4876664589062583\n",
      "Initial Cost on Val dataset for this epoch 8 = 1.4876664589062583\n",
      "learning rate for this epoch =  0.05946035575013606\n",
      "Error on this batch = 1.2761286613093268\n",
      "Error on this batch = 1.6289050182842173\n",
      "Cost on val dataset after 9 epochs is = 1.422604124373947\n",
      "Initial Cost on Val dataset for this epoch 9 = 1.422604124373947\n",
      "learning rate for this epoch =  0.05773502691896258\n",
      "Error on this batch = 1.1974401121902194\n",
      "Error on this batch = 1.5552322645261427\n",
      "Cost on val dataset after 10 epochs is = 1.3725259601355417\n",
      "Initial Cost on Val dataset for this epoch 10 = 1.3725259601355417\n",
      "learning rate for this epoch =  0.05623413251903491\n",
      "Error on this batch = 1.1370975743645209\n",
      "Error on this batch = 1.5026302679897452\n",
      "Cost on val dataset after 11 epochs is = 1.3326236121836055\n",
      "Initial Cost on Val dataset for this epoch 11 = 1.3326236121836055\n",
      "learning rate for this epoch =  0.05491004867761125\n",
      "Error on this batch = 1.0888923788288196\n",
      "Error on this batch = 1.460469338035764\n",
      "Cost on val dataset after 12 epochs is = 1.3002288689185864\n",
      "Initial Cost on Val dataset for this epoch 12 = 1.3002288689185864\n",
      "learning rate for this epoch =  0.0537284965911771\n",
      "Error on this batch = 1.0507538252371893\n",
      "Error on this batch = 1.4244396049094856\n",
      "Cost on val dataset after 13 epochs is = 1.273117398970834\n",
      "Initial Cost on Val dataset for this epoch 13 = 1.273117398970834\n",
      "learning rate for this epoch =  0.052664038784792665\n",
      "Error on this batch = 1.018989259159506\n",
      "Error on this batch = 1.3901729422065867\n",
      "Cost on val dataset after 14 epochs is = 1.2497065582810822\n",
      "Initial Cost on Val dataset for this epoch 14 = 1.2497065582810822\n",
      "learning rate for this epoch =  0.05169731539571706\n",
      "Error on this batch = 0.9938784428097175\n",
      "Error on this batch = 1.3610976738420058\n",
      "Cost on val dataset after 15 epochs is = 1.2300432078422268\n",
      "Initial Cost on Val dataset for this epoch 15 = 1.2300432078422268\n",
      "learning rate for this epoch =  0.05081327481546148\n",
      "Error on this batch = 0.9729204550346094\n",
      "Error on this batch = 1.3376602868608825\n",
      "Cost on val dataset after 16 epochs is = 1.2129163287057763\n",
      "Initial Cost on Val dataset for this epoch 16 = 1.2129163287057763\n",
      "learning rate for this epoch =  0.05\n",
      "Error on this batch = 0.9536727046513841\n",
      "Error on this batch = 1.3164892170538758\n",
      "Cost on val dataset after 17 epochs is = 1.197661272725907\n",
      "Initial Cost on Val dataset for this epoch 17 = 1.197661272725907\n",
      "learning rate for this epoch =  0.049247906050545236\n",
      "Error on this batch = 0.9374361704176275\n",
      "Error on this batch = 1.2972431618316704\n",
      "Cost on val dataset after 18 epochs is = 1.1841694400551483\n",
      "Initial Cost on Val dataset for this epoch 18 = 1.1841694400551483\n",
      "learning rate for this epoch =  0.048549177170732344\n",
      "Error on this batch = 0.9234819023584052\n",
      "Error on this batch = 1.2805743919437385\n",
      "Cost on val dataset after 19 epochs is = 1.1712288775946966\n",
      "Initial Cost on Val dataset for this epoch 19 = 1.1712288775946966\n",
      "learning rate for this epoch =  0.04789736254435747\n",
      "Error on this batch = 0.9104971374630492\n",
      "Error on this batch = 1.2644882724140858\n",
      "Cost on val dataset after 20 epochs is = 1.1597060058332262\n",
      "Initial Cost on Val dataset for this epoch 20 = 1.1597060058332262\n",
      "learning rate for this epoch =  0.047287080450158794\n",
      "Error on this batch = 0.8985239319695894\n",
      "Error on this batch = 1.2511405391626804\n",
      "Cost on val dataset after 21 epochs is = 1.1493385561191891\n",
      "Initial Cost on Val dataset for this epoch 21 = 1.1493385561191891\n",
      "learning rate for this epoch =  0.04671379777282001\n",
      "Error on this batch = 0.8875831216165618\n",
      "Error on this batch = 1.2386718359015116\n",
      "Cost on val dataset after 22 epochs is = 1.1403035641737094\n",
      "Initial Cost on Val dataset for this epoch 22 = 1.1403035641737094\n",
      "learning rate for this epoch =  0.04617366309441026\n",
      "Error on this batch = 0.8776541100492576\n",
      "Error on this batch = 1.2265250611019343\n",
      "Cost on val dataset after 23 epochs is = 1.132312168331301\n",
      "Initial Cost on Val dataset for this epoch 23 = 1.132312168331301\n",
      "learning rate for this epoch =  0.04566337854967313\n",
      "Error on this batch = 0.8689909761625018\n",
      "Error on this batch = 1.2165047901057002\n",
      "Cost on val dataset after 24 epochs is = 1.1248569108577087\n",
      "Initial Cost on Val dataset for this epoch 24 = 1.1248569108577087\n",
      "learning rate for this epoch =  0.04518010018049225\n",
      "Error on this batch = 0.8617387721550864\n",
      "Error on this batch = 1.2070469924445457\n",
      "Cost on val dataset after 25 epochs is = 1.1180005572633336\n",
      "Initial Cost on Val dataset for this epoch 25 = 1.1180005572633336\n",
      "learning rate for this epoch =  0.044721359549995794\n",
      "Error on this batch = 0.8552776212816522\n",
      "Error on this batch = 1.1980218418955106\n",
      "Cost on val dataset after 26 epochs is = 1.1120500415646468\n",
      "Initial Cost on Val dataset for this epoch 26 = 1.1120500415646468\n",
      "learning rate for this epoch =  0.04428500142691474\n",
      "Error on this batch = 0.849746873825257\n",
      "Error on this batch = 1.190627404878493\n",
      "Cost on val dataset after 27 epochs is = 1.1062264758338503\n",
      "Initial Cost on Val dataset for this epoch 27 = 1.1062264758338503\n",
      "learning rate for this epoch =  0.043869133765083085\n",
      "Error on this batch = 0.8443886786168893\n",
      "Error on this batch = 1.1828574479098266\n",
      "Cost on val dataset after 28 epochs is = 1.1009719258842023\n",
      "Initial Cost on Val dataset for this epoch 28 = 1.1009719258842023\n",
      "learning rate for this epoch =  0.043472087194499145\n",
      "Error on this batch = 0.8391220274307224\n",
      "Error on this batch = 1.1752798334577812\n",
      "Cost on val dataset after 29 epochs is = 1.095976094897564\n",
      "Initial Cost on Val dataset for this epoch 29 = 1.095976094897564\n",
      "learning rate for this epoch =  0.04309238194589061\n",
      "Error on this batch = 0.8339274551174343\n",
      "Error on this batch = 1.1694010850237464\n",
      "Cost on val dataset after 30 epochs is = 1.0915249394005708\n",
      "Initial Cost on Val dataset for this epoch 30 = 1.0915249394005708\n",
      "learning rate for this epoch =  0.042728700639623404\n",
      "Error on this batch = 0.8300343388539426\n",
      "Error on this batch = 1.1638204102865377\n",
      "Cost on val dataset after 31 epochs is = 1.0871472106427018\n",
      "Initial Cost on Val dataset for this epoch 31 = 1.0871472106427018\n",
      "learning rate for this epoch =  0.04237986574150217\n",
      "Error on this batch = 0.8257995855656249\n",
      "Error on this batch = 1.1573300936301267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 1.083082037159882\n",
      "Initial Cost on Val dataset for this epoch 32 = 1.083082037159882\n",
      "learning rate for this epoch =  0.04204482076268573\n",
      "Error on this batch = 0.8217006095139037\n",
      "Error on this batch = 1.1509390146976388\n",
      "Cost on val dataset after 33 epochs is = 1.0795678766906542\n",
      "Initial Cost on Val dataset for this epoch 33 = 1.0795678766906542\n",
      "learning rate for this epoch =  0.04172261448611506\n",
      "Error on this batch = 0.8181938630064265\n",
      "Error on this batch = 1.1446990640640704\n",
      "Cost on val dataset after 34 epochs is = 1.0761646018987852\n",
      "Initial Cost on Val dataset for this epoch 34 = 1.0761646018987852\n",
      "learning rate for this epoch =  0.041412387656655204\n",
      "Error on this batch = 0.8143973712134508\n",
      "Error on this batch = 1.1389130440668354\n",
      "Cost on val dataset after 35 epochs is = 1.0730155920483009\n",
      "Initial Cost on Val dataset for this epoch 35 = 1.0730155920483009\n",
      "learning rate for this epoch =  0.04111336169005197\n",
      "Error on this batch = 0.810668052379808\n",
      "Error on this batch = 1.132854177953819\n",
      "Cost on val dataset after 36 epochs is = 1.0698084960812462\n",
      "Initial Cost on Val dataset for this epoch 36 = 1.0698084960812462\n",
      "learning rate for this epoch =  0.040824829046386304\n",
      "Error on this batch = 0.8070801818916479\n",
      "Error on this batch = 1.1268965978961059\n",
      "Cost on val dataset after 37 epochs is = 1.0665993290611095\n",
      "Initial Cost on Val dataset for this epoch 37 = 1.0665993290611095\n",
      "learning rate for this epoch =  0.040546144983876986\n",
      "Error on this batch = 0.8033802333481547\n",
      "Error on this batch = 1.1207269196707454\n",
      "Cost on val dataset after 38 epochs is = 1.0638167326589634\n",
      "Initial Cost on Val dataset for this epoch 38 = 1.0638167326589634\n",
      "learning rate for this epoch =  0.04027672046365773\n",
      "Error on this batch = 0.8003212117979976\n",
      "Error on this batch = 1.1148095142152188\n",
      "Cost on val dataset after 39 epochs is = 1.0616410873073792\n",
      "Initial Cost on Val dataset for this epoch 39 = 1.0616410873073792\n",
      "learning rate for this epoch =  0.040016016019225\n",
      "Error on this batch = 0.7983471320613806\n",
      "Error on this batch = 1.109709788198642\n",
      "Cost on val dataset after 40 epochs is = 1.0592731546244043\n",
      "Initial Cost on Val dataset for this epoch 40 = 1.0592731546244043\n",
      "learning rate for this epoch =  0.03976353643835253\n",
      "Error on this batch = 0.7965085914944757\n",
      "Error on this batch = 1.1049480832523029\n",
      "Cost on val dataset after 41 epochs is = 1.056686331386001\n",
      "Initial Cost on Val dataset for this epoch 41 = 1.056686331386001\n",
      "learning rate for this epoch =  0.03951882613244048\n",
      "Error on this batch = 0.7934206652361553\n",
      "Error on this batch = 1.1000890974883935\n",
      "Cost on val dataset after 42 epochs is = 1.0544217596755034\n",
      "Initial Cost on Val dataset for this epoch 42 = 1.0544217596755034\n",
      "learning rate for this epoch =  0.0392814650900513\n",
      "Error on this batch = 0.7911898589855543\n",
      "Error on this batch = 1.0950261134145\n",
      "Cost on val dataset after 43 epochs is = 1.0524372723406148\n",
      "Initial Cost on Val dataset for this epoch 43 = 1.0524372723406148\n",
      "learning rate for this epoch =  0.03905106532895161\n",
      "Error on this batch = 0.7886576332458484\n",
      "Error on this batch = 1.091324602549052\n",
      "Cost on val dataset after 44 epochs is = 1.050412315246289\n",
      "Initial Cost on Val dataset for this epoch 44 = 1.050412315246289\n",
      "learning rate for this epoch =  0.03882726777522233\n",
      "Error on this batch = 0.7865703379462733\n",
      "Error on this batch = 1.0869660519788777\n",
      "Cost on val dataset after 45 epochs is = 1.0485556565252476\n",
      "Initial Cost on Val dataset for this epoch 45 = 1.0485556565252476\n",
      "learning rate for this epoch =  0.03860973950960897\n",
      "Error on this batch = 0.7840780219584538\n",
      "Error on this batch = 1.0827661277800347\n",
      "Cost on val dataset after 46 epochs is = 1.0465941753528787\n",
      "Initial Cost on Val dataset for this epoch 46 = 1.0465941753528787\n",
      "learning rate for this epoch =  0.0383981713307935\n",
      "Error on this batch = 0.7810991949953697\n",
      "Error on this batch = 1.079106819171264\n",
      "Cost on val dataset after 47 epochs is = 1.0446877156161392\n",
      "Initial Cost on Val dataset for this epoch 47 = 1.0446877156161392\n",
      "learning rate for this epoch =  0.03819227559309534\n",
      "Error on this batch = 0.778441243021037\n",
      "Error on this batch = 1.0753952979366463\n",
      "Cost on val dataset after 48 epochs is = 1.0432379862537278\n",
      "Initial Cost on Val dataset for this epoch 48 = 1.0432379862537278\n",
      "learning rate for this epoch =  0.037991784282579634\n",
      "Error on this batch = 0.7756339835936694\n",
      "Error on this batch = 1.0718233671112574\n",
      "Cost on val dataset after 49 epochs is = 1.0416102243098004\n",
      "Initial Cost on Val dataset for this epoch 49 = 1.0416102243098004\n",
      "learning rate for this epoch =  0.03779644730092272\n",
      "Error on this batch = 0.7732823449634312\n",
      "Error on this batch = 1.0688176885007534\n",
      "Cost on val dataset after 50 epochs is = 1.0400712409914417\n",
      "Initial Cost on Val dataset for this epoch 50 = 1.0400712409914417\n",
      "learning rate for this epoch =  0.03760603093086394\n",
      "Error on this batch = 0.7709889193008174\n",
      "Error on this batch = 1.0666524952899936\n",
      "Cost on val dataset after 51 epochs is = 1.038523796143003\n",
      "Initial Cost on Val dataset for this epoch 51 = 1.038523796143003\n",
      "learning rate for this epoch =  0.03742031646082125\n",
      "Error on this batch = 0.7691530508010922\n",
      "Error on this batch = 1.0634012566135485\n",
      "Cost on val dataset after 52 epochs is = 1.0371553287018391\n",
      "Initial Cost on Val dataset for this epoch 52 = 1.0371553287018391\n",
      "learning rate for this epoch =  0.03723909894939824\n",
      "Error on this batch = 0.7676060626651185\n",
      "Error on this batch = 1.0609682750976983\n",
      "Cost on val dataset after 53 epochs is = 1.0359812553032017\n",
      "Initial Cost on Val dataset for this epoch 53 = 1.0359812553032017\n",
      "learning rate for this epoch =  0.037062186113165134\n",
      "Error on this batch = 0.7656269669586883\n",
      "Error on this batch = 1.057970293056345\n",
      "Cost on val dataset after 54 epochs is = 1.034943901154386\n",
      "Initial Cost on Val dataset for this epoch 54 = 1.034943901154386\n",
      "learning rate for this epoch =  0.03688939732334406\n",
      "Error on this batch = 0.7639012079832719\n",
      "Error on this batch = 1.0565926145488056\n",
      "Cost on val dataset after 55 epochs is = 1.034113831584653\n",
      "Initial Cost on Val dataset for this epoch 55 = 1.034113831584653\n",
      "learning rate for this epoch =  0.03672056269893592\n",
      "Error on this batch = 0.7623221619594722\n",
      "Error on this batch = 1.055003124386783\n",
      "Cost on val dataset after 56 epochs is = 1.033265237054787\n",
      "Initial Cost on Val dataset for this epoch 56 = 1.033265237054787\n",
      "learning rate for this epoch =  0.03655552228545124\n",
      "Error on this batch = 0.7608823427351191\n",
      "Error on this batch = 1.0524151408511222\n",
      "Cost on val dataset after 57 epochs is = 1.0325839945623423\n",
      "Initial Cost on Val dataset for this epoch 57 = 1.0325839945623423\n",
      "learning rate for this epoch =  0.036394125309794766\n",
      "Error on this batch = 0.7593073528692518\n",
      "Error on this batch = 1.050785765128238\n",
      "Cost on val dataset after 58 epochs is = 1.0322248770084088\n",
      "Initial Cost on Val dataset for this epoch 58 = 1.0322248770084088\n",
      "learning rate for this epoch =  0.036236229503043296\n",
      "Error on this batch = 0.7585730244935783\n",
      "Error on this batch = 1.049072012904364\n",
      "Cost on val dataset after 59 epochs is = 1.0318107302586341\n",
      "Initial Cost on Val dataset for this epoch 59 = 1.0318107302586341\n",
      "learning rate for this epoch =  0.036081700483877405\n",
      "Error on this batch = 0.7573126379534177\n",
      "Error on this batch = 1.0471705541612089\n",
      "Cost on val dataset after 60 epochs is = 1.031524899182814\n",
      "Initial Cost on Val dataset for this epoch 60 = 1.031524899182814\n",
      "learning rate for this epoch =  0.03593041119630843\n",
      "Error on this batch = 0.7560998604781579\n",
      "Error on this batch = 1.0457146110527575\n",
      "Cost on val dataset after 61 epochs is = 1.0310694227757855\n",
      "Initial Cost on Val dataset for this epoch 61 = 1.0310694227757855\n",
      "learning rate for this epoch =  0.03578224139610262\n",
      "Error on this batch = 0.7550080179292911\n",
      "Error on this batch = 1.0446510721889513\n",
      "Cost on val dataset after 62 epochs is = 1.0308060489378477\n",
      "Initial Cost on Val dataset for this epoch 62 = 1.0308060489378477\n",
      "learning rate for this epoch =  0.03563707718096288\n",
      "Error on this batch = 0.7540290949818318\n",
      "Error on this batch = 1.0436034008841433\n",
      "Cost on val dataset after 63 epochs is = 1.0305380984918793\n",
      "Initial Cost on Val dataset for this epoch 63 = 1.0305380984918793\n",
      "learning rate for this epoch =  0.03549481056010053\n",
      "Error on this batch = 0.753282669621821\n",
      "Error on this batch = 1.042814613063983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 64 epochs is = 1.0301677233153075\n",
      "Initial Cost on Val dataset for this epoch 64 = 1.0301677233153075\n",
      "learning rate for this epoch =  0.035355339059327376\n",
      "Error on this batch = 0.7525712346792088\n",
      "Error on this batch = 1.0414964167249556\n",
      "Cost on val dataset after 65 epochs is = 1.0298608329336356\n",
      "Initial Cost on Val dataset for this epoch 65 = 1.0298608329336356\n",
      "learning rate for this epoch =  0.03521856535823236\n",
      "Error on this batch = 0.751912065722261\n",
      "Error on this batch = 1.040432927302541\n",
      "Cost on val dataset after 66 epochs is = 1.0297112432127649\n",
      "Initial Cost on Val dataset for this epoch 66 = 1.0297112432127649\n",
      "learning rate for this epoch =  0.035084396956386855\n",
      "Error on this batch = 0.7513912564437039\n",
      "Error on this batch = 1.0396461140236573\n",
      "Cost on val dataset after 67 epochs is = 1.0295036157879063\n",
      "Initial Cost on Val dataset for this epoch 67 = 1.0295036157879063\n",
      "learning rate for this epoch =  0.034952745865855124\n",
      "Error on this batch = 0.7506656190064607\n",
      "Error on this batch = 1.0377075948620607\n",
      "Cost on val dataset after 68 epochs is = 1.0293529406078088\n",
      "Initial Cost on Val dataset for this epoch 68 = 1.0293529406078088\n",
      "learning rate for this epoch =  0.03482352832757854\n",
      "Error on this batch = 0.7499521351931696\n",
      "Error on this batch = 1.0367119940084957\n",
      "Cost on val dataset after 69 epochs is = 1.0293108871294305\n",
      "Initial Cost on Val dataset for this epoch 69 = 1.0293108871294305\n",
      "learning rate for this epoch =  0.034696664549459105\n",
      "Error on this batch = 0.7487609705449094\n",
      "Error on this batch = 1.0365688648245202\n",
      "Cost on val dataset after 70 epochs is = 1.0293492713941812\n",
      "Initial Cost on Val dataset for this epoch 70 = 1.0293492713941812\n",
      "learning rate for this epoch =  0.034572078464194106\n",
      "Error on this batch = 0.7474779619114932\n",
      "Error on this batch = 1.0363433283742955\n",
      "Cost on val dataset after 71 epochs is = 1.0295276437477614\n",
      "Initial Cost on Val dataset for this epoch 71 = 1.0295276437477614\n",
      "learning rate for this epoch =  0.03444969750511394\n",
      "Error on this batch = 0.7455343652788995\n",
      "Error on this batch = 1.0357485865328935\n",
      "Cost on val dataset after 72 epochs is = 1.0297330437153411\n",
      "Initial Cost on Val dataset for this epoch 72 = 1.0297330437153411\n",
      "learning rate for this epoch =  0.03432945239845196\n",
      "Error on this batch = 0.7435538098330864\n",
      "Error on this batch = 1.0357569664645936\n",
      "Cost on val dataset after 73 epochs is = 1.030074270643092\n",
      "Initial Cost on Val dataset for this epoch 73 = 1.030074270643092\n",
      "learning rate for this epoch =  0.03421127697063215\n",
      "Error on this batch = 0.7426886099407493\n",
      "Error on this batch = 1.0359663459558468\n",
      "Cost on val dataset after 74 epochs is = 1.03024358926659\n",
      "Initial Cost on Val dataset for this epoch 74 = 1.03024358926659\n",
      "learning rate for this epoch =  0.03409510796929954\n",
      "Error on this batch = 0.7409055597359462\n",
      "Error on this batch = 1.0360820827512434\n",
      "Cost on val dataset after 75 epochs is = 1.0303219465255073\n",
      "Initial Cost on Val dataset for this epoch 75 = 1.0303219465255073\n",
      "learning rate for this epoch =  0.033980884896942454\n",
      "Error on this batch = 0.739160724620628\n",
      "Error on this batch = 1.0348105899015319\n",
      "Cost on val dataset after 76 epochs is = 1.0303724432650128\n",
      "Initial Cost on Val dataset for this epoch 76 = 1.0303724432650128\n",
      "learning rate for this epoch =  0.033868549856065716\n",
      "Error on this batch = 0.737236994192969\n",
      "Error on this batch = 1.0341623466155536\n",
      "Cost on val dataset after 77 epochs is = 1.0305708118322778\n",
      "Initial Cost on Val dataset for this epoch 77 = 1.0305708118322778\n",
      "learning rate for this epoch =  0.03375804740497264\n",
      "Error on this batch = 0.7353157712802986\n",
      "Error on this batch = 1.0338951895943727\n",
      "Cost on val dataset after 78 epochs is = 1.0310548419278427\n",
      "Initial Cost on Val dataset for this epoch 78 = 1.0310548419278427\n",
      "learning rate for this epoch =  0.03364932442330151\n",
      "Error on this batch = 0.7335667178308038\n",
      "Error on this batch = 1.033884415185547\n",
      "Cost on val dataset after 79 epochs is = 1.0311947513106106\n",
      "cost initial= 1.0310548419278427 , cost final=1.0311947513106106 , change in cost= 0.00013990938276786657\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with ReLU are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with ReLU is = 79\n",
      "The training time with ReLU is = 16.790sec\n",
      "The training accuracy with ReLU is = 88.661%\n",
      "The validation accuracy with ReLU is = 85.436%\n",
      "The test accuracy with ReLU is = 83.385%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.1\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'relu', 'adaptive', 'entropy')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'relu'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'relu'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'relu'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with ReLU are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with ReLU is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with ReLU is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with ReLU is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with ReLU is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with ReLU is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part F-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with Softplus activation and Cross Entropy------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part F-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with Softplus activation and Cross Entropy------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 19.81503930292858\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 19.794280492670666\n",
      "Error on this batch = 4.175317200313914\n",
      "Cost on val dataset after 2 epochs is = 4.024354564890312\n",
      "Initial Cost on Val dataset for this epoch 2 = 4.024354564890312\n",
      "learning rate for this epoch =  0.08408964152537146\n",
      "Error on this batch = 4.051570739139761\n",
      "Error on this batch = 3.4029525993912\n",
      "Cost on val dataset after 3 epochs is = 2.9019077904745707\n",
      "Initial Cost on Val dataset for this epoch 3 = 2.9019077904745707\n",
      "learning rate for this epoch =  0.07598356856515927\n",
      "Error on this batch = 2.939627005348293\n",
      "Error on this batch = 2.645088093797996\n",
      "Cost on val dataset after 4 epochs is = 2.180768819383366\n",
      "Initial Cost on Val dataset for this epoch 4 = 2.180768819383366\n",
      "learning rate for this epoch =  0.07071067811865475\n",
      "Error on this batch = 2.183160605921156\n",
      "Error on this batch = 2.2109997141826585\n",
      "Cost on val dataset after 5 epochs is = 1.8151391120957396\n",
      "Initial Cost on Val dataset for this epoch 5 = 1.8151391120957396\n",
      "learning rate for this epoch =  0.0668740304976422\n",
      "Error on this batch = 1.7056436571446687\n",
      "Error on this batch = 1.9419549862038767\n",
      "Cost on val dataset after 6 epochs is = 1.5947659128193645\n",
      "Initial Cost on Val dataset for this epoch 6 = 1.5947659128193645\n",
      "learning rate for this epoch =  0.06389431042462725\n",
      "Error on this batch = 1.4186687270400646\n",
      "Error on this batch = 1.757283772649388\n",
      "Cost on val dataset after 7 epochs is = 1.4608112218876002\n",
      "Initial Cost on Val dataset for this epoch 7 = 1.4608112218876002\n",
      "learning rate for this epoch =  0.06147881529512644\n",
      "Error on this batch = 1.263012749531799\n",
      "Error on this batch = 1.6353944437397439\n",
      "Cost on val dataset after 8 epochs is = 1.3738471788646582\n",
      "Initial Cost on Val dataset for this epoch 8 = 1.3738471788646582\n",
      "learning rate for this epoch =  0.05946035575013606\n",
      "Error on this batch = 1.1671087519484054\n",
      "Error on this batch = 1.5402006186395398\n",
      "Cost on val dataset after 9 epochs is = 1.3086103301282008\n",
      "Initial Cost on Val dataset for this epoch 9 = 1.3086103301282008\n",
      "learning rate for this epoch =  0.05773502691896258\n",
      "Error on this batch = 1.0960765681666444\n",
      "Error on this batch = 1.4617006945685973\n",
      "Cost on val dataset after 10 epochs is = 1.2557603414382288\n",
      "Initial Cost on Val dataset for this epoch 10 = 1.2557603414382288\n",
      "learning rate for this epoch =  0.05623413251903491\n",
      "Error on this batch = 1.0387711111558608\n",
      "Error on this batch = 1.3978562776030845\n",
      "Cost on val dataset after 11 epochs is = 1.211612959325901\n",
      "Initial Cost on Val dataset for this epoch 11 = 1.211612959325901\n",
      "learning rate for this epoch =  0.05491004867761125\n",
      "Error on this batch = 0.9909991242506396\n",
      "Error on this batch = 1.3461805057436362\n",
      "Cost on val dataset after 12 epochs is = 1.1741266291400536\n",
      "Initial Cost on Val dataset for this epoch 12 = 1.1741266291400536\n",
      "learning rate for this epoch =  0.0537284965911771\n",
      "Error on this batch = 0.9504466209399789\n",
      "Error on this batch = 1.3035323999385344\n",
      "Cost on val dataset after 13 epochs is = 1.1418542492847117\n",
      "Initial Cost on Val dataset for this epoch 13 = 1.1418542492847117\n",
      "learning rate for this epoch =  0.052664038784792665\n",
      "Error on this batch = 0.9154033958052614\n",
      "Error on this batch = 1.2672033047914208\n",
      "Cost on val dataset after 14 epochs is = 1.113692245742254\n",
      "Initial Cost on Val dataset for this epoch 14 = 1.113692245742254\n",
      "learning rate for this epoch =  0.05169731539571706\n",
      "Error on this batch = 0.8844787509160691\n",
      "Error on this batch = 1.235290533610019\n",
      "Cost on val dataset after 15 epochs is = 1.0887824103037318\n",
      "Initial Cost on Val dataset for this epoch 15 = 1.0887824103037318\n",
      "learning rate for this epoch =  0.05081327481546148\n",
      "Error on this batch = 0.8565550235668147\n",
      "Error on this batch = 1.206577446312441\n",
      "Cost on val dataset after 16 epochs is = 1.0664662405637126\n",
      "Initial Cost on Val dataset for this epoch 16 = 1.0664662405637126\n",
      "learning rate for this epoch =  0.05\n",
      "Error on this batch = 0.8308115137541748\n",
      "Error on this batch = 1.180313514476632\n",
      "Cost on val dataset after 17 epochs is = 1.0462541879992329\n",
      "Initial Cost on Val dataset for this epoch 17 = 1.0462541879992329\n",
      "learning rate for this epoch =  0.049247906050545236\n",
      "Error on this batch = 0.8067263050640163\n",
      "Error on this batch = 1.1560307611646456\n",
      "Cost on val dataset after 18 epochs is = 1.027784838273554\n",
      "Initial Cost on Val dataset for this epoch 18 = 1.027784838273554\n",
      "learning rate for this epoch =  0.048549177170732344\n",
      "Error on this batch = 0.7840134212094205\n",
      "Error on this batch = 1.1334192423186769\n",
      "Cost on val dataset after 19 epochs is = 1.0107816739363182\n",
      "Initial Cost on Val dataset for this epoch 19 = 1.0107816739363182\n",
      "learning rate for this epoch =  0.04789736254435747\n",
      "Error on this batch = 0.7625255289054397\n",
      "Error on this batch = 1.1122536813542225\n",
      "Cost on val dataset after 20 epochs is = 0.9950240257989524\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.9950240257989524\n",
      "learning rate for this epoch =  0.047287080450158794\n",
      "Error on this batch = 0.7421750718557846\n",
      "Error on this batch = 1.092355650003341\n",
      "Cost on val dataset after 21 epochs is = 0.9803330227766361\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.9803330227766361\n",
      "learning rate for this epoch =  0.04671379777282001\n",
      "Error on this batch = 0.7228935777816361\n",
      "Error on this batch = 1.0735764527891596\n",
      "Cost on val dataset after 22 epochs is = 0.9665640748050499\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.9665640748050499\n",
      "learning rate for this epoch =  0.04617366309441026\n",
      "Error on this batch = 0.7046174283095725\n",
      "Error on this batch = 1.055790052045333\n",
      "Cost on val dataset after 23 epochs is = 0.9536006640829484\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.9536006640829484\n",
      "learning rate for this epoch =  0.04566337854967313\n",
      "Error on this batch = 0.6872845040710616\n",
      "Error on this batch = 1.0388898226474519\n",
      "Cost on val dataset after 24 epochs is = 0.9413485950739896\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.9413485950739896\n",
      "learning rate for this epoch =  0.04518010018049225\n",
      "Error on this batch = 0.6708338538456735\n",
      "Error on this batch = 1.0227862096932843\n",
      "Cost on val dataset after 25 epochs is = 0.9297311174517937\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.9297311174517937\n",
      "learning rate for this epoch =  0.044721359549995794\n",
      "Error on this batch = 0.6552060468642907\n",
      "Error on this batch = 1.0074042838588322\n",
      "Cost on val dataset after 26 epochs is = 0.9186851141159775\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.9186851141159775\n",
      "learning rate for this epoch =  0.04428500142691474\n",
      "Error on this batch = 0.6403437477495788\n",
      "Error on this batch = 0.9926811052123786\n",
      "Cost on val dataset after 27 epochs is = 0.9081582341754629\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.9081582341754629\n",
      "learning rate for this epoch =  0.043869133765083085\n",
      "Error on this batch = 0.6261923742468564\n",
      "Error on this batch = 0.9785631253474005\n",
      "Cost on val dataset after 28 epochs is = 0.8981067422748793\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.8981067422748793\n",
      "learning rate for this epoch =  0.043472087194499145\n",
      "Error on this batch = 0.6127006932788553\n",
      "Error on this batch = 0.9650038766386039\n",
      "Cost on val dataset after 29 epochs is = 0.8884938724352862\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.8884938724352862\n",
      "learning rate for this epoch =  0.04309238194589061\n",
      "Error on this batch = 0.5998212337018817\n",
      "Error on this batch = 0.95196210235771\n",
      "Cost on val dataset after 30 epochs is = 0.8792885295932316\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.8792885295932316\n",
      "learning rate for this epoch =  0.042728700639623404\n",
      "Error on this batch = 0.5875104630310596\n",
      "Error on this batch = 0.9394003729403363\n",
      "Cost on val dataset after 31 epochs is = 0.8704642353409163\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.8704642353409163\n",
      "learning rate for this epoch =  0.04237986574150217\n",
      "Error on this batch = 0.5757287447451864\n",
      "Error on this batch = 0.9272841522164496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 0.8619982543747718\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.8619982543747718\n",
      "learning rate for this epoch =  0.04204482076268573\n",
      "Error on this batch = 0.564440134197126\n",
      "Error on this batch = 0.9155812301188323\n",
      "Cost on val dataset after 33 epochs is = 0.8538708642457267\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.8538708642457267\n",
      "learning rate for this epoch =  0.04172261448611506\n",
      "Error on this batch = 0.5536120816443589\n",
      "Error on this batch = 0.9042614203676581\n",
      "Cost on val dataset after 34 epochs is = 0.8460647459155728\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.8460647459155728\n",
      "learning rate for this epoch =  0.041412387656655204\n",
      "Error on this batch = 0.5432151008384287\n",
      "Error on this batch = 0.8932964255127908\n",
      "Cost on val dataset after 35 epochs is = 0.8385644798365265\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.8385644798365265\n",
      "learning rate for this epoch =  0.04111336169005197\n",
      "Error on this batch = 0.5332224432901284\n",
      "Error on this batch = 0.882659789589944\n",
      "Cost on val dataset after 36 epochs is = 0.8313561350415861\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.8313561350415861\n",
      "learning rate for this epoch =  0.040824829046386304\n",
      "Error on this batch = 0.5236098003524023\n",
      "Error on this batch = 0.8723268824104956\n",
      "Cost on val dataset after 37 epochs is = 0.8244269395728652\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.8244269395728652\n",
      "learning rate for this epoch =  0.040546144983876986\n",
      "Error on this batch = 0.5143550414971988\n",
      "Error on this batch = 0.8622748822480821\n",
      "Cost on val dataset after 38 epochs is = 0.8177650210130687\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.8177650210130687\n",
      "learning rate for this epoch =  0.04027672046365773\n",
      "Error on this batch = 0.5054379881323555\n",
      "Error on this batch = 0.8524827412963037\n",
      "Cost on val dataset after 39 epochs is = 0.8113592065707516\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.8113592065707516\n",
      "learning rate for this epoch =  0.040016016019225\n",
      "Error on this batch = 0.49684021709719867\n",
      "Error on this batch = 0.8429311297661312\n",
      "Cost on val dataset after 40 epochs is = 0.8051988731899224\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.8051988731899224\n",
      "learning rate for this epoch =  0.03976353643835253\n",
      "Error on this batch = 0.4885448855557945\n",
      "Error on this batch = 0.8336023609329187\n",
      "Cost on val dataset after 41 epochs is = 0.7992738393567818\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.7992738393567818\n",
      "learning rate for this epoch =  0.03951882613244048\n",
      "Error on this batch = 0.48053656870611927\n",
      "Error on this batch = 0.8244803024714236\n",
      "Cost on val dataset after 42 epochs is = 0.7935742914699111\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.7935742914699111\n",
      "learning rate for this epoch =  0.0392814650900513\n",
      "Error on this batch = 0.4728011031628492\n",
      "Error on this batch = 0.815550280324945\n",
      "Cost on val dataset after 43 epochs is = 0.7880907386718171\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.7880907386718171\n",
      "learning rate for this epoch =  0.03905106532895161\n",
      "Error on this batch = 0.46532543169521995\n",
      "Error on this batch = 0.8067989809225796\n",
      "Cost on val dataset after 44 epochs is = 0.7828139908061222\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.7828139908061222\n",
      "learning rate for this epoch =  0.03882726777522233\n",
      "Error on this batch = 0.4580974486681244\n",
      "Error on this batch = 0.798214356312802\n",
      "Cost on val dataset after 45 epochs is = 0.7777351546131134\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.7777351546131134\n",
      "learning rate for this epoch =  0.03860973950960897\n",
      "Error on this batch = 0.45110584926161656\n",
      "Error on this batch = 0.7897855352231801\n",
      "Cost on val dataset after 46 epochs is = 0.7728456434169734\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.7728456434169734\n",
      "learning rate for this epoch =  0.0383981713307935\n",
      "Error on this batch = 0.4443399884211794\n",
      "Error on this batch = 0.7815027416392137\n",
      "Cost on val dataset after 47 epochs is = 0.7681371954833152\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.7681371954833152\n",
      "learning rate for this epoch =  0.03819227559309534\n",
      "Error on this batch = 0.4377897567384438\n",
      "Error on this batch = 0.7733572214392944\n",
      "Cost on val dataset after 48 epochs is = 0.7636018961152244\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.7636018961152244\n",
      "learning rate for this epoch =  0.037991784282579634\n",
      "Error on this batch = 0.43144547972738745\n",
      "Error on this batch = 0.7653411768162613\n",
      "Cost on val dataset after 49 epochs is = 0.7592321986487192\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.7592321986487192\n",
      "learning rate for this epoch =  0.03779644730092272\n",
      "Error on this batch = 0.4252978444911974\n",
      "Error on this batch = 0.7574477073775208\n",
      "Cost on val dataset after 50 epochs is = 0.7550209400382458\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.7550209400382458\n",
      "learning rate for this epoch =  0.03760603093086394\n",
      "Error on this batch = 0.4193378543381791\n",
      "Error on this batch = 0.7496707558116427\n",
      "Cost on val dataset after 51 epochs is = 0.7509613478280944\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.7509613478280944\n",
      "learning rate for this epoch =  0.03742031646082125\n",
      "Error on this batch = 0.4135568084934101\n",
      "Error on this batch = 0.7420050550569313\n",
      "Cost on val dataset after 52 epochs is = 0.747047036939446\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.747047036939446\n",
      "learning rate for this epoch =  0.03723909894939824\n",
      "Error on this batch = 0.40794630152093336\n",
      "Error on this batch = 0.7344460734782431\n",
      "Cost on val dataset after 53 epochs is = 0.7432719965903717\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.7432719965903717\n",
      "learning rate for this epoch =  0.037062186113165134\n",
      "Error on this batch = 0.40249823587668987\n",
      "Error on this batch = 0.7269899550462182\n",
      "Cost on val dataset after 54 epochs is = 0.73963056936663\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.73963056936663\n",
      "learning rate for this epoch =  0.03688939732334406\n",
      "Error on this batch = 0.39720484114238674\n",
      "Error on this batch = 0.7196334529239737\n",
      "Cost on val dataset after 55 epochs is = 0.7361174255400672\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.7361174255400672\n",
      "learning rate for this epoch =  0.03672056269893592\n",
      "Error on this batch = 0.3920586945684902\n",
      "Error on this batch = 0.7123738567642736\n",
      "Cost on val dataset after 56 epochs is = 0.732727535962796\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.732727535962796\n",
      "learning rate for this epoch =  0.03655552228545124\n",
      "Error on this batch = 0.3870527390548233\n",
      "Error on this batch = 0.7052089157627738\n",
      "Cost on val dataset after 57 epochs is = 0.7294561463322637\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.7294561463322637\n",
      "learning rate for this epoch =  0.036394125309794766\n",
      "Error on this batch = 0.3821802961627724\n",
      "Error on this batch = 0.6981367605926966\n",
      "Cost on val dataset after 58 epochs is = 0.7262987546493297\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.7262987546493297\n",
      "learning rate for this epoch =  0.036236229503043296\n",
      "Error on this batch = 0.3774350729229525\n",
      "Error on this batch = 0.6911558276020116\n",
      "Cost on val dataset after 59 epochs is = 0.7232510926626842\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.7232510926626842\n",
      "learning rate for this epoch =  0.036081700483877405\n",
      "Error on this batch = 0.37281116201639747\n",
      "Error on this batch = 0.6842647882490406\n",
      "Cost on val dataset after 60 epochs is = 0.720309111283709\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.720309111283709\n",
      "learning rate for this epoch =  0.03593041119630843\n",
      "Error on this batch = 0.36830303542911735\n",
      "Error on this batch = 0.6774624859968607\n",
      "Cost on val dataset after 61 epochs is = 0.7174689694660624\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.7174689694660624\n",
      "learning rate for this epoch =  0.03578224139610262\n",
      "Error on this batch = 0.363905532005148\n",
      "Error on this batch = 0.6707478820588517\n",
      "Cost on val dataset after 62 epochs is = 0.7147270258333436\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.7147270258333436\n",
      "learning rate for this epoch =  0.03563707718096288\n",
      "Error on this batch = 0.3596138395267414\n",
      "Error on this batch = 0.6641200106472736\n",
      "Cost on val dataset after 63 epochs is = 0.7120798323040333\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.7120798323040333\n",
      "learning rate for this epoch =  0.03549481056010053\n",
      "Error on this batch = 0.3554234720745421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.6575779437753928\n",
      "Cost on val dataset after 64 epochs is = 0.7095241290087071\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.7095241290087071\n",
      "learning rate for this epoch =  0.035355339059327376\n",
      "Error on this batch = 0.35133024348788433\n",
      "Error on this batch = 0.651120765194832\n",
      "Cost on val dataset after 65 epochs is = 0.7070568398602558\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.7070568398602558\n",
      "learning rate for this epoch =  0.03521856535823236\n",
      "Error on this batch = 0.3473302377733606\n",
      "Error on this batch = 0.6447475526927045\n",
      "Cost on val dataset after 66 epochs is = 0.7046750682018554\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.7046750682018554\n",
      "learning rate for this epoch =  0.035084396956386855\n",
      "Error on this batch = 0.34341977731816914\n",
      "Error on this batch = 0.6384573677114791\n",
      "Cost on val dataset after 67 epochs is = 0.7023760920229639\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.7023760920229639\n",
      "learning rate for this epoch =  0.034952745865855124\n",
      "Error on this batch = 0.33959538977407905\n",
      "Error on this batch = 0.6322492510770363\n",
      "Cost on val dataset after 68 epochs is = 0.7001573583132087\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.7001573583132087\n",
      "learning rate for this epoch =  0.03482352832757854\n",
      "Error on this batch = 0.335853774504486\n",
      "Error on this batch = 0.6261222235146665\n",
      "Cost on val dataset after 69 epochs is = 0.6980164762280278\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.6980164762280278\n",
      "learning rate for this epoch =  0.034696664549459105\n",
      "Error on this batch = 0.3321917695376546\n",
      "Error on this batch = 0.6200752895830152\n",
      "Cost on val dataset after 70 epochs is = 0.6959512088706691\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.6959512088706691\n",
      "learning rate for this epoch =  0.034572078464194106\n",
      "Error on this batch = 0.32860632003825246\n",
      "Error on this batch = 0.6141074436458784\n",
      "Cost on val dataset after 71 epochs is = 0.6939594636458822\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.6939594636458822\n",
      "learning rate for this epoch =  0.03444969750511394\n",
      "Error on this batch = 0.32509444937816573\n",
      "Error on this batch = 0.6082176765219431\n",
      "Cost on val dataset after 72 epochs is = 0.6920392812977493\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.6920392812977493\n",
      "learning rate for this epoch =  0.03432945239845196\n",
      "Error on this batch = 0.3216532339271841\n",
      "Error on this batch = 0.6024049815075343\n",
      "Cost on val dataset after 73 epochs is = 0.6901888238906301\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.6901888238906301\n",
      "learning rate for this epoch =  0.03421127697063215\n",
      "Error on this batch = 0.318279782658463\n",
      "Error on this batch = 0.5966683585777134\n",
      "Cost on val dataset after 74 epochs is = 0.6884063621117599\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.6884063621117599\n",
      "learning rate for this epoch =  0.03409510796929954\n",
      "Error on this batch = 0.3149712225369282\n",
      "Error on this batch = 0.591006815767114\n",
      "Cost on val dataset after 75 epochs is = 0.6866902623538139\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.6866902623538139\n",
      "learning rate for this epoch =  0.033980884896942454\n",
      "Error on this batch = 0.3117246904057037\n",
      "Error on this batch = 0.5854193670387337\n",
      "Cost on val dataset after 76 epochs is = 0.6850389740685472\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.6850389740685472\n",
      "learning rate for this epoch =  0.033868549856065716\n",
      "Error on this batch = 0.30853733170379516\n",
      "Error on this batch = 0.5799050263675006\n",
      "Cost on val dataset after 77 epochs is = 0.6834510178678594\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.6834510178678594\n",
      "learning rate for this epoch =  0.03375804740497264\n",
      "Error on this batch = 0.30540630586754386\n",
      "Error on this batch = 0.5744627982595009\n",
      "Cost on val dataset after 78 epochs is = 0.6819249747918824\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.6819249747918824\n",
      "learning rate for this epoch =  0.03364932442330151\n",
      "Error on this batch = 0.3023287977503097\n",
      "Error on this batch = 0.5690916654263328\n",
      "Cost on val dataset after 79 epochs is = 0.6804594770752812\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.6804594770752812\n",
      "learning rate for this epoch =  0.03354232998654124\n",
      "Error on this batch = 0.29930203391824317\n",
      "Error on this batch = 0.5637905747517188\n",
      "Cost on val dataset after 80 epochs is = 0.679053200634969\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.679053200634969\n",
      "learning rate for this epoch =  0.0334370152488211\n",
      "Error on this batch = 0.2963233023164036\n",
      "Error on this batch = 0.5585584229529326\n",
      "Cost on val dataset after 81 epochs is = 0.6777048593858446\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.6777048593858446\n",
      "learning rate for this epoch =  0.03333333333333333\n",
      "Error on this batch = 0.29338997359161306\n",
      "Error on this batch = 0.5533940434178725\n",
      "Cost on val dataset after 82 epochs is = 0.6764132013736177\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.6764132013736177\n",
      "learning rate for this epoch =  0.03323123922980402\n",
      "Error on this batch = 0.29049952231339654\n",
      "Error on this batch = 0.548296195594857\n",
      "Cost on val dataset after 83 epochs is = 0.6751770065998076\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.6751770065998076\n",
      "learning rate for this epoch =  0.033130689698479016\n",
      "Error on this batch = 0.2876495464358215\n",
      "Error on this batch = 0.5432635580580952\n",
      "Cost on val dataset after 84 epochs is = 0.6739950863070576\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.6739950863070576\n",
      "learning rate for this epoch =  0.03303164318013808\n",
      "Error on this batch = 0.28483778357160966\n",
      "Error on this batch = 0.5382947260073537\n",
      "Cost on val dataset after 85 epochs is = 0.6728662833987044\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.6728662833987044\n",
      "learning rate for this epoch =  0.032934059711691804\n",
      "Error on this batch = 0.2820621229951083\n",
      "Error on this batch = 0.5333882135241713\n",
      "Cost on val dataset after 86 epochs is = 0.6717894735947594\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.6717894735947594\n",
      "learning rate for this epoch =  0.03283790084695403\n",
      "Error on this batch = 0.2793206127443727\n",
      "Error on this batch = 0.5285424604394556\n",
      "Cost on val dataset after 87 epochs is = 0.6707635668896909\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.6707635668896909\n",
      "learning rate for this epoch =  0.0327431295822161\n",
      "Error on this batch = 0.2766114617278695\n",
      "Error on this batch = 0.5237558432186309\n",
      "Cost on val dataset after 88 epochs is = 0.6697875088868642\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.6697875088868642\n",
      "learning rate for this epoch =  0.032649710286280526\n",
      "Error on this batch = 0.2739330372948091\n",
      "Error on this batch = 0.5190266889018003\n",
      "Cost on val dataset after 89 epochs is = 0.6688602816444292\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.6688602816444292\n",
      "learning rate for this epoch =  0.03255760863463962\n",
      "Error on this batch = 0.2712838592036177\n",
      "Error on this batch = 0.5143532909067196\n",
      "Cost on val dataset after 90 epochs is = 0.6679809037712128\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.6679809037712128\n",
      "learning rate for this epoch =  0.03246679154750989\n",
      "Error on this batch = 0.2686625912199312\n",
      "Error on this batch = 0.5097339254479143\n",
      "Cost on val dataset after 91 epochs is = 0.6671484296417182\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.6671484296417182\n",
      "learning rate for this epoch =  0.03237722713145643\n",
      "Error on this batch = 0.26606803162924264\n",
      "Error on this batch = 0.5051668674431565\n",
      "Cost on val dataset after 92 epochs is = 0.666361947733479\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.666361947733479\n",
      "learning rate for this epoch =  0.032288884624362205\n",
      "Error on this batch = 0.2634991037604885\n",
      "Error on this batch = 0.500650405026113\n",
      "Cost on val dataset after 93 epochs is = 0.6656205782054536\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.6656205782054536\n",
      "learning rate for this epoch =  0.03220173434351674\n",
      "Error on this batch = 0.2609548472524764\n",
      "Error on this batch = 0.4961828520945838\n",
      "Cost on val dataset after 94 epochs is = 0.6649234699167269\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.6649234699167269\n",
      "learning rate for this epoch =  0.0321157476366158\n",
      "Error on this batch = 0.25843441036251596\n",
      "Error on this batch = 0.4917625586295195\n",
      "Cost on val dataset after 95 epochs is = 0.6642697971234827\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.6642697971234827\n",
      "learning rate for this epoch =  0.03203089683547987\n",
      "Error on this batch = 0.2559370432253678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4873879187714366\n",
      "Cost on val dataset after 96 epochs is = 0.6636587560904479\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.6636587560904479\n",
      "learning rate for this epoch =  0.03194715521231362\n",
      "Error on this batch = 0.25346209169954426\n",
      "Error on this batch = 0.48305737681519106\n",
      "Cost on val dataset after 97 epochs is = 0.6630895618182764\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.6630895618182764\n",
      "learning rate for this epoch =  0.031864496938342195\n",
      "Error on this batch = 0.2510089913201687\n",
      "Error on this batch = 0.47876943138302963\n",
      "Cost on val dataset after 98 epochs is = 0.6625614450315347\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.6625614450315347\n",
      "learning rate for this epoch =  0.031782897044671854\n",
      "Error on this batch = 0.24857726090304874\n",
      "Error on this batch = 0.4745226380764392\n",
      "Cost on val dataset after 99 epochs is = 0.6620736495047799\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.6620736495047799\n",
      "learning rate for this epoch =  0.0317023313852343\n",
      "Error on this batch = 0.24616649547403302\n",
      "Error on this batch = 0.4703156109115726\n",
      "Cost on val dataset after 100 epochs is = 0.6616254297379166\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.6616254297379166\n",
      "learning rate for this epoch =  0.03162277660168379\n",
      "Error on this batch = 0.24377635838001369\n",
      "Error on this batch = 0.46614702282997655\n",
      "Cost on val dataset after 101 epochs is = 0.6612160489359875\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.6612160489359875\n",
      "learning rate for this epoch =  0.03154421009012572\n",
      "Error on this batch = 0.24140657262453755\n",
      "Error on this batch = 0.46201560555810944\n",
      "Cost on val dataset after 102 epochs is = 0.6608447772097171\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.6608447772097171\n",
      "learning rate for this epoch =  0.03146660996956416\n",
      "Error on this batch = 0.23905691162518905\n",
      "Error on this batch = 0.45792014907051026\n",
      "Cost on val dataset after 103 epochs is = 0.6605108898953872\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.6605108898953872\n",
      "learning rate for this epoch =  0.03138995505196357\n",
      "Error on this batch = 0.2367271896906883\n",
      "Error on this batch = 0.4538595008918893\n",
      "Cost on val dataset after 104 epochs is = 0.660213665896556\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.660213665896556\n",
      "learning rate for this epoch =  0.03131422481382735\n",
      "Error on this batch = 0.23441725255707052\n",
      "Error on this batch = 0.4498325654495985\n",
      "Cost on val dataset after 105 epochs is = 0.6599523859733016\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.6599523859733016\n",
      "learning rate for this epoch =  0.03123939936920256\n",
      "Error on this batch = 0.23212696831043272\n",
      "Error on this batch = 0.4458383036564683\n",
      "Cost on val dataset after 106 epochs is = 0.6597263309421239\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.6597263309421239\n",
      "learning rate for this epoch =  0.031165459444026558\n",
      "Error on this batch = 0.22985621897205719\n",
      "Error on this batch = 0.4418757328625806\n",
      "Cost on val dataset after 107 epochs is = 0.6595347797947124\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.6595347797947124\n",
      "learning rate for this epoch =  0.03109238635173672\n",
      "Error on this batch = 0.2276048929469517\n",
      "Error on this batch = 0.43794392726289033\n",
      "Cost on val dataset after 108 epochs is = 0.6593770077891953\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.6593770077891953\n",
      "learning rate for this epoch =  0.031020161970069987\n",
      "Error on this batch = 0.22537287845515067\n",
      "Error on this batch = 0.4340420187872627\n",
      "Cost on val dataset after 109 epochs is = 0.6592522846060409\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.6592522846060409\n",
      "learning rate for this epoch =  0.030948768718983822\n",
      "Error on this batch = 0.22316005798987681\n",
      "Error on this batch = 0.430169198433845\n",
      "Cost on val dataset after 110 epochs is = 0.6591598726866676\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.6591598726866676\n",
      "learning rate for this epoch =  0.030878189539634483\n",
      "Error on this batch = 0.2209663037871055\n",
      "Error on this batch = 0.42632471794095644\n",
      "Cost on val dataset after 111 epochs is = 0.6590990258820351\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.6590990258820351\n",
      "learning rate for this epoch =  0.03080840787435305\n",
      "Error on this batch = 0.21879147425199452\n",
      "Error on this batch = 0.4225078916333017\n",
      "Cost on val dataset after 112 epochs is = 0.6590689885298519\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.6590689885298519\n",
      "learning rate for this epoch =  0.03073940764756322\n",
      "Error on this batch = 0.21663541126960512\n",
      "Error on this batch = 0.4187180982328417\n",
      "Cost on val dataset after 113 epochs is = 0.6590689950541168\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.6590689950541168\n",
      "learning rate for this epoch =  0.030671173247588647\n",
      "Error on this batch = 0.2144979383272848\n",
      "Error on this batch = 0.4149547824001269\n",
      "Cost on val dataset after 114 epochs is = 0.6590982701438248\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.6590982701438248\n",
      "learning rate for this epoch =  0.0306036895093009\n",
      "Error on this batch = 0.21237885938836493\n",
      "Error on this batch = 0.41121745577345353\n",
      "Cost on val dataset after 115 epochs is = 0.6591560295249443\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.6591560295249443\n",
      "learning rate for this epoch =  0.030536941697562214\n",
      "Error on this batch = 0.21027795847434008\n",
      "Error on this batch = 0.4075056973026557\n",
      "Cost on val dataset after 116 epochs is = 0.6592414812978483\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.6592414812978483\n",
      "learning rate for this epoch =  0.03047091549142\n",
      "Error on this batch = 0.20819499992844406\n",
      "Error on this batch = 0.40381915272879076\n",
      "Cost on val dataset after 117 epochs is = 0.6593538277772112\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.6593538277772112\n",
      "learning rate for this epoch =  0.030405596969012936\n",
      "Error on this batch = 0.20612972934197135\n",
      "Error on this batch = 0.40015753313345437\n",
      "Cost on val dataset after 118 epochs is = 0.6594922677468957\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.6594922677468957\n",
      "learning rate for this epoch =  0.030340972593150727\n",
      "Error on this batch = 0.20408187512280965\n",
      "Error on this batch = 0.3965206125617627\n",
      "Cost on val dataset after 119 epochs is = 0.6596559990300415\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.6596559990300415\n",
      "learning rate for this epoch =  0.030277029197532102\n",
      "Error on this batch = 0.20205115067345372\n",
      "Error on this batch = 0.39290822480005605\n",
      "Cost on val dataset after 120 epochs is = 0.6598442212733892\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.6598442212733892\n",
      "learning rate for this epoch =  0.030213753973567684\n",
      "Error on this batch = 0.20003725712592144\n",
      "Error on this batch = 0.38932025945328674\n",
      "Cost on val dataset after 121 epochs is = 0.660056138852186\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.660056138852186\n",
      "learning rate for this epoch =  0.030151134457776365\n",
      "Error on this batch = 0.19803988655783117\n",
      "Error on this batch = 0.38575665751096955\n",
      "Cost on val dataset after 122 epochs is = 0.6602909638140824\n",
      "cost initial= 0.660056138852186 , cost final=0.6602909638140824 , change in cost= 0.00023482496189641822\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with softplus are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with softplus is = 122\n",
      "The training time with softplus is = 52.935sec\n",
      "The training accuracy with softplus is = 97.041%\n",
      "The validation accuracy with softplus is = 91.333%\n",
      "The test accuracy with softplus is = 89.800%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.1\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'softplus', 'adaptive', 'entropy')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'softplus'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'softplus'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'softplus'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with softplus are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with softplus is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with softplus is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with softplus is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with softplus is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with softplus is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Plotting Graphs for Part F - ReLU with Cross Entropy ------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"------------------Plotting Graphs for Part F - ReLU with Cross Entropy ------------------\")\n",
    "x=[0,1]\n",
    "data = [' ','ReLU', ' ' ,' ' ,' ',' ','Softplus']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy and Epochs for Neural Network [100,100]\\n with Cross-Entropy\")\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Activation Function\")\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend()\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "plt.legend(loc=4)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/partf/comp_diff_act.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E - MLP Classifier using SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part E-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with MLP Classifier------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part E-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with MLP Classifier------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlp_classifier\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_time = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=[]\n",
    "#Classifier - logistic with constant LR\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=400,\n",
    "                     tol=1e-5, verbose=True))\n",
    "#Classifier - logistic with early_stopping =True\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=400,\n",
    "                     early_stopping=True, tol=1e-5, verbose=True))\n",
    "#Classifier - logistic with invscaling with lr0=0.3 and p=5\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.3, learning_rate='invscaling', max_iter=400,\n",
    "                     power_t=(1/5), tol=1e-5, verbose=True))\n",
    "#Classifier - logistic with invscaling with pow(1/3)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.3, learning_rate='invscaling', max_iter=400,\n",
    "                     power_t=(1/4), tol=1e-5, verbose=True))\n",
    "\n",
    "\n",
    "#Classifier ReLU with constant LR (1e-5) lr=0.03\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.03, learning_rate='constant', max_iter=400,\n",
    "                     tol=1e-5, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-5) lr=0.1\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=400,\n",
    "                     tol=1e-5, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-5) with early stopping\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=400,\n",
    "                     early_stopping=True, tol=1e-5, verbose=True))\n",
    "\n",
    "#Classifier ReLU with constant LR (1e-6) with invscaling sqrt\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='invscaling', max_iter=400,\n",
    "                     power_t=(1/2), tol=1e-5, verbose=True))\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='invscaling', max_iter=400,\n",
    "                     power_t=(1/3), tol=1e-5, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-6) with invscaling pow(1/3)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='invscaling', max_iter=400,\n",
    "                     power_t=(1/4), tol=1e-5, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.40204009\n",
      "Iteration 2, loss = 3.66074777\n",
      "Iteration 3, loss = 2.62139016\n",
      "Iteration 4, loss = 1.97130534\n",
      "Iteration 5, loss = 1.48572083\n",
      "Iteration 6, loss = 1.21746981\n",
      "Iteration 7, loss = 1.04363075\n",
      "Iteration 8, loss = 0.92358638\n",
      "Iteration 9, loss = 0.82895469\n",
      "Iteration 10, loss = 0.74692766\n",
      "Iteration 11, loss = 0.67857800\n",
      "Iteration 12, loss = 0.62064775\n",
      "Iteration 13, loss = 0.56697164\n",
      "Iteration 14, loss = 0.51872707\n",
      "Iteration 15, loss = 0.48015339\n",
      "Iteration 16, loss = 0.44150042\n",
      "Iteration 17, loss = 0.41049340\n",
      "Iteration 18, loss = 0.37763241\n",
      "Iteration 19, loss = 0.34948171\n",
      "Iteration 20, loss = 0.32447954\n",
      "Iteration 21, loss = 0.30236718\n",
      "Iteration 22, loss = 0.27835123\n",
      "Iteration 23, loss = 0.25934719\n",
      "Iteration 24, loss = 0.24183724\n",
      "Iteration 25, loss = 0.22467190\n",
      "Iteration 26, loss = 0.20778959\n",
      "Iteration 27, loss = 0.19313224\n",
      "Iteration 28, loss = 0.18029302\n",
      "Iteration 29, loss = 0.16893995\n",
      "Iteration 30, loss = 0.15827005\n",
      "Iteration 31, loss = 0.14669585\n",
      "Iteration 32, loss = 0.13758022\n",
      "Iteration 33, loss = 0.12783293\n",
      "Iteration 34, loss = 0.11980845\n",
      "Iteration 35, loss = 0.11111068\n",
      "Iteration 36, loss = 0.10504885\n",
      "Iteration 37, loss = 0.09708357\n",
      "Iteration 38, loss = 0.09173372\n",
      "Iteration 39, loss = 0.08545294\n",
      "Iteration 40, loss = 0.08105341\n",
      "Iteration 41, loss = 0.07609224\n",
      "Iteration 42, loss = 0.07196706\n",
      "Iteration 43, loss = 0.06803188\n",
      "Iteration 44, loss = 0.06378161\n",
      "Iteration 45, loss = 0.06081301\n",
      "Iteration 46, loss = 0.05742576\n",
      "Iteration 47, loss = 0.05458759\n",
      "Iteration 48, loss = 0.05200551\n",
      "Iteration 49, loss = 0.04933576\n",
      "Iteration 50, loss = 0.04712343\n",
      "Iteration 51, loss = 0.04491332\n",
      "Iteration 52, loss = 0.04320393\n",
      "Iteration 53, loss = 0.04142540\n",
      "Iteration 54, loss = 0.03960232\n",
      "Iteration 55, loss = 0.03798973\n",
      "Iteration 56, loss = 0.03656130\n",
      "Iteration 57, loss = 0.03511367\n",
      "Iteration 58, loss = 0.03399215\n",
      "Iteration 59, loss = 0.03280153\n",
      "Iteration 60, loss = 0.03180340\n",
      "Iteration 61, loss = 0.03078779\n",
      "Iteration 62, loss = 0.02986183\n",
      "Iteration 63, loss = 0.02891720\n",
      "Iteration 64, loss = 0.02808212\n",
      "Iteration 65, loss = 0.02723299\n",
      "Iteration 66, loss = 0.02651760\n",
      "Iteration 67, loss = 0.02583327\n",
      "Iteration 68, loss = 0.02509525\n",
      "Iteration 69, loss = 0.02447914\n",
      "Iteration 70, loss = 0.02382518\n",
      "Iteration 71, loss = 0.02335943\n",
      "Iteration 72, loss = 0.02277192\n",
      "Iteration 73, loss = 0.02231830\n",
      "Iteration 74, loss = 0.02189824\n",
      "Iteration 75, loss = 0.02131874\n",
      "Iteration 76, loss = 0.02090527\n",
      "Iteration 77, loss = 0.02056057\n",
      "Iteration 78, loss = 0.02015735\n",
      "Iteration 79, loss = 0.01978273\n",
      "Iteration 80, loss = 0.01937606\n",
      "Iteration 81, loss = 0.01904981\n",
      "Iteration 82, loss = 0.01866519\n",
      "Iteration 83, loss = 0.01840304\n",
      "Iteration 84, loss = 0.01808720\n",
      "Iteration 85, loss = 0.01778201\n",
      "Iteration 86, loss = 0.01752614\n",
      "Iteration 87, loss = 0.01724211\n",
      "Iteration 88, loss = 0.01700247\n",
      "Iteration 89, loss = 0.01670989\n",
      "Iteration 90, loss = 0.01654650\n",
      "Iteration 91, loss = 0.01631125\n",
      "Iteration 92, loss = 0.01606307\n",
      "Iteration 93, loss = 0.01584243\n",
      "Iteration 94, loss = 0.01561394\n",
      "Iteration 95, loss = 0.01545457\n",
      "Iteration 96, loss = 0.01524160\n",
      "Iteration 97, loss = 0.01506932\n",
      "Iteration 98, loss = 0.01488436\n",
      "Iteration 99, loss = 0.01473324\n",
      "Iteration 100, loss = 0.01455704\n",
      "Iteration 101, loss = 0.01440066\n",
      "Iteration 102, loss = 0.01425662\n",
      "Iteration 103, loss = 0.01410303\n",
      "Iteration 104, loss = 0.01393855\n",
      "Iteration 105, loss = 0.01380999\n",
      "Iteration 106, loss = 0.01368839\n",
      "Iteration 107, loss = 0.01353903\n",
      "Iteration 108, loss = 0.01341992\n",
      "Iteration 109, loss = 0.01330407\n",
      "Iteration 110, loss = 0.01316626\n",
      "Iteration 111, loss = 0.01304702\n",
      "Iteration 112, loss = 0.01294387\n",
      "Iteration 113, loss = 0.01284021\n",
      "Iteration 114, loss = 0.01271476\n",
      "Iteration 115, loss = 0.01260906\n",
      "Iteration 116, loss = 0.01251042\n",
      "Iteration 117, loss = 0.01241642\n",
      "Iteration 118, loss = 0.01232576\n",
      "Iteration 119, loss = 0.01222111\n",
      "Iteration 120, loss = 0.01213973\n",
      "Iteration 121, loss = 0.01204958\n",
      "Iteration 122, loss = 0.01196323\n",
      "Iteration 123, loss = 0.01187167\n",
      "Iteration 124, loss = 0.01179343\n",
      "Iteration 125, loss = 0.01172101\n",
      "Iteration 126, loss = 0.01162321\n",
      "Iteration 127, loss = 0.01156576\n",
      "Iteration 128, loss = 0.01147804\n",
      "Iteration 129, loss = 0.01140943\n",
      "Iteration 130, loss = 0.01133584\n",
      "Iteration 131, loss = 0.01126395\n",
      "Iteration 132, loss = 0.01120298\n",
      "Iteration 133, loss = 0.01114407\n",
      "Iteration 134, loss = 0.01107196\n",
      "Iteration 135, loss = 0.01099460\n",
      "Iteration 136, loss = 0.01095187\n",
      "Iteration 137, loss = 0.01088946\n",
      "Iteration 138, loss = 0.01082675\n",
      "Iteration 139, loss = 0.01076342\n",
      "Iteration 140, loss = 0.01069870\n",
      "Iteration 141, loss = 0.01065665\n",
      "Iteration 142, loss = 0.01059737\n",
      "Iteration 143, loss = 0.01053905\n",
      "Iteration 144, loss = 0.01049493\n",
      "Iteration 145, loss = 0.01043424\n",
      "Iteration 146, loss = 0.01038339\n",
      "Iteration 147, loss = 0.01034109\n",
      "Iteration 148, loss = 0.01029803\n",
      "Iteration 149, loss = 0.01024317\n",
      "Iteration 150, loss = 0.01021626\n",
      "Iteration 151, loss = 0.01014558\n",
      "Iteration 152, loss = 0.01011473\n",
      "Iteration 153, loss = 0.01007082\n",
      "Iteration 154, loss = 0.01002634\n",
      "Iteration 155, loss = 0.00998114\n",
      "Iteration 156, loss = 0.00994086\n",
      "Iteration 157, loss = 0.00989858\n",
      "Iteration 158, loss = 0.00986134\n",
      "Iteration 159, loss = 0.00981633\n",
      "Iteration 160, loss = 0.00979050\n",
      "Iteration 161, loss = 0.00974905\n",
      "Iteration 162, loss = 0.00970911\n",
      "Iteration 163, loss = 0.00967642\n",
      "Iteration 164, loss = 0.00963878\n",
      "Iteration 165, loss = 0.00960936\n",
      "Iteration 166, loss = 0.00957371\n",
      "Iteration 167, loss = 0.00953582\n",
      "Iteration 168, loss = 0.00949659\n",
      "Iteration 169, loss = 0.00946822\n",
      "Iteration 170, loss = 0.00944037\n",
      "Iteration 171, loss = 0.00940468\n",
      "Iteration 172, loss = 0.00937364\n",
      "Iteration 173, loss = 0.00934377\n",
      "Iteration 174, loss = 0.00931584\n",
      "Iteration 175, loss = 0.00928949\n",
      "Iteration 176, loss = 0.00925717\n",
      "Iteration 177, loss = 0.00922908\n",
      "Iteration 178, loss = 0.00919094\n",
      "Iteration 179, loss = 0.00917554\n",
      "Iteration 180, loss = 0.00914835\n",
      "Iteration 181, loss = 0.00911896\n",
      "Iteration 182, loss = 0.00908949\n",
      "Iteration 183, loss = 0.00907392\n",
      "Iteration 184, loss = 0.00904644\n",
      "Iteration 185, loss = 0.00900770\n",
      "Iteration 186, loss = 0.00899690\n",
      "Iteration 187, loss = 0.00896435\n",
      "Iteration 188, loss = 0.00894361\n",
      "Iteration 189, loss = 0.00891941\n",
      "Iteration 190, loss = 0.00890139\n",
      "Iteration 191, loss = 0.00887427\n",
      "Iteration 192, loss = 0.00885376\n",
      "Iteration 193, loss = 0.00882811\n",
      "Iteration 194, loss = 0.00880976\n",
      "Iteration 195, loss = 0.00877956\n",
      "Iteration 196, loss = 0.00876240\n",
      "Iteration 197, loss = 0.00874443\n",
      "Iteration 198, loss = 0.00872387\n",
      "Iteration 199, loss = 0.00870664\n",
      "Iteration 200, loss = 0.00868290\n",
      "Iteration 201, loss = 0.00866127\n",
      "Iteration 202, loss = 0.00864172\n",
      "Iteration 203, loss = 0.00862401\n",
      "Iteration 204, loss = 0.00860221\n",
      "Iteration 205, loss = 0.00858625\n",
      "Iteration 206, loss = 0.00856700\n",
      "Iteration 207, loss = 0.00854957\n",
      "Iteration 208, loss = 0.00853101\n",
      "Iteration 209, loss = 0.00851226\n",
      "Iteration 210, loss = 0.00849268\n",
      "Iteration 211, loss = 0.00848000\n",
      "Iteration 212, loss = 0.00846560\n",
      "Iteration 213, loss = 0.00844677\n",
      "Iteration 214, loss = 0.00842751\n",
      "Iteration 215, loss = 0.00841426\n",
      "Iteration 216, loss = 0.00839427\n",
      "Iteration 217, loss = 0.00838103\n",
      "Iteration 218, loss = 0.00836681\n",
      "Iteration 219, loss = 0.00835262\n",
      "Iteration 220, loss = 0.00833742\n",
      "Iteration 221, loss = 0.00831973\n",
      "Iteration 222, loss = 0.00830835\n",
      "Iteration 223, loss = 0.00829356\n",
      "Iteration 224, loss = 0.00827775\n",
      "Iteration 225, loss = 0.00826039\n",
      "Iteration 226, loss = 0.00824949\n",
      "Iteration 227, loss = 0.00823476\n",
      "Iteration 228, loss = 0.00822110\n",
      "Iteration 229, loss = 0.00820431\n",
      "Iteration 230, loss = 0.00819250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 231, loss = 0.00818206\n",
      "Iteration 232, loss = 0.00816669\n",
      "Iteration 233, loss = 0.00815445\n",
      "Iteration 234, loss = 0.00814171\n",
      "Iteration 235, loss = 0.00812549\n",
      "Iteration 236, loss = 0.00811395\n",
      "Iteration 237, loss = 0.00810097\n",
      "Iteration 238, loss = 0.00809088\n",
      "Iteration 239, loss = 0.00807933\n",
      "Iteration 240, loss = 0.00806483\n",
      "Iteration 241, loss = 0.00805517\n",
      "Iteration 242, loss = 0.00804530\n",
      "Iteration 243, loss = 0.00803136\n",
      "Iteration 244, loss = 0.00802000\n",
      "Iteration 245, loss = 0.00800937\n",
      "Iteration 246, loss = 0.00799755\n",
      "Iteration 247, loss = 0.00798497\n",
      "Iteration 248, loss = 0.00797602\n",
      "Iteration 249, loss = 0.00796509\n",
      "Iteration 250, loss = 0.00795512\n",
      "Iteration 251, loss = 0.00794356\n",
      "Iteration 252, loss = 0.00793086\n",
      "Iteration 253, loss = 0.00792437\n",
      "Iteration 254, loss = 0.00791360\n",
      "Iteration 255, loss = 0.00790178\n",
      "Iteration 256, loss = 0.00789237\n",
      "Iteration 257, loss = 0.00788448\n",
      "Iteration 258, loss = 0.00787165\n",
      "Iteration 259, loss = 0.00786263\n",
      "Iteration 260, loss = 0.00785138\n",
      "Iteration 261, loss = 0.00784491\n",
      "Iteration 262, loss = 0.00783444\n",
      "Iteration 263, loss = 0.00782734\n",
      "Iteration 264, loss = 0.00781706\n",
      "Iteration 265, loss = 0.00780829\n",
      "Iteration 266, loss = 0.00779826\n",
      "Iteration 267, loss = 0.00778883\n",
      "Iteration 268, loss = 0.00778039\n",
      "Iteration 269, loss = 0.00777285\n",
      "Iteration 270, loss = 0.00776264\n",
      "Iteration 271, loss = 0.00775491\n",
      "Iteration 272, loss = 0.00774889\n",
      "Iteration 273, loss = 0.00773878\n",
      "Iteration 274, loss = 0.00773122\n",
      "Iteration 275, loss = 0.00772343\n",
      "Iteration 276, loss = 0.00771506\n",
      "Iteration 277, loss = 0.00770548\n",
      "Iteration 278, loss = 0.00769916\n",
      "Iteration 279, loss = 0.00769061\n",
      "Iteration 280, loss = 0.00768370\n",
      "Iteration 281, loss = 0.00767341\n",
      "Iteration 282, loss = 0.00766925\n",
      "Iteration 283, loss = 0.00766000\n",
      "Iteration 284, loss = 0.00765195\n",
      "Iteration 285, loss = 0.00764505\n",
      "Iteration 286, loss = 0.00763791\n",
      "Iteration 287, loss = 0.00763160\n",
      "Iteration 288, loss = 0.00762389\n",
      "Iteration 289, loss = 0.00761408\n",
      "Iteration 290, loss = 0.00760967\n",
      "Iteration 291, loss = 0.00759982\n",
      "Iteration 292, loss = 0.00759626\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 100.000\n",
      "The test Accuracy achieved is = 88.385\n",
      "The number of epochs is = 292\n",
      "The training time achieved is = 126.136\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.43052265\n",
      "Validation score: 0.000000\n",
      "Iteration 2, loss = 3.87209300\n",
      "Validation score: 0.000000\n",
      "Iteration 3, loss = 2.90003073\n",
      "Validation score: 0.102308\n",
      "Iteration 4, loss = 2.18054327\n",
      "Validation score: 0.357692\n",
      "Iteration 5, loss = 1.71302583\n",
      "Validation score: 0.546923\n",
      "Iteration 6, loss = 1.37670859\n",
      "Validation score: 0.677692\n",
      "Iteration 7, loss = 1.15313912\n",
      "Validation score: 0.743846\n",
      "Iteration 8, loss = 1.00005646\n",
      "Validation score: 0.775385\n",
      "Iteration 9, loss = 0.88637088\n",
      "Validation score: 0.791538\n",
      "Iteration 10, loss = 0.79859101\n",
      "Validation score: 0.811538\n",
      "Iteration 11, loss = 0.71923573\n",
      "Validation score: 0.819231\n",
      "Iteration 12, loss = 0.65559563\n",
      "Validation score: 0.825385\n",
      "Iteration 13, loss = 0.59621500\n",
      "Validation score: 0.826154\n",
      "Iteration 14, loss = 0.54909431\n",
      "Validation score: 0.840000\n",
      "Iteration 15, loss = 0.50323063\n",
      "Validation score: 0.850769\n",
      "Iteration 16, loss = 0.46458070\n",
      "Validation score: 0.859231\n",
      "Iteration 17, loss = 0.42659393\n",
      "Validation score: 0.862308\n",
      "Iteration 18, loss = 0.39623864\n",
      "Validation score: 0.862308\n",
      "Iteration 19, loss = 0.36547911\n",
      "Validation score: 0.863846\n",
      "Iteration 20, loss = 0.34069016\n",
      "Validation score: 0.862308\n",
      "Iteration 21, loss = 0.31472795\n",
      "Validation score: 0.876154\n",
      "Iteration 22, loss = 0.29222887\n",
      "Validation score: 0.873077\n",
      "Iteration 23, loss = 0.27142155\n",
      "Validation score: 0.876154\n",
      "Iteration 24, loss = 0.25149500\n",
      "Validation score: 0.876923\n",
      "Iteration 25, loss = 0.23390881\n",
      "Validation score: 0.875385\n",
      "Iteration 26, loss = 0.21576859\n",
      "Validation score: 0.880000\n",
      "Iteration 27, loss = 0.20144206\n",
      "Validation score: 0.877692\n",
      "Iteration 28, loss = 0.18705575\n",
      "Validation score: 0.885385\n",
      "Iteration 29, loss = 0.17211738\n",
      "Validation score: 0.884615\n",
      "Iteration 30, loss = 0.16180736\n",
      "Validation score: 0.883077\n",
      "Iteration 31, loss = 0.15108189\n",
      "Validation score: 0.888462\n",
      "Iteration 32, loss = 0.13983224\n",
      "Validation score: 0.891538\n",
      "Iteration 33, loss = 0.13059033\n",
      "Validation score: 0.891538\n",
      "Iteration 34, loss = 0.12108886\n",
      "Validation score: 0.893077\n",
      "Iteration 35, loss = 0.11371775\n",
      "Validation score: 0.891538\n",
      "Iteration 36, loss = 0.10588745\n",
      "Validation score: 0.892308\n",
      "Iteration 37, loss = 0.09993055\n",
      "Validation score: 0.894615\n",
      "Iteration 38, loss = 0.09394810\n",
      "Validation score: 0.893846\n",
      "Iteration 39, loss = 0.08754417\n",
      "Validation score: 0.893846\n",
      "Iteration 40, loss = 0.08257828\n",
      "Validation score: 0.896154\n",
      "Iteration 41, loss = 0.07844358\n",
      "Validation score: 0.893077\n",
      "Iteration 42, loss = 0.07382629\n",
      "Validation score: 0.893077\n",
      "Iteration 43, loss = 0.06919545\n",
      "Validation score: 0.896923\n",
      "Iteration 44, loss = 0.06590698\n",
      "Validation score: 0.894615\n",
      "Iteration 45, loss = 0.06304306\n",
      "Validation score: 0.892308\n",
      "Iteration 46, loss = 0.05990018\n",
      "Validation score: 0.892308\n",
      "Iteration 47, loss = 0.05678746\n",
      "Validation score: 0.893077\n",
      "Iteration 48, loss = 0.05417734\n",
      "Validation score: 0.895385\n",
      "Iteration 49, loss = 0.05201814\n",
      "Validation score: 0.900000\n",
      "Iteration 50, loss = 0.04983751\n",
      "Validation score: 0.899231\n",
      "Iteration 51, loss = 0.04764378\n",
      "Validation score: 0.898462\n",
      "Iteration 52, loss = 0.04587903\n",
      "Validation score: 0.899231\n",
      "Iteration 53, loss = 0.04373366\n",
      "Validation score: 0.897692\n",
      "Iteration 54, loss = 0.04240932\n",
      "Validation score: 0.898462\n",
      "Iteration 55, loss = 0.04083702\n",
      "Validation score: 0.898462\n",
      "Iteration 56, loss = 0.03926248\n",
      "Validation score: 0.898462\n",
      "Iteration 57, loss = 0.03803006\n",
      "Validation score: 0.896154\n",
      "Iteration 58, loss = 0.03664878\n",
      "Validation score: 0.897692\n",
      "Iteration 59, loss = 0.03552114\n",
      "Validation score: 0.897692\n",
      "Iteration 60, loss = 0.03427841\n",
      "Validation score: 0.896154\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 98.838\n",
      "The test Accuracy achieved is = 87.815\n",
      "The number of epochs is = 60\n",
      "The training time achieved is = 22.613\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.3, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.2,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.42801389\n",
      "Iteration 2, loss = 4.02596292\n",
      "Iteration 3, loss = 3.87454169\n",
      "Iteration 4, loss = 3.79304929\n",
      "Iteration 5, loss = 3.72809097\n",
      "Iteration 6, loss = 3.66152124\n",
      "Iteration 7, loss = 3.57633795\n",
      "Iteration 8, loss = 3.45514887\n",
      "Iteration 9, loss = 3.32199629\n",
      "Iteration 10, loss = 3.20917575\n",
      "Iteration 11, loss = 3.10525199\n",
      "Iteration 12, loss = 3.00536485\n",
      "Iteration 13, loss = 2.92012477\n",
      "Iteration 14, loss = 2.84166494\n",
      "Iteration 15, loss = 2.76640765\n",
      "Iteration 16, loss = 2.69109637\n",
      "Iteration 17, loss = 2.61113309\n",
      "Iteration 18, loss = 2.52343505\n",
      "Iteration 19, loss = 2.43415827\n",
      "Iteration 20, loss = 2.34216664\n",
      "Iteration 21, loss = 2.24796703\n",
      "Iteration 22, loss = 2.15390429\n",
      "Iteration 23, loss = 2.05949510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, loss = 1.96731984\n",
      "Iteration 25, loss = 1.87869472\n",
      "Iteration 26, loss = 1.79595583\n",
      "Iteration 27, loss = 1.72311480\n",
      "Iteration 28, loss = 1.65537157\n",
      "Iteration 29, loss = 1.59668851\n",
      "Iteration 30, loss = 1.53917002\n",
      "Iteration 31, loss = 1.48533925\n",
      "Iteration 32, loss = 1.43538380\n",
      "Iteration 33, loss = 1.38690275\n",
      "Iteration 34, loss = 1.34124156\n",
      "Iteration 35, loss = 1.29574277\n",
      "Iteration 36, loss = 1.25359031\n",
      "Iteration 37, loss = 1.21260901\n",
      "Iteration 38, loss = 1.17481083\n",
      "Iteration 39, loss = 1.13796467\n",
      "Iteration 40, loss = 1.10518988\n",
      "Iteration 41, loss = 1.07163165\n",
      "Iteration 42, loss = 1.04040277\n",
      "Iteration 43, loss = 1.00928791\n",
      "Iteration 44, loss = 0.98259498\n",
      "Iteration 45, loss = 0.95702545\n",
      "Iteration 46, loss = 0.93129600\n",
      "Iteration 47, loss = 0.90744259\n",
      "Iteration 48, loss = 0.88489825\n",
      "Iteration 49, loss = 0.86163559\n",
      "Iteration 50, loss = 0.84010861\n",
      "Iteration 51, loss = 0.82035608\n",
      "Iteration 52, loss = 0.80119383\n",
      "Iteration 53, loss = 0.78230972\n",
      "Iteration 54, loss = 0.76437147\n",
      "Iteration 55, loss = 0.74674593\n",
      "Iteration 56, loss = 0.73032045\n",
      "Iteration 57, loss = 0.71486781\n",
      "Iteration 58, loss = 0.69872644\n",
      "Iteration 59, loss = 0.68433118\n",
      "Iteration 60, loss = 0.67068505\n",
      "Iteration 61, loss = 0.65667782\n",
      "Iteration 62, loss = 0.64221628\n",
      "Iteration 63, loss = 0.62835683\n",
      "Iteration 64, loss = 0.61736321\n",
      "Iteration 65, loss = 0.60394175\n",
      "Iteration 66, loss = 0.59247090\n",
      "Iteration 67, loss = 0.58065916\n",
      "Iteration 68, loss = 0.56935173\n",
      "Iteration 69, loss = 0.55807900\n",
      "Iteration 70, loss = 0.54791753\n",
      "Iteration 71, loss = 0.53697121\n",
      "Iteration 72, loss = 0.52728448\n",
      "Iteration 73, loss = 0.51798119\n",
      "Iteration 74, loss = 0.50710346\n",
      "Iteration 75, loss = 0.49875019\n",
      "Iteration 76, loss = 0.49018189\n",
      "Iteration 77, loss = 0.48087214\n",
      "Iteration 78, loss = 0.47134677\n",
      "Iteration 79, loss = 0.46389234\n",
      "Iteration 80, loss = 0.45640911\n",
      "Iteration 81, loss = 0.44867696\n",
      "Iteration 82, loss = 0.44055118\n",
      "Iteration 83, loss = 0.43226412\n",
      "Iteration 84, loss = 0.42547985\n",
      "Iteration 85, loss = 0.41915436\n",
      "Iteration 86, loss = 0.41163913\n",
      "Iteration 87, loss = 0.40520965\n",
      "Iteration 88, loss = 0.39848776\n",
      "Iteration 89, loss = 0.39232861\n",
      "Iteration 90, loss = 0.38600247\n",
      "Iteration 91, loss = 0.37965624\n",
      "Iteration 92, loss = 0.37382535\n",
      "Iteration 93, loss = 0.36878828\n",
      "Iteration 94, loss = 0.36244755\n",
      "Iteration 95, loss = 0.35704318\n",
      "Iteration 96, loss = 0.35168623\n",
      "Iteration 97, loss = 0.34669781\n",
      "Iteration 98, loss = 0.34124396\n",
      "Iteration 99, loss = 0.33653188\n",
      "Iteration 100, loss = 0.33195351\n",
      "Iteration 101, loss = 0.32695590\n",
      "Iteration 102, loss = 0.32187908\n",
      "Iteration 103, loss = 0.31693791\n",
      "Iteration 104, loss = 0.31303903\n",
      "Iteration 105, loss = 0.30834405\n",
      "Iteration 106, loss = 0.30374883\n",
      "Iteration 107, loss = 0.29995082\n",
      "Iteration 108, loss = 0.29544999\n",
      "Iteration 109, loss = 0.29138400\n",
      "Iteration 110, loss = 0.28768476\n",
      "Iteration 111, loss = 0.28356550\n",
      "Iteration 112, loss = 0.27987562\n",
      "Iteration 113, loss = 0.27610100\n",
      "Iteration 114, loss = 0.27281977\n",
      "Iteration 115, loss = 0.26977477\n",
      "Iteration 116, loss = 0.26569487\n",
      "Iteration 117, loss = 0.26224303\n",
      "Iteration 118, loss = 0.25869619\n",
      "Iteration 119, loss = 0.25558058\n",
      "Iteration 120, loss = 0.25294445\n",
      "Iteration 121, loss = 0.24902542\n",
      "Iteration 122, loss = 0.24605263\n",
      "Iteration 123, loss = 0.24288517\n",
      "Iteration 124, loss = 0.23951310\n",
      "Iteration 125, loss = 0.23689188\n",
      "Iteration 126, loss = 0.23428508\n",
      "Iteration 127, loss = 0.23140076\n",
      "Iteration 128, loss = 0.22838908\n",
      "Iteration 129, loss = 0.22594893\n",
      "Iteration 130, loss = 0.22344797\n",
      "Iteration 131, loss = 0.22029702\n",
      "Iteration 132, loss = 0.21799959\n",
      "Iteration 133, loss = 0.21537239\n",
      "Iteration 134, loss = 0.21320504\n",
      "Iteration 135, loss = 0.21023807\n",
      "Iteration 136, loss = 0.20819698\n",
      "Iteration 137, loss = 0.20592935\n",
      "Iteration 138, loss = 0.20318257\n",
      "Iteration 139, loss = 0.20112463\n",
      "Iteration 140, loss = 0.19938497\n",
      "Iteration 141, loss = 0.19695483\n",
      "Iteration 142, loss = 0.19448832\n",
      "Iteration 143, loss = 0.19219015\n",
      "Iteration 144, loss = 0.19016994\n",
      "Iteration 145, loss = 0.18821283\n",
      "Iteration 146, loss = 0.18599074\n",
      "Iteration 147, loss = 0.18422964\n",
      "Iteration 148, loss = 0.18261870\n",
      "Iteration 149, loss = 0.18049157\n",
      "Iteration 150, loss = 0.17862336\n",
      "Iteration 151, loss = 0.17658817\n",
      "Iteration 152, loss = 0.17512091\n",
      "Iteration 153, loss = 0.17277945\n",
      "Iteration 154, loss = 0.17143461\n",
      "Iteration 155, loss = 0.16953045\n",
      "Iteration 156, loss = 0.16759579\n",
      "Iteration 157, loss = 0.16593310\n",
      "Iteration 158, loss = 0.16474714\n",
      "Iteration 159, loss = 0.16282972\n",
      "Iteration 160, loss = 0.16139491\n",
      "Iteration 161, loss = 0.15995103\n",
      "Iteration 162, loss = 0.15811383\n",
      "Iteration 163, loss = 0.15674313\n",
      "Iteration 164, loss = 0.15517774\n",
      "Iteration 165, loss = 0.15376795\n",
      "Iteration 166, loss = 0.15241225\n",
      "Iteration 167, loss = 0.15077035\n",
      "Iteration 168, loss = 0.14931782\n",
      "Iteration 169, loss = 0.14800046\n",
      "Iteration 170, loss = 0.14655841\n",
      "Iteration 171, loss = 0.14512184\n",
      "Iteration 172, loss = 0.14430608\n",
      "Iteration 173, loss = 0.14262715\n",
      "Iteration 174, loss = 0.14147225\n",
      "Iteration 175, loss = 0.14007233\n",
      "Iteration 176, loss = 0.13867286\n",
      "Iteration 177, loss = 0.13779971\n",
      "Iteration 178, loss = 0.13614189\n",
      "Iteration 179, loss = 0.13521686\n",
      "Iteration 180, loss = 0.13402851\n",
      "Iteration 181, loss = 0.13298224\n",
      "Iteration 182, loss = 0.13158191\n",
      "Iteration 183, loss = 0.13091976\n",
      "Iteration 184, loss = 0.12946209\n",
      "Iteration 185, loss = 0.12843424\n",
      "Iteration 186, loss = 0.12722025\n",
      "Iteration 187, loss = 0.12606506\n",
      "Iteration 188, loss = 0.12513385\n",
      "Iteration 189, loss = 0.12397712\n",
      "Iteration 190, loss = 0.12303982\n",
      "Iteration 191, loss = 0.12192599\n",
      "Iteration 192, loss = 0.12118540\n",
      "Iteration 193, loss = 0.12011229\n",
      "Iteration 194, loss = 0.11902348\n",
      "Iteration 195, loss = 0.11833788\n",
      "Iteration 196, loss = 0.11725797\n",
      "Iteration 197, loss = 0.11604579\n",
      "Iteration 198, loss = 0.11549879\n",
      "Iteration 199, loss = 0.11453971\n",
      "Iteration 200, loss = 0.11348562\n",
      "Iteration 201, loss = 0.11271014\n",
      "Iteration 202, loss = 0.11184574\n",
      "Iteration 203, loss = 0.11078856\n",
      "Iteration 204, loss = 0.11020917\n",
      "Iteration 205, loss = 0.10930323\n",
      "Iteration 206, loss = 0.10850250\n",
      "Iteration 207, loss = 0.10744229\n",
      "Iteration 208, loss = 0.10683273\n",
      "Iteration 209, loss = 0.10587065\n",
      "Iteration 210, loss = 0.10535131\n",
      "Iteration 211, loss = 0.10467204\n",
      "Iteration 212, loss = 0.10368789\n",
      "Iteration 213, loss = 0.10302804\n",
      "Iteration 214, loss = 0.10248892\n",
      "Iteration 215, loss = 0.10157965\n",
      "Iteration 216, loss = 0.10076664\n",
      "Iteration 217, loss = 0.10022637\n",
      "Iteration 218, loss = 0.09941799\n",
      "Iteration 219, loss = 0.09870604\n",
      "Iteration 220, loss = 0.09805520\n",
      "Iteration 221, loss = 0.09727673\n",
      "Iteration 222, loss = 0.09672400\n",
      "Iteration 223, loss = 0.09610762\n",
      "Iteration 224, loss = 0.09546185\n",
      "Iteration 225, loss = 0.09481178\n",
      "Iteration 226, loss = 0.09422092\n",
      "Iteration 227, loss = 0.09356621\n",
      "Iteration 228, loss = 0.09292427\n",
      "Iteration 229, loss = 0.09234703\n",
      "Iteration 230, loss = 0.09154780\n",
      "Iteration 231, loss = 0.09116365\n",
      "Iteration 232, loss = 0.09047250\n",
      "Iteration 233, loss = 0.09004131\n",
      "Iteration 234, loss = 0.08936616\n",
      "Iteration 235, loss = 0.08885564\n",
      "Iteration 236, loss = 0.08820695\n",
      "Iteration 237, loss = 0.08749100\n",
      "Iteration 238, loss = 0.08727527\n",
      "Iteration 239, loss = 0.08652396\n",
      "Iteration 240, loss = 0.08608779\n",
      "Iteration 241, loss = 0.08554535\n",
      "Iteration 242, loss = 0.08501101\n",
      "Iteration 243, loss = 0.08450900\n",
      "Iteration 244, loss = 0.08386397\n",
      "Iteration 245, loss = 0.08343973\n",
      "Iteration 246, loss = 0.08293502\n",
      "Iteration 247, loss = 0.08245518\n",
      "Iteration 248, loss = 0.08190525\n",
      "Iteration 249, loss = 0.08142579\n",
      "Iteration 250, loss = 0.08087739\n",
      "Iteration 251, loss = 0.08058237\n",
      "Iteration 252, loss = 0.07996684\n",
      "Iteration 253, loss = 0.07941003\n",
      "Iteration 254, loss = 0.07909255\n",
      "Iteration 255, loss = 0.07873914\n",
      "Iteration 256, loss = 0.07825658\n",
      "Iteration 257, loss = 0.07781730\n",
      "Iteration 258, loss = 0.07733891\n",
      "Iteration 259, loss = 0.07699726\n",
      "Iteration 260, loss = 0.07645686\n",
      "Iteration 261, loss = 0.07600619\n",
      "Iteration 262, loss = 0.07564447\n",
      "Iteration 263, loss = 0.07522895\n",
      "Iteration 264, loss = 0.07477167\n",
      "Iteration 265, loss = 0.07448077\n",
      "Iteration 266, loss = 0.07391180\n",
      "Iteration 267, loss = 0.07354199\n",
      "Iteration 268, loss = 0.07312457\n",
      "Iteration 269, loss = 0.07277911\n",
      "Iteration 270, loss = 0.07235955\n",
      "Iteration 271, loss = 0.07199347\n",
      "Iteration 272, loss = 0.07160507\n",
      "Iteration 273, loss = 0.07124282\n",
      "Iteration 274, loss = 0.07087873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 275, loss = 0.07055748\n",
      "Iteration 276, loss = 0.07021660\n",
      "Iteration 277, loss = 0.06981383\n",
      "Iteration 278, loss = 0.06944030\n",
      "Iteration 279, loss = 0.06910058\n",
      "Iteration 280, loss = 0.06874581\n",
      "Iteration 281, loss = 0.06836807\n",
      "Iteration 282, loss = 0.06819712\n",
      "Iteration 283, loss = 0.06769244\n",
      "Iteration 284, loss = 0.06745178\n",
      "Iteration 285, loss = 0.06713470\n",
      "Iteration 286, loss = 0.06673338\n",
      "Iteration 287, loss = 0.06650850\n",
      "Iteration 288, loss = 0.06613529\n",
      "Iteration 289, loss = 0.06580907\n",
      "Iteration 290, loss = 0.06552046\n",
      "Iteration 291, loss = 0.06518692\n",
      "Iteration 292, loss = 0.06489363\n",
      "Iteration 293, loss = 0.06458532\n",
      "Iteration 294, loss = 0.06433693\n",
      "Iteration 295, loss = 0.06392932\n",
      "Iteration 296, loss = 0.06369468\n",
      "Iteration 297, loss = 0.06342810\n",
      "Iteration 298, loss = 0.06310827\n",
      "Iteration 299, loss = 0.06288065\n",
      "Iteration 300, loss = 0.06253422\n",
      "Iteration 301, loss = 0.06231723\n",
      "Iteration 302, loss = 0.06201085\n",
      "Iteration 303, loss = 0.06171358\n",
      "Iteration 304, loss = 0.06139961\n",
      "Iteration 305, loss = 0.06118094\n",
      "Iteration 306, loss = 0.06090997\n",
      "Iteration 307, loss = 0.06057598\n",
      "Iteration 308, loss = 0.06035722\n",
      "Iteration 309, loss = 0.06011941\n",
      "Iteration 310, loss = 0.05984132\n",
      "Iteration 311, loss = 0.05958326\n",
      "Iteration 312, loss = 0.05936960\n",
      "Iteration 313, loss = 0.05909377\n",
      "Iteration 314, loss = 0.05888245\n",
      "Iteration 315, loss = 0.05860528\n",
      "Iteration 316, loss = 0.05829017\n",
      "Iteration 317, loss = 0.05816493\n",
      "Iteration 318, loss = 0.05783940\n",
      "Iteration 319, loss = 0.05761489\n",
      "Iteration 320, loss = 0.05744142\n",
      "Iteration 321, loss = 0.05720725\n",
      "Iteration 322, loss = 0.05693940\n",
      "Iteration 323, loss = 0.05673341\n",
      "Iteration 324, loss = 0.05655516\n",
      "Iteration 325, loss = 0.05628114\n",
      "Iteration 326, loss = 0.05610384\n",
      "Iteration 327, loss = 0.05579303\n",
      "Iteration 328, loss = 0.05562795\n",
      "Iteration 329, loss = 0.05542267\n",
      "Iteration 330, loss = 0.05517187\n",
      "Iteration 331, loss = 0.05501162\n",
      "Iteration 332, loss = 0.05473151\n",
      "Iteration 333, loss = 0.05454223\n",
      "Iteration 334, loss = 0.05433628\n",
      "Iteration 335, loss = 0.05415459\n",
      "Iteration 336, loss = 0.05392846\n",
      "Iteration 337, loss = 0.05372121\n",
      "Iteration 338, loss = 0.05352291\n",
      "Iteration 339, loss = 0.05331461\n",
      "Iteration 340, loss = 0.05313169\n",
      "Iteration 341, loss = 0.05292070\n",
      "Iteration 342, loss = 0.05275136\n",
      "Iteration 343, loss = 0.05254004\n",
      "Iteration 344, loss = 0.05235367\n",
      "Iteration 345, loss = 0.05218249\n",
      "Iteration 346, loss = 0.05199756\n",
      "Iteration 347, loss = 0.05180812\n",
      "Iteration 348, loss = 0.05163243\n",
      "Iteration 349, loss = 0.05145765\n",
      "Iteration 350, loss = 0.05131974\n",
      "Iteration 351, loss = 0.05101733\n",
      "Iteration 352, loss = 0.05090283\n",
      "Iteration 353, loss = 0.05066494\n",
      "Iteration 354, loss = 0.05053734\n",
      "Iteration 355, loss = 0.05036446\n",
      "Iteration 356, loss = 0.05017553\n",
      "Iteration 357, loss = 0.05003100\n",
      "Iteration 358, loss = 0.04979142\n",
      "Iteration 359, loss = 0.04967742\n",
      "Iteration 360, loss = 0.04947698\n",
      "Iteration 361, loss = 0.04937774\n",
      "Iteration 362, loss = 0.04914525\n",
      "Iteration 363, loss = 0.04897842\n",
      "Iteration 364, loss = 0.04882686\n",
      "Iteration 365, loss = 0.04863865\n",
      "Iteration 366, loss = 0.04852485\n",
      "Iteration 367, loss = 0.04836738\n",
      "Iteration 368, loss = 0.04819779\n",
      "Iteration 369, loss = 0.04795770\n",
      "Iteration 370, loss = 0.04786714\n",
      "Iteration 371, loss = 0.04768174\n",
      "Iteration 372, loss = 0.04754309\n",
      "Iteration 373, loss = 0.04740596\n",
      "Iteration 374, loss = 0.04723682\n",
      "Iteration 375, loss = 0.04705886\n",
      "Iteration 376, loss = 0.04692453\n",
      "Iteration 377, loss = 0.04673927\n",
      "Iteration 378, loss = 0.04661722\n",
      "Iteration 379, loss = 0.04649142\n",
      "Iteration 380, loss = 0.04633523\n",
      "Iteration 381, loss = 0.04618253\n",
      "Iteration 382, loss = 0.04603491\n",
      "Iteration 383, loss = 0.04594162\n",
      "Iteration 384, loss = 0.04576532\n",
      "Iteration 385, loss = 0.04564341\n",
      "Iteration 386, loss = 0.04547156\n",
      "Iteration 387, loss = 0.04534423\n",
      "Iteration 388, loss = 0.04518295\n",
      "Iteration 389, loss = 0.04503119\n",
      "Iteration 390, loss = 0.04490098\n",
      "Iteration 391, loss = 0.04477583\n",
      "Iteration 392, loss = 0.04464936\n",
      "Iteration 393, loss = 0.04448325\n",
      "Iteration 394, loss = 0.04434118\n",
      "Iteration 395, loss = 0.04421369\n",
      "Iteration 396, loss = 0.04409371\n",
      "Iteration 397, loss = 0.04392514\n",
      "Iteration 398, loss = 0.04381288\n",
      "Iteration 399, loss = 0.04363538\n",
      "Iteration 400, loss = 0.04354570\n",
      "The training Accuracy achieved is = 99.823\n",
      "The test Accuracy achieved is = 85.600\n",
      "The number of epochs is = 400\n",
      "The training time achieved is = 164.379\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.3, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.41860791\n",
      "Iteration 2, loss = 3.92305683\n",
      "Iteration 3, loss = 3.69283761\n",
      "Iteration 4, loss = 3.52263524\n",
      "Iteration 5, loss = 3.40990751\n",
      "Iteration 6, loss = 3.33047392\n",
      "Iteration 7, loss = 3.26896842\n",
      "Iteration 8, loss = 3.21575387\n",
      "Iteration 9, loss = 3.16705091\n",
      "Iteration 10, loss = 3.12102187\n",
      "Iteration 11, loss = 3.07501018\n",
      "Iteration 12, loss = 3.02956877\n",
      "Iteration 13, loss = 2.98388107\n",
      "Iteration 14, loss = 2.93721307\n",
      "Iteration 15, loss = 2.88950653\n",
      "Iteration 16, loss = 2.84111614\n",
      "Iteration 17, loss = 2.79153026\n",
      "Iteration 18, loss = 2.74044094\n",
      "Iteration 19, loss = 2.68632518\n",
      "Iteration 20, loss = 2.62973349\n",
      "Iteration 21, loss = 2.56902273\n",
      "Iteration 22, loss = 2.50463604\n",
      "Iteration 23, loss = 2.43767358\n",
      "Iteration 24, loss = 2.36900746\n",
      "Iteration 25, loss = 2.29983465\n",
      "Iteration 26, loss = 2.23232025\n",
      "Iteration 27, loss = 2.16772469\n",
      "Iteration 28, loss = 2.10575973\n",
      "Iteration 29, loss = 2.04804989\n",
      "Iteration 30, loss = 1.99381292\n",
      "Iteration 31, loss = 1.94346792\n",
      "Iteration 32, loss = 1.89556825\n",
      "Iteration 33, loss = 1.85023173\n",
      "Iteration 34, loss = 1.80778357\n",
      "Iteration 35, loss = 1.76731965\n",
      "Iteration 36, loss = 1.72812936\n",
      "Iteration 37, loss = 1.69083523\n",
      "Iteration 38, loss = 1.65586008\n",
      "Iteration 39, loss = 1.62215866\n",
      "Iteration 40, loss = 1.58899498\n",
      "Iteration 41, loss = 1.55745925\n",
      "Iteration 42, loss = 1.52657202\n",
      "Iteration 43, loss = 1.49693108\n",
      "Iteration 44, loss = 1.46752700\n",
      "Iteration 45, loss = 1.44051159\n",
      "Iteration 46, loss = 1.41330953\n",
      "Iteration 47, loss = 1.38694901\n",
      "Iteration 48, loss = 1.36150273\n",
      "Iteration 49, loss = 1.33667015\n",
      "Iteration 50, loss = 1.31282337\n",
      "Iteration 51, loss = 1.28877891\n",
      "Iteration 52, loss = 1.26721150\n",
      "Iteration 53, loss = 1.24516909\n",
      "Iteration 54, loss = 1.22419181\n",
      "Iteration 55, loss = 1.20307213\n",
      "Iteration 56, loss = 1.18291382\n",
      "Iteration 57, loss = 1.16416743\n",
      "Iteration 58, loss = 1.14518266\n",
      "Iteration 59, loss = 1.12677190\n",
      "Iteration 60, loss = 1.10965175\n",
      "Iteration 61, loss = 1.09278054\n",
      "Iteration 62, loss = 1.07546648\n",
      "Iteration 63, loss = 1.05977865\n",
      "Iteration 64, loss = 1.04454725\n",
      "Iteration 65, loss = 1.02883183\n",
      "Iteration 66, loss = 1.01350632\n",
      "Iteration 67, loss = 0.99961127\n",
      "Iteration 68, loss = 0.98503293\n",
      "Iteration 69, loss = 0.97109510\n",
      "Iteration 70, loss = 0.95849640\n",
      "Iteration 71, loss = 0.94539227\n",
      "Iteration 72, loss = 0.93305307\n",
      "Iteration 73, loss = 0.92072734\n",
      "Iteration 74, loss = 0.90938124\n",
      "Iteration 75, loss = 0.89802033\n",
      "Iteration 76, loss = 0.88724909\n",
      "Iteration 77, loss = 0.87712277\n",
      "Iteration 78, loss = 0.86611978\n",
      "Iteration 79, loss = 0.85633038\n",
      "Iteration 80, loss = 0.84719305\n",
      "Iteration 81, loss = 0.83716606\n",
      "Iteration 82, loss = 0.82779693\n",
      "Iteration 83, loss = 0.81883388\n",
      "Iteration 84, loss = 0.80975669\n",
      "Iteration 85, loss = 0.80141231\n",
      "Iteration 86, loss = 0.79222655\n",
      "Iteration 87, loss = 0.78455586\n",
      "Iteration 88, loss = 0.77649669\n",
      "Iteration 89, loss = 0.76861530\n",
      "Iteration 90, loss = 0.76101663\n",
      "Iteration 91, loss = 0.75308322\n",
      "Iteration 92, loss = 0.74604972\n",
      "Iteration 93, loss = 0.73890633\n",
      "Iteration 94, loss = 0.73138225\n",
      "Iteration 95, loss = 0.72439787\n",
      "Iteration 96, loss = 0.71756736\n",
      "Iteration 97, loss = 0.71112637\n",
      "Iteration 98, loss = 0.70416714\n",
      "Iteration 99, loss = 0.69719153\n",
      "Iteration 100, loss = 0.69147355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 101, loss = 0.68473413\n",
      "Iteration 102, loss = 0.67802450\n",
      "Iteration 103, loss = 0.67195478\n",
      "Iteration 104, loss = 0.66561303\n",
      "Iteration 105, loss = 0.65989320\n",
      "Iteration 106, loss = 0.65461498\n",
      "Iteration 107, loss = 0.64822412\n",
      "Iteration 108, loss = 0.64220850\n",
      "Iteration 109, loss = 0.63660359\n",
      "Iteration 110, loss = 0.63122280\n",
      "Iteration 111, loss = 0.62552928\n",
      "Iteration 112, loss = 0.62031232\n",
      "Iteration 113, loss = 0.61445731\n",
      "Iteration 114, loss = 0.60911162\n",
      "Iteration 115, loss = 0.60465334\n",
      "Iteration 116, loss = 0.59933084\n",
      "Iteration 117, loss = 0.59382760\n",
      "Iteration 118, loss = 0.58915062\n",
      "Iteration 119, loss = 0.58460169\n",
      "Iteration 120, loss = 0.57980956\n",
      "Iteration 121, loss = 0.57469338\n",
      "Iteration 122, loss = 0.56973948\n",
      "Iteration 123, loss = 0.56566116\n",
      "Iteration 124, loss = 0.56092946\n",
      "Iteration 125, loss = 0.55613936\n",
      "Iteration 126, loss = 0.55142383\n",
      "Iteration 127, loss = 0.54755226\n",
      "Iteration 128, loss = 0.54314335\n",
      "Iteration 129, loss = 0.53878096\n",
      "Iteration 130, loss = 0.53458791\n",
      "Iteration 131, loss = 0.53047494\n",
      "Iteration 132, loss = 0.52620569\n",
      "Iteration 133, loss = 0.52290687\n",
      "Iteration 134, loss = 0.51840489\n",
      "Iteration 135, loss = 0.51454013\n",
      "Iteration 136, loss = 0.51046183\n",
      "Iteration 137, loss = 0.50721535\n",
      "Iteration 138, loss = 0.50291761\n",
      "Iteration 139, loss = 0.49900886\n",
      "Iteration 140, loss = 0.49532599\n",
      "Iteration 141, loss = 0.49179771\n",
      "Iteration 142, loss = 0.48806758\n",
      "Iteration 143, loss = 0.48463251\n",
      "Iteration 144, loss = 0.48066276\n",
      "Iteration 145, loss = 0.47771127\n",
      "Iteration 146, loss = 0.47416149\n",
      "Iteration 147, loss = 0.47072447\n",
      "Iteration 148, loss = 0.46711550\n",
      "Iteration 149, loss = 0.46394600\n",
      "Iteration 150, loss = 0.46026839\n",
      "Iteration 151, loss = 0.45756959\n",
      "Iteration 152, loss = 0.45453937\n",
      "Iteration 153, loss = 0.45102427\n",
      "Iteration 154, loss = 0.44820941\n",
      "Iteration 155, loss = 0.44492132\n",
      "Iteration 156, loss = 0.44186554\n",
      "Iteration 157, loss = 0.43850080\n",
      "Iteration 158, loss = 0.43598419\n",
      "Iteration 159, loss = 0.43259973\n",
      "Iteration 160, loss = 0.42948696\n",
      "Iteration 161, loss = 0.42656767\n",
      "Iteration 162, loss = 0.42376721\n",
      "Iteration 163, loss = 0.42077531\n",
      "Iteration 164, loss = 0.41867372\n",
      "Iteration 165, loss = 0.41559242\n",
      "Iteration 166, loss = 0.41272623\n",
      "Iteration 167, loss = 0.41003484\n",
      "Iteration 168, loss = 0.40665734\n",
      "Iteration 169, loss = 0.40415167\n",
      "Iteration 170, loss = 0.40193775\n",
      "Iteration 171, loss = 0.39929994\n",
      "Iteration 172, loss = 0.39662760\n",
      "Iteration 173, loss = 0.39393069\n",
      "Iteration 174, loss = 0.39077793\n",
      "Iteration 175, loss = 0.38911379\n",
      "Iteration 176, loss = 0.38653894\n",
      "Iteration 177, loss = 0.38341717\n",
      "Iteration 178, loss = 0.38167682\n",
      "Iteration 179, loss = 0.37903440\n",
      "Iteration 180, loss = 0.37613452\n",
      "Iteration 181, loss = 0.37437713\n",
      "Iteration 182, loss = 0.37185902\n",
      "Iteration 183, loss = 0.36967618\n",
      "Iteration 184, loss = 0.36733007\n",
      "Iteration 185, loss = 0.36459175\n",
      "Iteration 186, loss = 0.36309490\n",
      "Iteration 187, loss = 0.36032343\n",
      "Iteration 188, loss = 0.35797884\n",
      "Iteration 189, loss = 0.35607148\n",
      "Iteration 190, loss = 0.35364556\n",
      "Iteration 191, loss = 0.35130935\n",
      "Iteration 192, loss = 0.34994444\n",
      "Iteration 193, loss = 0.34762320\n",
      "Iteration 194, loss = 0.34557453\n",
      "Iteration 195, loss = 0.34333824\n",
      "Iteration 196, loss = 0.34143923\n",
      "Iteration 197, loss = 0.33903238\n",
      "Iteration 198, loss = 0.33741833\n",
      "Iteration 199, loss = 0.33517691\n",
      "Iteration 200, loss = 0.33341192\n",
      "Iteration 201, loss = 0.33124917\n",
      "Iteration 202, loss = 0.32954148\n",
      "Iteration 203, loss = 0.32748036\n",
      "Iteration 204, loss = 0.32606919\n",
      "Iteration 205, loss = 0.32355451\n",
      "Iteration 206, loss = 0.32174350\n",
      "Iteration 207, loss = 0.32009954\n",
      "Iteration 208, loss = 0.31843028\n",
      "Iteration 209, loss = 0.31630607\n",
      "Iteration 210, loss = 0.31480616\n",
      "Iteration 211, loss = 0.31303979\n",
      "Iteration 212, loss = 0.31104779\n",
      "Iteration 213, loss = 0.30949666\n",
      "Iteration 214, loss = 0.30738320\n",
      "Iteration 215, loss = 0.30549870\n",
      "Iteration 216, loss = 0.30399633\n",
      "Iteration 217, loss = 0.30268424\n",
      "Iteration 218, loss = 0.30070662\n",
      "Iteration 219, loss = 0.29925437\n",
      "Iteration 220, loss = 0.29748293\n",
      "Iteration 221, loss = 0.29578487\n",
      "Iteration 222, loss = 0.29417353\n",
      "Iteration 223, loss = 0.29258435\n",
      "Iteration 224, loss = 0.29102059\n",
      "Iteration 225, loss = 0.28938000\n",
      "Iteration 226, loss = 0.28765632\n",
      "Iteration 227, loss = 0.28628326\n",
      "Iteration 228, loss = 0.28493913\n",
      "Iteration 229, loss = 0.28321343\n",
      "Iteration 230, loss = 0.28187198\n",
      "Iteration 231, loss = 0.28013442\n",
      "Iteration 232, loss = 0.27882805\n",
      "Iteration 233, loss = 0.27702538\n",
      "Iteration 234, loss = 0.27540364\n",
      "Iteration 235, loss = 0.27416667\n",
      "Iteration 236, loss = 0.27254522\n",
      "Iteration 237, loss = 0.27109239\n",
      "Iteration 238, loss = 0.27007164\n",
      "Iteration 239, loss = 0.26841797\n",
      "Iteration 240, loss = 0.26746394\n",
      "Iteration 241, loss = 0.26588663\n",
      "Iteration 242, loss = 0.26454229\n",
      "Iteration 243, loss = 0.26263406\n",
      "Iteration 244, loss = 0.26183711\n",
      "Iteration 245, loss = 0.26041082\n",
      "Iteration 246, loss = 0.25894190\n",
      "Iteration 247, loss = 0.25784742\n",
      "Iteration 248, loss = 0.25619616\n",
      "Iteration 249, loss = 0.25484157\n",
      "Iteration 250, loss = 0.25382218\n",
      "Iteration 251, loss = 0.25210428\n",
      "Iteration 252, loss = 0.25094923\n",
      "Iteration 253, loss = 0.25007843\n",
      "Iteration 254, loss = 0.24836344\n",
      "Iteration 255, loss = 0.24739915\n",
      "Iteration 256, loss = 0.24597038\n",
      "Iteration 257, loss = 0.24477255\n",
      "Iteration 258, loss = 0.24354855\n",
      "Iteration 259, loss = 0.24237610\n",
      "Iteration 260, loss = 0.24117301\n",
      "Iteration 261, loss = 0.24014043\n",
      "Iteration 262, loss = 0.23883540\n",
      "Iteration 263, loss = 0.23757238\n",
      "Iteration 264, loss = 0.23650233\n",
      "Iteration 265, loss = 0.23532055\n",
      "Iteration 266, loss = 0.23383227\n",
      "Iteration 267, loss = 0.23300357\n",
      "Iteration 268, loss = 0.23186999\n",
      "Iteration 269, loss = 0.23057254\n",
      "Iteration 270, loss = 0.22957197\n",
      "Iteration 271, loss = 0.22866173\n",
      "Iteration 272, loss = 0.22714703\n",
      "Iteration 273, loss = 0.22660764\n",
      "Iteration 274, loss = 0.22521611\n",
      "Iteration 275, loss = 0.22422350\n",
      "Iteration 276, loss = 0.22318779\n",
      "Iteration 277, loss = 0.22183830\n",
      "Iteration 278, loss = 0.22086281\n",
      "Iteration 279, loss = 0.21969117\n",
      "Iteration 280, loss = 0.21887058\n",
      "Iteration 281, loss = 0.21793776\n",
      "Iteration 282, loss = 0.21663860\n",
      "Iteration 283, loss = 0.21571251\n",
      "Iteration 284, loss = 0.21465214\n",
      "Iteration 285, loss = 0.21358979\n",
      "Iteration 286, loss = 0.21265332\n",
      "Iteration 287, loss = 0.21175628\n",
      "Iteration 288, loss = 0.21048716\n",
      "Iteration 289, loss = 0.20979676\n",
      "Iteration 290, loss = 0.20883081\n",
      "Iteration 291, loss = 0.20784543\n",
      "Iteration 292, loss = 0.20690848\n",
      "Iteration 293, loss = 0.20576436\n",
      "Iteration 294, loss = 0.20528777\n",
      "Iteration 295, loss = 0.20400591\n",
      "Iteration 296, loss = 0.20323107\n",
      "Iteration 297, loss = 0.20226888\n",
      "Iteration 298, loss = 0.20115194\n",
      "Iteration 299, loss = 0.20050120\n",
      "Iteration 300, loss = 0.19951151\n",
      "Iteration 301, loss = 0.19860446\n",
      "Iteration 302, loss = 0.19784666\n",
      "Iteration 303, loss = 0.19706907\n",
      "Iteration 304, loss = 0.19615698\n",
      "Iteration 305, loss = 0.19507382\n",
      "Iteration 306, loss = 0.19433078\n",
      "Iteration 307, loss = 0.19335057\n",
      "Iteration 308, loss = 0.19244227\n",
      "Iteration 309, loss = 0.19174385\n",
      "Iteration 310, loss = 0.19085076\n",
      "Iteration 311, loss = 0.18975689\n",
      "Iteration 312, loss = 0.18916620\n",
      "Iteration 313, loss = 0.18853216\n",
      "Iteration 314, loss = 0.18773461\n",
      "Iteration 315, loss = 0.18683164\n",
      "Iteration 316, loss = 0.18614903\n",
      "Iteration 317, loss = 0.18510848\n",
      "Iteration 318, loss = 0.18443225\n",
      "Iteration 319, loss = 0.18361306\n",
      "Iteration 320, loss = 0.18293076\n",
      "Iteration 321, loss = 0.18191071\n",
      "Iteration 322, loss = 0.18122172\n",
      "Iteration 323, loss = 0.18035109\n",
      "Iteration 324, loss = 0.17964035\n",
      "Iteration 325, loss = 0.17885454\n",
      "Iteration 326, loss = 0.17822525\n",
      "Iteration 327, loss = 0.17737744\n",
      "Iteration 328, loss = 0.17680891\n",
      "Iteration 329, loss = 0.17587024\n",
      "Iteration 330, loss = 0.17523060\n",
      "Iteration 331, loss = 0.17447983\n",
      "Iteration 332, loss = 0.17380686\n",
      "Iteration 333, loss = 0.17324573\n",
      "Iteration 334, loss = 0.17232112\n",
      "Iteration 335, loss = 0.17160025\n",
      "Iteration 336, loss = 0.17090692\n",
      "Iteration 337, loss = 0.17021806\n",
      "Iteration 338, loss = 0.16947458\n",
      "Iteration 339, loss = 0.16884348\n",
      "Iteration 340, loss = 0.16797283\n",
      "Iteration 341, loss = 0.16745488\n",
      "Iteration 342, loss = 0.16668086\n",
      "Iteration 343, loss = 0.16617954\n",
      "Iteration 344, loss = 0.16522123\n",
      "Iteration 345, loss = 0.16490228\n",
      "Iteration 346, loss = 0.16404482\n",
      "Iteration 347, loss = 0.16346339\n",
      "Iteration 348, loss = 0.16283265\n",
      "Iteration 349, loss = 0.16219554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 350, loss = 0.16151394\n",
      "Iteration 351, loss = 0.16078277\n",
      "Iteration 352, loss = 0.16020924\n",
      "Iteration 353, loss = 0.15941608\n",
      "Iteration 354, loss = 0.15892590\n",
      "Iteration 355, loss = 0.15828927\n",
      "Iteration 356, loss = 0.15772549\n",
      "Iteration 357, loss = 0.15699518\n",
      "Iteration 358, loss = 0.15629608\n",
      "Iteration 359, loss = 0.15576000\n",
      "Iteration 360, loss = 0.15509468\n",
      "Iteration 361, loss = 0.15463720\n",
      "Iteration 362, loss = 0.15393751\n",
      "Iteration 363, loss = 0.15324088\n",
      "Iteration 364, loss = 0.15275656\n",
      "Iteration 365, loss = 0.15217961\n",
      "Iteration 366, loss = 0.15172107\n",
      "Iteration 367, loss = 0.15089837\n",
      "Iteration 368, loss = 0.15059529\n",
      "Iteration 369, loss = 0.14990252\n",
      "Iteration 370, loss = 0.14923178\n",
      "Iteration 371, loss = 0.14867130\n",
      "Iteration 372, loss = 0.14816523\n",
      "Iteration 373, loss = 0.14754876\n",
      "Iteration 374, loss = 0.14700140\n",
      "Iteration 375, loss = 0.14642965\n",
      "Iteration 376, loss = 0.14601514\n",
      "Iteration 377, loss = 0.14524276\n",
      "Iteration 378, loss = 0.14477154\n",
      "Iteration 379, loss = 0.14436931\n",
      "Iteration 380, loss = 0.14373423\n",
      "Iteration 381, loss = 0.14319209\n",
      "Iteration 382, loss = 0.14270156\n",
      "Iteration 383, loss = 0.14206675\n",
      "Iteration 384, loss = 0.14156596\n",
      "Iteration 385, loss = 0.14097878\n",
      "Iteration 386, loss = 0.14038958\n",
      "Iteration 387, loss = 0.14003108\n",
      "Iteration 388, loss = 0.13944313\n",
      "Iteration 389, loss = 0.13893834\n",
      "Iteration 390, loss = 0.13835843\n",
      "Iteration 391, loss = 0.13793786\n",
      "Iteration 392, loss = 0.13734127\n",
      "Iteration 393, loss = 0.13696359\n",
      "Iteration 394, loss = 0.13630891\n",
      "Iteration 395, loss = 0.13594968\n",
      "Iteration 396, loss = 0.13531299\n",
      "Iteration 397, loss = 0.13499004\n",
      "Iteration 398, loss = 0.13444737\n",
      "Iteration 399, loss = 0.13395994\n",
      "Iteration 400, loss = 0.13351160\n",
      "The training Accuracy achieved is = 98.754\n",
      "The test Accuracy achieved is = 85.985\n",
      "The number of epochs is = 400\n",
      "The training time achieved is = 161.802\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.03, max_fun=15000, max_iter=400,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=1e-05, validation_fraction=0.1, verbose=True,\n",
      "              warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.50816383\n",
      "Iteration 2, loss = 1.03550767\n",
      "Iteration 3, loss = 0.80031625\n",
      "Iteration 4, loss = 0.65562967\n",
      "Iteration 5, loss = 0.54995677\n",
      "Iteration 6, loss = 0.46658296\n",
      "Iteration 7, loss = 0.40855145\n",
      "Iteration 8, loss = 0.35310345\n",
      "Iteration 9, loss = 0.31109136\n",
      "Iteration 10, loss = 0.27328861\n",
      "Iteration 11, loss = 0.24035228\n",
      "Iteration 12, loss = 0.21033184\n",
      "Iteration 13, loss = 0.18015944\n",
      "Iteration 14, loss = 0.15634685\n",
      "Iteration 15, loss = 0.13872468\n",
      "Iteration 16, loss = 0.11490303\n",
      "Iteration 17, loss = 0.09998127\n",
      "Iteration 18, loss = 0.08469757\n",
      "Iteration 19, loss = 0.07205677\n",
      "Iteration 20, loss = 0.06152100\n",
      "Iteration 21, loss = 0.04817851\n",
      "Iteration 22, loss = 0.04214471\n",
      "Iteration 23, loss = 0.03556062\n",
      "Iteration 24, loss = 0.02900015\n",
      "Iteration 25, loss = 0.02438611\n",
      "Iteration 26, loss = 0.02088990\n",
      "Iteration 27, loss = 0.01700693\n",
      "Iteration 28, loss = 0.01508868\n",
      "Iteration 29, loss = 0.01333514\n",
      "Iteration 30, loss = 0.01200468\n",
      "Iteration 31, loss = 0.01096737\n",
      "Iteration 32, loss = 0.01002612\n",
      "Iteration 33, loss = 0.00930630\n",
      "Iteration 34, loss = 0.00878092\n",
      "Iteration 35, loss = 0.00816508\n",
      "Iteration 36, loss = 0.00774515\n",
      "Iteration 37, loss = 0.00730698\n",
      "Iteration 38, loss = 0.00699837\n",
      "Iteration 39, loss = 0.00667722\n",
      "Iteration 40, loss = 0.00632899\n",
      "Iteration 41, loss = 0.00607510\n",
      "Iteration 42, loss = 0.00585758\n",
      "Iteration 43, loss = 0.00559460\n",
      "Iteration 44, loss = 0.00540806\n",
      "Iteration 45, loss = 0.00521687\n",
      "Iteration 46, loss = 0.00502819\n",
      "Iteration 47, loss = 0.00483502\n",
      "Iteration 48, loss = 0.00470609\n",
      "Iteration 49, loss = 0.00457549\n",
      "Iteration 50, loss = 0.00442761\n",
      "Iteration 51, loss = 0.00432187\n",
      "Iteration 52, loss = 0.00417088\n",
      "Iteration 53, loss = 0.00406345\n",
      "Iteration 54, loss = 0.00397302\n",
      "Iteration 55, loss = 0.00384805\n",
      "Iteration 56, loss = 0.00378185\n",
      "Iteration 57, loss = 0.00368852\n",
      "Iteration 58, loss = 0.00359066\n",
      "Iteration 59, loss = 0.00352527\n",
      "Iteration 60, loss = 0.00345755\n",
      "Iteration 61, loss = 0.00339083\n",
      "Iteration 62, loss = 0.00331779\n",
      "Iteration 63, loss = 0.00325677\n",
      "Iteration 64, loss = 0.00318057\n",
      "Iteration 65, loss = 0.00312447\n",
      "Iteration 66, loss = 0.00306888\n",
      "Iteration 67, loss = 0.00302831\n",
      "Iteration 68, loss = 0.00296707\n",
      "Iteration 69, loss = 0.00291042\n",
      "Iteration 70, loss = 0.00286782\n",
      "Iteration 71, loss = 0.00282112\n",
      "Iteration 72, loss = 0.00278308\n",
      "Iteration 73, loss = 0.00274146\n",
      "Iteration 74, loss = 0.00270168\n",
      "Iteration 75, loss = 0.00265672\n",
      "Iteration 76, loss = 0.00263024\n",
      "Iteration 77, loss = 0.00258818\n",
      "Iteration 78, loss = 0.00255951\n",
      "Iteration 79, loss = 0.00251788\n",
      "Iteration 80, loss = 0.00248601\n",
      "Iteration 81, loss = 0.00245561\n",
      "Iteration 82, loss = 0.00242803\n",
      "Iteration 83, loss = 0.00239440\n",
      "Iteration 84, loss = 0.00237409\n",
      "Iteration 85, loss = 0.00234379\n",
      "Iteration 86, loss = 0.00231379\n",
      "Iteration 87, loss = 0.00229338\n",
      "Iteration 88, loss = 0.00226435\n",
      "Iteration 89, loss = 0.00223859\n",
      "Iteration 90, loss = 0.00221807\n",
      "Iteration 91, loss = 0.00219839\n",
      "Iteration 92, loss = 0.00217207\n",
      "Iteration 93, loss = 0.00215391\n",
      "Iteration 94, loss = 0.00213435\n",
      "Iteration 95, loss = 0.00211181\n",
      "Iteration 96, loss = 0.00209314\n",
      "Iteration 97, loss = 0.00207582\n",
      "Iteration 98, loss = 0.00205340\n",
      "Iteration 99, loss = 0.00203770\n",
      "Iteration 100, loss = 0.00202272\n",
      "Iteration 101, loss = 0.00200419\n",
      "Iteration 102, loss = 0.00198849\n",
      "Iteration 103, loss = 0.00197368\n",
      "Iteration 104, loss = 0.00195758\n",
      "Iteration 105, loss = 0.00194029\n",
      "Iteration 106, loss = 0.00192265\n",
      "Iteration 107, loss = 0.00191210\n",
      "Iteration 108, loss = 0.00189567\n",
      "Iteration 109, loss = 0.00188651\n",
      "Iteration 110, loss = 0.00187229\n",
      "Iteration 111, loss = 0.00185412\n",
      "Iteration 112, loss = 0.00184323\n",
      "Iteration 113, loss = 0.00182986\n",
      "Iteration 114, loss = 0.00181990\n",
      "Iteration 115, loss = 0.00180794\n",
      "Iteration 116, loss = 0.00179747\n",
      "Iteration 117, loss = 0.00178439\n",
      "Iteration 118, loss = 0.00177357\n",
      "Iteration 119, loss = 0.00176334\n",
      "Iteration 120, loss = 0.00175028\n",
      "Iteration 121, loss = 0.00173917\n",
      "Iteration 122, loss = 0.00172981\n",
      "Iteration 123, loss = 0.00172139\n",
      "Iteration 124, loss = 0.00171105\n",
      "Iteration 125, loss = 0.00170145\n",
      "Iteration 126, loss = 0.00168975\n",
      "Iteration 127, loss = 0.00168404\n",
      "Iteration 128, loss = 0.00167474\n",
      "Iteration 129, loss = 0.00166369\n",
      "Iteration 130, loss = 0.00165704\n",
      "Iteration 131, loss = 0.00164781\n",
      "Iteration 132, loss = 0.00163885\n",
      "Iteration 133, loss = 0.00163204\n",
      "Iteration 134, loss = 0.00162407\n",
      "Iteration 135, loss = 0.00161573\n",
      "Iteration 136, loss = 0.00160881\n",
      "Iteration 137, loss = 0.00160036\n",
      "Iteration 138, loss = 0.00159316\n",
      "Iteration 139, loss = 0.00158582\n",
      "Iteration 140, loss = 0.00157948\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 100.000\n",
      "The test Accuracy achieved is = 87.138\n",
      "The number of epochs is = 140\n",
      "The training time achieved is = 54.048\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.28002440\n",
      "Iteration 2, loss = 0.93314845\n",
      "Iteration 3, loss = 0.72801301\n",
      "Iteration 4, loss = 0.61449528\n",
      "Iteration 5, loss = 0.54836739\n",
      "Iteration 6, loss = 0.48893531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.45466208\n",
      "Iteration 8, loss = 0.41740540\n",
      "Iteration 9, loss = 0.40251739\n",
      "Iteration 10, loss = 0.38387278\n",
      "Iteration 11, loss = 0.38546111\n",
      "Iteration 12, loss = 0.31049517\n",
      "Iteration 13, loss = 0.29283614\n",
      "Iteration 14, loss = 0.29064743\n",
      "Iteration 15, loss = 0.28061811\n",
      "Iteration 16, loss = 0.26203566\n",
      "Iteration 17, loss = 0.23036564\n",
      "Iteration 18, loss = 0.25744236\n",
      "Iteration 19, loss = 0.28180248\n",
      "Iteration 20, loss = 0.26243069\n",
      "Iteration 21, loss = 0.23746253\n",
      "Iteration 22, loss = 0.22963996\n",
      "Iteration 23, loss = 0.21726602\n",
      "Iteration 24, loss = 0.29524830\n",
      "Iteration 25, loss = 0.21364457\n",
      "Iteration 26, loss = 0.23123348\n",
      "Iteration 27, loss = 0.22795417\n",
      "Iteration 28, loss = 0.26122991\n",
      "Iteration 29, loss = 0.23128931\n",
      "Iteration 30, loss = 0.23307178\n",
      "Iteration 31, loss = 0.22865244\n",
      "Iteration 32, loss = 0.26366610\n",
      "Iteration 33, loss = 0.22509109\n",
      "Iteration 34, loss = 0.22665693\n",
      "Iteration 35, loss = 0.20683230\n",
      "Iteration 36, loss = 0.21010729\n",
      "Iteration 37, loss = 0.23322607\n",
      "Iteration 38, loss = 0.23006940\n",
      "Iteration 39, loss = 0.27472534\n",
      "Iteration 40, loss = 0.30832348\n",
      "Iteration 41, loss = 0.24362074\n",
      "Iteration 42, loss = 0.24378863\n",
      "Iteration 43, loss = 0.27747537\n",
      "Iteration 44, loss = 0.28507226\n",
      "Iteration 45, loss = 0.26051795\n",
      "Iteration 46, loss = 0.24829271\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 95.100\n",
      "The test Accuracy achieved is = 83.800\n",
      "The number of epochs is = 46\n",
      "The training time achieved is = 17.847\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.20622490\n",
      "Validation score: 0.721538\n",
      "Iteration 2, loss = 0.82468036\n",
      "Validation score: 0.795385\n",
      "Iteration 3, loss = 0.63752924\n",
      "Validation score: 0.788462\n",
      "Iteration 4, loss = 0.52529713\n",
      "Validation score: 0.835385\n",
      "Iteration 5, loss = 0.45804845\n",
      "Validation score: 0.841538\n",
      "Iteration 6, loss = 0.40087818\n",
      "Validation score: 0.833846\n",
      "Iteration 7, loss = 0.35909792\n",
      "Validation score: 0.843846\n",
      "Iteration 8, loss = 0.32292334\n",
      "Validation score: 0.853846\n",
      "Iteration 9, loss = 0.28772920\n",
      "Validation score: 0.861538\n",
      "Iteration 10, loss = 0.28075918\n",
      "Validation score: 0.852308\n",
      "Iteration 11, loss = 0.25526977\n",
      "Validation score: 0.859231\n",
      "Iteration 12, loss = 0.26589626\n",
      "Validation score: 0.856154\n",
      "Iteration 13, loss = 0.23561895\n",
      "Validation score: 0.855385\n",
      "Iteration 14, loss = 0.23430291\n",
      "Validation score: 0.843846\n",
      "Iteration 15, loss = 0.21951470\n",
      "Validation score: 0.856923\n",
      "Iteration 16, loss = 0.19478360\n",
      "Validation score: 0.870000\n",
      "Iteration 17, loss = 0.16384635\n",
      "Validation score: 0.860000\n",
      "Iteration 18, loss = 0.21333081\n",
      "Validation score: 0.865385\n",
      "Iteration 19, loss = 0.21018309\n",
      "Validation score: 0.859231\n",
      "Iteration 20, loss = 0.19926010\n",
      "Validation score: 0.842308\n",
      "Iteration 21, loss = 0.20578398\n",
      "Validation score: 0.860769\n",
      "Iteration 22, loss = 0.21082835\n",
      "Validation score: 0.866923\n",
      "Iteration 23, loss = 0.21561982\n",
      "Validation score: 0.847692\n",
      "Iteration 24, loss = 0.22850654\n",
      "Validation score: 0.838462\n",
      "Iteration 25, loss = 0.24207469\n",
      "Validation score: 0.867692\n",
      "Iteration 26, loss = 0.21472789\n",
      "Validation score: 0.859231\n",
      "Iteration 27, loss = 0.16972725\n",
      "Validation score: 0.853846\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 94.485\n",
      "The test Accuracy achieved is = 83.954\n",
      "The number of epochs is = 27\n",
      "The training time achieved is = 9.879\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.73069938\n",
      "Iteration 2, loss = 1.56754722\n",
      "Iteration 3, loss = 1.22990585\n",
      "Iteration 4, loss = 1.16991265\n",
      "Iteration 5, loss = 1.13561008\n",
      "Iteration 6, loss = 1.11233189\n",
      "Iteration 7, loss = 1.09477943\n",
      "Iteration 8, loss = 1.08093597\n",
      "Iteration 9, loss = 1.06987084\n",
      "Iteration 10, loss = 1.06043249\n",
      "Iteration 11, loss = 1.05250075\n",
      "Iteration 12, loss = 1.04554116\n",
      "Iteration 13, loss = 1.03944531\n",
      "Iteration 14, loss = 1.03413500\n",
      "Iteration 15, loss = 1.02942758\n",
      "Iteration 16, loss = 1.02514721\n",
      "Iteration 17, loss = 1.02121338\n",
      "Iteration 18, loss = 1.01770199\n",
      "Iteration 19, loss = 1.01428754\n",
      "Iteration 20, loss = 1.01124867\n",
      "Iteration 21, loss = 1.00827942\n",
      "Iteration 22, loss = 1.00553671\n",
      "Iteration 23, loss = 1.00299230\n",
      "Iteration 24, loss = 1.00054891\n",
      "Iteration 25, loss = 0.99819390\n",
      "Iteration 26, loss = 0.99612769\n",
      "Iteration 27, loss = 0.99403191\n",
      "Iteration 28, loss = 0.99200976\n",
      "Iteration 29, loss = 0.99008519\n",
      "Iteration 30, loss = 0.98819271\n",
      "Iteration 31, loss = 0.98646392\n",
      "Iteration 32, loss = 0.98476812\n",
      "Iteration 33, loss = 0.98317449\n",
      "Iteration 34, loss = 0.98157414\n",
      "Iteration 35, loss = 0.98001716\n",
      "Iteration 36, loss = 0.97860030\n",
      "Iteration 37, loss = 0.97719309\n",
      "Iteration 38, loss = 0.97579893\n",
      "Iteration 39, loss = 0.97449043\n",
      "Iteration 40, loss = 0.97309923\n",
      "Iteration 41, loss = 0.97186980\n",
      "Iteration 42, loss = 0.97061660\n",
      "Iteration 43, loss = 0.96939761\n",
      "Iteration 44, loss = 0.96821220\n",
      "Iteration 45, loss = 0.96707385\n",
      "Iteration 46, loss = 0.96597914\n",
      "Iteration 47, loss = 0.96480615\n",
      "Iteration 48, loss = 0.96371473\n",
      "Iteration 49, loss = 0.96265340\n",
      "Iteration 50, loss = 0.96162773\n",
      "Iteration 51, loss = 0.96061160\n",
      "Iteration 52, loss = 0.95964258\n",
      "Iteration 53, loss = 0.95867207\n",
      "Iteration 54, loss = 0.95768965\n",
      "Iteration 55, loss = 0.95677520\n",
      "Iteration 56, loss = 0.95587059\n",
      "Iteration 57, loss = 0.95495740\n",
      "Iteration 58, loss = 0.95413856\n",
      "Iteration 59, loss = 0.95313865\n",
      "Iteration 60, loss = 0.95230443\n",
      "Iteration 61, loss = 0.95146209\n",
      "Iteration 62, loss = 0.95061197\n",
      "Iteration 63, loss = 0.94980701\n",
      "Iteration 64, loss = 0.94900130\n",
      "Iteration 65, loss = 0.94818868\n",
      "Iteration 66, loss = 0.94735442\n",
      "Iteration 67, loss = 0.94666433\n",
      "Iteration 68, loss = 0.94584680\n",
      "Iteration 69, loss = 0.94513167\n",
      "Iteration 70, loss = 0.94443642\n",
      "Iteration 71, loss = 0.94365084\n",
      "Iteration 72, loss = 0.94294501\n",
      "Iteration 73, loss = 0.94220648\n",
      "Iteration 74, loss = 0.94150838\n",
      "Iteration 75, loss = 0.94078014\n",
      "Iteration 76, loss = 0.94013356\n",
      "Iteration 77, loss = 0.93946519\n",
      "Iteration 78, loss = 0.93877795\n",
      "Iteration 79, loss = 0.93810190\n",
      "Iteration 80, loss = 0.93747966\n",
      "Iteration 81, loss = 0.93685686\n",
      "Iteration 82, loss = 0.93613788\n",
      "Iteration 83, loss = 0.93550625\n",
      "Iteration 84, loss = 0.93493129\n",
      "Iteration 85, loss = 0.93429399\n",
      "Iteration 86, loss = 0.93366307\n",
      "Iteration 87, loss = 0.93306444\n",
      "Iteration 88, loss = 0.93249977\n",
      "Iteration 89, loss = 0.93186505\n",
      "Iteration 90, loss = 0.93124324\n",
      "Iteration 91, loss = 0.93068502\n",
      "Iteration 92, loss = 0.93011523\n",
      "Iteration 93, loss = 0.92953503\n",
      "Iteration 94, loss = 0.92897212\n",
      "Iteration 95, loss = 0.92844283\n",
      "Iteration 96, loss = 0.92785112\n",
      "Iteration 97, loss = 0.92733312\n",
      "Iteration 98, loss = 0.92675049\n",
      "Iteration 99, loss = 0.92619843\n",
      "Iteration 100, loss = 0.92563810\n",
      "Iteration 101, loss = 0.92515549\n",
      "Iteration 102, loss = 0.92458527\n",
      "Iteration 103, loss = 0.92403709\n",
      "Iteration 104, loss = 0.92354200\n",
      "Iteration 105, loss = 0.92303621\n",
      "Iteration 106, loss = 0.92253363\n",
      "Iteration 107, loss = 0.92200707\n",
      "Iteration 108, loss = 0.92146465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 109, loss = 0.92095441\n",
      "Iteration 110, loss = 0.92045281\n",
      "Iteration 111, loss = 0.91997026\n",
      "Iteration 112, loss = 0.91946343\n",
      "Iteration 113, loss = 0.91898389\n",
      "Iteration 114, loss = 0.91854619\n",
      "Iteration 115, loss = 0.91803954\n",
      "Iteration 116, loss = 0.91754126\n",
      "Iteration 117, loss = 0.91708428\n",
      "Iteration 118, loss = 0.91662288\n",
      "Iteration 119, loss = 0.91617878\n",
      "Iteration 120, loss = 0.91568364\n",
      "Iteration 121, loss = 0.91523951\n",
      "Iteration 122, loss = 0.91481068\n",
      "Iteration 123, loss = 0.91431557\n",
      "Iteration 124, loss = 0.91385689\n",
      "Iteration 125, loss = 0.91343110\n",
      "Iteration 126, loss = 0.91296676\n",
      "Iteration 127, loss = 0.91258223\n",
      "Iteration 128, loss = 0.91208481\n",
      "Iteration 129, loss = 0.91164543\n",
      "Iteration 130, loss = 0.91127515\n",
      "Iteration 131, loss = 0.91086186\n",
      "Iteration 132, loss = 0.91038538\n",
      "Iteration 133, loss = 0.90996572\n",
      "Iteration 134, loss = 0.90954440\n",
      "Iteration 135, loss = 0.90909752\n",
      "Iteration 136, loss = 0.90871332\n",
      "Iteration 137, loss = 0.90829956\n",
      "Iteration 138, loss = 0.90791209\n",
      "Iteration 139, loss = 0.90751258\n",
      "Iteration 140, loss = 0.90703604\n",
      "Iteration 141, loss = 0.90666029\n",
      "Iteration 142, loss = 0.90629026\n",
      "Iteration 143, loss = 0.90587952\n",
      "Iteration 144, loss = 0.90548054\n",
      "Iteration 145, loss = 0.90509890\n",
      "Iteration 146, loss = 0.90468873\n",
      "Iteration 147, loss = 0.90428534\n",
      "Iteration 148, loss = 0.90389029\n",
      "Iteration 149, loss = 0.90353455\n",
      "Iteration 150, loss = 0.90310253\n",
      "Iteration 151, loss = 0.90279044\n",
      "Iteration 152, loss = 0.90237694\n",
      "Iteration 153, loss = 0.90199241\n",
      "Iteration 154, loss = 0.90164290\n",
      "Iteration 155, loss = 0.90127558\n",
      "Iteration 156, loss = 0.90087702\n",
      "Iteration 157, loss = 0.90052435\n",
      "Iteration 158, loss = 0.90013694\n",
      "Iteration 159, loss = 0.89977345\n",
      "Iteration 160, loss = 0.89940305\n",
      "Iteration 161, loss = 0.89902009\n",
      "Iteration 162, loss = 0.89870088\n",
      "Iteration 163, loss = 0.89832142\n",
      "Iteration 164, loss = 0.89795020\n",
      "Iteration 165, loss = 0.89759193\n",
      "Iteration 166, loss = 0.89725810\n",
      "Iteration 167, loss = 0.89690390\n",
      "Iteration 168, loss = 0.89656912\n",
      "Iteration 169, loss = 0.89619620\n",
      "Iteration 170, loss = 0.89586150\n",
      "Iteration 171, loss = 0.89547082\n",
      "Iteration 172, loss = 0.89515913\n",
      "Iteration 173, loss = 0.89482783\n",
      "Iteration 174, loss = 0.89447282\n",
      "Iteration 175, loss = 0.89415096\n",
      "Iteration 176, loss = 0.89383148\n",
      "Iteration 177, loss = 0.89348500\n",
      "Iteration 178, loss = 0.89313782\n",
      "Iteration 179, loss = 0.89278040\n",
      "Iteration 180, loss = 0.89245217\n",
      "Iteration 181, loss = 0.89211110\n",
      "Iteration 182, loss = 0.89180730\n",
      "Iteration 183, loss = 0.89147536\n",
      "Iteration 184, loss = 0.89115425\n",
      "Iteration 185, loss = 0.89080590\n",
      "Iteration 186, loss = 0.89053813\n",
      "Iteration 187, loss = 0.89015589\n",
      "Iteration 188, loss = 0.88986530\n",
      "Iteration 189, loss = 0.88955640\n",
      "Iteration 190, loss = 0.88921223\n",
      "Iteration 191, loss = 0.88890387\n",
      "Iteration 192, loss = 0.88860981\n",
      "Iteration 193, loss = 0.88828393\n",
      "Iteration 194, loss = 0.88795991\n",
      "Iteration 195, loss = 0.88765217\n",
      "Iteration 196, loss = 0.88733533\n",
      "Iteration 197, loss = 0.88701514\n",
      "Iteration 198, loss = 0.88675554\n",
      "Iteration 199, loss = 0.88644113\n",
      "Iteration 200, loss = 0.88612434\n",
      "Iteration 201, loss = 0.88584277\n",
      "Iteration 202, loss = 0.88554701\n",
      "Iteration 203, loss = 0.88522004\n",
      "Iteration 204, loss = 0.88494350\n",
      "Iteration 205, loss = 0.88462061\n",
      "Iteration 206, loss = 0.88432347\n",
      "Iteration 207, loss = 0.88402077\n",
      "Iteration 208, loss = 0.88373344\n",
      "Iteration 209, loss = 0.88343249\n",
      "Iteration 210, loss = 0.88316110\n",
      "Iteration 211, loss = 0.88285700\n",
      "Iteration 212, loss = 0.88258207\n",
      "Iteration 213, loss = 0.88226168\n",
      "Iteration 214, loss = 0.88197776\n",
      "Iteration 215, loss = 0.88169938\n",
      "Iteration 216, loss = 0.88142482\n",
      "Iteration 217, loss = 0.88113712\n",
      "Iteration 218, loss = 0.88086989\n",
      "Iteration 219, loss = 0.88054166\n",
      "Iteration 220, loss = 0.88030006\n",
      "Iteration 221, loss = 0.88001308\n",
      "Iteration 222, loss = 0.87972494\n",
      "Iteration 223, loss = 0.87945557\n",
      "Iteration 224, loss = 0.87915715\n",
      "Iteration 225, loss = 0.87889472\n",
      "Iteration 226, loss = 0.87862136\n",
      "Iteration 227, loss = 0.87831993\n",
      "Iteration 228, loss = 0.87806034\n",
      "Iteration 229, loss = 0.87778997\n",
      "Iteration 230, loss = 0.87749902\n",
      "Iteration 231, loss = 0.87722678\n",
      "Iteration 232, loss = 0.87696053\n",
      "Iteration 233, loss = 0.87669165\n",
      "Iteration 234, loss = 0.87641132\n",
      "Iteration 235, loss = 0.87615519\n",
      "Iteration 236, loss = 0.87586667\n",
      "Iteration 237, loss = 0.87561978\n",
      "Iteration 238, loss = 0.87536993\n",
      "Iteration 239, loss = 0.87507459\n",
      "Iteration 240, loss = 0.87482282\n",
      "Iteration 241, loss = 0.87455184\n",
      "Iteration 242, loss = 0.87427412\n",
      "Iteration 243, loss = 0.87403453\n",
      "Iteration 244, loss = 0.87376127\n",
      "Iteration 245, loss = 0.87351324\n",
      "Iteration 246, loss = 0.87322940\n",
      "Iteration 247, loss = 0.87298439\n",
      "Iteration 248, loss = 0.87270840\n",
      "Iteration 249, loss = 0.87249207\n",
      "Iteration 250, loss = 0.87222541\n",
      "Iteration 251, loss = 0.87199293\n",
      "Iteration 252, loss = 0.87169795\n",
      "Iteration 253, loss = 0.87147275\n",
      "Iteration 254, loss = 0.87119471\n",
      "Iteration 255, loss = 0.87094623\n",
      "Iteration 256, loss = 0.87070522\n",
      "Iteration 257, loss = 0.87046585\n",
      "Iteration 258, loss = 0.87024480\n",
      "Iteration 259, loss = 0.86994595\n",
      "Iteration 260, loss = 0.86970187\n",
      "Iteration 261, loss = 0.86944887\n",
      "Iteration 262, loss = 0.86923826\n",
      "Iteration 263, loss = 0.86895764\n",
      "Iteration 264, loss = 0.86873377\n",
      "Iteration 265, loss = 0.86846294\n",
      "Iteration 266, loss = 0.86820217\n",
      "Iteration 267, loss = 0.86797578\n",
      "Iteration 268, loss = 0.86774435\n",
      "Iteration 269, loss = 0.86749780\n",
      "Iteration 270, loss = 0.86728339\n",
      "Iteration 271, loss = 0.86702202\n",
      "Iteration 272, loss = 0.86679662\n",
      "Iteration 273, loss = 0.86650783\n",
      "Iteration 274, loss = 0.86631299\n",
      "Iteration 275, loss = 0.86604680\n",
      "Iteration 276, loss = 0.86581513\n",
      "Iteration 277, loss = 0.86557141\n",
      "Iteration 278, loss = 0.86532365\n",
      "Iteration 279, loss = 0.86511748\n",
      "Iteration 280, loss = 0.86488798\n",
      "Iteration 281, loss = 0.86465772\n",
      "Iteration 282, loss = 0.86441208\n",
      "Iteration 283, loss = 0.86416470\n",
      "Iteration 284, loss = 0.86392620\n",
      "Iteration 285, loss = 0.86368242\n",
      "Iteration 286, loss = 0.86347230\n",
      "Iteration 287, loss = 0.86324716\n",
      "Iteration 288, loss = 0.86302133\n",
      "Iteration 289, loss = 0.86280079\n",
      "Iteration 290, loss = 0.86256099\n",
      "Iteration 291, loss = 0.86231494\n",
      "Iteration 292, loss = 0.86210548\n",
      "Iteration 293, loss = 0.86186383\n",
      "Iteration 294, loss = 0.86164434\n",
      "Iteration 295, loss = 0.86143789\n",
      "Iteration 296, loss = 0.86119656\n",
      "Iteration 297, loss = 0.86094361\n",
      "Iteration 298, loss = 0.86075506\n",
      "Iteration 299, loss = 0.86051705\n",
      "Iteration 300, loss = 0.86031954\n",
      "Iteration 301, loss = 0.86006875\n",
      "Iteration 302, loss = 0.85985305\n",
      "Iteration 303, loss = 0.85964148\n",
      "Iteration 304, loss = 0.85942254\n",
      "Iteration 305, loss = 0.85918128\n",
      "Iteration 306, loss = 0.85898205\n",
      "Iteration 307, loss = 0.85875012\n",
      "Iteration 308, loss = 0.85852913\n",
      "Iteration 309, loss = 0.85829491\n",
      "Iteration 310, loss = 0.85810805\n",
      "Iteration 311, loss = 0.85789204\n",
      "Iteration 312, loss = 0.85769343\n",
      "Iteration 313, loss = 0.85744985\n",
      "Iteration 314, loss = 0.85724223\n",
      "Iteration 315, loss = 0.85701749\n",
      "Iteration 316, loss = 0.85680797\n",
      "Iteration 317, loss = 0.85660332\n",
      "Iteration 318, loss = 0.85637421\n",
      "Iteration 319, loss = 0.85615233\n",
      "Iteration 320, loss = 0.85597940\n",
      "Iteration 321, loss = 0.85574536\n",
      "Iteration 322, loss = 0.85553427\n",
      "Iteration 323, loss = 0.85532914\n",
      "Iteration 324, loss = 0.85510694\n",
      "Iteration 325, loss = 0.85489991\n",
      "Iteration 326, loss = 0.85469504\n",
      "Iteration 327, loss = 0.85450140\n",
      "Iteration 328, loss = 0.85426880\n",
      "Iteration 329, loss = 0.85410838\n",
      "Iteration 330, loss = 0.85385225\n",
      "Iteration 331, loss = 0.85365439\n",
      "Iteration 332, loss = 0.85346910\n",
      "Iteration 333, loss = 0.85330232\n",
      "Iteration 334, loss = 0.85305267\n",
      "Iteration 335, loss = 0.85284099\n",
      "Iteration 336, loss = 0.85261280\n",
      "Iteration 337, loss = 0.85240083\n",
      "Iteration 338, loss = 0.85221966\n",
      "Iteration 339, loss = 0.85202289\n",
      "Iteration 340, loss = 0.85182287\n",
      "Iteration 341, loss = 0.85163129\n",
      "Iteration 342, loss = 0.85139298\n",
      "Iteration 343, loss = 0.85121011\n",
      "Iteration 344, loss = 0.85102597\n",
      "Iteration 345, loss = 0.85081844\n",
      "Iteration 346, loss = 0.85061148\n",
      "Iteration 347, loss = 0.85041033\n",
      "Iteration 348, loss = 0.85023026\n",
      "Iteration 349, loss = 0.85002227\n",
      "Iteration 350, loss = 0.84978844\n",
      "Iteration 351, loss = 0.84963045\n",
      "Iteration 352, loss = 0.84941231\n",
      "Iteration 353, loss = 0.84921127\n",
      "Iteration 354, loss = 0.84901192\n",
      "Iteration 355, loss = 0.84882301\n",
      "Iteration 356, loss = 0.84862512\n",
      "Iteration 357, loss = 0.84846401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 358, loss = 0.84824036\n",
      "Iteration 359, loss = 0.84803610\n",
      "Iteration 360, loss = 0.84786221\n",
      "Iteration 361, loss = 0.84766666\n",
      "Iteration 362, loss = 0.84746268\n",
      "Iteration 363, loss = 0.84727543\n",
      "Iteration 364, loss = 0.84706110\n",
      "Iteration 365, loss = 0.84686935\n",
      "Iteration 366, loss = 0.84667067\n",
      "Iteration 367, loss = 0.84648897\n",
      "Iteration 368, loss = 0.84633199\n",
      "Iteration 369, loss = 0.84610225\n",
      "Iteration 370, loss = 0.84590900\n",
      "Iteration 371, loss = 0.84574617\n",
      "Iteration 372, loss = 0.84552312\n",
      "Iteration 373, loss = 0.84533882\n",
      "Iteration 374, loss = 0.84516721\n",
      "Iteration 375, loss = 0.84497333\n",
      "Iteration 376, loss = 0.84477417\n",
      "Iteration 377, loss = 0.84458420\n",
      "Iteration 378, loss = 0.84443227\n",
      "Iteration 379, loss = 0.84421148\n",
      "Iteration 380, loss = 0.84403171\n",
      "Iteration 381, loss = 0.84380755\n",
      "Iteration 382, loss = 0.84365738\n",
      "Iteration 383, loss = 0.84346041\n",
      "Iteration 384, loss = 0.84325605\n",
      "Iteration 385, loss = 0.84308005\n",
      "Iteration 386, loss = 0.84289855\n",
      "Iteration 387, loss = 0.84270491\n",
      "Iteration 388, loss = 0.84250289\n",
      "Iteration 389, loss = 0.84234348\n",
      "Iteration 390, loss = 0.84212799\n",
      "Iteration 391, loss = 0.84197018\n",
      "Iteration 392, loss = 0.84179111\n",
      "Iteration 393, loss = 0.84161492\n",
      "Iteration 394, loss = 0.84141706\n",
      "Iteration 395, loss = 0.84124264\n",
      "Iteration 396, loss = 0.84106193\n",
      "Iteration 397, loss = 0.84088340\n",
      "Iteration 398, loss = 0.84068984\n",
      "Iteration 399, loss = 0.84051369\n",
      "Iteration 400, loss = 0.84032190\n",
      "The training Accuracy achieved is = 78.238\n",
      "The test Accuracy achieved is = 73.354\n",
      "The number of epochs is = 400\n",
      "The training time achieved is = 145.058\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.3333333333333333, random_state=None, shuffle=True,\n",
      "              solver='sgd', tol=1e-05, validation_fraction=0.1, verbose=True,\n",
      "              warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.16621442\n",
      "Iteration 2, loss = 0.88704192\n",
      "Iteration 3, loss = 0.69863746\n",
      "Iteration 4, loss = 0.65769184\n",
      "Iteration 5, loss = 0.63482190\n",
      "Iteration 6, loss = 0.61623806\n",
      "Iteration 7, loss = 0.60254822\n",
      "Iteration 8, loss = 0.59003410\n",
      "Iteration 9, loss = 0.58026566\n",
      "Iteration 10, loss = 0.56972129\n",
      "Iteration 11, loss = 0.56155086\n",
      "Iteration 12, loss = 0.55297599\n",
      "Iteration 13, loss = 0.54581243\n",
      "Iteration 14, loss = 0.53914658\n",
      "Iteration 15, loss = 0.53221415\n",
      "Iteration 16, loss = 0.52606206\n",
      "Iteration 17, loss = 0.52030167\n",
      "Iteration 18, loss = 0.51445561\n",
      "Iteration 19, loss = 0.50941221\n",
      "Iteration 20, loss = 0.50376875\n",
      "Iteration 21, loss = 0.49884585\n",
      "Iteration 22, loss = 0.49401444\n",
      "Iteration 23, loss = 0.48969436\n",
      "Iteration 24, loss = 0.48495763\n",
      "Iteration 25, loss = 0.48074517\n",
      "Iteration 26, loss = 0.47637311\n",
      "Iteration 27, loss = 0.47230945\n",
      "Iteration 28, loss = 0.46800025\n",
      "Iteration 29, loss = 0.46438749\n",
      "Iteration 30, loss = 0.46034384\n",
      "Iteration 31, loss = 0.45672435\n",
      "Iteration 32, loss = 0.45312908\n",
      "Iteration 33, loss = 0.44991649\n",
      "Iteration 34, loss = 0.44658453\n",
      "Iteration 35, loss = 0.44284812\n",
      "Iteration 36, loss = 0.43968531\n",
      "Iteration 37, loss = 0.43647997\n",
      "Iteration 38, loss = 0.43329739\n",
      "Iteration 39, loss = 0.43009271\n",
      "Iteration 40, loss = 0.42721819\n",
      "Iteration 41, loss = 0.42415931\n",
      "Iteration 42, loss = 0.42136557\n",
      "Iteration 43, loss = 0.41840101\n",
      "Iteration 44, loss = 0.41580193\n",
      "Iteration 45, loss = 0.41293213\n",
      "Iteration 46, loss = 0.41037191\n",
      "Iteration 47, loss = 0.40788199\n",
      "Iteration 48, loss = 0.40489639\n",
      "Iteration 49, loss = 0.40252284\n",
      "Iteration 50, loss = 0.39995187\n",
      "Iteration 51, loss = 0.39762975\n",
      "Iteration 52, loss = 0.39504587\n",
      "Iteration 53, loss = 0.39253267\n",
      "Iteration 54, loss = 0.39031653\n",
      "Iteration 55, loss = 0.38804422\n",
      "Iteration 56, loss = 0.38594870\n",
      "Iteration 57, loss = 0.38331217\n",
      "Iteration 58, loss = 0.38103784\n",
      "Iteration 59, loss = 0.37897563\n",
      "Iteration 60, loss = 0.37615880\n",
      "Iteration 61, loss = 0.37456281\n",
      "Iteration 62, loss = 0.37255830\n",
      "Iteration 63, loss = 0.37060547\n",
      "Iteration 64, loss = 0.36841044\n",
      "Iteration 65, loss = 0.36625983\n",
      "Iteration 66, loss = 0.36422700\n",
      "Iteration 67, loss = 0.36240795\n",
      "Iteration 68, loss = 0.36024725\n",
      "Iteration 69, loss = 0.35849824\n",
      "Iteration 70, loss = 0.35663679\n",
      "Iteration 71, loss = 0.35457984\n",
      "Iteration 72, loss = 0.35287724\n",
      "Iteration 73, loss = 0.35090402\n",
      "Iteration 74, loss = 0.34927141\n",
      "Iteration 75, loss = 0.34710628\n",
      "Iteration 76, loss = 0.34561852\n",
      "Iteration 77, loss = 0.34386433\n",
      "Iteration 78, loss = 0.34210510\n",
      "Iteration 79, loss = 0.34045918\n",
      "Iteration 80, loss = 0.33863091\n",
      "Iteration 81, loss = 0.33707664\n",
      "Iteration 82, loss = 0.33554235\n",
      "Iteration 83, loss = 0.33349366\n",
      "Iteration 84, loss = 0.33233039\n",
      "Iteration 85, loss = 0.33035315\n",
      "Iteration 86, loss = 0.32904203\n",
      "Iteration 87, loss = 0.32759413\n",
      "Iteration 88, loss = 0.32610480\n",
      "Iteration 89, loss = 0.32434816\n",
      "Iteration 90, loss = 0.32295796\n",
      "Iteration 91, loss = 0.32154743\n",
      "Iteration 92, loss = 0.31998755\n",
      "Iteration 93, loss = 0.31855709\n",
      "Iteration 94, loss = 0.31685953\n",
      "Iteration 95, loss = 0.31561629\n",
      "Iteration 96, loss = 0.31381420\n",
      "Iteration 97, loss = 0.31281781\n",
      "Iteration 98, loss = 0.31113966\n",
      "Iteration 99, loss = 0.30976118\n",
      "Iteration 100, loss = 0.30852872\n",
      "Iteration 101, loss = 0.30709462\n",
      "Iteration 102, loss = 0.30573355\n",
      "Iteration 103, loss = 0.30422383\n",
      "Iteration 104, loss = 0.30297511\n",
      "Iteration 105, loss = 0.30160951\n",
      "Iteration 106, loss = 0.30051993\n",
      "Iteration 107, loss = 0.29915113\n",
      "Iteration 108, loss = 0.29784543\n",
      "Iteration 109, loss = 0.29654304\n",
      "Iteration 110, loss = 0.29517652\n",
      "Iteration 111, loss = 0.29427892\n",
      "Iteration 112, loss = 0.29266417\n",
      "Iteration 113, loss = 0.29171915\n",
      "Iteration 114, loss = 0.29034561\n",
      "Iteration 115, loss = 0.28900165\n",
      "Iteration 116, loss = 0.28806185\n",
      "Iteration 117, loss = 0.28664647\n",
      "Iteration 118, loss = 0.28559241\n",
      "Iteration 119, loss = 0.28437959\n",
      "Iteration 120, loss = 0.28318465\n",
      "Iteration 121, loss = 0.28196110\n",
      "Iteration 122, loss = 0.28086865\n",
      "Iteration 123, loss = 0.27978978\n",
      "Iteration 124, loss = 0.27853470\n",
      "Iteration 125, loss = 0.27735090\n",
      "Iteration 126, loss = 0.27623138\n",
      "Iteration 127, loss = 0.27516970\n",
      "Iteration 128, loss = 0.27398319\n",
      "Iteration 129, loss = 0.27294679\n",
      "Iteration 130, loss = 0.27202449\n",
      "Iteration 131, loss = 0.27071451\n",
      "Iteration 132, loss = 0.26967554\n",
      "Iteration 133, loss = 0.26864990\n",
      "Iteration 134, loss = 0.26788568\n",
      "Iteration 135, loss = 0.26667805\n",
      "Iteration 136, loss = 0.26534466\n",
      "Iteration 137, loss = 0.26431130\n",
      "Iteration 138, loss = 0.26341696\n",
      "Iteration 139, loss = 0.26235560\n",
      "Iteration 140, loss = 0.26141435\n",
      "Iteration 141, loss = 0.26045846\n",
      "Iteration 142, loss = 0.25938291\n",
      "Iteration 143, loss = 0.25840776\n",
      "Iteration 144, loss = 0.25747536\n",
      "Iteration 145, loss = 0.25646417\n",
      "Iteration 146, loss = 0.25542842\n",
      "Iteration 147, loss = 0.25441023\n",
      "Iteration 148, loss = 0.25352092\n",
      "Iteration 149, loss = 0.25239377\n",
      "Iteration 150, loss = 0.25155865\n",
      "Iteration 151, loss = 0.25063799\n",
      "Iteration 152, loss = 0.24965514\n",
      "Iteration 153, loss = 0.24880656\n",
      "Iteration 154, loss = 0.24806649\n",
      "Iteration 155, loss = 0.24687617\n",
      "Iteration 156, loss = 0.24620869\n",
      "Iteration 157, loss = 0.24512193\n",
      "Iteration 158, loss = 0.24427775\n",
      "Iteration 159, loss = 0.24355179\n",
      "Iteration 160, loss = 0.24263523\n",
      "Iteration 161, loss = 0.24146533\n",
      "Iteration 162, loss = 0.24078930\n",
      "Iteration 163, loss = 0.23981890\n",
      "Iteration 164, loss = 0.23905795\n",
      "Iteration 165, loss = 0.23822736\n",
      "Iteration 166, loss = 0.23744468\n",
      "Iteration 167, loss = 0.23647825\n",
      "Iteration 168, loss = 0.23579739\n",
      "Iteration 169, loss = 0.23469574\n",
      "Iteration 170, loss = 0.23410345\n",
      "Iteration 171, loss = 0.23316109\n",
      "Iteration 172, loss = 0.23223991\n",
      "Iteration 173, loss = 0.23153481\n",
      "Iteration 174, loss = 0.23063172\n",
      "Iteration 175, loss = 0.22980931\n",
      "Iteration 176, loss = 0.22915923\n",
      "Iteration 177, loss = 0.22831985\n",
      "Iteration 178, loss = 0.22747299\n",
      "Iteration 179, loss = 0.22664620\n",
      "Iteration 180, loss = 0.22581840\n",
      "Iteration 181, loss = 0.22509686\n",
      "Iteration 182, loss = 0.22440516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 183, loss = 0.22378002\n",
      "Iteration 184, loss = 0.22308853\n",
      "Iteration 185, loss = 0.22226440\n",
      "Iteration 186, loss = 0.22129813\n",
      "Iteration 187, loss = 0.22072569\n",
      "Iteration 188, loss = 0.21971548\n",
      "Iteration 189, loss = 0.21924308\n",
      "Iteration 190, loss = 0.21852067\n",
      "Iteration 191, loss = 0.21750360\n",
      "Iteration 192, loss = 0.21688271\n",
      "Iteration 193, loss = 0.21618128\n",
      "Iteration 194, loss = 0.21551231\n",
      "Iteration 195, loss = 0.21462492\n",
      "Iteration 196, loss = 0.21392063\n",
      "Iteration 197, loss = 0.21323670\n",
      "Iteration 198, loss = 0.21264538\n",
      "Iteration 199, loss = 0.21171549\n",
      "Iteration 200, loss = 0.21116058\n",
      "Iteration 201, loss = 0.21031539\n",
      "Iteration 202, loss = 0.20991482\n",
      "Iteration 203, loss = 0.20894214\n",
      "Iteration 204, loss = 0.20833130\n",
      "Iteration 205, loss = 0.20765074\n",
      "Iteration 206, loss = 0.20685114\n",
      "Iteration 207, loss = 0.20632746\n",
      "Iteration 208, loss = 0.20553188\n",
      "Iteration 209, loss = 0.20500502\n",
      "Iteration 210, loss = 0.20418192\n",
      "Iteration 211, loss = 0.20355915\n",
      "Iteration 212, loss = 0.20295277\n",
      "Iteration 213, loss = 0.20220789\n",
      "Iteration 214, loss = 0.20146936\n",
      "Iteration 215, loss = 0.20087229\n",
      "Iteration 216, loss = 0.20039794\n",
      "Iteration 217, loss = 0.19955318\n",
      "Iteration 218, loss = 0.19900304\n",
      "Iteration 219, loss = 0.19826927\n",
      "Iteration 220, loss = 0.19772309\n",
      "Iteration 221, loss = 0.19727340\n",
      "Iteration 222, loss = 0.19637892\n",
      "Iteration 223, loss = 0.19574680\n",
      "Iteration 224, loss = 0.19518091\n",
      "Iteration 225, loss = 0.19445054\n",
      "Iteration 226, loss = 0.19389509\n",
      "Iteration 227, loss = 0.19333123\n",
      "Iteration 228, loss = 0.19253115\n",
      "Iteration 229, loss = 0.19201669\n",
      "Iteration 230, loss = 0.19132176\n",
      "Iteration 231, loss = 0.19083251\n",
      "Iteration 232, loss = 0.19021654\n",
      "Iteration 233, loss = 0.18948003\n",
      "Iteration 234, loss = 0.18899749\n",
      "Iteration 235, loss = 0.18839046\n",
      "Iteration 236, loss = 0.18774985\n",
      "Iteration 237, loss = 0.18721585\n",
      "Iteration 238, loss = 0.18675520\n",
      "Iteration 239, loss = 0.18599985\n",
      "Iteration 240, loss = 0.18533328\n",
      "Iteration 241, loss = 0.18483459\n",
      "Iteration 242, loss = 0.18418501\n",
      "Iteration 243, loss = 0.18368966\n",
      "Iteration 244, loss = 0.18321441\n",
      "Iteration 245, loss = 0.18249226\n",
      "Iteration 246, loss = 0.18200091\n",
      "Iteration 247, loss = 0.18135531\n",
      "Iteration 248, loss = 0.18077577\n",
      "Iteration 249, loss = 0.18020873\n",
      "Iteration 250, loss = 0.17970282\n",
      "Iteration 251, loss = 0.17915154\n",
      "Iteration 252, loss = 0.17871783\n",
      "Iteration 253, loss = 0.17816694\n",
      "Iteration 254, loss = 0.17745628\n",
      "Iteration 255, loss = 0.17680825\n",
      "Iteration 256, loss = 0.17631394\n",
      "Iteration 257, loss = 0.17584205\n",
      "Iteration 258, loss = 0.17523616\n",
      "Iteration 259, loss = 0.17479634\n",
      "Iteration 260, loss = 0.17419545\n",
      "Iteration 261, loss = 0.17372168\n",
      "Iteration 262, loss = 0.17319837\n",
      "Iteration 263, loss = 0.17265528\n",
      "Iteration 264, loss = 0.17217022\n",
      "Iteration 265, loss = 0.17159666\n",
      "Iteration 266, loss = 0.17120212\n",
      "Iteration 267, loss = 0.17046378\n",
      "Iteration 268, loss = 0.16989178\n",
      "Iteration 269, loss = 0.16957824\n",
      "Iteration 270, loss = 0.16903939\n",
      "Iteration 271, loss = 0.16839870\n",
      "Iteration 272, loss = 0.16803681\n",
      "Iteration 273, loss = 0.16745262\n",
      "Iteration 274, loss = 0.16678880\n",
      "Iteration 275, loss = 0.16640722\n",
      "Iteration 276, loss = 0.16594775\n",
      "Iteration 277, loss = 0.16529633\n",
      "Iteration 278, loss = 0.16481308\n",
      "Iteration 279, loss = 0.16442677\n",
      "Iteration 280, loss = 0.16393165\n",
      "Iteration 281, loss = 0.16335899\n",
      "Iteration 282, loss = 0.16294081\n",
      "Iteration 283, loss = 0.16244224\n",
      "Iteration 284, loss = 0.16192736\n",
      "Iteration 285, loss = 0.16158335\n",
      "Iteration 286, loss = 0.16097727\n",
      "Iteration 287, loss = 0.16062477\n",
      "Iteration 288, loss = 0.16005254\n",
      "Iteration 289, loss = 0.15950045\n",
      "Iteration 290, loss = 0.15906012\n",
      "Iteration 291, loss = 0.15857558\n",
      "Iteration 292, loss = 0.15808295\n",
      "Iteration 293, loss = 0.15764326\n",
      "Iteration 294, loss = 0.15721902\n",
      "Iteration 295, loss = 0.15674076\n",
      "Iteration 296, loss = 0.15629738\n",
      "Iteration 297, loss = 0.15583201\n",
      "Iteration 298, loss = 0.15538113\n",
      "Iteration 299, loss = 0.15492748\n",
      "Iteration 300, loss = 0.15447792\n",
      "Iteration 301, loss = 0.15390884\n",
      "Iteration 302, loss = 0.15363422\n",
      "Iteration 303, loss = 0.15319898\n",
      "Iteration 304, loss = 0.15258039\n",
      "Iteration 305, loss = 0.15227217\n",
      "Iteration 306, loss = 0.15175450\n",
      "Iteration 307, loss = 0.15136766\n",
      "Iteration 308, loss = 0.15098336\n",
      "Iteration 309, loss = 0.15042454\n",
      "Iteration 310, loss = 0.15007581\n",
      "Iteration 311, loss = 0.14950508\n",
      "Iteration 312, loss = 0.14931518\n",
      "Iteration 313, loss = 0.14870359\n",
      "Iteration 314, loss = 0.14832228\n",
      "Iteration 315, loss = 0.14795568\n",
      "Iteration 316, loss = 0.14746717\n",
      "Iteration 317, loss = 0.14699970\n",
      "Iteration 318, loss = 0.14658552\n",
      "Iteration 319, loss = 0.14629777\n",
      "Iteration 320, loss = 0.14576639\n",
      "Iteration 321, loss = 0.14537311\n",
      "Iteration 322, loss = 0.14493454\n",
      "Iteration 323, loss = 0.14446464\n",
      "Iteration 324, loss = 0.14419734\n",
      "Iteration 325, loss = 0.14373319\n",
      "Iteration 326, loss = 0.14329289\n",
      "Iteration 327, loss = 0.14283187\n",
      "Iteration 328, loss = 0.14246571\n",
      "Iteration 329, loss = 0.14204361\n",
      "Iteration 330, loss = 0.14167316\n",
      "Iteration 331, loss = 0.14124073\n",
      "Iteration 332, loss = 0.14087039\n",
      "Iteration 333, loss = 0.14048954\n",
      "Iteration 334, loss = 0.14016486\n",
      "Iteration 335, loss = 0.13963883\n",
      "Iteration 336, loss = 0.13930346\n",
      "Iteration 337, loss = 0.13882358\n",
      "Iteration 338, loss = 0.13846336\n",
      "Iteration 339, loss = 0.13810722\n",
      "Iteration 340, loss = 0.13774206\n",
      "Iteration 341, loss = 0.13734074\n",
      "Iteration 342, loss = 0.13691741\n",
      "Iteration 343, loss = 0.13660493\n",
      "Iteration 344, loss = 0.13624601\n",
      "Iteration 345, loss = 0.13585568\n",
      "Iteration 346, loss = 0.13538161\n",
      "Iteration 347, loss = 0.13510180\n",
      "Iteration 348, loss = 0.13465948\n",
      "Iteration 349, loss = 0.13428660\n",
      "Iteration 350, loss = 0.13392197\n",
      "Iteration 351, loss = 0.13356320\n",
      "Iteration 352, loss = 0.13324777\n",
      "Iteration 353, loss = 0.13277116\n",
      "Iteration 354, loss = 0.13247955\n",
      "Iteration 355, loss = 0.13221963\n",
      "Iteration 356, loss = 0.13180486\n",
      "Iteration 357, loss = 0.13128813\n",
      "Iteration 358, loss = 0.13101058\n",
      "Iteration 359, loss = 0.13070951\n",
      "Iteration 360, loss = 0.13031966\n",
      "Iteration 361, loss = 0.12998790\n",
      "Iteration 362, loss = 0.12960962\n",
      "Iteration 363, loss = 0.12933017\n",
      "Iteration 364, loss = 0.12895444\n",
      "Iteration 365, loss = 0.12863041\n",
      "Iteration 366, loss = 0.12814166\n",
      "Iteration 367, loss = 0.12792646\n",
      "Iteration 368, loss = 0.12751815\n",
      "Iteration 369, loss = 0.12710653\n",
      "Iteration 370, loss = 0.12679880\n",
      "Iteration 371, loss = 0.12645486\n",
      "Iteration 372, loss = 0.12614523\n",
      "Iteration 373, loss = 0.12579476\n",
      "Iteration 374, loss = 0.12545125\n",
      "Iteration 375, loss = 0.12510886\n",
      "Iteration 376, loss = 0.12481501\n",
      "Iteration 377, loss = 0.12437036\n",
      "Iteration 378, loss = 0.12413550\n",
      "Iteration 379, loss = 0.12379523\n",
      "Iteration 380, loss = 0.12349231\n",
      "Iteration 381, loss = 0.12318874\n",
      "Iteration 382, loss = 0.12269481\n",
      "Iteration 383, loss = 0.12252617\n",
      "Iteration 384, loss = 0.12220047\n",
      "Iteration 385, loss = 0.12181975\n",
      "Iteration 386, loss = 0.12147061\n",
      "Iteration 387, loss = 0.12117258\n",
      "Iteration 388, loss = 0.12079871\n",
      "Iteration 389, loss = 0.12044840\n",
      "Iteration 390, loss = 0.12024621\n",
      "Iteration 391, loss = 0.11985937\n",
      "Iteration 392, loss = 0.11955165\n",
      "Iteration 393, loss = 0.11932374\n",
      "Iteration 394, loss = 0.11897187\n",
      "Iteration 395, loss = 0.11865840\n",
      "Iteration 396, loss = 0.11840940\n",
      "Iteration 397, loss = 0.11802632\n",
      "Iteration 398, loss = 0.11772557\n",
      "Iteration 399, loss = 0.11739889\n",
      "Iteration 400, loss = 0.11717409\n",
      "The training Accuracy achieved is = 97.908\n",
      "The test Accuracy achieved is = 85.662\n",
      "The number of epochs is = 400\n",
      "The training time achieved is = 152.810\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=400, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.23735264\n",
      "Iteration 2, loss = 0.82176518\n",
      "Iteration 3, loss = 0.67902448\n",
      "Iteration 4, loss = 0.63485710\n",
      "Iteration 5, loss = 0.60335081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.58025195\n",
      "Iteration 7, loss = 0.55987122\n",
      "Iteration 8, loss = 0.53958283\n",
      "Iteration 9, loss = 0.52299793\n",
      "Iteration 10, loss = 0.50883853\n",
      "Iteration 11, loss = 0.49523129\n",
      "Iteration 12, loss = 0.48299034\n",
      "Iteration 13, loss = 0.47009574\n",
      "Iteration 14, loss = 0.45982906\n",
      "Iteration 15, loss = 0.45124358\n",
      "Iteration 16, loss = 0.44011492\n",
      "Iteration 17, loss = 0.43085941\n",
      "Iteration 18, loss = 0.42184192\n",
      "Iteration 19, loss = 0.41269597\n",
      "Iteration 20, loss = 0.40568441\n",
      "Iteration 21, loss = 0.39768676\n",
      "Iteration 22, loss = 0.39032091\n",
      "Iteration 23, loss = 0.38272313\n",
      "Iteration 24, loss = 0.37585606\n",
      "Iteration 25, loss = 0.37127166\n",
      "Iteration 26, loss = 0.36485406\n",
      "Iteration 27, loss = 0.35676028\n",
      "Iteration 28, loss = 0.35136442\n",
      "Iteration 29, loss = 0.34566282\n",
      "Iteration 30, loss = 0.33892398\n",
      "Iteration 31, loss = 0.33487128\n",
      "Iteration 32, loss = 0.33031968\n",
      "Iteration 33, loss = 0.32420922\n",
      "Iteration 34, loss = 0.31845482\n",
      "Iteration 35, loss = 0.31468834\n",
      "Iteration 36, loss = 0.31012624\n",
      "Iteration 37, loss = 0.30438451\n",
      "Iteration 38, loss = 0.30087491\n",
      "Iteration 39, loss = 0.29594258\n",
      "Iteration 40, loss = 0.29150069\n",
      "Iteration 41, loss = 0.28836513\n",
      "Iteration 42, loss = 0.28401236\n",
      "Iteration 43, loss = 0.27969530\n",
      "Iteration 44, loss = 0.27690762\n",
      "Iteration 45, loss = 0.27219675\n",
      "Iteration 46, loss = 0.26855897\n",
      "Iteration 47, loss = 0.26485603\n",
      "Iteration 48, loss = 0.26049112\n",
      "Iteration 49, loss = 0.25768358\n",
      "Iteration 50, loss = 0.25519960\n",
      "Iteration 51, loss = 0.25111019\n",
      "Iteration 52, loss = 0.24851987\n",
      "Iteration 53, loss = 0.24461898\n",
      "Iteration 54, loss = 0.24175530\n",
      "Iteration 55, loss = 0.23909777\n",
      "Iteration 56, loss = 0.23570492\n",
      "Iteration 57, loss = 0.23241994\n",
      "Iteration 58, loss = 0.22951963\n",
      "Iteration 59, loss = 0.22742330\n",
      "Iteration 60, loss = 0.22434626\n",
      "Iteration 61, loss = 0.22123603\n",
      "Iteration 62, loss = 0.21879233\n",
      "Iteration 63, loss = 0.21611665\n",
      "Iteration 64, loss = 0.21275538\n",
      "Iteration 65, loss = 0.21083157\n",
      "Iteration 66, loss = 0.20835560\n",
      "Iteration 67, loss = 0.20623190\n",
      "Iteration 68, loss = 0.20310282\n",
      "Iteration 69, loss = 0.20124868\n",
      "Iteration 70, loss = 0.19824255\n",
      "Iteration 71, loss = 0.19638798\n",
      "Iteration 72, loss = 0.19343089\n",
      "Iteration 73, loss = 0.19149914\n",
      "Iteration 74, loss = 0.18910349\n",
      "Iteration 75, loss = 0.18706564\n",
      "Iteration 76, loss = 0.18514320\n",
      "Iteration 77, loss = 0.18304795\n",
      "Iteration 78, loss = 0.18074024\n",
      "Iteration 79, loss = 0.17848236\n",
      "Iteration 80, loss = 0.17605494\n",
      "Iteration 81, loss = 0.17469780\n",
      "Iteration 82, loss = 0.17275316\n",
      "Iteration 83, loss = 0.17016668\n",
      "Iteration 84, loss = 0.16883838\n",
      "Iteration 85, loss = 0.16701739\n",
      "Iteration 86, loss = 0.16447470\n",
      "Iteration 87, loss = 0.16276089\n",
      "Iteration 88, loss = 0.16099350\n",
      "Iteration 89, loss = 0.15921175\n",
      "Iteration 90, loss = 0.15791468\n",
      "Iteration 91, loss = 0.15589128\n",
      "Iteration 92, loss = 0.15489200\n",
      "Iteration 93, loss = 0.15218721\n",
      "Iteration 94, loss = 0.15039101\n",
      "Iteration 95, loss = 0.14916727\n",
      "Iteration 96, loss = 0.14782335\n",
      "Iteration 97, loss = 0.14576896\n",
      "Iteration 98, loss = 0.14419377\n",
      "Iteration 99, loss = 0.14260636\n",
      "Iteration 100, loss = 0.14113117\n",
      "Iteration 101, loss = 0.13897939\n",
      "Iteration 102, loss = 0.13760362\n",
      "Iteration 103, loss = 0.13615827\n",
      "Iteration 104, loss = 0.13503128\n",
      "Iteration 105, loss = 0.13349371\n",
      "Iteration 106, loss = 0.13192969\n",
      "Iteration 107, loss = 0.13061745\n",
      "Iteration 108, loss = 0.12945206\n",
      "Iteration 109, loss = 0.12774929\n",
      "Iteration 110, loss = 0.12600423\n",
      "Iteration 111, loss = 0.12549182\n",
      "Iteration 112, loss = 0.12362857\n",
      "Iteration 113, loss = 0.12260391\n",
      "Iteration 114, loss = 0.12138187\n",
      "Iteration 115, loss = 0.11954477\n",
      "Iteration 116, loss = 0.11886254\n",
      "Iteration 117, loss = 0.11721325\n",
      "Iteration 118, loss = 0.11602861\n",
      "Iteration 119, loss = 0.11484125\n",
      "Iteration 120, loss = 0.11366366\n",
      "Iteration 121, loss = 0.11260015\n",
      "Iteration 122, loss = 0.11130147\n",
      "Iteration 123, loss = 0.11021454\n",
      "Iteration 124, loss = 0.10882920\n",
      "Iteration 125, loss = 0.10800531\n",
      "Iteration 126, loss = 0.10672241\n",
      "Iteration 127, loss = 0.10572425\n",
      "Iteration 128, loss = 0.10472366\n",
      "Iteration 129, loss = 0.10378301\n",
      "Iteration 130, loss = 0.10250341\n",
      "Iteration 131, loss = 0.10144374\n",
      "Iteration 132, loss = 0.10017135\n",
      "Iteration 133, loss = 0.09906774\n",
      "Iteration 134, loss = 0.09897172\n",
      "Iteration 135, loss = 0.09745201\n",
      "Iteration 136, loss = 0.09643013\n",
      "Iteration 137, loss = 0.09550837\n",
      "Iteration 138, loss = 0.09430345\n",
      "Iteration 139, loss = 0.09339969\n",
      "Iteration 140, loss = 0.09278083\n",
      "Iteration 141, loss = 0.09178110\n",
      "Iteration 142, loss = 0.09100659\n",
      "Iteration 143, loss = 0.08985651\n",
      "Iteration 144, loss = 0.08944951\n",
      "Iteration 145, loss = 0.08823677\n",
      "Iteration 146, loss = 0.08717701\n",
      "Iteration 147, loss = 0.08681679\n",
      "Iteration 148, loss = 0.08572033\n",
      "Iteration 149, loss = 0.08486409\n",
      "Iteration 150, loss = 0.08408857\n",
      "Iteration 151, loss = 0.08337416\n",
      "Iteration 152, loss = 0.08233180\n",
      "Iteration 153, loss = 0.08162917\n",
      "Iteration 154, loss = 0.08065509\n",
      "Iteration 155, loss = 0.08035844\n",
      "Iteration 156, loss = 0.07940185\n",
      "Iteration 157, loss = 0.07870160\n",
      "Iteration 158, loss = 0.07764999\n",
      "Iteration 159, loss = 0.07701743\n",
      "Iteration 160, loss = 0.07626875\n",
      "Iteration 161, loss = 0.07573877\n",
      "Iteration 162, loss = 0.07504270\n",
      "Iteration 163, loss = 0.07429638\n",
      "Iteration 164, loss = 0.07353878\n",
      "Iteration 165, loss = 0.07289745\n",
      "Iteration 166, loss = 0.07229455\n",
      "Iteration 167, loss = 0.07159860\n",
      "Iteration 168, loss = 0.07089093\n",
      "Iteration 169, loss = 0.07051470\n",
      "Iteration 170, loss = 0.06963639\n",
      "Iteration 171, loss = 0.06893353\n",
      "Iteration 172, loss = 0.06815662\n",
      "Iteration 173, loss = 0.06797282\n",
      "Iteration 174, loss = 0.06698478\n",
      "Iteration 175, loss = 0.06657021\n",
      "Iteration 176, loss = 0.06594244\n",
      "Iteration 177, loss = 0.06524500\n",
      "Iteration 178, loss = 0.06468401\n",
      "Iteration 179, loss = 0.06404803\n",
      "Iteration 180, loss = 0.06350234\n",
      "Iteration 181, loss = 0.06317751\n",
      "Iteration 182, loss = 0.06251635\n",
      "Iteration 183, loss = 0.06192627\n",
      "Iteration 184, loss = 0.06111800\n",
      "Iteration 185, loss = 0.06093491\n",
      "Iteration 186, loss = 0.06042957\n",
      "Iteration 187, loss = 0.05976469\n",
      "Iteration 188, loss = 0.05919849\n",
      "Iteration 189, loss = 0.05881629\n",
      "Iteration 190, loss = 0.05820818\n",
      "Iteration 191, loss = 0.05773141\n",
      "Iteration 192, loss = 0.05720023\n",
      "Iteration 193, loss = 0.05669252\n",
      "Iteration 194, loss = 0.05618546\n",
      "Iteration 195, loss = 0.05587628\n",
      "Iteration 196, loss = 0.05534462\n",
      "Iteration 197, loss = 0.05504132\n",
      "Iteration 198, loss = 0.05439211\n",
      "Iteration 199, loss = 0.05398835\n",
      "Iteration 200, loss = 0.05353137\n",
      "Iteration 201, loss = 0.05301748\n",
      "Iteration 202, loss = 0.05265311\n",
      "Iteration 203, loss = 0.05220254\n",
      "Iteration 204, loss = 0.05199113\n",
      "Iteration 205, loss = 0.05134108\n",
      "Iteration 206, loss = 0.05092371\n",
      "Iteration 207, loss = 0.05054053\n",
      "Iteration 208, loss = 0.04999789\n",
      "Iteration 209, loss = 0.04971793\n",
      "Iteration 210, loss = 0.04921654\n",
      "Iteration 211, loss = 0.04885173\n",
      "Iteration 212, loss = 0.04864669\n",
      "Iteration 213, loss = 0.04814701\n",
      "Iteration 214, loss = 0.04763147\n",
      "Iteration 215, loss = 0.04744366\n",
      "Iteration 216, loss = 0.04689301\n",
      "Iteration 217, loss = 0.04657885\n",
      "Iteration 218, loss = 0.04618483\n",
      "Iteration 219, loss = 0.04581477\n",
      "Iteration 220, loss = 0.04547057\n",
      "Iteration 221, loss = 0.04525308\n",
      "Iteration 222, loss = 0.04474653\n",
      "Iteration 223, loss = 0.04452471\n",
      "Iteration 224, loss = 0.04414670\n",
      "Iteration 225, loss = 0.04382289\n",
      "Iteration 226, loss = 0.04338871\n",
      "Iteration 227, loss = 0.04308544\n",
      "Iteration 228, loss = 0.04286919\n",
      "Iteration 229, loss = 0.04236605\n",
      "Iteration 230, loss = 0.04221096\n",
      "Iteration 231, loss = 0.04178849\n",
      "Iteration 232, loss = 0.04132168\n",
      "Iteration 233, loss = 0.04118299\n",
      "Iteration 234, loss = 0.04083337\n",
      "Iteration 235, loss = 0.04049576\n",
      "Iteration 236, loss = 0.04025935\n",
      "Iteration 237, loss = 0.04007945\n",
      "Iteration 238, loss = 0.03962297\n",
      "Iteration 239, loss = 0.03920940\n",
      "Iteration 240, loss = 0.03906700\n",
      "Iteration 241, loss = 0.03876534\n",
      "Iteration 242, loss = 0.03851601\n",
      "Iteration 243, loss = 0.03814277\n",
      "Iteration 244, loss = 0.03802656\n",
      "Iteration 245, loss = 0.03772832\n",
      "Iteration 246, loss = 0.03736073\n",
      "Iteration 247, loss = 0.03716903\n",
      "Iteration 248, loss = 0.03682550\n",
      "Iteration 249, loss = 0.03668703\n",
      "Iteration 250, loss = 0.03640634\n",
      "Iteration 251, loss = 0.03612294\n",
      "Iteration 252, loss = 0.03590384\n",
      "Iteration 253, loss = 0.03561076\n",
      "Iteration 254, loss = 0.03542686\n",
      "Iteration 255, loss = 0.03517487\n",
      "Iteration 256, loss = 0.03487547\n",
      "Iteration 257, loss = 0.03463554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 258, loss = 0.03440347\n",
      "Iteration 259, loss = 0.03418925\n",
      "Iteration 260, loss = 0.03395377\n",
      "Iteration 261, loss = 0.03377979\n",
      "Iteration 262, loss = 0.03339570\n",
      "Iteration 263, loss = 0.03330592\n",
      "Iteration 264, loss = 0.03304871\n",
      "Iteration 265, loss = 0.03283415\n",
      "Iteration 266, loss = 0.03256884\n",
      "Iteration 267, loss = 0.03239052\n",
      "Iteration 268, loss = 0.03220928\n",
      "Iteration 269, loss = 0.03195420\n",
      "Iteration 270, loss = 0.03170700\n",
      "Iteration 271, loss = 0.03154922\n",
      "Iteration 272, loss = 0.03138918\n",
      "Iteration 273, loss = 0.03111388\n",
      "Iteration 274, loss = 0.03095575\n",
      "Iteration 275, loss = 0.03071109\n",
      "Iteration 276, loss = 0.03052132\n",
      "Iteration 277, loss = 0.03027156\n",
      "Iteration 278, loss = 0.03015775\n",
      "Iteration 279, loss = 0.02993633\n",
      "Iteration 280, loss = 0.02971359\n",
      "Iteration 281, loss = 0.02963429\n",
      "Iteration 282, loss = 0.02938193\n",
      "Iteration 283, loss = 0.02918376\n",
      "Iteration 284, loss = 0.02903303\n",
      "Iteration 285, loss = 0.02876871\n",
      "Iteration 286, loss = 0.02863484\n",
      "Iteration 287, loss = 0.02848699\n",
      "Iteration 288, loss = 0.02828884\n",
      "Iteration 289, loss = 0.02815826\n",
      "Iteration 290, loss = 0.02798871\n",
      "Iteration 291, loss = 0.02781374\n",
      "Iteration 292, loss = 0.02763354\n",
      "Iteration 293, loss = 0.02746253\n",
      "Iteration 294, loss = 0.02735359\n",
      "Iteration 295, loss = 0.02713460\n",
      "Iteration 296, loss = 0.02694920\n",
      "Iteration 297, loss = 0.02684026\n",
      "Iteration 298, loss = 0.02661431\n",
      "Iteration 299, loss = 0.02653839\n",
      "Iteration 300, loss = 0.02635206\n",
      "Iteration 301, loss = 0.02611864\n",
      "Iteration 302, loss = 0.02600146\n",
      "Iteration 303, loss = 0.02589846\n",
      "Iteration 304, loss = 0.02574692\n",
      "Iteration 305, loss = 0.02555325\n",
      "Iteration 306, loss = 0.02535839\n",
      "Iteration 307, loss = 0.02531604\n",
      "Iteration 308, loss = 0.02514834\n",
      "Iteration 309, loss = 0.02500843\n",
      "Iteration 310, loss = 0.02485650\n",
      "Iteration 311, loss = 0.02468677\n",
      "Iteration 312, loss = 0.02453319\n",
      "Iteration 313, loss = 0.02442512\n",
      "Iteration 314, loss = 0.02431630\n",
      "Iteration 315, loss = 0.02418512\n",
      "Iteration 316, loss = 0.02401995\n",
      "Iteration 317, loss = 0.02388897\n",
      "Iteration 318, loss = 0.02377652\n",
      "Iteration 319, loss = 0.02364680\n",
      "Iteration 320, loss = 0.02356555\n",
      "Iteration 321, loss = 0.02340517\n",
      "Iteration 322, loss = 0.02326632\n",
      "Iteration 323, loss = 0.02312747\n",
      "Iteration 324, loss = 0.02303955\n",
      "Iteration 325, loss = 0.02287991\n",
      "Iteration 326, loss = 0.02273506\n",
      "Iteration 327, loss = 0.02263243\n",
      "Iteration 328, loss = 0.02246089\n",
      "Iteration 329, loss = 0.02242083\n",
      "Iteration 330, loss = 0.02230644\n",
      "Iteration 331, loss = 0.02214775\n",
      "Iteration 332, loss = 0.02206382\n",
      "Iteration 333, loss = 0.02196501\n",
      "Iteration 334, loss = 0.02180980\n",
      "Iteration 335, loss = 0.02174458\n",
      "Iteration 336, loss = 0.02161197\n",
      "Iteration 337, loss = 0.02148432\n",
      "Iteration 338, loss = 0.02142251\n",
      "Iteration 339, loss = 0.02126514\n",
      "Iteration 340, loss = 0.02113256\n",
      "Iteration 341, loss = 0.02107131\n",
      "Iteration 342, loss = 0.02094088\n",
      "Iteration 343, loss = 0.02087184\n",
      "Iteration 344, loss = 0.02073931\n",
      "Iteration 345, loss = 0.02062713\n",
      "Iteration 346, loss = 0.02055525\n",
      "Iteration 347, loss = 0.02044512\n",
      "Iteration 348, loss = 0.02034063\n",
      "Iteration 349, loss = 0.02019979\n",
      "Iteration 350, loss = 0.02014366\n",
      "Iteration 351, loss = 0.02006035\n",
      "Iteration 352, loss = 0.01998231\n",
      "Iteration 353, loss = 0.01984100\n",
      "Iteration 354, loss = 0.01975869\n",
      "Iteration 355, loss = 0.01964482\n",
      "Iteration 356, loss = 0.01953419\n",
      "Iteration 357, loss = 0.01948353\n",
      "Iteration 358, loss = 0.01939677\n",
      "Iteration 359, loss = 0.01933973\n",
      "Iteration 360, loss = 0.01917514\n",
      "Iteration 361, loss = 0.01910346\n",
      "Iteration 362, loss = 0.01901688\n",
      "Iteration 363, loss = 0.01892993\n",
      "Iteration 364, loss = 0.01884551\n",
      "Iteration 365, loss = 0.01871134\n",
      "Iteration 366, loss = 0.01869746\n",
      "Iteration 367, loss = 0.01858956\n",
      "Iteration 368, loss = 0.01846485\n",
      "Iteration 369, loss = 0.01839792\n",
      "Iteration 370, loss = 0.01830673\n",
      "Iteration 371, loss = 0.01823231\n",
      "Iteration 372, loss = 0.01817263\n",
      "Iteration 373, loss = 0.01807407\n",
      "Iteration 374, loss = 0.01800664\n",
      "Iteration 375, loss = 0.01791347\n",
      "Iteration 376, loss = 0.01784185\n",
      "Iteration 377, loss = 0.01777260\n",
      "Iteration 378, loss = 0.01768257\n",
      "Iteration 379, loss = 0.01760636\n",
      "Iteration 380, loss = 0.01754211\n",
      "Iteration 381, loss = 0.01747731\n",
      "Iteration 382, loss = 0.01741102\n",
      "Iteration 383, loss = 0.01727455\n",
      "Iteration 384, loss = 0.01723826\n",
      "Iteration 385, loss = 0.01717040\n",
      "Iteration 386, loss = 0.01707221\n",
      "Iteration 387, loss = 0.01699677\n",
      "Iteration 388, loss = 0.01695810\n",
      "Iteration 389, loss = 0.01685334\n",
      "Iteration 390, loss = 0.01680441\n",
      "Iteration 391, loss = 0.01673251\n",
      "Iteration 392, loss = 0.01664871\n",
      "Iteration 393, loss = 0.01659589\n",
      "Iteration 394, loss = 0.01652268\n",
      "Iteration 395, loss = 0.01643381\n",
      "Iteration 396, loss = 0.01638480\n",
      "Iteration 397, loss = 0.01633336\n",
      "Iteration 398, loss = 0.01624556\n",
      "Iteration 399, loss = 0.01617537\n",
      "Iteration 400, loss = 0.01609103\n",
      "The training Accuracy achieved is = 99.977\n",
      "The test Accuracy achieved is = 85.185\n",
      "The number of epochs is = 400\n",
      "The training time achieved is = 161.150\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf)):\n",
    "    print(\"--------Training the classifier with following params--------------\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(clf[i])\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    start =time.time()\n",
    "    clf[i].fit(X_train, train_class_enc)\n",
    "    end = time.time()\n",
    "    epochs.append(clf[i].n_iter_)\n",
    "    train_accuracy.append(clf[i].score(X_train, train_class_enc)*100)\n",
    "    test_accuracy.append(clf[i].score(X_test, test_actual_class_enc)*100)\n",
    "    train_time.append(end-start)\n",
    "    print(\"The training Accuracy achieved is = {:2.3f}\".format(train_accuracy[-1]))\n",
    "    print(\"The test Accuracy achieved is = {:2.3f}\".format(test_accuracy[-1]))    \n",
    "    print(\"The number of epochs is = {}\".format(epochs[-1]))    \n",
    "    print(\"The training time achieved is = {:2.3f}\".format(train_time[-1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy with different MLP classifiers with\\n ReLU and Sigmoid Activation\")\n",
    "data=['S_lr=0.1', 'S_earlystop','S_0.3/ep^(1/5)','S_0.3/ep^(1/4)','R_lr=0.03', 'R_lr=0.1', 'R_EarlyStop', 'R_0.1/ep^(1/2)', 'R_0.1/ep^(1/3)', 'R_0.1/ep^(1/4)']\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Classifier Type\")\n",
    "ax.set_xticklabels(data, rotation=90)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend(framealpha=0.5)\n",
    "ax.set_xticks(range(0,len(clf)))\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "plt.legend(loc=4,framealpha=0.5)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig(\"plots/parte/accuracy_final.png\", dpi=1000, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

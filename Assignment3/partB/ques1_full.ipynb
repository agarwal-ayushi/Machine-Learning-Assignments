{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "The total number of training samples = 13000\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "arch = [10] #means one hidden layer with 2 perceptrons \n",
    "M = 100 # Mini-Batch Size\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = np.random.random((n+1,arch[0]))\n",
    "theta2 = np.random.random((arch[0],r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.9520288128047689\n",
      "Error = 0.0739838002926372\n",
      "Error = 0.0739645176161679\n",
      "Error = 0.07396449706835137\n",
      "Error = 0.07396449704643157\n",
      "Error = 0.07396449704640859\n",
      "Error = 0.0739644970464085\n",
      "Error = 0.07396449704640852\n",
      "Error = 0.07396449704640853\n",
      "Error = 0.07396449704640853\n",
      "Error = 0.07396449704640853\n",
      "Error = 0.07396449704640853\n"
     ]
    }
   ],
   "source": [
    "for it in range(60000):\n",
    "    # Forward Propagation\n",
    "    l0 = X_train\n",
    "    l1 = activation(np.dot(l0, theta1))\n",
    "    l2 = activation(np.dot(l1, theta2))\n",
    "\n",
    "    if (it % 5000 == 0):\n",
    "        print(\"Error = \"+str(np.mean(np.abs(train_class_enc-l2))))\n",
    "\n",
    "    #Backward Propagation\n",
    "    delta_l2 = (1/m)*(train_class_enc - l2)*l2*(1-l2)\n",
    "\n",
    "    delta_l1 = np.dot(delta_l2, theta2.T)*l1*(1-l1)\n",
    "\n",
    "    theta1 += lr*np.dot(l0.T, delta_l1)\n",
    "    theta2 += lr*np.dot(l1.T, delta_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, theta):\n",
    "    l0 = data\n",
    "    l1 = activation(np.dot(l0, theta[0]))\n",
    "    l2 = activation(np.dot(l1, theta[1]))\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Accuracy of the model = 0.0%\n"
     ]
    }
   ],
   "source": [
    "test_pred_class = forward_prop(X_test, [theta1, theta2])\n",
    "test_acc = 0\n",
    "for i in range(len(test_actual_class_enc)):\n",
    "    if (np.array_equal(test_pred_class[i], test_actual_class_enc[i])):\n",
    "        test_acc+=1\n",
    "test_acc /= X_test.shape[0]\n",
    "\n",
    "print(\"The Test Accuracy of the model = {}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.00489358e-01,  1.73813611e-01, -1.41573820e-02,\n",
       "        -4.78355229e-01, -4.80102032e-01, -4.99123119e-02,\n",
       "        -5.93169219e-01, -6.25571130e-01,  1.60587189e-01,\n",
       "        -1.89132850e-01,  2.00435367e-01,  1.50920459e-01,\n",
       "        -7.35954143e-01,  1.44778909e-01, -6.62448810e-01,\n",
       "        -6.85832663e-01,  9.18529775e-02,  1.78268150e-01,\n",
       "        -6.12953780e-01, -4.10197002e-01, -5.84338836e-02,\n",
       "        -4.45545342e-02, -4.63852090e-01, -3.81741256e-01,\n",
       "        -6.60996902e-01, -3.71292671e-01],\n",
       "       [ 1.76257408e-01, -1.28330741e-01, -4.64932616e-01,\n",
       "         2.74772398e-01, -5.86859679e-01, -8.46514968e-01,\n",
       "        -1.36603599e-01,  4.24632913e-02, -8.99160048e-02,\n",
       "        -6.77758458e-01, -3.81221060e-01,  2.14991002e-01,\n",
       "        -3.06182924e-01,  8.90061130e-02, -6.85228569e-01,\n",
       "        -3.16292453e-01, -3.30494822e-01, -2.56459771e-01,\n",
       "        -3.47593260e-01,  1.31268534e-01, -9.12909266e-02,\n",
       "        -4.99101624e-01,  2.19408530e-01, -6.86964556e-01,\n",
       "        -5.07303322e-01, -3.75791252e-01],\n",
       "       [ 2.56569018e-01, -5.16129701e-01,  7.75059899e-02,\n",
       "        -3.28432840e-01, -2.92478050e-01,  1.33143631e-01,\n",
       "        -2.35209884e-01, -8.72680266e-02, -5.85343469e-01,\n",
       "        -5.13224419e-02, -5.60578897e-01, -6.60887875e-01,\n",
       "        -7.52833424e-01,  1.00292276e-01, -3.74640861e-01,\n",
       "        -3.67928445e-01, -1.55087161e-01, -7.13623643e-01,\n",
       "        -7.48026303e-01, -4.86597996e-01, -3.08547616e-01,\n",
       "        -7.02156577e-01, -7.64816073e-01, -9.37907467e-02,\n",
       "        -2.85308978e-01, -6.16606111e-02],\n",
       "       [-6.67003501e-01, -4.07768693e-01,  5.22348862e-02,\n",
       "        -2.00024763e-01, -6.62614175e-01, -5.53769078e-01,\n",
       "        -1.85763567e-01, -1.31791522e-01, -5.83483074e-01,\n",
       "        -2.53924999e-01, -7.13765520e-01, -6.95070389e-01,\n",
       "        -3.85699484e-01, -8.64075926e-02,  1.21576319e-01,\n",
       "        -1.42236453e-01, -3.31562399e-01, -5.50186721e-01,\n",
       "         9.72022338e-02,  2.88086529e-03, -2.70104946e-01,\n",
       "        -3.03566234e-01, -1.63567234e-01, -4.92153931e-01,\n",
       "        -6.36492614e-01, -5.41278977e-01],\n",
       "       [-5.31537162e-01, -6.02584771e-01, -3.76317438e-01,\n",
       "        -2.76732521e-01, -4.87862342e-01, -7.53213578e-01,\n",
       "        -2.31301243e-01,  2.85204998e-02, -7.94486673e-01,\n",
       "         1.24535253e-01,  4.77136729e-02, -4.03800253e-01,\n",
       "        -5.47116008e-01, -3.86703859e-01, -1.14311780e-01,\n",
       "        -2.08225094e-01,  1.20588848e-01, -6.68736646e-01,\n",
       "        -7.12472560e-01, -5.17066901e-01, -8.01040107e-01,\n",
       "        -7.03397288e-01,  6.93896911e-03, -6.11611189e-01,\n",
       "        -3.70643408e-01,  1.21242040e-01],\n",
       "       [-1.84569045e-01, -7.12460604e-01, -6.92169992e-01,\n",
       "        -4.88287884e-01, -1.55804311e-01, -4.91141138e-01,\n",
       "        -1.40503644e-01, -6.33088110e-01,  7.55148578e-02,\n",
       "        -6.81604074e-01, -4.98822742e-01, -6.85190842e-01,\n",
       "         1.15068278e-01, -5.52668640e-01, -4.46748659e-01,\n",
       "        -4.05538960e-01,  5.15335375e-02, -6.48665898e-01,\n",
       "        -4.80204944e-01,  1.04654717e-01,  5.55819977e-02,\n",
       "         2.05257961e-01, -1.41578988e-01,  5.48511776e-02,\n",
       "        -1.21450456e-01, -8.61368996e-01],\n",
       "       [-6.79797754e-01, -3.26302594e-02, -3.76030207e-01,\n",
       "        -4.79458082e-01,  2.49742793e-01, -4.03494520e-01,\n",
       "        -6.04439808e-01, -4.12822516e-01, -6.51100331e-01,\n",
       "        -3.19054564e-01, -3.64303345e-01, -6.90169768e-01,\n",
       "         3.69255920e-03, -3.88147493e-01, -4.69864326e-01,\n",
       "         1.43988652e-02, -5.47823286e-01, -8.13348118e-02,\n",
       "         1.07110532e-01, -4.65254771e-01, -2.23343695e-01,\n",
       "        -6.52158256e-01, -5.37614906e-01, -1.08421464e-01,\n",
       "        -7.58615227e-02,  3.04685962e-02],\n",
       "       [-6.25311260e-01,  1.47137964e-01, -6.89093887e-01,\n",
       "        -5.51272011e-01, -4.26430664e-01, -1.37442427e-01,\n",
       "        -2.65178406e-01, -4.73732785e-01, -6.74753539e-01,\n",
       "        -8.98987029e-02, -1.36040495e-01, -2.56086780e-01,\n",
       "         1.99872824e-01, -7.29098317e-01,  6.76342732e-02,\n",
       "        -4.97104106e-01, -5.59959374e-01, -4.02063805e-01,\n",
       "         5.27789485e-03, -4.65911302e-01, -7.00369850e-01,\n",
       "        -1.45723877e-01, -5.31530494e-01, -7.18236164e-01,\n",
       "        -7.50392257e-02, -2.20452916e-01],\n",
       "       [ 1.34800239e-01, -7.44187959e-01, -1.65098125e-02,\n",
       "        -5.37957882e-01, -3.22815115e-02, -9.97273570e-02,\n",
       "        -4.95551957e-01, -9.00121148e-01,  1.46983362e-01,\n",
       "        -6.85618262e-01, -4.35438949e-01, -1.03663224e-01,\n",
       "        -5.66444834e-01, -7.37935500e-01, -1.98626497e-01,\n",
       "        -3.24410459e-01, -7.68180774e-01, -5.43483727e-05,\n",
       "        -2.32575018e-01, -6.57502713e-01,  9.15947027e-03,\n",
       "        -3.18923603e-01, -4.96007468e-01, -1.18172856e-02,\n",
       "         8.69572559e-03, -1.65380386e-01],\n",
       "       [-4.97794421e-01, -3.95734681e-01, -7.19405375e-01,\n",
       "        -1.53127017e-01, -3.44185862e-01, -1.68040871e-02,\n",
       "        -3.31154505e-01, -2.54643815e-02, -2.22878154e-01,\n",
       "        -3.95096732e-01, -3.76853862e-01, -8.99181600e-02,\n",
       "        -2.43278676e-01, -6.71991733e-01, -4.56216921e-01,\n",
       "        -2.85706064e-01, -7.89743382e-01, -7.60183405e-02,\n",
       "        -2.94640630e-01, -4.55149193e-01, -8.30486283e-01,\n",
       "        -5.45518008e-02, -3.46256076e-01, -1.68990411e-01,\n",
       "        -4.94475127e-01, -7.73360660e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

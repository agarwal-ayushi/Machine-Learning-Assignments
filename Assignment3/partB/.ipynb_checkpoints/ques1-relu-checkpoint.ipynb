{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "The total number of training samples = 11050\n",
      "The total number of validation samples = 1950\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "np.random.shuffle(X_train.to_numpy())\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "\n",
    "X_valid = X_train.iloc[(int(0.85*m)):]\n",
    "valid_class = train_class[(int(0.85*m)):]\n",
    "X_train = X_train.iloc[0:int(0.85*m)]\n",
    "train_class = train_class[0:int(0.85*m)]\n",
    "\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The total number of validation samples = {}\".format(X_valid.shape[0]))\n",
    "\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "valid_class_enc = pd.get_dummies(valid_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_valid = np.hstack((np.ones((X_valid.shape[0],1)), X_valid.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "arch_test = [1,5,10,50,100]\n",
    "arch = [arch_test[3]] #means one hidden layer with 2 perceptrons \n",
    "batch_size = 100 # Mini-Batch Size\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mini-batches formed is = 111\n"
     ]
    }
   ],
   "source": [
    "#Mini-Batch formation\n",
    "mini_batch = [(X_train[i:i+batch_size,:], train_class_enc[i:i+batch_size]) for i in range(0, m, batch_size)]\n",
    "print(\"The number of mini-batches formed is = {}\".format(len(mini_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta Initialization \n",
    "def theta_init(arch=[50]):\n",
    "    theta = []\n",
    "    for i in range(len(arch)+1):\n",
    "        if i == 0:\n",
    "            dim0=n+1\n",
    "            dim1=arch[i]\n",
    "        elif (i == len(arch)):\n",
    "            dim0=arch[i-1]\n",
    "            dim1 = r\n",
    "        else:\n",
    "            dim0=arch[i-1]\n",
    "            dim1= arch[i]\n",
    "\n",
    "        theta.append(2*np.random.random((dim0, dim1))-1)\n",
    "        #theta.append(np.zeros((dim0, dim1)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_act(x):\n",
    "#     x[x<=0] = 0.01*x[x<=0]\n",
    "#     return x\n",
    "    return np.maximum(0.0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_relu(x):\n",
    "    #x[x<=0] = -0.01\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 3.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,-1,0], [-2.5, 0, 3]])\n",
    "print(relu_act(a))\n",
    "print(deriv_relu(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, theta):\n",
    "    fm = []\n",
    "    fm.append(data)\n",
    "    for l in range(len(theta)):\n",
    "        if (l != len(theta)-1):\n",
    "            #print(\"relu\")\n",
    "            fm.append(relu_act(np.dot(fm[l], theta[l])))\n",
    "        else:\n",
    "            fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "            #print(\"sigmoid output\")\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.651318686497593"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta_init([100, 100, 100])\n",
    "print(theta[3].shape)\n",
    "cost_total(X_train, theta, train_class_enc, m)\n",
    "#fm = forward_prop(X_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_total(X, theta, Y, m):\n",
    "    fm = forward_prop(X, theta)\n",
    "    cost = (1/(2*m))*np.sum((Y-fm[-1])**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, theta, actual_class):\n",
    "    pred_class = forward_prop(data, theta)\n",
    "    test_pred_class = pred_class[-1]\n",
    "    for i in range(len(test_pred_class)):\n",
    "        test_pred_class[i][test_pred_class[i] == np.max(test_pred_class[i])] = 1\n",
    "        test_pred_class[i][test_pred_class[i] != np.max(test_pred_class[i])] = 0\n",
    "\n",
    "\n",
    "    test_acc = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if (np.array_equal(test_pred_class[i], actual_class[i])):\n",
    "            test_acc+=1\n",
    "    test_acc /= data.shape[0]\n",
    "\n",
    "    #print(\"The Test Accuracy of the model = {}%\".format(test_acc*100))\n",
    "    return (test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_time = []\n",
    "valid_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 100) (100, 100) (100, 26)\n",
      "learning rate =  0.01\n",
      "Initial Cost on Val dataset for this epoch 1 = 5.895641653944859\n",
      "Error on this batch = 5.985440584979438\n",
      "Error on this batch = 5.04503593416163\n",
      "Cost on val dataset after 2 epochs is = 4.651091786425487\n",
      "learning rate =  0.007937005259840998\n",
      "Initial Cost on Val dataset for this epoch 2 = 4.651091786425487\n",
      "Error on this batch = 4.636449087144846\n",
      "Error on this batch = 4.168984113340867\n",
      "Cost on val dataset after 3 epochs is = 3.9424397375646447\n",
      "learning rate =  0.006933612743506347\n",
      "Initial Cost on Val dataset for this epoch 3 = 3.9424397375646447\n",
      "Error on this batch = 3.8247727850018807\n",
      "Error on this batch = 3.6891692390999435\n",
      "Cost on val dataset after 4 epochs is = 3.464505487818876\n",
      "learning rate =  0.006299605249474366\n",
      "Initial Cost on Val dataset for this epoch 4 = 3.464505487818876\n",
      "Error on this batch = 3.335938682485011\n",
      "Error on this batch = 3.2585021982779945\n",
      "Cost on val dataset after 5 epochs is = 3.0753844315888754\n",
      "learning rate =  0.005848035476425733\n",
      "Initial Cost on Val dataset for this epoch 5 = 3.0753844315888754\n",
      "Error on this batch = 2.909484420309759\n",
      "Error on this batch = 2.8992185576225586\n",
      "Cost on val dataset after 6 epochs is = 2.7885767777805843\n",
      "learning rate =  0.005503212081491044\n",
      "Initial Cost on Val dataset for this epoch 6 = 2.7885767777805843\n",
      "Error on this batch = 2.6884843246387002\n",
      "Error on this batch = 2.6990599677959746\n",
      "Cost on val dataset after 7 epochs is = 2.579937437406407\n",
      "learning rate =  0.005227579585747102\n",
      "Initial Cost on Val dataset for this epoch 7 = 2.579937437406407\n",
      "Error on this batch = 2.4882162691266827\n",
      "Error on this batch = 2.5187586608015087\n",
      "Cost on val dataset after 8 epochs is = 2.403422075435428\n",
      "learning rate =  0.005\n",
      "Initial Cost on Val dataset for this epoch 8 = 2.403422075435428\n",
      "Error on this batch = 2.320050782289515\n",
      "Error on this batch = 2.2949209496512832\n",
      "Cost on val dataset after 9 epochs is = 2.2617634351734006\n",
      "learning rate =  0.004807498567691361\n",
      "Initial Cost on Val dataset for this epoch 9 = 2.2617634351734006\n",
      "Error on this batch = 2.153947177671275\n",
      "Error on this batch = 2.1530870403940185\n",
      "Cost on val dataset after 10 epochs is = 2.1539976433227777\n",
      "learning rate =  0.004641588833612779\n",
      "Initial Cost on Val dataset for this epoch 10 = 2.1539976433227777\n",
      "Error on this batch = 2.034908542198414\n",
      "Error on this batch = 2.0415716149806675\n",
      "Cost on val dataset after 11 epochs is = 2.0609248717898385\n",
      "learning rate =  0.004496443130226092\n",
      "Initial Cost on Val dataset for this epoch 11 = 2.0609248717898385\n",
      "Error on this batch = 1.9636353254532573\n",
      "Error on this batch = 1.964519757863842\n",
      "Cost on val dataset after 12 epochs is = 1.9822293152792636\n",
      "learning rate =  0.004367902323681495\n",
      "Initial Cost on Val dataset for this epoch 12 = 1.9822293152792636\n",
      "Error on this batch = 1.902776286969966\n",
      "Error on this batch = 1.9033128153419987\n",
      "Cost on val dataset after 13 epochs is = 1.9222114227688873\n",
      "learning rate =  0.0042529037028299025\n",
      "Initial Cost on Val dataset for this epoch 13 = 1.9222114227688873\n",
      "Error on this batch = 1.8411965439272266\n",
      "Error on this batch = 1.855210637701847\n",
      "Cost on val dataset after 14 epochs is = 1.869813549492112\n",
      "learning rate =  0.004149132666831218\n",
      "Initial Cost on Val dataset for this epoch 14 = 1.869813549492112\n",
      "Error on this batch = 1.7912344045283448\n",
      "Error on this batch = 1.7990750086377538\n",
      "Cost on val dataset after 15 epochs is = 1.8241692605402806\n",
      "learning rate =  0.004054801330382267\n",
      "Initial Cost on Val dataset for this epoch 15 = 1.8241692605402806\n",
      "Error on this batch = 1.7437004227943644\n",
      "Error on this batch = 1.7571933479115054\n",
      "Cost on val dataset after 16 epochs is = 1.7878664615265534\n",
      "learning rate =  0.003968502629920499\n",
      "Initial Cost on Val dataset for this epoch 16 = 1.7878664615265534\n",
      "Error on this batch = 1.7155092718033877\n",
      "Error on this batch = 1.7234773652947473\n",
      "Cost on val dataset after 17 epochs is = 1.7570303499105016\n",
      "learning rate =  0.0038891111873282035\n",
      "Initial Cost on Val dataset for this epoch 17 = 1.7570303499105016\n",
      "Error on this batch = 1.7047077694960484\n",
      "Error on this batch = 1.706020790466529\n",
      "Cost on val dataset after 18 epochs is = 1.730660637109786\n",
      "learning rate =  0.00381571414184444\n",
      "Initial Cost on Val dataset for this epoch 18 = 1.730660637109786\n",
      "Error on this batch = 1.6831073190642538\n",
      "Error on this batch = 1.6921376266950308\n",
      "Cost on val dataset after 19 epochs is = 1.7061645289344138\n",
      "learning rate =  0.0037475617678431545\n",
      "Initial Cost on Val dataset for this epoch 19 = 1.7061645289344138\n",
      "Error on this batch = 1.6498506616938613\n",
      "Error on this batch = 1.6719237316062632\n",
      "Cost on val dataset after 20 epochs is = 1.6852259334006703\n",
      "learning rate =  0.003684031498640387\n",
      "Initial Cost on Val dataset for this epoch 20 = 1.6852259334006703\n",
      "Error on this batch = 1.6220486276544948\n",
      "Error on this batch = 1.6532177625025144\n",
      "Cost on val dataset after 21 epochs is = 1.6662055812175802\n",
      "learning rate =  0.0036246012433429745\n",
      "Initial Cost on Val dataset for this epoch 21 = 1.6662055812175802\n",
      "Error on this batch = 1.6114702074030414\n",
      "Error on this batch = 1.6385487557637646\n",
      "Cost on val dataset after 22 epochs is = 1.6499977370888486\n",
      "learning rate =  0.0035688292775180415\n",
      "Initial Cost on Val dataset for this epoch 22 = 1.6499977370888486\n",
      "Error on this batch = 1.5969140032339555\n",
      "Error on this batch = 1.615206592040929\n",
      "Cost on val dataset after 23 epochs is = 1.6359268425468103\n",
      "learning rate =  0.0035163388691695934\n",
      "Initial Cost on Val dataset for this epoch 23 = 1.6359268425468103\n",
      "Error on this batch = 1.5839922601015903\n",
      "Error on this batch = 1.5933020824139175\n",
      "Cost on val dataset after 24 epochs is = 1.6229650537106108\n",
      "learning rate =  0.0034668063717531736\n",
      "Initial Cost on Val dataset for this epoch 24 = 1.6229650537106108\n",
      "Error on this batch = 1.5731408140088599\n",
      "Error on this batch = 1.579937580224222\n",
      "Cost on val dataset after 25 epochs is = 1.6108583882139524\n",
      "learning rate =  0.003419951893353394\n",
      "Initial Cost on Val dataset for this epoch 25 = 1.6108583882139524\n",
      "Error on this batch = 1.5628241070016449\n",
      "Error on this batch = 1.5715339988440995\n",
      "Cost on val dataset after 26 epochs is = 1.5996851935923537\n",
      "learning rate =  0.0033755319058958186\n",
      "Initial Cost on Val dataset for this epoch 26 = 1.5996851935923537\n",
      "Error on this batch = 1.5468280070903813\n",
      "Error on this batch = 1.568720659054597\n",
      "Cost on val dataset after 27 epochs is = 1.590130320162387\n",
      "learning rate =  0.0033333333333333335\n",
      "Initial Cost on Val dataset for this epoch 27 = 1.590130320162387\n",
      "Error on this batch = 1.5347918301099526\n",
      "Error on this batch = 1.5677037703331105\n",
      "Cost on val dataset after 28 epochs is = 1.58101911538658\n",
      "learning rate =  0.0032931687800417477\n",
      "Initial Cost on Val dataset for this epoch 28 = 1.58101911538658\n",
      "Error on this batch = 1.5203372606953114\n",
      "Error on this batch = 1.565392164738654\n",
      "Cost on val dataset after 29 epochs is = 1.5726353783895073\n",
      "learning rate =  0.0032548726473766764\n",
      "Initial Cost on Val dataset for this epoch 29 = 1.5726353783895073\n",
      "Error on this batch = 1.5105716982963344\n",
      "Error on this batch = 1.5565009940353784\n",
      "Cost on val dataset after 30 epochs is = 1.5655026309649562\n",
      "learning rate =  0.003218297948685433\n",
      "Initial Cost on Val dataset for this epoch 30 = 1.5655026309649562\n",
      "Error on this batch = 1.503866645286888\n",
      "Error on this batch = 1.5494288693145126\n",
      "Cost on val dataset after 31 epochs is = 1.5591125714808651\n",
      "learning rate =  0.0031833136784577337\n",
      "Initial Cost on Val dataset for this epoch 31 = 1.5591125714808651\n",
      "Error on this batch = 1.4971905154500922\n",
      "Error on this batch = 1.5432465400760371\n",
      "Cost on val dataset after 32 epochs is = 1.5531767136104628\n",
      "learning rate =  0.003149802624737183\n",
      "Initial Cost on Val dataset for this epoch 32 = 1.5531767136104628\n",
      "Error on this batch = 1.490415055936156\n",
      "Error on this batch = 1.5403058070947324\n",
      "Cost on val dataset after 33 epochs is = 1.5478396680225568\n",
      "learning rate =  0.00311765953881872\n",
      "Initial Cost on Val dataset for this epoch 33 = 1.5478396680225568\n",
      "Error on this batch = 1.4849771001702887\n",
      "Error on this batch = 1.5390690536600846\n",
      "Cost on val dataset after 34 epochs is = 1.542777870762127\n",
      "learning rate =  0.0030867895949930418\n",
      "Initial Cost on Val dataset for this epoch 34 = 1.542777870762127\n",
      "Error on this batch = 1.4797435608411416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 1.5378093803294552\n",
      "Cost on val dataset after 35 epochs is = 1.5382109398527206\n",
      "learning rate =  0.0030571070873287986\n",
      "Initial Cost on Val dataset for this epoch 35 = 1.5382109398527206\n",
      "Error on this batch = 1.4730904524166244\n",
      "Error on this batch = 1.5360496129951668\n",
      "Cost on val dataset after 36 epochs is = 1.5338848594192864\n",
      "learning rate =  0.0030285343213869\n",
      "Initial Cost on Val dataset for this epoch 36 = 1.5338848594192864\n",
      "Error on this batch = 1.4639675124441396\n",
      "Error on this batch = 1.5341823751328323\n",
      "Cost on val dataset after 37 epochs is = 1.5298107966901193\n",
      "learning rate =  0.003001000667185618\n",
      "Initial Cost on Val dataset for this epoch 37 = 1.5298107966901193\n",
      "Error on this batch = 1.4562645047696914\n",
      "Error on this batch = 1.53277449361155\n",
      "Cost on val dataset after 38 epochs is = 1.5257581414579784\n",
      "learning rate =  0.0029744417462950145\n",
      "Initial Cost on Val dataset for this epoch 38 = 1.5257581414579784\n",
      "Error on this batch = 1.4526986980132086\n",
      "Error on this batch = 1.5310968713733792\n",
      "Cost on val dataset after 39 epochs is = 1.5219208694351607\n",
      "learning rate =  0.002948798731084674\n",
      "Initial Cost on Val dataset for this epoch 39 = 1.5219208694351607\n",
      "Error on this batch = 1.4502251379517879\n",
      "Error on this batch = 1.527854137496197\n",
      "Cost on val dataset after 40 epochs is = 1.5182777862013281\n",
      "learning rate =  0.0029240177382128664\n",
      "Initial Cost on Val dataset for this epoch 40 = 1.5182777862013281\n",
      "Error on this batch = 1.4471743255313232\n",
      "Error on this batch = 1.524143420123583\n",
      "Cost on val dataset after 41 epochs is = 1.5151028724079878\n",
      "learning rate =  0.0029000493016762665\n",
      "Initial Cost on Val dataset for this epoch 41 = 1.5151028724079878\n",
      "Error on this batch = 1.4433348440902458\n",
      "Error on this batch = 1.5217322638749478\n",
      "Cost on val dataset after 42 epochs is = 1.5122754736519637\n",
      "learning rate =  0.0028768479133239404\n",
      "Initial Cost on Val dataset for this epoch 42 = 1.5122754736519637\n",
      "Error on this batch = 1.439693505270413\n",
      "Error on this batch = 1.5193985200539157\n",
      "Cost on val dataset after 43 epochs is = 1.509567407427738\n",
      "learning rate =  0.002854371620818945\n",
      "Initial Cost on Val dataset for this epoch 43 = 1.509567407427738\n",
      "Error on this batch = 1.436206490990955\n",
      "Error on this batch = 1.516483923765858\n",
      "Cost on val dataset after 44 epochs is = 1.5069001031361258\n",
      "learning rate =  0.0028325816747135236\n",
      "Initial Cost on Val dataset for this epoch 44 = 1.5069001031361258\n",
      "Error on this batch = 1.433400828454713\n",
      "Error on this batch = 1.512638164287188\n",
      "Cost on val dataset after 45 epochs is = 1.5043855085971365\n",
      "learning rate =  0.0028114422176724976\n",
      "Initial Cost on Val dataset for this epoch 45 = 1.5043855085971365\n",
      "Error on this batch = 1.4319271267450373\n",
      "Error on this batch = 1.5074069368542642\n",
      "Cost on val dataset after 46 epochs is = 1.5019688460031828\n",
      "learning rate =  0.002790920009998241\n",
      "Initial Cost on Val dataset for this epoch 46 = 1.5019688460031828\n",
      "Error on this batch = 1.4310328512825583\n",
      "Error on this batch = 1.5008493674688768\n",
      "Cost on val dataset after 47 epochs is = 1.4994971976268916\n",
      "learning rate =  0.002770984186529621\n",
      "Initial Cost on Val dataset for this epoch 47 = 1.4994971976268916\n",
      "Error on this batch = 1.4306786983935087\n",
      "Error on this batch = 1.4954516493198224\n",
      "Cost on val dataset after 48 epochs is = 1.496907430768905\n",
      "learning rate =  0.0027516060407455226\n",
      "Initial Cost on Val dataset for this epoch 48 = 1.496907430768905\n",
      "Error on this batch = 1.4306150145000947\n",
      "Error on this batch = 1.4928374646586422\n",
      "Cost on val dataset after 49 epochs is = 1.494399305052828\n",
      "learning rate =  0.002732758832531985\n",
      "Initial Cost on Val dataset for this epoch 49 = 1.494399305052828\n",
      "Error on this batch = 1.430596699161486\n",
      "Error on this batch = 1.491290577545415\n",
      "Cost on val dataset after 50 epochs is = 1.492201945419649\n",
      "learning rate =  0.002714417616594907\n",
      "Initial Cost on Val dataset for this epoch 50 = 1.492201945419649\n",
      "Error on this batch = 1.4304756491215402\n",
      "Error on this batch = 1.4901172341600284\n",
      "Cost on val dataset after 51 epochs is = 1.490282123128853\n",
      "learning rate =  0.002696559088937193\n",
      "Initial Cost on Val dataset for this epoch 51 = 1.490282123128853\n",
      "Error on this batch = 1.430269541678357\n",
      "Error on this batch = 1.4891115920399798\n",
      "Cost on val dataset after 52 epochs is = 1.4885300856958492\n",
      "learning rate =  0.002679161449185622\n",
      "Initial Cost on Val dataset for this epoch 52 = 1.4885300856958492\n",
      "Error on this batch = 1.4300180322473222\n",
      "Error on this batch = 1.4881117309857108\n",
      "Cost on val dataset after 53 epochs is = 1.4868971956352328\n",
      "learning rate =  0.002662204276861164\n",
      "Initial Cost on Val dataset for this epoch 53 = 1.4868971956352328\n",
      "Error on this batch = 1.4297502057650056\n",
      "Error on this batch = 1.4869926028833202\n",
      "Cost on val dataset after 54 epochs is = 1.4853570782372227\n",
      "learning rate =  0.0026456684199469994\n",
      "Initial Cost on Val dataset for this epoch 54 = 1.4853570782372227\n",
      "Error on this batch = 1.4295093407617088\n",
      "Error on this batch = 1.4856427057070267\n",
      "Cost on val dataset after 55 epochs is = 1.4838538115352229\n",
      "learning rate =  0.0026295358943292956\n",
      "Initial Cost on Val dataset for this epoch 55 = 1.4838538115352229\n",
      "Error on this batch = 1.4293373916671988\n",
      "Error on this batch = 1.483840267876376\n",
      "Cost on val dataset after 56 epochs is = 1.4823439705568837\n",
      "learning rate =  0.002613789792873551\n",
      "Initial Cost on Val dataset for this epoch 56 = 1.4823439705568837\n",
      "Error on this batch = 1.4293718166780713\n",
      "Error on this batch = 1.4811705255495815\n",
      "Cost on val dataset after 57 epochs is = 1.4807917207413723\n",
      "learning rate =  0.0025984142030594476\n",
      "Initial Cost on Val dataset for this epoch 57 = 1.4807917207413723\n",
      "Error on this batch = 1.4297124854409622\n",
      "Error on this batch = 1.4773934907865567\n",
      "Cost on val dataset after 58 epochs is = 1.4792052238048239\n",
      "learning rate =  0.0025833941322341274\n",
      "Initial Cost on Val dataset for this epoch 58 = 1.4792052238048239\n",
      "Error on this batch = 1.4303450284273571\n",
      "Error on this batch = 1.4740523833637662\n",
      "Cost on val dataset after 59 epochs is = 1.4777144456135511\n",
      "learning rate =  0.002568715439661365\n",
      "Initial Cost on Val dataset for this epoch 59 = 1.4777144456135511\n",
      "Error on this batch = 1.4308367172645584\n",
      "Error on this batch = 1.4721426837989893\n",
      "Cost on val dataset after 60 epochs is = 1.476400048338232\n",
      "learning rate =  0.0025543647746451774\n",
      "Initial Cost on Val dataset for this epoch 60 = 1.476400048338232\n",
      "Error on this batch = 1.4307879273134347\n",
      "Error on this batch = 1.47116012861461\n",
      "Cost on val dataset after 61 epochs is = 1.475160928023996\n",
      "learning rate =  0.002540329520093663\n",
      "Initial Cost on Val dataset for this epoch 61 = 1.475160928023996\n",
      "Error on this batch = 1.4301992063015945\n",
      "Error on this batch = 1.4705793389299389\n",
      "Cost on val dataset after 62 epochs is = 1.4738974278379493\n",
      "learning rate =  0.0025265977409642828\n",
      "Initial Cost on Val dataset for this epoch 62 = 1.4738974278379493\n",
      "Error on this batch = 1.4290655144393862\n",
      "Error on this batch = 1.4701786421990568\n",
      "Cost on val dataset after 63 epochs is = 1.4726218866367773\n",
      "learning rate =  0.0025131581370971797\n",
      "Initial Cost on Val dataset for this epoch 63 = 1.4726218866367773\n",
      "Error on this batch = 1.4274427961221359\n",
      "Error on this batch = 1.4698513086972724\n",
      "Cost on val dataset after 64 epochs is = 1.4713353912006204\n",
      "learning rate =  0.0025000000000000005\n",
      "Initial Cost on Val dataset for this epoch 64 = 1.4713353912006204\n",
      "Error on this batch = 1.4256536871382812\n",
      "Error on this batch = 1.469536589347322\n",
      "Cost on val dataset after 65 epochs is = 1.47002689044534\n",
      "learning rate =  0.0024871131731971623\n",
      "Initial Cost on Val dataset for this epoch 65 = 1.47002689044534\n",
      "Error on this batch = 1.4237614039535091\n",
      "Error on this batch = 1.4692238739099868\n",
      "Cost on val dataset after 66 epochs is = 1.4687289913796227\n",
      "learning rate =  0.002474488015799764\n",
      "Initial Cost on Val dataset for this epoch 66 = 1.4687289913796227\n",
      "Error on this batch = 1.4215141447699875\n",
      "Error on this batch = 1.468911658545863\n",
      "Cost on val dataset after 67 epochs is = 1.4674528087535965\n",
      "learning rate =  0.002462115368990136\n",
      "Initial Cost on Val dataset for this epoch 67 = 1.4674528087535965\n",
      "Error on this batch = 1.4190149348364451\n",
      "Error on this batch = 1.4685665085923494\n",
      "Cost on val dataset after 68 epochs is = 1.4662108478426372\n",
      "learning rate =  0.0024499865251482234\n",
      "Initial Cost on Val dataset for this epoch 68 = 1.4662108478426372\n",
      "Error on this batch = 1.4165965527778008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 1.4681257603220053\n",
      "Cost on val dataset after 69 epochs is = 1.4651390669952555\n",
      "learning rate =  0.002438093199376099\n",
      "Initial Cost on Val dataset for this epoch 69 = 1.4651390669952555\n",
      "Error on this batch = 1.4145118370512524\n",
      "Error on this batch = 1.467584688587237\n",
      "Cost on val dataset after 70 epochs is = 1.4640602517987777\n",
      "learning rate =  0.002426427503202587\n",
      "Initial Cost on Val dataset for this epoch 70 = 1.4640602517987777\n",
      "Error on this batch = 1.4126840760995947\n",
      "Error on this batch = 1.4669619184063174\n",
      "Cost on val dataset after 71 epochs is = 1.4629276983357142\n",
      "learning rate =  0.002414981920272584\n",
      "Initial Cost on Val dataset for this epoch 71 = 1.4629276983357142\n",
      "Error on this batch = 1.4111858115386204\n",
      "Error on this batch = 1.4662917605691796\n",
      "Cost on val dataset after 72 epochs is = 1.4617977549565104\n",
      "learning rate =  0.0024037492838456806\n",
      "Initial Cost on Val dataset for this epoch 72 = 1.4617977549565104\n",
      "Error on this batch = 1.409916699457848\n",
      "Error on this batch = 1.4656930396320147\n",
      "Cost on val dataset after 73 epochs is = 1.4605706966672822\n",
      "learning rate =  0.0023927227559463727\n",
      "Initial Cost on Val dataset for this epoch 73 = 1.4605706966672822\n",
      "Error on this batch = 1.4088632149162905\n",
      "Error on this batch = 1.4652059632963224\n",
      "Cost on val dataset after 74 epochs is = 1.4593594818867064\n",
      "learning rate =  0.0023818958080238594\n",
      "Initial Cost on Val dataset for this epoch 74 = 1.4593594818867064\n",
      "Error on this batch = 1.407939545046521\n",
      "Error on this batch = 1.4646797911441303\n",
      "Cost on val dataset after 75 epochs is = 1.4582437698071538\n",
      "learning rate =  0.0023712622029933754\n",
      "Initial Cost on Val dataset for this epoch 75 = 1.4582437698071538\n",
      "Error on this batch = 1.4070837531143963\n",
      "Error on this batch = 1.4641277577386231\n",
      "Cost on val dataset after 76 epochs is = 1.4571338964771137\n",
      "learning rate =  0.002360815978543417\n",
      "Initial Cost on Val dataset for this epoch 76 = 1.4571338964771137\n",
      "Error on this batch = 1.406265793061737\n",
      "Error on this batch = 1.4635529853767775\n",
      "Cost on val dataset after 77 epochs is = 1.455921258765676\n",
      "learning rate =  0.002350551431604272\n",
      "Initial Cost on Val dataset for this epoch 77 = 1.455921258765676\n",
      "Error on this batch = 1.4052849045903337\n",
      "Error on this batch = 1.4630063564944704\n",
      "Cost on val dataset after 78 epochs is = 1.4546354053267656\n",
      "learning rate =  0.0023404631038831513\n",
      "Initial Cost on Val dataset for this epoch 78 = 1.4546354053267656\n",
      "Error on this batch = 1.4036799061570122\n",
      "Error on this batch = 1.462450996090787\n",
      "Cost on val dataset after 79 epochs is = 1.4533595247405635\n",
      "learning rate =  0.0023305457683800565\n",
      "Initial Cost on Val dataset for this epoch 79 = 1.4533595247405635\n",
      "Error on this batch = 1.401753966771346\n",
      "Error on this batch = 1.461880174389559\n",
      "Cost on val dataset after 80 epochs is = 1.4519184028354295\n",
      "learning rate =  0.00232079441680639\n",
      "Initial Cost on Val dataset for this epoch 80 = 1.4519184028354295\n",
      "Error on this batch = 1.400688719306108\n",
      "Error on this batch = 1.4614504212116473\n",
      "Cost on val dataset after 81 epochs is = 1.4500716369530926\n",
      "learning rate =  0.0023112042478354495\n",
      "Initial Cost on Val dataset for this epoch 81 = 1.4500716369530926\n",
      "Error on this batch = 1.400559199249259\n",
      "Error on this batch = 1.460999074570965\n",
      "Cost on val dataset after 82 epochs is = 1.448234625370188\n",
      "learning rate =  0.0023017706561202743\n",
      "Initial Cost on Val dataset for this epoch 82 = 1.448234625370188\n",
      "Error on this batch = 1.4005244975536653\n",
      "Error on this batch = 1.460094402844217\n",
      "Cost on val dataset after 83 epochs is = 1.446672559335206\n",
      "learning rate =  0.002292489222020055\n",
      "Initial Cost on Val dataset for this epoch 83 = 1.446672559335206\n",
      "Error on this batch = 1.4001275487845168\n",
      "Error on this batch = 1.4580497932164522\n",
      "Cost on val dataset after 84 epochs is = 1.4452085031794812\n",
      "learning rate =  0.002283355701981471\n",
      "Initial Cost on Val dataset for this epoch 84 = 1.4452085031794812\n",
      "Error on this batch = 1.398059557659439\n",
      "Error on this batch = 1.45390628936891\n",
      "Cost on val dataset after 85 epochs is = 1.4436576057387833\n",
      "learning rate =  0.0022743660195259532\n",
      "Initial Cost on Val dataset for this epoch 85 = 1.4436576057387833\n",
      "Error on this batch = 1.3929625743530554\n",
      "Error on this batch = 1.448130500539989\n",
      "Cost on val dataset after 86 epochs is = 1.4418542944517456\n",
      "learning rate =  0.0022655162567980836\n",
      "Initial Cost on Val dataset for this epoch 86 = 1.4418542944517456\n",
      "Error on this batch = 1.3908951851912912\n",
      "Error on this batch = 1.4423573077882725\n",
      "Cost on val dataset after 87 epochs is = 1.4401817088927718\n",
      "learning rate =  0.0022568026466341165\n",
      "Initial Cost on Val dataset for this epoch 87 = 1.4401817088927718\n",
      "Error on this batch = 1.3909227422041095\n",
      "Error on this batch = 1.4373842282063385\n",
      "Cost on val dataset after 88 epochs is = 1.438367816580917\n",
      "learning rate =  0.002248221565113046\n",
      "Initial Cost on Val dataset for this epoch 88 = 1.438367816580917\n",
      "Error on this batch = 1.3910602707301787\n",
      "Error on this batch = 1.434583990633118\n",
      "Cost on val dataset after 89 epochs is = 1.4361666336257473\n",
      "learning rate =  0.002239769524555751\n",
      "Initial Cost on Val dataset for this epoch 89 = 1.4361666336257473\n",
      "Error on this batch = 1.3911798353059572\n",
      "Error on this batch = 1.4332388423431652\n",
      "Cost on val dataset after 90 epochs is = 1.433944177372115\n",
      "learning rate =  0.0022314431669405656\n",
      "Initial Cost on Val dataset for this epoch 90 = 1.433944177372115\n",
      "Error on this batch = 1.3898053581097167\n",
      "Error on this batch = 1.4329204931852217\n",
      "Cost on val dataset after 91 epochs is = 1.4312207834067971\n",
      "learning rate =  0.0022232392577061855\n",
      "Initial Cost on Val dataset for this epoch 91 = 1.4312207834067971\n",
      "Error on this batch = 1.3859018912982628\n",
      "Error on this batch = 1.4325824444508508\n",
      "Cost on val dataset after 92 epochs is = 1.4290588917334057\n",
      "learning rate =  0.0022151546799151524\n",
      "Initial Cost on Val dataset for this epoch 92 = 1.4290588917334057\n",
      "Error on this batch = 1.382470101575681\n",
      "Error on this batch = 1.4310702511649773\n",
      "Cost on val dataset after 93 epochs is = 1.426877134513983\n",
      "learning rate =  0.002207186428753261\n",
      "Initial Cost on Val dataset for this epoch 93 = 1.426877134513983\n",
      "Error on this batch = 1.3794370171523445\n",
      "Error on this batch = 1.4267742615721943\n",
      "Cost on val dataset after 94 epochs is = 1.4244695191966457\n",
      "learning rate =  0.0021993316063421827\n",
      "Initial Cost on Val dataset for this epoch 94 = 1.4244695191966457\n",
      "Error on this batch = 1.3776966616276227\n",
      "Error on this batch = 1.4223928531848185\n",
      "Cost on val dataset after 95 epochs is = 1.422215171087855\n",
      "learning rate =  0.0021915874168443503\n",
      "Initial Cost on Val dataset for this epoch 95 = 1.422215171087855\n",
      "Error on this batch = 1.3777160435742648\n",
      "Error on this batch = 1.4215543086951192\n",
      "Cost on val dataset after 96 epochs is = 1.4196670440630523\n",
      "learning rate =  0.0021839511618407473\n",
      "Initial Cost on Val dataset for this epoch 96 = 1.4196670440630523\n",
      "Error on this batch = 1.3770504786833795\n",
      "Error on this batch = 1.4214481461017487\n",
      "Cost on val dataset after 97 epochs is = 1.4168562484801508\n",
      "learning rate =  0.0021764202359637287\n",
      "Initial Cost on Val dataset for this epoch 97 = 1.4168562484801508\n",
      "Error on this batch = 1.374465615024922\n",
      "Error on this batch = 1.4216115051190195\n",
      "Cost on val dataset after 98 epochs is = 1.4136284800298051\n",
      "learning rate =  0.002168992122768331\n",
      "Initial Cost on Val dataset for this epoch 98 = 1.4136284800298051\n",
      "Error on this batch = 1.372712590114437\n",
      "Error on this batch = 1.4213744312779073\n",
      "Cost on val dataset after 99 epochs is = 1.4110186896339663\n",
      "learning rate =  0.00216166439082676\n",
      "Initial Cost on Val dataset for this epoch 99 = 1.4110186896339663\n",
      "Error on this batch = 1.3660873924141879\n",
      "Error on this batch = 1.4207005373453279\n",
      "Cost on val dataset after 100 epochs is = 1.408341869876846\n",
      "learning rate =  0.002154434690031884\n",
      "Initial Cost on Val dataset for this epoch 100 = 1.408341869876846\n",
      "Error on this batch = 1.3591401175026523\n",
      "Error on this batch = 1.4194351456030985\n",
      "Cost on val dataset after 101 epochs is = 1.4055254558026116\n",
      "learning rate =  0.002147300748096567\n",
      "Initial Cost on Val dataset for this epoch 101 = 1.4055254558026116\n",
      "Error on this batch = 1.3532740561949685\n",
      "Error on this batch = 1.4167578148728657\n",
      "Cost on val dataset after 102 epochs is = 1.4016260199878132\n",
      "learning rate =  0.002140260367236655\n",
      "Initial Cost on Val dataset for this epoch 102 = 1.4016260199878132\n",
      "Error on this batch = 1.3447072293794866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 1.4083431895423986\n",
      "Cost on val dataset after 103 epochs is = 1.39672841839955\n",
      "learning rate =  0.0021333114210262795\n",
      "Initial Cost on Val dataset for this epoch 103 = 1.39672841839955\n",
      "Error on this batch = 1.3366754658356286\n",
      "Error on this batch = 1.4029276922557858\n",
      "Cost on val dataset after 104 epochs is = 1.3924307073650293\n",
      "learning rate =  0.0021264518514149513\n",
      "Initial Cost on Val dataset for this epoch 104 = 1.3924307073650293\n",
      "Error on this batch = 1.334722340475208\n",
      "Error on this batch = 1.3970742309925175\n",
      "Cost on val dataset after 105 epochs is = 1.388151740617709\n",
      "learning rate =  0.002119679665896653\n",
      "Initial Cost on Val dataset for this epoch 105 = 1.388151740617709\n",
      "Error on this batch = 1.3338180163345295\n",
      "Error on this batch = 1.387850820847961\n",
      "Cost on val dataset after 106 epochs is = 1.3832874578730243\n",
      "learning rate =  0.002112992934821826\n",
      "Initial Cost on Val dataset for this epoch 106 = 1.3832874578730243\n",
      "Error on this batch = 1.328254810749886\n",
      "Error on this batch = 1.376386258720426\n",
      "Cost on val dataset after 107 epochs is = 1.3771480157745355\n",
      "learning rate =  0.002106389788843754\n",
      "Initial Cost on Val dataset for this epoch 107 = 1.3771480157745355\n",
      "Error on this batch = 1.3230046212079507\n",
      "Error on this batch = 1.3740597873049836\n",
      "Cost on val dataset after 108 epochs is = 1.3717734681071765\n",
      "learning rate =  0.0020998684164914554\n",
      "Initial Cost on Val dataset for this epoch 108 = 1.3717734681071765\n",
      "Error on this batch = 1.3189697190596703\n",
      "Error on this batch = 1.3740195443472412\n",
      "Cost on val dataset after 109 epochs is = 1.3660270192461477\n",
      "learning rate =  0.0020934270618616926\n",
      "Initial Cost on Val dataset for this epoch 109 = 1.3660270192461477\n",
      "Error on this batch = 1.3121343524546216\n",
      "Error on this batch = 1.3727784943320256\n",
      "Cost on val dataset after 110 epochs is = 1.3584739702992368\n",
      "learning rate =  0.0020870640224232317\n",
      "Initial Cost on Val dataset for this epoch 110 = 1.3584739702992368\n",
      "Error on this batch = 1.3017505176029693\n",
      "Error on this batch = 1.370273913812804\n",
      "Cost on val dataset after 111 epochs is = 1.3523441440397237\n",
      "learning rate =  0.0020807776469269255\n",
      "Initial Cost on Val dataset for this epoch 111 = 1.3523441440397237\n",
      "Error on this batch = 1.2958803108957246\n",
      "Error on this batch = 1.369726531027096\n",
      "Cost on val dataset after 112 epochs is = 1.3473451718993987\n",
      "learning rate =  0.002074566333415609\n",
      "Initial Cost on Val dataset for this epoch 112 = 1.3473451718993987\n",
      "Error on this batch = 1.292719624299262\n",
      "Error on this batch = 1.369124314477496\n",
      "Cost on val dataset after 113 epochs is = 1.3408231003070332\n",
      "learning rate =  0.002068428527328215\n",
      "Initial Cost on Val dataset for this epoch 113 = 1.3408231003070332\n",
      "Error on this batch = 1.290349481188249\n",
      "Error on this batch = 1.3524200771114472\n",
      "Cost on val dataset after 114 epochs is = 1.3341667005262654\n",
      "learning rate =  0.0020623627196928386\n",
      "Initial Cost on Val dataset for this epoch 114 = 1.3341667005262654\n",
      "Error on this batch = 1.2841184956525495\n",
      "Error on this batch = 1.3372480214338487\n",
      "Cost on val dataset after 115 epochs is = 1.3280040144135925\n",
      "learning rate =  0.0020563674454038526\n",
      "Initial Cost on Val dataset for this epoch 115 = 1.3280040144135925\n",
      "Error on this batch = 1.284333270461967\n",
      "Error on this batch = 1.3144350765388755\n",
      "Cost on val dataset after 116 epochs is = 1.3193656086590775\n",
      "learning rate =  0.0020504412815784637\n",
      "Initial Cost on Val dataset for this epoch 116 = 1.3193656086590775\n",
      "Error on this batch = 1.2843056245532771\n",
      "Error on this batch = 1.3051460016233791\n",
      "Cost on val dataset after 117 epochs is = 1.311967685680538\n",
      "learning rate =  0.002044582845988404\n",
      "Initial Cost on Val dataset for this epoch 117 = 1.311967685680538\n",
      "Error on this batch = 1.2778466133433997\n",
      "Error on this batch = 1.3030666639493904\n",
      "Cost on val dataset after 118 epochs is = 1.3053346378124149\n",
      "learning rate =  0.0020387907955627038\n",
      "Initial Cost on Val dataset for this epoch 118 = 1.3053346378124149\n",
      "Error on this batch = 1.2745897697490083\n",
      "Error on this batch = 1.291825049552852\n",
      "Cost on val dataset after 119 epochs is = 1.2964753368747588\n",
      "learning rate =  0.002033063824957759\n",
      "Initial Cost on Val dataset for this epoch 119 = 1.2964753368747588\n",
      "Error on this batch = 1.2696083709719668\n",
      "Error on this batch = 1.2847331080165714\n",
      "Cost on val dataset after 120 epochs is = 1.2881035102163123\n",
      "learning rate =  0.0020274006651911335\n",
      "Initial Cost on Val dataset for this epoch 120 = 1.2881035102163123\n",
      "Error on this batch = 1.2647577969026982\n",
      "Error on this batch = 1.2719288000160722\n",
      "Cost on val dataset after 121 epochs is = 1.2793093683380914\n",
      "learning rate =  0.0020218000823357418\n",
      "Initial Cost on Val dataset for this epoch 121 = 1.2793093683380914\n",
      "Error on this batch = 1.2492389828765444\n",
      "Error on this batch = 1.2550400541992603\n",
      "Cost on val dataset after 122 epochs is = 1.2713617626199407\n",
      "learning rate =  0.002016260876271276\n",
      "Initial Cost on Val dataset for this epoch 122 = 1.2713617626199407\n",
      "Error on this batch = 1.2403963099959707\n",
      "Error on this batch = 1.2486496437553773\n",
      "Cost on val dataset after 123 epochs is = 1.2632857664630206\n",
      "learning rate =  0.0020107818794899246\n",
      "Initial Cost on Val dataset for this epoch 123 = 1.2632857664630206\n",
      "Error on this batch = 1.221032030290531\n",
      "Error on this batch = 1.2354847356103411\n",
      "Cost on val dataset after 124 epochs is = 1.2529959860283995\n",
      "learning rate =  0.0020053619559535895\n",
      "Initial Cost on Val dataset for this epoch 124 = 1.2529959860283995\n",
      "Error on this batch = 1.2062755695995158\n",
      "Error on this batch = 1.2343155392103464\n",
      "Cost on val dataset after 125 epochs is = 1.2447902202730716\n",
      "learning rate =  0.0020000000000000005\n",
      "Initial Cost on Val dataset for this epoch 125 = 1.2447902202730716\n",
      "Error on this batch = 1.2006835278023502\n",
      "Error on this batch = 1.224825014270768\n",
      "Cost on val dataset after 126 epochs is = 1.2363471425411077\n",
      "learning rate =  0.0019946949352952514\n",
      "Initial Cost on Val dataset for this epoch 126 = 1.2363471425411077\n",
      "Error on this batch = 1.1861170757642066\n",
      "Error on this batch = 1.2258898848228976\n",
      "Cost on val dataset after 127 epochs is = 1.2296643018772029\n",
      "learning rate =  0.0019894457138304456\n",
      "Initial Cost on Val dataset for this epoch 127 = 1.2296643018772029\n",
      "Error on this batch = 1.1829145492056106\n",
      "Error on this batch = 1.2246169695178302\n",
      "Cost on val dataset after 128 epochs is = 1.219512919722442\n",
      "learning rate =  0.0019842513149602495\n",
      "Initial Cost on Val dataset for this epoch 128 = 1.219512919722442\n",
      "Error on this batch = 1.1739850325256673\n",
      "Error on this batch = 1.2152841930812575\n",
      "Cost on val dataset after 129 epochs is = 1.2081494044172607\n",
      "learning rate =  0.0019791107444813104\n",
      "Initial Cost on Val dataset for this epoch 129 = 1.2081494044172607\n",
      "Error on this batch = 1.168336917192073\n",
      "Error on this batch = 1.207818525281748\n",
      "Cost on val dataset after 130 epochs is = 1.197973385176475\n",
      "learning rate =  0.0019740230337485713\n",
      "Initial Cost on Val dataset for this epoch 130 = 1.197973385176475\n",
      "Error on this batch = 1.1514334686207357\n",
      "Error on this batch = 1.1950332562656198\n",
      "Cost on val dataset after 131 epochs is = 1.1873326802929964\n",
      "learning rate =  0.001968987238827663\n",
      "Initial Cost on Val dataset for this epoch 131 = 1.1873326802929964\n",
      "Error on this batch = 1.1404761871589253\n",
      "Error on this batch = 1.176567270154508\n",
      "Cost on val dataset after 132 epochs is = 1.177234466349082\n",
      "learning rate =  0.001964002439681624\n",
      "Initial Cost on Val dataset for this epoch 132 = 1.177234466349082\n",
      "Error on this batch = 1.1390078768610645\n",
      "Error on this batch = 1.1622097356704115\n",
      "Cost on val dataset after 133 epochs is = 1.1694027602773343\n",
      "learning rate =  0.00195906773939032\n",
      "Initial Cost on Val dataset for this epoch 133 = 1.1694027602773343\n",
      "Error on this batch = 1.1351415795299677\n",
      "Error on this batch = 1.1581492203236072\n",
      "Cost on val dataset after 134 epochs is = 1.1621247324447923\n",
      "learning rate =  0.001954182263401007\n",
      "Initial Cost on Val dataset for this epoch 134 = 1.1621247324447923\n",
      "Error on this batch = 1.1285421311301014\n",
      "Error on this batch = 1.1480562479253056\n",
      "Cost on val dataset after 135 epochs is = 1.155909763004008\n",
      "learning rate =  0.0019493451588085777\n",
      "Initial Cost on Val dataset for this epoch 135 = 1.155909763004008\n",
      "Error on this batch = 1.1183611719817874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 1.1375386492106478\n",
      "Cost on val dataset after 136 epochs is = 1.149694701560518\n",
      "learning rate =  0.0019445555936641018\n",
      "Initial Cost on Val dataset for this epoch 136 = 1.149694701560518\n",
      "Error on this batch = 1.1137420652608818\n",
      "Error on this batch = 1.130267809349989\n",
      "Cost on val dataset after 137 epochs is = 1.142225414442883\n",
      "learning rate =  0.001939812756310351\n",
      "Initial Cost on Val dataset for this epoch 137 = 1.142225414442883\n",
      "Error on this batch = 1.1082339250604394\n",
      "Error on this batch = 1.1228198360548394\n",
      "Cost on val dataset after 138 epochs is = 1.1354049667678414\n",
      "learning rate =  0.0019351158547430665\n",
      "Initial Cost on Val dataset for this epoch 138 = 1.1354049667678414\n",
      "Error on this batch = 1.1075031942798126\n",
      "Error on this batch = 1.1158475995130737\n",
      "Cost on val dataset after 139 epochs is = 1.1296559818591445\n",
      "learning rate =  0.0019304641159967957\n",
      "Initial Cost on Val dataset for this epoch 139 = 1.1296559818591445\n",
      "Error on this batch = 1.1069237226715034\n",
      "Error on this batch = 1.1135495149299948\n",
      "Cost on val dataset after 140 epochs is = 1.123345402043398\n",
      "learning rate =  0.001925856785554179\n",
      "Initial Cost on Val dataset for this epoch 140 = 1.123345402043398\n",
      "Error on this batch = 1.1035369109090016\n",
      "Error on this batch = 1.1098058135157174\n",
      "Cost on val dataset after 141 epochs is = 1.1164426501823603\n",
      "learning rate =  0.001921293126777635\n",
      "Initial Cost on Val dataset for this epoch 141 = 1.1164426501823603\n",
      "Error on this batch = 1.1011911442632707\n",
      "Error on this batch = 1.0965051384620972\n",
      "Cost on val dataset after 142 epochs is = 1.1105669726160166\n",
      "learning rate =  0.001916772420362441\n",
      "Initial Cost on Val dataset for this epoch 142 = 1.1105669726160166\n",
      "Error on this batch = 1.0969308821296353\n",
      "Error on this batch = 1.0852171462057327\n",
      "Cost on val dataset after 143 epochs is = 1.1057984554538065\n",
      "learning rate =  0.001912293963810262\n",
      "Initial Cost on Val dataset for this epoch 143 = 1.1057984554538065\n",
      "Error on this batch = 1.0986352968385538\n",
      "Error on this batch = 1.0817257597577727\n",
      "Cost on val dataset after 144 epochs is = 1.1010439860620866\n",
      "learning rate =  0.00190785707092222\n",
      "Initial Cost on Val dataset for this epoch 144 = 1.1010439860620866\n",
      "Error on this batch = 1.0982357635175717\n",
      "Error on this batch = 1.0783146617274524\n",
      "Cost on val dataset after 145 epochs is = 1.0963096879762884\n",
      "learning rate =  0.0019034610713106548\n",
      "Initial Cost on Val dataset for this epoch 145 = 1.0963096879762884\n",
      "Error on this batch = 1.094673389314226\n",
      "Error on this batch = 1.0733568862837188\n",
      "Cost on val dataset after 146 epochs is = 1.0920397043574779\n",
      "learning rate =  0.001899105309928761\n",
      "Initial Cost on Val dataset for this epoch 146 = 1.0920397043574779\n",
      "Error on this batch = 1.0900676858318457\n",
      "Error on this batch = 1.071290276481142\n",
      "Cost on val dataset after 147 epochs is = 1.087153444335002\n",
      "learning rate =  0.0018947891466173294\n",
      "Initial Cost on Val dataset for this epoch 147 = 1.087153444335002\n",
      "Error on this batch = 1.0828018577686802\n",
      "Error on this batch = 1.0669206271586038\n",
      "Cost on val dataset after 148 epochs is = 1.0829394979950695\n",
      "learning rate =  0.0018905119556678594\n",
      "Initial Cost on Val dataset for this epoch 148 = 1.0829394979950695\n",
      "Error on this batch = 1.0751585353938875\n",
      "Error on this batch = 1.0653883253326413\n",
      "Cost on val dataset after 149 epochs is = 1.079392211432797\n",
      "learning rate =  0.0018862731254013418\n",
      "Initial Cost on Val dataset for this epoch 149 = 1.079392211432797\n",
      "Error on this batch = 1.0726334450059747\n",
      "Error on this batch = 1.0630580461336012\n",
      "Cost on val dataset after 150 epochs is = 1.0758960748540096\n",
      "learning rate =  0.0018820720577620571\n",
      "Initial Cost on Val dataset for this epoch 150 = 1.0758960748540096\n",
      "Error on this batch = 1.0739868437664206\n",
      "Error on this batch = 1.0617115543249258\n",
      "Cost on val dataset after 151 epochs is = 1.0721132500338122\n",
      "learning rate =  0.0018779081679257492\n",
      "Initial Cost on Val dataset for this epoch 151 = 1.0721132500338122\n",
      "Error on this batch = 1.0738284604450499\n",
      "Error on this batch = 1.0574392388803335\n",
      "Cost on val dataset after 152 epochs is = 1.0689907583987142\n",
      "learning rate =  0.0018737808839215777\n",
      "Initial Cost on Val dataset for this epoch 152 = 1.0689907583987142\n",
      "Error on this batch = 1.070702369660171\n",
      "Error on this batch = 1.0509831099658309\n",
      "Cost on val dataset after 153 epochs is = 1.066141952406238\n",
      "learning rate =  0.0018696896462672785\n",
      "Initial Cost on Val dataset for this epoch 153 = 1.066141952406238\n",
      "Error on this batch = 1.068314381123537\n",
      "Error on this batch = 1.0457980852951294\n",
      "Cost on val dataset after 154 epochs is = 1.0629078734584314\n",
      "learning rate =  0.0018656339076169892\n",
      "Initial Cost on Val dataset for this epoch 154 = 1.0629078734584314\n",
      "Error on this batch = 1.0647727277077979\n",
      "Error on this batch = 1.0446900219533144\n",
      "Cost on val dataset after 155 epochs is = 1.0597021322947755\n",
      "learning rate =  0.0018616131324212123\n",
      "Initial Cost on Val dataset for this epoch 155 = 1.0597021322947755\n",
      "Error on this batch = 1.0610758335185315\n",
      "Error on this batch = 1.0439836311974404\n",
      "Cost on val dataset after 156 epochs is = 1.0570470861505408\n",
      "learning rate =  0.0018576267965984361\n",
      "Initial Cost on Val dataset for this epoch 156 = 1.0570470861505408\n",
      "Error on this batch = 1.059546778676924\n",
      "Error on this batch = 1.0433112811387426\n",
      "Cost on val dataset after 157 epochs is = 1.0545072129532036\n",
      "learning rate =  0.0018536743872179294\n",
      "Initial Cost on Val dataset for this epoch 157 = 1.0545072129532036\n",
      "Error on this batch = 1.05910282604813\n",
      "Error on this batch = 1.0426292201800398\n",
      "Cost on val dataset after 158 epochs is = 1.0521373489209767\n",
      "learning rate =  0.0018497554021932685\n",
      "Initial Cost on Val dataset for this epoch 158 = 1.0521373489209767\n",
      "Error on this batch = 1.0583450095032936\n",
      "Error on this batch = 1.0418616253206339\n",
      "Cost on val dataset after 159 epochs is = 1.0495877135348033\n",
      "learning rate =  0.0018458693499861668\n",
      "Initial Cost on Val dataset for this epoch 159 = 1.0495877135348033\n",
      "Error on this batch = 1.0563316657187352\n",
      "Error on this batch = 1.0407318447801677\n",
      "Cost on val dataset after 160 epochs is = 1.0472496412082897\n",
      "learning rate =  0.0018420157493201936\n",
      "Initial Cost on Val dataset for this epoch 160 = 1.0472496412082897\n",
      "Error on this batch = 1.0521125418024189\n",
      "Error on this batch = 1.0387949595430812\n",
      "Cost on val dataset after 161 epochs is = 1.0447270227410552\n",
      "learning rate =  0.0018381941289040019\n",
      "Initial Cost on Val dataset for this epoch 161 = 1.0447270227410552\n",
      "Error on this batch = 1.0471728246468712\n",
      "Error on this batch = 1.036455593005452\n",
      "Cost on val dataset after 162 epochs is = 1.042056580667415\n",
      "learning rate =  0.0018344040271636817\n",
      "Initial Cost on Val dataset for this epoch 162 = 1.042056580667415\n",
      "Error on this batch = 1.0438092388553588\n",
      "Error on this batch = 1.0341761057486671\n",
      "Cost on val dataset after 163 epochs is = 1.0394882454618086\n",
      "learning rate =  0.0018306449919838924\n",
      "Initial Cost on Val dataset for this epoch 163 = 1.0394882454618086\n",
      "Error on this batch = 1.0399305700809338\n",
      "Error on this batch = 1.030866197323842\n",
      "Cost on val dataset after 164 epochs is = 1.0371435346847784\n",
      "learning rate =  0.001826916580457428\n",
      "Initial Cost on Val dataset for this epoch 164 = 1.0371435346847784\n",
      "Error on this batch = 1.0378482635524195\n",
      "Error on this batch = 1.0276120604027659\n",
      "Cost on val dataset after 165 epochs is = 1.035083073091011\n",
      "learning rate =  0.0018232183586428963\n",
      "Initial Cost on Val dataset for this epoch 165 = 1.035083073091011\n",
      "Error on this batch = 1.0356670673156467\n",
      "Error on this batch = 1.0264176385035457\n",
      "Cost on val dataset after 166 epochs is = 1.0329694834715213\n",
      "learning rate =  0.0018195499013301977\n",
      "Initial Cost on Val dataset for this epoch 166 = 1.0329694834715213\n",
      "Error on this batch = 1.032970732848716\n",
      "Error on this batch = 1.026122866239494\n",
      "Cost on val dataset after 167 epochs is = 1.0307995403368744\n",
      "learning rate =  0.0018159107918135084\n",
      "Initial Cost on Val dataset for this epoch 167 = 1.0307995403368744\n",
      "Error on this batch = 1.030882630350062\n",
      "Error on this batch = 1.0258666242259316\n",
      "Cost on val dataset after 168 epochs is = 1.0286803354135303\n",
      "learning rate =  0.0018123006216714873\n",
      "Initial Cost on Val dataset for this epoch 168 = 1.0286803354135303\n",
      "Error on this batch = 1.0296629865338711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 1.0254966773583578\n",
      "Cost on val dataset after 169 epochs is = 1.026573632639944\n",
      "learning rate =  0.0018087189905544292\n",
      "Initial Cost on Val dataset for this epoch 169 = 1.026573632639944\n",
      "Error on this batch = 1.0287171585427752\n",
      "Error on this batch = 1.024909279574815\n",
      "Cost on val dataset after 170 epochs is = 1.0244463228373697\n",
      "learning rate =  0.0018051655059781123\n",
      "Initial Cost on Val dataset for this epoch 170 = 1.0244463228373697\n",
      "Error on this batch = 1.0273972779423417\n",
      "Error on this batch = 1.023817958848\n",
      "Cost on val dataset after 171 epochs is = 1.0223791349954297\n",
      "learning rate =  0.0018016397831240876\n",
      "Initial Cost on Val dataset for this epoch 171 = 1.0223791349954297\n",
      "Error on this batch = 1.0252429749121834\n",
      "Error on this batch = 1.0217962778019696\n",
      "Cost on val dataset after 172 epochs is = 1.020217353413741\n",
      "learning rate =  0.001798141444646168\n",
      "Initial Cost on Val dataset for this epoch 172 = 1.020217353413741\n",
      "Error on this batch = 1.0214851082419572\n",
      "Error on this batch = 1.018731116023086\n",
      "Cost on val dataset after 173 epochs is = 1.0177911156819128\n",
      "learning rate =  0.0017946701204829033\n",
      "Initial Cost on Val dataset for this epoch 173 = 1.0177911156819128\n",
      "Error on this batch = 1.0162649958794128\n",
      "Error on this batch = 1.0162407246536385\n",
      "Cost on val dataset after 174 epochs is = 1.0151033200316355\n",
      "learning rate =  0.0017912254476758068\n",
      "Initial Cost on Val dataset for this epoch 174 = 1.0151033200316355\n",
      "Error on this batch = 1.0121389916948291\n",
      "Error on this batch = 1.0154955400729515\n",
      "Cost on val dataset after 175 epochs is = 1.0125590005597511\n",
      "learning rate =  0.0017878070701931354\n",
      "Initial Cost on Val dataset for this epoch 175 = 1.0125590005597511\n",
      "Error on this batch = 1.0084722554094703\n",
      "Error on this batch = 1.015318928803611\n",
      "Cost on val dataset after 176 epochs is = 1.0103362666965598\n",
      "learning rate =  0.0017844146387590207\n",
      "Initial Cost on Val dataset for this epoch 176 = 1.0103362666965598\n",
      "Error on this batch = 1.0049189965817236\n",
      "Error on this batch = 1.0151730439441438\n",
      "Cost on val dataset after 177 epochs is = 1.0084734817375893\n",
      "learning rate =  0.0017810478106877552\n",
      "Initial Cost on Val dataset for this epoch 177 = 1.0084734817375893\n",
      "Error on this batch = 1.0030834861624895\n",
      "Error on this batch = 1.015047756424622\n",
      "Cost on val dataset after 178 epochs is = 1.0065756585054646\n",
      "learning rate =  0.0017777062497230567\n",
      "Initial Cost on Val dataset for this epoch 178 = 1.0065756585054646\n",
      "Error on this batch = 1.0013349456089977\n",
      "Error on this batch = 1.01501529416938\n",
      "Cost on val dataset after 179 epochs is = 1.0042147011590474\n",
      "learning rate =  0.0017743896258821292\n",
      "Initial Cost on Val dataset for this epoch 179 = 1.0042147011590474\n",
      "Error on this batch = 0.9984285881749954\n",
      "Error on this batch = 1.0150562858516046\n",
      "Cost on val dataset after 180 epochs is = 1.0016693233090102\n",
      "learning rate =  0.001771097615304352\n",
      "Initial Cost on Val dataset for this epoch 180 = 1.0016693233090102\n",
      "Error on this batch = 0.9957788492579076\n",
      "Error on this batch = 1.0149821457333643\n",
      "Cost on val dataset after 181 epochs is = 0.9991448107443388\n",
      "learning rate =  0.0017678299001044377\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.9991448107443388\n",
      "Error on this batch = 0.9946948125647671\n",
      "Error on this batch = 1.0147056321652352\n",
      "Cost on val dataset after 182 epochs is = 0.996439412412283\n",
      "learning rate =  0.001764586168229899\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.996439412412283\n",
      "Error on this batch = 0.9943825330831746\n",
      "Error on this batch = 1.014116343801099\n",
      "Cost on val dataset after 183 epochs is = 0.9934010644320658\n",
      "learning rate =  0.0017613661133226788\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.9934010644320658\n",
      "Error on this batch = 0.9941052061119251\n",
      "Error on this batch = 1.0125675862175714\n",
      "Cost on val dataset after 184 epochs is = 0.9897987506941304\n",
      "learning rate =  0.001758169434584797\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.9897987506941304\n",
      "Error on this batch = 0.992132608976201\n",
      "Error on this batch = 1.0093310835016007\n",
      "Cost on val dataset after 185 epochs is = 0.9863980357406256\n",
      "learning rate =  0.0017549958366478784\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.9863980357406256\n",
      "Error on this batch = 0.9893055959798548\n",
      "Error on this batch = 1.0037407762419652\n",
      "Cost on val dataset after 186 epochs is = 0.9826959537514568\n",
      "learning rate =  0.0017518450294464298\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.9826959537514568\n",
      "Error on this batch = 0.9882350379428624\n",
      "Error on this batch = 0.997137760264924\n",
      "Cost on val dataset after 187 epochs is = 0.9786142804999639\n",
      "learning rate =  0.0017487167280947338\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.9786142804999639\n",
      "Error on this batch = 0.9843446825553991\n",
      "Error on this batch = 0.9908537153712385\n",
      "Cost on val dataset after 188 epochs is = 0.9739650708604425\n",
      "learning rate =  0.0017456106527672455\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.9739650708604425\n",
      "Error on this batch = 0.9786592479465472\n",
      "Error on this batch = 0.9825378327482541\n",
      "Cost on val dataset after 189 epochs is = 0.9689316646092169\n",
      "learning rate =  0.0017425265285823674\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.9689316646092169\n",
      "Error on this batch = 0.9731197421197088\n",
      "Error on this batch = 0.97595344092873\n",
      "Cost on val dataset after 190 epochs is = 0.9648119490573084\n",
      "learning rate =  0.0017394640854894953\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.9648119490573084\n",
      "Error on this batch = 0.9684090184730195\n",
      "Error on this batch = 0.9735542007564338\n",
      "Cost on val dataset after 191 epochs is = 0.9591775204622127\n",
      "learning rate =  0.0017364230581592198\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.9591775204622127\n",
      "Error on this batch = 0.9579007820079702\n",
      "Error on this batch = 0.9720392289428506\n",
      "Cost on val dataset after 192 epochs is = 0.9523094885150614\n",
      "learning rate =  0.0017334031858765868\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.9523094885150614\n",
      "Error on this batch = 0.9481649342021381\n",
      "Error on this batch = 0.9698328769773176\n",
      "Cost on val dataset after 193 epochs is = 0.9446255233739593\n",
      "learning rate =  0.001730404212437312\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.9446255233739593\n",
      "Error on this batch = 0.9427913122852012\n",
      "Error on this batch = 0.9659962835632133\n",
      "Cost on val dataset after 194 epochs is = 0.9343051148828097\n",
      "learning rate =  0.0017274258860468501\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.9343051148828097\n",
      "Error on this batch = 0.9404186960623092\n",
      "Error on this batch = 0.9606715259792423\n",
      "Cost on val dataset after 195 epochs is = 0.9260034101852838\n",
      "learning rate =  0.0017244679592222354\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.9260034101852838\n",
      "Error on this batch = 0.9381254547161525\n",
      "Error on this batch = 0.9440759534163371\n",
      "Cost on val dataset after 196 epochs is = 0.9154325570321209\n",
      "learning rate =  0.001721530188696593\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.9154325570321209\n",
      "Error on this batch = 0.9311701597443737\n",
      "Error on this batch = 0.9370791140995489\n",
      "Cost on val dataset after 197 epochs is = 0.9032022996331652\n",
      "learning rate =  0.0017186123353262403\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.9032022996331652\n",
      "Error on this batch = 0.9220914589312027\n",
      "Error on this batch = 0.9250860347828982\n",
      "Cost on val dataset after 198 epochs is = 0.8913462921454144\n",
      "learning rate =  0.0017157141640002978\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.8913462921454144\n",
      "Error on this batch = 0.9061888237754883\n",
      "Error on this batch = 0.9085354791234841\n",
      "Cost on val dataset after 199 epochs is = 0.8739293810796221\n",
      "learning rate =  0.0017128354435527232\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.8739293810796221\n",
      "Error on this batch = 0.8830604037090011\n",
      "Error on this batch = 0.8845783377307345\n",
      "Cost on val dataset after 200 epochs is = 0.855920044767294\n",
      "learning rate =  0.0017099759466766974\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.855920044767294\n",
      "Error on this batch = 0.8558252590011813\n",
      "Error on this batch = 0.8610250931342169\n",
      "Cost on val dataset after 201 epochs is = 0.8370983027851844\n",
      "learning rate =  0.0017071354498412838\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.8370983027851844\n",
      "Error on this batch = 0.8283025496059552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.8534534043379459\n",
      "Cost on val dataset after 202 epochs is = 0.8182180282396881\n",
      "learning rate =  0.001704313733210296\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.8182180282396881\n",
      "Error on this batch = 0.8038653339011633\n",
      "Error on this batch = 0.8402408690278369\n",
      "Cost on val dataset after 203 epochs is = 0.7988298422645931\n",
      "learning rate =  0.001701510580563294\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.7988298422645931\n",
      "Error on this batch = 0.7841569841947725\n",
      "Error on this batch = 0.8168655674804716\n",
      "Cost on val dataset after 204 epochs is = 0.7824701347538905\n",
      "learning rate =  0.0016987257792186554\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.7824701347538905\n",
      "Error on this batch = 0.7717147852387458\n",
      "Error on this batch = 0.8046958987315431\n",
      "Cost on val dataset after 205 epochs is = 0.7647607049652884\n",
      "learning rate =  0.001695959119958648\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.7647607049652884\n",
      "Error on this batch = 0.757644880925547\n",
      "Error on this batch = 0.7810763413339038\n",
      "Cost on val dataset after 206 epochs is = 0.7475794367135055\n",
      "learning rate =  0.0016932103969564453\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.7475794367135055\n",
      "Error on this batch = 0.74998123504812\n",
      "Error on this batch = 0.7694131841572256\n",
      "Cost on val dataset after 207 epochs is = 0.7306709590318972\n",
      "learning rate =  0.0016904794077050283\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.7306709590318972\n",
      "Error on this batch = 0.72936989873222\n",
      "Error on this batch = 0.7495232291547843\n",
      "Cost on val dataset after 208 epochs is = 0.7141997725353415\n",
      "learning rate =  0.0016877659529479093\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.7141997725353415\n",
      "Error on this batch = 0.707654022668282\n",
      "Error on this batch = 0.7293300921081988\n",
      "Cost on val dataset after 209 epochs is = 0.6996601102086543\n",
      "learning rate =  0.0016850698366116302\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.6996601102086543\n",
      "Error on this batch = 0.6864808650361585\n",
      "Error on this batch = 0.7218912663793355\n",
      "Cost on val dataset after 210 epochs is = 0.6866872650781611\n",
      "learning rate =  0.0016823908657399745\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.6866872650781611\n",
      "Error on this batch = 0.6621988109304932\n",
      "Error on this batch = 0.7124238860679006\n",
      "Cost on val dataset after 211 epochs is = 0.6759940508700002\n",
      "learning rate =  0.0016797288504298471\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.6759940508700002\n",
      "Error on this batch = 0.6492350288682134\n",
      "Error on this batch = 0.6970316032313874\n",
      "Cost on val dataset after 212 epochs is = 0.667342804534156\n",
      "learning rate =  0.0016770836037687698\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.667342804534156\n",
      "Error on this batch = 0.641787077902621\n",
      "Error on this batch = 0.6852258082700138\n",
      "Cost on val dataset after 213 epochs is = 0.6584316285900019\n",
      "learning rate =  0.0016744549417739417\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.6584316285900019\n",
      "Error on this batch = 0.6388971990636809\n",
      "Error on this batch = 0.6783984787232737\n",
      "Cost on val dataset after 214 epochs is = 0.6503908876466076\n",
      "learning rate =  0.0016718426833328246\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.6503908876466076\n",
      "Error on this batch = 0.6267295260310436\n",
      "Error on this batch = 0.6726553013390825\n",
      "Cost on val dataset after 215 epochs is = 0.6424128468965569\n",
      "learning rate =  0.0016692466501452008\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.6424128468965569\n",
      "Error on this batch = 0.6239187828128968\n",
      "Error on this batch = 0.6704316129386699\n",
      "Cost on val dataset after 216 epochs is = 0.6353934032579583\n",
      "learning rate =  0.001666666666666667\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.6353934032579583\n",
      "Error on this batch = 0.6211580253738397\n",
      "Error on this batch = 0.6666694416889787\n",
      "Cost on val dataset after 217 epochs is = 0.6290206065153292\n",
      "learning rate =  0.0016641025600535164\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.6290206065153292\n",
      "Error on this batch = 0.6125418947694992\n",
      "Error on this batch = 0.6617665676175173\n",
      "Cost on val dataset after 218 epochs is = 0.6234283897498383\n",
      "learning rate =  0.001661554160108974\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.6234283897498383\n",
      "Error on this batch = 0.6064975417669473\n",
      "Error on this batch = 0.6578229895950451\n",
      "Cost on val dataset after 219 epochs is = 0.6183774552459301\n",
      "learning rate =  0.00165902129923074\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.6183774552459301\n",
      "Error on this batch = 0.6057182763333697\n",
      "Error on this batch = 0.6525885903399816\n",
      "Cost on val dataset after 220 epochs is = 0.6132356426543019\n",
      "learning rate =  0.0016565038123598102\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.6132356426543019\n",
      "Error on this batch = 0.6025810092870417\n",
      "Error on this batch = 0.6506047566743038\n",
      "Cost on val dataset after 221 epochs is = 0.6091248756860269\n",
      "learning rate =  0.0016540015369305313\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.6091248756860269\n",
      "Error on this batch = 0.5963529494794826\n",
      "Error on this batch = 0.647636531290855\n",
      "Cost on val dataset after 222 epochs is = 0.6058959446781897\n",
      "learning rate =  0.0016515143128218578\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.6058959446781897\n",
      "Error on this batch = 0.5869219166095627\n",
      "Error on this batch = 0.6434730440601711\n",
      "Cost on val dataset after 223 epochs is = 0.6029184939378003\n",
      "learning rate =  0.0016490419823097784\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.6029184939378003\n",
      "Error on this batch = 0.5793699075312398\n",
      "Error on this batch = 0.6397582961075304\n",
      "Cost on val dataset after 224 epochs is = 0.6001404027977866\n",
      "learning rate =  0.0016465843900208739\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.6001404027977866\n",
      "Error on this batch = 0.57418351451574\n",
      "Error on this batch = 0.6341730031669359\n",
      "Cost on val dataset after 225 epochs is = 0.5968509110756542\n",
      "learning rate =  0.0016441413828869804\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.5968509110756542\n",
      "Error on this batch = 0.5700439901188702\n",
      "Error on this batch = 0.626855472010896\n",
      "Cost on val dataset after 226 epochs is = 0.5936760358767023\n",
      "learning rate =  0.001641712810100921\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.5936760358767023\n",
      "Error on this batch = 0.5682208871833782\n",
      "Error on this batch = 0.6216936543996251\n",
      "Cost on val dataset after 227 epochs is = 0.5908947839413284\n",
      "learning rate =  0.0016392985230732832\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.5908947839413284\n",
      "Error on this batch = 0.5672222477435716\n",
      "Error on this batch = 0.6169801654031686\n",
      "Cost on val dataset after 228 epochs is = 0.5884673976947276\n",
      "learning rate =  0.0016368983753902045\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.5884673976947276\n",
      "Error on this batch = 0.5662806696484975\n",
      "Error on this batch = 0.6128850751863307\n",
      "Cost on val dataset after 229 epochs is = 0.5862452908274561\n",
      "learning rate =  0.001634512222772145\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.5862452908274561\n",
      "Error on this batch = 0.5654034751376787\n",
      "Error on this batch = 0.6095288059527758\n",
      "Cost on val dataset after 230 epochs is = 0.5840064455703071\n",
      "learning rate =  0.001632139923033617\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.5840064455703071\n",
      "Error on this batch = 0.5647043658299804\n",
      "Error on this batch = 0.6066228056175441\n",
      "Cost on val dataset after 231 epochs is = 0.581968238459176\n",
      "learning rate =  0.0016297813360438467\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.581968238459176\n",
      "Error on this batch = 0.5641338891031732\n",
      "Error on this batch = 0.6044463304137946\n",
      "Cost on val dataset after 232 epochs is = 0.5801263267097144\n",
      "learning rate =  0.0016274363236883382\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.5801263267097144\n",
      "Error on this batch = 0.5635788717509488\n",
      "Error on this batch = 0.6029876728780508\n",
      "Cost on val dataset after 233 epochs is = 0.578469409509796\n",
      "learning rate =  0.0016251047498313232\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.578469409509796\n",
      "Error on this batch = 0.5628160677310322\n",
      "Error on this batch = 0.6017447305657541\n",
      "Cost on val dataset after 234 epochs is = 0.576968655854827\n",
      "learning rate =  0.0016227864802790641\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.576968655854827\n",
      "Error on this batch = 0.5613803224362672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.6000231842904548\n",
      "Cost on val dataset after 235 epochs is = 0.5754642441689731\n",
      "learning rate =  0.001620481382743992\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.5754642441689731\n",
      "Error on this batch = 0.5591688516695819\n",
      "Error on this batch = 0.5972458176819005\n",
      "Cost on val dataset after 236 epochs is = 0.5739874009773464\n",
      "learning rate =  0.0016181893268096589\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.5739874009773464\n",
      "Error on this batch = 0.5576923896684685\n",
      "Error on this batch = 0.595231861428376\n",
      "Cost on val dataset after 237 epochs is = 0.5726309635083919\n",
      "learning rate =  0.001615910183896475\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.5726309635083919\n",
      "Error on this batch = 0.557250988376042\n",
      "Error on this batch = 0.5941558057634635\n",
      "Cost on val dataset after 238 epochs is = 0.5712908583901779\n",
      "learning rate =  0.001613643827228219\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.5712908583901779\n",
      "Error on this batch = 0.5570325661470246\n",
      "Error on this batch = 0.5930183746549264\n",
      "Cost on val dataset after 239 epochs is = 0.5700662130427613\n",
      "learning rate =  0.0016113901317992947\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.5700662130427613\n",
      "Error on this batch = 0.5567699318173164\n",
      "Error on this batch = 0.5913096328219837\n",
      "Cost on val dataset after 240 epochs is = 0.5689361067081184\n",
      "learning rate =  0.0016091489743427165\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.5689361067081184\n",
      "Error on this batch = 0.5564572252922625\n",
      "Error on this batch = 0.5889187454940762\n",
      "Cost on val dataset after 241 epochs is = 0.567814262814832\n",
      "learning rate =  0.0016069202332988054\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.567814262814832\n",
      "Error on this batch = 0.5561154166446487\n",
      "Error on this batch = 0.5862387260393799\n",
      "Cost on val dataset after 242 epochs is = 0.5666527489844887\n",
      "learning rate =  0.0016047037887845742\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.5666527489844887\n",
      "Error on this batch = 0.5557611395100761\n",
      "Error on this batch = 0.5838083604547396\n",
      "Cost on val dataset after 243 epochs is = 0.5654750826159238\n",
      "learning rate =  0.0016024995225637874\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.5654750826159238\n",
      "Error on this batch = 0.5553811631884271\n",
      "Error on this batch = 0.5815867563939173\n",
      "Cost on val dataset after 244 epochs is = 0.5642852947374433\n",
      "learning rate =  0.0016003073180176739\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.5642852947374433\n",
      "Error on this batch = 0.55496959713656\n",
      "Error on this batch = 0.5793608540755006\n",
      "Cost on val dataset after 245 epochs is = 0.563111540912432\n",
      "learning rate =  0.0015981270601162813\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.563111540912432\n",
      "Error on this batch = 0.5545180999029145\n",
      "Error on this batch = 0.5771562597626229\n",
      "Cost on val dataset after 246 epochs is = 0.5619972989227362\n",
      "learning rate =  0.0015959586353904499\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.5619972989227362\n",
      "Error on this batch = 0.554040569048941\n",
      "Error on this batch = 0.5750982100151583\n",
      "Cost on val dataset after 247 epochs is = 0.5610057034303184\n",
      "learning rate =  0.0015938019319043926\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.5610057034303184\n",
      "Error on this batch = 0.5535514268844071\n",
      "Error on this batch = 0.5731309155392725\n",
      "Cost on val dataset after 248 epochs is = 0.56011776703602\n",
      "learning rate =  0.0015916568392288668\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.56011776703602\n",
      "Error on this batch = 0.5530751879113543\n",
      "Error on this batch = 0.571078701664424\n",
      "Cost on val dataset after 249 epochs is = 0.5592872853584872\n",
      "learning rate =  0.0015895232484149208\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.5592872853584872\n",
      "Error on this batch = 0.552628210050408\n",
      "Error on this batch = 0.5688361939303708\n",
      "Cost on val dataset after 250 epochs is = 0.5584818829073828\n",
      "learning rate =  0.0015874010519681997\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.5584818829073828\n",
      "Error on this batch = 0.5521934205344835\n",
      "Error on this batch = 0.5663861460545606\n",
      "Cost on val dataset after 251 epochs is = 0.557678523608649\n",
      "learning rate =  0.0015852901438238012\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.557678523608649\n",
      "Error on this batch = 0.5517362283823569\n",
      "Error on this batch = 0.5637679139700843\n",
      "Cost on val dataset after 252 epochs is = 0.5568620452553114\n",
      "learning rate =  0.001583190419321661\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.5568620452553114\n",
      "Error on this batch = 0.551227944099186\n",
      "Error on this batch = 0.5611301852833925\n",
      "Cost on val dataset after 253 epochs is = 0.5560365255176344\n",
      "learning rate =  0.0015811017751824602\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.5560365255176344\n",
      "Error on this batch = 0.5506230401213269\n",
      "Error on this batch = 0.558748269668275\n",
      "Cost on val dataset after 254 epochs is = 0.5552097875901112\n",
      "learning rate =  0.0015790241094840373\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.5552097875901112\n",
      "Error on this batch = 0.5498626255503903\n",
      "Error on this batch = 0.5568646481605766\n",
      "Cost on val dataset after 255 epochs is = 0.5544002469244812\n",
      "learning rate =  0.0015769573216382956\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.5544002469244812\n",
      "Error on this batch = 0.5488957874319589\n",
      "Error on this batch = 0.5555615411743726\n",
      "Cost on val dataset after 256 epochs is = 0.553616554955082\n",
      "learning rate =  0.0015749013123685916\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.553616554955082\n",
      "Error on this batch = 0.5476937350836066\n",
      "Error on this batch = 0.5547264787822894\n",
      "Cost on val dataset after 257 epochs is = 0.5528412787086008\n",
      "learning rate =  0.0015728559836875938\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.5528412787086008\n",
      "Error on this batch = 0.546240503345563\n",
      "Error on this batch = 0.554187073478805\n",
      "Cost on val dataset after 258 epochs is = 0.5520891690443925\n",
      "learning rate =  0.001570821238875599\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.5520891690443925\n",
      "Error on this batch = 0.5445614404149214\n",
      "Error on this batch = 0.5538032598105452\n",
      "Cost on val dataset after 259 epochs is = 0.5513763792924554\n",
      "learning rate =  0.0015687969824592972\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.5513763792924554\n",
      "Error on this batch = 0.542741966423678\n",
      "Error on this batch = 0.5534851393777963\n",
      "Cost on val dataset after 260 epochs is = 0.550699807886738\n",
      "learning rate =  0.0015667831201909694\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.550699807886738\n",
      "Error on this batch = 0.540928744060112\n",
      "Error on this batch = 0.5531769827727379\n",
      "Cost on val dataset after 261 epochs is = 0.5500528019080351\n",
      "learning rate =  0.0015647795590281162\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.5500528019080351\n",
      "Error on this batch = 0.5392046429205168\n",
      "Error on this batch = 0.5528396293039771\n",
      "Cost on val dataset after 262 epochs is = 0.5494309924555035\n",
      "learning rate =  0.0015627862071134965\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.5494309924555035\n",
      "Error on this batch = 0.5376036409011511\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr0=0.01\n",
    "costs = []\n",
    "theta = theta_init(arch)\n",
    "print(theta[0].shape, theta[1].shape, theta[2].shape)\n",
    "epoch = 1\n",
    "start = time.time()\n",
    "cost_init = cost_total(X_train, theta, train_class_enc, m) #Validation loss not giving much info\n",
    "costs.append(cost_init)\n",
    "while(True):\n",
    "    count = 0\n",
    "    lr = lr0/(np.power(epoch, 1/3))\n",
    "    print(\"learning rate = \", lr)\n",
    "\n",
    "    print(\"Initial Cost on Val dataset for this epoch {} = {}\".format(epoch, cost_init))\n",
    "\n",
    "    for b in mini_batch:\n",
    "        X_b = b[0]\n",
    "        Y_b = b[1]\n",
    "        fm = forward_prop(X_b, theta)\n",
    "        delta = [None]*len(fm)\n",
    "\n",
    "        if (count % 60 == 0):\n",
    "            print(\"Error on this batch = \"+str(cost_total(X_b, theta, Y_b, batch_size)))\n",
    "        #Backward Propagation\n",
    "\n",
    "        for l in range(len(fm)-1, 0, -1):\n",
    "            if (l == len(fm)-1):\n",
    "                delta[l] = ((1/batch_size)*(Y_b - fm[l])*fm[l]*(1-fm[l]))\n",
    "                #print(\"delta for last layer=\",delta[l])\n",
    "            else:\n",
    "                delta[l]=(np.dot(delta[l+1], theta[l].T)*deriv_relu(fm[l]))\n",
    "                #print(\"delta for hidden layer=\",np.mean(delta[l]))\n",
    "\n",
    "        for t in range(len(theta)):\n",
    "            theta[t] += lr*np.dot(fm[t].T, delta[t+1]) \n",
    "\n",
    "        count+=1\n",
    "    epoch+=1 #Number of epochs\n",
    "    #ite+=1\n",
    "\n",
    "    cost_final = cost_total(X_train, theta, train_class_enc, m)\n",
    "    if(epoch%10==0): costs.append(cost_final)\n",
    "    print(\"Cost on val dataset after {} epochs is = {}\".format(epoch, cost_final))\n",
    "    if (abs(cost_final-cost_init) < 1e-08):\n",
    "        print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "        break\n",
    "    cost_init = cost_final\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer arch= {} are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs = {:2.3f}\".format(epochs[-1]))\n",
    "print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8307692307692305"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(X_test, theta, test_actual_class_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Loss with Epochs\")\n",
    "x = np.arange(0,len(costs[10:]))\n",
    "ax.plot(x, costs[10:], marker='o', label='Train Accuracy')\n",
    "ax.set_xlabel(\"number of epochs\")\n",
    "ax.set_ylabel(\"Train Loss\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"accuracy_HiddenUnit_val20per.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.831782109502939,\n",
       " 3.065637409541897,\n",
       " 1.8247308746788262,\n",
       " 1.5705342932734632,\n",
       " 1.33022343238924,\n",
       " 1.1285249107258797,\n",
       " 1.0643045095099792,\n",
       " 1.035211733200288,\n",
       " 1.018805714862765,\n",
       " 6.376557034638974,\n",
       " 1.422657448017669,\n",
       " 1.4211259379043941,\n",
       " 1.419297906735625,\n",
       " 1.4176605209953743,\n",
       " 1.4166161084913558,\n",
       " 1.416185709207088,\n",
       " 1.4152965281422567,\n",
       " 1.4146839345350188,\n",
       " 1.4144074662583,\n",
       " 1.4142618066732653,\n",
       " 1.4140713474500968,\n",
       " 1.4134148478899253,\n",
       " 1.4131559125054791,\n",
       " 1.412979612601874,\n",
       " 1.4128589818155581,\n",
       " 1.4127652801754333,\n",
       " 1.412630967544444,\n",
       " 1.412496660264301,\n",
       " 1.4123353187531043]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

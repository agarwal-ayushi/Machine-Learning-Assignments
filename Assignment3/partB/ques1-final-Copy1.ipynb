{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "----------------Preprocessing the data-------------------\n",
      "The total number of training samples = 11050\n",
      "The total number of validation samples = 1950\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "\n",
    "np.random.shuffle(X_train.to_numpy()) #Randomly shuffle the training data for batching\n",
    "\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "print(\"----------------Preprocessing the data-------------------\")\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "\n",
    "#Separating 15% of the training Data as Validation Dataset\n",
    "X_valid = X_train.iloc[(int(0.85*m)):]\n",
    "valid_class = train_class[(int(0.85*m)):]\n",
    "X_train = X_train.iloc[0:int(0.85*m)]\n",
    "train_class = train_class[0:int(0.85*m)]\n",
    "\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The total number of validation samples = {}\".format(X_valid.shape[0]))\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n",
      "--------------------Done----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "valid_class_enc = pd.get_dummies(valid_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()\n",
    "print(\"--------------------Done----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Adding the intercept term in the dataset as bias------------\n",
      "-----------------------------Done----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "print(\"--------Adding the intercept term in the dataset as bias------------\")\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_valid = np.hstack((np.ones((X_valid.shape[0],1)), X_valid.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))\n",
    "print(\"-----------------------------Done----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Forming mini-batches of size 100---------------------\n",
      "The number of mini-batches formed is = 111\n"
     ]
    }
   ],
   "source": [
    "#Mini-Batch formation\n",
    "\n",
    "batch_size = 100 # Mini-Batch Size\n",
    "\n",
    "print(\"----------------Forming mini-batches of size {}---------------------\".format(batch_size))\n",
    "mini_batch = [(X_train[i:i+batch_size,:], train_class_enc[i:i+batch_size]) for i in range(0, m, batch_size)]\n",
    "print(\"The number of mini-batches formed is = {}\".format(len(mini_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta Initialization \n",
    "\n",
    "def theta_init(arch=[50], mode='normal'):\n",
    "    theta = []\n",
    "    for i in range(len(arch)+1):\n",
    "        if i == 0:\n",
    "            dim0=n+1\n",
    "            dim1=arch[i]\n",
    "        elif (i == len(arch)):\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1 = r\n",
    "        else:\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1= arch[i]\n",
    "        if (mode=='normal'):\n",
    "            theta.append(np.random.normal(0,0.05, (dim0,dim1)))\n",
    "        elif(mode=='random'):\n",
    "            theta.append(2*np.random.random((dim0, dim1))-1)\n",
    "        elif(mode=='uniform'):\n",
    "            theta.append(np.random.uniform(-0.05,0.05, (dim0,dim1)))\n",
    "            \n",
    "        #theta.append(np.zeros((dim0, dim1)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#ReLU Activation Function\n",
    "def relu_act(x):\n",
    "    return np.maximum(0.0, x)\n",
    "\n",
    "#Derivative of ReLU activation Function\n",
    "def deriv_relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))\n",
    "\n",
    "def deriv_softplus(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "\n",
    "def forward_prop(data, theta, act_fn='sigmoid'):\n",
    "    fm = []\n",
    "    fm.append(data)\n",
    "    #Sigmoid Activation Function \n",
    "    if (act_fn == 'sigmoid'):\n",
    "        for l in range(len(theta)):\n",
    "            fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "            if (l!=len(theta)-1):\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1]))\n",
    "    #ReLU Activation Function \n",
    "    elif(act_fn == 'relu'):\n",
    "        for l in range(len(theta)):\n",
    "            if (l != len(theta)-1):\n",
    "                fm.append(relu_act(np.dot(fm[l], theta[l])))\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1]))\n",
    "            else:\n",
    "                fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "    #Softplus Activation Function       \n",
    "    elif(act_fn == 'softplus'):\n",
    "        for l in range(len(theta)):\n",
    "            if (l != len(theta)-1):\n",
    "                fm.append(softplus(np.dot(fm[l], theta[l])))\n",
    "                fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1]))\n",
    "            else:\n",
    "                fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward_prop(fm, Y_b, theta, batch_size, act_fn='sigmoid', cost_fn='sqr_error'):\n",
    "    delta = [None]*len(fm)\n",
    "    for l in range(len(fm)-1, 0, -1):\n",
    "        if (l == len(fm)-1):\n",
    "            if (cost_fn=='entropy'):\n",
    "                delta[l] = ((1/batch_size)*((Y_b/fm[l])-((1-Y_b)/(1-fm[l])))*fm[l]*(1-fm[l]))\n",
    "            else:\n",
    "                delta[l] = ((1/batch_size)*(Y_b - fm[l])*fm[l]*(1-fm[l]))\n",
    "        elif (l+1 == len(fm)-1):\n",
    "            if (act_fn == 'sigmoid'):\n",
    "                delta[l]=(np.dot(delta[l+1], theta[l].T)*fm[l]*(1-fm[l]))\n",
    "            elif(act_fn == 'relu'):\n",
    "                delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_relu(fm[l])\n",
    "            elif(act_fn=='softplus'):\n",
    "                delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_softplus(fm[l])\n",
    "        else:\n",
    "            if (act_fn == 'sigmoid'):\n",
    "                delta[l]=(np.dot(delta[l+1][:,1:], theta[l].T)*fm[l]*(1-fm[l]))\n",
    "            elif(act_fn == 'relu'):\n",
    "                delta[l]=np.dot(delta[l+1][:,1:], theta[l].T)*deriv_relu(fm[l])\n",
    "            elif(act_fn=='softplus'):\n",
    "                delta[l]=np.dot(delta[l+1][:,1:], theta[l].T)*deriv_softplus(fm[l])\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_total(X, theta, Y, m, act_fn='sigmoid', cost_fn='sqr_error'):\n",
    "    fm = forward_prop(X, theta, act_fn)\n",
    "    if (cost_fn == 'sqr_error'):\n",
    "        cost = (1/(2*m))*np.sum((Y-fm[-1])**2)\n",
    "    else:\n",
    "        cost = -(1/m)*(np.sum(((Y*np.log(fm[-1]))+((1-Y)*(np.log(1-fm[-1]))))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, theta, actual_class, act_fn='sigmoid'):\n",
    "    pred_class = forward_prop(data, theta, act_fn)\n",
    "    test_pred_class = pred_class[-1]\n",
    "    for i in range(len(test_pred_class)):\n",
    "        test_pred_class[i][test_pred_class[i] == np.max(test_pred_class[i])] = 1\n",
    "        test_pred_class[i][test_pred_class[i] != np.max(test_pred_class[i])] = 0\n",
    "\n",
    "\n",
    "    test_acc = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if (np.array_equal(test_pred_class[i], actual_class[i])):\n",
    "            test_acc+=1\n",
    "    test_acc /= data.shape[0]\n",
    "\n",
    "    return (test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART AB - One Hidden Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(mini_batch, X_valid, valid_class_enc, theta, lr, act_fn='sigmoid', lr_mode='constant', cost_fn='sqr_error'):\n",
    "    lr0=lr\n",
    "    epoch = 1 # Number of epochs\n",
    "    early_stop=0 #Early stop count of iteration\n",
    "    \n",
    "    cost_init = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0], act_fn, cost_fn)\n",
    "    \n",
    "    while(True):\n",
    "        count_batch = 0\n",
    "        print(\"Initial Cost on Val dataset for this epoch {} = {}\".format(epoch, cost_init))\n",
    "        \n",
    "        if(lr_mode == \"adaptive\"):\n",
    "            lr = lr0/(np.power(epoch, 1/4))\n",
    "            print(\"learning rate for this epoch = \", lr)\n",
    "        \n",
    "        for b in mini_batch:\n",
    "            X_b = b[0] #100x785\n",
    "            Y_b = b[1]\n",
    "            \n",
    "            #Forward Propagation\n",
    "            fm = forward_prop(X_b, theta, act_fn) #theta 785x100 fm=100x100\n",
    "            \n",
    "            if (count_batch % 60 == 0):\n",
    "                print(\"Error on this batch = \"+str(cost_total(X_b, theta, Y_b, batch_size, act_fn, cost_fn)))\n",
    "                    \n",
    "            #Backward Propagation\n",
    "            delta = [None]*len(fm)\n",
    "            delta = backward_prop(fm, Y_b, theta, batch_size, act_fn, cost_fn)\n",
    "\n",
    "            #Theta Update\n",
    "            for t in range(len(theta)):\n",
    "                if (t == len(theta)-1):\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1]) \n",
    "                else:\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1])[:,1:]\n",
    "\n",
    "            count_batch+=1\n",
    "\n",
    "        epoch+=1 #Number of epochs\n",
    "        \n",
    "        \n",
    "        cost_final = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0], act_fn, cost_fn)\n",
    "        print(\"Cost on val dataset after {} epochs is = {}\".format(epoch, cost_final))\n",
    "        #Stopping criteria for sigmoid - when Validation loss stops decreasing beyond a threshold for 10 epochs\n",
    "        if (act_fn =='sigmoid'):\n",
    "            if (abs(cost_final-cost_init) < 1e-05):\n",
    "                early_stop +=1\n",
    "            else:\n",
    "                early_stop=0\n",
    "            if (early_stop == 10):\n",
    "                print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "                break\n",
    "        \n",
    "        #Stopping criteria for relu - when Validation loss increases continuously for 30 epochs\n",
    "        elif(act_fn=='relu' or act_fn=='softplus'):\n",
    "            if ((cost_final-cost_init) > 0):\n",
    "                early_stop +=1\n",
    "            else:\n",
    "                early_stop=0\n",
    "            if (early_stop == 10):\n",
    "                print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "                break\n",
    "        \n",
    "        cost_init = cost_final\n",
    "    return epoch, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(\"Accuracy with number of hidden units \\n in one hidden layer network\")\n",
    "    ax.plot(arch_test, train_accuracy, marker='o', label='Train Accuracy')\n",
    "    ax.plot(arch_test, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "    ax.plot(arch_test, test_accuracy, marker='o', label='Test Accuracy')\n",
    "    ax.set_xlabel(\"number of hidden units\")\n",
    "    ax.set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plots/partc/accuracy_normal_lr0.5_cube.png\", dpi=1000, bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_epoch(arch_test, epochs, train_time):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(211)\n",
    "    plt.title(\"Epochs/Time with number of hidden units \\n in one hidden layer network\")\n",
    "    ax.plot(arch_test, epochs, c='b', marker='o', label='#epochs')\n",
    "    ax.set_xlabel(\"number of hidden units\")\n",
    "    ax.set_ylabel(\"Epochs\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = fig.add_subplot(212)\n",
    "    ax1.plot(arch_test, train_time, c='b', marker='o', label='train time')\n",
    "    ax1.set_xlabel(\"number of hidden units\")\n",
    "    ax1.set_ylabel(\"train time(sec)\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"plots/partc/epochs_time_normal_lr0.5_cube.png\", dpi=1000, bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_test = [1,5,10,50,100] # Specifically for part a and b\n",
    "arch = [50] #means one hidden layer with 50 perceptrons (DEFAULT)\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 1 hidden layer with 1 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 1)\n",
      "theta between layer 1 and layer 2 is (2, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2519140993343103\n",
      "Error on this batch = 3.2521425944234545\n",
      "Error on this batch = 0.4978580119964171\n",
      "Cost on val dataset after 2 epochs is = 0.4862347192657634\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4862347192657634\n",
      "Error on this batch = 0.48614471880585103\n",
      "Error on this batch = 0.48289187960649105\n",
      "Cost on val dataset after 3 epochs is = 0.4818940037674934\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4818940037674934\n",
      "Error on this batch = 0.4818104066821387\n",
      "Error on this batch = 0.48135580468339784\n",
      "Cost on val dataset after 4 epochs is = 0.4811457959209773\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4811457959209773\n",
      "Error on this batch = 0.48105925376063535\n",
      "Error on this batch = 0.4809999087221998\n",
      "Cost on val dataset after 5 epochs is = 0.4809473066775132\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4809473066775132\n",
      "Error on this batch = 0.4808564335525884\n",
      "Error on this batch = 0.48089472851073917\n",
      "Cost on val dataset after 6 epochs is = 0.4808861523337416\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4808861523337416\n",
      "Error on this batch = 0.4807910939714662\n",
      "Error on this batch = 0.48086082336429614\n",
      "Cost on val dataset after 7 epochs is = 0.48086680712091406\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.48086680712091406\n",
      "Error on this batch = 0.48076812942373415\n",
      "Error on this batch = 0.4808500099325594\n",
      "Cost on val dataset after 8 epochs is = 0.48086131780294455\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48086131780294455\n",
      "Error on this batch = 0.48075967679250525\n",
      "Error on this batch = 0.480847068551227\n",
      "Cost on val dataset after 9 epochs is = 0.4808604684618455\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4808604684618455\n",
      "Error on this batch = 0.48075648590406367\n",
      "Error on this batch = 0.4808467700760326\n",
      "Cost on val dataset after 10 epochs is = 0.4808610456599938\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4808610456599938\n",
      "Error on this batch = 0.4807552610807218\n",
      "Error on this batch = 0.48084725585982724\n",
      "Cost on val dataset after 11 epochs is = 0.4808619232178538\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4808619232178538\n",
      "Error on this batch = 0.4807547806332175\n",
      "Error on this batch = 0.48084787451445343\n",
      "Cost on val dataset after 12 epochs is = 0.4808627310470193\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4808627310470193\n",
      "Error on this batch = 0.48075458256516457\n",
      "Error on this batch = 0.48084841804171286\n",
      "Cost on val dataset after 13 epochs is = 0.48086337404672397\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48086337404672397\n",
      "Error on this batch = 0.48075449114034013\n",
      "Error on this batch = 0.48084883950360796\n",
      "Cost on val dataset after 14 epochs is = 0.48086385252841246\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.48086385252841246\n",
      "Error on this batch = 0.4807544398805992\n",
      "Error on this batch = 0.48084914654269306\n",
      "Cost on val dataset after 15 epochs is = 0.4808641948647735\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4808641948647735\n",
      "Error on this batch = 0.4807544040254\n",
      "Error on this batch = 0.48084936151675195\n",
      "Cost on val dataset after 16 epochs is = 0.480864433053668\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.480864433053668\n",
      "Error on this batch = 0.4807543745621515\n",
      "Error on this batch = 0.48084950731513654\n",
      "Cost on val dataset after 17 epochs is = 0.4808645947987575\n",
      "cost initial= 0.480864433053668 , cost final=0.4808645947987575 , change in cost= 1.6174508948862965e-07\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 1 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 17\n",
      "The training time = 1.060sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 5 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 5)\n",
      "theta between layer 1 and layer 2 is (6, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.3016196064769834\n",
      "Error on this batch = 3.3012654325740587\n",
      "Error on this batch = 0.4827180943058321\n",
      "Cost on val dataset after 2 epochs is = 0.48119702190255687\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48119702190255687\n",
      "Error on this batch = 0.4810458079596366\n",
      "Error on this batch = 0.48095075703086254\n",
      "Cost on val dataset after 3 epochs is = 0.4809113979722743\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4809113979722743\n",
      "Error on this batch = 0.48077943267942536\n",
      "Error on this batch = 0.48090000891482504\n",
      "Cost on val dataset after 4 epochs is = 0.4809014315734396\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4809014315734396\n",
      "Error on this batch = 0.48076904400423986\n",
      "Error on this batch = 0.48089736516896525\n",
      "Cost on val dataset after 5 epochs is = 0.48090094743542416\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48090094743542416\n",
      "Error on this batch = 0.48076757028630257\n",
      "Error on this batch = 0.480896124810921\n",
      "Cost on val dataset after 6 epochs is = 0.4808997015481933\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4808997015481933\n",
      "Error on this batch = 0.4807661529559921\n",
      "Error on this batch = 0.4808944667118557\n",
      "Cost on val dataset after 7 epochs is = 0.48089797833889114\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.48089797833889114\n",
      "Error on this batch = 0.48076473122989855\n",
      "Error on this batch = 0.4808926735136164\n",
      "Cost on val dataset after 8 epochs is = 0.4808961580798549\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4808961580798549\n",
      "Error on this batch = 0.48076339159632\n",
      "Error on this batch = 0.48089091354504804\n",
      "Cost on val dataset after 9 epochs is = 0.4808943875893539\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4808943875893539\n",
      "Error on this batch = 0.4807621461833547\n",
      "Error on this batch = 0.4808892428376265\n",
      "Cost on val dataset after 10 epochs is = 0.48089270917332394\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48089270917332394\n",
      "Error on this batch = 0.4807609870749323\n",
      "Error on this batch = 0.48088767248033865\n",
      "Cost on val dataset after 11 epochs is = 0.48089112852786703\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48089112852786703\n",
      "Error on this batch = 0.4807599040469242\n",
      "Error on this batch = 0.4808861987430593\n",
      "Cost on val dataset after 12 epochs is = 0.4808896401625252\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4808896401625252\n",
      "Error on this batch = 0.48075888797634964\n",
      "Error on this batch = 0.4808848139060743\n",
      "Cost on val dataset after 13 epochs is = 0.48088823592056407\n",
      "cost initial= 0.4808896401625252 , cost final=0.48088823592056407 , change in cost= -1.4042419611559609e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 5 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 13\n",
      "The training time = 0.851sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 10 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 10)\n",
      "theta between layer 1 and layer 2 is (11, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2138546782328503\n",
      "Error on this batch = 3.21231154661315\n",
      "Error on this batch = 0.4812818170083387\n",
      "Cost on val dataset after 2 epochs is = 0.48103561191416133\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48103561191416133\n",
      "Error on this batch = 0.48093335851263525\n",
      "Error on this batch = 0.4809370991375834\n",
      "Cost on val dataset after 3 epochs is = 0.48099732454659566\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48099732454659566\n",
      "Error on this batch = 0.48091106049967436\n",
      "Error on this batch = 0.48092122959081646\n",
      "Cost on val dataset after 4 epochs is = 0.48098007997747333\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.48098007997747333\n",
      "Error on this batch = 0.48089456218963805\n",
      "Error on this batch = 0.4809085822944995\n",
      "Cost on val dataset after 5 epochs is = 0.48096285642882464\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48096285642882464\n",
      "Error on this batch = 0.48087786621422746\n",
      "Error on this batch = 0.48089661874458417\n",
      "Cost on val dataset after 6 epochs is = 0.4809459419455936\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4809459419455936\n",
      "Error on this batch = 0.48086154746705945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4808847914170438\n",
      "Cost on val dataset after 7 epochs is = 0.480928471379602\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.480928471379602\n",
      "Error on this batch = 0.48084456558257244\n",
      "Error on this batch = 0.48087228859583414\n",
      "Cost on val dataset after 8 epochs is = 0.4809086579556926\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4809086579556926\n",
      "Error on this batch = 0.4808249341291825\n",
      "Error on this batch = 0.4808575538272428\n",
      "Cost on val dataset after 9 epochs is = 0.48088264315349316\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48088264315349316\n",
      "Error on this batch = 0.4807983464981166\n",
      "Error on this batch = 0.48083672966032026\n",
      "Cost on val dataset after 10 epochs is = 0.4808398737512902\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4808398737512902\n",
      "Error on this batch = 0.48075299557717416\n",
      "Error on this batch = 0.4807968942267619\n",
      "Cost on val dataset after 11 epochs is = 0.48074346908050397\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48074346908050397\n",
      "Error on this batch = 0.48064904328512714\n",
      "Error on this batch = 0.4806813029999805\n",
      "Cost on val dataset after 12 epochs is = 0.480482340834077\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.480482340834077\n",
      "Error on this batch = 0.4803880722116762\n",
      "Error on this batch = 0.48035512470470965\n",
      "Cost on val dataset after 13 epochs is = 0.48003965251345665\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48003965251345665\n",
      "Error on this batch = 0.4799834167434187\n",
      "Error on this batch = 0.479895164263573\n",
      "Cost on val dataset after 14 epochs is = 0.47948335171848044\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.47948335171848044\n",
      "Error on this batch = 0.4794429757060513\n",
      "Error on this batch = 0.47936644798474976\n",
      "Cost on val dataset after 15 epochs is = 0.4788134712970487\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4788134712970487\n",
      "Error on this batch = 0.4787681815791781\n",
      "Error on this batch = 0.47879571626572043\n",
      "Cost on val dataset after 16 epochs is = 0.4780579489430936\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4780579489430936\n",
      "Error on this batch = 0.47798521223827733\n",
      "Error on this batch = 0.4782601966879467\n",
      "Cost on val dataset after 17 epochs is = 0.4772402167294683\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.4772402167294683\n",
      "Error on this batch = 0.47709688101467784\n",
      "Error on this batch = 0.4779066118874175\n",
      "Cost on val dataset after 18 epochs is = 0.47635967564217296\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.47635967564217296\n",
      "Error on this batch = 0.47608961310294545\n",
      "Error on this batch = 0.47792979469015495\n",
      "Cost on val dataset after 19 epochs is = 0.47542202249686916\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.47542202249686916\n",
      "Error on this batch = 0.4750276427425061\n",
      "Error on this batch = 0.47840289828579885\n",
      "Cost on val dataset after 20 epochs is = 0.4744738427646003\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4744738427646003\n",
      "Error on this batch = 0.47405124289366074\n",
      "Error on this batch = 0.4792742187032259\n",
      "Cost on val dataset after 21 epochs is = 0.47355705338092824\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.47355705338092824\n",
      "Error on this batch = 0.47311431109067786\n",
      "Error on this batch = 0.4802401898133155\n",
      "Cost on val dataset after 22 epochs is = 0.4726290186732591\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4726290186732591\n",
      "Error on this batch = 0.47195455924802504\n",
      "Error on this batch = 0.48085338913157716\n",
      "Cost on val dataset after 23 epochs is = 0.47157066153845106\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.47157066153845106\n",
      "Error on this batch = 0.4705028360472072\n",
      "Error on this batch = 0.48072824934389824\n",
      "Cost on val dataset after 24 epochs is = 0.4703081945546895\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.4703081945546895\n",
      "Error on this batch = 0.46877555939166954\n",
      "Error on this batch = 0.4800359639371913\n",
      "Cost on val dataset after 25 epochs is = 0.4689323976174675\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4689323976174675\n",
      "Error on this batch = 0.4671037297361832\n",
      "Error on this batch = 0.478936486310853\n",
      "Cost on val dataset after 26 epochs is = 0.4673665628386778\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.4673665628386778\n",
      "Error on this batch = 0.46531514705495\n",
      "Error on this batch = 0.4773494734925853\n",
      "Cost on val dataset after 27 epochs is = 0.4655385004561782\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.4655385004561782\n",
      "Error on this batch = 0.4632782668234119\n",
      "Error on this batch = 0.4750462190976282\n",
      "Cost on val dataset after 28 epochs is = 0.4631117933331089\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4631117933331089\n",
      "Error on this batch = 0.4607000292023136\n",
      "Error on this batch = 0.4720392862083235\n",
      "Cost on val dataset after 29 epochs is = 0.46023784271994\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.46023784271994\n",
      "Error on this batch = 0.4577103892415645\n",
      "Error on this batch = 0.468377567341178\n",
      "Cost on val dataset after 30 epochs is = 0.4568221919940399\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.4568221919940399\n",
      "Error on this batch = 0.4542766347875347\n",
      "Error on this batch = 0.46385469547847813\n",
      "Cost on val dataset after 31 epochs is = 0.4524965551653664\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.4524965551653664\n",
      "Error on this batch = 0.44973249511727886\n",
      "Error on this batch = 0.45784282625681855\n",
      "Cost on val dataset after 32 epochs is = 0.4461796134279377\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.4461796134279377\n",
      "Error on this batch = 0.4422146926629962\n",
      "Error on this batch = 0.45043713680756087\n",
      "Cost on val dataset after 33 epochs is = 0.43839886356293484\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.43839886356293484\n",
      "Error on this batch = 0.43269858402444983\n",
      "Error on this batch = 0.4426100764099266\n",
      "Cost on val dataset after 34 epochs is = 0.4295958789780238\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.4295958789780238\n",
      "Error on this batch = 0.4227126164994679\n",
      "Error on this batch = 0.4346982645452962\n",
      "Cost on val dataset after 35 epochs is = 0.42033182356957377\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.42033182356957377\n",
      "Error on this batch = 0.41358907114700943\n",
      "Error on this batch = 0.4270104907052532\n",
      "Cost on val dataset after 36 epochs is = 0.41110214605621126\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.41110214605621126\n",
      "Error on this batch = 0.40557691389878403\n",
      "Error on this batch = 0.4196427783355172\n",
      "Cost on val dataset after 37 epochs is = 0.4021725598811353\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.4021725598811353\n",
      "Error on this batch = 0.3983377291049869\n",
      "Error on this batch = 0.4125325274430214\n",
      "Cost on val dataset after 38 epochs is = 0.39347255198825726\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.39347255198825726\n",
      "Error on this batch = 0.39145598793985203\n",
      "Error on this batch = 0.4054557352817105\n",
      "Cost on val dataset after 39 epochs is = 0.38458128375839323\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.38458128375839323\n",
      "Error on this batch = 0.38452236726695127\n",
      "Error on this batch = 0.3981241067351493\n",
      "Cost on val dataset after 40 epochs is = 0.37556619277900644\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.37556619277900644\n",
      "Error on this batch = 0.3774656512362655\n",
      "Error on this batch = 0.3907558780398365\n",
      "Cost on val dataset after 41 epochs is = 0.3669635342931488\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.3669635342931488\n",
      "Error on this batch = 0.37078780215016516\n",
      "Error on this batch = 0.38379805106279985\n",
      "Cost on val dataset after 42 epochs is = 0.3590831420193184\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.3590831420193184\n",
      "Error on this batch = 0.3649589779685033\n",
      "Error on this batch = 0.3776823074319395\n",
      "Cost on val dataset after 43 epochs is = 0.3521050379263962\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.3521050379263962\n",
      "Error on this batch = 0.3599896570871087\n",
      "Error on this batch = 0.37225086432971777\n",
      "Cost on val dataset after 44 epochs is = 0.3459486034391479\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.3459486034391479\n",
      "Error on this batch = 0.35562645748281446\n",
      "Error on this batch = 0.3672695683004558\n",
      "Cost on val dataset after 45 epochs is = 0.34045882556291723\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.34045882556291723\n",
      "Error on this batch = 0.3515026156457482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.36258816264877086\n",
      "Cost on val dataset after 46 epochs is = 0.3355208712261168\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.3355208712261168\n",
      "Error on this batch = 0.3475442008486657\n",
      "Error on this batch = 0.35827709032619903\n",
      "Cost on val dataset after 47 epochs is = 0.3310492036409551\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.3310492036409551\n",
      "Error on this batch = 0.34380887335058147\n",
      "Error on this batch = 0.354375632747112\n",
      "Cost on val dataset after 48 epochs is = 0.3269641984186822\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.3269641984186822\n",
      "Error on this batch = 0.34027377641573936\n",
      "Error on this batch = 0.3508385222988271\n",
      "Cost on val dataset after 49 epochs is = 0.3232004067552941\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.3232004067552941\n",
      "Error on this batch = 0.33689385304200087\n",
      "Error on this batch = 0.34758965906621037\n",
      "Cost on val dataset after 50 epochs is = 0.3197138301162313\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.3197138301162313\n",
      "Error on this batch = 0.33364767684393554\n",
      "Error on this batch = 0.3445498064772876\n",
      "Cost on val dataset after 51 epochs is = 0.3164804633535902\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.3164804633535902\n",
      "Error on this batch = 0.3305222925692148\n",
      "Error on this batch = 0.3416535203762871\n",
      "Cost on val dataset after 52 epochs is = 0.3134839866921171\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.3134839866921171\n",
      "Error on this batch = 0.32749154427152266\n",
      "Error on this batch = 0.33885737676224315\n",
      "Cost on val dataset after 53 epochs is = 0.31070603644234895\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.31070603644234895\n",
      "Error on this batch = 0.32453402154612837\n",
      "Error on this batch = 0.33613527717007413\n",
      "Cost on val dataset after 54 epochs is = 0.308125829969586\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.308125829969586\n",
      "Error on this batch = 0.32164150972007954\n",
      "Error on this batch = 0.33347158926848786\n",
      "Cost on val dataset after 55 epochs is = 0.30572264293809037\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.30572264293809037\n",
      "Error on this batch = 0.31881076407534553\n",
      "Error on this batch = 0.33085694538571475\n",
      "Cost on val dataset after 56 epochs is = 0.30347711144258516\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.30347711144258516\n",
      "Error on this batch = 0.3160391141710895\n",
      "Error on this batch = 0.32828583265705547\n",
      "Cost on val dataset after 57 epochs is = 0.3013717481528373\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.3013717481528373\n",
      "Error on this batch = 0.3133250572077569\n",
      "Error on this batch = 0.32575548903262574\n",
      "Cost on val dataset after 58 epochs is = 0.2993914556923948\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.2993914556923948\n",
      "Error on this batch = 0.31066958471081274\n",
      "Error on this batch = 0.32326543761919496\n",
      "Cost on val dataset after 59 epochs is = 0.2975239416646462\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.2975239416646462\n",
      "Error on this batch = 0.3080765048676068\n",
      "Error on this batch = 0.32081692360078107\n",
      "Cost on val dataset after 60 epochs is = 0.29575967467661585\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.29575967467661585\n",
      "Error on this batch = 0.3055517507300876\n",
      "Error on this batch = 0.3184121033525084\n",
      "Cost on val dataset after 61 epochs is = 0.29409136414704173\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.29409136414704173\n",
      "Error on this batch = 0.30310232714054364\n",
      "Error on this batch = 0.31605338585941\n",
      "Cost on val dataset after 62 epochs is = 0.2925132480759805\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.2925132480759805\n",
      "Error on this batch = 0.30073549462641447\n",
      "Error on this batch = 0.3137432520879482\n",
      "Cost on val dataset after 63 epochs is = 0.29102044665996357\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.29102044665996357\n",
      "Error on this batch = 0.29845830802671974\n",
      "Error on this batch = 0.3114844304867039\n",
      "Cost on val dataset after 64 epochs is = 0.28960848812849854\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.28960848812849854\n",
      "Error on this batch = 0.2962772717245129\n",
      "Error on this batch = 0.30928006292453974\n",
      "Cost on val dataset after 65 epochs is = 0.28827301261005456\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.28827301261005456\n",
      "Error on this batch = 0.29419792249631654\n",
      "Error on this batch = 0.30713359135086704\n",
      "Cost on val dataset after 66 epochs is = 0.2870096100631521\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.2870096100631521\n",
      "Error on this batch = 0.2922243798649008\n",
      "Error on this batch = 0.30504830767042396\n",
      "Cost on val dataset after 67 epochs is = 0.28581372795947463\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.28581372795947463\n",
      "Error on this batch = 0.29035901096187994\n",
      "Error on this batch = 0.3030266590944872\n",
      "Cost on val dataset after 68 epochs is = 0.28468059568794246\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.28468059568794246\n",
      "Error on this batch = 0.2886023096659685\n",
      "Error on this batch = 0.30106945624255493\n",
      "Cost on val dataset after 69 epochs is = 0.28360513589745506\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.28360513589745506\n",
      "Error on this batch = 0.28695301770297404\n",
      "Error on this batch = 0.29917514457240074\n",
      "Cost on val dataset after 70 epochs is = 0.2825818268720512\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.2825818268720512\n",
      "Error on this batch = 0.285408497884182\n",
      "Error on this batch = 0.29733936636585945\n",
      "Cost on val dataset after 71 epochs is = 0.2816044068024346\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.2816044068024346\n",
      "Error on this batch = 0.28396536098244524\n",
      "Error on this batch = 0.295555233313319\n",
      "Cost on val dataset after 72 epochs is = 0.2806650993942658\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.2806650993942658\n",
      "Error on this batch = 0.28262020061613163\n",
      "Error on this batch = 0.29381499715310605\n",
      "Cost on val dataset after 73 epochs is = 0.27975238458651686\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.27975238458651686\n",
      "Error on this batch = 0.28136969015140295\n",
      "Error on this batch = 0.2921140837798976\n",
      "Cost on val dataset after 74 epochs is = 0.27884354014075075\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.27884354014075075\n",
      "Error on this batch = 0.2802068832578699\n",
      "Error on this batch = 0.2904606049315777\n",
      "Cost on val dataset after 75 epochs is = 0.27787467636705077\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.27787467636705077\n",
      "Error on this batch = 0.27910181709529974\n",
      "Error on this batch = 0.2889073219051133\n",
      "Cost on val dataset after 76 epochs is = 0.2767559986736796\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.2767559986736796\n",
      "Error on this batch = 0.27801850198887956\n",
      "Error on this batch = 0.2872939770797644\n",
      "Cost on val dataset after 77 epochs is = 0.2756636913041333\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.2756636913041333\n",
      "Error on this batch = 0.2770690875403836\n",
      "Error on this batch = 0.2853235642236787\n",
      "Cost on val dataset after 78 epochs is = 0.2745468615870062\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.2745468615870062\n",
      "Error on this batch = 0.2762010099503136\n",
      "Error on this batch = 0.28310137469723684\n",
      "Cost on val dataset after 79 epochs is = 0.2733237082627805\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.2733237082627805\n",
      "Error on this batch = 0.275268972473496\n",
      "Error on this batch = 0.28071661107784623\n",
      "Cost on val dataset after 80 epochs is = 0.27195038598177296\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.27195038598177296\n",
      "Error on this batch = 0.2742307530270303\n",
      "Error on this batch = 0.27824038401980494\n",
      "Cost on val dataset after 81 epochs is = 0.2704104996513718\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.2704104996513718\n",
      "Error on this batch = 0.2731257075536653\n",
      "Error on this batch = 0.27564832248579624\n",
      "Cost on val dataset after 82 epochs is = 0.2687353955070172\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.2687353955070172\n",
      "Error on this batch = 0.27198440831336645\n",
      "Error on this batch = 0.27297272605680595\n",
      "Cost on val dataset after 83 epochs is = 0.2669818956081228\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.2669818956081228\n",
      "Error on this batch = 0.27079306596495323\n",
      "Error on this batch = 0.270297323172696\n",
      "Cost on val dataset after 84 epochs is = 0.2651834577977227\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.2651834577977227\n",
      "Error on this batch = 0.2695288604273272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.26768982219825527\n",
      "Cost on val dataset after 85 epochs is = 0.2633671576260864\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.2633671576260864\n",
      "Error on this batch = 0.26816603322708144\n",
      "Error on this batch = 0.265197744445473\n",
      "Cost on val dataset after 86 epochs is = 0.2615634454961238\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.2615634454961238\n",
      "Error on this batch = 0.26669582575845596\n",
      "Error on this batch = 0.26283779914004224\n",
      "Cost on val dataset after 87 epochs is = 0.2598062206927073\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.2598062206927073\n",
      "Error on this batch = 0.26514059352015557\n",
      "Error on this batch = 0.260609934152862\n",
      "Cost on val dataset after 88 epochs is = 0.25812290145309574\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.25812290145309574\n",
      "Error on this batch = 0.2635334704155314\n",
      "Error on this batch = 0.25851157039085154\n",
      "Cost on val dataset after 89 epochs is = 0.25653009510079827\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.25653009510079827\n",
      "Error on this batch = 0.26190234863132056\n",
      "Error on this batch = 0.2565396693643615\n",
      "Cost on val dataset after 90 epochs is = 0.25503500681885366\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.25503500681885366\n",
      "Error on this batch = 0.26026571502468737\n",
      "Error on this batch = 0.25469026271442485\n",
      "Cost on val dataset after 91 epochs is = 0.25363848084827983\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.25363848084827983\n",
      "Error on this batch = 0.25863445362362947\n",
      "Error on this batch = 0.2529587506847978\n",
      "Cost on val dataset after 92 epochs is = 0.25233748788671895\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.25233748788671895\n",
      "Error on this batch = 0.2570145884904285\n",
      "Error on this batch = 0.2513401887705421\n",
      "Cost on val dataset after 93 epochs is = 0.2511268104698586\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.2511268104698586\n",
      "Error on this batch = 0.25540961810163154\n",
      "Error on this batch = 0.24982921205414044\n",
      "Cost on val dataset after 94 epochs is = 0.2500001563283198\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.2500001563283198\n",
      "Error on this batch = 0.2538224762478945\n",
      "Error on this batch = 0.2484197894268088\n",
      "Cost on val dataset after 95 epochs is = 0.24895086701260855\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.24895086701260855\n",
      "Error on this batch = 0.2522570417556384\n",
      "Error on this batch = 0.24710502164073855\n",
      "Cost on val dataset after 96 epochs is = 0.24797232585788673\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.24797232585788673\n",
      "Error on this batch = 0.25071889444029194\n",
      "Error on this batch = 0.24587709093467894\n",
      "Cost on val dataset after 97 epochs is = 0.2470581649594909\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.2470581649594909\n",
      "Error on this batch = 0.24921508957939673\n",
      "Error on this batch = 0.2447273969697411\n",
      "Cost on val dataset after 98 epochs is = 0.24620236038438134\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.24620236038438134\n",
      "Error on this batch = 0.24775307652453044\n",
      "Error on this batch = 0.2436468563117424\n",
      "Cost on val dataset after 99 epochs is = 0.2453992677655812\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.2453992677655812\n",
      "Error on this batch = 0.24633931766519465\n",
      "Error on this batch = 0.2426262850881779\n",
      "Cost on val dataset after 100 epochs is = 0.24464360683961917\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.24464360683961917\n",
      "Error on this batch = 0.24497828161203367\n",
      "Error on this batch = 0.24165674779455992\n",
      "Cost on val dataset after 101 epochs is = 0.2439303722416155\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.2439303722416155\n",
      "Error on this batch = 0.24367210965061709\n",
      "Error on this batch = 0.24072975733018695\n",
      "Cost on val dataset after 102 epochs is = 0.2432546251465343\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.2432546251465343\n",
      "Error on this batch = 0.2424207117422508\n",
      "Error on this batch = 0.2398372414123134\n",
      "Cost on val dataset after 103 epochs is = 0.24261108746885116\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.24261108746885116\n",
      "Error on this batch = 0.2412217309880855\n",
      "Error on this batch = 0.23897122746875776\n",
      "Cost on val dataset after 104 epochs is = 0.2419934629698432\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.2419934629698432\n",
      "Error on this batch = 0.24006970279146608\n",
      "Error on this batch = 0.23812321689099228\n",
      "Cost on val dataset after 105 epochs is = 0.24139398067311757\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.24139398067311757\n",
      "Error on this batch = 0.2389538169401888\n",
      "Error on this batch = 0.23728196770326293\n",
      "Cost on val dataset after 106 epochs is = 0.2408061971887263\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.2408061971887263\n",
      "Error on this batch = 0.23785646585297707\n",
      "Error on this batch = 0.23641476748170256\n",
      "Cost on val dataset after 107 epochs is = 0.2402291451050274\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.2402291451050274\n",
      "Error on this batch = 0.23676287844348307\n",
      "Error on this batch = 0.23540639975313\n",
      "Cost on val dataset after 108 epochs is = 0.23965481140013767\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.23965481140013767\n",
      "Error on this batch = 0.23568209763300324\n",
      "Error on this batch = 0.2340660148675146\n",
      "Cost on val dataset after 109 epochs is = 0.23907373505304766\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.23907373505304766\n",
      "Error on this batch = 0.23472538253666933\n",
      "Error on this batch = 0.2325081668219331\n",
      "Cost on val dataset after 110 epochs is = 0.2384907695081024\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.2384907695081024\n",
      "Error on this batch = 0.23405266780385056\n",
      "Error on this batch = 0.23113155750266193\n",
      "Cost on val dataset after 111 epochs is = 0.2379134926490315\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.2379134926490315\n",
      "Error on this batch = 0.23367170046384314\n",
      "Error on this batch = 0.22997133632218694\n",
      "Cost on val dataset after 112 epochs is = 0.2373640637310892\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.2373640637310892\n",
      "Error on this batch = 0.23352702518463134\n",
      "Error on this batch = 0.2288840361586156\n",
      "Cost on val dataset after 113 epochs is = 0.2368728854066634\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.2368728854066634\n",
      "Error on this batch = 0.23339372290569835\n",
      "Error on this batch = 0.22776014699818312\n",
      "Cost on val dataset after 114 epochs is = 0.2364615352557532\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.2364615352557532\n",
      "Error on this batch = 0.23308738118049888\n",
      "Error on this batch = 0.2266131656157785\n",
      "Cost on val dataset after 115 epochs is = 0.23607538841901315\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.23607538841901315\n",
      "Error on this batch = 0.23257118632640683\n",
      "Error on this batch = 0.22553858930794657\n",
      "Cost on val dataset after 116 epochs is = 0.23562034560341064\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.23562034560341064\n",
      "Error on this batch = 0.2318948896084021\n",
      "Error on this batch = 0.2245831894331772\n",
      "Cost on val dataset after 117 epochs is = 0.2351182667778651\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.2351182667778651\n",
      "Error on this batch = 0.23114640972465722\n",
      "Error on this batch = 0.2237418697397771\n",
      "Cost on val dataset after 118 epochs is = 0.23461550926289176\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.23461550926289176\n",
      "Error on this batch = 0.230370498921508\n",
      "Error on this batch = 0.22299007053755432\n",
      "Cost on val dataset after 119 epochs is = 0.23413047612786558\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.23413047612786558\n",
      "Error on this batch = 0.22958984989459358\n",
      "Error on this batch = 0.22229750908066567\n",
      "Cost on val dataset after 120 epochs is = 0.23366616056689407\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.23366616056689407\n",
      "Error on this batch = 0.22881678391971796\n",
      "Error on this batch = 0.22164099374306406\n",
      "Cost on val dataset after 121 epochs is = 0.23322072814596492\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.23322072814596492\n",
      "Error on this batch = 0.2280554874512004\n",
      "Error on this batch = 0.22100781816320741\n",
      "Cost on val dataset after 122 epochs is = 0.23279112936484944\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.23279112936484944\n",
      "Error on this batch = 0.22730488375118782\n",
      "Error on this batch = 0.22039233156836333\n",
      "Cost on val dataset after 123 epochs is = 0.23237402128322965\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.23237402128322965\n",
      "Error on this batch = 0.22656116659333542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.21979197457181351\n",
      "Cost on val dataset after 124 epochs is = 0.23196609279214248\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.23196609279214248\n",
      "Error on this batch = 0.22581958360632332\n",
      "Error on this batch = 0.21920491827737235\n",
      "Cost on val dataset after 125 epochs is = 0.23156429939763346\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.23156429939763346\n",
      "Error on this batch = 0.2250754648223609\n",
      "Error on this batch = 0.21862907492651956\n",
      "Cost on val dataset after 126 epochs is = 0.23116601664523578\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.23116601664523578\n",
      "Error on this batch = 0.22432464618153872\n",
      "Error on this batch = 0.2180618580086104\n",
      "Cost on val dataset after 127 epochs is = 0.2307690860175414\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.2307690860175414\n",
      "Error on this batch = 0.22356355605897957\n",
      "Error on this batch = 0.21750027626797613\n",
      "Cost on val dataset after 128 epochs is = 0.23037177010804383\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.23037177010804383\n",
      "Error on this batch = 0.2227891808817929\n",
      "Error on this batch = 0.21694114506501094\n",
      "Cost on val dataset after 129 epochs is = 0.22997265060339497\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.22997265060339497\n",
      "Error on this batch = 0.22199899458081881\n",
      "Error on this batch = 0.21638130012739715\n",
      "Cost on val dataset after 130 epochs is = 0.22957049893339534\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.22957049893339534\n",
      "Error on this batch = 0.22119084676320555\n",
      "Error on this batch = 0.21581775778721407\n",
      "Cost on val dataset after 131 epochs is = 0.22916414233787363\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.22916414233787363\n",
      "Error on this batch = 0.22036279226384278\n",
      "Error on this batch = 0.2152478139519925\n",
      "Cost on val dataset after 132 epochs is = 0.2287523429611528\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.2287523429611528\n",
      "Error on this batch = 0.21951288469757316\n",
      "Error on this batch = 0.21466910566201236\n",
      "Cost on val dataset after 133 epochs is = 0.22833370314446014\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.22833370314446014\n",
      "Error on this batch = 0.21863900284941057\n",
      "Error on this batch = 0.21407966882888013\n",
      "Cost on val dataset after 134 epochs is = 0.22790660536153062\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.22790660536153062\n",
      "Error on this batch = 0.21773879600186058\n",
      "Error on this batch = 0.21347802292187418\n",
      "Cost on val dataset after 135 epochs is = 0.2274691917700211\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.2274691917700211\n",
      "Error on this batch = 0.21680981474103658\n",
      "Error on this batch = 0.21286330996404623\n",
      "Cost on val dataset after 136 epochs is = 0.22701938870082453\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.22701938870082453\n",
      "Error on this batch = 0.21584985514738975\n",
      "Error on this batch = 0.21223551549335695\n",
      "Cost on val dataset after 137 epochs is = 0.22655498758142603\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.22655498758142603\n",
      "Error on this batch = 0.21485751433443578\n",
      "Error on this batch = 0.211595799061443\n",
      "Cost on val dataset after 138 epochs is = 0.22607380698703844\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.22607380698703844\n",
      "Error on this batch = 0.21383295296956192\n",
      "Error on this batch = 0.21094694938102698\n",
      "Cost on val dataset after 139 epochs is = 0.22557398138332896\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.22557398138332896\n",
      "Error on this batch = 0.21277888564841682\n",
      "Error on this batch = 0.2102939328981411\n",
      "Cost on val dataset after 140 epochs is = 0.22505444816311101\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.22505444816311101\n",
      "Error on this batch = 0.21170184896014732\n",
      "Error on this batch = 0.20964440261039494\n",
      "Cost on val dataset after 141 epochs is = 0.22451571567411469\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.22451571567411469\n",
      "Error on this batch = 0.21061375322525888\n",
      "Error on this batch = 0.20900889307819448\n",
      "Cost on val dataset after 142 epochs is = 0.223960917693059\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.223960917693059\n",
      "Error on this batch = 0.20953341255062952\n",
      "Error on this batch = 0.20840033963538912\n",
      "Cost on val dataset after 143 epochs is = 0.2233968469742889\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.2233968469742889\n",
      "Error on this batch = 0.20848688125128134\n",
      "Error on this batch = 0.20783262300846886\n",
      "Cost on val dataset after 144 epochs is = 0.22283406701608613\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.22283406701608613\n",
      "Error on this batch = 0.2075041609540333\n",
      "Error on this batch = 0.20731808599841586\n",
      "Cost on val dataset after 145 epochs is = 0.22228492763467306\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.22228492763467306\n",
      "Error on this batch = 0.2066100793904347\n",
      "Error on this batch = 0.2068645497923116\n",
      "Cost on val dataset after 146 epochs is = 0.2217596077861953\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.2217596077861953\n",
      "Error on this batch = 0.20581199472502854\n",
      "Error on this batch = 0.20647325103102346\n",
      "Cost on val dataset after 147 epochs is = 0.22126275747422525\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.22126275747422525\n",
      "Error on this batch = 0.20509367473809814\n",
      "Error on this batch = 0.20613914187865642\n",
      "Cost on val dataset after 148 epochs is = 0.22079340350807156\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.22079340350807156\n",
      "Error on this batch = 0.2044216916377406\n",
      "Error on this batch = 0.2058533213619989\n",
      "Cost on val dataset after 149 epochs is = 0.2203473779596682\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.2203473779596682\n",
      "Error on this batch = 0.20375818065010085\n",
      "Error on this batch = 0.20560589150751538\n",
      "Cost on val dataset after 150 epochs is = 0.21991929363124244\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.21991929363124244\n",
      "Error on this batch = 0.20307015896640607\n",
      "Error on this batch = 0.2053879209952464\n",
      "Cost on val dataset after 151 epochs is = 0.21950287418897002\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.21950287418897002\n",
      "Error on this batch = 0.20233353685064795\n",
      "Error on this batch = 0.20519231337671057\n",
      "Cost on val dataset after 152 epochs is = 0.2190909178879378\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.2190909178879378\n",
      "Error on this batch = 0.20153481550521146\n",
      "Error on this batch = 0.2050139080366736\n",
      "Cost on val dataset after 153 epochs is = 0.21867619094478158\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.21867619094478158\n",
      "Error on this batch = 0.200671732433442\n",
      "Error on this batch = 0.2048491087418128\n",
      "Cost on val dataset after 154 epochs is = 0.21825303585088615\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.21825303585088615\n",
      "Error on this batch = 0.19975218366243688\n",
      "Error on this batch = 0.2046951636766447\n",
      "Cost on val dataset after 155 epochs is = 0.21781862674196606\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.21781862674196606\n",
      "Error on this batch = 0.1987913005877333\n",
      "Error on this batch = 0.204549292021918\n",
      "Cost on val dataset after 156 epochs is = 0.21737319470982264\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.21737319470982264\n",
      "Error on this batch = 0.1978077373990498\n",
      "Error on this batch = 0.20440809986233457\n",
      "Cost on val dataset after 157 epochs is = 0.21691932022906693\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.21691932022906693\n",
      "Error on this batch = 0.19682041356048458\n",
      "Error on this batch = 0.20426761577580224\n",
      "Cost on val dataset after 158 epochs is = 0.21646081397744815\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.21646081397744815\n",
      "Error on this batch = 0.19584638705858004\n",
      "Error on this batch = 0.2041237624443828\n",
      "Cost on val dataset after 159 epochs is = 0.21600171156431708\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.21600171156431708\n",
      "Error on this batch = 0.19489992165795827\n",
      "Error on this batch = 0.2039727960634746\n",
      "Cost on val dataset after 160 epochs is = 0.21554566324549473\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.21554566324549473\n",
      "Error on this batch = 0.1939923968174322\n",
      "Error on this batch = 0.20381146764896685\n",
      "Cost on val dataset after 161 epochs is = 0.2150957070267134\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.2150957070267134\n",
      "Error on this batch = 0.19313249477796132\n",
      "Error on this batch = 0.20363706047684013\n",
      "Cost on val dataset after 162 epochs is = 0.21465422853666313\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.21465422853666313\n",
      "Error on this batch = 0.1923261389644753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.20344766583826537\n",
      "Cost on val dataset after 163 epochs is = 0.21422288251575372\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.21422288251575372\n",
      "Error on this batch = 0.19157604789914245\n",
      "Error on this batch = 0.2032428626875197\n",
      "Cost on val dataset after 164 epochs is = 0.21380236779464387\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.21380236779464387\n",
      "Error on this batch = 0.1908813559713091\n",
      "Error on this batch = 0.20302446517201453\n",
      "Cost on val dataset after 165 epochs is = 0.21339216202617772\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.21339216202617772\n",
      "Error on this batch = 0.1902379598358226\n",
      "Error on this batch = 0.2027967251377145\n",
      "Cost on val dataset after 166 epochs is = 0.21299049310395465\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.21299049310395465\n",
      "Error on this batch = 0.18963970178078932\n",
      "Error on this batch = 0.20256569560322416\n",
      "Cost on val dataset after 167 epochs is = 0.21259475474454537\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.21259475474454537\n",
      "Error on this batch = 0.18907978234761125\n",
      "Error on this batch = 0.20233801562146297\n",
      "Cost on val dataset after 168 epochs is = 0.21220225820915534\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.21220225820915534\n",
      "Error on this batch = 0.18855173303429718\n",
      "Error on this batch = 0.20211963194546975\n",
      "Cost on val dataset after 169 epochs is = 0.21181092963981651\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.21181092963981651\n",
      "Error on this batch = 0.18804973897666685\n",
      "Error on this batch = 0.2019148773066519\n",
      "Cost on val dataset after 170 epochs is = 0.21141952439911046\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.21141952439911046\n",
      "Error on this batch = 0.18756839681533508\n",
      "Error on this batch = 0.20172603639899347\n",
      "Cost on val dataset after 171 epochs is = 0.21102702188403116\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.21102702188403116\n",
      "Error on this batch = 0.18710184266976776\n",
      "Error on this batch = 0.20155311125275202\n",
      "Cost on val dataset after 172 epochs is = 0.2106306607619543\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.2106306607619543\n",
      "Error on this batch = 0.18664144480948658\n",
      "Error on this batch = 0.20139263996682438\n",
      "Cost on val dataset after 173 epochs is = 0.21022000025212864\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.21022000025212864\n",
      "Error on this batch = 0.18616798708965485\n",
      "Error on this batch = 0.20122927972105553\n",
      "Cost on val dataset after 174 epochs is = 0.20974901863090942\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.20974901863090942\n",
      "Error on this batch = 0.18560979636820304\n",
      "Error on this batch = 0.2009530862547804\n",
      "Cost on val dataset after 175 epochs is = 0.20900038820127745\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.20900038820127745\n",
      "Error on this batch = 0.18456031950159563\n",
      "Error on this batch = 0.20058740685770432\n",
      "Cost on val dataset after 176 epochs is = 0.20832432460162773\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.20832432460162773\n",
      "Error on this batch = 0.18383139611628313\n",
      "Error on this batch = 0.20109931309718498\n",
      "Cost on val dataset after 177 epochs is = 0.20810333715118925\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.20810333715118925\n",
      "Error on this batch = 0.18343586009934731\n",
      "Error on this batch = 0.20132001105730105\n",
      "Cost on val dataset after 178 epochs is = 0.20789886834607504\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.20789886834607504\n",
      "Error on this batch = 0.18267752597939926\n",
      "Error on this batch = 0.20097264781316068\n",
      "Cost on val dataset after 179 epochs is = 0.2076075184556633\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.2076075184556633\n",
      "Error on this batch = 0.1819221969106696\n",
      "Error on this batch = 0.20050066186578247\n",
      "Cost on val dataset after 180 epochs is = 0.20728715001684742\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.20728715001684742\n",
      "Error on this batch = 0.18127790662581597\n",
      "Error on this batch = 0.20006839090845382\n",
      "Cost on val dataset after 181 epochs is = 0.20696416031622902\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.20696416031622902\n",
      "Error on this batch = 0.18073185995360838\n",
      "Error on this batch = 0.1996899775565965\n",
      "Cost on val dataset after 182 epochs is = 0.20664832764587326\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.20664832764587326\n",
      "Error on this batch = 0.18026152708361146\n",
      "Error on this batch = 0.19935214523453174\n",
      "Cost on val dataset after 183 epochs is = 0.20634425311651744\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.20634425311651744\n",
      "Error on this batch = 0.17984802063703853\n",
      "Error on this batch = 0.19904333671291347\n",
      "Cost on val dataset after 184 epochs is = 0.2060538981913983\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.2060538981913983\n",
      "Error on this batch = 0.17947664686687148\n",
      "Error on this batch = 0.19875633511515717\n",
      "Cost on val dataset after 185 epochs is = 0.20577762647769712\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.20577762647769712\n",
      "Error on this batch = 0.17913651671378789\n",
      "Error on this batch = 0.1984866698404234\n",
      "Cost on val dataset after 186 epochs is = 0.20551493057322512\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.20551493057322512\n",
      "Error on this batch = 0.1788198427692469\n",
      "Error on this batch = 0.19823130842125072\n",
      "Cost on val dataset after 187 epochs is = 0.20526489429670178\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.20526489429670178\n",
      "Error on this batch = 0.17852116818704822\n",
      "Error on this batch = 0.19798798987852861\n",
      "Cost on val dataset after 188 epochs is = 0.20502645662458632\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.20502645662458632\n",
      "Error on this batch = 0.17823669937921346\n",
      "Error on this batch = 0.19775494060699966\n",
      "Cost on val dataset after 189 epochs is = 0.20479855387169904\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.20479855387169904\n",
      "Error on this batch = 0.17796379571353732\n",
      "Error on this batch = 0.19753076057436672\n",
      "Cost on val dataset after 190 epochs is = 0.20458019204270905\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.20458019204270905\n",
      "Error on this batch = 0.17770060396560297\n",
      "Error on this batch = 0.19731436885725764\n",
      "Cost on val dataset after 191 epochs is = 0.20437047987041315\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.20437047987041315\n",
      "Error on this batch = 0.17744580456122458\n",
      "Error on this batch = 0.19710496215323825\n",
      "Cost on val dataset after 192 epochs is = 0.20416864031193752\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.20416864031193752\n",
      "Error on this batch = 0.1771984370601769\n",
      "Error on this batch = 0.19690197167073378\n",
      "Cost on val dataset after 193 epochs is = 0.20397401082299263\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.20397401082299263\n",
      "Error on this batch = 0.1769577794465065\n",
      "Error on this batch = 0.1967050166218377\n",
      "Cost on val dataset after 194 epochs is = 0.20378603807772636\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.20378603807772636\n",
      "Error on this batch = 0.1767232633027213\n",
      "Error on this batch = 0.19651385632919222\n",
      "Cost on val dataset after 195 epochs is = 0.20360426986239852\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.20360426986239852\n",
      "Error on this batch = 0.17649441290584403\n",
      "Error on this batch = 0.19632834318047976\n",
      "Cost on val dataset after 196 epochs is = 0.20342834513851088\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.20342834513851088\n",
      "Error on this batch = 0.17627080054486333\n",
      "Error on this batch = 0.1961483779872831\n",
      "Cost on val dataset after 197 epochs is = 0.2032579824050995\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.2032579824050995\n",
      "Error on this batch = 0.17605201327443978\n",
      "Error on this batch = 0.19597386886249482\n",
      "Cost on val dataset after 198 epochs is = 0.2030929662217702\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.2030929662217702\n",
      "Error on this batch = 0.17583762822701102\n",
      "Error on this batch = 0.19580469483503346\n",
      "Cost on val dataset after 199 epochs is = 0.20293313188155296\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.20293313188155296\n",
      "Error on this batch = 0.17562719471775357\n",
      "Error on this batch = 0.195640675935679\n",
      "Cost on val dataset after 200 epochs is = 0.20277834860338884\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.20277834860338884\n",
      "Error on this batch = 0.17542022184840939\n",
      "Error on this batch = 0.19548155205374496\n",
      "Cost on val dataset after 201 epochs is = 0.20262850213639605\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.20262850213639605\n",
      "Error on this batch = 0.17521617035184547\n",
      "Error on this batch = 0.19532697306346078\n",
      "Cost on val dataset after 202 epochs is = 0.20248347820998133\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.20248347820998133\n",
      "Error on this batch = 0.17501444732651025\n",
      "Error on this batch = 0.19517650219034555\n",
      "Cost on val dataset after 203 epochs is = 0.20234314866723815\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.20234314866723815\n",
      "Error on this batch = 0.17481440261822964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.19502963311122337\n",
      "Cost on val dataset after 204 epochs is = 0.20220736220975957\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.20220736220975957\n",
      "Error on this batch = 0.17461532608664893\n",
      "Error on this batch = 0.1948858189052661\n",
      "Cost on val dataset after 205 epochs is = 0.2020759413411737\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.2020759413411737\n",
      "Error on this batch = 0.17441644573589984\n",
      "Error on this batch = 0.19474450821602482\n",
      "Cost on val dataset after 206 epochs is = 0.20194868633985935\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.20194868633985935\n",
      "Error on this batch = 0.1742169274070872\n",
      "Error on this batch = 0.19460518190482035\n",
      "Cost on val dataset after 207 epochs is = 0.20182538607522607\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.20182538607522607\n",
      "Error on this batch = 0.17401587722609854\n",
      "Error on this batch = 0.19446738326408053\n",
      "Cost on val dataset after 208 epochs is = 0.20170583439802509\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.20170583439802509\n",
      "Error on this batch = 0.17381234832001838\n",
      "Error on this batch = 0.19433073697885772\n",
      "Cost on val dataset after 209 epochs is = 0.20158984977307995\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.20158984977307995\n",
      "Error on this batch = 0.1736053536225283\n",
      "Error on this batch = 0.19419495562335376\n",
      "Cost on val dataset after 210 epochs is = 0.20147729478476906\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.20147729478476906\n",
      "Error on this batch = 0.17339388693199898\n",
      "Error on this batch = 0.1940598358013865\n",
      "Cost on val dataset after 211 epochs is = 0.20136809126914867\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.20136809126914867\n",
      "Error on this batch = 0.17317695464883084\n",
      "Error on this batch = 0.19392524762861216\n",
      "Cost on val dataset after 212 epochs is = 0.2012622265836496\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.2012622265836496\n",
      "Error on this batch = 0.17295362063461703\n",
      "Error on this batch = 0.1937911208958732\n",
      "Cost on val dataset after 213 epochs is = 0.20115974756697744\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.20115974756697744\n",
      "Error on this batch = 0.17272306618254896\n",
      "Error on this batch = 0.19365742990489487\n",
      "Cost on val dataset after 214 epochs is = 0.20106074138077895\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.20106074138077895\n",
      "Error on this batch = 0.1724846656516237\n",
      "Error on this batch = 0.19352417787754078\n",
      "Cost on val dataset after 215 epochs is = 0.20096530616135647\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.20096530616135647\n",
      "Error on this batch = 0.17223807496805862\n",
      "Error on this batch = 0.1933913816493849\n",
      "Cost on val dataset after 216 epochs is = 0.2008735179433861\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.2008735179433861\n",
      "Error on this batch = 0.17198332411888909\n",
      "Error on this batch = 0.19325905784065767\n",
      "Cost on val dataset after 217 epochs is = 0.20078540211555698\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.20078540211555698\n",
      "Error on this batch = 0.1717208965400257\n",
      "Error on this batch = 0.19312721216922943\n",
      "Cost on val dataset after 218 epochs is = 0.20070091677757176\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.20070091677757176\n",
      "Error on this batch = 0.17145177116170138\n",
      "Error on this batch = 0.19299583346768734\n",
      "Cost on val dataset after 219 epochs is = 0.20061995197738441\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.20061995197738441\n",
      "Error on this batch = 0.17117740230912187\n",
      "Error on this batch = 0.19286489311528027\n",
      "Cost on val dataset after 220 epochs is = 0.20054234417976663\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.20054234417976663\n",
      "Error on this batch = 0.1708996233790483\n",
      "Error on this batch = 0.19273434919833846\n",
      "Cost on val dataset after 221 epochs is = 0.20046790114324903\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.20046790114324903\n",
      "Error on this batch = 0.17062048165300117\n",
      "Error on this batch = 0.19260415329390035\n",
      "Cost on val dataset after 222 epochs is = 0.2003964300264569\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.2003964300264569\n",
      "Error on this batch = 0.1703420356168287\n",
      "Error on this batch = 0.19247425702652976\n",
      "Cost on val dataset after 223 epochs is = 0.20032776159753576\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.20032776159753576\n",
      "Error on this batch = 0.17006616043501432\n",
      "Error on this batch = 0.19234461595276373\n",
      "Cost on val dataset after 224 epochs is = 0.200261765593756\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.200261765593756\n",
      "Error on this batch = 0.16979440349105032\n",
      "Error on this batch = 0.19221518973315962\n",
      "Cost on val dataset after 225 epochs is = 0.20019835555820661\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.20019835555820661\n",
      "Error on this batch = 0.16952791229457706\n",
      "Error on this batch = 0.19208593921916337\n",
      "Cost on val dataset after 226 epochs is = 0.20013748456041805\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.20013748456041805\n",
      "Error on this batch = 0.16926743258547824\n",
      "Error on this batch = 0.19195682219032123\n",
      "Cost on val dataset after 227 epochs is = 0.2000791350927544\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.2000791350927544\n",
      "Error on this batch = 0.16901335680470161\n",
      "Error on this batch = 0.19182778964724498\n",
      "Cost on val dataset after 228 epochs is = 0.2000233068402582\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.2000233068402582\n",
      "Error on this batch = 0.16876579737724498\n",
      "Error on this batch = 0.19169878396779289\n",
      "Cost on val dataset after 229 epochs is = 0.1999700053106511\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.1999700053106511\n",
      "Error on this batch = 0.16852466325862125\n",
      "Error on this batch = 0.19156973932051258\n",
      "Cost on val dataset after 230 epochs is = 0.19991923310860144\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.19991923310860144\n",
      "Error on this batch = 0.16828972644867196\n",
      "Error on this batch = 0.1914405839169418\n",
      "Cost on val dataset after 231 epochs is = 0.19987098447021698\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.19987098447021698\n",
      "Error on this batch = 0.1680606730577598\n",
      "Error on this batch = 0.19131124320619847\n",
      "Cost on val dataset after 232 epochs is = 0.1998252428181475\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.1998252428181475\n",
      "Error on this batch = 0.16783713887595986\n",
      "Error on this batch = 0.19118164303008442\n",
      "Cost on val dataset after 233 epochs is = 0.19978198061726388\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.19978198061726388\n",
      "Error on this batch = 0.167618732094669\n",
      "Error on this batch = 0.19105171200374874\n",
      "Cost on val dataset after 234 epochs is = 0.19974116064875802\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.19974116064875802\n",
      "Error on this batch = 0.1674050466100728\n",
      "Error on this batch = 0.1909213828286037\n",
      "Cost on val dataset after 235 epochs is = 0.19970273787954493\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.19970273787954493\n",
      "Error on this batch = 0.16719566905531963\n",
      "Error on this batch = 0.19079059270697493\n",
      "Cost on val dataset after 236 epochs is = 0.1996666612882103\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.1996666612882103\n",
      "Error on this batch = 0.1669901819995271\n",
      "Error on this batch = 0.1906592833554491\n",
      "Cost on val dataset after 237 epochs is = 0.19963287523985562\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.19963287523985562\n",
      "Error on this batch = 0.1667881649937403\n",
      "Error on this batch = 0.19052740122031672\n",
      "Cost on val dataset after 238 epochs is = 0.19960132022431581\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.19960132022431581\n",
      "Error on this batch = 0.16658919451851406\n",
      "Error on this batch = 0.19039489838918244\n",
      "Cost on val dataset after 239 epochs is = 0.1995719329544133\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.1995719329544133\n",
      "Error on this batch = 0.16639284345791303\n",
      "Error on this batch = 0.19026173443806485\n",
      "Cost on val dataset after 240 epochs is = 0.19954464595483623\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.19954464595483623\n",
      "Error on this batch = 0.16619868049346057\n",
      "Error on this batch = 0.19012787913864007\n",
      "Cost on val dataset after 241 epochs is = 0.19951938686492157\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.19951938686492157\n",
      "Error on this batch = 0.16600626975858848\n",
      "Error on this batch = 0.1899933156398764\n",
      "Cost on val dataset after 242 epochs is = 0.1994960777416981\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.1994960777416981\n",
      "Error on this batch = 0.165815171188553\n",
      "Error on this batch = 0.18985804347347335\n",
      "Cost on val dataset after 243 epochs is = 0.19947463468832394\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.19947463468832394\n",
      "Error on this batch = 0.1656249421921293\n",
      "Error on this batch = 0.18972208055882522\n",
      "Cost on val dataset after 244 epochs is = 0.1994549681387328\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.1994549681387328\n",
      "Error on this batch = 0.1654351414677071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.18958546337864612\n",
      "Cost on val dataset after 245 epochs is = 0.1994369840773405\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.1994369840773405\n",
      "Error on this batch = 0.16524533583903506\n",
      "Error on this batch = 0.18944824476555874\n",
      "Cost on val dataset after 246 epochs is = 0.19942058633161452\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.19942058633161452\n",
      "Error on this batch = 0.16505511071029488\n",
      "Error on this batch = 0.18931048934901298\n",
      "Cost on val dataset after 247 epochs is = 0.19940567982953886\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.19940567982953886\n",
      "Error on this batch = 0.16486408399936037\n",
      "Error on this batch = 0.18917226757690223\n",
      "Cost on val dataset after 248 epochs is = 0.1993921743954883\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.1993921743954883\n",
      "Error on this batch = 0.1646719222495642\n",
      "Error on this batch = 0.18903365003546374\n",
      "Cost on val dataset after 249 epochs is = 0.19937998836569856\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.19937998836569856\n",
      "Error on this batch = 0.16447835638542177\n",
      "Error on this batch = 0.18889470408383674\n",
      "Cost on val dataset after 250 epochs is = 0.19936905117979092\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.19936905117979092\n",
      "Error on this batch = 0.16428319384454199\n",
      "Error on this batch = 0.18875549426404667\n",
      "Cost on val dataset after 251 epochs is = 0.19935930425346382\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.19935930425346382\n",
      "Error on this batch = 0.16408632410485813\n",
      "Error on this batch = 0.1886160866478982\n",
      "Cost on val dataset after 252 epochs is = 0.1993506998425113\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.1993506998425113\n",
      "Error on this batch = 0.16388771600404206\n",
      "Error on this batch = 0.18847655581754325\n",
      "Cost on val dataset after 253 epochs is = 0.19934319811210188\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.19934319811210188\n",
      "Error on this batch = 0.16368740718565997\n",
      "Error on this batch = 0.18833699224756228\n",
      "Cost on val dataset after 254 epochs is = 0.1993367630138902\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.1993367630138902\n",
      "Error on this batch = 0.1634854876487487\n",
      "Error on this batch = 0.18819750781795017\n",
      "Cost on val dataset after 255 epochs is = 0.1993313577014126\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.1993313577014126\n",
      "Error on this batch = 0.1632820800578105\n",
      "Error on this batch = 0.18805823786258274\n",
      "Cost on val dataset after 256 epochs is = 0.19932694006764842\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.19932694006764842\n",
      "Error on this batch = 0.16307731904323106\n",
      "Error on this batch = 0.18791933904918087\n",
      "Cost on val dataset after 257 epochs is = 0.199323458652401\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.199323458652401\n",
      "Error on this batch = 0.16287133049255698\n",
      "Error on this batch = 0.1877809830340841\n",
      "Cost on val dataset after 258 epochs is = 0.1993208487457204\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.1993208487457204\n",
      "Error on this batch = 0.16266421023158983\n",
      "Error on this batch = 0.18764334602637242\n",
      "Cost on val dataset after 259 epochs is = 0.19931902807785098\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.19931902807785098\n",
      "Error on this batch = 0.1624559997815784\n",
      "Error on this batch = 0.18750659415444723\n",
      "Cost on val dataset after 260 epochs is = 0.19931789107344097\n",
      "cost initial= 0.19931902807785098 , cost final=0.19931789107344097 , change in cost= -1.137004410012299e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 10 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 260\n",
      "The training time = 20.370sec\n",
      "The training accuracy is = 81.258%\n",
      "The validation accuracy is = 72.821%\n",
      "The test accuracy is = 72.108%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 50 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 50)\n",
      "theta between layer 1 and layer 2 is (51, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.4198192865048322\n",
      "Error on this batch = 3.4202848064809017\n",
      "Error on this batch = 0.480167146283967\n",
      "Cost on val dataset after 2 epochs is = 0.47945217515538197\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.47945217515538197\n",
      "Error on this batch = 0.4790290624106092\n",
      "Error on this batch = 0.4780468422892399\n",
      "Cost on val dataset after 3 epochs is = 0.4764234998038342\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4764234998038342\n",
      "Error on this batch = 0.47585081348813\n",
      "Error on this batch = 0.4732062217893474\n",
      "Cost on val dataset after 4 epochs is = 0.4683659492303805\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4683659492303805\n",
      "Error on this batch = 0.46721321034686847\n",
      "Error on this batch = 0.45808700067627817\n",
      "Cost on val dataset after 5 epochs is = 0.4396709445195497\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4396709445195497\n",
      "Error on this batch = 0.43678415250092856\n",
      "Error on this batch = 0.42423064788165804\n",
      "Cost on val dataset after 6 epochs is = 0.394059992931313\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.394059992931313\n",
      "Error on this batch = 0.3894123656168105\n",
      "Error on this batch = 0.38308619431036633\n",
      "Cost on val dataset after 7 epochs is = 0.3406334244798474\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.3406334244798474\n",
      "Error on this batch = 0.3345848851152849\n",
      "Error on this batch = 0.3402373591349204\n",
      "Cost on val dataset after 8 epochs is = 0.296411755959325\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.296411755959325\n",
      "Error on this batch = 0.2872930051071299\n",
      "Error on this batch = 0.30238142980918176\n",
      "Cost on val dataset after 9 epochs is = 0.26099520641783597\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.26099520641783597\n",
      "Error on this batch = 0.24736678768446355\n",
      "Error on this batch = 0.27083925872322007\n",
      "Cost on val dataset after 10 epochs is = 0.23352772505579936\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.23352772505579936\n",
      "Error on this batch = 0.21573366199006994\n",
      "Error on this batch = 0.2467986711826115\n",
      "Cost on val dataset after 11 epochs is = 0.21294627641301359\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.21294627641301359\n",
      "Error on this batch = 0.19240040616000534\n",
      "Error on this batch = 0.22879737577312448\n",
      "Cost on val dataset after 12 epochs is = 0.19731383699021196\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.19731383699021196\n",
      "Error on this batch = 0.17523801341825\n",
      "Error on this batch = 0.2147087630318286\n",
      "Cost on val dataset after 13 epochs is = 0.1851216856756727\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.1851216856756727\n",
      "Error on this batch = 0.16212401920527847\n",
      "Error on this batch = 0.2031646231963936\n",
      "Cost on val dataset after 14 epochs is = 0.17540655701856991\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.17540655701856991\n",
      "Error on this batch = 0.15165373668574708\n",
      "Error on this batch = 0.19342293981465822\n",
      "Cost on val dataset after 15 epochs is = 0.1675145964178297\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.1675145964178297\n",
      "Error on this batch = 0.14298511101994685\n",
      "Error on this batch = 0.18504885708263769\n",
      "Cost on val dataset after 16 epochs is = 0.16098120355786932\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.16098120355786932\n",
      "Error on this batch = 0.13561584744142113\n",
      "Error on this batch = 0.17775192983536706\n",
      "Cost on val dataset after 17 epochs is = 0.15547690927582222\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.15547690927582222\n",
      "Error on this batch = 0.1292367562693988\n",
      "Error on this batch = 0.1713219769814191\n",
      "Cost on val dataset after 18 epochs is = 0.15076761395823976\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.15076761395823976\n",
      "Error on this batch = 0.1236464458015341\n",
      "Error on this batch = 0.16560163213906098\n",
      "Cost on val dataset after 19 epochs is = 0.14668427565866793\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.14668427565866793\n",
      "Error on this batch = 0.11870403095480214\n",
      "Error on this batch = 0.1604709152842825\n",
      "Cost on val dataset after 20 epochs is = 0.1431021936733553\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.1431021936733553\n",
      "Error on this batch = 0.11430317152465086\n",
      "Error on this batch = 0.15583709179125277\n",
      "Cost on val dataset after 21 epochs is = 0.13992749747924568\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.13992749747924568\n",
      "Error on this batch = 0.1103580280547404\n",
      "Error on this batch = 0.15162768363461143\n",
      "Cost on val dataset after 22 epochs is = 0.13708828427448397\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.13708828427448397\n",
      "Error on this batch = 0.10679621652423794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1477853764537962\n",
      "Cost on val dataset after 23 epochs is = 0.13452864178093413\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.13452864178093413\n",
      "Error on this batch = 0.10355569313271877\n",
      "Error on this batch = 0.14426410799243541\n",
      "Cost on val dataset after 24 epochs is = 0.13220450144338483\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.13220450144338483\n",
      "Error on this batch = 0.10058336617533536\n",
      "Error on this batch = 0.14102603752851361\n",
      "Cost on val dataset after 25 epochs is = 0.130080700108994\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.130080700108994\n",
      "Error on this batch = 0.09783416635099666\n",
      "Error on this batch = 0.1380392652252828\n",
      "Cost on val dataset after 26 epochs is = 0.1281288654784933\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.1281288654784933\n",
      "Error on this batch = 0.09527015217029189\n",
      "Error on this batch = 0.1352761924485992\n",
      "Cost on val dataset after 27 epochs is = 0.1263258735202972\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.1263258735202972\n",
      "Error on this batch = 0.09285964887911602\n",
      "Error on this batch = 0.13271240183948332\n",
      "Cost on val dataset after 28 epochs is = 0.12465270609091252\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.12465270609091252\n",
      "Error on this batch = 0.09057648129514619\n",
      "Error on this batch = 0.13032593492301595\n",
      "Cost on val dataset after 29 epochs is = 0.12309359003405561\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.12309359003405561\n",
      "Error on this batch = 0.08839930259709246\n",
      "Error on this batch = 0.1280968575042784\n",
      "Cost on val dataset after 30 epochs is = 0.12163533804937567\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.12163533804937567\n",
      "Error on this batch = 0.08631099128291023\n",
      "Error on this batch = 0.12600701950306686\n",
      "Cost on val dataset after 31 epochs is = 0.12026684027564186\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.12026684027564186\n",
      "Error on this batch = 0.08429810509418718\n",
      "Error on this batch = 0.1240399316332627\n",
      "Cost on val dataset after 32 epochs is = 0.11897867312023896\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.11897867312023896\n",
      "Error on this batch = 0.08235040374779555\n",
      "Error on this batch = 0.12218069799653013\n",
      "Cost on val dataset after 33 epochs is = 0.11776279982968169\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.11776279982968169\n",
      "Error on this batch = 0.0804604523495605\n",
      "Error on this batch = 0.12041596252684776\n",
      "Cost on val dataset after 34 epochs is = 0.116612340389587\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.116612340389587\n",
      "Error on this batch = 0.07862329475972869\n",
      "Error on this batch = 0.11873384612240066\n",
      "Cost on val dataset after 35 epochs is = 0.1155213910823697\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.1155213910823697\n",
      "Error on this batch = 0.07683615777022133\n",
      "Error on this batch = 0.11712386690340534\n",
      "Cost on val dataset after 36 epochs is = 0.11448487810349832\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.11448487810349832\n",
      "Error on this batch = 0.07509813095350525\n",
      "Error on this batch = 0.11557684681534579\n",
      "Cost on val dataset after 37 epochs is = 0.11349843439130587\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.11349843439130587\n",
      "Error on this batch = 0.07340977548361476\n",
      "Error on this batch = 0.114084814227976\n",
      "Cost on val dataset after 38 epochs is = 0.1125582930280483\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.1125582930280483\n",
      "Error on this batch = 0.07177264882243295\n",
      "Error on this batch = 0.11264091503284802\n",
      "Cost on val dataset after 39 epochs is = 0.11166119354494772\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.11166119354494772\n",
      "Error on this batch = 0.07018877784113993\n",
      "Error on this batch = 0.11123934391357779\n",
      "Cost on val dataset after 40 epochs is = 0.1108042992237551\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.1108042992237551\n",
      "Error on this batch = 0.06866014912786483\n",
      "Error on this batch = 0.10987530231533316\n",
      "Cost on val dataset after 41 epochs is = 0.10998512436840509\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.10998512436840509\n",
      "Error on this batch = 0.0671882940083801\n",
      "Error on this batch = 0.10854498021766704\n",
      "Cost on val dataset after 42 epochs is = 0.10920147085943904\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.10920147085943904\n",
      "Error on this batch = 0.06577402370011702\n",
      "Error on this batch = 0.1072455469245634\n",
      "Cost on val dataset after 43 epochs is = 0.10845137333519785\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.10845137333519785\n",
      "Error on this batch = 0.06441732933234344\n",
      "Error on this batch = 0.10597512560260468\n",
      "Cost on val dataset after 44 epochs is = 0.10773305223695707\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.10773305223695707\n",
      "Error on this batch = 0.06311742178285118\n",
      "Error on this batch = 0.10473272240372584\n",
      "Cost on val dataset after 45 epochs is = 0.10704487387709297\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.10704487387709297\n",
      "Error on this batch = 0.061872862511612094\n",
      "Error on this batch = 0.1035180882217814\n",
      "Cost on val dataset after 46 epochs is = 0.10638531681490458\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.10638531681490458\n",
      "Error on this batch = 0.060681733124708225\n",
      "Error on this batch = 0.102331510384962\n",
      "Cost on val dataset after 47 epochs is = 0.10575294425068384\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.10575294425068384\n",
      "Error on this batch = 0.05954180309612015\n",
      "Error on this batch = 0.10117355764626938\n",
      "Cost on val dataset after 48 epochs is = 0.10514638274075087\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.10514638274075087\n",
      "Error on this batch = 0.058450672773996126\n",
      "Error on this batch = 0.10004482362507551\n",
      "Cost on val dataset after 49 epochs is = 0.10456430788417204\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.10456430788417204\n",
      "Error on this batch = 0.05740588450140074\n",
      "Error on this batch = 0.0989457196438217\n",
      "Cost on val dataset after 50 epochs is = 0.10400543730186776\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.10400543730186776\n",
      "Error on this batch = 0.05640500413437154\n",
      "Error on this batch = 0.0978763532565754\n",
      "Cost on val dataset after 51 epochs is = 0.10346853019596426\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.10346853019596426\n",
      "Error on this batch = 0.05544567826097122\n",
      "Error on this batch = 0.0968365007089196\n",
      "Cost on val dataset after 52 epochs is = 0.10295239158153884\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.10295239158153884\n",
      "Error on this batch = 0.05452567159823687\n",
      "Error on this batch = 0.09582565425061539\n",
      "Cost on val dataset after 53 epochs is = 0.10245587864159034\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.10245587864159034\n",
      "Error on this batch = 0.05364288751482259\n",
      "Error on this batch = 0.09484311033096593\n",
      "Cost on val dataset after 54 epochs is = 0.1019779068899971\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.1019779068899971\n",
      "Error on this batch = 0.052795374204895204\n",
      "Error on this batch = 0.09388806500049214\n",
      "Cost on val dataset after 55 epochs is = 0.10151745468217965\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.10151745468217965\n",
      "Error on this batch = 0.05198131970339418\n",
      "Error on this batch = 0.09295969317313935\n",
      "Cost on val dataset after 56 epochs is = 0.10107356557032043\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.10107356557032043\n",
      "Error on this batch = 0.051199039697887645\n",
      "Error on this batch = 0.09205720124428683\n",
      "Cost on val dataset after 57 epochs is = 0.10064534867451075\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.10064534867451075\n",
      "Error on this batch = 0.05044696214917982\n",
      "Error on this batch = 0.09117985264475642\n",
      "Cost on val dataset after 58 epochs is = 0.10023197753288512\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.10023197753288512\n",
      "Error on this batch = 0.04972361195710105\n",
      "Error on this batch = 0.0903269715235141\n",
      "Cost on val dataset after 59 epochs is = 0.09983268790116774\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.09983268790116774\n",
      "Error on this batch = 0.04902759767909698\n",
      "Error on this batch = 0.08949793160916243\n",
      "Cost on val dataset after 60 epochs is = 0.09944677484773555\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.09944677484773555\n",
      "Error on this batch = 0.0483576011061672\n",
      "Error on this batch = 0.08869213693035638\n",
      "Cost on val dataset after 61 epochs is = 0.09907358935160764\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.09907358935160764\n",
      "Error on this batch = 0.04771236963478087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.087908999781279\n",
      "Cost on val dataset after 62 epochs is = 0.09871253451570429\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.09871253451570429\n",
      "Error on this batch = 0.047090710929073264\n",
      "Error on this batch = 0.08714791985791602\n",
      "Cost on val dataset after 63 epochs is = 0.09836306146628139\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.09836306146628139\n",
      "Error on this batch = 0.04649148926461361\n",
      "Error on this batch = 0.08640826716686699\n",
      "Cost on val dataset after 64 epochs is = 0.09802466500539163\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.09802466500539163\n",
      "Error on this batch = 0.04591362303206497\n",
      "Error on this batch = 0.0856893701772751\n",
      "Cost on val dataset after 65 epochs is = 0.09769687909457717\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.09769687909457717\n",
      "Error on this batch = 0.045356083012048874\n",
      "Error on this batch = 0.08499050972964156\n",
      "Cost on val dataset after 66 epochs is = 0.09737927226094513\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.09737927226094513\n",
      "Error on this batch = 0.04481789112151462\n",
      "Error on this batch = 0.08431091842929102\n",
      "Cost on val dataset after 67 epochs is = 0.09707144302994704\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.09707144302994704\n",
      "Error on this batch = 0.044298119355588556\n",
      "Error on this batch = 0.08364978466593691\n",
      "Cost on val dataset after 68 epochs is = 0.09677301550826262\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.09677301550826262\n",
      "Error on this batch = 0.04379588864200404\n",
      "Error on this batch = 0.08300626004943268\n",
      "Cost on val dataset after 69 epochs is = 0.09648363526707061\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.09648363526707061\n",
      "Error on this batch = 0.04331036734731626\n",
      "Error on this batch = 0.0823794689416562\n",
      "Cost on val dataset after 70 epochs is = 0.09620296570003335\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.09620296570003335\n",
      "Error on this batch = 0.042840769270540806\n",
      "Error on this batch = 0.08176851885539069\n",
      "Cost on val dataset after 71 epochs is = 0.09593068502917466\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.09593068502917466\n",
      "Error on this batch = 0.04238635112964026\n",
      "Error on this batch = 0.08117251070798416\n",
      "Cost on val dataset after 72 epochs is = 0.09566648408407345\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.09566648408407345\n",
      "Error on this batch = 0.041946409734028085\n",
      "Error on this batch = 0.08059054818267822\n",
      "Cost on val dataset after 73 epochs is = 0.0954100648825732\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.0954100648825732\n",
      "Error on this batch = 0.041520279159085814\n",
      "Error on this batch = 0.08002174571384245\n",
      "Cost on val dataset after 74 epochs is = 0.09516113991903632\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.09516113991903632\n",
      "Error on this batch = 0.041107328237465025\n",
      "Error on this batch = 0.079465234858912\n",
      "Cost on val dataset after 75 epochs is = 0.0949194319612147\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.0949194319612147\n",
      "Error on this batch = 0.04070695856177919\n",
      "Error on this batch = 0.0789201690489894\n",
      "Cost on val dataset after 76 epochs is = 0.0946846741056622\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.0946846741056622\n",
      "Error on this batch = 0.040318603020128345\n",
      "Error on this batch = 0.07838572690900471\n",
      "Cost on val dataset after 77 epochs is = 0.09445660985598675\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.09445660985598675\n",
      "Error on this batch = 0.039941724742104494\n",
      "Error on this batch = 0.0778611144773989\n",
      "Cost on val dataset after 78 epochs is = 0.0942349930525289\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.0942349930525289\n",
      "Error on this batch = 0.03957581626956719\n",
      "Error on this batch = 0.07734556670895917\n",
      "Cost on val dataset after 79 epochs is = 0.09401958756599452\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.09401958756599452\n",
      "Error on this batch = 0.039220398786128256\n",
      "Error on this batch = 0.07683834861339593\n",
      "Cost on val dataset after 80 epochs is = 0.09381016674221997\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.09381016674221997\n",
      "Error on this batch = 0.03887502131050945\n",
      "Error on this batch = 0.07633875629485393\n",
      "Cost on val dataset after 81 epochs is = 0.09360651263310574\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.09360651263310574\n",
      "Error on this batch = 0.03853925984181944\n",
      "Error on this batch = 0.07584611805290692\n",
      "Cost on val dataset after 82 epochs is = 0.09340841506595202\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.09340841506595202\n",
      "Error on this batch = 0.038212716509486724\n",
      "Error on this batch = 0.07535979561556656\n",
      "Cost on val dataset after 83 epochs is = 0.0932156705965771\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.0932156705965771\n",
      "Error on this batch = 0.03789501881381442\n",
      "Error on this batch = 0.07487918551605136\n",
      "Cost on val dataset after 84 epochs is = 0.09302808137266906\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.09302808137266906\n",
      "Error on this batch = 0.03758581904545059\n",
      "Error on this batch = 0.0744037205996472\n",
      "Cost on val dataset after 85 epochs is = 0.09284545391556033\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.09284545391556033\n",
      "Error on this batch = 0.037284793950251846\n",
      "Error on this batch = 0.07393287164569755\n",
      "Cost on val dataset after 86 epochs is = 0.09266759782198704\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.09266759782198704\n",
      "Error on this batch = 0.036991644664633644\n",
      "Error on this batch = 0.07346614909349734\n",
      "Cost on val dataset after 87 epochs is = 0.09249432440119613\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.09249432440119613\n",
      "Error on this batch = 0.03670609688219243\n",
      "Error on this batch = 0.07300310484144729\n",
      "Cost on val dataset after 88 epochs is = 0.09232544530433492\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.09232544530433492\n",
      "Error on this batch = 0.03642790111382983\n",
      "Error on this batch = 0.07254333401302582\n",
      "Cost on val dataset after 89 epochs is = 0.0921607712774927\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.0921607712774927\n",
      "Error on this batch = 0.03615683275985442\n",
      "Error on this batch = 0.07208647642519508\n",
      "Cost on val dataset after 90 epochs is = 0.09200011127436096\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.09200011127436096\n",
      "Error on this batch = 0.03589269153129937\n",
      "Error on this batch = 0.0716322172612297\n",
      "Cost on val dataset after 91 epochs is = 0.09184327227672069\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.09184327227672069\n",
      "Error on this batch = 0.03563529959049857\n",
      "Error on this batch = 0.07118028621264469\n",
      "Cost on val dataset after 92 epochs is = 0.09169006023589271\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.09169006023589271\n",
      "Error on this batch = 0.03538449773980227\n",
      "Error on this batch = 0.07073045427248388\n",
      "Cost on val dataset after 93 epochs is = 0.09154028248400094\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.09154028248400094\n",
      "Error on this batch = 0.03514013922093321\n",
      "Error on this batch = 0.07028252764509808\n",
      "Cost on val dataset after 94 epochs is = 0.09139375171024039\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.09139375171024039\n",
      "Error on this batch = 0.03490208128546733\n",
      "Error on this batch = 0.06983633901599884\n",
      "Cost on val dataset after 95 epochs is = 0.09125029120264641\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.09125029120264641\n",
      "Error on this batch = 0.03467017554364154\n",
      "Error on this batch = 0.0693917375547026\n",
      "Cost on val dataset after 96 epochs is = 0.09110974072482479\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.09110974072482479\n",
      "Error on this batch = 0.034444258803044046\n",
      "Error on this batch = 0.06894857999720944\n",
      "Cost on val dataset after 97 epochs is = 0.09097196238998832\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.09097196238998832\n",
      "Error on this batch = 0.03422414617309865\n",
      "Error on this batch = 0.06850672533288854\n",
      "Cost on val dataset after 98 epochs is = 0.09083684629359597\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.09083684629359597\n",
      "Error on this batch = 0.03400962742063018\n",
      "Error on this batch = 0.06806603472200355\n",
      "Cost on val dataset after 99 epochs is = 0.0907043162298415\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.0907043162298415\n",
      "Error on this batch = 0.03380046627132963\n",
      "Error on this batch = 0.06762637669758091\n",
      "Cost on val dataset after 100 epochs is = 0.09057433612027532\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.09057433612027532\n",
      "Error on this batch = 0.03359640133729835\n",
      "Error on this batch = 0.06718763630437682\n",
      "Cost on val dataset after 101 epochs is = 0.0904469175105564\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.0904469175105564\n",
      "Error on this batch = 0.03339714731501949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06674972625603698\n",
      "Cost on val dataset after 102 epochs is = 0.09032212759692788\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.09032212759692788\n",
      "Error on this batch = 0.03320239627687999\n",
      "Error on this batch = 0.0663125984944603\n",
      "Cost on val dataset after 103 epochs is = 0.09020009591403082\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.09020009591403082\n",
      "Error on this batch = 0.033011820952825885\n",
      "Error on this batch = 0.06587625524850843\n",
      "Cost on val dataset after 104 epochs is = 0.09008101646847098\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.09008101646847098\n",
      "Error on this batch = 0.032825083940701695\n",
      "Error on this batch = 0.06544075923810051\n",
      "Cost on val dataset after 105 epochs is = 0.08996514149038358\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.08996514149038358\n",
      "Error on this batch = 0.03264185705492927\n",
      "Error on this batch = 0.06500624267292962\n",
      "Cost on val dataset after 106 epochs is = 0.08985276404713217\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.08985276404713217\n",
      "Error on this batch = 0.03246185129171833\n",
      "Error on this batch = 0.06457291405963105\n",
      "Cost on val dataset after 107 epochs is = 0.08974418992975208\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.08974418992975208\n",
      "Error on this batch = 0.03228484966611056\n",
      "Error on this batch = 0.06414106084884423\n",
      "Cost on val dataset after 108 epochs is = 0.0896397034875964\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.0896397034875964\n",
      "Error on this batch = 0.03211072726338366\n",
      "Error on this batch = 0.06371104547187068\n",
      "Cost on val dataset after 109 epochs is = 0.08953953525696388\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.08953953525696388\n",
      "Error on this batch = 0.03193944445044752\n",
      "Error on this batch = 0.06328329342555963\n",
      "Cost on val dataset after 110 epochs is = 0.08944383937571151\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.08944383937571151\n",
      "Error on this batch = 0.031771013775483865\n",
      "Error on this batch = 0.06285827482244255\n",
      "Cost on val dataset after 111 epochs is = 0.08935268551025707\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.08935268551025707\n",
      "Error on this batch = 0.031605457637735576\n",
      "Error on this batch = 0.062436483396118736\n",
      "Cost on val dataset after 112 epochs is = 0.08926606482869558\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.08926606482869558\n",
      "Error on this batch = 0.031442776962533316\n",
      "Error on this batch = 0.06201841719405402\n",
      "Cost on val dataset after 113 epochs is = 0.08918390520230247\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.08918390520230247\n",
      "Error on this batch = 0.0312829398711487\n",
      "Error on this batch = 0.06160456315558867\n",
      "Cost on val dataset after 114 epochs is = 0.08910608947933206\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.08910608947933206\n",
      "Error on this batch = 0.03112588637111811\n",
      "Error on this batch = 0.061195385486694905\n",
      "Cost on val dataset after 115 epochs is = 0.08903247219221795\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.08903247219221795\n",
      "Error on this batch = 0.030971539978888765\n",
      "Error on this batch = 0.06079131673659829\n",
      "Cost on val dataset after 116 epochs is = 0.08896289258169339\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.08896289258169339\n",
      "Error on this batch = 0.030819819123039292\n",
      "Error on this batch = 0.06039275066129204\n",
      "Cost on val dataset after 117 epochs is = 0.08889718376175437\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.08889718376175437\n",
      "Error on this batch = 0.030670645118396296\n",
      "Error on this batch = 0.06000003649782077\n",
      "Cost on val dataset after 118 epochs is = 0.08883517876216958\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.08883517876216958\n",
      "Error on this batch = 0.03052394632396376\n",
      "Error on this batch = 0.05961347462716687\n",
      "Cost on val dataset after 119 epochs is = 0.088776714356358\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.088776714356358\n",
      "Error on this batch = 0.03037965932425068\n",
      "Error on this batch = 0.05923331369188553\n",
      "Cost on val dataset after 120 epochs is = 0.08872163341801888\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.08872163341801888\n",
      "Error on this batch = 0.03023772820489948\n",
      "Error on this batch = 0.05885974918034712\n",
      "Cost on val dataset after 121 epochs is = 0.08866978631063177\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.08866978631063177\n",
      "Error on this batch = 0.030098102822349277\n",
      "Error on this batch = 0.05849292340843612\n",
      "Cost on val dataset after 122 epochs is = 0.08862103161077577\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.08862103161077577\n",
      "Error on this batch = 0.029960736711003855\n",
      "Error on this batch = 0.05813292677249113\n",
      "Cost on val dataset after 123 epochs is = 0.08857523632673373\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.08857523632673373\n",
      "Error on this batch = 0.029825585045726983\n",
      "Error on this batch = 0.05777980011927108\n",
      "Cost on val dataset after 124 epochs is = 0.08853227569312723\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.08853227569312723\n",
      "Error on this batch = 0.029692602905201166\n",
      "Error on this batch = 0.05743353806920599\n",
      "Cost on val dataset after 125 epochs is = 0.08849203258699329\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.08849203258699329\n",
      "Error on this batch = 0.029561743956064035\n",
      "Error on this batch = 0.05709409312855373\n",
      "Cost on val dataset after 126 epochs is = 0.08845439660692984\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.08845439660692984\n",
      "Error on this batch = 0.029432959588206912\n",
      "Error on this batch = 0.05676138043018868\n",
      "Cost on val dataset after 127 epochs is = 0.08841926287206091\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.08841926287206091\n",
      "Error on this batch = 0.02930619847040784\n",
      "Error on this batch = 0.056435282951271634\n",
      "Cost on val dataset after 128 epochs is = 0.08838653062035211\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.08838653062035211\n",
      "Error on this batch = 0.02918140645743106\n",
      "Error on this batch = 0.056115657069660055\n",
      "Cost on val dataset after 129 epochs is = 0.08835610170676873\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.08835610170676873\n",
      "Error on this batch = 0.029058526760802703\n",
      "Error on this batch = 0.05580233833925602\n",
      "Cost on val dataset after 130 epochs is = 0.08832787911384125\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.08832787911384125\n",
      "Error on this batch = 0.02893750029167376\n",
      "Error on this batch = 0.055495147385288705\n",
      "Cost on val dataset after 131 epochs is = 0.0883017655862758\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.0883017655862758\n",
      "Error on this batch = 0.02881826609135386\n",
      "Error on this batch = 0.055193895839737384\n",
      "Cost on val dataset after 132 epochs is = 0.0882776624863244\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.0882776624863244\n",
      "Error on this batch = 0.028700761779264852\n",
      "Error on this batch = 0.05489839224950334\n",
      "Cost on val dataset after 133 epochs is = 0.0882554689395446\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.0882554689395446\n",
      "Error on this batch = 0.028584923965908057\n",
      "Error on this batch = 0.0546084478902247\n",
      "Cost on val dataset after 134 epochs is = 0.0882350813054413\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.0882350813054413\n",
      "Error on this batch = 0.02847068859768309\n",
      "Error on this batch = 0.05432388240245314\n",
      "Cost on val dataset after 135 epochs is = 0.08821639297001731\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.08821639297001731\n",
      "Error on this batch = 0.028357991219949193\n",
      "Error on this batch = 0.05404452913169097\n",
      "Cost on val dataset after 136 epochs is = 0.08819929442416886\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.08819929442416886\n",
      "Error on this batch = 0.028246767164651753\n",
      "Error on this batch = 0.05377023999870875\n",
      "Cost on val dataset after 137 epochs is = 0.08818367357008029\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.08818367357008029\n",
      "Error on this batch = 0.028136951690266736\n",
      "Error on this batch = 0.05350088965161921\n",
      "Cost on val dataset after 138 epochs is = 0.08816941619329118\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.08816941619329118\n",
      "Error on this batch = 0.02802848012669609\n",
      "Error on this batch = 0.053236378555394044\n",
      "Cost on val dataset after 139 epochs is = 0.08815640655401016\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.08815640655401016\n",
      "Error on this batch = 0.027921288108175395\n",
      "Error on this batch = 0.05297663455455526\n",
      "Cost on val dataset after 140 epochs is = 0.08814452808443154\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.08814452808443154\n",
      "Error on this batch = 0.027815312013455405\n",
      "Error on this batch = 0.052721612296583786\n",
      "Cost on val dataset after 141 epochs is = 0.08813366421548675\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.08813366421548675\n",
      "Error on this batch = 0.027710489768418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.0524712897317359\n",
      "Cost on val dataset after 142 epochs is = 0.08812369936793361\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.08812369936793361\n",
      "Error on this batch = 0.027606762182547016\n",
      "Error on this batch = 0.05222566074735013\n",
      "Cost on val dataset after 143 epochs is = 0.08811452008682992\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.08811452008682992\n",
      "Error on this batch = 0.02750407494815466\n",
      "Error on this batch = 0.05198472297212236\n",
      "Cost on val dataset after 144 epochs is = 0.08810601613702268\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.08810601613702268\n",
      "Error on this batch = 0.027402381273175857\n",
      "Error on this batch = 0.051748460179649076\n",
      "Cost on val dataset after 145 epochs is = 0.08809808111954542\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.08809808111954542\n",
      "Error on this batch = 0.02730164479378902\n",
      "Error on this batch = 0.05151682004523945\n",
      "Cost on val dataset after 146 epochs is = 0.08809061193777072\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.08809061193777072\n",
      "Error on this batch = 0.027201841932745642\n",
      "Error on this batch = 0.051289690928685135\n",
      "Cost on val dataset after 147 epochs is = 0.08808350652368421\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.08808350652368421\n",
      "Error on this batch = 0.02710296238984673\n",
      "Error on this batch = 0.05106688606370816\n",
      "Cost on val dataset after 148 epochs is = 0.08807666001244427\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.08807666001244427\n",
      "Error on this batch = 0.027005006352644533\n",
      "Error on this batch = 0.050848148184988\n",
      "Cost on val dataset after 149 epochs is = 0.0880699611860501\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.0880699611860501\n",
      "Error on this batch = 0.026907977857548476\n",
      "Error on this batch = 0.05063318656916121\n",
      "Cost on val dataset after 150 epochs is = 0.08806329280707076\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.08806329280707076\n",
      "Error on this batch = 0.026811875853168736\n",
      "Error on this batch = 0.05042174445370291\n",
      "Cost on val dataset after 151 epochs is = 0.08805653951382203\n",
      "cost initial= 0.08806329280707076 , cost final=0.08805653951382203 , change in cost= -6.7532932487290864e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 50 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 151\n",
      "The training time = 19.428sec\n",
      "The training accuracy is = 95.900%\n",
      "The validation accuracy is = 89.641%\n",
      "The test accuracy is = 88.477%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 100 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.417146543324373\n",
      "Error on this batch = 3.419129840686809\n",
      "Error on this batch = 0.48051074016705453\n",
      "Cost on val dataset after 2 epochs is = 0.4782646363474272\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4782646363474272\n",
      "Error on this batch = 0.4769542035391652\n",
      "Error on this batch = 0.47596588098577985\n",
      "Cost on val dataset after 3 epochs is = 0.47086283768395515\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47086283768395515\n",
      "Error on this batch = 0.46988623045086825\n",
      "Error on this batch = 0.46168140199179014\n",
      "Cost on val dataset after 4 epochs is = 0.43997664452775787\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.43997664452775787\n",
      "Error on this batch = 0.4377081680220942\n",
      "Error on this batch = 0.4180406211954513\n",
      "Cost on val dataset after 5 epochs is = 0.38366264235468295\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.38366264235468295\n",
      "Error on this batch = 0.37817676568872627\n",
      "Error on this batch = 0.3703968829337984\n",
      "Cost on val dataset after 6 epochs is = 0.3239803083386801\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.3239803083386801\n",
      "Error on this batch = 0.3135608772608014\n",
      "Error on this batch = 0.32226860209357994\n",
      "Cost on val dataset after 7 epochs is = 0.27243658017209077\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.27243658017209077\n",
      "Error on this batch = 0.25595365831945033\n",
      "Error on this batch = 0.2818497652244164\n",
      "Cost on val dataset after 8 epochs is = 0.23675775822756176\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.23675775822756176\n",
      "Error on this batch = 0.21709148470222617\n",
      "Error on this batch = 0.2512156052727976\n",
      "Cost on val dataset after 9 epochs is = 0.21205481013340213\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.21205481013340213\n",
      "Error on this batch = 0.19079666784126134\n",
      "Error on this batch = 0.22925528850346585\n",
      "Cost on val dataset after 10 epochs is = 0.19462185967509302\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.19462185967509302\n",
      "Error on this batch = 0.17258271965929495\n",
      "Error on this batch = 0.213192468449185\n",
      "Cost on val dataset after 11 epochs is = 0.18176597194028862\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.18176597194028862\n",
      "Error on this batch = 0.15910149541599827\n",
      "Error on this batch = 0.20055750647820808\n",
      "Cost on val dataset after 12 epochs is = 0.17184833404626637\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.17184833404626637\n",
      "Error on this batch = 0.1483424328570384\n",
      "Error on this batch = 0.1900843445890414\n",
      "Cost on val dataset after 13 epochs is = 0.16393028166080417\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.16393028166080417\n",
      "Error on this batch = 0.13935711670696424\n",
      "Error on this batch = 0.18111236339910328\n",
      "Cost on val dataset after 14 epochs is = 0.15743112921236227\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.15743112921236227\n",
      "Error on this batch = 0.1316864387526349\n",
      "Error on this batch = 0.17326982662058618\n",
      "Cost on val dataset after 15 epochs is = 0.1519677831891075\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.1519677831891075\n",
      "Error on this batch = 0.12506927733608422\n",
      "Error on this batch = 0.16631761146325916\n",
      "Cost on val dataset after 16 epochs is = 0.14728045008569543\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.14728045008569543\n",
      "Error on this batch = 0.11932821559831741\n",
      "Error on this batch = 0.1600829249599746\n",
      "Cost on val dataset after 17 epochs is = 0.14319012042222376\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.14319012042222376\n",
      "Error on this batch = 0.11432327313153107\n",
      "Error on this batch = 0.15443775583275363\n",
      "Cost on val dataset after 18 epochs is = 0.1395709675380303\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.1395709675380303\n",
      "Error on this batch = 0.10993389971385184\n",
      "Error on this batch = 0.14928799533977313\n",
      "Cost on val dataset after 19 epochs is = 0.1363322278382418\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.1363322278382418\n",
      "Error on this batch = 0.10605367871185033\n",
      "Error on this batch = 0.14456352624478291\n",
      "Cost on val dataset after 20 epochs is = 0.13340652560745314\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.13340652560745314\n",
      "Error on this batch = 0.10258977678280105\n",
      "Error on this batch = 0.1402101876411909\n",
      "Cost on val dataset after 21 epochs is = 0.1307424295822074\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.1307424295822074\n",
      "Error on this batch = 0.09946336670241135\n",
      "Error on this batch = 0.13618445607105187\n",
      "Cost on val dataset after 22 epochs is = 0.12829970339614225\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.12829970339614225\n",
      "Error on this batch = 0.09660949288312697\n",
      "Error on this batch = 0.13245027111408758\n",
      "Cost on val dataset after 23 epochs is = 0.12604623201006718\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.12604623201006718\n",
      "Error on this batch = 0.09397603091039962\n",
      "Error on this batch = 0.12897713618828632\n",
      "Cost on val dataset after 24 epochs is = 0.12395597325720423\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.12395597325720423\n",
      "Error on this batch = 0.09152196764374271\n",
      "Error on this batch = 0.12573890159391382\n",
      "Cost on val dataset after 25 epochs is = 0.12200753976897437\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.12200753976897437\n",
      "Error on this batch = 0.08921539013894361\n",
      "Error on this batch = 0.12271292124862335\n",
      "Cost on val dataset after 26 epochs is = 0.12018318310160193\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.12018318310160193\n",
      "Error on this batch = 0.08703151150718277\n",
      "Error on this batch = 0.11987942763817047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 27 epochs is = 0.11846804694403232\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.11846804694403232\n",
      "Error on this batch = 0.08495093888467196\n",
      "Error on this batch = 0.11722104096286116\n",
      "Cost on val dataset after 28 epochs is = 0.11684960617837445\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.11684960617837445\n",
      "Error on this batch = 0.08295828151531222\n",
      "Error on this batch = 0.11472236978513987\n",
      "Cost on val dataset after 29 epochs is = 0.11531723662712846\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.11531723662712846\n",
      "Error on this batch = 0.08104112238627416\n",
      "Error on this batch = 0.11236968526423624\n",
      "Cost on val dataset after 30 epochs is = 0.11386187833313617\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.11386187833313617\n",
      "Error on this batch = 0.07918932662240954\n",
      "Error on this batch = 0.11015066065481458\n",
      "Cost on val dataset after 31 epochs is = 0.11247576677539255\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.11247576677539255\n",
      "Error on this batch = 0.07739462527038253\n",
      "Error on this batch = 0.10805416909237485\n",
      "Cost on val dataset after 32 epochs is = 0.11115221371078822\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.11115221371078822\n",
      "Error on this batch = 0.07565039306158328\n",
      "Error on this batch = 0.10607013387797148\n",
      "Cost on val dataset after 33 epochs is = 0.10988542527241675\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.10988542527241675\n",
      "Error on this batch = 0.07395153522713376\n",
      "Error on this batch = 0.10418942867234644\n",
      "Cost on val dataset after 34 epochs is = 0.10867035119230631\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.10867035119230631\n",
      "Error on this batch = 0.07229441024869881\n",
      "Error on this batch = 0.10240382731400903\n",
      "Cost on val dataset after 35 epochs is = 0.1075025644325328\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.1075025644325328\n",
      "Error on this batch = 0.07067673743187283\n",
      "Error on this batch = 0.10070599873904026\n",
      "Cost on val dataset after 36 epochs is = 0.10637817245561185\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.10637817245561185\n",
      "Error on this batch = 0.06909746399617134\n",
      "Error on this batch = 0.09908952649264458\n",
      "Cost on val dataset after 37 epochs is = 0.10529375837744669\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.10529375837744669\n",
      "Error on this batch = 0.06755658934678443\n",
      "Error on this batch = 0.09754891056030114\n",
      "Cost on val dataset after 38 epochs is = 0.10424634439766685\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.10424634439766685\n",
      "Error on this batch = 0.06605495759133334\n",
      "Error on this batch = 0.09607950495978239\n",
      "Cost on val dataset after 39 epochs is = 0.10323336663712207\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.10323336663712207\n",
      "Error on this batch = 0.06459403018520836\n",
      "Error on this batch = 0.0946773750473783\n",
      "Cost on val dataset after 40 epochs is = 0.10225265411209988\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.10225265411209988\n",
      "Error on this batch = 0.06317564480015868\n",
      "Error on this batch = 0.09333910413407892\n",
      "Cost on val dataset after 41 epochs is = 0.10130241285696868\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.10130241285696868\n",
      "Error on this batch = 0.061801765774191095\n",
      "Error on this batch = 0.09206160019661518\n",
      "Cost on val dataset after 42 epochs is = 0.100381221937385\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.100381221937385\n",
      "Error on this batch = 0.06047424061815216\n",
      "Error on this batch = 0.09084193852056269\n",
      "Cost on val dataset after 43 epochs is = 0.0994880458244496\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.0994880458244496\n",
      "Error on this batch = 0.05919458785267669\n",
      "Error on this batch = 0.08967724819806489\n",
      "Cost on val dataset after 44 epochs is = 0.0986222569229281\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.0986222569229281\n",
      "Error on this batch = 0.05796384241845466\n",
      "Error on this batch = 0.08856463448438831\n",
      "Cost on val dataset after 45 epochs is = 0.09778364657653708\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.09778364657653708\n",
      "Error on this batch = 0.056782473759967755\n",
      "Error on this batch = 0.08750113067092158\n",
      "Cost on val dataset after 46 epochs is = 0.0969723907630876\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.0969723907630876\n",
      "Error on this batch = 0.05565037567129849\n",
      "Error on this batch = 0.08648368295944366\n",
      "Cost on val dataset after 47 epochs is = 0.09618894067127581\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.09618894067127581\n",
      "Error on this batch = 0.054566913475948456\n",
      "Error on this batch = 0.08550917782789735\n",
      "Cost on val dataset after 48 epochs is = 0.09543383675509029\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.09543383675509029\n",
      "Error on this batch = 0.053531004745132775\n",
      "Error on this batch = 0.08457451608432895\n",
      "Cost on val dataset after 49 epochs is = 0.0947074867782936\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.0947074867782936\n",
      "Error on this batch = 0.05254120518383412\n",
      "Error on this batch = 0.08367671967255401\n",
      "Cost on val dataset after 50 epochs is = 0.09400997514033037\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.09400997514033037\n",
      "Error on this batch = 0.051595777827279844\n",
      "Error on this batch = 0.08281303478680062\n",
      "Cost on val dataset after 51 epochs is = 0.09334096204643422\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.09334096204643422\n",
      "Error on this batch = 0.05069274496717523\n",
      "Error on this batch = 0.08198098944730195\n",
      "Cost on val dataset after 52 epochs is = 0.0926996927752054\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.0926996927752054\n",
      "Error on this batch = 0.04982994238085652\n",
      "Error on this batch = 0.08117838967892023\n",
      "Cost on val dataset after 53 epochs is = 0.09208509252280533\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.09208509252280533\n",
      "Error on this batch = 0.049005091332101125\n",
      "Error on this batch = 0.0804032754404786\n",
      "Cost on val dataset after 54 epochs is = 0.09149589626422211\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.09149589626422211\n",
      "Error on this batch = 0.04821588110919663\n",
      "Error on this batch = 0.0796538707807453\n",
      "Cost on val dataset after 55 epochs is = 0.09093076746423545\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.09093076746423545\n",
      "Error on this batch = 0.04746004206394491\n",
      "Error on this batch = 0.07892854822180516\n",
      "Cost on val dataset after 56 epochs is = 0.09038838265970789\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.09038838265970789\n",
      "Error on this batch = 0.046735396116781215\n",
      "Error on this batch = 0.07822580802020705\n",
      "Cost on val dataset after 57 epochs is = 0.08986748047203458\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.08986748047203458\n",
      "Error on this batch = 0.04603988456272209\n",
      "Error on this batch = 0.07754426469291031\n",
      "Cost on val dataset after 58 epochs is = 0.08936688392550579\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.08936688392550579\n",
      "Error on this batch = 0.045371579706468504\n",
      "Error on this batch = 0.07688263489393664\n",
      "Cost on val dataset after 59 epochs is = 0.08888550625789822\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.08888550625789822\n",
      "Error on this batch = 0.04472868704037495\n",
      "Error on this batch = 0.07623972527951794\n",
      "Cost on val dataset after 60 epochs is = 0.08842234791948364\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.08842234791948364\n",
      "Error on this batch = 0.04410954248168235\n",
      "Error on this batch = 0.07561442193021581\n",
      "Cost on val dataset after 61 epochs is = 0.08797648948416298\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.08797648948416298\n",
      "Error on this batch = 0.04351260724001275\n",
      "Error on this batch = 0.07500568335477778\n",
      "Cost on val dataset after 62 epochs is = 0.08754708296640405\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.08754708296640405\n",
      "Error on this batch = 0.04293646177783709\n",
      "Error on this batch = 0.07441253801196963\n",
      "Cost on val dataset after 63 epochs is = 0.08713334271732334\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.08713334271732334\n",
      "Error on this batch = 0.042379799772902266\n",
      "Error on this batch = 0.07383408583470687\n",
      "Cost on val dataset after 64 epochs is = 0.08673453647463925\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.08673453647463925\n",
      "Error on this batch = 0.04184142263237881\n",
      "Error on this batch = 0.07326950217815066\n",
      "Cost on val dataset after 65 epochs is = 0.08634997699707868\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.08634997699707868\n",
      "Error on this batch = 0.041320234748899155\n",
      "Error on this batch = 0.07271804216089317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 66 epochs is = 0.0859790147537139\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.0859790147537139\n",
      "Error on this batch = 0.040815239301728375\n",
      "Error on this batch = 0.07217904340004422\n",
      "Cost on val dataset after 67 epochs is = 0.08562103212363212\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.08562103212363212\n",
      "Error on this batch = 0.040325534069989254\n",
      "Error on this batch = 0.0716519254549122\n",
      "Cost on val dataset after 68 epochs is = 0.08527543933473306\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.08527543933473306\n",
      "Error on this batch = 0.03985030653797871\n",
      "Error on this batch = 0.07113618480995697\n",
      "Cost on val dataset after 69 epochs is = 0.08494167191576348\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.08494167191576348\n",
      "Error on this batch = 0.039388827585606107\n",
      "Error on this batch = 0.07063138499705343\n",
      "Cost on val dataset after 70 epochs is = 0.08461918890268791\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.08461918890268791\n",
      "Error on this batch = 0.038940443268073624\n",
      "Error on this batch = 0.07013714248087732\n",
      "Cost on val dataset after 71 epochs is = 0.0843074707016805\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.0843074707016805\n",
      "Error on this batch = 0.03850456459006732\n",
      "Error on this batch = 0.06965310996704309\n",
      "Cost on val dataset after 72 epochs is = 0.08400601563096402\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.08400601563096402\n",
      "Error on this batch = 0.03808065575205912\n",
      "Error on this batch = 0.06917895940877582\n",
      "Cost on val dataset after 73 epochs is = 0.08371433483072932\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.08371433483072932\n",
      "Error on this batch = 0.03766822196988928\n",
      "Error on this batch = 0.06871436690272019\n",
      "Cost on val dataset after 74 epochs is = 0.0834319462765642\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.0834319462765642\n",
      "Error on this batch = 0.03726679838626474\n",
      "Error on this batch = 0.06825900102943315\n",
      "Cost on val dataset after 75 epochs is = 0.08315836971532015\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.08315836971532015\n",
      "Error on this batch = 0.036875941555172126\n",
      "Error on this batch = 0.06781251544533266\n",
      "Cost on val dataset after 76 epochs is = 0.08289312508072169\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.08289312508072169\n",
      "Error on this batch = 0.03649522444502681\n",
      "Error on this batch = 0.06737454593274157\n",
      "Cost on val dataset after 77 epochs is = 0.08263573694380709\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.08263573694380709\n",
      "Error on this batch = 0.036124235052399194\n",
      "Error on this batch = 0.0669447115332854\n",
      "Cost on val dataset after 78 epochs is = 0.08238574640518492\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.08238574640518492\n",
      "Error on this batch = 0.03576257779581697\n",
      "Error on this batch = 0.06652261861832993\n",
      "Cost on val dataset after 79 epochs is = 0.082142729382131\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.082142729382131\n",
      "Error on this batch = 0.03540987611568333\n",
      "Error on this batch = 0.06610786597396627\n",
      "Cost on val dataset after 80 epochs is = 0.08190631708687085\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.08190631708687085\n",
      "Error on this batch = 0.035065774441569185\n",
      "Error on this batch = 0.06570004878386584\n",
      "Cost on val dataset after 81 epochs is = 0.08167621221240398\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.08167621221240398\n",
      "Error on this batch = 0.03472993819184767\n",
      "Error on this batch = 0.0652987601807491\n",
      "Cost on val dataset after 82 epochs is = 0.08145219471404734\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.08145219471404734\n",
      "Error on this batch = 0.034402051694564076\n",
      "Error on this batch = 0.06490359046447942\n",
      "Cost on val dataset after 83 epochs is = 0.08123411453772313\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.08123411453772313\n",
      "Error on this batch = 0.03408181523319853\n",
      "Error on this batch = 0.0645141252528188\n",
      "Cost on val dataset after 84 epochs is = 0.08102187349748381\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.08102187349748381\n",
      "Error on this batch = 0.03376894296707309\n",
      "Error on this batch = 0.06412994406413992\n",
      "Cost on val dataset after 85 epochs is = 0.08081540200385409\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.08081540200385409\n",
      "Error on this batch = 0.03346316293055522\n",
      "Error on this batch = 0.06375062019714586\n",
      "Cost on val dataset after 86 epochs is = 0.08061463684465385\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.08061463684465385\n",
      "Error on this batch = 0.03316421919930971\n",
      "Error on this batch = 0.06337572186177988\n",
      "Cost on val dataset after 87 epochs is = 0.0804195041963217\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.0804195041963217\n",
      "Error on this batch = 0.03287187544401838\n",
      "Error on this batch = 0.06300481387635715\n",
      "Cost on val dataset after 88 epochs is = 0.08022990922923685\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.08022990922923685\n",
      "Error on this batch = 0.0325859188590653\n",
      "Error on this batch = 0.06263745906577471\n",
      "Cost on val dataset after 89 epochs is = 0.08004573154685322\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.08004573154685322\n",
      "Error on this batch = 0.03230616367393953\n",
      "Error on this batch = 0.06227321866370687\n",
      "Cost on val dataset after 90 epochs is = 0.07986682476619367\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.07986682476619367\n",
      "Error on this batch = 0.032032453762052625\n",
      "Error on this batch = 0.061911651337409175\n",
      "Cost on val dataset after 91 epochs is = 0.07969301854674694\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.07969301854674694\n",
      "Error on this batch = 0.03176466405706844\n",
      "Error on this batch = 0.061552310764526316\n",
      "Cost on val dataset after 92 epochs is = 0.07952412181643088\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.07952412181643088\n",
      "Error on this batch = 0.03150270058848624\n",
      "Error on this batch = 0.06119474191880811\n",
      "Cost on val dataset after 93 epochs is = 0.07935992644954296\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.07935992644954296\n",
      "Error on this batch = 0.03124649905074101\n",
      "Error on this batch = 0.060838476333885984\n",
      "Cost on val dataset after 94 epochs is = 0.07920021103994407\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.07920021103994407\n",
      "Error on this batch = 0.03099602196814994\n",
      "Error on this batch = 0.060483026599378834\n",
      "Cost on val dataset after 95 epochs is = 0.07904474464607543\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.07904474464607543\n",
      "Error on this batch = 0.030751254676794706\n",
      "Error on this batch = 0.06012788020561921\n",
      "Cost on val dataset after 96 epochs is = 0.07889329049812173\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.07889329049812173\n",
      "Error on this batch = 0.030512200446994955\n",
      "Error on this batch = 0.059772492622486136\n",
      "Cost on val dataset after 97 epochs is = 0.0787456097028684\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.0787456097028684\n",
      "Error on this batch = 0.030278875082803802\n",
      "Error on this batch = 0.05941627923915031\n",
      "Cost on val dataset after 98 epochs is = 0.07860146499182304\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.07860146499182304\n",
      "Error on this batch = 0.03005130128777887\n",
      "Error on this batch = 0.05905860559884303\n",
      "Cost on val dataset after 99 epochs is = 0.07846062453742063\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.07846062453742063\n",
      "Error on this batch = 0.029829503046884143\n",
      "Error on this batch = 0.05869877533426378\n",
      "Cost on val dataset after 100 epochs is = 0.07832286579661328\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.07832286579661328\n",
      "Error on this batch = 0.029613500289797513\n",
      "Error on this batch = 0.058336015407792347\n",
      "Cost on val dataset after 101 epochs is = 0.07818797922298076\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.07818797922298076\n",
      "Error on this batch = 0.029403304156099066\n",
      "Error on this batch = 0.057969458675107104\n",
      "Cost on val dataset after 102 epochs is = 0.07805577154092139\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.07805577154092139\n",
      "Error on this batch = 0.02919891321497564\n",
      "Error on this batch = 0.05759812432763506\n",
      "Cost on val dataset after 103 epochs is = 0.07792606816060274\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.07792606816060274\n",
      "Error on this batch = 0.02900031095287926\n",
      "Error on this batch = 0.057220897296371157\n",
      "Cost on val dataset after 104 epochs is = 0.0777987143079602\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.0777987143079602\n",
      "Error on this batch = 0.028807464757772423\n",
      "Error on this batch = 0.05683650813125829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 105 epochs is = 0.07767357459340919\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.07767357459340919\n",
      "Error on this batch = 0.028620326601302856\n",
      "Error on this batch = 0.05644351525752783\n",
      "Cost on val dataset after 106 epochs is = 0.07755053100765581\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.07755053100765581\n",
      "Error on this batch = 0.028438835762982225\n",
      "Error on this batch = 0.05604029210447626\n",
      "Cost on val dataset after 107 epochs is = 0.07742947959263298\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.07742947959263298\n",
      "Error on this batch = 0.028262924269974034\n",
      "Error on this batch = 0.05562502285598647\n",
      "Cost on val dataset after 108 epochs is = 0.07731032615788218\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.07731032615788218\n",
      "Error on this batch = 0.028092526084908254\n",
      "Error on this batch = 0.05519571300966435\n",
      "Cost on val dataset after 109 epochs is = 0.0771929813620983\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.0771929813620983\n",
      "Error on this batch = 0.027927591134718713\n",
      "Error on this batch = 0.05475022482517068\n",
      "Cost on val dataset after 110 epochs is = 0.07707735538193991\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.07707735538193991\n",
      "Error on this batch = 0.02776810462428886\n",
      "Error on this batch = 0.05428635265000747\n",
      "Cost on val dataset after 111 epochs is = 0.07696335248922719\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.07696335248922719\n",
      "Error on this batch = 0.027614110312321465\n",
      "Error on this batch = 0.05380195741339097\n",
      "Cost on val dataset after 112 epochs is = 0.07685086638645992\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.07685086638645992\n",
      "Error on this batch = 0.027465733168283695\n",
      "Error on this batch = 0.05329518009434688\n",
      "Cost on val dataset after 113 epochs is = 0.07673977818959117\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.07673977818959117\n",
      "Error on this batch = 0.02732319186089508\n",
      "Error on this batch = 0.052764745790169716\n",
      "Cost on val dataset after 114 epochs is = 0.0766299602544172\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.0766299602544172\n",
      "Error on this batch = 0.027186785465006903\n",
      "Error on this batch = 0.05221034738145106\n",
      "Cost on val dataset after 115 epochs is = 0.07652128976881985\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.07652128976881985\n",
      "Error on this batch = 0.027056834633271434\n",
      "Error on this batch = 0.05163305783129884\n",
      "Cost on val dataset after 116 epochs is = 0.0764136744956908\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.0764136744956908\n",
      "Error on this batch = 0.02693356223793386\n",
      "Error on this batch = 0.051035670502050164\n",
      "Cost on val dataset after 117 epochs is = 0.0763070874723964\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.0763070874723964\n",
      "Error on this batch = 0.026816921003423033\n",
      "Error on this batch = 0.05042283300104512\n",
      "Cost on val dataset after 118 epochs is = 0.07620159868990532\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.07620159868990532\n",
      "Error on this batch = 0.02670641625813157\n",
      "Error on this batch = 0.049800859402293146\n",
      "Cost on val dataset after 119 epochs is = 0.07609738612937743\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.07609738612937743\n",
      "Error on this batch = 0.026601008018683064\n",
      "Error on this batch = 0.04917719716275278\n",
      "Cost on val dataset after 120 epochs is = 0.0759947145955313\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.0759947145955313\n",
      "Error on this batch = 0.02649916760141654\n",
      "Error on this batch = 0.048559652994828735\n",
      "Cost on val dataset after 121 epochs is = 0.07589388809774004\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.07589388809774004\n",
      "Error on this batch = 0.026399093609736583\n",
      "Error on this batch = 0.04795556740441725\n",
      "Cost on val dataset after 122 epochs is = 0.07579519605678971\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.07579519605678971\n",
      "Error on this batch = 0.026299006126417376\n",
      "Error on this batch = 0.04737112074487273\n",
      "Cost on val dataset after 123 epochs is = 0.07569887284445255\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.07569887284445255\n",
      "Error on this batch = 0.026197406611201176\n",
      "Error on this batch = 0.046810882480419876\n",
      "Cost on val dataset after 124 epochs is = 0.07560507843324729\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.07560507843324729\n",
      "Error on this batch = 0.026093231075038404\n",
      "Error on this batch = 0.046277639740334005\n",
      "Cost on val dataset after 125 epochs is = 0.07551389793856028\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.07551389793856028\n",
      "Error on this batch = 0.0259858894174039\n",
      "Error on this batch = 0.045772485244693385\n",
      "Cost on val dataset after 126 epochs is = 0.07542535419223396\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.07542535419223396\n",
      "Error on this batch = 0.02587522587556137\n",
      "Error on this batch = 0.045295101709657754\n",
      "Cost on val dataset after 127 epochs is = 0.07533942684590592\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.07533942684590592\n",
      "Error on this batch = 0.025761441631452487\n",
      "Error on this batch = 0.044844151324773984\n",
      "Cost on val dataset after 128 epochs is = 0.07525607153347456\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.07525607153347456\n",
      "Error on this batch = 0.0256450052148832\n",
      "Error on this batch = 0.04441767587319479\n",
      "Cost on val dataset after 129 epochs is = 0.07517523408325354\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.07517523408325354\n",
      "Error on this batch = 0.025526560424833877\n",
      "Error on this batch = 0.04401343644352771\n",
      "Cost on val dataset after 130 epochs is = 0.07509685800601955\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.07509685800601955\n",
      "Error on this batch = 0.025406836590056717\n",
      "Error on this batch = 0.04362915842386793\n",
      "Cost on val dataset after 131 epochs is = 0.0750208868022091\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.0750208868022091\n",
      "Error on this batch = 0.02528656860193859\n",
      "Error on this batch = 0.04326268100593735\n",
      "Cost on val dataset after 132 epochs is = 0.07494726407648539\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.07494726407648539\n",
      "Error on this batch = 0.025166434975544227\n",
      "Error on this batch = 0.04291203055968959\n",
      "Cost on val dataset after 133 epochs is = 0.07487593380433605\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.07487593380433605\n",
      "Error on this batch = 0.025047018046337303\n",
      "Error on this batch = 0.042575443143658374\n",
      "Cost on val dataset after 134 epochs is = 0.07480684161622508\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.07480684161622508\n",
      "Error on this batch = 0.024928784847426142\n",
      "Error on this batch = 0.04225135824785046\n",
      "Cost on val dataset after 135 epochs is = 0.07473993683845004\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.07473993683845004\n",
      "Error on this batch = 0.024812083957760682\n",
      "Error on this batch = 0.041938399458667334\n",
      "Cost on val dataset after 136 epochs is = 0.07467517461517156\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.07467517461517156\n",
      "Error on this batch = 0.02469715317520441\n",
      "Error on this batch = 0.04163535164661167\n",
      "Cost on val dataset after 137 epochs is = 0.07461251752780368\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.07461251752780368\n",
      "Error on this batch = 0.024584133827231375\n",
      "Error on this batch = 0.041341139727178185\n",
      "Cost on val dataset after 138 epochs is = 0.07455193641824151\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.07455193641824151\n",
      "Error on this batch = 0.02447308856992996\n",
      "Error on this batch = 0.041054811020148366\n",
      "Cost on val dataset after 139 epochs is = 0.07449341040574856\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.07449341040574856\n",
      "Error on this batch = 0.024364020175391597\n",
      "Error on this batch = 0.04077552138433927\n",
      "Cost on val dataset after 140 epochs is = 0.07443692626900722\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.07443692626900722\n",
      "Error on this batch = 0.024256889210733226\n",
      "Error on this batch = 0.04050252432386706\n",
      "Cost on val dataset after 141 epochs is = 0.07438247742276596\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.07438247742276596\n",
      "Error on this batch = 0.02415162895547507\n",
      "Error on this batch = 0.04023516192020669\n",
      "Cost on val dataset after 142 epochs is = 0.07433006267528243\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.07433006267528243\n",
      "Error on this batch = 0.024048156519173504\n",
      "Error on this batch = 0.039972856543247434\n",
      "Cost on val dataset after 143 epochs is = 0.07427968485462992\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.07427968485462992\n",
      "Error on this batch = 0.02394637983274142\n",
      "Error on this batch = 0.03971510263825412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 144 epochs is = 0.07423134928818517\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.07423134928818517\n",
      "Error on this batch = 0.02384620082527901\n",
      "Error on this batch = 0.03946145829769626\n",
      "Cost on val dataset after 145 epochs is = 0.07418506204715195\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.07418506204715195\n",
      "Error on this batch = 0.023747515538008912\n",
      "Error on this batch = 0.0392115366796148\n",
      "Cost on val dataset after 146 epochs is = 0.07414082784693829\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.07414082784693829\n",
      "Error on this batch = 0.023650212152176185\n",
      "Error on this batch = 0.03896499756087959\n",
      "Cost on val dataset after 147 epochs is = 0.07409864753223493\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.07409864753223493\n",
      "Error on this batch = 0.023554167990839793\n",
      "Error on this batch = 0.03872153939782667\n",
      "Cost on val dataset after 148 epochs is = 0.07405851517249509\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.07405851517249509\n",
      "Error on this batch = 0.02345924658943696\n",
      "Error on this batch = 0.03848089221991023\n",
      "Cost on val dataset after 149 epochs is = 0.07402041493909446\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.07402041493909446\n",
      "Error on this batch = 0.02336529596734555\n",
      "Error on this batch = 0.03824281152564732\n",
      "Cost on val dataset after 150 epochs is = 0.07398431810018763\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.07398431810018763\n",
      "Error on this batch = 0.02327214923927001\n",
      "Error on this batch = 0.03800707311161434\n",
      "Cost on val dataset after 151 epochs is = 0.07395018059402794\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.07395018059402794\n",
      "Error on this batch = 0.02317962856005786\n",
      "Error on this batch = 0.0377734684909745\n",
      "Cost on val dataset after 152 epochs is = 0.07391794164254331\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.07391794164254331\n",
      "Error on this batch = 0.023087552935320704\n",
      "Error on this batch = 0.037541800336663995\n",
      "Cost on val dataset after 153 epochs is = 0.07388752367432223\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.07388752367432223\n",
      "Error on this batch = 0.022995749552003765\n",
      "Error on this batch = 0.03731187735601205\n",
      "Cost on val dataset after 154 epochs is = 0.07385883345698803\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.07385883345698803\n",
      "Error on this batch = 0.022904067094090513\n",
      "Error on this batch = 0.03708350831695616\n",
      "Cost on val dataset after 155 epochs is = 0.07383176396224216\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.07383176396224216\n",
      "Error on this batch = 0.02281238840656607\n",
      "Error on this batch = 0.03685649564785519\n",
      "Cost on val dataset after 156 epochs is = 0.07380619639144785\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.07380619639144785\n",
      "Error on this batch = 0.022720639431758286\n",
      "Error on this batch = 0.03663062994793451\n",
      "Cost on val dataset after 157 epochs is = 0.07378200219342217\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.07378200219342217\n",
      "Error on this batch = 0.02262879198318967\n",
      "Error on this batch = 0.036405687474690945\n",
      "Cost on val dataset after 158 epochs is = 0.07375904568822357\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.07375904568822357\n",
      "Error on this batch = 0.022536859551637374\n",
      "Error on this batch = 0.03618143278164071\n",
      "Cost on val dataset after 159 epochs is = 0.07373718851022597\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.07373718851022597\n",
      "Error on this batch = 0.022444887322304728\n",
      "Error on this batch = 0.03595762795149579\n",
      "Cost on val dataset after 160 epochs is = 0.07371629678922036\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.07371629678922036\n",
      "Error on this batch = 0.022352939104678126\n",
      "Error on this batch = 0.035734048449848795\n",
      "Cost on val dataset after 161 epochs is = 0.07369625055194978\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.07369625055194978\n",
      "Error on this batch = 0.02226108438863731\n",
      "Error on this batch = 0.03551050395653997\n",
      "Cost on val dataset after 162 epochs is = 0.07367695294435182\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.07367695294435182\n",
      "Error on this batch = 0.02216938815626562\n",
      "Error on this batch = 0.035286861203130834\n",
      "Cost on val dataset after 163 epochs is = 0.07365833593787645\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.07365833593787645\n",
      "Error on this batch = 0.022077904710370938\n",
      "Error on this batch = 0.035063065362754664\n",
      "Cost on val dataset after 164 epochs is = 0.07364036019085915\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.07364036019085915\n",
      "Error on this batch = 0.02198667520021485\n",
      "Error on this batch = 0.034839157030027434\n",
      "Cost on val dataset after 165 epochs is = 0.07362300922924113\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.07362300922924113\n",
      "Error on this batch = 0.021895727398597513\n",
      "Error on this batch = 0.03461528286410606\n",
      "Cost on val dataset after 166 epochs is = 0.0736062803517869\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.0736062803517869\n",
      "Error on this batch = 0.02180507608037263\n",
      "Error on this batch = 0.03439169884067154\n",
      "Cost on val dataset after 167 epochs is = 0.07359017513527566\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.07359017513527566\n",
      "Error on this batch = 0.02171472302521548\n",
      "Error on this batch = 0.03416876542293168\n",
      "Cost on val dataset after 168 epochs is = 0.07357469115043846\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.07357469115043846\n",
      "Error on this batch = 0.02162465664909284\n",
      "Error on this batch = 0.0339469341736186\n",
      "Cost on val dataset after 169 epochs is = 0.07355981488253001\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.07355981488253001\n",
      "Error on this batch = 0.0215348518841166\n",
      "Error on this batch = 0.03372672603316932\n",
      "Cost on val dataset after 170 epochs is = 0.07354551521689635\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.07354551521689635\n",
      "Error on this batch = 0.02144527088456538\n",
      "Error on this batch = 0.033508702849448964\n",
      "Cost on val dataset after 171 epochs is = 0.07353173741641206\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.07353173741641206\n",
      "Error on this batch = 0.021355864656354133\n",
      "Error on this batch = 0.033293435170137047\n",
      "Cost on val dataset after 172 epochs is = 0.07351839851882436\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.07351839851882436\n",
      "Error on this batch = 0.021266575225146408\n",
      "Error on this batch = 0.03308146996229765\n",
      "Cost on val dataset after 173 epochs is = 0.0735053856237886\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.0735053856237886\n",
      "Error on this batch = 0.021177337761400895\n",
      "Error on this batch = 0.03287330147899735\n",
      "Cost on val dataset after 174 epochs is = 0.07349255820892955\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.07349255820892955\n",
      "Error on this batch = 0.021088082173244153\n",
      "Error on this batch = 0.03266934741849203\n",
      "Cost on val dataset after 175 epochs is = 0.07347975455298453\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.07347975455298453\n",
      "Error on this batch = 0.02099873390187013\n",
      "Error on this batch = 0.032469931700928455\n",
      "Cost on val dataset after 176 epochs is = 0.07346680110111226\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.07346680110111226\n",
      "Error on this batch = 0.02090921386806177\n",
      "Error on this batch = 0.03227527522674634\n",
      "Cost on val dataset after 177 epochs is = 0.07345352292553747\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.07345352292553747\n",
      "Error on this batch = 0.020819437675678617\n",
      "Error on this batch = 0.0320854966382955\n",
      "Cost on val dataset after 178 epochs is = 0.07343975380208745\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.07343975380208745\n",
      "Error on this batch = 0.020729314280076624\n",
      "Error on this batch = 0.03190062518619539\n",
      "Cost on val dataset after 179 epochs is = 0.07342534552674715\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.07342534552674715\n",
      "Error on this batch = 0.020638744347281485\n",
      "Error on this batch = 0.03172062582477143\n",
      "Cost on val dataset after 180 epochs is = 0.07341017684665403\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.07341017684665403\n",
      "Error on this batch = 0.02054761840948952\n",
      "Error on this batch = 0.03154543232355081\n",
      "Cost on val dataset after 181 epochs is = 0.07339416187754254\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.07339416187754254\n",
      "Error on this batch = 0.020455814700060984\n",
      "Error on this batch = 0.031374979626856196\n",
      "Cost on val dataset after 182 epochs is = 0.07337725650529928\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.07337725650529928\n",
      "Error on this batch = 0.02036319641884142\n",
      "Error on this batch = 0.03120922565512057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 183 epochs is = 0.07335946051701078\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.07335946051701078\n",
      "Error on this batch = 0.02026960832304475\n",
      "Error on this batch = 0.031048157113022137\n",
      "Cost on val dataset after 184 epochs is = 0.07334081414681834\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.07334081414681834\n",
      "Error on this batch = 0.020174872884016128\n",
      "Error on this batch = 0.03089178109957972\n",
      "Cost on val dataset after 185 epochs is = 0.07332138981485205\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.07332138981485205\n",
      "Error on this batch = 0.020078786488028567\n",
      "Error on this batch = 0.03074010945908885\n",
      "Cost on val dataset after 186 epochs is = 0.07330128154236783\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.07330128154236783\n",
      "Error on this batch = 0.019981116096181882\n",
      "Error on this batch = 0.030593143222540548\n",
      "Cost on val dataset after 187 epochs is = 0.07328059484277691\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.07328059484277691\n",
      "Error on this batch = 0.019881596533763604\n",
      "Error on this batch = 0.030450861520083743\n",
      "Cost on val dataset after 188 epochs is = 0.0732594390074997\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.0732594390074997\n",
      "Error on this batch = 0.01977992840224018\n",
      "Error on this batch = 0.030313215949097614\n",
      "Cost on val dataset after 189 epochs is = 0.0732379224326679\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.0732379224326679\n",
      "Error on this batch = 0.01967577661962732\n",
      "Error on this batch = 0.030180129387615804\n",
      "Cost on val dataset after 190 epochs is = 0.07321615060747001\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.07321615060747001\n",
      "Error on this batch = 0.0195687697578777\n",
      "Error on this batch = 0.030051497804422126\n",
      "Cost on val dataset after 191 epochs is = 0.07319422581688764\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.07319422581688764\n",
      "Error on this batch = 0.019458500576531083\n",
      "Error on this batch = 0.02992719407660987\n",
      "Cost on val dataset after 192 epochs is = 0.07317224743084386\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.07317224743084386\n",
      "Error on this batch = 0.019344528411287715\n",
      "Error on this batch = 0.029807073506702725\n",
      "Cost on val dataset after 193 epochs is = 0.0731503117314676\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.0731503117314676\n",
      "Error on this batch = 0.019226384365670188\n",
      "Error on this batch = 0.02969098120505146\n",
      "Cost on val dataset after 194 epochs is = 0.07312851050368574\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.07312851050368574\n",
      "Error on this batch = 0.019103580564240167\n",
      "Error on this batch = 0.02957876155706791\n",
      "Cost on val dataset after 195 epochs is = 0.07310692807225726\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.07310692807225726\n",
      "Error on this batch = 0.01897562498943504\n",
      "Error on this batch = 0.029470269605678938\n",
      "Cost on val dataset after 196 epochs is = 0.07308563707639885\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.07308563707639885\n",
      "Error on this batch = 0.018842043499030604\n",
      "Error on this batch = 0.029365383566815666\n",
      "Cost on val dataset after 197 epochs is = 0.073064693884245\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.073064693884245\n",
      "Error on this batch = 0.0187024103198083\n",
      "Error on this batch = 0.02926401731683538\n",
      "Cost on val dataset after 198 epochs is = 0.07304413491125139\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.07304413491125139\n",
      "Error on this batch = 0.018556387475223004\n",
      "Error on this batch = 0.029166131951080986\n",
      "Cost on val dataset after 199 epochs is = 0.0730239750209652\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.0730239750209652\n",
      "Error on this batch = 0.0184037722066551\n",
      "Error on this batch = 0.02907174616261401\n",
      "Cost on val dataset after 200 epochs is = 0.07300420871783198\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.07300420871783198\n",
      "Error on this batch = 0.01824454977441295\n",
      "Error on this batch = 0.0289809446119714\n",
      "Cost on val dataset after 201 epochs is = 0.07298481435531912\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.07298481435531912\n",
      "Error on this batch = 0.018078948080578593\n",
      "Error on this batch = 0.02889387764691179\n",
      "Cost on val dataset after 202 epochs is = 0.07296576150754226\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.07296576150754226\n",
      "Error on this batch = 0.017907493079078008\n",
      "Error on this batch = 0.028810725680004538\n",
      "Cost on val dataset after 203 epochs is = 0.07294702204307282\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.07294702204307282\n",
      "Error on this batch = 0.017731076278251347\n",
      "Error on this batch = 0.02873155009980755\n",
      "Cost on val dataset after 204 epochs is = 0.07292858515675153\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.07292858515675153\n",
      "Error on this batch = 0.01755107795212426\n",
      "Error on this batch = 0.02865587065776076\n",
      "Cost on val dataset after 205 epochs is = 0.07291047173448835\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.07291047173448835\n",
      "Error on this batch = 0.017369633977063224\n",
      "Error on this batch = 0.028581909659449064\n",
      "Cost on val dataset after 206 epochs is = 0.07289273094663477\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.07289273094663477\n",
      "Error on this batch = 0.017190049134524196\n",
      "Error on this batch = 0.028506432955595833\n",
      "Cost on val dataset after 207 epochs is = 0.07287541360182852\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.07287541360182852\n",
      "Error on this batch = 0.01701676441226874\n",
      "Error on this batch = 0.028427043846260908\n",
      "Cost on val dataset after 208 epochs is = 0.0728585928036438\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.0728585928036438\n",
      "Error on this batch = 0.01685378146048953\n",
      "Error on this batch = 0.028344632081692866\n",
      "Cost on val dataset after 209 epochs is = 0.07284240604388022\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.07284240604388022\n",
      "Error on this batch = 0.01670267081622432\n",
      "Error on this batch = 0.028261655932140136\n",
      "Cost on val dataset after 210 epochs is = 0.07282693944332226\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.07282693944332226\n",
      "Error on this batch = 0.016562831119438255\n",
      "Error on this batch = 0.028179742741547244\n",
      "Cost on val dataset after 211 epochs is = 0.07281213195543774\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.07281213195543774\n",
      "Error on this batch = 0.016432988805334833\n",
      "Error on this batch = 0.028099487356163383\n",
      "Cost on val dataset after 212 epochs is = 0.07279784381933935\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.07279784381933935\n",
      "Error on this batch = 0.01631199941332366\n",
      "Error on this batch = 0.028020995544169546\n",
      "Cost on val dataset after 213 epochs is = 0.07278394684671571\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.07278394684671571\n",
      "Error on this batch = 0.016198962912154634\n",
      "Error on this batch = 0.02794422619361319\n",
      "Cost on val dataset after 214 epochs is = 0.07277035907595246\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.07277035907595246\n",
      "Error on this batch = 0.016093142699005206\n",
      "Error on this batch = 0.027869115838963354\n",
      "Cost on val dataset after 215 epochs is = 0.07275704214817102\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.07275704214817102\n",
      "Error on this batch = 0.015993890860348466\n",
      "Error on this batch = 0.027795608389186786\n",
      "Cost on val dataset after 216 epochs is = 0.07274398779092489\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.07274398779092489\n",
      "Error on this batch = 0.015900609767589443\n",
      "Error on this batch = 0.027723656091876644\n",
      "Cost on val dataset after 217 epochs is = 0.07273120514317195\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.07273120514317195\n",
      "Error on this batch = 0.015812738138309232\n",
      "Error on this batch = 0.02765321530790148\n",
      "Cost on val dataset after 218 epochs is = 0.07271871162160819\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.07271871162160819\n",
      "Error on this batch = 0.015729748704683834\n",
      "Error on this batch = 0.02758424332405574\n",
      "Cost on val dataset after 219 epochs is = 0.0727065269043513\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.0727065269043513\n",
      "Error on this batch = 0.01565114995027341\n",
      "Error on this batch = 0.027516696917431794\n",
      "Cost on val dataset after 220 epochs is = 0.0726946690619193\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.0726946690619193\n",
      "Error on this batch = 0.015576488427610247\n",
      "Error on this batch = 0.027450532096675043\n",
      "Cost on val dataset after 221 epochs is = 0.07268315211214695\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.07268315211214695\n",
      "Error on this batch = 0.01550535039609201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.027385704400297667\n",
      "Cost on val dataset after 222 epochs is = 0.07267198466918615\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.07267198466918615\n",
      "Error on this batch = 0.015437362519601693\n",
      "Error on this batch = 0.027322169329242838\n",
      "Cost on val dataset after 223 epochs is = 0.07266116968234765\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.07266116968234765\n",
      "Error on this batch = 0.015372191696716185\n",
      "Error on this batch = 0.02725988262515823\n",
      "Cost on val dataset after 224 epochs is = 0.07265070539378254\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.07265070539378254\n",
      "Error on this batch = 0.015309544155699935\n",
      "Error on this batch = 0.0271988001224724\n",
      "Cost on val dataset after 225 epochs is = 0.07264058747721804\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.07264058747721804\n",
      "Error on this batch = 0.015249163970258599\n",
      "Error on this batch = 0.027138876895403886\n",
      "Cost on val dataset after 226 epochs is = 0.07263081185893497\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.07263081185893497\n",
      "Error on this batch = 0.015190831221237338\n",
      "Error on this batch = 0.027080065573092164\n",
      "Cost on val dataset after 227 epochs is = 0.0726213772112995\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.0726213772112995\n",
      "Error on this batch = 0.015134360079757988\n",
      "Error on this batch = 0.02702231409482362\n",
      "Cost on val dataset after 228 epochs is = 0.07261228596359172\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.07261228596359172\n",
      "Error on this batch = 0.015079597005661199\n",
      "Error on this batch = 0.026965563621013516\n",
      "Cost on val dataset after 229 epochs is = 0.07260354314399473\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.07260354314399473\n",
      "Error on this batch = 0.015026419029738726\n",
      "Error on this batch = 0.026909747421065645\n",
      "Cost on val dataset after 230 epochs is = 0.0725951532374639\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.0725951532374639\n",
      "Error on this batch = 0.01497473185619051\n",
      "Error on this batch = 0.026854791171975218\n",
      "Cost on val dataset after 231 epochs is = 0.07258711598536513\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.07258711598536513\n",
      "Error on this batch = 0.014924467433097215\n",
      "Error on this batch = 0.026800614503329753\n",
      "Cost on val dataset after 232 epochs is = 0.07257942228939362\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.07257942228939362\n",
      "Error on this batch = 0.014875580695168669\n",
      "Error on this batch = 0.026747133242821394\n",
      "Cost on val dataset after 233 epochs is = 0.07257205116242325\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.07257205116242325\n",
      "Error on this batch = 0.014828045257051722\n",
      "Error on this batch = 0.0266942618259355\n",
      "Cost on val dataset after 234 epochs is = 0.07256496828782624\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.07256496828782624\n",
      "Error on this batch = 0.014781847838047582\n",
      "Error on this batch = 0.02664191559958468\n",
      "Cost on val dataset after 235 epochs is = 0.0725581264296861\n",
      "cost initial= 0.07256496828782624 , cost final=0.0725581264296861 , change in cost= -6.841858140135826e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 100 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 235\n",
      "The training time = 45.782sec\n",
      "The training accuracy is = 97.683%\n",
      "The validation accuracy is = 91.795%\n",
      "The test accuracy is = 90.723%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []\n",
    "\n",
    "lr=1.5\n",
    "\n",
    "for i in range(len(arch_test)):\n",
    "    #Choose between normal or random. Normal gives better results\n",
    "    theta = theta_init([arch_test[i]], 'normal')\n",
    "    #print(theta[0].shape, theta[1].shape, theta[2].shape)\n",
    "    print(\"Training the network with {} hidden layer with {} units\".format(len([arch_test[i]]), arch_test[i]))\n",
    "    print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "    for j in range(len(theta)):\n",
    "        print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "\n",
    "    start = time.time()\n",
    "    epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'sigmoid')\n",
    "    \n",
    "    epochs.append(epoch)\n",
    "    train_time.append(time.time()-start)\n",
    "    train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "    valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "    test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "    print(\"\\n------------------------------------------------------------------------------\")\n",
    "    print(\"The stats for number of units in the hidden layer = {} are as below:\".format(arch_test[i]))\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"The number of epochs = {}\".format(epochs[-1]))\n",
    "    print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "    print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "    print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "    print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "    print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------Plotting Graphs for Part B - Fixed LR - One Hidden Layer ------------------\")\n",
    "plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy)\n",
    "plot_epoch(arch_test, epochs, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Adaptive Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 1 hidden layer with 1 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 1)\n",
      "theta between layer 1 and layer 2 is (2, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2597392406061334\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.258361740537336\n",
      "Error on this batch = 0.5819904510458613\n",
      "Cost on val dataset after 2 epochs is = 0.5204024792332181\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.5204024792332181\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.5202182476249874\n",
      "Error on this batch = 0.50212506489877\n",
      "Cost on val dataset after 3 epochs is = 0.4949624359871587\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4949624359871587\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4948485111676423\n",
      "Error on this batch = 0.49057920223495843\n",
      "Cost on val dataset after 4 epochs is = 0.48822364573631355\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.48822364573631355\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48812951795626336\n",
      "Error on this batch = 0.4864411017911279\n",
      "Cost on val dataset after 5 epochs is = 0.4853560069995764\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4853560069995764\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4852702521139584\n",
      "Error on this batch = 0.48444401232249745\n",
      "Cost on val dataset after 6 epochs is = 0.48385197513995554\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.48385197513995554\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4837703251632127\n",
      "Error on this batch = 0.4833204755751648\n",
      "Cost on val dataset after 7 epochs is = 0.4829630768751136\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4829630768751136\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4828835239700297\n",
      "Error on this batch = 0.48262590249868903\n",
      "Cost on val dataset after 8 epochs is = 0.48239537342820915\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48239537342820915\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.48231683908040085\n",
      "Error on this batch = 0.48216814886298764\n",
      "Cost on val dataset after 9 epochs is = 0.4820125168039131\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4820125168039131\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.48193437077273643\n",
      "Error on this batch = 0.48185217896092314\n",
      "Cost on val dataset after 10 epochs is = 0.48174369797047717\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48174369797047717\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.4816655508392964\n",
      "Error on this batch = 0.4816263026976067\n",
      "Cost on val dataset after 11 epochs is = 0.48154900226022057\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48154900226022057\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.48147060441885525\n",
      "Error on this batch = 0.48146034510635366\n",
      "Cost on val dataset after 12 epochs is = 0.4814044829327383\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4814044829327383\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48132567079928623\n",
      "Error on this batch = 0.48133569922196545\n",
      "Cost on val dataset after 13 epochs is = 0.4812950513242689\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4812950513242689\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4812157166894792\n",
      "Error on this batch = 0.4812403789143144\n",
      "Cost on val dataset after 14 epochs is = 0.48121081643960084\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.48121081643960084\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.48113088802007736\n",
      "Error on this batch = 0.48116638272522755\n",
      "Cost on val dataset after 15 epochs is = 0.4811450796186406\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4811450796186406\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.4810645114585555\n",
      "Error on this batch = 0.4811082084759502\n",
      "Cost on val dataset after 16 epochs is = 0.48109317858907674\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.48109317858907674\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4810119424985157\n",
      "Error on this batch = 0.48106197673483236\n",
      "Cost on val dataset after 17 epochs is = 0.4810517922426216\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.4810517922426216\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4809698727154488\n",
      "Error on this batch = 0.48102489308147767\n",
      "Cost on val dataset after 18 epochs is = 0.48101850719097006\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.48101850719097006\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.4809358978999215\n",
      "Error on this batch = 0.4809949070962916\n",
      "Cost on val dataset after 19 epochs is = 0.4809915390568528\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.4809915390568528\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.4809082403824344\n",
      "Error on this batch = 0.48097048982628543\n",
      "Cost on val dataset after 20 epochs is = 0.4809695483947119\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4809695483947119\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.48088556564955726\n",
      "Error on this batch = 0.48095048489487513\n",
      "Cost on val dataset after 21 epochs is = 0.480951516224597\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.480951516224597\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.48086685835643295\n",
      "Error on this batch = 0.4809340066729284\n",
      "Cost on val dataset after 22 epochs is = 0.48093665811171704\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.48093665811171704\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.48085133674238\n",
      "Error on this batch = 0.4809203692673546\n",
      "Cost on val dataset after 23 epochs is = 0.48092436375149034\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.48092436375149034\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.4808383924561351\n",
      "Error on this batch = 0.4809090361332837\n",
      "Cost on val dataset after 24 epochs is = 0.48091415378257\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.48091415378257\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.480827547543312\n",
      "Error on this batch = 0.48089958375872416\n",
      "Cost on val dataset after 25 epochs is = 0.48090564845372946\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.48090564845372946\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.4808184232417862\n",
      "Error on this batch = 0.48089167512098707\n",
      "Cost on val dataset after 26 epochs is = 0.4808985445840222\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.4808985445840222\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.4808107170377391\n",
      "Error on this batch = 0.48088504003672217\n",
      "Cost on val dataset after 27 epochs is = 0.48089259841351206\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.48089259841351206\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.48080418558877314\n",
      "Error on this batch = 0.48087946044557656\n",
      "Cost on val dataset after 28 epochs is = 0.4808876126959658\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4808876126959658\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.48079863187182853\n",
      "Error on this batch = 0.4808747592713812\n",
      "Cost on val dataset after 29 epochs is = 0.4808834268849919\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.4808834268849919\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.4807938954118523\n",
      "Error on this batch = 0.4808707919088892\n",
      "Cost on val dataset after 30 epochs is = 0.48087990960226196\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.48087990960226196\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.48078984478306425\n",
      "Error on this batch = 0.4808674396588134\n",
      "Cost on val dataset after 31 epochs is = 0.48087695280725723\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.48087695280725723\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.4807863718045745\n",
      "Error on this batch = 0.4808646046234041\n",
      "Cost on val dataset after 32 epochs is = 0.4808744672481807\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.4808744672481807\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.48078338701169443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4808622057072821\n",
      "Cost on val dataset after 33 epochs is = 0.48087237888632844\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.48087237888632844\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.4807808160964955\n",
      "Error on this batch = 0.48086017546199744\n",
      "Cost on val dataset after 34 epochs is = 0.4808706260663819\n",
      "cost initial= 0.48087237888632844 , cost final=0.4808706260663819 , change in cost= -1.7528199465211003e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 1 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 34\n",
      "The training time = 2.163sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 5 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 5)\n",
      "theta between layer 1 and layer 2 is (6, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2884481219596324\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.287007203952446\n",
      "Error on this batch = 0.49897808664779675\n",
      "Cost on val dataset after 2 epochs is = 0.4865578565525861\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4865578565525861\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.4862483057750571\n",
      "Error on this batch = 0.483406225275497\n",
      "Cost on val dataset after 3 epochs is = 0.4822794022366817\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4822794022366817\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4821105944181454\n",
      "Error on this batch = 0.481714140829764\n",
      "Cost on val dataset after 4 epochs is = 0.4814090111840232\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4814090111840232\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48127966463242666\n",
      "Error on this batch = 0.4812444781063708\n",
      "Cost on val dataset after 5 epochs is = 0.481122525673021\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.481122525673021\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4810097464237582\n",
      "Error on this batch = 0.48106822884843936\n",
      "Cost on val dataset after 6 epochs is = 0.48100651870635475\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.48100651870635475\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.48090187501931086\n",
      "Error on this batch = 0.48099115573123585\n",
      "Cost on val dataset after 7 epochs is = 0.4809538867390374\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4809538867390374\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4808535234604673\n",
      "Error on this batch = 0.48095419451914956\n",
      "Cost on val dataset after 8 epochs is = 0.4809283100849405\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4809283100849405\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4808302445842416\n",
      "Error on this batch = 0.48093534590460507\n",
      "Cost on val dataset after 9 epochs is = 0.48091534528442004\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48091534528442004\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.4808184860964096\n",
      "Error on this batch = 0.48092529834701436\n",
      "Cost on val dataset after 10 epochs is = 0.48090861380937544\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48090861380937544\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.4808123368784131\n",
      "Error on this batch = 0.4809197503883323\n",
      "Cost on val dataset after 11 epochs is = 0.4809050848901941\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4809050848901941\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.48080902775299666\n",
      "Error on this batch = 0.4809165860814039\n",
      "Cost on val dataset after 12 epochs is = 0.4809032404331069\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4809032404331069\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48080719352933543\n",
      "Error on this batch = 0.4809147150402417\n",
      "Cost on val dataset after 13 epochs is = 0.48090229032710086\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48090229032710086\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4808061359894963\n",
      "Error on this batch = 0.48091355551189163\n",
      "Cost on val dataset after 14 epochs is = 0.4809018120424333\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4809018120424333\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.48080548867964235\n",
      "Error on this batch = 0.4809127890621804\n",
      "Cost on val dataset after 15 epochs is = 0.4809015756488622\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4809015756488622\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.4808050560204363\n",
      "Error on this batch = 0.4809122382454738\n",
      "Cost on val dataset after 16 epochs is = 0.4809014550381529\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4809014550381529\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.48080473277100655\n",
      "Error on this batch = 0.4809118031282054\n",
      "Cost on val dataset after 17 epochs is = 0.48090138126616333\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.48090138126616333\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.48080446236080576\n",
      "Error on this batch = 0.4809114272702392\n",
      "Cost on val dataset after 18 epochs is = 0.4809013173256754\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.4809013173256754\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.4808042147651926\n",
      "Error on this batch = 0.48091107900608093\n",
      "Cost on val dataset after 19 epochs is = 0.4809012441937833\n",
      "cost initial= 0.4809013173256754 , cost final=0.4809012441937833 , change in cost= -7.313189215318872e-08\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 5 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 19\n",
      "The training time = 1.215sec\n",
      "The training accuracy is = 3.928%\n",
      "The validation accuracy is = 2.974%\n",
      "The test accuracy is = 3.800%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 10 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 10)\n",
      "theta between layer 1 and layer 2 is (11, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2708585206102443\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.2741713120071916\n",
      "Error on this batch = 0.4871291320862221\n",
      "Cost on val dataset after 2 epochs is = 0.4825887531052519\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4825887531052519\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.48228837867881197\n",
      "Error on this batch = 0.48153559050390415\n",
      "Cost on val dataset after 3 epochs is = 0.48129831723234257\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.48129831723234257\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.48112272119109706\n",
      "Error on this batch = 0.48112804393300146\n",
      "Cost on val dataset after 4 epochs is = 0.4811132453323031\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4811132453323031\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.48097114574172867\n",
      "Error on this batch = 0.48104845399481494\n",
      "Cost on val dataset after 5 epochs is = 0.48106821345786166\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.48106821345786166\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4809389924731349\n",
      "Error on this batch = 0.48102578802783086\n",
      "Cost on val dataset after 6 epochs is = 0.4810531489557464\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4810531489557464\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4809296492132114\n",
      "Error on this batch = 0.4810168451397722\n",
      "Cost on val dataset after 7 epochs is = 0.4810461328688657\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4810461328688657\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.48092540137423767\n",
      "Error on this batch = 0.4810118236828902\n",
      "Cost on val dataset after 8 epochs is = 0.48104156658626607\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.48104156658626607\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.48092228385566727\n",
      "Error on this batch = 0.48100806636253474\n",
      "Cost on val dataset after 9 epochs is = 0.48103781503906357\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48103781503906357\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.48091937178044564\n",
      "Error on this batch = 0.4810047768107806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 10 epochs is = 0.4810343673084456\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4810343673084456\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.480916481605657\n",
      "Error on this batch = 0.4810017030440847\n",
      "Cost on val dataset after 11 epochs is = 0.48103106224571907\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.48103106224571907\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4809136069741128\n",
      "Error on this batch = 0.4809987635196389\n",
      "Cost on val dataset after 12 epochs is = 0.4810278525830765\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.4810278525830765\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.48091077379551955\n",
      "Error on this batch = 0.48099593164119336\n",
      "Cost on val dataset after 13 epochs is = 0.48102472781311595\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.48102472781311595\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.48090800522828164\n",
      "Error on this batch = 0.4809931982501489\n",
      "Cost on val dataset after 14 epochs is = 0.4810216880620939\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4810216880620939\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4809053158580807\n",
      "Error on this batch = 0.4809905592176925\n",
      "Cost on val dataset after 15 epochs is = 0.4810187353161667\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4810187353161667\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.48090271294141435\n",
      "Error on this batch = 0.48098801144207665\n",
      "Cost on val dataset after 16 epochs is = 0.481015870738236\n",
      "cost initial= 0.4810187353161667 , cost final=0.481015870738236 , change in cost= -2.8645779306946118e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 10 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 16\n",
      "The training time = 1.121sec\n",
      "The training accuracy is = 3.973%\n",
      "The validation accuracy is = 3.128%\n",
      "The test accuracy is = 3.846%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 50 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 50)\n",
      "theta between layer 1 and layer 2 is (51, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.432333393911887\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.4325365973151007\n",
      "Error on this batch = 0.4816799445840069\n",
      "Cost on val dataset after 2 epochs is = 0.4811310837562912\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4811310837562912\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.4809476615658362\n",
      "Error on this batch = 0.4809422897462403\n",
      "Cost on val dataset after 3 epochs is = 0.4807636732506059\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4807636732506059\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.4805579543179439\n",
      "Error on this batch = 0.48059490344520767\n",
      "Cost on val dataset after 4 epochs is = 0.4804193978131324\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4804193978131324\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.4801582422429723\n",
      "Error on this batch = 0.4802392062749708\n",
      "Cost on val dataset after 5 epochs is = 0.4800511215770093\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4800511215770093\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.47972384140699026\n",
      "Error on this batch = 0.47984843821733036\n",
      "Cost on val dataset after 6 epochs is = 0.47964409516789963\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.47964409516789963\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.4792375703832661\n",
      "Error on this batch = 0.47940489424889743\n",
      "Cost on val dataset after 7 epochs is = 0.4791833203572708\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4791833203572708\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4786788211408088\n",
      "Error on this batch = 0.47889015503073795\n",
      "Cost on val dataset after 8 epochs is = 0.4786507559620688\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4786507559620688\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4780216704689768\n",
      "Error on this batch = 0.4782816185270896\n",
      "Cost on val dataset after 9 epochs is = 0.4780232840770061\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4780232840770061\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.47723168551668765\n",
      "Error on this batch = 0.47754984435306524\n",
      "Cost on val dataset after 10 epochs is = 0.4772701879242917\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.4772701879242917\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.47626156576623163\n",
      "Error on this batch = 0.4766556855187335\n",
      "Cost on val dataset after 11 epochs is = 0.47634988591143557\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.47634988591143557\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4750455502404155\n",
      "Error on this batch = 0.4755475168242492\n",
      "Cost on val dataset after 12 epochs is = 0.47520634368775766\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.47520634368775766\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.4734939713144921\n",
      "Error on this batch = 0.4741611553074326\n",
      "Cost on val dataset after 13 epochs is = 0.4737676446554184\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4737676446554184\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.47149412389500284\n",
      "Error on this batch = 0.4724304214649544\n",
      "Cost on val dataset after 14 epochs is = 0.47195409791279475\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.47195409791279475\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4689336897037091\n",
      "Error on this batch = 0.47032276689406943\n",
      "Cost on val dataset after 15 epochs is = 0.46970751620475243\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.46970751620475243\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.46576695565961984\n",
      "Error on this batch = 0.4678987161231362\n",
      "Cost on val dataset after 16 epochs is = 0.4670359010446531\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4670359010446531\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4620969720624404\n",
      "Error on this batch = 0.46532695197889995\n",
      "Cost on val dataset after 17 epochs is = 0.464021845059292\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.464021845059292\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4581600911514769\n",
      "Error on this batch = 0.4627814979206925\n",
      "Cost on val dataset after 18 epochs is = 0.46076414932386217\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.46076414932386217\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.45417984434454356\n",
      "Error on this batch = 0.46032196918175217\n",
      "Cost on val dataset after 19 epochs is = 0.4573220654570584\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.4573220654570584\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.4502565516045523\n",
      "Error on this batch = 0.45789243563585535\n",
      "Cost on val dataset after 20 epochs is = 0.4537063371775303\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4537063371775303\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.44637960828556944\n",
      "Error on this batch = 0.4553908357385549\n",
      "Cost on val dataset after 21 epochs is = 0.4498809827432542\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.4498809827432542\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.4424763731836791\n",
      "Error on this batch = 0.45271310577580975\n",
      "Cost on val dataset after 22 epochs is = 0.4457636796851843\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4457636796851843\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.4384397880204572\n",
      "Error on this batch = 0.4497566987384009\n",
      "Cost on val dataset after 23 epochs is = 0.44124868546201085\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.44124868546201085\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.4341545959475549\n",
      "Error on this batch = 0.446416657977873\n",
      "Cost on val dataset after 24 epochs is = 0.4362664469062646\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.4362664469062646\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.42954866601813585\n",
      "Error on this batch = 0.44260964294386973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 25 epochs is = 0.4308390192203968\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4308390192203968\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.42463729820746243\n",
      "Error on this batch = 0.43832162491402576\n",
      "Cost on val dataset after 26 epochs is = 0.42504557291164574\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.42504557291164574\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.41948296891911485\n",
      "Error on this batch = 0.4336120664941014\n",
      "Cost on val dataset after 27 epochs is = 0.4189259015501969\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.4189259015501969\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.41410075649129957\n",
      "Error on this batch = 0.42855988913067267\n",
      "Cost on val dataset after 28 epochs is = 0.4124580820502143\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4124580820502143\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.4084357983657928\n",
      "Error on this batch = 0.4232254193501368\n",
      "Cost on val dataset after 29 epochs is = 0.4056320408135874\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.4056320408135874\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.40243147395154466\n",
      "Error on this batch = 0.41766227080205\n",
      "Cost on val dataset after 30 epochs is = 0.3985280787403657\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.3985280787403657\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.3961066517103239\n",
      "Error on this batch = 0.4119454112895529\n",
      "Cost on val dataset after 31 epochs is = 0.3913116596827842\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.3913116596827842\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.38956152100226404\n",
      "Error on this batch = 0.4061651498650477\n",
      "Cost on val dataset after 32 epochs is = 0.3841479375294367\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.3841479375294367\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.3829106141068073\n",
      "Error on this batch = 0.4003895451292566\n",
      "Cost on val dataset after 33 epochs is = 0.37713647538413114\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.37713647538413114\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.3762285631961899\n",
      "Error on this batch = 0.3946462297225676\n",
      "Cost on val dataset after 34 epochs is = 0.3703158763048405\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.3703158763048405\n",
      "learning rate for this epoch =  0.20706193828327601\n",
      "Error on this batch = 0.3695526017227866\n",
      "Error on this batch = 0.38893691824383825\n",
      "Cost on val dataset after 35 epochs is = 0.363696920896734\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.363696920896734\n",
      "learning rate for this epoch =  0.20556680845025985\n",
      "Error on this batch = 0.36290704158974485\n",
      "Error on this batch = 0.38325869695957127\n",
      "Cost on val dataset after 36 epochs is = 0.3572840682426129\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.3572840682426129\n",
      "learning rate for this epoch =  0.20412414523193154\n",
      "Error on this batch = 0.35631648867177335\n",
      "Error on this batch = 0.3776148268342326\n",
      "Cost on val dataset after 37 epochs is = 0.3510805700531517\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.3510805700531517\n",
      "learning rate for this epoch =  0.2027307249193849\n",
      "Error on this batch = 0.34980576099513727\n",
      "Error on this batch = 0.37201522949372284\n",
      "Cost on val dataset after 38 epochs is = 0.34508652730861644\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.34508652730861644\n",
      "learning rate for this epoch =  0.20138360231828867\n",
      "Error on this batch = 0.34339573777919435\n",
      "Error on this batch = 0.3664727145341491\n",
      "Cost on val dataset after 39 epochs is = 0.33929686598166353\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.33929686598166353\n",
      "learning rate for this epoch =  0.20008008009612496\n",
      "Error on this batch = 0.337100787007826\n",
      "Error on this batch = 0.36099940221391025\n",
      "Cost on val dataset after 40 epochs is = 0.333701218172429\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.333701218172429\n",
      "learning rate for this epoch =  0.19881768219176266\n",
      "Error on this batch = 0.3309285557474891\n",
      "Error on this batch = 0.3556048000752023\n",
      "Cost on val dataset after 41 epochs is = 0.32828516910117317\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.32828516910117317\n",
      "learning rate for this epoch =  0.19759413066220238\n",
      "Error on this batch = 0.3248810929359412\n",
      "Error on this batch = 0.3502952675461174\n",
      "Cost on val dataset after 42 epochs is = 0.32303195285227887\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.32303195285227887\n",
      "learning rate for this epoch =  0.1964073254502565\n",
      "Error on this batch = 0.3189563889464066\n",
      "Error on this batch = 0.3450742156125314\n",
      "Cost on val dataset after 43 epochs is = 0.3179240479034149\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.3179240479034149\n",
      "learning rate for this epoch =  0.19525532664475806\n",
      "Error on this batch = 0.3131498990343821\n",
      "Error on this batch = 0.3399425827039322\n",
      "Cost on val dataset after 44 epochs is = 0.312944474355369\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.312944474355369\n",
      "learning rate for this epoch =  0.19413633887611162\n",
      "Error on this batch = 0.3074559005231848\n",
      "Error on this batch = 0.33489937630132505\n",
      "Cost on val dataset after 45 epochs is = 0.30807777092616734\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.30807777092616734\n",
      "learning rate for this epoch =  0.19304869754804485\n",
      "Error on this batch = 0.30186862570488304\n",
      "Error on this batch = 0.3299422142463464\n",
      "Cost on val dataset after 46 epochs is = 0.30331068690659263\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.30331068690659263\n",
      "learning rate for this epoch =  0.19199085665396748\n",
      "Error on this batch = 0.29638313241749925\n",
      "Error on this batch = 0.32506785851854825\n",
      "Cost on val dataset after 47 epochs is = 0.298632630290758\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.298632630290758\n",
      "learning rate for this epoch =  0.1909613779654767\n",
      "Error on this batch = 0.29099589245704865\n",
      "Error on this batch = 0.3202727521439309\n",
      "Cost on val dataset after 48 epochs is = 0.2940359041972479\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.2940359041972479\n",
      "learning rate for this epoch =  0.18995892141289814\n",
      "Error on this batch = 0.28570510911013847\n",
      "Error on this batch = 0.31555356674710483\n",
      "Cost on val dataset after 49 epochs is = 0.28951575160758114\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.28951575160758114\n",
      "learning rate for this epoch =  0.1889822365046136\n",
      "Error on this batch = 0.2805108047662898\n",
      "Error on this batch = 0.3109077441397881\n",
      "Cost on val dataset after 50 epochs is = 0.28507021812111544\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.28507021812111544\n",
      "learning rate for this epoch =  0.1880301546543197\n",
      "Error on this batch = 0.2754147314218986\n",
      "Error on this batch = 0.3063339750757709\n",
      "Cost on val dataset after 51 epochs is = 0.2806998412857163\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.2806998412857163\n",
      "learning rate for this epoch =  0.18710158230410626\n",
      "Error on this batch = 0.2704201494271501\n",
      "Error on this batch = 0.30183252803740573\n",
      "Cost on val dataset after 52 epochs is = 0.2764071895136236\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.2764071895136236\n",
      "learning rate for this epoch =  0.1861954947469912\n",
      "Error on this batch = 0.26553150651935603\n",
      "Error on this batch = 0.29740535439025245\n",
      "Cost on val dataset after 53 epochs is = 0.2721962986790607\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.2721962986790607\n",
      "learning rate for this epoch =  0.18531093056582568\n",
      "Error on this batch = 0.2607540449326325\n",
      "Error on this batch = 0.29305595673736945\n",
      "Cost on val dataset after 54 epochs is = 0.26807207434981095\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.26807207434981095\n",
      "learning rate for this epoch =  0.18444698661672027\n",
      "Error on this batch = 0.25609337166318663\n",
      "Error on this batch = 0.28878907421783295\n",
      "Cost on val dataset after 55 epochs is = 0.26403972905986395\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.26403972905986395\n",
      "learning rate for this epoch =  0.1836028134946796\n",
      "Error on this batch = 0.25155503474827695\n",
      "Error on this batch = 0.28461026798535094\n",
      "Cost on val dataset after 56 epochs is = 0.260104306920193\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.260104306920193\n",
      "learning rate for this epoch =  0.18277761142725618\n",
      "Error on this batch = 0.2471441449870821\n",
      "Error on this batch = 0.2805254788636504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 57 epochs is = 0.2562703223868598\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.2562703223868598\n",
      "learning rate for this epoch =  0.18197062654897384\n",
      "Error on this batch = 0.2428650682544209\n",
      "Error on this batch = 0.27654060452233153\n",
      "Cost on val dataset after 58 epochs is = 0.2525415173157063\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.2525415173157063\n",
      "learning rate for this epoch =  0.1811811475152165\n",
      "Error on this batch = 0.23872119841991782\n",
      "Error on this batch = 0.27266112603794185\n",
      "Cost on val dataset after 59 epochs is = 0.2489207258471806\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.2489207258471806\n",
      "learning rate for this epoch =  0.180408502419387\n",
      "Error on this batch = 0.2347148121852778\n",
      "Error on this batch = 0.26889180438382276\n",
      "Cost on val dataset after 60 epochs is = 0.24540982945864656\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.24540982945864656\n",
      "learning rate for this epoch =  0.17965205598154213\n",
      "Error on this batch = 0.2308470039286113\n",
      "Error on this batch = 0.2652364597550986\n",
      "Cost on val dataset after 61 epochs is = 0.24200978179168514\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.24200978179168514\n",
      "learning rate for this epoch =  0.1789112069805131\n",
      "Error on this batch = 0.2271176962536032\n",
      "Error on this batch = 0.26169783771717897\n",
      "Cost on val dataset after 62 epochs is = 0.23872068256831466\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.23872068256831466\n",
      "learning rate for this epoch =  0.1781853859048144\n",
      "Error on this batch = 0.223525717769585\n",
      "Error on this batch = 0.2582775572141501\n",
      "Cost on val dataset after 63 epochs is = 0.23554188129348447\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.23554188129348447\n",
      "learning rate for this epoch =  0.17747405280050266\n",
      "Error on this batch = 0.22006893429145458\n",
      "Error on this batch = 0.25497612860412494\n",
      "Cost on val dataset after 64 epochs is = 0.23247209419226306\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.23247209419226306\n",
      "learning rate for this epoch =  0.17677669529663687\n",
      "Error on this batch = 0.21674441517421145\n",
      "Error on this batch = 0.2517930260865378\n",
      "Cost on val dataset after 65 epochs is = 0.22950952150388837\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.22950952150388837\n",
      "learning rate for this epoch =  0.1760928267911618\n",
      "Error on this batch = 0.21354861450600449\n",
      "Error on this batch = 0.24872679792135757\n",
      "Cost on val dataset after 66 epochs is = 0.2266519562395852\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.2266519562395852\n",
      "learning rate for this epoch =  0.17542198478193427\n",
      "Error on this batch = 0.21047754790996578\n",
      "Error on this batch = 0.2457751989096115\n",
      "Cost on val dataset after 67 epochs is = 0.2238968792329648\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.2238968792329648\n",
      "learning rate for this epoch =  0.1747637293292756\n",
      "Error on this batch = 0.20752694935584123\n",
      "Error on this batch = 0.24293533186869462\n",
      "Cost on val dataset after 68 epochs is = 0.22124153839141797\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.22124153839141797\n",
      "learning rate for this epoch =  0.1741176416378927\n",
      "Error on this batch = 0.20469239775101677\n",
      "Error on this batch = 0.24020378764649594\n",
      "Cost on val dataset after 69 epochs is = 0.21868301233824405\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.21868301233824405\n",
      "learning rate for this epoch =  0.1734833227472955\n",
      "Error on this batch = 0.20196940908731598\n",
      "Error on this batch = 0.2375767761365586\n",
      "Cost on val dataset after 70 epochs is = 0.2162182601296517\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.2162182601296517\n",
      "learning rate for this epoch =  0.1728603923209705\n",
      "Error on this batch = 0.19935349552417517\n",
      "Error on this batch = 0.23505024349422715\n",
      "Cost on val dataset after 71 epochs is = 0.2138441595394646\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.2138441595394646\n",
      "learning rate for this epoch =  0.17224848752556968\n",
      "Error on this batch = 0.19684019713280174\n",
      "Error on this batch = 0.23261997312002922\n",
      "Cost on val dataset after 72 epochs is = 0.2115575366609635\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.2115575366609635\n",
      "learning rate for this epoch =  0.17164726199225983\n",
      "Error on this batch = 0.19442509455972556\n",
      "Error on this batch = 0.23028166985332327\n",
      "Cost on val dataset after 73 epochs is = 0.20935518941848594\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.20935518941848594\n",
      "learning rate for this epoch =  0.17105638485316074\n",
      "Error on this batch = 0.19210381144267508\n",
      "Error on this batch = 0.22803102815812223\n",
      "Cost on val dataset after 74 epochs is = 0.20723390714784076\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.20723390714784076\n",
      "learning rate for this epoch =  0.1704755398464977\n",
      "Error on this batch = 0.18987201429189157\n",
      "Error on this batch = 0.2258637859045264\n",
      "Cost on val dataset after 75 epochs is = 0.20519048782652283\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.20519048782652283\n",
      "learning rate for this epoch =  0.16990442448471224\n",
      "Error on this batch = 0.18772541531668374\n",
      "Error on this batch = 0.22377576573193644\n",
      "Cost on val dataset after 76 epochs is = 0.20322175393255068\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.20322175393255068\n",
      "learning rate for this epoch =  0.16934274928032858\n",
      "Error on this batch = 0.1856597810408293\n",
      "Error on this batch = 0.22176290603780924\n",
      "Cost on val dataset after 77 epochs is = 0.20132456738075996\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.20132456738075996\n",
      "learning rate for this epoch =  0.16879023702486318\n",
      "Error on this batch = 0.1836709471478741\n",
      "Error on this batch = 0.21982128348900964\n",
      "Cost on val dataset after 78 epochs is = 0.19949584358848352\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.19949584358848352\n",
      "learning rate for this epoch =  0.16824662211650757\n",
      "Error on this batch = 0.18175483824539002\n",
      "Error on this batch = 0.21794712870633112\n",
      "Cost on val dataset after 79 epochs is = 0.19773256448060017\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.19773256448060017\n",
      "learning rate for this epoch =  0.1677116499327062\n",
      "Error on this batch = 0.17990749028653827\n",
      "Error on this batch = 0.21613683650168888\n",
      "Cost on val dataset after 80 epochs is = 0.1960317901452003\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.1960317901452003\n",
      "learning rate for this epoch =  0.1671850762441055\n",
      "Error on this batch = 0.17812507316581522\n",
      "Error on this batch = 0.21438697179581348\n",
      "Cost on val dataset after 81 epochs is = 0.19439066886223938\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.19439066886223938\n",
      "learning rate for this epoch =  0.16666666666666666\n",
      "Error on this batch = 0.17640391131104877\n",
      "Error on this batch = 0.2126942721306928\n",
      "Cost on val dataset after 82 epochs is = 0.1928064453070953\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.1928064453070953\n",
      "learning rate for this epoch =  0.16615619614902008\n",
      "Error on this batch = 0.1747405006873027\n",
      "Error on this batch = 0.2110556475179529\n",
      "Cost on val dataset after 83 epochs is = 0.19127646684031566\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.19127646684031566\n",
      "learning rate for this epoch =  0.16565344849239508\n",
      "Error on this batch = 0.17313152130409287\n",
      "Error on this batch = 0.20946817822626687\n",
      "Cost on val dataset after 84 epochs is = 0.18979818790466185\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.18979818790466185\n",
      "learning rate for this epoch =  0.16515821590069035\n",
      "Error on this batch = 0.17157384493302552\n",
      "Error on this batch = 0.20792911099998526\n",
      "Cost on val dataset after 85 epochs is = 0.18836917264256248\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.18836917264256248\n",
      "learning rate for this epoch =  0.164670298558459\n",
      "Error on this batch = 0.17006453822333392\n",
      "Error on this batch = 0.20643585411058638\n",
      "Cost on val dataset after 86 epochs is = 0.18698709591296175\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.18698709591296175\n",
      "learning rate for this epoch =  0.16418950423477013\n",
      "Error on this batch = 0.16860086172577776\n",
      "Error on this batch = 0.20498597156725054\n",
      "Cost on val dataset after 87 epochs is = 0.18564974292526984\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.18564974292526984\n",
      "learning rate for this epoch =  0.16371564791108048\n",
      "Error on this batch = 0.16718026551314652\n",
      "Error on this batch = 0.20357717674961373\n",
      "Cost on val dataset after 88 epochs is = 0.18435500772307953\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.18435500772307953\n",
      "learning rate for this epoch =  0.16324855143140263\n",
      "Error on this batch = 0.16580038214733506\n",
      "Error on this batch = 0.20220732567256433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 89 epochs is = 0.1831008907469176\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1831008907469176\n",
      "learning rate for this epoch =  0.1627880431731981\n",
      "Error on this batch = 0.1644590177224032\n",
      "Error on this batch = 0.2008744100484762\n",
      "Cost on val dataset after 90 epochs is = 0.18188549568929502\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.18188549568929502\n",
      "learning rate for this epoch =  0.16233395773754944\n",
      "Error on this batch = 0.16315414164117506\n",
      "Error on this batch = 0.1995765502755002\n",
      "Cost on val dataset after 91 epochs is = 0.1807070258318478\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.1807070258318478\n",
      "learning rate for this epoch =  0.16188613565728216\n",
      "Error on this batch = 0.16188387568468293\n",
      "Error on this batch = 0.19831198845053932\n",
      "Cost on val dataset after 92 epochs is = 0.17956378002748996\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.17956378002748996\n",
      "learning rate for this epoch =  0.161444423121811\n",
      "Error on this batch = 0.16064648282711702\n",
      "Error on this batch = 0.19707908148136583\n",
      "Cost on val dataset after 93 epochs is = 0.17845414846318913\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.17845414846318913\n",
      "learning rate for this epoch =  0.16100867171758368\n",
      "Error on this batch = 0.15944035614575244\n",
      "Error on this batch = 0.19587629435312134\n",
      "Cost on val dataset after 94 epochs is = 0.17737660831314783\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.17737660831314783\n",
      "learning rate for this epoch =  0.160578738183079\n",
      "Error on this batch = 0.15826400808244476\n",
      "Error on this batch = 0.19470219358930854\n",
      "Cost on val dataset after 95 epochs is = 0.17632971936895095\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.17632971936895095\n",
      "learning rate for this epoch =  0.16015448417739933\n",
      "Error on this batch = 0.157116060233993\n",
      "Error on this batch = 0.19355544093556445\n",
      "Cost on val dataset after 96 epochs is = 0.1753121197131221\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.1753121197131221\n",
      "learning rate for this epoch =  0.1597357760615681\n",
      "Error on this batch = 0.15599523378379318\n",
      "Error on this batch = 0.19243478728534505\n",
      "Cost on val dataset after 97 epochs is = 0.17432252148562263\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.17432252148562263\n",
      "learning rate for this epoch =  0.15932248469171095\n",
      "Error on this batch = 0.15490034063607966\n",
      "Error on this batch = 0.19133906685958885\n",
      "Cost on val dataset after 98 epochs is = 0.17335970677895657\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.17335970677895657\n",
      "learning rate for this epoch =  0.15891448522335927\n",
      "Error on this batch = 0.15383027527520374\n",
      "Error on this batch = 0.19026719164702158\n",
      "Cost on val dataset after 99 epochs is = 0.17242252368640992\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.17242252368640992\n",
      "learning rate for this epoch =  0.15851165692617153\n",
      "Error on this batch = 0.1527840073439937\n",
      "Error on this batch = 0.18921814610765836\n",
      "Cost on val dataset after 100 epochs is = 0.17150988251918428\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.17150988251918428\n",
      "learning rate for this epoch =  0.15811388300841897\n",
      "Error on this batch = 0.15176057491540115\n",
      "Error on this batch = 0.188190982138979\n",
      "Cost on val dataset after 101 epochs is = 0.1706207522014064\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.1706207522014064\n",
      "learning rate for this epoch =  0.1577210504506286\n",
      "Error on this batch = 0.150759078418597\n",
      "Error on this batch = 0.18718481430198047\n",
      "Cost on val dataset after 102 epochs is = 0.16975415684684683\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.16975415684684683\n",
      "learning rate for this epoch =  0.1573330498478208\n",
      "Error on this batch = 0.14977867517288895\n",
      "Error on this batch = 0.18619881530267116\n",
      "Cost on val dataset after 103 epochs is = 0.16890917251735263\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.16890917251735263\n",
      "learning rate for this epoch =  0.15694977525981785\n",
      "Error on this batch = 0.14881857447897168\n",
      "Error on this batch = 0.18523221172343227\n",
      "Cost on val dataset after 104 epochs is = 0.16808492416020843\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.16808492416020843\n",
      "learning rate for this epoch =  0.15657112406913673\n",
      "Error on this batch = 0.14787803321601936\n",
      "Error on this batch = 0.1842842799979143\n",
      "Cost on val dataset after 105 epochs is = 0.16728058271966734\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.16728058271966734\n",
      "learning rate for this epoch =  0.1561969968460128\n",
      "Error on this batch = 0.14695635189413403\n",
      "Error on this batch = 0.1833543426226693\n",
      "Cost on val dataset after 106 epochs is = 0.16649536241654844\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.16649536241654844\n",
      "learning rate for this epoch =  0.15582729722013278\n",
      "Error on this batch = 0.14605287111400547\n",
      "Error on this batch = 0.1824417645984596\n",
      "Cost on val dataset after 107 epochs is = 0.16572851818892667\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.16572851818892667\n",
      "learning rate for this epoch =  0.15546193175868359\n",
      "Error on this batch = 0.14516696838881957\n",
      "Error on this batch = 0.18154595009406777\n",
      "Cost on val dataset after 108 epochs is = 0.16497934328643565\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.16497934328643565\n",
      "learning rate for this epoch =  0.15510080985034994\n",
      "Error on this batch = 0.1442980552870949\n",
      "Error on this batch = 0.1806663393254005\n",
      "Cost on val dataset after 109 epochs is = 0.16424716701045833\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.16424716701045833\n",
      "learning rate for this epoch =  0.1547438435949191\n",
      "Error on this batch = 0.14344557485896478\n",
      "Error on this batch = 0.17980240564269043\n",
      "Cost on val dataset after 110 epochs is = 0.16353135259243465\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.16353135259243465\n",
      "learning rate for this epoch =  0.1543909476981724\n",
      "Error on this batch = 0.1426089993122608\n",
      "Error on this batch = 0.17895365281861572\n",
      "Cost on val dataset after 111 epochs is = 0.16283129520260298\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.16283129520260298\n",
      "learning rate for this epoch =  0.15404203937176525\n",
      "Error on this batch = 0.14178782790846708\n",
      "Error on this batch = 0.17811961253015626\n",
      "Cost on val dataset after 112 epochs is = 0.1621464200816825\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.1621464200816825\n",
      "learning rate for this epoch =  0.1536970382378161\n",
      "Error on this batch = 0.14098158505211925\n",
      "Error on this batch = 0.17729984202696955\n",
      "Cost on val dataset after 113 epochs is = 0.16147618078825543\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.16147618078825543\n",
      "learning rate for this epoch =  0.15335586623794323\n",
      "Error on this batch = 0.14018981855046442\n",
      "Error on this batch = 0.17649392197899227\n",
      "Cost on val dataset after 114 epochs is = 0.16082005755490217\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.16082005755490217\n",
      "learning rate for this epoch =  0.1530184475465045\n",
      "Error on this batch = 0.1394120980231623\n",
      "Error on this batch = 0.1757014544958545\n",
      "Cost on val dataset after 115 epochs is = 0.16017755574646392\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.16017755574646392\n",
      "learning rate for this epoch =  0.15268470848781107\n",
      "Error on this batch = 0.1386480134444733\n",
      "Error on this batch = 0.1749220613105401\n",
      "Cost on val dataset after 116 epochs is = 0.15954820441413747\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.15954820441413747\n",
      "learning rate for this epoch =  0.1523545774571\n",
      "Error on this batch = 0.13789717380276206\n",
      "Error on this batch = 0.17415538211954698\n",
      "Cost on val dataset after 117 epochs is = 0.15893155493944153\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.15893155493944153\n",
      "learning rate for this epoch =  0.15202798484506466\n",
      "Error on this batch = 0.13715920586424868\n",
      "Error on this batch = 0.1734010730716087\n",
      "Cost on val dataset after 118 epochs is = 0.1583271797624249\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.1583271797624249\n",
      "learning rate for this epoch =  0.15170486296575364\n",
      "Error on this batch = 0.13643375302978547\n",
      "Error on this batch = 0.17265880539685402\n",
      "Cost on val dataset after 119 epochs is = 0.15773467118881065\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.15773467118881065\n",
      "learning rate for this epoch =  0.1513851459876605\n",
      "Error on this batch = 0.13572047427504427\n",
      "Error on this batch = 0.17192826416810852\n",
      "Cost on val dataset after 120 epochs is = 0.15715364027108109\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.15715364027108109\n",
      "learning rate for this epoch =  0.1510687698678384\n",
      "Error on this batch = 0.13501904316588642\n",
      "Error on this batch = 0.1712091471859125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 121 epochs is = 0.15658371575880936\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.15658371575880936\n",
      "learning rate for this epoch =  0.15075567228888181\n",
      "Error on this batch = 0.13432914694187997\n",
      "Error on this batch = 0.1705011639787388\n",
      "Cost on val dataset after 122 epochs is = 0.15602454311382913\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.15602454311382913\n",
      "learning rate for this epoch =  0.1504457925986288\n",
      "Error on this batch = 0.1336504856619447\n",
      "Error on this batch = 0.16980403490986434\n",
      "Cost on val dataset after 123 epochs is = 0.15547578358610503\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.15547578358610503\n",
      "learning rate for this epoch =  0.15013907175244492\n",
      "Error on this batch = 0.1329827714069663\n",
      "Error on this batch = 0.1691174903823866\n",
      "Cost on val dataset after 124 epochs is = 0.15493711334642557\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.15493711334642557\n",
      "learning rate for this epoch =  0.1498354522579582\n",
      "Error on this batch = 0.13232572753494506\n",
      "Error on this batch = 0.16844127013397622\n",
      "Cost on val dataset after 125 epochs is = 0.15440822267228207\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.15440822267228207\n",
      "learning rate for this epoch =  0.14953487812212204\n",
      "Error on this batch = 0.13167908798485053\n",
      "Error on this batch = 0.16777512261313463\n",
      "Cost on val dataset after 126 epochs is = 0.15388881518352826\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.15388881518352826\n",
      "learning rate for this epoch =  0.14923729480049114\n",
      "Error on this batch = 0.13104259662585588\n",
      "Error on this batch = 0.16711880442896515\n",
      "Cost on val dataset after 127 epochs is = 0.15337860712463156\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.15337860712463156\n",
      "learning rate for this epoch =  0.14894264914859962\n",
      "Error on this batch = 0.13041600664903913\n",
      "Error on this batch = 0.1664720798667736\n",
      "Cost on val dataset after 128 epochs is = 0.1528773266905303\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.1528773266905303\n",
      "learning rate for this epoch =  0.14865088937534013\n",
      "Error on this batch = 0.12979907999897874\n",
      "Error on this batch = 0.16583472046217584\n",
      "Cost on val dataset after 129 epochs is = 0.15238471339330342\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.15238471339330342\n",
      "learning rate for this epoch =  0.14836196499824542\n",
      "Error on this batch = 0.12919158684294452\n",
      "Error on this batch = 0.16520650462680064\n",
      "Cost on val dataset after 130 epochs is = 0.151900517467039\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.151900517467039\n",
      "learning rate for this epoch =  0.14807582680058123\n",
      "Error on this batch = 0.12859330507560787\n",
      "Error on this batch = 0.164587217319126\n",
      "Cost on val dataset after 131 epochs is = 0.15142449930845708\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.15142449930845708\n",
      "learning rate for this epoch =  0.14779242679016388\n",
      "Error on this batch = 0.12800401985737137\n",
      "Error on this batch = 0.16397664975446405\n",
      "Cost on val dataset after 132 epochs is = 0.15095642895100075\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.15095642895100075\n",
      "learning rate for this epoch =  0.1475117181598202\n",
      "Error on this batch = 0.12742352318455946\n",
      "Error on this batch = 0.163374599148605\n",
      "Cost on val dataset after 133 epochs is = 0.15049608557025784\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.15049608557025784\n",
      "learning rate for this epoch =  0.147233655249413\n",
      "Error on this batch = 0.12685161348982227\n",
      "Error on this batch = 0.16278086849013587\n",
      "Cost on val dataset after 134 epochs is = 0.150043257018716\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.150043257018716\n",
      "learning rate for this epoch =  0.1469581935093583\n",
      "Error on this batch = 0.1262880952711922\n",
      "Error on this batch = 0.16219526633695083\n",
      "Cost on val dataset after 135 epochs is = 0.14959773938798257\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.14959773938798257\n",
      "learning rate for this epoch =  0.14668528946556555\n",
      "Error on this batch = 0.12573277874830205\n",
      "Error on this batch = 0.16161760663296357\n",
      "Cost on val dataset after 136 epochs is = 0.14915933659672503\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.14915933659672503\n",
      "learning rate for this epoch =  0.14641490068573487\n",
      "Error on this batch = 0.12518547954432738\n",
      "Error on this batch = 0.16104770854150827\n",
      "Cost on val dataset after 137 epochs is = 0.14872786000269927\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.14872786000269927\n",
      "learning rate for this epoch =  0.14614698574694937\n",
      "Error on this batch = 0.12464601839225964\n",
      "Error on this batch = 0.16048539629236971\n",
      "Cost on val dataset after 138 epochs is = 0.14830312803734316\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.14830312803734316\n",
      "learning rate for this epoch =  0.145881504204504\n",
      "Error on this batch = 0.12411422086415361\n",
      "Error on this batch = 0.1599304990398083\n",
      "Cost on val dataset after 139 epochs is = 0.1478849658615094\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.1478849658615094\n",
      "learning rate for this epoch =  0.14561841656191457\n",
      "Error on this batch = 0.12358991712202379\n",
      "Error on this batch = 0.15938285072934172\n",
      "Cost on val dataset after 140 epochs is = 0.1474732050410074\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.1474732050410074\n",
      "learning rate for this epoch =  0.14535768424205484\n",
      "Error on this batch = 0.1230729416890926\n",
      "Error on this batch = 0.15884228997140656\n",
      "Cost on val dataset after 141 epochs is = 0.14706768324070935\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.14706768324070935\n",
      "learning rate for this epoch =  0.14509926955937089\n",
      "Error on this batch = 0.1225631332401213\n",
      "Error on this batch = 0.1583086599203509\n",
      "Cost on val dataset after 142 epochs is = 0.14666824393605934\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.14666824393605934\n",
      "learning rate for this epoch =  0.1448431356931257\n",
      "Error on this batch = 0.12206033440958247\n",
      "Error on this batch = 0.15778180815750087\n",
      "Cost on val dataset after 143 epochs is = 0.14627473614089687\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.14627473614089687\n",
      "learning rate for this epoch =  0.14458924666162856\n",
      "Error on this batch = 0.12156439161646039\n",
      "Error on this batch = 0.15726158657730513\n",
      "Cost on val dataset after 144 epochs is = 0.14588701415058047\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.14588701415058047\n",
      "learning rate for this epoch =  0.14433756729740646\n",
      "Error on this batch = 0.12107515490449759\n",
      "Error on this batch = 0.15674785127578317\n",
      "Cost on val dataset after 145 epochs is = 0.1455049372994619\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.1455049372994619\n",
      "learning rate for this epoch =  0.14408806322327672\n",
      "Error on this batch = 0.12059247779673878\n",
      "Error on this batch = 0.15624046244070117\n",
      "Cost on val dataset after 146 epochs is = 0.1451283697318222\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.1451283697318222\n",
      "learning rate for this epoch =  0.14384070082928266\n",
      "Error on this batch = 0.12011621716325817\n",
      "Error on this batch = 0.1557392842430617\n",
      "Cost on val dataset after 147 epochs is = 0.1447571801854401\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.1447571801854401\n",
      "learning rate for this epoch =  0.1435954472504545\n",
      "Error on this batch = 0.11964623310099565\n",
      "Error on this batch = 0.15524418472963286\n",
      "Cost on val dataset after 148 epochs is = 0.1443912417870173\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.1443912417870173\n",
      "learning rate for this epoch =  0.1433522703453617\n",
      "Error on this batch = 0.11918238882466799\n",
      "Error on this batch = 0.15475503571635546\n",
      "Cost on val dataset after 149 epochs is = 0.14403043185873252\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.14403043185873252\n",
      "learning rate for this epoch =  0.1431111386754225\n",
      "Error on this batch = 0.11872455056776442\n",
      "Error on this batch = 0.15427171268255765\n",
      "Cost on val dataset after 150 epochs is = 0.14367463173524697\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.14367463173524697\n",
      "learning rate for this epoch =  0.14287202148493997\n",
      "Error on this batch = 0.11827258749268303\n",
      "Error on this batch = 0.153794094665981\n",
      "Cost on val dataset after 151 epochs is = 0.1433237265905249\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.1433237265905249\n",
      "learning rate for this epoch =  0.14263488868183333\n",
      "Error on this batch = 0.11782637160911051\n",
      "Error on this batch = 0.15332206415867397\n",
      "Cost on val dataset after 152 epochs is = 0.14297760527387435\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.14297760527387435\n",
      "learning rate for this epoch =  0.14239971081903682\n",
      "Error on this batch = 0.1173857776997989\n",
      "Error on this batch = 0.15285550700385206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 153 epochs is = 0.14263616015465203\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.14263616015465203\n",
      "learning rate for this epoch =  0.14216645907653844\n",
      "Error on this batch = 0.11695068325294208\n",
      "Error on this batch = 0.15239431229385045\n",
      "Cost on val dataset after 154 epochs is = 0.14229928697511143\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.14229928697511143\n",
      "learning rate for this epoch =  0.14193510524403224\n",
      "Error on this batch = 0.11652096840040599\n",
      "Error on this batch = 0.15193837226931325\n",
      "Cost on val dataset after 155 epochs is = 0.14196688471090552\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.14196688471090552\n",
      "learning rate for this epoch =  0.1417056217041599\n",
      "Error on this batch = 0.11609651586111898\n",
      "Error on this batch = 0.1514875822197722\n",
      "Cost on val dataset after 156 epochs is = 0.14163885543878865\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.14163885543878865\n",
      "learning rate for this epoch =  0.14147798141631754\n",
      "Error on this batch = 0.11567721088897823\n",
      "Error on this batch = 0.15104184038577048\n",
      "Cost on val dataset after 157 epochs is = 0.1413151042110896\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.1413151042110896\n",
      "learning rate for this epoch =  0.14125215790100537\n",
      "Error on this batch = 0.11526294122468014\n",
      "Error on this batch = 0.15060104786268286\n",
      "Cost on val dataset after 158 epochs is = 0.14099553893655462\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.14099553893655462\n",
      "learning rate for this epoch =  0.14102812522469854\n",
      "Error on this batch = 0.11485359705093118\n",
      "Error on this batch = 0.1501651085063765\n",
      "Cost on val dataset after 159 epochs is = 0.14068007026718665\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.14068007026718665\n",
      "learning rate for this epoch =  0.1408058579852188\n",
      "Error on this batch = 0.11444907095054463\n",
      "Error on this batch = 0.14973392884084555\n",
      "Cost on val dataset after 160 epochs is = 0.14036861149072824\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.14036861149072824\n",
      "learning rate for this epoch =  0.14058533129758727\n",
      "Error on this batch = 0.11404925786697515\n",
      "Error on this batch = 0.14930741796793962\n",
      "Cost on val dataset after 161 epochs is = 0.14006107842845955\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.14006107842845955\n",
      "learning rate for this epoch =  0.14036652078033962\n",
      "Error on this batch = 0.11365405506688772\n",
      "Error on this batch = 0.14888548747929142\n",
      "Cost on val dataset after 162 epochs is = 0.1397573893380031\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.1397573893380031\n",
      "learning rate for this epoch =  0.14014940254228575\n",
      "Error on this batch = 0.11326336210440083\n",
      "Error on this batch = 0.14846805137053345\n",
      "Cost on val dataset after 163 epochs is = 0.13945746482084573\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.13945746482084573\n",
      "learning rate for this epoch =  0.13993395316969692\n",
      "Error on this batch = 0.11287708078668388\n",
      "Error on this batch = 0.1480550259578784\n",
      "Cost on val dataset after 164 epochs is = 0.13916122773430706\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.13916122773430706\n",
      "learning rate for this epoch =  0.13972014971390403\n",
      "Error on this batch = 0.11249511514062716\n",
      "Error on this batch = 0.1476463297971212\n",
      "Cost on val dataset after 165 epochs is = 0.13886860310770102\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.13886860310770102\n",
      "learning rate for this epoch =  0.13950796967929133\n",
      "Error on this batch = 0.11211737138033892\n",
      "Error on this batch = 0.14724188360510657\n",
      "Cost on val dataset after 166 epochs is = 0.1385795180624517\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.1385795180624517\n",
      "learning rate for this epoch =  0.13929739101167085\n",
      "Error on this batch = 0.11174375787525609\n",
      "Error on this batch = 0.1468416101836904\n",
      "Cost on val dataset after 167 epochs is = 0.13829390173594103\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.13829390173594103\n",
      "learning rate for this epoch =  0.13908839208702292\n",
      "Error on this batch = 0.11137418511868799\n",
      "Error on this batch = 0.14644543434621046\n",
      "Cost on val dataset after 168 epochs is = 0.1380116852088782\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.1380116852088782\n",
      "learning rate for this epoch =  0.13888095170058953\n",
      "Error on this batch = 0.11100856569663861\n",
      "Error on this batch = 0.1460532828464688\n",
      "Cost on val dataset after 169 epochs is = 0.1377328014359958\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.1377328014359958\n",
      "learning rate for this epoch =  0.1386750490563073\n",
      "Error on this batch = 0.11064681425678007\n",
      "Error on this batch = 0.14566508431021644\n",
      "Cost on val dataset after 170 epochs is = 0.13745718517988745\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.13745718517988745\n",
      "learning rate for this epoch =  0.13847066375656708\n",
      "Error on this batch = 0.11028884747747299\n",
      "Error on this batch = 0.14528076916912108\n",
      "Cost on val dataset after 171 epochs is = 0.13718477294781506\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.13718477294781506\n",
      "learning rate for this epoch =  0.1382677757922894\n",
      "Error on this batch = 0.10993458403675031\n",
      "Error on this batch = 0.14490026959718857\n",
      "Cost on val dataset after 172 epochs is = 0.1369155029313232\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.1369155029313232\n",
      "learning rate for this epoch =  0.1380663655333028\n",
      "Error on this batch = 0.1095839445812008\n",
      "Error on this batch = 0.14452351944960096\n",
      "Cost on val dataset after 173 epochs is = 0.136649314948509\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.136649314948509\n",
      "learning rate for this epoch =  0.13786641371901512\n",
      "Error on this batch = 0.10923685169470383\n",
      "Error on this batch = 0.1441504542039263\n",
      "Cost on val dataset after 174 epochs is = 0.13638615038880458\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.13638615038880458\n",
      "learning rate for this epoch =  0.13766790144936686\n",
      "Error on this batch = 0.10889322986698372\n",
      "Error on this batch = 0.1437810109036504\n",
      "Cost on val dataset after 175 epochs is = 0.13612595216013806\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.13612595216013806\n",
      "learning rate for this epoch =  0.1374708101760565\n",
      "Error on this batch = 0.108553005461963\n",
      "Error on this batch = 0.1434151281039736\n",
      "Cost on val dataset after 176 epochs is = 0.1358686646383478\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.1358686646383478\n",
      "learning rate for this epoch =  0.1372751216940281\n",
      "Error on this batch = 0.10821610668590693\n",
      "Error on this batch = 0.14305274581981367\n",
      "Cost on val dataset after 177 epochs is = 0.13561423361873076\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.13561423361873076\n",
      "learning rate for this epoch =  0.1370808181332119\n",
      "Error on this batch = 0.10788246355535924\n",
      "Error on this batch = 0.14269380547594995\n",
      "Cost on val dataset after 178 epochs is = 0.13536260626961533\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.13536260626961533\n",
      "learning rate for this epoch =  0.13688788195050916\n",
      "Error on this batch = 0.10755200786487942\n",
      "Error on this batch = 0.14233824985924345\n",
      "Cost on val dataset after 179 epochs is = 0.13511373108785293\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.13511373108785293\n",
      "learning rate for this epoch =  0.13669629592201246\n",
      "Error on this batch = 0.10722467315459724\n",
      "Error on this batch = 0.14198602307286456\n",
      "Cost on val dataset after 180 epochs is = 0.13486755785613097\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.13486755785613097\n",
      "learning rate for this epoch =  0.13650604313545334\n",
      "Error on this batch = 0.10690039467760556\n",
      "Error on this batch = 0.14163707049245847\n",
      "Cost on val dataset after 181 epochs is = 0.13462403760201552\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.13462403760201552\n",
      "learning rate for this epoch =  0.13631710698286975\n",
      "Error on this batch = 0.10657910936721883\n",
      "Error on this batch = 0.14129133872417768\n",
      "Cost on val dataset after 182 epochs is = 0.13438312255863544\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.13438312255863544\n",
      "learning rate for this epoch =  0.1361294711534851\n",
      "Error on this batch = 0.10626075580412572\n",
      "Error on this batch = 0.14094877556451205\n",
      "Cost on val dataset after 183 epochs is = 0.13414476612692788\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.13414476612692788\n",
      "learning rate for this epoch =  0.13594311962679215\n",
      "Error on this batch = 0.10594527418346926\n",
      "Error on this batch = 0.14060932996184466\n",
      "Cost on val dataset after 184 epochs is = 0.13390892283936748\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.13390892283936748\n",
      "learning rate for this epoch =  0.13575803666583477\n",
      "Error on this batch = 0.10563260628188842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.14027295197966397\n",
      "Cost on val dataset after 185 epochs is = 0.13367554832510678\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.13367554832510678\n",
      "learning rate for this epoch =  0.13557420681068058\n",
      "Error on this batch = 0.10532269542455634\n",
      "Error on this batch = 0.13993959276136345\n",
      "Cost on val dataset after 186 epochs is = 0.13344459927646046\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.13344459927646046\n",
      "learning rate for this epoch =  0.13539161487207826\n",
      "Error on this batch = 0.10501548645225192\n",
      "Error on this batch = 0.13960920449656003\n",
      "Cost on val dataset after 187 epochs is = 0.13321603341666818\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.13321603341666818\n",
      "learning rate for this epoch =  0.13521024592529318\n",
      "Error on this batch = 0.10471092568850063\n",
      "Error on this batch = 0.13928174038886554\n",
      "Cost on val dataset after 188 epochs is = 0.13298980946887634\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.13298980946887634\n",
      "learning rate for this epoch =  0.1350300853041159\n",
      "Error on this batch = 0.10440896090682071\n",
      "Error on this batch = 0.13895715462504535\n",
      "Cost on val dataset after 189 epochs is = 0.13276588712628068\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.13276588712628068\n",
      "learning rate for this epoch =  0.13485111859503687\n",
      "Error on this batch = 0.10410954129811022\n",
      "Error on this batch = 0.13863540234550129\n",
      "Cost on val dataset after 190 epochs is = 0.1325442270233771\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.1325442270233771\n",
      "learning rate for this epoch =  0.13467333163158285\n",
      "Error on this batch = 0.10381261743820912\n",
      "Error on this batch = 0.13831643961601772\n",
      "Cost on val dataset after 191 epochs is = 0.1323247907082682\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.1323247907082682\n",
      "learning rate for this epoch =  0.13449671048880912\n",
      "Error on this batch = 0.10351814125566947\n",
      "Error on this batch = 0.13800022340071025\n",
      "Cost on val dataset after 192 epochs is = 0.13210754061597887\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.13210754061597887\n",
      "learning rate for this epoch =  0.13432124147794275\n",
      "Error on this batch = 0.10322606599976589\n",
      "Error on this batch = 0.1376867115361211\n",
      "Cost on val dataset after 193 epochs is = 0.1318924400427347\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.1318924400427347\n",
      "learning rate for this epoch =  0.1341469111411715\n",
      "Error on this batch = 0.10293634620877586\n",
      "Error on this batch = 0.13737586270640445\n",
      "Cost on val dataset after 194 epochs is = 0.13167945312116036\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.13167945312116036\n",
      "learning rate for this epoch =  0.13397370624657456\n",
      "Error on this batch = 0.10264893767855936\n",
      "Error on this batch = 0.1370676364195491\n",
      "Cost on val dataset after 195 epochs is = 0.13146854479635756\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.13146854479635756\n",
      "learning rate for this epoch =  0.13380161378318955\n",
      "Error on this batch = 0.10236379743146336\n",
      "Error on this batch = 0.13676199298458766\n",
      "Cost on val dataset after 196 epochs is = 0.13125968080282402\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.13125968080282402\n",
      "learning rate for this epoch =  0.1336306209562122\n",
      "Error on this batch = 0.10208088368557697\n",
      "Error on this batch = 0.13645889348974233\n",
      "Cost on val dataset after 197 epochs is = 0.13105282764217688\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.13105282764217688\n",
      "learning rate for this epoch =  0.13346071518232402\n",
      "Error on this batch = 0.10180015582436017\n",
      "Error on this batch = 0.13615829978146154\n",
      "Cost on val dataset after 198 epochs is = 0.13084795256164627\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.13084795256164627\n",
      "learning rate for this epoch =  0.13329188408514428\n",
      "Error on this batch = 0.10152157436666706\n",
      "Error on this batch = 0.13586017444430162\n",
      "Cost on val dataset after 199 epochs is = 0.13064502353330637\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.13064502353330637\n",
      "learning rate for this epoch =  0.13312411549080203\n",
      "Error on this batch = 0.10124510093718328\n",
      "Error on this batch = 0.13556448078161137\n",
      "Cost on val dataset after 200 epochs is = 0.13044400923401278\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.13044400923401278\n",
      "learning rate for this epoch =  0.13295739742362472\n",
      "Error on this batch = 0.10097069823729492\n",
      "Error on this batch = 0.13527118279697872\n",
      "Cost on val dataset after 201 epochs is = 0.13024487902601675\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.13024487902601675\n",
      "learning rate for this epoch =  0.13279171810193946\n",
      "Error on this batch = 0.10069833001640481\n",
      "Error on this batch = 0.1349802451764002\n",
      "Cost on val dataset after 202 epochs is = 0.13004760293822887\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.13004760293822887\n",
      "learning rate for this epoch =  0.13262706593398382\n",
      "Error on this batch = 0.10042796104371032\n",
      "Error on this batch = 0.1346916332711373\n",
      "Cost on val dataset after 203 epochs is = 0.12985215164810485\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.12985215164810485\n",
      "learning rate for this epoch =  0.13246342951392248\n",
      "Error on this batch = 0.10015955708045468\n",
      "Error on this batch = 0.1344053130812235\n",
      "Cost on val dataset after 204 epochs is = 0.1296584964641292\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.1296584964641292\n",
      "learning rate for this epoch =  0.13230079761796648\n",
      "Error on this batch = 0.09989308485266288\n",
      "Error on this batch = 0.1341212512395896\n",
      "Cost on val dataset after 205 epochs is = 0.12946660930887183\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.12946660930887183\n",
      "learning rate for this epoch =  0.13213915920059222\n",
      "Error on this batch = 0.0996285120243709\n",
      "Error on this batch = 0.1338394149967754\n",
      "Cost on val dataset after 206 epochs is = 0.1292764627025957\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.1292764627025957\n",
      "learning rate for this epoch =  0.13197850339085695\n",
      "Error on this batch = 0.09936580717135664\n",
      "Error on this batch = 0.13355977220619808\n",
      "Cost on val dataset after 207 epochs is = 0.12908802974739322\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.12908802974739322\n",
      "learning rate for this epoch =  0.1318188194888078\n",
      "Error on this batch = 0.09910493975537797\n",
      "Error on this batch = 0.13328229130994854\n",
      "Cost on val dataset after 208 epochs is = 0.12890128411183105\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.12890128411183105\n",
      "learning rate for this epoch =  0.13166009696198164\n",
      "Error on this batch = 0.09884588009892376\n",
      "Error on this batch = 0.13300694132508956\n",
      "Cost on val dataset after 209 epochs is = 0.12871620001608364\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.12871620001608364\n",
      "learning rate for this epoch =  0.1315023254419931\n",
      "Error on this batch = 0.09858859936048069\n",
      "Error on this batch = 0.13273369183042977\n",
      "Cost on val dataset after 210 epochs is = 0.12853275221753654\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.12853275221753654\n",
      "learning rate for this epoch =  0.1313454947212079\n",
      "Error on this batch = 0.09833306951031912\n",
      "Error on this batch = 0.13246251295375017\n",
      "Cost on val dataset after 211 epochs is = 0.12835091599684206\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.12835091599684206\n",
      "learning rate for this epoch =  0.13118959474949932\n",
      "Error on this batch = 0.09807926330679917\n",
      "Error on this batch = 0.13219337535946\n",
      "Cost on val dataset after 212 epochs is = 0.1281706671444096\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.1281706671444096\n",
      "learning rate for this epoch =  0.1310346156310848\n",
      "Error on this batch = 0.09782715427319721\n",
      "Error on this batch = 0.1319262502366611\n",
      "Cost on val dataset after 213 epochs is = 0.12799198194731512\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.12799198194731512\n",
      "learning rate for this epoch =  0.13088054762144102\n",
      "Error on this batch = 0.09757671667505259\n",
      "Error on this batch = 0.13166110928760041\n",
      "Cost on val dataset after 214 epochs is = 0.1278148371766134\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.1278148371766134\n",
      "learning rate for this epoch =  0.13072738112429463\n",
      "Error on this batch = 0.09732792549803293\n",
      "Error on this batch = 0.13139792471649148\n",
      "Cost on val dataset after 215 epochs is = 0.1276392100750393\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.1276392100750393\n",
      "learning rate for this epoch =  0.1305751066886864\n",
      "Error on this batch = 0.09708075642631574\n",
      "Error on this batch = 0.13113666921868744\n",
      "Cost on val dataset after 216 epochs is = 0.12746507834508247\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.12746507834508247\n",
      "learning rate for this epoch =  0.13042371500610728\n",
      "Error on this batch = 0.09683518582148332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.13087731597018853\n",
      "Cost on val dataset after 217 epochs is = 0.12729242013742334\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.12729242013742334\n",
      "learning rate for this epoch =  0.13027319690770342\n",
      "Error on this batch = 0.09659119070192762\n",
      "Error on this batch = 0.13061983861746781\n",
      "Cost on val dataset after 218 epochs is = 0.1271212140397166\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.1271212140397166\n",
      "learning rate for this epoch =  0.13012354336154894\n",
      "Error on this batch = 0.09634874872276009\n",
      "Error on this batch = 0.13036421126760067\n",
      "Cost on val dataset after 219 epochs is = 0.12695143906570966\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.12695143906570966\n",
      "learning rate for this epoch =  0.12997474546998408\n",
      "Error on this batch = 0.09610783815622219\n",
      "Error on this batch = 0.13011040847868408\n",
      "Cost on val dataset after 220 epochs is = 0.126783074644685\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.126783074644685\n",
      "learning rate for this epoch =  0.12982679446701692\n",
      "Error on this batch = 0.09586843787259092\n",
      "Error on this batch = 0.12985840525053155\n",
      "Cost on val dataset after 221 epochs is = 0.1266161006112141\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.1266161006112141\n",
      "learning rate for this epoch =  0.12967968171578698\n",
      "Error on this batch = 0.09563052732157318\n",
      "Error on this batch = 0.12960817701563232\n",
      "Cost on val dataset after 222 epochs is = 0.12645049719521248\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.12645049719521248\n",
      "learning rate for this epoch =  0.12953339870608896\n",
      "Error on this batch = 0.09539408651418356\n",
      "Error on this batch = 0.1293596996303623\n",
      "Cost on val dataset after 223 epochs is = 0.12628624501228594\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.12628624501228594\n",
      "learning rate for this epoch =  0.12938793705195484\n",
      "Error on this batch = 0.09515909600509759\n",
      "Error on this batch = 0.12911294936643633\n",
      "Cost on val dataset after 224 epochs is = 0.12612332505435664\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.12612332505435664\n",
      "learning rate for this epoch =  0.12924328848929265\n",
      "Error on this batch = 0.0949255368754746\n",
      "Error on this batch = 0.1288679029025907\n",
      "Cost on val dataset after 225 epochs is = 0.1259617186805607\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.1259617186805607\n",
      "learning rate for this epoch =  0.12909944487358055\n",
      "Error on this batch = 0.09469339071624226\n",
      "Error on this batch = 0.12862453731648657\n",
      "Cost on val dataset after 226 epochs is = 0.12580140760840744\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.12580140760840744\n",
      "learning rate for this epoch =  0.1289563981776146\n",
      "Error on this batch = 0.09446263961183533\n",
      "Error on this batch = 0.12838283007682524\n",
      "Cost on val dataset after 227 epochs is = 0.12564237390519173\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.12564237390519173\n",
      "learning rate for this epoch =  0.12881414048930848\n",
      "Error on this batch = 0.0942332661243811\n",
      "Error on this batch = 0.12814275903566624\n",
      "Cost on val dataset after 228 epochs is = 0.12548459997965034\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.12548459997965034\n",
      "learning rate for this epoch =  0.1286726640095442\n",
      "Error on this batch = 0.09400525327832307\n",
      "Error on this batch = 0.1279043024209401\n",
      "Cost on val dataset after 229 epochs is = 0.1253280685738552\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.1253280685738552\n",
      "learning rate for this epoch =  0.12853196105007209\n",
      "Error on this batch = 0.09377858454547539\n",
      "Error on this batch = 0.1276674388291488\n",
      "Cost on val dataset after 230 epochs is = 0.12517276275533457\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.12517276275533457\n",
      "learning rate for this epoch =  0.12839202403145872\n",
      "Error on this batch = 0.0935532438304994\n",
      "Error on this batch = 0.12743214721824575\n",
      "Cost on val dataset after 231 epochs is = 0.1250186659094153\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.1250186659094153\n",
      "learning rate for this epoch =  0.12825284548108173\n",
      "Error on this batch = 0.0933292154567939\n",
      "Error on this batch = 0.1271984069006892\n",
      "Cost on val dataset after 232 epochs is = 0.12486576173177905\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.12486576173177905\n",
      "learning rate for this epoch =  0.1281144180311698\n",
      "Error on this batch = 0.09310648415279106\n",
      "Error on this batch = 0.12696619753666233\n",
      "Cost on val dataset after 233 epochs is = 0.12471403422122447\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.12471403422122447\n",
      "learning rate for this epoch =  0.12797673441688712\n",
      "Error on this batch = 0.0928850350386492\n",
      "Error on this batch = 0.1267354991274543\n",
      "Cost on val dataset after 234 epochs is = 0.12456346767263037\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.12456346767263037\n",
      "learning rate for this epoch =  0.12783978747446093\n",
      "Error on this batch = 0.09266485361333433\n",
      "Error on this batch = 0.1265062920089965\n",
      "Cost on val dataset after 235 epochs is = 0.1244140466701115\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.1244140466701115\n",
      "learning rate for this epoch =  0.12770357013935066\n",
      "Error on this batch = 0.09244592574208145\n",
      "Error on this batch = 0.1262785568455481\n",
      "Cost on val dataset after 236 epochs is = 0.12426575608036242\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.12426575608036242\n",
      "learning rate for this epoch =  0.12756807544445822\n",
      "Error on this batch = 0.09222823764422751\n",
      "Error on this batch = 0.12605227462352714\n",
      "Cost on val dataset after 237 epochs is = 0.12411858104618223\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.12411858104618223\n",
      "learning rate for this epoch =  0.1274332965183777\n",
      "Error on this batch = 0.09201177588140765\n",
      "Error on this batch = 0.1258274266454808\n",
      "Cost on val dataset after 238 epochs is = 0.12397250698017531\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.12397250698017531\n",
      "learning rate for this epoch =  0.12729922658368395\n",
      "Error on this batch = 0.0917965273461056\n",
      "Error on this batch = 0.1256039945241918\n",
      "Cost on val dataset after 239 epochs is = 0.12382751955862199\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.12382751955862199\n",
      "learning rate for this epoch =  0.12716585895525878\n",
      "Error on this batch = 0.09158247925055114\n",
      "Error on this batch = 0.12538196017691555\n",
      "Cost on val dataset after 240 epochs is = 0.12368360471551414\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.12368360471551414\n",
      "learning rate for this epoch =  0.12703318703865368\n",
      "Error on this batch = 0.091369619115955\n",
      "Error on this batch = 0.12516130581974483\n",
      "Cost on val dataset after 241 epochs is = 0.12354074863675014\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.12354074863675014\n",
      "learning rate for this epoch =  0.12690120432848842\n",
      "Error on this batch = 0.09115793476207351\n",
      "Error on this batch = 0.12494201396209781\n",
      "Cost on val dataset after 242 epochs is = 0.12339893775448497\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.12339893775448497\n",
      "learning rate for this epoch =  0.12676990440688446\n",
      "Error on this batch = 0.09094741429709557\n",
      "Error on this batch = 0.12472406740132583\n",
      "Cost on val dataset after 243 epochs is = 0.12325815874162992\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.12325815874162992\n",
      "learning rate for this epoch =  0.12663928094193208\n",
      "Error on this batch = 0.0907380461078424\n",
      "Error on this batch = 0.12450744921743738\n",
      "Cost on val dataset after 244 epochs is = 0.12311839850649768\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.12311839850649768\n",
      "learning rate for this epoch =  0.12650932768619078\n",
      "Error on this batch = 0.0905298188502737\n",
      "Error on this batch = 0.12429214276793568\n",
      "Cost on val dataset after 245 epochs is = 0.12297964418758864\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.12297964418758864\n",
      "learning rate for this epoch =  0.12638003847522164\n",
      "Error on this batch = 0.09032272144029115\n",
      "Error on this batch = 0.12407813168276575\n",
      "Cost on val dataset after 246 epochs is = 0.12284188314851342\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.12284188314851342\n",
      "learning rate for this epoch =  0.1262514072261512\n",
      "Error on this batch = 0.0901167430448327\n",
      "Error on this batch = 0.12386539985936888\n",
      "Cost on val dataset after 247 epochs is = 0.12270510297304821\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.12270510297304821\n",
      "learning rate for this epoch =  0.12612342793626585\n",
      "Error on this batch = 0.08991187307324867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.12365393145784126\n",
      "Cost on val dataset after 248 epochs is = 0.12256929146031857\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.12256929146031857\n",
      "learning rate for this epoch =  0.1259960946816361\n",
      "Error on this batch = 0.08970810116895392\n",
      "Error on this batch = 0.12344371089619412\n",
      "Cost on val dataset after 249 epochs is = 0.12243443662010801\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.12243443662010801\n",
      "learning rate for this epoch =  0.12586940161576976\n",
      "Error on this batch = 0.08950541720134719\n",
      "Error on this batch = 0.12323472284571314\n",
      "Cost on val dataset after 250 epochs is = 0.12230052666828745\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.12230052666828745\n",
      "learning rate for this epoch =  0.12574334296829354\n",
      "Error on this batch = 0.08930381125799147\n",
      "Error on this batch = 0.12302695222641424\n",
      "Cost on val dataset after 251 epochs is = 0.12216755002236222\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.12216755002236222\n",
      "learning rate for this epoch =  0.1256179130436622\n",
      "Error on this batch = 0.08910327363704805\n",
      "Error on this batch = 0.1228203842025934\n",
      "Cost on val dataset after 252 epochs is = 0.12203549529713312\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.12203549529713312\n",
      "learning rate for this epoch =  0.12549310621989482\n",
      "Error on this batch = 0.08890379483995708\n",
      "Error on this batch = 0.12261500417846896\n",
      "Cost on val dataset after 253 epochs is = 0.121904351300468\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.121904351300468\n",
      "learning rate for this epoch =  0.125368916947337\n",
      "Error on this batch = 0.08870536556435847\n",
      "Error on this batch = 0.1224107977939132\n",
      "Cost on val dataset after 254 epochs is = 0.1217741070291806\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.1217741070291806\n",
      "learning rate for this epoch =  0.12524533974744914\n",
      "Error on this batch = 0.08850797669724603\n",
      "Error on this batch = 0.12220775092027182\n",
      "Cost on val dataset after 255 epochs is = 0.12164475166501436\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.12164475166501436\n",
      "learning rate for this epoch =  0.12512236921161915\n",
      "Error on this batch = 0.08831161930834858\n",
      "Error on this batch = 0.12200584965626923\n",
      "Cost on val dataset after 256 epochs is = 0.12151627457072683\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.12151627457072683\n",
      "learning rate for this epoch =  0.125\n",
      "Error on this batch = 0.08811628464373181\n",
      "Error on this batch = 0.12180508032399726\n",
      "Cost on val dataset after 257 epochs is = 0.12138866528627282\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.12138866528627282\n",
      "learning rate for this epoch =  0.12487822684037092\n",
      "Error on this batch = 0.08792196411961445\n",
      "Error on this batch = 0.12160542946498605\n",
      "Cost on val dataset after 258 epochs is = 0.12126191352508314\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.12126191352508314\n",
      "learning rate for this epoch =  0.12475704452702165\n",
      "Error on this batch = 0.08772864931639311\n",
      "Error on this batch = 0.12140688383635485\n",
      "Cost on val dataset after 259 epochs is = 0.1211360091704362\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.1211360091704362\n",
      "learning rate for this epoch =  0.12463644791965951\n",
      "Error on this batch = 0.08753633197286956\n",
      "Error on this batch = 0.12120943040704102\n",
      "Cost on val dataset after 260 epochs is = 0.12101094227191987\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.12101094227191987\n",
      "learning rate for this epoch =  0.12451643194233865\n",
      "Error on this batch = 0.0873450039806746\n",
      "Error on this batch = 0.12101305635410567\n",
      "Cost on val dataset after 261 epochs is = 0.12088670304198106\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.12088670304198106\n",
      "learning rate for this epoch =  0.12439699158241055\n",
      "Error on this batch = 0.08715465737888405\n",
      "Error on this batch = 0.12081774905911437\n",
      "Cost on val dataset after 262 epochs is = 0.12076328185256037\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.12076328185256037\n",
      "learning rate for this epoch =  0.12427812188949586\n",
      "Error on this batch = 0.08696528434881927\n",
      "Error on this batch = 0.1206234961045908\n",
      "Cost on val dataset after 263 epochs is = 0.12064066923180998\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.12064066923180998\n",
      "learning rate for this epoch =  0.1241598179744767\n",
      "Error on this batch = 0.08677687720902924\n",
      "Error on this batch = 0.12043028527054254\n",
      "Cost on val dataset after 264 epochs is = 0.12051885586089177\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.12051885586089177\n",
      "learning rate for this epoch =  0.12404207500850907\n",
      "Error on this batch = 0.08658942841044724\n",
      "Error on this batch = 0.12023810453105682\n",
      "Cost on val dataset after 265 epochs is = 0.12039783257085376\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.12039783257085376\n",
      "learning rate for this epoch =  0.12392488822205483\n",
      "Error on this batch = 0.08640293053171803\n",
      "Error on this batch = 0.12004694205096485\n",
      "Cost on val dataset after 266 epochs is = 0.12027759033958312\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.12027759033958312\n",
      "learning rate for this epoch =  0.12380825290393263\n",
      "Error on this batch = 0.0862173762746903\n",
      "Error on this batch = 0.11985678618257381\n",
      "Cost on val dataset after 267 epochs is = 0.12015812028883262\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.12015812028883262\n",
      "learning rate for this epoch =  0.12369216440038802\n",
      "Error on this batch = 0.08603275846006941\n",
      "Error on this batch = 0.1196676254624644\n",
      "Cost on val dataset after 268 epochs is = 0.1200394136813196\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.1200394136813196\n",
      "learning rate for this epoch =  0.1235766181141811\n",
      "Error on this batch = 0.08584907002322664\n",
      "Error on this batch = 0.11947944860835286\n",
      "Cost on val dataset after 269 epochs is = 0.11992146191789484\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.11992146191789484\n",
      "learning rate for this epoch =  0.12346160950369273\n",
      "Error on this batch = 0.08566630401015847\n",
      "Error on this batch = 0.1192922445160162\n",
      "Cost on val dataset after 270 epochs is = 0.11980425653477957\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.11980425653477957\n",
      "learning rate for this epoch =  0.12334713408204756\n",
      "Error on this batch = 0.08548445357359395\n",
      "Error on this batch = 0.11910600225627899\n",
      "Cost on val dataset after 271 epochs is = 0.1196877892008687\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.1196877892008687\n",
      "learning rate for this epoch =  0.12323318741625437\n",
      "Error on this batch = 0.08530351196924403\n",
      "Error on this batch = 0.11892071107206122\n",
      "Cost on val dataset after 272 epochs is = 0.11957205171509877\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.11957205171509877\n",
      "learning rate for this epoch =  0.12311976512636309\n",
      "Error on this batch = 0.08512347255218906\n",
      "Error on this batch = 0.11873636037548431\n",
      "Cost on val dataset after 273 epochs is = 0.1194570360038785\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.1194570360038785\n",
      "learning rate for this epoch =  0.12300686288463769\n",
      "Error on this batch = 0.08494432877340084\n",
      "Error on this batch = 0.11855293974503639\n",
      "Cost on val dataset after 274 epochs is = 0.11934273411858044\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.11934273411858044\n",
      "learning rate for this epoch =  0.12289447641474543\n",
      "Error on this batch = 0.08476607417639474\n",
      "Error on this batch = 0.1183704389227933\n",
      "Cost on val dataset after 275 epochs is = 0.11922913823309221\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.11922913823309221\n",
      "learning rate for this epoch =  0.12278260149096118\n",
      "Error on this batch = 0.08458870239400831\n",
      "Error on this batch = 0.1181888478116957\n",
      "Cost on val dataset after 276 epochs is = 0.11911624064142529\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.11911624064142529\n",
      "learning rate for this epoch =  0.12267123393738709\n",
      "Error on this batch = 0.08441220714530216\n",
      "Error on this batch = 0.11800815647288043\n",
      "Cost on val dataset after 277 epochs is = 0.11900403375538036\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.11900403375538036\n",
      "learning rate for this epoch =  0.12256036962718717\n",
      "Error on this batch = 0.08423658223258017\n",
      "Error on this batch = 0.1178283551230653\n",
      "Cost on val dataset after 278 epochs is = 0.11889251010226755\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.11889251010226755\n",
      "learning rate for this epoch =  0.12245000448183609\n",
      "Error on this batch = 0.08406182153852441\n",
      "Error on this batch = 0.11764943413198588\n",
      "Cost on val dataset after 279 epochs is = 0.1187816623226796\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.1187816623226796\n",
      "learning rate for this epoch =  0.12234013447038239\n",
      "Error on this batch = 0.08388791902344261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11747138401988325\n",
      "Cost on val dataset after 280 epochs is = 0.11867148316831756\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.11867148316831756\n",
      "learning rate for this epoch =  0.12223075560872526\n",
      "Error on this batch = 0.08371486872262317\n",
      "Error on this batch = 0.11729419545504213\n",
      "Cost on val dataset after 281 epochs is = 0.11856196549986651\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.11856196549986651\n",
      "learning rate for this epoch =  0.12212186395890517\n",
      "Error on this batch = 0.08354266474379603\n",
      "Error on this batch = 0.11711785925137758\n",
      "Cost on val dataset after 282 epochs is = 0.11845310228492097\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.11845310228492097\n",
      "learning rate for this epoch =  0.12201345562840739\n",
      "Error on this batch = 0.0833713012646946\n",
      "Error on this batch = 0.11694236636606978\n",
      "Cost on val dataset after 283 epochs is = 0.11834488659595803\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.11834488659595803\n",
      "learning rate for this epoch =  0.12190552676947876\n",
      "Error on this batch = 0.08320077253071702\n",
      "Error on this batch = 0.11676770789724569\n",
      "Cost on val dataset after 284 epochs is = 0.11823731160835714\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.11823731160835714\n",
      "learning rate for this epoch =  0.12179807357845675\n",
      "Error on this batch = 0.08303107285268262\n",
      "Error on this batch = 0.11659387508170671\n",
      "Cost on val dataset after 285 epochs is = 0.11813037059846573\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.11813037059846573\n",
      "learning rate for this epoch =  0.12169109229511134\n",
      "Error on this batch = 0.08286219660468107\n",
      "Error on this batch = 0.1164208592927011\n",
      "Cost on val dataset after 286 epochs is = 0.11802405694170864\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.11802405694170864\n",
      "learning rate for this epoch =  0.12158457920199858\n",
      "Error on this batch = 0.08269413822201106\n",
      "Error on this batch = 0.11624865203774049\n",
      "Cost on val dataset after 287 epochs is = 0.11791836411074118\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.11791836411074118\n",
      "learning rate for this epoch =  0.1214785306238262\n",
      "Error on this batch = 0.08252689219920614\n",
      "Error on this batch = 0.11607724495645957\n",
      "Cost on val dataset after 288 epochs is = 0.11781328567364395\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.11781328567364395\n",
      "learning rate for this epoch =  0.12137294292683086\n",
      "Error on this batch = 0.08236045308814399\n",
      "Error on this batch = 0.11590662981851788\n",
      "Cost on val dataset after 289 epochs is = 0.11770881529215864\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.11770881529215864\n",
      "learning rate for this epoch =  0.12126781251816648\n",
      "Error on this batch = 0.08219481549623762\n",
      "Error on this batch = 0.1157367985215426\n",
      "Cost on val dataset after 290 epochs is = 0.117604946719964\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.117604946719964\n",
      "learning rate for this epoch =  0.121163135845304\n",
      "Error on this batch = 0.08202997408470473\n",
      "Error on this batch = 0.11556774308911223\n",
      "Cost on val dataset after 291 epochs is = 0.11750167380099028\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.11750167380099028\n",
      "learning rate for this epoch =  0.12105890939544156\n",
      "Error on this batch = 0.08186592356691329\n",
      "Error on this batch = 0.11539945566877925\n",
      "Cost on val dataset after 292 epochs is = 0.11739899046777208\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.11739899046777208\n",
      "learning rate for this epoch =  0.1209551296949258\n",
      "Error on this batch = 0.08170265870680064\n",
      "Error on this batch = 0.11523192853013192\n",
      "Cost on val dataset after 293 epochs is = 0.11729689073983766\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.11729689073983766\n",
      "learning rate for this epoch =  0.12085179330868305\n",
      "Error on this batch = 0.08154017431736386\n",
      "Error on this batch = 0.11506515406289364\n",
      "Cost on val dataset after 294 epochs is = 0.11719536872213468\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.11719536872213468\n",
      "learning rate for this epoch =  0.12074889683966107\n",
      "Error on this batch = 0.08137846525921823\n",
      "Error on this batch = 0.11489912477505929\n",
      "Cost on val dataset after 295 epochs is = 0.11709441860349067\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.11709441860349067\n",
      "learning rate for this epoch =  0.12064643692828043\n",
      "Error on this batch = 0.08121752643922271\n",
      "Error on this batch = 0.11473383329106834\n",
      "Cost on val dataset after 296 epochs is = 0.11699403465510812\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.11699403465510812\n",
      "learning rate for this epoch =  0.120544410251896\n",
      "Error on this batch = 0.08105735280916887\n",
      "Error on this batch = 0.11456927235001266\n",
      "Cost on val dataset after 297 epochs is = 0.11689421122909249\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.11689421122909249\n",
      "learning rate for this epoch =  0.12044281352426756\n",
      "Error on this batch = 0.08089793936453196\n",
      "Error on this batch = 0.11440543480387959\n",
      "Cost on val dataset after 298 epochs is = 0.1167949427570132\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.1167949427570132\n",
      "learning rate for this epoch =  0.12034164349504001\n",
      "Error on this batch = 0.08073928114328133\n",
      "Error on this batch = 0.11424231361582879\n",
      "Cost on val dataset after 299 epochs is = 0.11669622374849617\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.11669622374849617\n",
      "learning rate for this epoch =  0.12024089694923273\n",
      "Error on this batch = 0.0805813732247485\n",
      "Error on this batch = 0.11407990185850203\n",
      "Cost on val dataset after 300 epochs is = 0.1165980487898471\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.1165980487898471\n",
      "learning rate for this epoch =  0.12014057070673773\n",
      "Error on this batch = 0.08042421072855045\n",
      "Error on this batch = 0.113918192712366\n",
      "Cost on val dataset after 301 epochs is = 0.11650041254270548\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.11650041254270548\n",
      "learning rate for this epoch =  0.1200406616218266\n",
      "Error on this batch = 0.08026778881356667\n",
      "Error on this batch = 0.11375717946408631\n",
      "Cost on val dataset after 302 epochs is = 0.11640330974272747\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.11640330974272747\n",
      "learning rate for this epoch =  0.11994116658266626\n",
      "Error on this batch = 0.08011210267696688\n",
      "Error on this batch = 0.11359685550493281\n",
      "Cost on val dataset after 303 epochs is = 0.11630673519829803\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.11630673519829803\n",
      "learning rate for this epoch =  0.1198420825108428\n",
      "Error on this batch = 0.07995714755328914\n",
      "Error on this batch = 0.11343721432921537\n",
      "Cost on val dataset after 304 epochs is = 0.11621068378927069\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.11621068378927069\n",
      "learning rate for this epoch =  0.11974340636089367\n",
      "Error on this batch = 0.07980291871356468\n",
      "Error on this batch = 0.11327824953274894\n",
      "Cost on val dataset after 305 epochs is = 0.11611515046573496\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.11611515046573496\n",
      "learning rate for this epoch =  0.11964513511984808\n",
      "Error on this batch = 0.0796494114644891\n",
      "Error on this batch = 0.11311995481134808\n",
      "Cost on val dataset after 306 epochs is = 0.11602013024681049\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.11602013024681049\n",
      "learning rate for this epoch =  0.11954726580677509\n",
      "Error on this batch = 0.07949662114763709\n",
      "Error on this batch = 0.1129623239593495\n",
      "Cost on val dataset after 307 epochs is = 0.1159256182194671\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.1159256182194671\n",
      "learning rate for this epoch =  0.11944979547233951\n",
      "Error on this batch = 0.07934454313871991\n",
      "Error on this batch = 0.11280535086816258\n",
      "Cost on val dataset after 308 epochs is = 0.11583160953737046\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.11583160953737046\n",
      "learning rate for this epoch =  0.1193527211983654\n",
      "Error on this batch = 0.07919317284688278\n",
      "Error on this batch = 0.11264902952484648\n",
      "Cost on val dataset after 309 epochs is = 0.1157380994197526\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.1157380994197526\n",
      "learning rate for this epoch =  0.11925604009740705\n",
      "Error on this batch = 0.07904250571404176\n",
      "Error on this batch = 0.1124933540107142\n",
      "Cost on val dataset after 310 epochs is = 0.11564508315030667\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.11564508315030667\n",
      "learning rate for this epoch =  0.11915974931232703\n",
      "Error on this batch = 0.07889253721425739\n",
      "Error on this batch = 0.11233831849996215\n",
      "Cost on val dataset after 311 epochs is = 0.11555255607610555\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.11555255607610555\n",
      "learning rate for this epoch =  0.1190638460158816\n",
      "Error on this batch = 0.07874326285314445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11218391725832491\n",
      "Cost on val dataset after 312 epochs is = 0.11546051360654346\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.11546051360654346\n",
      "learning rate for this epoch =  0.11896832741031306\n",
      "Error on this batch = 0.07859467816731569\n",
      "Error on this batch = 0.11203014464175459\n",
      "Cost on val dataset after 313 epochs is = 0.11536895121230037\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.11536895121230037\n",
      "learning rate for this epoch =  0.11887319072694875\n",
      "Error on this batch = 0.07844677872385844\n",
      "Error on this batch = 0.11187699509512429\n",
      "Cost on val dataset after 314 epochs is = 0.11527786442432844\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.11527786442432844\n",
      "learning rate for this epoch =  0.11877843322580707\n",
      "Error on this batch = 0.07829956011984222\n",
      "Error on this batch = 0.11172446315095468\n",
      "Cost on val dataset after 315 epochs is = 0.1151872488328602\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.1151872488328602\n",
      "learning rate for this epoch =  0.11868405219520976\n",
      "Error on this batch = 0.07815301798185677\n",
      "Error on this batch = 0.1115725434281637\n",
      "Cost on val dataset after 316 epochs is = 0.11509710008643759\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.11509710008643759\n",
      "learning rate for this epoch =  0.11859004495140096\n",
      "Error on this batch = 0.07800714796557788\n",
      "Error on this batch = 0.11142123063083831\n",
      "Cost on val dataset after 317 epochs is = 0.11500741389096213\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.11500741389096213\n",
      "learning rate for this epoch =  0.11849640883817222\n",
      "Error on this batch = 0.07786194575536116\n",
      "Error on this batch = 0.11127051954702794\n",
      "Cost on val dataset after 318 epochs is = 0.11491818600876473\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.11491818600876473\n",
      "learning rate for this epoch =  0.11840314122649412\n",
      "Error on this batch = 0.07771740706386124\n",
      "Error on this batch = 0.1111204050475589\n",
      "Cost on val dataset after 319 epochs is = 0.11482941225769569\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.11482941225769569\n",
      "learning rate for this epoch =  0.11831023951415345\n",
      "Error on this batch = 0.07757352763167594\n",
      "Error on this batch = 0.11097088208486973\n",
      "Cost on val dataset after 320 epochs is = 0.11474108851023371\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.11474108851023371\n",
      "learning rate for this epoch =  0.11821770112539698\n",
      "Error on this batch = 0.0774303032270139\n",
      "Error on this batch = 0.11082194569186612\n",
      "Cost on val dataset after 321 epochs is = 0.114653210692614\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.114653210692614\n",
      "learning rate for this epoch =  0.11812552351058042\n",
      "Error on this batch = 0.0772877296453843\n",
      "Error on this batch = 0.11067359098079557\n",
      "Cost on val dataset after 322 epochs is = 0.11456577478397462\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.11456577478397462\n",
      "learning rate for this epoch =  0.11803370414582362\n",
      "Error on this batch = 0.07714580270930813\n",
      "Error on this batch = 0.11052581314214083\n",
      "Cost on val dataset after 323 epochs is = 0.11447877681552106\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.11447877681552106\n",
      "learning rate for this epoch =  0.11794224053267104\n",
      "Error on this batch = 0.07700451826804938\n",
      "Error on this batch = 0.11037860744353176\n",
      "Cost on val dataset after 324 epochs is = 0.11439221286970841\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.11439221286970841\n",
      "learning rate for this epoch =  0.11785113019775793\n",
      "Error on this batch = 0.07686387219736533\n",
      "Error on this batch = 0.11023196922867523\n",
      "Cost on val dataset after 325 epochs is = 0.11430607907944078\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.11430607907944078\n",
      "learning rate for this epoch =  0.11776037069248181\n",
      "Error on this batch = 0.07672386039927483\n",
      "Error on this batch = 0.1100858939163023\n",
      "Cost on val dataset after 326 epochs is = 0.1142203716272876\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.1142203716272876\n",
      "learning rate for this epoch =  0.11766995959267931\n",
      "Error on this batch = 0.07658447880184359\n",
      "Error on this batch = 0.10994037699913206\n",
      "Cost on val dataset after 327 epochs is = 0.11413508674471655\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.11413508674471655\n",
      "learning rate for this epoch =  0.11757989449830816\n",
      "Error on this batch = 0.0764457233589857\n",
      "Error on this batch = 0.10979541404285215\n",
      "Cost on val dataset after 328 epochs is = 0.11405022071134265\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.11405022071134265\n",
      "learning rate for this epoch =  0.11749017303313421\n",
      "Error on this batch = 0.0763075900502802\n",
      "Error on this batch = 0.10965100068511503\n",
      "Cost on val dataset after 329 epochs is = 0.11396576985419285\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.11396576985419285\n",
      "learning rate for this epoch =  0.11740079284442367\n",
      "Error on this batch = 0.07617007488080192\n",
      "Error on this batch = 0.10950713263454954\n",
      "Cost on val dataset after 330 epochs is = 0.11388173054698676\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.11388173054698676\n",
      "learning rate for this epoch =  0.11731175160264\n",
      "Error on this batch = 0.07603317388096563\n",
      "Error on this batch = 0.10936380566978755\n",
      "Cost on val dataset after 331 epochs is = 0.1137980992094319\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.1137980992094319\n",
      "learning rate for this epoch =  0.11722304700114572\n",
      "Error on this batch = 0.07589688310638301\n",
      "Error on this batch = 0.10922101563850489\n",
      "Cost on val dataset after 332 epochs is = 0.113714872306534\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.113714872306534\n",
      "learning rate for this epoch =  0.11713467675590904\n",
      "Error on this batch = 0.07576119863773126\n",
      "Error on this batch = 0.10907875845647647\n",
      "Cost on val dataset after 333 epochs is = 0.11363204634792186\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.11363204634792186\n",
      "learning rate for this epoch =  0.11704663860521486\n",
      "Error on this batch = 0.07562611658063248\n",
      "Error on this batch = 0.10893703010664446\n",
      "Cost on val dataset after 334 epochs is = 0.11354961788718637\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.11354961788718637\n",
      "learning rate for this epoch =  0.1169589303093807\n",
      "Error on this batch = 0.07549163306554382\n",
      "Error on this batch = 0.10879582663820024\n",
      "Cost on val dataset after 335 epochs is = 0.11346758352123341\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.11346758352123341\n",
      "learning rate for this epoch =  0.11687154965047665\n",
      "Error on this batch = 0.0753577442476567\n",
      "Error on this batch = 0.10865514416567827\n",
      "Cost on val dataset after 336 epochs is = 0.11338593988965018\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.11338593988965018\n",
      "learning rate for this epoch =  0.11678449443205002\n",
      "Error on this batch = 0.07522444630680501\n",
      "Error on this batch = 0.10851497886806272\n",
      "Cost on val dataset after 337 epochs is = 0.11330468367408511\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.11330468367408511\n",
      "learning rate for this epoch =  0.11669776247885426\n",
      "Error on this batch = 0.07509173544738174\n",
      "Error on this batch = 0.10837532698790542\n",
      "Cost on val dataset after 338 epochs is = 0.11322381159764051\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.11322381159764051\n",
      "learning rate for this epoch =  0.1166113516365818\n",
      "Error on this batch = 0.07495960789826278\n",
      "Error on this batch = 0.1082361848304556\n",
      "Cost on val dataset after 339 epochs is = 0.11314332042427808\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.11314332042427808\n",
      "learning rate for this epoch =  0.1165252597716015\n",
      "Error on this batch = 0.07482805991273794\n",
      "Error on this batch = 0.10809754876280016\n",
      "Cost on val dataset after 340 epochs is = 0.11306320695823673\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.11306320695823673\n",
      "learning rate for this epoch =  0.11643948477069971\n",
      "Error on this batch = 0.07469708776844815\n",
      "Error on this batch = 0.10795941521301479\n",
      "Cost on val dataset after 341 epochs is = 0.11298346804346276\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.11298346804346276\n",
      "learning rate for this epoch =  0.11635402454082565\n",
      "Error on this batch = 0.07456668776732854\n",
      "Error on this batch = 0.1078217806693251\n",
      "Cost on val dataset after 342 epochs is = 0.11290410056305177\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.11290410056305177\n",
      "learning rate for this epoch =  0.1162688770088405\n",
      "Error on this batch = 0.07443685623555676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1076846416792776\n",
      "Cost on val dataset after 343 epochs is = 0.11282510143870231\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.11282510143870231\n",
      "learning rate for this epoch =  0.11618404012127041\n",
      "Error on this batch = 0.07430758952350607\n",
      "Error on this batch = 0.10754799484892004\n",
      "Cost on val dataset after 344 epochs is = 0.11274646763018073\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.11274646763018073\n",
      "learning rate for this epoch =  0.11609951184406334\n",
      "Error on this batch = 0.07417888400570234\n",
      "Error on this batch = 0.10741183684199085\n",
      "Cost on val dataset after 345 epochs is = 0.11266819613479744\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.11266819613479744\n",
      "learning rate for this epoch =  0.11601529016234945\n",
      "Error on this batch = 0.07405073608078525\n",
      "Error on this batch = 0.10727616437911706\n",
      "Cost on val dataset after 346 epochs is = 0.11259028398689384\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.11259028398689384\n",
      "learning rate for this epoch =  0.11593137308020533\n",
      "Error on this batch = 0.0739231421714726\n",
      "Error on this batch = 0.10714097423702092\n",
      "Cost on val dataset after 347 epochs is = 0.11251272825733986\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.11251272825733986\n",
      "learning rate for this epoch =  0.11584775862042163\n",
      "Error on this batch = 0.07379609872452723\n",
      "Error on this batch = 0.10700626324773428\n",
      "Cost on val dataset after 348 epochs is = 0.11243552605304187\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.11243552605304187\n",
      "learning rate for this epoch =  0.11576444482427425\n",
      "Error on this batch = 0.07366960221072684\n",
      "Error on this batch = 0.1068720282978207\n",
      "Cost on val dataset after 349 epochs is = 0.11235867451646099\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.11235867451646099\n",
      "learning rate for this epoch =  0.11568142975129903\n",
      "Error on this batch = 0.07354364912483545\n",
      "Error on this batch = 0.10673826632760496\n",
      "Cost on val dataset after 350 epochs is = 0.11228217082514091\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.11228217082514091\n",
      "learning rate for this epoch =  0.11559871147906978\n",
      "Error on this batch = 0.07341823598557681\n",
      "Error on this batch = 0.10660497433040966\n",
      "Cost on val dataset after 351 epochs is = 0.11220601219124576\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.11220601219124576\n",
      "learning rate for this epoch =  0.11551628810297963\n",
      "Error on this batch = 0.0732933593356088\n",
      "Error on this batch = 0.1064721493517985\n",
      "Cost on val dataset after 352 epochs is = 0.11213019586110705\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.11213019586110705\n",
      "learning rate for this epoch =  0.11543415773602565\n",
      "Error on this batch = 0.07316901574149914\n",
      "Error on this batch = 0.10633978848882628\n",
      "Cost on val dataset after 353 epochs is = 0.11205471911478018\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.11205471911478018\n",
      "learning rate for this epoch =  0.11535231850859669\n",
      "Error on this batch = 0.07304520179370154\n",
      "Error on this batch = 0.10620788888929479\n",
      "Cost on val dataset after 354 epochs is = 0.11197957926560959\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.11197957926560959\n",
      "learning rate for this epoch =  0.11527076856826429\n",
      "Error on this batch = 0.07292191410653207\n",
      "Error on this batch = 0.10607644775101506\n",
      "Cost on val dataset after 355 epochs is = 0.11190477365980316\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.11190477365980316\n",
      "learning rate for this epoch =  0.1151895060795769\n",
      "Error on this batch = 0.07279914931814563\n",
      "Error on this batch = 0.10594546232107505\n",
      "Cost on val dataset after 356 epochs is = 0.1118302996760145\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.1118302996760145\n",
      "learning rate for this epoch =  0.11510852922385682\n",
      "Error on this batch = 0.07267690409051249\n",
      "Error on this batch = 0.10581492989511279\n",
      "Cost on val dataset after 357 epochs is = 0.11175615472493422\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.11175615472493422\n",
      "learning rate for this epoch =  0.11502783619900045\n",
      "Error on this batch = 0.07255517510939356\n",
      "Error on this batch = 0.10568484781659511\n",
      "Cost on val dataset after 358 epochs is = 0.11168233624888896\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.11168233624888896\n",
      "learning rate for this epoch =  0.11494742521928122\n",
      "Error on this batch = 0.07243395908431569\n",
      "Error on this batch = 0.10555521347610086\n",
      "Cost on val dataset after 359 epochs is = 0.11160884172144837\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.11160884172144837\n",
      "learning rate for this epoch =  0.11486729451515557\n",
      "Error on this batch = 0.07231325274854541\n",
      "Error on this batch = 0.10542602431060961\n",
      "Cost on val dataset after 360 epochs is = 0.1115356686470399\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.1115356686470399\n",
      "learning rate for this epoch =  0.11478744233307164\n",
      "Error on this batch = 0.07219305285906172\n",
      "Error on this batch = 0.10529727780279441\n",
      "Cost on val dataset after 361 epochs is = 0.11146281456057107\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.11146281456057107\n",
      "learning rate for this epoch =  0.11470786693528087\n",
      "Error on this batch = 0.07207335619652713\n",
      "Error on this batch = 0.10516897148031934\n",
      "Cost on val dataset after 362 epochs is = 0.1113902770270589\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.1113902770270589\n",
      "learning rate for this epoch =  0.11462856659965227\n",
      "Error on this batch = 0.07195415956525761\n",
      "Error on this batch = 0.1050411029151413\n",
      "Cost on val dataset after 363 epochs is = 0.11131805364126655\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.11131805364126655\n",
      "learning rate for this epoch =  0.11454953961948931\n",
      "Error on this batch = 0.07183545979319\n",
      "Error on this batch = 0.10491366972281566\n",
      "Cost on val dataset after 364 epochs is = 0.11124614202734706\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.11124614202734706\n",
      "learning rate for this epoch =  0.11447078430334955\n",
      "Error on this batch = 0.07171725373184812\n",
      "Error on this batch = 0.10478666956180639\n",
      "Cost on val dataset after 365 epochs is = 0.11117453983849312\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.11117453983849312\n",
      "learning rate for this epoch =  0.11439229897486693\n",
      "Error on this batch = 0.07159953825630609\n",
      "Error on this batch = 0.10466010013279937\n",
      "Cost on val dataset after 366 epochs is = 0.11110324475659436\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.11110324475659436\n",
      "learning rate for this epoch =  0.11431408197257639\n",
      "Error on this batch = 0.07148231026515\n",
      "Error on this batch = 0.1045339591780201\n",
      "Cost on val dataset after 367 epochs is = 0.1110322544918999\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.1110322544918999\n",
      "learning rate for this epoch =  0.11423613164974125\n",
      "Error on this batch = 0.0713655666804365\n",
      "Error on this batch = 0.10440824448055441\n",
      "Cost on val dataset after 368 epochs is = 0.11096156678268784\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.11096156678268784\n",
      "learning rate for this epoch =  0.11415844637418282\n",
      "Error on this batch = 0.07124930444764932\n",
      "Error on this batch = 0.1042829538636729\n",
      "Cost on val dataset after 369 epochs is = 0.11089117939494025\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.11089117939494025\n",
      "learning rate for this epoch =  0.11408102452811265\n",
      "Error on this batch = 0.07113352053565289\n",
      "Error on this batch = 0.10415808519015883\n",
      "Cost on val dataset after 370 epochs is = 0.11082109012202401\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.11082109012202401\n",
      "learning rate for this epoch =  0.11400386450796704\n",
      "Error on this batch = 0.07101821193664326\n",
      "Error on this batch = 0.1040336363616392\n",
      "Cost on val dataset after 371 epochs is = 0.11075129678437728\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.11075129678437728\n",
      "learning rate for this epoch =  0.11392696472424395\n",
      "Error on this batch = 0.07090337566609606\n",
      "Error on this batch = 0.10390960531791915\n",
      "Cost on val dataset after 372 epochs is = 0.11068179722920125\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.11068179722920125\n",
      "learning rate for this epoch =  0.11385032360134212\n",
      "Error on this batch = 0.07078900876271164\n",
      "Error on this batch = 0.10378599003631914\n",
      "Cost on val dataset after 373 epochs is = 0.11061258933015734\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.11061258933015734\n",
      "learning rate for this epoch =  0.11377393957740255\n",
      "Error on this batch = 0.07067510828835719\n",
      "Error on this batch = 0.10366278853101597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 374 epochs is = 0.11054367098706898\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.11054367098706898\n",
      "learning rate for this epoch =  0.11369781110415222\n",
      "Error on this batch = 0.07056167132800545\n",
      "Error on this batch = 0.10353999885238611\n",
      "Cost on val dataset after 375 epochs is = 0.11047504012562868\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.11047504012562868\n",
      "learning rate for this epoch =  0.11362193664674994\n",
      "Error on this batch = 0.07044869498967085\n",
      "Error on this batch = 0.10341761908635239\n",
      "Cost on val dataset after 376 epochs is = 0.11040669469710965\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.11040669469710965\n",
      "learning rate for this epoch =  0.11354631468363437\n",
      "Error on this batch = 0.070336176404342\n",
      "Error on this batch = 0.10329564735373375\n",
      "Cost on val dataset after 377 epochs is = 0.11033863267808183\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.11033863267808183\n",
      "learning rate for this epoch =  0.1134709437063741\n",
      "Error on this batch = 0.07022411272591116\n",
      "Error on this batch = 0.10317408180959783\n",
      "Cost on val dataset after 378 epochs is = 0.11027085207013229\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.11027085207013229\n",
      "learning rate for this epoch =  0.11339582221952002\n",
      "Error on this batch = 0.07011250113110042\n",
      "Error on this batch = 0.10305292064261642\n",
      "Cost on val dataset after 379 epochs is = 0.11020335089959002\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.11020335089959002\n",
      "learning rate for this epoch =  0.11332094874045952\n",
      "Error on this batch = 0.07000133881938457\n",
      "Error on this batch = 0.10293216207442427\n",
      "Cost on val dataset after 380 epochs is = 0.11013612721725441\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.11013612721725441\n",
      "learning rate for this epoch =  0.1132463217992727\n",
      "Error on this batch = 0.06989062301291092\n",
      "Error on this batch = 0.1028118043589803\n",
      "Cost on val dataset after 381 epochs is = 0.11006917909812773\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.11006917909812773\n",
      "learning rate for this epoch =  0.11317193993859079\n",
      "Error on this batch = 0.06978035095641541\n",
      "Error on this batch = 0.10269184578193226\n",
      "Cost on val dataset after 382 epochs is = 0.11000250464115154\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.11000250464115154\n",
      "learning rate for this epoch =  0.11309780171345626\n",
      "Error on this batch = 0.06967051991713596\n",
      "Error on this batch = 0.10257228465998437\n",
      "Cost on val dataset after 383 epochs is = 0.1099361019689461\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.1099361019689461\n",
      "learning rate for this epoch =  0.11302390569118509\n",
      "Error on this batch = 0.06956112718472204\n",
      "Error on this batch = 0.10245311934026763\n",
      "Cost on val dataset after 384 epochs is = 0.10986996922755377\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.10986996922755377\n",
      "learning rate for this epoch =  0.11295025045123061\n",
      "Error on this batch = 0.06945217007114142\n",
      "Error on this batch = 0.10233434819971363\n",
      "Cost on val dataset after 385 epochs is = 0.1098041045861851\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.1098041045861851\n",
      "learning rate for this epoch =  0.11287683458504956\n",
      "Error on this batch = 0.0693436459105835\n",
      "Error on this batch = 0.10221596964443119\n",
      "Cost on val dataset after 386 epochs is = 0.10973850623696844\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.10973850623696844\n",
      "learning rate for this epoch =  0.11280365669596971\n",
      "Error on this batch = 0.06923555205935947\n",
      "Error on this batch = 0.1020979821090865\n",
      "Cost on val dataset after 387 epochs is = 0.10967317239470213\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.10967317239470213\n",
      "learning rate for this epoch =  0.11273071539905938\n",
      "Error on this batch = 0.06912788589579917\n",
      "Error on this batch = 0.10198038405628605\n",
      "Cost on val dataset after 388 epochs is = 0.10960810129660985\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.10960810129660985\n",
      "learning rate for this epoch =  0.11265800932099873\n",
      "Error on this batch = 0.06902064482014517\n",
      "Error on this batch = 0.10186317397596341\n",
      "Cost on val dataset after 389 epochs is = 0.1095432912020982\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.1095432912020982\n",
      "learning rate for this epoch =  0.11258553709995278\n",
      "Error on this batch = 0.06891382625444352\n",
      "Error on this batch = 0.10174635038476874\n",
      "Cost on val dataset after 390 epochs is = 0.10947874039251715\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.10947874039251715\n",
      "learning rate for this epoch =  0.11251329738544609\n",
      "Error on this batch = 0.06880742764243147\n",
      "Error on this batch = 0.10162991182546229\n",
      "Cost on val dataset after 391 epochs is = 0.10941444717092269\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.10941444717092269\n",
      "learning rate for this epoch =  0.11244128883823923\n",
      "Error on this batch = 0.0687014464494225\n",
      "Error on this batch = 0.10151385686631137\n",
      "Cost on val dataset after 392 epochs is = 0.10935040986184175\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.10935040986184175\n",
      "learning rate for this epoch =  0.11236951013020673\n",
      "Error on this batch = 0.0685958801621881\n",
      "Error on this batch = 0.1013981841004905\n",
      "Cost on val dataset after 393 epochs is = 0.10928662681103923\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.10928662681103923\n",
      "learning rate for this epoch =  0.11229795994421696\n",
      "Error on this batch = 0.06849072628883696\n",
      "Error on this batch = 0.10128289214548566\n",
      "Cost on val dataset after 394 epochs is = 0.1092230963852871\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.1092230963852871\n",
      "learning rate for this epoch =  0.11222663697401325\n",
      "Error on this batch = 0.06838598235869144\n",
      "Error on this batch = 0.10116797964250239\n",
      "Cost on val dataset after 395 epochs is = 0.10915981697213514\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.10915981697213514\n",
      "learning rate for this epoch =  0.11215553992409688\n",
      "Error on this batch = 0.06828164592216118\n",
      "Error on this batch = 0.10105344525587746\n",
      "Cost on val dataset after 396 epochs is = 0.1090967869796838\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.1090967869796838\n",
      "learning rate for this epoch =  0.11208466750961145\n",
      "Error on this batch = 0.06817771455061414\n",
      "Error on this batch = 0.10093928767249467\n",
      "Cost on val dataset after 397 epochs is = 0.10903400483635825\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.10903400483635825\n",
      "learning rate for this epoch =  0.11201401845622891\n",
      "Error on this batch = 0.06807418583624528\n",
      "Error on this batch = 0.10082550560120507\n",
      "Cost on val dataset after 398 epochs is = 0.1089714689906842\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.1089714689906842\n",
      "learning rate for this epoch =  0.11194359150003692\n",
      "Error on this batch = 0.06797105739194265\n",
      "Error on this batch = 0.10071209777225068\n",
      "Cost on val dataset after 399 epochs is = 0.1089091779110652\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.1089091779110652\n",
      "learning rate for this epoch =  0.11187338538742793\n",
      "Error on this batch = 0.06786832685115121\n",
      "Error on this batch = 0.10059906293669339\n",
      "Cost on val dataset after 400 epochs is = 0.1088471300855609\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.1088471300855609\n",
      "learning rate for this epoch =  0.11180339887498948\n",
      "Error on this batch = 0.06776599186773423\n",
      "Error on this batch = 0.10048639986584754\n",
      "Cost on val dataset after 401 epochs is = 0.10878532402166687\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.10878532402166687\n",
      "learning rate for this epoch =  0.11173363072939616\n",
      "Error on this batch = 0.06766405011583287\n",
      "Error on this batch = 0.10037410735071747\n",
      "Cost on val dataset after 402 epochs is = 0.10872375824609509\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.10872375824609509\n",
      "learning rate for this epoch =  0.11166407972730269\n",
      "Error on this batch = 0.06756249928972334\n",
      "Error on this batch = 0.10026218420143965\n",
      "Cost on val dataset after 403 epochs is = 0.10866243130455605\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.10866243130455605\n",
      "learning rate for this epoch =  0.1115947446552388\n",
      "Error on this batch = 0.06746133710367222\n",
      "Error on this batch = 0.10015062924672954\n",
      "Cost on val dataset after 404 epochs is = 0.10860134176154103\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.10860134176154103\n",
      "learning rate for this epoch =  0.11152562430950505\n",
      "Error on this batch = 0.06736056129178984\n",
      "Error on this batch = 0.10003944133333331\n",
      "Cost on val dataset after 405 epochs is = 0.10854048820010556\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.10854048820010556\n",
      "learning rate for this epoch =  0.11145671749607033\n",
      "Error on this batch = 0.06726016960788213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.09992861932548465\n",
      "Cost on val dataset after 406 epochs is = 0.10847986922165376\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.10847986922165376\n",
      "learning rate for this epoch =  0.1113880230304705\n",
      "Error on this batch = 0.06716015982530041\n",
      "Error on this batch = 0.09981816210436659\n",
      "Cost on val dataset after 407 epochs is = 0.10841948344572287\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.10841948344572287\n",
      "learning rate for this epoch =  0.11131953973770842\n",
      "Error on this batch = 0.06706052973678978\n",
      "Error on this batch = 0.09970806856757886\n",
      "Cost on val dataset after 408 epochs is = 0.1083593295097687\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.1083593295097687\n",
      "learning rate for this epoch =  0.11125126645215519\n",
      "Error on this batch = 0.06696127715433618\n",
      "Error on this batch = 0.09959833762861023\n",
      "Cost on val dataset after 409 epochs is = 0.10829940606895148\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.10829940606895148\n",
      "learning rate for this epoch =  0.11118320201745278\n",
      "Error on this batch = 0.0668623999090118\n",
      "Error on this batch = 0.09948896821631649\n",
      "Cost on val dataset after 410 epochs is = 0.10823971179592196\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.10823971179592196\n",
      "learning rate for this epoch =  0.11111534528641788\n",
      "Error on this batch = 0.06676389585081934\n",
      "Error on this batch = 0.09937995927440425\n",
      "Cost on val dataset after 411 epochs is = 0.10818024538060798\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.10818024538060798\n",
      "learning rate for this epoch =  0.11104769512094681\n",
      "Error on this batch = 0.06666576284853509\n",
      "Error on this batch = 0.09927130976092009\n",
      "Cost on val dataset after 412 epochs is = 0.10812100553000142\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.10812100553000142\n",
      "learning rate for this epoch =  0.11098025039192183\n",
      "Error on this batch = 0.06656799878955097\n",
      "Error on this batch = 0.09916301864774571\n",
      "Cost on val dataset after 413 epochs is = 0.10806199096794514\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.10806199096794514\n",
      "learning rate for this epoch =  0.11091300997911864\n",
      "Error on this batch = 0.06647060157971549\n",
      "Error on this batch = 0.09905508492009915\n",
      "Cost on val dataset after 414 epochs is = 0.10800320043492027\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.10800320043492027\n",
      "learning rate for this epoch =  0.11084597277111498\n",
      "Error on this batch = 0.06637356914317394\n",
      "Error on this batch = 0.0989475075760419\n",
      "Cost on val dataset after 415 epochs is = 0.10794463268783341\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.10794463268783341\n",
      "learning rate for this epoch =  0.11077913766520031\n",
      "Error on this batch = 0.06627689942220769\n",
      "Error on this batch = 0.0988402856259921\n",
      "Cost on val dataset after 416 epochs is = 0.10788628649980418\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.10788628649980418\n",
      "learning rate for this epoch =  0.11071250356728685\n",
      "Error on this batch = 0.0661805903770729\n",
      "Error on this batch = 0.09873341809224438\n",
      "Cost on val dataset after 417 epochs is = 0.10782816065995257\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.10782816065995257\n",
      "learning rate for this epoch =  0.11064606939182157\n",
      "Error on this batch = 0.06608463998583859\n",
      "Error on this batch = 0.09862690400849551\n",
      "Cost on val dataset after 418 epochs is = 0.10777025397318624\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.10777025397318624\n",
      "learning rate for this epoch =  0.11057983406169934\n",
      "Error on this batch = 0.06598904624422425\n",
      "Error on this batch = 0.09852074241937718\n",
      "Cost on val dataset after 419 epochs is = 0.10771256525998799\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.10771256525998799\n",
      "learning rate for this epoch =  0.11051379650817714\n",
      "Error on this batch = 0.06589380716543705\n",
      "Error on this batch = 0.09841493237999485\n",
      "Cost on val dataset after 420 epochs is = 0.10765509335620294\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.10765509335620294\n",
      "learning rate for this epoch =  0.11044795567078942\n",
      "Error on this batch = 0.06579892078000879\n",
      "Error on this batch = 0.09830947295547343\n",
      "Cost on val dataset after 421 epochs is = 0.10759783711282564\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.10759783711282564\n",
      "learning rate for this epoch =  0.1103823104972644\n",
      "Error on this batch = 0.06570438513563243\n",
      "Error on this batch = 0.09820436322050993\n",
      "Cost on val dataset after 422 epochs is = 0.10754079539578712\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.10754079539578712\n",
      "learning rate for this epoch =  0.11031685994344151\n",
      "Error on this batch = 0.0656101982969987\n",
      "Error on this batch = 0.09809960225893263\n",
      "Cost on val dataset after 423 epochs is = 0.10748396708574172\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.10748396708574172\n",
      "learning rate for this epoch =  0.11025160297318981\n",
      "Error on this batch = 0.06551635834563271\n",
      "Error on this batch = 0.0979951891632675\n",
      "Cost on val dataset after 424 epochs is = 0.1074273510778537\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.1074273510778537\n",
      "learning rate for this epoch =  0.11018653855832754\n",
      "Error on this batch = 0.06542286337973031\n",
      "Error on this batch = 0.09789112303431143\n",
      "Cost on val dataset after 425 epochs is = 0.10737094628158382\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.10737094628158382\n",
      "learning rate for this epoch =  0.11012166567854233\n",
      "Error on this batch = 0.06532971151399504\n",
      "Error on this batch = 0.09778740298071269\n",
      "Cost on val dataset after 426 epochs is = 0.10731475162047559\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.10731475162047559\n",
      "learning rate for this epoch =  0.11005698332131283\n",
      "Error on this batch = 0.06523690087947466\n",
      "Error on this batch = 0.09768402811855854\n",
      "Cost on val dataset after 427 epochs is = 0.10725876603194133\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.10725876603194133\n",
      "learning rate for this epoch =  0.10999249048183099\n",
      "Error on this batch = 0.06514442962339857\n",
      "Error on this batch = 0.09758099757097025\n",
      "Cost on val dataset after 428 epochs is = 0.10720298846704825\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.10720298846704825\n",
      "learning rate for this epoch =  0.10992818616292545\n",
      "Error on this batch = 0.06505229590901516\n",
      "Error on this batch = 0.09747831046770497\n",
      "Cost on val dataset after 429 epochs is = 0.10714741789030395\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.10714741789030395\n",
      "learning rate for this epoch =  0.10986406937498579\n",
      "Error on this batch = 0.06496049791543002\n",
      "Error on this batch = 0.09737596594476564\n",
      "Cost on val dataset after 430 epochs is = 0.10709205327944224\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.10709205327944224\n",
      "learning rate for this epoch =  0.10980013913588772\n",
      "Error on this batch = 0.06486903383744401\n",
      "Error on this batch = 0.09727396314401791\n",
      "Cost on val dataset after 431 epochs is = 0.1070368936252083\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.1070368936252083\n",
      "learning rate for this epoch =  0.10973639447091926\n",
      "Error on this batch = 0.06477790188539252\n",
      "Error on this batch = 0.0971723012128146\n",
      "Cost on val dataset after 432 epochs is = 0.10698193793114419\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.10698193793114419\n",
      "learning rate for this epoch =  0.10967283441270771\n",
      "Error on this batch = 0.06468710028498512\n",
      "Error on this batch = 0.09707097930362801\n",
      "Cost on val dataset after 433 epochs is = 0.10692718521337369\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.10692718521337369\n",
      "learning rate for this epoch =  0.10960945800114749\n",
      "Error on this batch = 0.0645966272771457\n",
      "Error on this batch = 0.09696999657368935\n",
      "Cost on val dataset after 434 epochs is = 0.10687263450038766\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.10687263450038766\n",
      "learning rate for this epoch =  0.10954626428332909\n",
      "Error on this batch = 0.0645064811178538\n",
      "Error on this batch = 0.09686935218463624\n",
      "Cost on val dataset after 435 epochs is = 0.1068182848328287\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.1068182848328287\n",
      "learning rate for this epoch =  0.10948325231346849\n",
      "Error on this batch = 0.06441666007798637\n",
      "Error on this batch = 0.09676904530216775\n",
      "Cost on val dataset after 436 epochs is = 0.10676413526327634\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.10676413526327634\n",
      "learning rate for this epoch =  0.1094204211528378\n",
      "Error on this batch = 0.06432716244316057\n",
      "Error on this batch = 0.096669075095707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 437 epochs is = 0.10671018485603187\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.10671018485603187\n",
      "learning rate for this epoch =  0.1093577698696965\n",
      "Error on this batch = 0.06423798651357748\n",
      "Error on this batch = 0.09656944073807179\n",
      "Cost on val dataset after 438 epochs is = 0.1066564326869032\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.1066564326869032\n",
      "learning rate for this epoch =  0.1092952975392236\n",
      "Error on this batch = 0.06414913060386669\n",
      "Error on this batch = 0.09647014140515277\n",
      "Cost on val dataset after 439 epochs is = 0.10660287784299015\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.10660287784299015\n",
      "learning rate for this epoch =  0.10923300324345062\n",
      "Error on this batch = 0.06406059304293209\n",
      "Error on this batch = 0.09637117627559931\n",
      "Cost on val dataset after 440 epochs is = 0.10654951942246949\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.10654951942246949\n",
      "learning rate for this epoch =  0.10917088607119531\n",
      "Error on this batch = 0.06397237217379856\n",
      "Error on this batch = 0.09627254453051362\n",
      "Cost on val dataset after 441 epochs is = 0.10649635653438026\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.10649635653438026\n",
      "learning rate for this epoch =  0.1091089451179962\n",
      "Error on this batch = 0.06388446635345968\n",
      "Error on this batch = 0.09617424535315212\n",
      "Cost on val dataset after 442 epochs is = 0.10644338829840955\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.10644338829840955\n",
      "learning rate for this epoch =  0.10904717948604793\n",
      "Error on this batch = 0.06379687395272689\n",
      "Error on this batch = 0.096076277928635\n",
      "Cost on val dataset after 443 epochs is = 0.10639061384467827\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.10639061384467827\n",
      "learning rate for this epoch =  0.10898558828413735\n",
      "Error on this batch = 0.0637095933560795\n",
      "Error on this batch = 0.09597864144366351\n",
      "Cost on val dataset after 444 epochs is = 0.10633803231352733\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.10633803231352733\n",
      "learning rate for this epoch =  0.10892417062758035\n",
      "Error on this batch = 0.06362262296151608\n",
      "Error on this batch = 0.09588133508624495\n",
      "Cost on val dataset after 445 epochs is = 0.10628564285530441\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.10628564285530441\n",
      "learning rate for this epoch =  0.10886292563815944\n",
      "Error on this batch = 0.06353596118040718\n",
      "Error on this batch = 0.09578435804542554\n",
      "Cost on val dataset after 446 epochs is = 0.10623344463015112\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.10623344463015112\n",
      "learning rate for this epoch =  0.10880185244406208\n",
      "Error on this batch = 0.06344960643734897\n",
      "Error on this batch = 0.09568770951103123\n",
      "Cost on val dataset after 447 epochs is = 0.10618143680779046\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.10618143680779046\n",
      "learning rate for this epoch =  0.10874095017981981\n",
      "Error on this batch = 0.06336355717001858\n",
      "Error on this batch = 0.09559138867341592\n",
      "Cost on val dataset after 448 epochs is = 0.10612961856731536\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.10612961856731536\n",
      "learning rate for this epoch =  0.10868021798624786\n",
      "Error on this batch = 0.06327781182903067\n",
      "Error on this batch = 0.09549539472321797\n",
      "Cost on val dataset after 449 epochs is = 0.10607798909697735\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.10607798909697735\n",
      "learning rate for this epoch =  0.10861965501038574\n",
      "Error on this batch = 0.06319236887779489\n",
      "Error on this batch = 0.09539972685112387\n",
      "Cost on val dataset after 450 epochs is = 0.10602654759397673\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.10602654759397673\n",
      "learning rate for this epoch =  0.10855926040543842\n",
      "Error on this batch = 0.0631072267923756\n",
      "Error on this batch = 0.09530438424763986\n",
      "Cost on val dataset after 451 epochs is = 0.10597529326425267\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.10597529326425267\n",
      "learning rate for this epoch =  0.1084990333307181\n",
      "Error on this batch = 0.06302238406135204\n",
      "Error on this batch = 0.09520936610287155\n",
      "Cost on val dataset after 452 epochs is = 0.10592422532227502\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.10592422532227502\n",
      "learning rate for this epoch =  0.10843897295158678\n",
      "Error on this batch = 0.06293783918568054\n",
      "Error on this batch = 0.0951146716063105\n",
      "Cost on val dataset after 453 epochs is = 0.10587334299083669\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.10587334299083669\n",
      "learning rate for this epoch =  0.10837907843939941\n",
      "Error on this batch = 0.06285359067855781\n",
      "Error on this batch = 0.09502029994662899\n",
      "Cost on val dataset after 454 epochs is = 0.10582264550084716\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.10582264550084716\n",
      "learning rate for this epoch =  0.10831934897144786\n",
      "Error on this batch = 0.0627696370652858\n",
      "Error on this batch = 0.09492625031148197\n",
      "Cost on val dataset after 455 epochs is = 0.10577213209112747\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.10577213209112747\n",
      "learning rate for this epoch =  0.10825978373090529\n",
      "Error on this batch = 0.06268597688313786\n",
      "Error on this batch = 0.09483252188731665\n",
      "Cost on val dataset after 456 epochs is = 0.10572180200820581\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.10572180200820581\n",
      "learning rate for this epoch =  0.10820038190677136\n",
      "Error on this batch = 0.0626026086812266\n",
      "Error on this batch = 0.09473911385918964\n",
      "Cost on val dataset after 457 epochs is = 0.10567165450611526\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.10567165450611526\n",
      "learning rate for this epoch =  0.10814114269381797\n",
      "Error on this batch = 0.06251953102037291\n",
      "Error on this batch = 0.09464602541059108\n",
      "Cost on val dataset after 458 epochs is = 0.10562168884619234\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.10562168884619234\n",
      "learning rate for this epoch =  0.10808206529253567\n",
      "Error on this batch = 0.06243674247297654\n",
      "Error on this batch = 0.09455325572327672\n",
      "Cost on val dataset after 459 epochs is = 0.10557190429687732\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.10557190429687732\n",
      "learning rate for this epoch =  0.10802314890908067\n",
      "Error on this batch = 0.06235424162288817\n",
      "Error on this batch = 0.09446080397710674\n",
      "Cost on val dataset after 460 epochs is = 0.10552230013351602\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.10552230013351602\n",
      "learning rate for this epoch =  0.10796439275522242\n",
      "Error on this batch = 0.062272027065282884\n",
      "Error on this batch = 0.09436866934989184\n",
      "Cost on val dataset after 461 epochs is = 0.10547287563816357\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.10547287563816357\n",
      "learning rate for this epoch =  0.10790579604829184\n",
      "Error on this batch = 0.06219009740653521\n",
      "Error on this batch = 0.09427685101724684\n",
      "Cost on val dataset after 462 epochs is = 0.10542363009938972\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.10542363009938972\n",
      "learning rate for this epoch =  0.10784735801113018\n",
      "Error on this batch = 0.06210845126409537\n",
      "Error on this batch = 0.09418534815245089\n",
      "Cost on val dataset after 463 epochs is = 0.10537456281208585\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.10537456281208585\n",
      "learning rate for this epoch =  0.10778907787203826\n",
      "Error on this batch = 0.062027087266367256\n",
      "Error on this batch = 0.09409415992631485\n",
      "Cost on val dataset after 464 epochs is = 0.1053256730772746\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.1053256730772746\n",
      "learning rate for this epoch =  0.1077309548647265\n",
      "Error on this batch = 0.06194600405258762\n",
      "Error on this batch = 0.09400328550705571\n",
      "Cost on val dataset after 465 epochs is = 0.10527696020192072\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.10527696020192072\n",
      "learning rate for this epoch =  0.10767298822826553\n",
      "Error on this batch = 0.06186520027270687\n",
      "Error on this batch = 0.09391272406017745\n",
      "Cost on val dataset after 466 epochs is = 0.10522842349874464\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.10522842349874464\n",
      "learning rate for this epoch =  0.10761517720703706\n",
      "Error on this batch = 0.061784674587271146\n",
      "Error on this batch = 0.09382247474835918\n",
      "Cost on val dataset after 467 epochs is = 0.10518006228603823\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.10518006228603823\n",
      "learning rate for this epoch =  0.10755752105068565\n",
      "Error on this batch = 0.06170442566730606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.09373253673134936\n",
      "Cost on val dataset after 468 epochs is = 0.10513187588748256\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.10513187588748256\n",
      "learning rate for this epoch =  0.1075000190140709\n",
      "Error on this batch = 0.0616244521942015\n",
      "Error on this batch = 0.09364290916586704\n",
      "Cost on val dataset after 469 epochs is = 0.10508386363196831\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.10508386363196831\n",
      "learning rate for this epoch =  0.10744267035722005\n",
      "Error on this batch = 0.06154475285959809\n",
      "Error on this batch = 0.09355359120550932\n",
      "Cost on val dataset after 470 epochs is = 0.10503602485341872\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.10503602485341872\n",
      "learning rate for this epoch =  0.10738547434528128\n",
      "Error on this batch = 0.061465326365274894\n",
      "Error on this batch = 0.09346458200066521\n",
      "Cost on val dataset after 471 epochs is = 0.10498835889061499\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.10498835889061499\n",
      "learning rate for this epoch =  0.10732843024847744\n",
      "Error on this batch = 0.06138617142303874\n",
      "Error on this batch = 0.09337588069843582\n",
      "Cost on val dataset after 472 epochs is = 0.10494086508702422\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.10494086508702422\n",
      "learning rate for this epoch =  0.10727153734206031\n",
      "Error on this batch = 0.06130728675461456\n",
      "Error on this batch = 0.09328748644256077\n",
      "Cost on val dataset after 473 epochs is = 0.10489354279063047\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.10489354279063047\n",
      "learning rate for this epoch =  0.1072147949062655\n",
      "Error on this batch = 0.061228671091537325\n",
      "Error on this batch = 0.09319939837335067\n",
      "Cost on val dataset after 474 epochs is = 0.10484639135376825\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.10484639135376825\n",
      "learning rate for this epoch =  0.10715820222626746\n",
      "Error on this batch = 0.06115032317504524\n",
      "Error on this batch = 0.0931116156276254\n",
      "Cost on val dataset after 475 epochs is = 0.10479941013295907\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.10479941013295907\n",
      "learning rate for this epoch =  0.1071017585921356\n",
      "Error on this batch = 0.061072241755974144\n",
      "Error on this batch = 0.09302413733865858\n",
      "Cost on val dataset after 476 epochs is = 0.104752598488751\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.104752598488751\n",
      "learning rate for this epoch =  0.1070454632987902\n",
      "Error on this batch = 0.060994425594653484\n",
      "Error on this batch = 0.09293696263612748\n",
      "Cost on val dataset after 477 epochs is = 0.10470595578556117\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.10470595578556117\n",
      "learning rate for this epoch =  0.10698931564595948\n",
      "Error on this batch = 0.0609168734608033\n",
      "Error on this batch = 0.09285009064606876\n",
      "Cost on val dataset after 478 epochs is = 0.10465948139152134\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.10465948139152134\n",
      "learning rate for this epoch =  0.1069333149381366\n",
      "Error on this batch = 0.06083958413343262\n",
      "Error on this batch = 0.09276352049084001\n",
      "Cost on val dataset after 479 epochs is = 0.1046131746783268\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.1046131746783268\n",
      "learning rate for this epoch =  0.10687746048453738\n",
      "Error on this batch = 0.06076255640073904\n",
      "Error on this batch = 0.092677251289086\n",
      "Cost on val dataset after 480 epochs is = 0.10456703502108841\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.10456703502108841\n",
      "learning rate for this epoch =  0.10682175159905852\n",
      "Error on this batch = 0.06068578906000964\n",
      "Error on this batch = 0.09259128215571125\n",
      "Cost on val dataset after 481 epochs is = 0.10452106179818782\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.10452106179818782\n",
      "learning rate for this epoch =  0.1067661876002362\n",
      "Error on this batch = 0.06060928091752292\n",
      "Error on this batch = 0.09250561220185688\n",
      "Cost on val dataset after 482 epochs is = 0.10447525439113621\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.10447525439113621\n",
      "learning rate for this epoch =  0.1067107678112051\n",
      "Error on this batch = 0.06053303078845214\n",
      "Error on this batch = 0.09242024053488318\n",
      "Cost on val dataset after 483 epochs is = 0.10442961218443633\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.10442961218443633\n",
      "learning rate for this epoch =  0.10665549155965787\n",
      "Error on this batch = 0.06045703749676969\n",
      "Error on this batch = 0.09233516625835707\n",
      "Cost on val dataset after 484 epochs is = 0.10438413456544794\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.10438413456544794\n",
      "learning rate for this epoch =  0.10660035817780521\n",
      "Error on this batch = 0.06038129987515276\n",
      "Error on this batch = 0.09225038847204402\n",
      "Cost on val dataset after 485 epochs is = 0.10433882092425703\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.10433882092425703\n",
      "learning rate for this epoch =  0.10654536700233612\n",
      "Error on this batch = 0.060305816764889955\n",
      "Error on this batch = 0.09216590627190538\n",
      "Cost on val dataset after 486 epochs is = 0.10429367065354792\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.10429367065354792\n",
      "learning rate for this epoch =  0.10649051737437876\n",
      "Error on this batch = 0.06023058701578906\n",
      "Error on this batch = 0.09208171875009986\n",
      "Cost on val dataset after 487 epochs is = 0.10424868314847972\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.10424868314847972\n",
      "learning rate for this epoch =  0.10643580863946162\n",
      "Error on this batch = 0.06015560948608632\n",
      "Error on this batch = 0.09199782499498962\n",
      "Cost on val dataset after 488 epochs is = 0.10420385780656581\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.10420385780656581\n",
      "learning rate for this epoch =  0.10638124014747533\n",
      "Error on this batch = 0.06008088304235601\n",
      "Error on this batch = 0.09191422409115099\n",
      "Cost on val dataset after 489 epochs is = 0.10415919402755715\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.10415919402755715\n",
      "learning rate for this epoch =  0.1063268112526345\n",
      "Error on this batch = 0.0600064065594218\n",
      "Error on this batch = 0.09183091511938919\n",
      "Cost on val dataset after 490 epochs is = 0.10411469121332928\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.10411469121332928\n",
      "learning rate for this epoch =  0.10627252131344038\n",
      "Error on this batch = 0.05993217892026877\n",
      "Error on this batch = 0.09174789715675737\n",
      "Cost on val dataset after 491 epochs is = 0.10407034876777291\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.10407034876777291\n",
      "learning rate for this epoch =  0.10621836969264359\n",
      "Error on this batch = 0.05985819901595664\n",
      "Error on this batch = 0.09166516927657979\n",
      "Cost on val dataset after 492 epochs is = 0.10402616609668802\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.10402616609668802\n",
      "learning rate for this epoch =  0.10616435575720744\n",
      "Error on this batch = 0.059784465745533776\n",
      "Error on this batch = 0.09158273054847857\n",
      "Cost on val dataset after 493 epochs is = 0.10398214260768218\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.10398214260768218\n",
      "learning rate for this epoch =  0.1061104788782716\n",
      "Error on this batch = 0.059710978015952404\n",
      "Error on this batch = 0.09150058003840475\n",
      "Cost on val dataset after 494 epochs is = 0.10393827771007193\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.10393827771007193\n",
      "learning rate for this epoch =  0.10605673843111615\n",
      "Error on this batch = 0.05963773474198481\n",
      "Error on this batch = 0.09141871680867251\n",
      "Cost on val dataset after 495 epochs is = 0.10389457081478835\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.10389457081478835\n",
      "learning rate for this epoch =  0.10600313379512592\n",
      "Error on this batch = 0.05956473484614021\n",
      "Error on this batch = 0.09133713991799755\n",
      "Cost on val dataset after 496 epochs is = 0.10385102133428598\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.10385102133428598\n",
      "learning rate for this epoch =  0.10594966435375541\n",
      "Error on this batch = 0.05949197725858288\n",
      "Error on this batch = 0.09125584842153835\n",
      "Cost on val dataset after 497 epochs is = 0.10380762868245576\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.10380762868245576\n",
      "learning rate for this epoch =  0.10589632949449389\n",
      "Error on this batch = 0.05941946091705095\n",
      "Error on this batch = 0.0911748413709411\n",
      "Cost on val dataset after 498 epochs is = 0.1037643922745413\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.1037643922745413\n",
      "learning rate for this epoch =  0.10584312860883092\n",
      "Error on this batch = 0.05934718476677625\n",
      "Error on this batch = 0.09109411781438778\n",
      "Cost on val dataset after 499 epochs is = 0.10372131152705928\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.10372131152705928\n",
      "learning rate for this epoch =  0.10579006109222232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.05927514776040512\n",
      "Error on this batch = 0.09101367679664747\n",
      "Cost on val dataset after 500 epochs is = 0.1036783858577228\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.1036783858577228\n",
      "learning rate for this epoch =  0.10573712634405641\n",
      "Error on this batch = 0.05920334885791975\n",
      "Error on this batch = 0.09093351735913015\n",
      "Cost on val dataset after 501 epochs is = 0.10363561468536918\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.10363561468536918\n",
      "learning rate for this epoch =  0.1056843237676206\n",
      "Error on this batch = 0.05913178702656076\n",
      "Error on this batch = 0.09085363853994416\n",
      "Cost on val dataset after 502 epochs is = 0.10359299742989074\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.10359299742989074\n",
      "learning rate for this epoch =  0.10563165277006838\n",
      "Error on this batch = 0.05906046124075026\n",
      "Error on this batch = 0.09077403937395563\n",
      "Cost on val dataset after 503 epochs is = 0.10355053351216956\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.10355053351216956\n",
      "learning rate for this epoch =  0.10557911276238661\n",
      "Error on this batch = 0.058989370482016065\n",
      "Error on this batch = 0.09069471889285115\n",
      "Cost on val dataset after 504 epochs is = 0.10350822235401524\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.10350822235401524\n",
      "learning rate for this epoch =  0.10552670315936317\n",
      "Error on this batch = 0.05891851373891659\n",
      "Error on this batch = 0.09061567612520254\n",
      "Cost on val dataset after 505 epochs is = 0.1034660633781068\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.1034660633781068\n",
      "learning rate for this epoch =  0.105474423379555\n",
      "Error on this batch = 0.05884789000696634\n",
      "Error on this batch = 0.09053691009653445\n",
      "Cost on val dataset after 506 epochs is = 0.10342405600793772\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.10342405600793772\n",
      "learning rate for this epoch =  0.10542227284525636\n",
      "Error on this batch = 0.05877749828856251\n",
      "Error on this batch = 0.09045841982939372\n",
      "Cost on val dataset after 507 epochs is = 0.10338219966776419\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.10338219966776419\n",
      "learning rate for this epoch =  0.10537025098246748\n",
      "Error on this batch = 0.05870733759291206\n",
      "Error on this batch = 0.09038020434342155\n",
      "Cost on val dataset after 508 epochs is = 0.10334049378255702\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.10334049378255702\n",
      "learning rate for this epoch =  0.10531835722086355\n",
      "Error on this batch = 0.05863740693595984\n",
      "Error on this batch = 0.09030226265542733\n",
      "Cost on val dataset after 509 epochs is = 0.10329893777795691\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.10329893777795691\n",
      "learning rate for this epoch =  0.10526659099376405\n",
      "Error on this batch = 0.058567705340317196\n",
      "Error on this batch = 0.09022459377946455\n",
      "Cost on val dataset after 510 epochs is = 0.10325753108023258\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.10325753108023258\n",
      "learning rate for this epoch =  0.10521495173810227\n",
      "Error on this batch = 0.058498231835191435\n",
      "Error on this batch = 0.09014719672690862\n",
      "Cost on val dataset after 511 epochs is = 0.10321627311624251\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.10321627311624251\n",
      "learning rate for this epoch =  0.10516343889439533\n",
      "Error on this batch = 0.05842898545631594\n",
      "Error on this batch = 0.09007007050653658\n",
      "Cost on val dataset after 512 epochs is = 0.10317516331339951\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.10317516331339951\n",
      "learning rate for this epoch =  0.10511205190671433\n",
      "Error on this batch = 0.05835996524588106\n",
      "Error on this batch = 0.08999321412460827\n",
      "Cost on val dataset after 513 epochs is = 0.1031342010996386\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.1031342010996386\n",
      "learning rate for this epoch =  0.10506079022265488\n",
      "Error on this batch = 0.05829117025246578\n",
      "Error on this batch = 0.08991662658494917\n",
      "Cost on val dataset after 514 epochs is = 0.10309338590338771\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.10309338590338771\n",
      "learning rate for this epoch =  0.10500965329330811\n",
      "Error on this batch = 0.05822259953096992\n",
      "Error on this batch = 0.08984030688903463\n",
      "Cost on val dataset after 515 epochs is = 0.10305271715354133\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.10305271715354133\n",
      "learning rate for this epoch =  0.10495864057323148\n",
      "Error on this batch = 0.05815425214254698\n",
      "Error on this batch = 0.08976425403607567\n",
      "Cost on val dataset after 516 epochs is = 0.10301219427943717\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.10301219427943717\n",
      "learning rate for this epoch =  0.10490775152042053\n",
      "Error on this batch = 0.058086127154537925\n",
      "Error on this batch = 0.0896884670231059\n",
      "Cost on val dataset after 517 epochs is = 0.10297181671083545\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.10297181671083545\n",
      "learning rate for this epoch =  0.10485698559628044\n",
      "Error on this batch = 0.058018223640405306\n",
      "Error on this batch = 0.08961294484506949\n",
      "Cost on val dataset after 518 epochs is = 0.10293158387790095\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.10293158387790095\n",
      "learning rate for this epoch =  0.10480634226559798\n",
      "Error on this batch = 0.0579505406796685\n",
      "Error on this batch = 0.08953768649491065\n",
      "Cost on val dataset after 519 epochs is = 0.10289149521118775\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.10289149521118775\n",
      "learning rate for this epoch =  0.10475582099651397\n",
      "Error on this batch = 0.05788307735783883\n",
      "Error on this batch = 0.08946269096366354\n",
      "Cost on val dataset after 520 epochs is = 0.10285155014162652\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.10285155014162652\n",
      "learning rate for this epoch =  0.10470542126049572\n",
      "Error on this batch = 0.05781583276635635\n",
      "Error on this batch = 0.08938795724054367\n",
      "Cost on val dataset after 521 epochs is = 0.10281174810051408\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.10281174810051408\n",
      "learning rate for this epoch =  0.10465514253230984\n",
      "Error on this batch = 0.05774880600252621\n",
      "Error on this batch = 0.08931348431303975\n",
      "Cost on val dataset after 522 epochs is = 0.10277208851950591\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.10277208851950591\n",
      "learning rate for this epoch =  0.10460498428999554\n",
      "Error on this batch = 0.05768199616945658\n",
      "Error on this batch = 0.08923927116700622\n",
      "Cost on val dataset after 523 epochs is = 0.1027325708306102\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.1027325708306102\n",
      "learning rate for this epoch =  0.10455494601483782\n",
      "Error on this batch = 0.05761540237599654\n",
      "Error on this batch = 0.08916531678675689\n",
      "Cost on val dataset after 524 epochs is = 0.10269319446618488\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.10269319446618488\n",
      "learning rate for this epoch =  0.10450502719134125\n",
      "Error on this batch = 0.05754902373667495\n",
      "Error on this batch = 0.08909162015515854\n",
      "Cost on val dataset after 525 epochs is = 0.1026539588589364\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.1026539588589364\n",
      "learning rate for this epoch =  0.10445522730720382\n",
      "Error on this batch = 0.05748285937163969\n",
      "Error on this batch = 0.08901818025372556\n",
      "Cost on val dataset after 526 epochs is = 0.10261486344192054\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.10261486344192054\n",
      "learning rate for this epoch =  0.10440554585329116\n",
      "Error on this batch = 0.057416908406597814\n",
      "Error on this batch = 0.08894499606271478\n",
      "Cost on val dataset after 527 epochs is = 0.10257590764854554\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.10257590764854554\n",
      "learning rate for this epoch =  0.10435598232361096\n",
      "Error on this batch = 0.05735116997275603\n",
      "Error on this batch = 0.08887206656122039\n",
      "Cost on val dataset after 528 epochs is = 0.1025370909125769\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.1025370909125769\n",
      "learning rate for this epoch =  0.10430653621528765\n",
      "Error on this batch = 0.05728564320676194\n",
      "Error on this batch = 0.0887993907272697\n",
      "Cost on val dataset after 529 epochs is = 0.10249841266814397\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.10249841266814397\n",
      "learning rate for this epoch =  0.10425720702853739\n",
      "Error on this batch = 0.057220327250645714\n",
      "Error on this batch = 0.08872696753791852\n",
      "Cost on val dataset after 530 epochs is = 0.10245987234974845\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.10245987234974845\n",
      "learning rate for this epoch =  0.10420799426664315\n",
      "Error on this batch = 0.05715522125176263\n",
      "Error on this batch = 0.08865479596934722\n",
      "Cost on val dataset after 531 epochs is = 0.10242146939227445\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.10242146939227445\n",
      "learning rate for this epoch =  0.10415889743593033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.05709032436273592\n",
      "Error on this batch = 0.08858287499695626\n",
      "Cost on val dataset after 532 epochs is = 0.10238320323100018\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.10238320323100018\n",
      "learning rate for this epoch =  0.10410991604574225\n",
      "Error on this batch = 0.057025635741400356\n",
      "Error on this batch = 0.08851120359546219\n",
      "Cost on val dataset after 533 epochs is = 0.10234507330161101\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.10234507330161101\n",
      "learning rate for this epoch =  0.10406104960841617\n",
      "Error on this batch = 0.0569611545507464\n",
      "Error on this batch = 0.08843978073899347\n",
      "Cost on val dataset after 534 epochs is = 0.10230707904021429\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.10230707904021429\n",
      "learning rate for this epoch =  0.1040122976392594\n",
      "Error on this batch = 0.05689687995886493\n",
      "Error on this batch = 0.088368605401186\n",
      "Cost on val dataset after 535 epochs is = 0.10226921988335491\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.10226921988335491\n",
      "learning rate for this epoch =  0.10396365965652576\n",
      "Error on this batch = 0.056832811138892436\n",
      "Error on this batch = 0.08829767655527865\n",
      "Cost on val dataset after 536 epochs is = 0.10223149526803285\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.10223149526803285\n",
      "learning rate for this epoch =  0.10391513518139214\n",
      "Error on this batch = 0.056768947268957044\n",
      "Error on this batch = 0.08822699317420855\n",
      "Cost on val dataset after 537 epochs is = 0.1021939046317212\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.1021939046317212\n",
      "learning rate for this epoch =  0.10386672373793533\n",
      "Error on this batch = 0.05670528753212475\n",
      "Error on this batch = 0.08815655423070588\n",
      "Cost on val dataset after 538 epochs is = 0.10215644741238596\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.10215644741238596\n",
      "learning rate for this epoch =  0.10381842485310916\n",
      "Error on this batch = 0.05664183111634651\n",
      "Error on this batch = 0.08808635869738847\n",
      "Cost on val dataset after 539 epochs is = 0.10211912304850623\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.10211912304850623\n",
      "learning rate for this epoch =  0.10377023805672174\n",
      "Error on this batch = 0.056578577214405894\n",
      "Error on this batch = 0.08801640554685623\n",
      "Cost on val dataset after 540 epochs is = 0.1020819309790958\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.1020819309790958\n",
      "learning rate for this epoch =  0.10372216288141306\n",
      "Error on this batch = 0.05651552502386697\n",
      "Error on this batch = 0.08794669375178449\n",
      "Cost on val dataset after 541 epochs is = 0.10204487064372562\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.10204487064372562\n",
      "learning rate for this epoch =  0.10367419886263263\n",
      "Error on this batch = 0.05645267374702314\n",
      "Error on this batch = 0.08787722228501768\n",
      "Cost on val dataset after 542 epochs is = 0.10200794148254672\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.10200794148254672\n",
      "learning rate for this epoch =  0.10362634553861746\n",
      "Error on this batch = 0.05639002259084634\n",
      "Error on this batch = 0.08780799011966166\n",
      "Cost on val dataset after 543 epochs is = 0.10197114293631411\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.10197114293631411\n",
      "learning rate for this epoch =  0.10357860245037034\n",
      "Error on this batch = 0.05632757076693671\n",
      "Error on this batch = 0.08773899622917603\n",
      "Cost on val dataset after 544 epochs is = 0.10193447444641159\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.10193447444641159\n",
      "learning rate for this epoch =  0.10353096914163801\n",
      "Error on this batch = 0.05626531749147299\n",
      "Error on this batch = 0.0876702395874657\n",
      "Cost on val dataset after 545 epochs is = 0.10189793545487671\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.10189793545487671\n",
      "learning rate for this epoch =  0.10348344515888994\n",
      "Error on this batch = 0.056203261985163414\n",
      "Error on this batch = 0.08760171916897154\n",
      "Cost on val dataset after 546 epochs is = 0.10186152540442653\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.10186152540442653\n",
      "learning rate for this epoch =  0.10343603005129703\n",
      "Error on this batch = 0.056141403473196995\n",
      "Error on this batch = 0.08753343394876063\n",
      "Cost on val dataset after 547 epochs is = 0.10182524373848388\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.10182524373848388\n",
      "learning rate for this epoch =  0.1033887233707106\n",
      "Error on this batch = 0.05607974118519536\n",
      "Error on this batch = 0.08746538290261566\n",
      "Cost on val dataset after 548 epochs is = 0.10178908990120399\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.10178908990120399\n",
      "learning rate for this epoch =  0.10334152467164161\n",
      "Error on this batch = 0.056018274355165494\n",
      "Error on this batch = 0.08739756500712346\n",
      "Cost on val dataset after 549 epochs is = 0.10175306333750139\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.10175306333750139\n",
      "learning rate for this epoch =  0.10329443351124007\n",
      "Error on this batch = 0.05595700222145244\n",
      "Error on this batch = 0.08732997923976296\n",
      "Cost on val dataset after 550 epochs is = 0.10171716349307738\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.10171716349307738\n",
      "learning rate for this epoch =  0.10324744944927464\n",
      "Error on this batch = 0.05589592402669293\n",
      "Error on this batch = 0.08726262457899203\n",
      "Cost on val dataset after 551 epochs is = 0.10168138981444744\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.10168138981444744\n",
      "learning rate for this epoch =  0.10320057204811232\n",
      "Error on this batch = 0.0558350390177693\n",
      "Error on this batch = 0.08719550000433365\n",
      "Cost on val dataset after 552 epochs is = 0.10164574174896902\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.10164574174896902\n",
      "learning rate for this epoch =  0.10315380087269863\n",
      "Error on this batch = 0.05577434644576412\n",
      "Error on this batch = 0.0871286044964612\n",
      "Cost on val dataset after 553 epochs is = 0.10161021874486952\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.10161021874486952\n",
      "learning rate for this epoch =  0.10310713549053749\n",
      "Error on this batch = 0.0557138455659151\n",
      "Error on this batch = 0.0870619370372826\n",
      "Cost on val dataset after 554 epochs is = 0.10157482025127416\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.10157482025127416\n",
      "learning rate for this epoch =  0.10306057547167191\n",
      "Error on this batch = 0.055653535637570715\n",
      "Error on this batch = 0.08699549661002381\n",
      "Cost on val dataset after 555 epochs is = 0.1015395457182342\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.1015395457182342\n",
      "learning rate for this epoch =  0.1030141203886643\n",
      "Error on this batch = 0.05559341592414618\n",
      "Error on this batch = 0.08692928219931116\n",
      "Cost on val dataset after 556 epochs is = 0.10150439459675485\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.10150439459675485\n",
      "learning rate for this epoch =  0.10296776981657725\n",
      "Error on this batch = 0.05553348569307996\n",
      "Error on this batch = 0.0868632927912525\n",
      "Cost on val dataset after 557 epochs is = 0.1014693663388234\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.1014693663388234\n",
      "learning rate for this epoch =  0.10292152333295448\n",
      "Error on this batch = 0.05547374421579072\n",
      "Error on this batch = 0.08679752737351809\n",
      "Cost on val dataset after 558 epochs is = 0.10143446039743717\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.10143446039743717\n",
      "learning rate for this epoch =  0.10287538051780193\n",
      "Error on this batch = 0.05541419076763497\n",
      "Error on this batch = 0.08673198493541945\n",
      "Cost on val dataset after 559 epochs is = 0.10139967622663129\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.10139967622663129\n",
      "learning rate for this epoch =  0.10282934095356899\n",
      "Error on this batch = 0.055354824627864695\n",
      "Error on this batch = 0.08666666446798786\n",
      "Cost on val dataset after 560 epochs is = 0.10136501328150639\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.10136501328150639\n",
      "learning rate for this epoch =  0.10278340422512992\n",
      "Error on this batch = 0.05529564507958616\n",
      "Error on this batch = 0.08660156496405154\n",
      "Cost on val dataset after 561 epochs is = 0.10133047101825622\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.10133047101825622\n",
      "learning rate for this epoch =  0.10273756991976561\n",
      "Error on this batch = 0.05523665140971844\n",
      "Error on this batch = 0.08653668541831179\n",
      "Cost on val dataset after 562 epochs is = 0.10129604889419477\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.10129604889419477\n",
      "learning rate for this epoch =  0.10269183762714515\n",
      "Error on this batch = 0.055177842908952945\n",
      "Error on this batch = 0.08647202482741795\n",
      "Cost on val dataset after 563 epochs is = 0.10126174636778339\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.10126174636778339\n",
      "learning rate for this epoch =  0.10264620693930798\n",
      "Error on this batch = 0.0551192188717131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08640758219004141\n",
      "Cost on val dataset after 564 epochs is = 0.10122756289865747\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.10122756289865747\n",
      "learning rate for this epoch =  0.10260067745064594\n",
      "Error on this batch = 0.055060778596114524\n",
      "Error on this batch = 0.08634335650694837\n",
      "Cost on val dataset after 565 epochs is = 0.10119349794765294\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.10119349794765294\n",
      "learning rate for this epoch =  0.10255524875788552\n",
      "Error on this batch = 0.05500252138392593\n",
      "Error on this batch = 0.08627934678107138\n",
      "Cost on val dataset after 566 epochs is = 0.10115955097683225\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.10115955097683225\n",
      "learning rate for this epoch =  0.10250992046007043\n",
      "Error on this batch = 0.054944446540529754\n",
      "Error on this batch = 0.08621555201758004\n",
      "Cost on val dataset after 567 epochs is = 0.10112572144951029\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.10112572144951029\n",
      "learning rate for this epoch =  0.10246469215854406\n",
      "Error on this batch = 0.05488655337488407\n",
      "Error on this batch = 0.08615197122395013\n",
      "Cost on val dataset after 568 epochs is = 0.10109200883027943\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.10109200883027943\n",
      "learning rate for this epoch =  0.10241956345693246\n",
      "Error on this batch = 0.05482884119948414\n",
      "Error on this batch = 0.08608860341003194\n",
      "Cost on val dataset after 569 epochs is = 0.10105841258503477\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.10105841258503477\n",
      "learning rate for this epoch =  0.1023745339611271\n",
      "Error on this batch = 0.054771309330324994\n",
      "Error on this batch = 0.08602544758811721\n",
      "Cost on val dataset after 570 epochs is = 0.10102493218099844\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.10102493218099844\n",
      "learning rate for this epoch =  0.10232960327926806\n",
      "Error on this batch = 0.054713957086863906\n",
      "Error on this batch = 0.08596250277300493\n",
      "Cost on val dataset after 571 epochs is = 0.1009915670867438\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.1009915670867438\n",
      "learning rate for this epoch =  0.10228477102172728\n",
      "Error on this batch = 0.05465678379198366\n",
      "Error on this batch = 0.08589976798206603\n",
      "Cost on val dataset after 572 epochs is = 0.10095831677221884\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.10095831677221884\n",
      "learning rate for this epoch =  0.10224003680109194\n",
      "Error on this batch = 0.05459978877195582\n",
      "Error on this batch = 0.08583724223530671\n",
      "Cost on val dataset after 573 epochs is = 0.10092518070876957\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.10092518070876957\n",
      "learning rate for this epoch =  0.10219540023214801\n",
      "Error on this batch = 0.0545429713564047\n",
      "Error on this batch = 0.08577492455543084\n",
      "Cost on val dataset after 574 epochs is = 0.1008921583691624\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.1008921583691624\n",
      "learning rate for this epoch =  0.10215086093186404\n",
      "Error on this batch = 0.054486330878271545\n",
      "Error on this batch = 0.08571281396790081\n",
      "Cost on val dataset after 575 epochs is = 0.10085924922760643\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.10085924922760643\n",
      "learning rate for this epoch =  0.10210641851937487\n",
      "Error on this batch = 0.05442986667377903\n",
      "Error on this batch = 0.08565090950099752\n",
      "Cost on val dataset after 576 epochs is = 0.10082645275977499\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.10082645275977499\n",
      "learning rate for this epoch =  0.10206207261596577\n",
      "Error on this batch = 0.05437357808239618\n",
      "Error on this batch = 0.08558921018587903\n",
      "Cost on val dataset after 577 epochs is = 0.10079376844282674\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.10079376844282674\n",
      "learning rate for this epoch =  0.10201782284505649\n",
      "Error on this batch = 0.05431746444680366\n",
      "Error on this batch = 0.08552771505663781\n",
      "Cost on val dataset after 578 epochs is = 0.10076119575542618\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.10076119575542618\n",
      "learning rate for this epoch =  0.10197366883218573\n",
      "Error on this batch = 0.054261525112859206\n",
      "Error on this batch = 0.08546642315035716\n",
      "Cost on val dataset after 579 epochs is = 0.1007287341777637\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.1007287341777637\n",
      "learning rate for this epoch =  0.1019296102049953\n",
      "Error on this batch = 0.0542057594295637\n",
      "Error on this batch = 0.08540533350716603\n",
      "Cost on val dataset after 580 epochs is = 0.10069638319157506\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.10069638319157506\n",
      "learning rate for this epoch =  0.10188564659321496\n",
      "Error on this batch = 0.054150166749027236\n",
      "Error on this batch = 0.08534444517029303\n",
      "Cost on val dataset after 581 epochs is = 0.10066414228016016\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.10066414228016016\n",
      "learning rate for this epoch =  0.10184177762864698\n",
      "Error on this batch = 0.054094746426435754\n",
      "Error on this batch = 0.0852837571861189\n",
      "Cost on val dataset after 582 epochs is = 0.10063201092840153\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.10063201092840153\n",
      "learning rate for this epoch =  0.10179800294515103\n",
      "Error on this batch = 0.05403949782001765\n",
      "Error on this batch = 0.08522326860422785\n",
      "Cost on val dataset after 583 epochs is = 0.1005999886227821\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.1005999886227821\n",
      "learning rate for this epoch =  0.10175432217862923\n",
      "Error on this batch = 0.05398442029101128\n",
      "Error on this batch = 0.08516297847745787\n",
      "Cost on val dataset after 584 epochs is = 0.10056807485140228\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.10056807485140228\n",
      "learning rate for this epoch =  0.10171073496701123\n",
      "Error on this batch = 0.05392951320363177\n",
      "Error on this batch = 0.08510288586194965\n",
      "Cost on val dataset after 585 epochs is = 0.10053626910399668\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.10053626910399668\n",
      "learning rate for this epoch =  0.10166724095023941\n",
      "Error on this batch = 0.05387477592503931\n",
      "Error on this batch = 0.08504298981719446\n",
      "Cost on val dataset after 586 epochs is = 0.10050457087195025\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.10050457087195025\n",
      "learning rate for this epoch =  0.10162383977025442\n",
      "Error on this batch = 0.05382020782530668\n",
      "Error on this batch = 0.08498328940608055\n",
      "Cost on val dataset after 587 epochs is = 0.10047297964831373\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.10047297964831373\n",
      "learning rate for this epoch =  0.10158053107098057\n",
      "Error on this batch = 0.0537658082773876\n",
      "Error on this batch = 0.08492378369493879\n",
      "Cost on val dataset after 588 epochs is = 0.10044149492781856\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.10044149492781856\n",
      "learning rate for this epoch =  0.10153731449831156\n",
      "Error on this batch = 0.05371157665708518\n",
      "Error on this batch = 0.0848644717535867\n",
      "Cost on val dataset after 589 epochs is = 0.1004101162068913\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.1004101162068913\n",
      "learning rate for this epoch =  0.1014941897000962\n",
      "Error on this batch = 0.05365751234302065\n",
      "Error on this batch = 0.08480535265537167\n",
      "Cost on val dataset after 590 epochs is = 0.10037884298366748\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.10037884298366748\n",
      "learning rate for this epoch =  0.10145115632612439\n",
      "Error on this batch = 0.053603614716602264\n",
      "Error on this batch = 0.08474642547721258\n",
      "Cost on val dataset after 591 epochs is = 0.10034767475800474\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.10034767475800474\n",
      "learning rate for this epoch =  0.10140821402811308\n",
      "Error on this batch = 0.05354988316199456\n",
      "Error on this batch = 0.08468768929964067\n",
      "Cost on val dataset after 592 epochs is = 0.10031661103149572\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.10031661103149572\n",
      "learning rate for this epoch =  0.10136536245969245\n",
      "Error on this batch = 0.05349631706608779\n",
      "Error on this batch = 0.0846291432068391\n",
      "Cost on val dataset after 593 epochs is = 0.10028565130747992\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.10028565130747992\n",
      "learning rate for this epoch =  0.10132260127639228\n",
      "Error on this batch = 0.05344291581846743\n",
      "Error on this batch = 0.0845707862866811\n",
      "Cost on val dataset after 594 epochs is = 0.10025479509105557\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.10025479509105557\n",
      "learning rate for this epoch =  0.10127993013562818\n",
      "Error on this batch = 0.05338967881138434\n",
      "Error on this batch = 0.08451261763076748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 595 epochs is = 0.10022404188909059\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.10022404188909059\n",
      "learning rate for this epoch =  0.10123734869668825\n",
      "Error on this batch = 0.05333660543972453\n",
      "Error on this batch = 0.0844546363344623\n",
      "Cost on val dataset after 596 epochs is = 0.10019339121023303\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.10019339121023303\n",
      "learning rate for this epoch =  0.10119485662071964\n",
      "Error on this batch = 0.05328369510097973\n",
      "Error on this batch = 0.08439684149692823\n",
      "Cost on val dataset after 597 epochs is = 0.10016284256492114\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.10016284256492114\n",
      "learning rate for this epoch =  0.10115245357071535\n",
      "Error on this batch = 0.053230947195217815\n",
      "Error on this batch = 0.08433923222116001\n",
      "Cost on val dataset after 598 epochs is = 0.1001323954653928\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.1001323954653928\n",
      "learning rate for this epoch =  0.10111013921150111\n",
      "Error on this batch = 0.05317836112505345\n",
      "Error on this batch = 0.0842818076140172\n",
      "Cost on val dataset after 599 epochs is = 0.10010204942569456\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.10010204942569456\n",
      "learning rate for this epoch =  0.1010679132097223\n",
      "Error on this batch = 0.0531259362956191\n",
      "Error on this batch = 0.0842245667862559\n",
      "Cost on val dataset after 600 epochs is = 0.10007180396168992\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.10007180396168992\n",
      "learning rate for this epoch =  0.10102577523383117\n",
      "Error on this batch = 0.05307367211453624\n",
      "Error on this batch = 0.08416750885255893\n",
      "Cost on val dataset after 601 epochs is = 0.10004165859106737\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.10004165859106737\n",
      "learning rate for this epoch =  0.10098372495407393\n",
      "Error on this batch = 0.053021567991886454\n",
      "Error on this batch = 0.08411063293156534\n",
      "Cost on val dataset after 602 epochs is = 0.1000116128333478\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.1000116128333478\n",
      "learning rate for this epoch =  0.10094176204247814\n",
      "Error on this batch = 0.05296962334018313\n",
      "Error on this batch = 0.08405393814589865\n",
      "Cost on val dataset after 603 epochs is = 0.09998166620989155\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.09998166620989155\n",
      "learning rate for this epoch =  0.10089988617284017\n",
      "Error on this batch = 0.05291783757434318\n",
      "Error on this batch = 0.08399742362219378\n",
      "Cost on val dataset after 604 epochs is = 0.09995181824390476\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.09995181824390476\n",
      "learning rate for this epoch =  0.10085809702071269\n",
      "Error on this batch = 0.05286621011165882\n",
      "Error on this batch = 0.08394108849112358\n",
      "Cost on val dataset after 605 epochs is = 0.09992206846044546\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.09992206846044546\n",
      "learning rate for this epoch =  0.10081639426339235\n",
      "Error on this batch = 0.052814740371769774\n",
      "Error on this batch = 0.08388493188742337\n",
      "Cost on val dataset after 606 epochs is = 0.09989241638642916\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.09989241638642916\n",
      "learning rate for this epoch =  0.10077477757990758\n",
      "Error on this batch = 0.05276342777663563\n",
      "Error on this batch = 0.0838289529499152\n",
      "Cost on val dataset after 607 epochs is = 0.09986286155063391\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.09986286155063391\n",
      "learning rate for this epoch =  0.10073324665100637\n",
      "Error on this batch = 0.05271227175050818\n",
      "Error on this batch = 0.08377315082153071\n",
      "Cost on val dataset after 608 epochs is = 0.09983340348370505\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.09983340348370505\n",
      "learning rate for this epoch =  0.10069180115914433\n",
      "Error on this batch = 0.052661271719904236\n",
      "Error on this batch = 0.08371752464933291\n",
      "Cost on val dataset after 609 epochs is = 0.09980404171815939\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.09980404171815939\n",
      "learning rate for this epoch =  0.1006504407884727\n",
      "Error on this batch = 0.05261042711357849\n",
      "Error on this batch = 0.08366207358453713\n",
      "Cost on val dataset after 610 epochs is = 0.09977477578838914\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.09977477578838914\n",
      "learning rate for this epoch =  0.10060916522482655\n",
      "Error on this batch = 0.05255973736249666\n",
      "Error on this batch = 0.08360679678253082\n",
      "Cost on val dataset after 611 epochs is = 0.09974560523066521\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.09974560523066521\n",
      "learning rate for this epoch =  0.10056797415571314\n",
      "Error on this batch = 0.052509201899808663\n",
      "Error on this batch = 0.08355169340289229\n",
      "Cost on val dataset after 612 epochs is = 0.09971652958314042\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.09971652958314042\n",
      "learning rate for this epoch =  0.10052686727030014\n",
      "Error on this batch = 0.05245882016082232\n",
      "Error on this batch = 0.08349676260940864\n",
      "Cost on val dataset after 613 epochs is = 0.09968754838585206\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.09968754838585206\n",
      "learning rate for this epoch =  0.10048584425940424\n",
      "Error on this batch = 0.05240859158297696\n",
      "Error on this batch = 0.08344200357009263\n",
      "Cost on val dataset after 614 epochs is = 0.09965866118072413\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.09965866118072413\n",
      "learning rate for this epoch =  0.10044490481547967\n",
      "Error on this batch = 0.05235851560581738\n",
      "Error on this batch = 0.08338741545719841\n",
      "Cost on val dataset after 615 epochs is = 0.09962986751156941\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.09962986751156941\n",
      "learning rate for this epoch =  0.10040404863260693\n",
      "Error on this batch = 0.05230859167096815\n",
      "Error on this batch = 0.08333299744723636\n",
      "Cost on val dataset after 616 epochs is = 0.09960116692409088\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.09960116692409088\n",
      "learning rate for this epoch =  0.10036327540648149\n",
      "Error on this batch = 0.05225881922210785\n",
      "Error on this batch = 0.08327874872098728\n",
      "Cost on val dataset after 617 epochs is = 0.09957255896588309\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.09957255896588309\n",
      "learning rate for this epoch =  0.10032258483440272\n",
      "Error on this batch = 0.05220919770494391\n",
      "Error on this batch = 0.08322466846351517\n",
      "Cost on val dataset after 618 epochs is = 0.09954404318643294\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.09954404318643294\n",
      "learning rate for this epoch =  0.10028197661526282\n",
      "Error on this batch = 0.052159726567187335\n",
      "Error on this batch = 0.08317075586417931\n",
      "Cost on val dataset after 619 epochs is = 0.09951561913712043\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.09951561913712043\n",
      "learning rate for this epoch =  0.10024145044953589\n",
      "Error on this batch = 0.05211040525852813\n",
      "Error on this batch = 0.08311701011664542\n",
      "Cost on val dataset after 620 epochs is = 0.0994872863712188\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.0994872863712188\n",
      "learning rate for this epoch =  0.10020100603926707\n",
      "Error on this batch = 0.05206123323061039\n",
      "Error on this batch = 0.08306343041889601\n",
      "Cost on val dataset after 621 epochs is = 0.09945904444389468\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.09945904444389468\n",
      "learning rate for this epoch =  0.1001606430880618\n",
      "Error on this batch = 0.05201220993700839\n",
      "Error on this batch = 0.08301001597323948\n",
      "Cost on val dataset after 622 epochs is = 0.09943089291220765\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.09943089291220765\n",
      "learning rate for this epoch =  0.10012036130107511\n",
      "Error on this batch = 0.05196333483320228\n",
      "Error on this batch = 0.08295676598631868\n",
      "Cost on val dataset after 623 epochs is = 0.09940283133510988\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.09940283133510988\n",
      "learning rate for this epoch =  0.10008016038500113\n",
      "Error on this batch = 0.05191460737655459\n",
      "Error on this batch = 0.08290367966911844\n",
      "Cost on val dataset after 624 epochs is = 0.09937485927344525\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.09937485927344525\n",
      "learning rate for this epoch =  0.10004004004806248\n",
      "Error on this batch = 0.051866027026286655\n",
      "Error on this batch = 0.0828507562369723\n",
      "Cost on val dataset after 625 epochs is = 0.09934697628994825\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.09934697628994825\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 0.05181759324345581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08279799490956846\n",
      "Cost on val dataset after 626 epochs is = 0.09931918194924286\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.09931918194924286\n",
      "learning rate for this epoch =  0.09996003995206232\n",
      "Error on this batch = 0.05176930549093245\n",
      "Error on this batch = 0.08274539491095449\n",
      "Cost on val dataset after 627 epochs is = 0.09929147581784085\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.09929147581784085\n",
      "learning rate for this epoch =  0.0999201596169957\n",
      "Error on this batch = 0.051721163233377734\n",
      "Error on this batch = 0.08269295546954177\n",
      "Cost on val dataset after 628 epochs is = 0.09926385746414043\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.09926385746414043\n",
      "learning rate for this epoch =  0.09988035870903386\n",
      "Error on this batch = 0.05167316593722159\n",
      "Error on this batch = 0.08264067581810874\n",
      "Cost on val dataset after 629 epochs is = 0.09923632645842399\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.09923632645842399\n",
      "learning rate for this epoch =  0.09984063694388798\n",
      "Error on this batch = 0.05162531307064102\n",
      "Error on this batch = 0.0825885551938035\n",
      "Cost on val dataset after 630 epochs is = 0.09920888237285634\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.09920888237285634\n",
      "learning rate for this epoch =  0.09980099403873664\n",
      "Error on this batch = 0.05157760410353898\n",
      "Error on this batch = 0.08253659283814561\n",
      "Cost on val dataset after 631 epochs is = 0.09918152478148233\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.09918152478148233\n",
      "learning rate for this epoch =  0.099761429712216\n",
      "Error on this batch = 0.05153003850752349\n",
      "Error on this batch = 0.08248478799702698\n",
      "Cost on val dataset after 632 epochs is = 0.09915425326022444\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.09915425326022444\n",
      "learning rate for this epoch =  0.09972194368440992\n",
      "Error on this batch = 0.05148261575588714\n",
      "Error on this batch = 0.08243313992071213\n",
      "Cost on val dataset after 633 epochs is = 0.09912706738688042\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.09912706738688042\n",
      "learning rate for this epoch =  0.09968253567684038\n",
      "Error on this batch = 0.05143533532358735\n",
      "Error on this batch = 0.08238164786383781\n",
      "Cost on val dataset after 634 epochs is = 0.0990999667411205\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.0990999667411205\n",
      "learning rate for this epoch =  0.09964320541245761\n",
      "Error on this batch = 0.05138819668722672\n",
      "Error on this batch = 0.08233031108541156\n",
      "Cost on val dataset after 635 epochs is = 0.0990729509044846\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.0990729509044846\n",
      "learning rate for this epoch =  0.09960395261563074\n",
      "Error on this batch = 0.051341199325034045\n",
      "Error on this batch = 0.08227912884880974\n",
      "Cost on val dataset after 636 epochs is = 0.09904601946037962\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.09904601946037962\n",
      "learning rate for this epoch =  0.0995647770121382\n",
      "Error on this batch = 0.05129434271684578\n",
      "Error on this batch = 0.08222810042177489\n",
      "Cost on val dataset after 637 epochs is = 0.09901917199407625\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.09901917199407625\n",
      "learning rate for this epoch =  0.0995256783291583\n",
      "Error on this batch = 0.05124762634408814\n",
      "Error on this batch = 0.08217722507641234\n",
      "Cost on val dataset after 638 epochs is = 0.09899240809270615\n",
      "Initial Cost on Val dataset for this epoch 638 = 0.09899240809270615\n",
      "learning rate for this epoch =  0.09948665629526\n",
      "Error on this batch = 0.051201049689759394\n",
      "Error on this batch = 0.082126502089186\n",
      "Cost on val dataset after 639 epochs is = 0.09896572734525853\n",
      "Initial Cost on Val dataset for this epoch 639 = 0.09896572734525853\n",
      "learning rate for this epoch =  0.09944771064039355\n",
      "Error on this batch = 0.05115461223841311\n",
      "Error on this batch = 0.08207593074091377\n",
      "Cost on val dataset after 640 epochs is = 0.09893912934257741\n",
      "Initial Cost on Val dataset for this epoch 640 = 0.09893912934257741\n",
      "learning rate for this epoch =  0.09940884109588133\n",
      "Error on this batch = 0.05110831347614182\n",
      "Error on this batch = 0.08202551031676186\n",
      "Cost on val dataset after 641 epochs is = 0.09891261367735792\n",
      "Initial Cost on Val dataset for this epoch 641 = 0.09891261367735792\n",
      "learning rate for this epoch =  0.09937004739440881\n",
      "Error on this batch = 0.05106215289056104\n",
      "Error on this batch = 0.08197524010623901\n",
      "Cost on val dataset after 642 epochs is = 0.09888617994414342\n",
      "Initial Cost on Val dataset for this epoch 642 = 0.09888617994414342\n",
      "learning rate for this epoch =  0.09933132927001546\n",
      "Error on this batch = 0.051016129970794286\n",
      "Error on this batch = 0.08192511940318958\n",
      "Cost on val dataset after 643 epochs is = 0.09885982773932205\n",
      "Initial Cost on Val dataset for this epoch 643 = 0.09885982773932205\n",
      "learning rate for this epoch =  0.09929268645808582\n",
      "Error on this batch = 0.050970244207458375\n",
      "Error on this batch = 0.08187514750578627\n",
      "Cost on val dataset after 644 epochs is = 0.0988335566611235\n",
      "Initial Cost on Val dataset for this epoch 644 = 0.0988335566611235\n",
      "learning rate for this epoch =  0.09925411869534059\n",
      "Error on this batch = 0.050924495092649597\n",
      "Error on this batch = 0.08182532371652217\n",
      "Cost on val dataset after 645 epochs is = 0.0988073663096157\n",
      "Initial Cost on Val dataset for this epoch 645 = 0.0988073663096157\n",
      "learning rate for this epoch =  0.0992156257198279\n",
      "Error on this batch = 0.05087888211993032\n",
      "Error on this batch = 0.08177564734220225\n",
      "Cost on val dataset after 646 epochs is = 0.09878125628670163\n",
      "Initial Cost on Val dataset for this epoch 646 = 0.09878125628670163\n",
      "learning rate for this epoch =  0.09917720727091442\n",
      "Error on this batch = 0.05083340478431654\n",
      "Error on this batch = 0.08172611769393423\n",
      "Cost on val dataset after 647 epochs is = 0.09875522619611603\n",
      "Initial Cost on Val dataset for this epoch 647 = 0.09875522619611603\n",
      "learning rate for this epoch =  0.09913886308927693\n",
      "Error on this batch = 0.05078806258226589\n",
      "Error on this batch = 0.08167673408711888\n",
      "Cost on val dataset after 648 epochs is = 0.09872927564342218\n",
      "Initial Cost on Val dataset for this epoch 648 = 0.09872927564342218\n",
      "learning rate for this epoch =  0.09910059291689342\n",
      "Error on this batch = 0.050742855011666484\n",
      "Error on this batch = 0.08162749584143981\n",
      "Cost on val dataset after 649 epochs is = 0.0987034042360088\n",
      "Initial Cost on Val dataset for this epoch 649 = 0.0987034042360088\n",
      "learning rate for this epoch =  0.09906239649703485\n",
      "Error on this batch = 0.050697781571826306\n",
      "Error on this batch = 0.08157840228085263\n",
      "Cost on val dataset after 650 epochs is = 0.09867761158308695\n",
      "Initial Cost on Val dataset for this epoch 650 = 0.09867761158308695\n",
      "learning rate for this epoch =  0.09902427357425653\n",
      "Error on this batch = 0.05065284176346365\n",
      "Error on this batch = 0.08152945273357366\n",
      "Cost on val dataset after 651 epochs is = 0.09865189729568696\n",
      "Initial Cost on Val dataset for this epoch 651 = 0.09865189729568696\n",
      "learning rate for this epoch =  0.09898622389438974\n",
      "Error on this batch = 0.05060803508869803\n",
      "Error on this batch = 0.08148064653206813\n",
      "Cost on val dataset after 652 epochs is = 0.09862626098665551\n",
      "Initial Cost on Val dataset for this epoch 652 = 0.09862626098665551\n",
      "learning rate for this epoch =  0.09894824720453346\n",
      "Error on this batch = 0.05056336105104193\n",
      "Error on this batch = 0.08143198301303788\n",
      "Cost on val dataset after 653 epochs is = 0.09860070227065278\n",
      "Initial Cost on Val dataset for this epoch 653 = 0.09860070227065278\n",
      "learning rate for this epoch =  0.09891034325304611\n",
      "Error on this batch = 0.05051881915539345\n",
      "Error on this batch = 0.08138346151740841\n",
      "Cost on val dataset after 654 epochs is = 0.09857522076414967\n",
      "Initial Cost on Val dataset for this epoch 654 = 0.09857522076414967\n",
      "learning rate for this epoch =  0.09887251178953727\n",
      "Error on this batch = 0.05047440890802955\n",
      "Error on this batch = 0.08133508139031559\n",
      "Cost on val dataset after 655 epochs is = 0.09854981608542515\n",
      "Initial Cost on Val dataset for this epoch 655 = 0.09854981608542515\n",
      "learning rate for this epoch =  0.09883475256485971\n",
      "Error on this batch = 0.050430129816600354\n",
      "Error on this batch = 0.0812868419810921\n",
      "Cost on val dataset after 656 epochs is = 0.0985244878545637\n",
      "Initial Cost on Val dataset for this epoch 656 = 0.0985244878545637\n",
      "learning rate for this epoch =  0.09879706533110119\n",
      "Error on this batch = 0.05038598139012388\n",
      "Error on this batch = 0.0812387426432529\n",
      "Cost on val dataset after 657 epochs is = 0.09849923569345291\n",
      "Initial Cost on Val dataset for this epoch 657 = 0.09849923569345291\n",
      "learning rate for this epoch =  0.09875944984157659\n",
      "Error on this batch = 0.050341963138982086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.08119078273448083\n",
      "Cost on val dataset after 658 epochs is = 0.09847405922578115\n",
      "Initial Cost on Val dataset for this epoch 658 = 0.09847405922578115\n",
      "learning rate for this epoch =  0.09872190585081982\n",
      "Error on this batch = 0.05029807457491736\n",
      "Error on this batch = 0.08114296161661139\n",
      "Cost on val dataset after 659 epochs is = 0.09844895807703555\n",
      "Initial Cost on Val dataset for this epoch 659 = 0.09844895807703555\n",
      "learning rate for this epoch =  0.09868443311457611\n",
      "Error on this batch = 0.05025431521102995\n",
      "Error on this batch = 0.08109527865561718\n",
      "Cost on val dataset after 660 epochs is = 0.0984239318744997\n",
      "Initial Cost on Val dataset for this epoch 660 = 0.0984239318744997\n",
      "learning rate for this epoch =  0.09864703138979418\n",
      "Error on this batch = 0.05021068456177634\n",
      "Error on this batch = 0.08104773322159221\n",
      "Cost on val dataset after 661 epochs is = 0.09839898024725224\n",
      "Initial Cost on Val dataset for this epoch 661 = 0.09839898024725224\n",
      "learning rate for this epoch =  0.09860970043461836\n",
      "Error on this batch = 0.05016718214296837\n",
      "Error on this batch = 0.08100032468873533\n",
      "Cost on val dataset after 662 epochs is = 0.0983741028261647\n",
      "Initial Cost on Val dataset for this epoch 662 = 0.0983741028261647\n",
      "learning rate for this epoch =  0.09857244000838114\n",
      "Error on this batch = 0.050123807471773335\n",
      "Error on this batch = 0.08095305243533364\n",
      "Cost on val dataset after 663 epochs is = 0.09834929924390032\n",
      "Initial Cost on Val dataset for this epoch 663 = 0.09834929924390032\n",
      "learning rate for this epoch =  0.09853524987159529\n",
      "Error on this batch = 0.05008056006671474\n",
      "Error on this batch = 0.08090591584374565\n",
      "Cost on val dataset after 664 epochs is = 0.09832456913491246\n",
      "Initial Cost on Val dataset for this epoch 664 = 0.09832456913491246\n",
      "learning rate for this epoch =  0.0984981297859465\n",
      "Error on this batch = 0.05003743944767404\n",
      "Error on this batch = 0.08085891430038349\n",
      "Cost on val dataset after 665 epochs is = 0.09829991213544347\n",
      "Initial Cost on Val dataset for this epoch 665 = 0.09829991213544347\n",
      "learning rate for this epoch =  0.09846107951428583\n",
      "Error on this batch = 0.04999444513589324\n",
      "Error on this batch = 0.08081204719569535\n",
      "Cost on val dataset after 666 epochs is = 0.09827532788352382\n",
      "Initial Cost on Val dataset for this epoch 666 = 0.09827532788352382\n",
      "learning rate for this epoch =  0.09842409882062221\n",
      "Error on this batch = 0.04995157665397832\n",
      "Error on this batch = 0.08076531392414749\n",
      "Cost on val dataset after 667 epochs is = 0.09825081601897105\n",
      "Initial Cost on Val dataset for this epoch 667 = 0.09825081601897105\n",
      "learning rate for this epoch =  0.09838718747011513\n",
      "Error on this batch = 0.04990883352590347\n",
      "Error on this batch = 0.08071871388420558\n",
      "Cost on val dataset after 668 epochs is = 0.09822637618338921\n",
      "Initial Cost on Val dataset for this epoch 668 = 0.09822637618338921\n",
      "learning rate for this epoch =  0.09835034522906724\n",
      "Error on this batch = 0.04986621527701624\n",
      "Error on this batch = 0.08067224647831614\n",
      "Cost on val dataset after 669 epochs is = 0.09820200802016839\n",
      "Initial Cost on Val dataset for this epoch 669 = 0.09820200802016839\n",
      "learning rate for this epoch =  0.09831357186491718\n",
      "Error on this batch = 0.04982372143404339\n",
      "Error on this batch = 0.0806259111128874\n",
      "Cost on val dataset after 670 epochs is = 0.09817771117448448\n",
      "Initial Cost on Val dataset for this epoch 670 = 0.09817771117448448\n",
      "learning rate for this epoch =  0.09827686714623232\n",
      "Error on this batch = 0.049781351525097745\n",
      "Error on this batch = 0.08057970719826991\n",
      "Cost on val dataset after 671 epochs is = 0.09815348529329897\n",
      "Initial Cost on Val dataset for this epoch 671 = 0.09815348529329897\n",
      "learning rate for this epoch =  0.09824023084270153\n",
      "Error on this batch = 0.04973910507968562\n",
      "Error on this batch = 0.08053363414873715\n",
      "Cost on val dataset after 672 epochs is = 0.0981293300253591\n",
      "Initial Cost on Val dataset for this epoch 672 = 0.0981293300253591\n",
      "learning rate for this epoch =  0.09820366272512825\n",
      "Error on this batch = 0.049696981628715324\n",
      "Error on this batch = 0.08048769138246527\n",
      "Cost on val dataset after 673 epochs is = 0.0981052450211982\n",
      "Initial Cost on Val dataset for this epoch 673 = 0.0981052450211982\n",
      "learning rate for this epoch =  0.0981671625654233\n",
      "Error on this batch = 0.04965498070450616\n",
      "Error on this batch = 0.08044187832151313\n",
      "Cost on val dataset after 674 epochs is = 0.09808122993313603\n",
      "Initial Cost on Val dataset for this epoch 674 = 0.09808122993313603\n",
      "learning rate for this epoch =  0.09813073013659797\n",
      "Error on this batch = 0.0496131018407984\n",
      "Error on this batch = 0.08039619439180186\n",
      "Cost on val dataset after 675 epochs is = 0.09805728441527951\n",
      "Initial Cost on Val dataset for this epoch 675 = 0.09805728441527951\n",
      "learning rate for this epoch =  0.09809436521275706\n",
      "Error on this batch = 0.04957134457276388\n",
      "Error on this batch = 0.08035063902309403\n",
      "Cost on val dataset after 676 epochs is = 0.09803340812352347\n",
      "Initial Cost on Val dataset for this epoch 676 = 0.09803340812352347\n",
      "learning rate for this epoch =  0.09805806756909202\n",
      "Error on this batch = 0.049529708437017275\n",
      "Error on this batch = 0.0803052116489729\n",
      "Cost on val dataset after 677 epochs is = 0.09800960071555177\n",
      "Initial Cost on Val dataset for this epoch 677 = 0.09800960071555177\n",
      "learning rate for this epoch =  0.09802183698187408\n",
      "Error on this batch = 0.049488192971628264\n",
      "Error on this batch = 0.08025991170682106\n",
      "Cost on val dataset after 678 epochs is = 0.09798586185083834\n",
      "Initial Cost on Val dataset for this epoch 678 = 0.09798586185083834\n",
      "learning rate for this epoch =  0.09798567322844758\n",
      "Error on this batch = 0.04944679771613414\n",
      "Error on this batch = 0.08021473863779915\n",
      "Cost on val dataset after 679 epochs is = 0.09796219119064863\n",
      "Initial Cost on Val dataset for this epoch 679 = 0.09796219119064863\n",
      "learning rate for this epoch =  0.09794957608722307\n",
      "Error on this batch = 0.049405522211553164\n",
      "Error on this batch = 0.0801696918868241\n",
      "Cost on val dataset after 680 epochs is = 0.097938588398041\n",
      "Initial Cost on Val dataset for this epoch 680 = 0.097938588398041\n",
      "learning rate for this epoch =  0.09791354533767088\n",
      "Error on this batch = 0.049364366000398605\n",
      "Error on this batch = 0.08012477090254748\n",
      "Cost on val dataset after 681 epochs is = 0.0979150531378685\n",
      "Initial Cost on Val dataset for this epoch 681 = 0.0979150531378685\n",
      "learning rate for this epoch =  0.09787758076031428\n",
      "Error on this batch = 0.04932332862669318\n",
      "Error on this batch = 0.08007997513733323\n",
      "Cost on val dataset after 682 epochs is = 0.09789158507678061\n",
      "Initial Cost on Val dataset for this epoch 682 = 0.09789158507678061\n",
      "learning rate for this epoch =  0.09784168213672302\n",
      "Error on this batch = 0.04928240963598423\n",
      "Error on this batch = 0.08003530404723552\n",
      "Cost on val dataset after 683 epochs is = 0.0978681838832252\n",
      "Initial Cost on Val dataset for this epoch 683 = 0.0978681838832252\n",
      "learning rate for this epoch =  0.09780584924950686\n",
      "Error on this batch = 0.04924160857535938\n",
      "Error on this batch = 0.0799907570919763\n",
      "Cost on val dataset after 684 epochs is = 0.0978448492274506\n",
      "Initial Cost on Val dataset for this epoch 684 = 0.0978448492274506\n",
      "learning rate for this epoch =  0.09777008188230901\n",
      "Error on this batch = 0.04920092499346245\n",
      "Error on this batch = 0.07994633373492267\n",
      "Cost on val dataset after 685 epochs is = 0.09782158078150782\n",
      "Initial Cost on Val dataset for this epoch 685 = 0.09782158078150782\n",
      "learning rate for this epoch =  0.09773437981979974\n",
      "Error on this batch = 0.04916035844051016\n",
      "Error on this batch = 0.07990203344306386\n",
      "Cost on val dataset after 686 epochs is = 0.09779837821925293\n",
      "Initial Cost on Val dataset for this epoch 686 = 0.09779837821925293\n",
      "learning rate for this epoch =  0.09769874284767002\n",
      "Error on this batch = 0.049119908468309055\n",
      "Error on this batch = 0.07985785568698854\n",
      "Cost on val dataset after 687 epochs is = 0.09777524121634934\n",
      "Initial Cost on Val dataset for this epoch 687 = 0.09777524121634934\n",
      "learning rate for this epoch =  0.0976631707526253\n",
      "Error on this batch = 0.04907957463027274\n",
      "Error on this batch = 0.07981379994086116\n",
      "Cost on val dataset after 688 epochs is = 0.09775216945027046\n",
      "Initial Cost on Val dataset for this epoch 688 = 0.09775216945027046\n",
      "learning rate for this epoch =  0.09762766332237903\n",
      "Error on this batch = 0.04903935648143959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07976986568239919\n",
      "Cost on val dataset after 689 epochs is = 0.09772916260030222\n",
      "Initial Cost on Val dataset for this epoch 689 = 0.09772916260030222\n",
      "learning rate for this epoch =  0.09759222034564662\n",
      "Error on this batch = 0.04899925357849062\n",
      "Error on this batch = 0.07972605239284901\n",
      "Cost on val dataset after 690 epochs is = 0.09770622034754571\n",
      "Initial Cost on Val dataset for this epoch 690 = 0.09770622034754571\n",
      "learning rate for this epoch =  0.09755684161213918\n",
      "Error on this batch = 0.04895926547976779\n",
      "Error on this batch = 0.07968235955696266\n",
      "Cost on val dataset after 691 epochs is = 0.09768334237492006\n",
      "Initial Cost on Val dataset for this epoch 691 = 0.09768334237492006\n",
      "learning rate for this epoch =  0.09752152691255746\n",
      "Error on this batch = 0.04891939174529224\n",
      "Error on this batch = 0.07963878666297367\n",
      "Cost on val dataset after 692 epochs is = 0.09766052836716498\n",
      "Initial Cost on Val dataset for this epoch 692 = 0.09766052836716498\n",
      "learning rate for this epoch =  0.09748627603858566\n",
      "Error on this batch = 0.04887963193678271\n",
      "Error on this batch = 0.07959533320257318\n",
      "Cost on val dataset after 693 epochs is = 0.09763777801084378\n",
      "Initial Cost on Val dataset for this epoch 693 = 0.09763777801084378\n",
      "learning rate for this epoch =  0.09745108878288547\n",
      "Error on this batch = 0.048839985617674504\n",
      "Error on this batch = 0.07955199867088585\n",
      "Cost on val dataset after 694 epochs is = 0.097615090994346\n",
      "Initial Cost on Val dataset for this epoch 694 = 0.097615090994346\n",
      "learning rate for this epoch =  0.09741596493909016\n",
      "Error on this batch = 0.048800452353137826\n",
      "Error on this batch = 0.0795087825664454\n",
      "Cost on val dataset after 695 epochs is = 0.09759246700789036\n",
      "Initial Cost on Val dataset for this epoch 695 = 0.09759246700789036\n",
      "learning rate for this epoch =  0.09738090430179841\n",
      "Error on this batch = 0.04876103171009675\n",
      "Error on this batch = 0.07946568439117027\n",
      "Cost on val dataset after 696 epochs is = 0.09756990574352747\n",
      "Initial Cost on Val dataset for this epoch 696 = 0.09756990574352747\n",
      "learning rate for this epoch =  0.09734590666656863\n",
      "Error on this batch = 0.048721723257247634\n",
      "Error on this batch = 0.07942270365033897\n",
      "Cost on val dataset after 697 epochs is = 0.09754740689514269\n",
      "Initial Cost on Val dataset for this epoch 697 = 0.09754740689514269\n",
      "learning rate for this epoch =  0.09731097182991302\n",
      "Error on this batch = 0.04868252656507801\n",
      "Error on this batch = 0.07937983985256535\n",
      "Cost on val dataset after 698 epochs is = 0.09752497015845872\n",
      "Initial Cost on Val dataset for this epoch 698 = 0.09752497015845872\n",
      "learning rate for this epoch =  0.09727609958929176\n",
      "Error on this batch = 0.048643441205884916\n",
      "Error on this batch = 0.07933709250977368\n",
      "Cost on val dataset after 699 epochs is = 0.09750259523103844\n",
      "Initial Cost on Val dataset for this epoch 699 = 0.09750259523103844\n",
      "learning rate for this epoch =  0.09724128974310718\n",
      "Error on this batch = 0.04860446675379319\n",
      "Error on this batch = 0.07929446113717388\n",
      "Cost on val dataset after 700 epochs is = 0.0974802818122874\n",
      "Initial Cost on Val dataset for this epoch 700 = 0.0974802818122874\n",
      "learning rate for this epoch =  0.09720654209069819\n",
      "Error on this batch = 0.04856560278477362\n",
      "Error on this batch = 0.07925194525323598\n",
      "Cost on val dataset after 701 epochs is = 0.0974580296034563\n",
      "Initial Cost on Val dataset for this epoch 701 = 0.0974580296034563\n",
      "learning rate for this epoch =  0.09717185643233449\n",
      "Error on this batch = 0.048526848876660846\n",
      "Error on this batch = 0.07920954437966522\n",
      "Cost on val dataset after 702 epochs is = 0.09743583830764352\n",
      "Initial Cost on Val dataset for this epoch 702 = 0.09743583830764352\n",
      "learning rate for this epoch =  0.09713723256921088\n",
      "Error on this batch = 0.048488204609170714\n",
      "Error on this batch = 0.07916725804137657\n",
      "Cost on val dataset after 703 epochs is = 0.09741370762979724\n",
      "Initial Cost on Val dataset for this epoch 703 = 0.09741370762979724\n",
      "learning rate for this epoch =  0.09710267030344186\n",
      "Error on this batch = 0.048449669563917636\n",
      "Error on this batch = 0.07912508576646905\n",
      "Cost on val dataset after 704 epochs is = 0.09739163727671761\n",
      "Initial Cost on Val dataset for this epoch 704 = 0.09739163727671761\n",
      "learning rate for this epoch =  0.09706816943805581\n",
      "Error on this batch = 0.048411243324431405\n",
      "Error on this batch = 0.07908302708620032\n",
      "Cost on val dataset after 705 epochs is = 0.09736962695705882\n",
      "Initial Cost on Val dataset for this epoch 705 = 0.09736962695705882\n",
      "learning rate for this epoch =  0.09703372977698975\n",
      "Error on this batch = 0.04837292547617333\n",
      "Error on this batch = 0.07904108153496085\n",
      "Cost on val dataset after 706 epochs is = 0.0973476763813308\n",
      "Initial Cost on Val dataset for this epoch 706 = 0.0973476763813308\n",
      "learning rate for this epoch =  0.09699935112508366\n",
      "Error on this batch = 0.04833471560655252\n",
      "Error on this batch = 0.07899924865024813\n",
      "Cost on val dataset after 707 epochs is = 0.09732578526190085\n",
      "Initial Cost on Val dataset for this epoch 707 = 0.09732578526190085\n",
      "learning rate for this epoch =  0.09696503328807513\n",
      "Error on this batch = 0.04829661330494073\n",
      "Error on this batch = 0.07895752797264051\n",
      "Cost on val dataset after 708 epochs is = 0.09730395331299513\n",
      "Initial Cost on Val dataset for this epoch 708 = 0.09730395331299513\n",
      "learning rate for this epoch =  0.09693077607259398\n",
      "Error on this batch = 0.04825861816268777\n",
      "Error on this batch = 0.07891591904577137\n",
      "Cost on val dataset after 709 epochs is = 0.09728218025069979\n",
      "Initial Cost on Val dataset for this epoch 709 = 0.09728218025069979\n",
      "learning rate for this epoch =  0.09689657928615694\n",
      "Error on this batch = 0.04822072977313532\n",
      "Error on this batch = 0.07887442141630288\n",
      "Cost on val dataset after 710 epochs is = 0.09726046579296194\n",
      "Initial Cost on Val dataset for this epoch 710 = 0.09726046579296194\n",
      "learning rate for this epoch =  0.09686244273716216\n",
      "Error on this batch = 0.048182947731630725\n",
      "Error on this batch = 0.07883303463389957\n",
      "Cost on val dataset after 711 epochs is = 0.0972388096595904\n",
      "Initial Cost on Val dataset for this epoch 711 = 0.0972388096595904\n",
      "learning rate for this epoch =  0.09682836623488422\n",
      "Error on this batch = 0.04814527163553987\n",
      "Error on this batch = 0.0787917582512022\n",
      "Cost on val dataset after 712 epochs is = 0.09721721157225607\n",
      "Initial Cost on Val dataset for this epoch 712 = 0.09721721157225607\n",
      "learning rate for this epoch =  0.09679434958946864\n",
      "Error on this batch = 0.048107701084259526\n",
      "Error on this batch = 0.07875059182380102\n",
      "Cost on val dataset after 713 epochs is = 0.0971956712544923\n",
      "Initial Cost on Val dataset for this epoch 713 = 0.0971956712544923\n",
      "learning rate for this epoch =  0.09676039261192684\n",
      "Error on this batch = 0.0480702356792288\n",
      "Error on this batch = 0.0787095349102096\n",
      "Cost on val dataset after 714 epochs is = 0.09717418843169451\n",
      "Initial Cost on Val dataset for this epoch 714 = 0.09717418843169451\n",
      "learning rate for this epoch =  0.09672649511413095\n",
      "Error on this batch = 0.048032875023940054\n",
      "Error on this batch = 0.07866858707183771\n",
      "Cost on val dataset after 715 epochs is = 0.09715276283111995\n",
      "Initial Cost on Val dataset for this epoch 715 = 0.09715276283111995\n",
      "learning rate for this epoch =  0.0966926569088086\n",
      "Error on this batch = 0.04799561872394879\n",
      "Error on this batch = 0.07862774787296505\n",
      "Cost on val dataset after 716 epochs is = 0.09713139418188708\n",
      "Initial Cost on Val dataset for this epoch 716 = 0.09713139418188708\n",
      "learning rate for this epoch =  0.09665887780953801\n",
      "Error on this batch = 0.04795846638688298\n",
      "Error on this batch = 0.0785870168807141\n",
      "Cost on val dataset after 717 epochs is = 0.09711008221497419\n",
      "Initial Cost on Val dataset for this epoch 717 = 0.09711008221497419\n",
      "learning rate for this epoch =  0.09662515763074277\n",
      "Error on this batch = 0.047921417622451355\n",
      "Error on this batch = 0.07854639366502345\n",
      "Cost on val dataset after 718 epochs is = 0.09708882666321839\n",
      "Initial Cost on Val dataset for this epoch 718 = 0.09708882666321839\n",
      "learning rate for this epoch =  0.09659149618768699\n",
      "Error on this batch = 0.04788447204245116\n",
      "Error on this batch = 0.07850587779862077\n",
      "Cost on val dataset after 719 epochs is = 0.09706762726131353\n",
      "Initial Cost on Val dataset for this epoch 719 = 0.09706762726131353\n",
      "learning rate for this epoch =  0.09655789329647017\n",
      "Error on this batch = 0.047847629260774606\n",
      "Error on this batch = 0.07846546885699582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 720 epochs is = 0.09704648374580836\n",
      "Initial Cost on Val dataset for this epoch 720 = 0.09704648374580836\n",
      "learning rate for this epoch =  0.09652434877402243\n",
      "Error on this batch = 0.04781088889341493\n",
      "Error on this batch = 0.07842516641837347\n",
      "Cost on val dataset after 721 epochs is = 0.09702539585510404\n",
      "Initial Cost on Val dataset for this epoch 721 = 0.09702539585510404\n",
      "learning rate for this epoch =  0.09649086243809947\n",
      "Error on this batch = 0.04777425055847127\n",
      "Error on this batch = 0.07838497006368639\n",
      "Cost on val dataset after 722 epochs is = 0.09700436332945124\n",
      "Initial Cost on Val dataset for this epoch 722 = 0.09700436332945124\n",
      "learning rate for this epoch =  0.09645743410727778\n",
      "Error on this batch = 0.047737713876152645\n",
      "Error on this batch = 0.07834487937654809\n",
      "Cost on val dataset after 723 epochs is = 0.0969833859109469\n",
      "Initial Cost on Val dataset for this epoch 723 = 0.0969833859109469\n",
      "learning rate for this epoch =  0.09642406360094986\n",
      "Error on this batch = 0.04770127846878122\n",
      "Error on this batch = 0.07830489394322551\n",
      "Cost on val dataset after 724 epochs is = 0.09696246334353081\n",
      "Initial Cost on Val dataset for this epoch 724 = 0.09696246334353081\n",
      "learning rate for this epoch =  0.09639075073931928\n",
      "Error on this batch = 0.04766494396079448\n",
      "Error on this batch = 0.07826501335261196\n",
      "Cost on val dataset after 725 epochs is = 0.09694159537298143\n",
      "Initial Cost on Val dataset for this epoch 725 = 0.09694159537298143\n",
      "learning rate for this epoch =  0.09635749534339606\n",
      "Error on this batch = 0.04762870997874666\n",
      "Error on this batch = 0.07822523719619963\n",
      "Cost on val dataset after 726 epochs is = 0.09692078174691177\n",
      "Initial Cost on Val dataset for this epoch 726 = 0.09692078174691177\n",
      "learning rate for this epoch =  0.0963242972349919\n",
      "Error on this batch = 0.047592576151309046\n",
      "Error on this batch = 0.07818556506805252\n",
      "Cost on val dataset after 727 epochs is = 0.09690002221476426\n",
      "Initial Cost on Val dataset for this epoch 727 = 0.09690002221476426\n",
      "learning rate for this epoch =  0.09629115623671548\n",
      "Error on this batch = 0.04755654210926941\n",
      "Error on this batch = 0.07814599656477886\n",
      "Cost on val dataset after 728 epochs is = 0.09687931652780585\n",
      "Initial Cost on Val dataset for this epoch 728 = 0.09687931652780585\n",
      "learning rate for this epoch =  0.09625807217196783\n",
      "Error on this batch = 0.047520607485530934\n",
      "Error on this batch = 0.07810653128550397\n",
      "Cost on val dataset after 729 epochs is = 0.09685866443912243\n",
      "Initial Cost on Val dataset for this epoch 729 = 0.09685866443912243\n",
      "learning rate for this epoch =  0.09622504486493763\n",
      "Error on this batch = 0.047484771915109504\n",
      "Error on this batch = 0.07806716883184282\n",
      "Cost on val dataset after 730 epochs is = 0.09683806570361267\n",
      "Initial Cost on Val dataset for this epoch 730 = 0.09683806570361267\n",
      "learning rate for this epoch =  0.09619207414059677\n",
      "Error on this batch = 0.047449035035130774\n",
      "Error on this batch = 0.07802790880787266\n",
      "Cost on val dataset after 731 epochs is = 0.09681752007798172\n",
      "Initial Cost on Val dataset for this epoch 731 = 0.09681752007798172\n",
      "learning rate for this epoch =  0.09615915982469565\n",
      "Error on this batch = 0.047413396484825884\n",
      "Error on this batch = 0.07798875082010569\n",
      "Cost on val dataset after 732 epochs is = 0.09679702732073445\n",
      "Initial Cost on Val dataset for this epoch 732 = 0.09679702732073445\n",
      "learning rate for this epoch =  0.09612630174375877\n",
      "Error on this batch = 0.047377855905526636\n",
      "Error on this batch = 0.07794969447746179\n",
      "Cost on val dataset after 733 epochs is = 0.09677658719216814\n",
      "Initial Cost on Val dataset for this epoch 733 = 0.09677658719216814\n",
      "learning rate for this epoch =  0.09609349972508012\n",
      "Error on this batch = 0.04734241294065953\n",
      "Error on this batch = 0.07791073939124112\n",
      "Cost on val dataset after 734 epochs is = 0.09675619945436507\n",
      "Initial Cost on Val dataset for this epoch 734 = 0.09675619945436507\n",
      "learning rate for this epoch =  0.09606075359671883\n",
      "Error on this batch = 0.047307067235739124\n",
      "Error on this batch = 0.07787188517509694\n",
      "Cost on val dataset after 735 epochs is = 0.09673586387118431\n",
      "Initial Cost on Val dataset for this epoch 735 = 0.09673586387118431\n",
      "learning rate for this epoch =  0.09602806318749467\n",
      "Error on this batch = 0.04727181843836047\n",
      "Error on this batch = 0.07783313144500824\n",
      "Cost on val dataset after 736 epochs is = 0.0967155802082534\n",
      "Initial Cost on Val dataset for this epoch 736 = 0.0967155802082534\n",
      "learning rate for this epoch =  0.09599542832698374\n",
      "Error on this batch = 0.04723666619819083\n",
      "Error on this batch = 0.07779447781925258\n",
      "Cost on val dataset after 737 epochs is = 0.09669534823295962\n",
      "Initial Cost on Val dataset for this epoch 737 = 0.09669534823295962\n",
      "learning rate for this epoch =  0.095962848845514\n",
      "Error on this batch = 0.047201610166960374\n",
      "Error on this batch = 0.07775592391837899\n",
      "Cost on val dataset after 738 epochs is = 0.0966751677144408\n",
      "Initial Cost on Val dataset for this epoch 738 = 0.0966751677144408\n",
      "learning rate for this epoch =  0.09593032457416101\n",
      "Error on this batch = 0.04716664999845252\n",
      "Error on this batch = 0.0777174693651808\n",
      "Cost on val dataset after 739 epochs is = 0.09665503842357573\n",
      "Initial Cost on Val dataset for this epoch 739 = 0.09665503842357573\n",
      "learning rate for this epoch =  0.09589785534474361\n",
      "Error on this batch = 0.047131785348492945\n",
      "Error on this batch = 0.07767911378466856\n",
      "Cost on val dataset after 740 epochs is = 0.0966349601329743\n",
      "Initial Cost on Val dataset for this epoch 740 = 0.0966349601329743\n",
      "learning rate for this epoch =  0.09586544098981967\n",
      "Error on this batch = 0.04709701587493838\n",
      "Error on this batch = 0.07764085680404322\n",
      "Cost on val dataset after 741 epochs is = 0.0966149326169672\n",
      "Initial Cost on Val dataset for this epoch 741 = 0.0966149326169672\n",
      "learning rate for this epoch =  0.09583308134268179\n",
      "Error on this batch = 0.047062341237664417\n",
      "Error on this batch = 0.07760269805266905\n",
      "Cost on val dataset after 742 epochs is = 0.09659495565159527\n",
      "Initial Cost on Val dataset for this epoch 742 = 0.09659495565159527\n",
      "learning rate for this epoch =  0.09580077623735313\n",
      "Error on this batch = 0.04702776109855271\n",
      "Error on this batch = 0.077564637162047\n",
      "Cost on val dataset after 743 epochs is = 0.09657502901459863\n",
      "Initial Cost on Val dataset for this epoch 743 = 0.09657502901459863\n",
      "learning rate for this epoch =  0.09576852550858327\n",
      "Error on this batch = 0.04699327512147745\n",
      "Error on this batch = 0.07752667376578788\n",
      "Cost on val dataset after 744 epochs is = 0.09655515248540521\n",
      "Initial Cost on Val dataset for this epoch 744 = 0.09655515248540521\n",
      "learning rate for this epoch =  0.09573632899184395\n",
      "Error on this batch = 0.04695888297229145\n",
      "Error on this batch = 0.07748880749958566\n",
      "Cost on val dataset after 745 epochs is = 0.09653532584511927\n",
      "Initial Cost on Val dataset for this epoch 745 = 0.09653532584511927\n",
      "learning rate for this epoch =  0.09570418652332507\n",
      "Error on this batch = 0.04692458431881119\n",
      "Error on this batch = 0.0774510380011912\n",
      "Cost on val dataset after 746 epochs is = 0.0965155488765093\n",
      "Initial Cost on Val dataset for this epoch 746 = 0.0965155488765093\n",
      "learning rate for this epoch =  0.0956720979399305\n",
      "Error on this batch = 0.046890378830801716\n",
      "Error on this batch = 0.07741336491038571\n",
      "Cost on val dataset after 747 epochs is = 0.09649582136399593\n",
      "Initial Cost on Val dataset for this epoch 747 = 0.09649582136399593\n",
      "learning rate for this epoch =  0.0956400630792741\n",
      "Error on this batch = 0.04685626617996086\n",
      "Error on this batch = 0.07737578786895438\n",
      "Cost on val dataset after 748 epochs is = 0.0964761430936393\n",
      "Initial Cost on Val dataset for this epoch 748 = 0.0964761430936393\n",
      "learning rate for this epoch =  0.09560808177967559\n",
      "Error on this batch = 0.04682224603990269\n",
      "Error on this batch = 0.07733830652066039\n",
      "Cost on val dataset after 749 epochs is = 0.09645651385312623\n",
      "Initial Cost on Val dataset for this epoch 749 = 0.09645651385312623\n",
      "learning rate for this epoch =  0.09557615388015658\n",
      "Error on this batch = 0.04678831808614088\n",
      "Error on this batch = 0.0773009205112188\n",
      "Cost on val dataset after 750 epochs is = 0.09643693343175717\n",
      "Initial Cost on Val dataset for this epoch 750 = 0.09643693343175717\n",
      "learning rate for this epoch =  0.09554427922043668\n",
      "Error on this batch = 0.046754481996071434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07726362948827074\n",
      "Cost on val dataset after 751 epochs is = 0.09641740162043283\n",
      "Initial Cost on Val dataset for this epoch 751 = 0.09641740162043283\n",
      "learning rate for this epoch =  0.0955124576409294\n",
      "Error on this batch = 0.046720737448954754\n",
      "Error on this batch = 0.07722643310135754\n",
      "Cost on val dataset after 752 epochs is = 0.09639791821164063\n",
      "Initial Cost on Val dataset for this epoch 752 = 0.09639791821164063\n",
      "learning rate for this epoch =  0.09548068898273834\n",
      "Error on this batch = 0.04668708412589766\n",
      "Error on this batch = 0.07718933100189528\n",
      "Cost on val dataset after 753 epochs is = 0.09637848299944092\n",
      "Initial Cost on Val dataset for this epoch 753 = 0.09637848299944092\n",
      "learning rate for this epoch =  0.09544897308765321\n",
      "Error on this batch = 0.04665352170983499\n",
      "Error on this batch = 0.07715232284314927\n",
      "Cost on val dataset after 754 epochs is = 0.09635909577945283\n",
      "Initial Cost on Val dataset for this epoch 754 = 0.09635909577945283\n",
      "learning rate for this epoch =  0.09541730979814601\n",
      "Error on this batch = 0.04662004988551059\n",
      "Error on this batch = 0.07711540828020888\n",
      "Cost on val dataset after 755 epochs is = 0.0963397563488402\n",
      "Initial Cost on Val dataset for this epoch 755 = 0.0963397563488402\n",
      "learning rate for this epoch =  0.09538569895736723\n",
      "Error on this batch = 0.04658666833945829\n",
      "Error on this batch = 0.07707858696996234\n",
      "Cost on val dataset after 756 epochs is = 0.09632046450629714\n",
      "Initial Cost on Val dataset for this epoch 756 = 0.09632046450629714\n",
      "learning rate for this epoch =  0.0953541404091419\n",
      "Error on this batch = 0.046553376759982355\n",
      "Error on this batch = 0.07704185857107192\n",
      "Cost on val dataset after 757 epochs is = 0.0963012200520333\n",
      "Initial Cost on Val dataset for this epoch 757 = 0.0963012200520333\n",
      "learning rate for this epoch =  0.09532263399796595\n",
      "Error on this batch = 0.04652017483713792\n",
      "Error on this batch = 0.07700522274394907\n",
      "Cost on val dataset after 758 epochs is = 0.09628202278775946\n",
      "Initial Cost on Val dataset for this epoch 758 = 0.09628202278775946\n",
      "learning rate for this epoch =  0.09529117956900235\n",
      "Error on this batch = 0.04648706226271096\n",
      "Error on this batch = 0.07696867915072997\n",
      "Cost on val dataset after 759 epochs is = 0.09626287251667229\n",
      "Initial Cost on Val dataset for this epoch 759 = 0.09626287251667229\n",
      "learning rate for this epoch =  0.09525977696807737\n",
      "Error on this batch = 0.046454038730198176\n",
      "Error on this batch = 0.07693222745525109\n",
      "Cost on val dataset after 760 epochs is = 0.09624376904343956\n",
      "Initial Cost on Val dataset for this epoch 760 = 0.09624376904343956\n",
      "learning rate for this epoch =  0.095228426041677\n",
      "Error on this batch = 0.046421103934786746\n",
      "Error on this batch = 0.07689586732302509\n",
      "Cost on val dataset after 761 epochs is = 0.09622471217418498\n",
      "Initial Cost on Val dataset for this epoch 761 = 0.09622471217418498\n",
      "learning rate for this epoch =  0.09519712663694305\n",
      "Error on this batch = 0.04638825757333384\n",
      "Error on this batch = 0.07685959842121667\n",
      "Cost on val dataset after 762 epochs is = 0.09620570171647297\n",
      "Initial Cost on Val dataset for this epoch 762 = 0.09620570171647297\n",
      "learning rate for this epoch =  0.09516587860166968\n",
      "Error on this batch = 0.04635549934434599\n",
      "Error on this batch = 0.07682342041861902\n",
      "Cost on val dataset after 763 epochs is = 0.09618673747929331\n",
      "Initial Cost on Val dataset for this epoch 763 = 0.09618673747929331\n",
      "learning rate for this epoch =  0.09513468178429965\n",
      "Error on this batch = 0.04632282894795841\n",
      "Error on this batch = 0.07678733298563005\n",
      "Cost on val dataset after 764 epochs is = 0.09616781927304587\n",
      "Initial Cost on Val dataset for this epoch 764 = 0.09616781927304587\n",
      "learning rate for this epoch =  0.0951035360339208\n",
      "Error on this batch = 0.046290246085914345\n",
      "Error on this batch = 0.07675133579422919\n",
      "Cost on val dataset after 765 epochs is = 0.09614894690952495\n",
      "Initial Cost on Val dataset for this epoch 765 = 0.09614894690952495\n",
      "learning rate for this epoch =  0.09507244120026234\n",
      "Error on this batch = 0.04625775046154406\n",
      "Error on this batch = 0.07671542851795403\n",
      "Cost on val dataset after 766 epochs is = 0.0961301202019041\n",
      "Initial Cost on Val dataset for this epoch 766 = 0.0961301202019041\n",
      "learning rate for this epoch =  0.09504139713369145\n",
      "Error on this batch = 0.046225341779744106\n",
      "Error on this batch = 0.07667961083187753\n",
      "Cost on val dataset after 767 epochs is = 0.09611133896472035\n",
      "Initial Cost on Val dataset for this epoch 767 = 0.09611133896472035\n",
      "learning rate for this epoch =  0.09501040368520958\n",
      "Error on this batch = 0.046193019746956436\n",
      "Error on this batch = 0.07664388241258538\n",
      "Cost on val dataset after 768 epochs is = 0.09609260301385869\n",
      "Initial Cost on Val dataset for this epoch 768 = 0.09609260301385869\n",
      "learning rate for this epoch =  0.09497946070644907\n",
      "Error on this batch = 0.04616078407114749\n",
      "Error on this batch = 0.0766082429381532\n",
      "Cost on val dataset after 769 epochs is = 0.0960739121665367\n",
      "Initial Cost on Val dataset for this epoch 769 = 0.0960739121665367\n",
      "learning rate for this epoch =  0.09494856804966957\n",
      "Error on this batch = 0.046128634461787464\n",
      "Error on this batch = 0.07657269208812459\n",
      "Cost on val dataset after 770 epochs is = 0.09605526624128878\n",
      "Initial Cost on Val dataset for this epoch 770 = 0.09605526624128878\n",
      "learning rate for this epoch =  0.09491772556775467\n",
      "Error on this batch = 0.046096570629829275\n",
      "Error on this batch = 0.0765372295434889\n",
      "Cost on val dataset after 771 epochs is = 0.09603666505795085\n",
      "Initial Cost on Val dataset for this epoch 771 = 0.09603666505795085\n",
      "learning rate for this epoch =  0.09488693311420834\n",
      "Error on this batch = 0.0460645922876881\n",
      "Error on this batch = 0.07650185498665939\n",
      "Cost on val dataset after 772 epochs is = 0.09601810843764462\n",
      "Initial Cost on Val dataset for this epoch 772 = 0.09601810843764462\n",
      "learning rate for this epoch =  0.0948561905431516\n",
      "Error on this batch = 0.046032699149220535\n",
      "Error on this batch = 0.07646656810145162\n",
      "Cost on val dataset after 773 epochs is = 0.09599959620276236\n",
      "Initial Cost on Val dataset for this epoch 773 = 0.09599959620276236\n",
      "learning rate for this epoch =  0.09482549770931908\n",
      "Error on this batch = 0.04600089092970422\n",
      "Error on this batch = 0.07643136857306232\n",
      "Cost on val dataset after 774 epochs is = 0.09598112817695124\n",
      "Initial Cost on Val dataset for this epoch 774 = 0.09598112817695124\n",
      "learning rate for this epoch =  0.09479485446805574\n",
      "Error on this batch = 0.04596916734581709\n",
      "Error on this batch = 0.07639625608804791\n",
      "Cost on val dataset after 775 epochs is = 0.0959627041850983\n",
      "Initial Cost on Val dataset for this epoch 775 = 0.0959627041850983\n",
      "learning rate for this epoch =  0.09476426067531338\n",
      "Error on this batch = 0.04593752811561736\n",
      "Error on this batch = 0.07636123033430385\n",
      "Cost on val dataset after 776 epochs is = 0.09594432405331488\n",
      "Initial Cost on Val dataset for this epoch 776 = 0.09594432405331488\n",
      "learning rate for this epoch =  0.0947337161876474\n",
      "Error on this batch = 0.04590597295852309\n",
      "Error on this batch = 0.07632629100104381\n",
      "Cost on val dataset after 777 epochs is = 0.09592598760892165\n",
      "Initial Cost on Val dataset for this epoch 777 = 0.09592598760892165\n",
      "learning rate for this epoch =  0.09470322086221351\n",
      "Error on this batch = 0.045874501595292216\n",
      "Error on this batch = 0.07629143777877945\n",
      "Cost on val dataset after 778 epochs is = 0.0959076946804334\n",
      "Initial Cost on Val dataset for this epoch 778 = 0.0959076946804334\n",
      "learning rate for this epoch =  0.09467277455676439\n",
      "Error on this batch = 0.045843113748002685\n",
      "Error on this batch = 0.07625667035929996\n",
      "Cost on val dataset after 779 epochs is = 0.09588944509754409\n",
      "Initial Cost on Val dataset for this epoch 779 = 0.09588944509754409\n",
      "learning rate for this epoch =  0.0946423771296465\n",
      "Error on this batch = 0.045811809140032744\n",
      "Error on this batch = 0.07622198843565232\n",
      "Cost on val dataset after 780 epochs is = 0.09587123869111194\n",
      "Initial Cost on Val dataset for this epoch 780 = 0.09587123869111194\n",
      "learning rate for this epoch =  0.09461202843979676\n",
      "Error on this batch = 0.04578058749604129\n",
      "Error on this batch = 0.07618739170212149\n",
      "Cost on val dataset after 781 epochs is = 0.09585307529314475\n",
      "Initial Cost on Val dataset for this epoch 781 = 0.09585307529314475\n",
      "learning rate for this epoch =  0.09458172834673945\n",
      "Error on this batch = 0.04574944854194847\n",
      "Error on this batch = 0.07615287985421092\n",
      "Cost on val dataset after 782 epochs is = 0.09583495473678513\n",
      "Initial Cost on Val dataset for this epoch 782 = 0.09583495473678513\n",
      "learning rate for this epoch =  0.09455147671058287\n",
      "Error on this batch = 0.045718392004916834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07611845258862336\n",
      "Cost on val dataset after 783 epochs is = 0.0958168768562961\n",
      "Initial Cost on Val dataset for this epoch 783 = 0.0958168768562961\n",
      "learning rate for this epoch =  0.09452127339201631\n",
      "Error on this batch = 0.045687417613331914\n",
      "Error on this batch = 0.07608410960324187\n",
      "Cost on val dataset after 784 epochs is = 0.09579884148704669\n",
      "Initial Cost on Val dataset for this epoch 784 = 0.09579884148704669\n",
      "learning rate for this epoch =  0.0944911182523068\n",
      "Error on this batch = 0.04565652509678378\n",
      "Error on this batch = 0.07604985059711095\n",
      "Cost on val dataset after 785 epochs is = 0.09578084846549777\n",
      "Initial Cost on Val dataset for this epoch 785 = 0.09578084846549777\n",
      "learning rate for this epoch =  0.09446101115329605\n",
      "Error on this batch = 0.04562571418604842\n",
      "Error on this batch = 0.07601567527041811\n",
      "Cost on val dataset after 786 epochs is = 0.09576289762918791\n",
      "Initial Cost on Val dataset for this epoch 786 = 0.09576289762918791\n",
      "learning rate for this epoch =  0.09443095195739727\n",
      "Error on this batch = 0.04559498461306921\n",
      "Error on this batch = 0.0759815833244756\n",
      "Cost on val dataset after 787 epochs is = 0.09574498881671954\n",
      "Initial Cost on Val dataset for this epoch 787 = 0.09574498881671954\n",
      "learning rate for this epoch =  0.09440094052759214\n",
      "Error on this batch = 0.04556433611093907\n",
      "Error on this batch = 0.07594757446170236\n",
      "Cost on val dataset after 788 epochs is = 0.09572712186774529\n",
      "Initial Cost on Val dataset for this epoch 788 = 0.09572712186774529\n",
      "learning rate for this epoch =  0.09437097672742772\n",
      "Error on this batch = 0.045533768413882444\n",
      "Error on this batch = 0.07591364838560613\n",
      "Cost on val dataset after 789 epochs is = 0.09570929662295423\n",
      "Initial Cost on Val dataset for this epoch 789 = 0.09570929662295423\n",
      "learning rate for this epoch =  0.09434106042101341\n",
      "Error on this batch = 0.04550328125723759\n",
      "Error on this batch = 0.07587980480076599\n",
      "Cost on val dataset after 790 epochs is = 0.09569151292405866\n",
      "Initial Cost on Val dataset for this epoch 790 = 0.09569151292405866\n",
      "learning rate for this epoch =  0.09431119147301793\n",
      "Error on this batch = 0.0454728743774392\n",
      "Error on this batch = 0.07584604341281499\n",
      "Cost on val dataset after 791 epochs is = 0.09567377061378089\n",
      "Initial Cost on Val dataset for this epoch 791 = 0.09567377061378089\n",
      "learning rate for this epoch =  0.09428136974866627\n",
      "Error on this batch = 0.0454425475120012\n",
      "Error on this batch = 0.07581236392842311\n",
      "Cost on val dataset after 792 epochs is = 0.09565606953584012\n",
      "Initial Cost on Val dataset for this epoch 792 = 0.09565606953584012\n",
      "learning rate for this epoch =  0.09425159511373676\n",
      "Error on this batch = 0.04541230039949969\n",
      "Error on this batch = 0.07577876605528029\n",
      "Cost on val dataset after 793 epochs is = 0.0956384095349397\n",
      "Initial Cost on Val dataset for this epoch 793 = 0.0956384095349397\n",
      "learning rate for this epoch =  0.09422186743455808\n",
      "Error on this batch = 0.04538213277955631\n",
      "Error on this batch = 0.07574524950207995\n",
      "Cost on val dataset after 794 epochs is = 0.09562079045675442\n",
      "Initial Cost on Val dataset for this epoch 794 = 0.09562079045675442\n",
      "learning rate for this epoch =  0.0941921865780063\n",
      "Error on this batch = 0.045352044392821644\n",
      "Error on this batch = 0.07571181397850263\n",
      "Cost on val dataset after 795 epochs is = 0.09560321214791814\n",
      "Initial Cost on Val dataset for this epoch 795 = 0.09560321214791814\n",
      "learning rate for this epoch =  0.09416255241150198\n",
      "Error on this batch = 0.04532203498095894\n",
      "Error on this batch = 0.07567845919519965\n",
      "Cost on val dataset after 796 epochs is = 0.09558567445601146\n",
      "Initial Cost on Val dataset for this epoch 796 = 0.09558567445601146\n",
      "learning rate for this epoch =  0.09413296480300724\n",
      "Error on this batch = 0.04529210428662804\n",
      "Error on this batch = 0.0756451848637775\n",
      "Cost on val dataset after 797 epochs is = 0.09556817722954973\n",
      "Initial Cost on Val dataset for this epoch 797 = 0.09556817722954973\n",
      "learning rate for this epoch =  0.09410342362102285\n",
      "Error on this batch = 0.04526225205346957\n",
      "Error on this batch = 0.07561199069678196\n",
      "Cost on val dataset after 798 epochs is = 0.09555072031797113\n",
      "Initial Cost on Val dataset for this epoch 798 = 0.09555072031797113\n",
      "learning rate for this epoch =  0.09407392873458542\n",
      "Error on this batch = 0.04523247802608938\n",
      "Error on this batch = 0.07557887640768284\n",
      "Cost on val dataset after 799 epochs is = 0.09553330357162507\n",
      "Initial Cost on Val dataset for this epoch 799 = 0.09553330357162507\n",
      "learning rate for this epoch =  0.09404448001326453\n",
      "Error on this batch = 0.045202781950043146\n",
      "Error on this batch = 0.07554584171085851\n",
      "Cost on val dataset after 800 epochs is = 0.09551592684176075\n",
      "Initial Cost on Val dataset for this epoch 800 = 0.09551592684176075\n",
      "learning rate for this epoch =  0.09401507732715984\n",
      "Error on this batch = 0.04517316357182103\n",
      "Error on this batch = 0.07551288632158143\n",
      "Cost on val dataset after 801 epochs is = 0.09549858998051583\n",
      "Initial Cost on Val dataset for this epoch 801 = 0.09549858998051583\n",
      "learning rate for this epoch =  0.09398572054689833\n",
      "Error on this batch = 0.04514362263883305\n",
      "Error on this batch = 0.07548000995600289\n",
      "Cost on val dataset after 802 epochs is = 0.09548129284090545\n",
      "Initial Cost on Val dataset for this epoch 802 = 0.09548129284090545\n",
      "learning rate for this epoch =  0.09395640954363149\n",
      "Error on this batch = 0.045114158899394054\n",
      "Error on this batch = 0.07544721233113888\n",
      "Cost on val dataset after 803 epochs is = 0.09546403527681145\n",
      "Initial Cost on Val dataset for this epoch 803 = 0.09546403527681145\n",
      "learning rate for this epoch =  0.09392714418903259\n",
      "Error on this batch = 0.045084772102709496\n",
      "Error on this batch = 0.07541449316485578\n",
      "Cost on val dataset after 804 epochs is = 0.09544681714297167\n",
      "Initial Cost on Val dataset for this epoch 804 = 0.09544681714297167\n",
      "learning rate for this epoch =  0.0938979243552938\n",
      "Error on this batch = 0.045055461998860846\n",
      "Error on this batch = 0.07538185217585629\n",
      "Cost on val dataset after 805 epochs is = 0.09542963829496945\n",
      "Initial Cost on Val dataset for this epoch 805 = 0.09542963829496945\n",
      "learning rate for this epoch =  0.0938687499151236\n",
      "Error on this batch = 0.04502622833879177\n",
      "Error on this batch = 0.07534928908366559\n",
      "Cost on val dataset after 806 epochs is = 0.09541249858922356\n",
      "Initial Cost on Val dataset for this epoch 806 = 0.09541249858922356\n",
      "learning rate for this epoch =  0.09383962074174393\n",
      "Error on this batch = 0.04499707087429395\n",
      "Error on this batch = 0.07531680360861798\n",
      "Cost on val dataset after 807 epochs is = 0.09539539788297813\n",
      "Initial Cost on Val dataset for this epoch 807 = 0.09539539788297813\n",
      "learning rate for this epoch =  0.09381053670888753\n",
      "Error on this batch = 0.044967989357993614\n",
      "Error on this batch = 0.07528439547184343\n",
      "Cost on val dataset after 808 epochs is = 0.09537833603429272\n",
      "Initial Cost on Val dataset for this epoch 808 = 0.09537833603429272\n",
      "learning rate for this epoch =  0.09378149769079532\n",
      "Error on this batch = 0.04493898354333796\n",
      "Error on this batch = 0.07525206439525452\n",
      "Cost on val dataset after 809 epochs is = 0.09536131290203295\n",
      "Initial Cost on Val dataset for this epoch 809 = 0.09536131290203295\n",
      "learning rate for this epoch =  0.09375250356221361\n",
      "Error on this batch = 0.0449100531845818\n",
      "Error on this batch = 0.0752198101015336\n",
      "Cost on val dataset after 810 epochs is = 0.09534432834586082\n",
      "Initial Cost on Val dataset for this epoch 810 = 0.09534432834586082\n",
      "learning rate for this epoch =  0.09372355419839151\n",
      "Error on this batch = 0.04488119803677454\n",
      "Error on this batch = 0.07518763231412023\n",
      "Cost on val dataset after 811 epochs is = 0.09532738222622568\n",
      "Initial Cost on Val dataset for this epoch 811 = 0.09532738222622568\n",
      "learning rate for this epoch =  0.09369464947507833\n",
      "Error on this batch = 0.04485241785574703\n",
      "Error on this batch = 0.07515553075719876\n",
      "Cost on val dataset after 812 epochs is = 0.09531047440435514\n",
      "Initial Cost on Val dataset for this epoch 812 = 0.09531047440435514\n",
      "learning rate for this epoch =  0.09366578926852086\n",
      "Error on this batch = 0.044823712398098986\n",
      "Error on this batch = 0.07512350515568614\n",
      "Cost on val dataset after 813 epochs is = 0.0952936047422463\n",
      "Initial Cost on Val dataset for this epoch 813 = 0.0952936047422463\n",
      "learning rate for this epoch =  0.09363697345546085\n",
      "Error on this batch = 0.04479508142118634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07509155523522011\n",
      "Cost on val dataset after 814 epochs is = 0.09527677310265706\n",
      "Initial Cost on Val dataset for this epoch 814 = 0.09527677310265706\n",
      "learning rate for this epoch =  0.09360820191313243\n",
      "Error on this batch = 0.04476652468310876\n",
      "Error on this batch = 0.07505968072214746\n",
      "Cost on val dataset after 815 epochs is = 0.09525997934909779\n",
      "Initial Cost on Val dataset for this epoch 815 = 0.09525997934909779\n",
      "learning rate for this epoch =  0.09357947451925948\n",
      "Error on this batch = 0.04473804194269745\n",
      "Error on this batch = 0.07502788134351257\n",
      "Cost on val dataset after 816 epochs is = 0.09524322334582293\n",
      "Initial Cost on Val dataset for this epoch 816 = 0.09524322334582293\n",
      "learning rate for this epoch =  0.09355079115205313\n",
      "Error on this batch = 0.04470963295950297\n",
      "Error on this batch = 0.07499615682704627\n",
      "Cost on val dataset after 817 epochs is = 0.09522650495782316\n",
      "Initial Cost on Val dataset for this epoch 817 = 0.09522650495782316\n",
      "learning rate for this epoch =  0.09352215169020917\n",
      "Error on this batch = 0.04468129749378336\n",
      "Error on this batch = 0.0749645069011547\n",
      "Cost on val dataset after 818 epochs is = 0.09520982405081732\n",
      "Initial Cost on Val dataset for this epoch 818 = 0.09520982405081732\n",
      "learning rate for this epoch =  0.09349355601290561\n",
      "Error on this batch = 0.04465303530649226\n",
      "Error on this batch = 0.07493293129490888\n",
      "Cost on val dataset after 819 epochs is = 0.0951931804912449\n",
      "Initial Cost on Val dataset for this epoch 819 = 0.0951931804912449\n",
      "learning rate for this epoch =  0.09346500399980012\n",
      "Error on this batch = 0.044624846159267345\n",
      "Error on this batch = 0.0749014297380338\n",
      "Cost on val dataset after 820 epochs is = 0.09517657414625835\n",
      "Initial Cost on Val dataset for this epoch 820 = 0.09517657414625835\n",
      "learning rate for this epoch =  0.09343649553102754\n",
      "Error on this batch = 0.04459672981441864\n",
      "Error on this batch = 0.07487000196089849\n",
      "Cost on val dataset after 821 epochs is = 0.09516000488371598\n",
      "Initial Cost on Val dataset for this epoch 821 = 0.09516000488371598\n",
      "learning rate for this epoch =  0.0934080304871974\n",
      "Error on this batch = 0.04456868603491744\n",
      "Error on this batch = 0.07483864769450571\n",
      "Cost on val dataset after 822 epochs is = 0.09514347257217462\n",
      "Initial Cost on Val dataset for this epoch 822 = 0.09514347257217462\n",
      "learning rate for this epoch =  0.09337960874939158\n",
      "Error on this batch = 0.04454071458438472\n",
      "Error on this batch = 0.07480736667048239\n",
      "Cost on val dataset after 823 epochs is = 0.0951269770808828\n",
      "Initial Cost on Val dataset for this epoch 823 = 0.0951269770808828\n",
      "learning rate for this epoch =  0.09335123019916165\n",
      "Error on this batch = 0.04451281522708032\n",
      "Error on this batch = 0.07477615862106983\n",
      "Cost on val dataset after 824 epochs is = 0.09511051827977376\n",
      "Initial Cost on Val dataset for this epoch 824 = 0.09511051827977376\n",
      "learning rate for this epoch =  0.09332289471852671\n",
      "Error on this batch = 0.04448498772789175\n",
      "Error on this batch = 0.07474502327911446\n",
      "Cost on val dataset after 825 epochs is = 0.09509409603945904\n",
      "Initial Cost on Val dataset for this epoch 825 = 0.09509409603945904\n",
      "learning rate for this epoch =  0.09329460218997072\n",
      "Error on this batch = 0.04445723185232344\n",
      "Error on this batch = 0.07471396037805875\n",
      "Cost on val dataset after 826 epochs is = 0.09507771023122179\n",
      "Initial Cost on Val dataset for this epoch 826 = 0.09507771023122179\n",
      "learning rate for this epoch =  0.09326635249644033\n",
      "Error on this batch = 0.04442954736648602\n",
      "Error on this batch = 0.07468296965193232\n",
      "Cost on val dataset after 827 epochs is = 0.09506136072701059\n",
      "Initial Cost on Val dataset for this epoch 827 = 0.09506136072701059\n",
      "learning rate for this epoch =  0.09323814552134235\n",
      "Error on this batch = 0.04440193403708552\n",
      "Error on this batch = 0.07465205083534324\n",
      "Cost on val dataset after 828 epochs is = 0.09504504739943327\n",
      "Initial Cost on Val dataset for this epoch 828 = 0.09504504739943327\n",
      "learning rate for this epoch =  0.09320998114854143\n",
      "Error on this batch = 0.044374391631413095\n",
      "Error on this batch = 0.07462120366346979\n",
      "Cost on val dataset after 829 epochs is = 0.09502877012175082\n",
      "Initial Cost on Val dataset for this epoch 829 = 0.09502877012175082\n",
      "learning rate for this epoch =  0.09318185926235777\n",
      "Error on this batch = 0.04434691991733446\n",
      "Error on this batch = 0.07459042787205204\n",
      "Cost on val dataset after 830 epochs is = 0.09501252876787171\n",
      "Initial Cost on Val dataset for this epoch 830 = 0.09501252876787171\n",
      "learning rate for this epoch =  0.09315377974756468\n",
      "Error on this batch = 0.04431951866327962\n",
      "Error on this batch = 0.07455972319738415\n",
      "Cost on val dataset after 831 epochs is = 0.09499632321234597\n",
      "Initial Cost on Val dataset for this epoch 831 = 0.09499632321234597\n",
      "learning rate for this epoch =  0.09312574248938638\n",
      "Error on this batch = 0.04429218763823275\n",
      "Error on this batch = 0.07452908937630649\n",
      "Cost on val dataset after 832 epochs is = 0.09498015333035983\n",
      "Initial Cost on Val dataset for this epoch 832 = 0.09498015333035983\n",
      "learning rate for this epoch =  0.0930977473734956\n",
      "Error on this batch = 0.044264926611721975\n",
      "Error on this batch = 0.07449852614619838\n",
      "Cost on val dataset after 833 epochs is = 0.09496401899773028\n",
      "Initial Cost on Val dataset for this epoch 833 = 0.09496401899773028\n",
      "learning rate for this epoch =  0.09306979428601131\n",
      "Error on this batch = 0.04423773535380945\n",
      "Error on this batch = 0.07446803324497057\n",
      "Cost on val dataset after 834 epochs is = 0.09494792009089961\n",
      "Initial Cost on Val dataset for this epoch 834 = 0.09494792009089961\n",
      "learning rate for this epoch =  0.0930418831134965\n",
      "Error on this batch = 0.04421061363508153\n",
      "Error on this batch = 0.07443761041105855\n",
      "Cost on val dataset after 835 epochs is = 0.09493185648693041\n",
      "Initial Cost on Val dataset for this epoch 835 = 0.09493185648693041\n",
      "learning rate for this epoch =  0.09301401374295587\n",
      "Error on this batch = 0.044183561226638836\n",
      "Error on this batch = 0.07440725738341554\n",
      "Cost on val dataset after 836 epochs is = 0.09491582806350066\n",
      "Initial Cost on Val dataset for this epoch 836 = 0.09491582806350066\n",
      "learning rate for this epoch =  0.09298618606183358\n",
      "Error on this batch = 0.04415657790008664\n",
      "Error on this batch = 0.07437697390150604\n",
      "Cost on val dataset after 837 epochs is = 0.09489983469889864\n",
      "Initial Cost on Val dataset for this epoch 837 = 0.09489983469889864\n",
      "learning rate for this epoch =  0.09295839995801103\n",
      "Error on this batch = 0.044129663427525216\n",
      "Error on this batch = 0.07434675970529961\n",
      "Cost on val dataset after 838 epochs is = 0.09488387627201827\n",
      "Initial Cost on Val dataset for this epoch 838 = 0.09488387627201827\n",
      "learning rate for this epoch =  0.09293065531980463\n",
      "Error on this batch = 0.04410281758154028\n",
      "Error on this batch = 0.07431661453526467\n",
      "Cost on val dataset after 839 epochs is = 0.09486795266235454\n",
      "Initial Cost on Val dataset for this epoch 839 = 0.09486795266235454\n",
      "learning rate for this epoch =  0.09290295203596367\n",
      "Error on this batch = 0.044076040135193624\n",
      "Error on this batch = 0.07428653813236276\n",
      "Cost on val dataset after 840 epochs is = 0.09485206374999891\n",
      "Initial Cost on Val dataset for this epoch 840 = 0.09485206374999891\n",
      "learning rate for this epoch =  0.09287528999566799\n",
      "Error on this batch = 0.044049330862013694\n",
      "Error on this batch = 0.07425653023804296\n",
      "Cost on val dataset after 841 epochs is = 0.09483620941563488\n",
      "Initial Cost on Val dataset for this epoch 841 = 0.09483620941563488\n",
      "learning rate for this epoch =  0.09284766908852593\n",
      "Error on this batch = 0.04402268953598634\n",
      "Error on this batch = 0.07422659059423635\n",
      "Cost on val dataset after 842 epochs is = 0.09482038954053382\n",
      "Initial Cost on Val dataset for this epoch 842 = 0.09482038954053382\n",
      "learning rate for this epoch =  0.09282008920457209\n",
      "Error on this batch = 0.043996115931545614\n",
      "Error on this batch = 0.07419671894335107\n",
      "Cost on val dataset after 843 epochs is = 0.09480460400655079\n",
      "Initial Cost on Val dataset for this epoch 843 = 0.09480460400655079\n",
      "learning rate for this epoch =  0.09279255023426522\n",
      "Error on this batch = 0.04396960982356474\n",
      "Error on this batch = 0.07416691502826735\n",
      "Cost on val dataset after 844 epochs is = 0.09478885269612032\n",
      "Initial Cost on Val dataset for this epoch 844 = 0.09478885269612032\n",
      "learning rate for this epoch =  0.09276505206848605\n",
      "Error on this batch = 0.04394317098734701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07413717859233268\n",
      "Cost on val dataset after 845 epochs is = 0.09477313549225258\n",
      "Initial Cost on Val dataset for this epoch 845 = 0.09477313549225258\n",
      "learning rate for this epoch =  0.09273759459853521\n",
      "Error on this batch = 0.04391679919861694\n",
      "Error on this batch = 0.07410750937935758\n",
      "Cost on val dataset after 846 epochs is = 0.09475745227852954\n",
      "Initial Cost on Val dataset for this epoch 846 = 0.09475745227852954\n",
      "learning rate for this epoch =  0.0927101777161311\n",
      "Error on this batch = 0.04389049423351121\n",
      "Error on this batch = 0.07407790713361122\n",
      "Cost on val dataset after 847 epochs is = 0.0947418029391011\n",
      "Initial Cost on Val dataset for this epoch 847 = 0.0947418029391011\n",
      "learning rate for this epoch =  0.09268280131340775\n",
      "Error on this batch = 0.043864255868570255\n",
      "Error on this batch = 0.07404837159981748\n",
      "Cost on val dataset after 848 epochs is = 0.09472618735868144\n",
      "Initial Cost on Val dataset for this epoch 848 = 0.09472618735868144\n",
      "learning rate for this epoch =  0.09265546528291284\n",
      "Error on this batch = 0.04383808388072927\n",
      "Error on this batch = 0.07401890252315116\n",
      "Cost on val dataset after 849 epochs is = 0.09471060542254552\n",
      "Initial Cost on Val dataset for this epoch 849 = 0.09471060542254552\n",
      "learning rate for this epoch =  0.09262816951760545\n",
      "Error on this batch = 0.043811978047309685\n",
      "Error on this batch = 0.07398949964923443\n",
      "Cost on val dataset after 850 epochs is = 0.09469505701652549\n",
      "Initial Cost on Val dataset for this epoch 850 = 0.09469505701652549\n",
      "learning rate for this epoch =  0.09260091391085426\n",
      "Error on this batch = 0.04378593814601068\n",
      "Error on this batch = 0.07396016272413346\n",
      "Cost on val dataset after 851 epochs is = 0.09467954202700732\n",
      "Initial Cost on Val dataset for this epoch 851 = 0.09467954202700732\n",
      "learning rate for this epoch =  0.09257369835643524\n",
      "Error on this batch = 0.04375996395490077\n",
      "Error on this batch = 0.07393089149435533\n",
      "Cost on val dataset after 852 epochs is = 0.09466406034092748\n",
      "Initial Cost on Val dataset for this epoch 852 = 0.09466406034092748\n",
      "learning rate for this epoch =  0.09254652274852981\n",
      "Error on this batch = 0.0437340552524094\n",
      "Error on this batch = 0.07390168570684516\n",
      "Cost on val dataset after 853 epochs is = 0.0946486118457697\n",
      "Initial Cost on Val dataset for this epoch 853 = 0.0946486118457697\n",
      "learning rate for this epoch =  0.0925193869817227\n",
      "Error on this batch = 0.043708211817318716\n",
      "Error on this batch = 0.07387254510898346\n",
      "Cost on val dataset after 854 epochs is = 0.09463319642956174\n",
      "Initial Cost on Val dataset for this epoch 854 = 0.09463319642956174\n",
      "learning rate for this epoch =  0.092492290951\n",
      "Error on this batch = 0.043682433428755336\n",
      "Error on this batch = 0.07384346944858355\n",
      "Cost on val dataset after 855 epochs is = 0.09461781398087236\n",
      "Initial Cost on Val dataset for this epoch 855 = 0.09461781398087236\n",
      "learning rate for this epoch =  0.09246523455174717\n",
      "Error on this batch = 0.043656719866182296\n",
      "Error on this batch = 0.07381445847388944\n",
      "Cost on val dataset after 856 epochs is = 0.09460246438880827\n",
      "Initial Cost on Val dataset for this epoch 856 = 0.09460246438880827\n",
      "learning rate for this epoch =  0.092438217679747\n",
      "Error on this batch = 0.043631070909391105\n",
      "Error on this batch = 0.07378551193357372\n",
      "Cost on val dataset after 857 epochs is = 0.0945871475430111\n",
      "Initial Cost on Val dataset for this epoch 857 = 0.0945871475430111\n",
      "learning rate for this epoch =  0.09241124023117771\n",
      "Error on this batch = 0.043605486338493656\n",
      "Error on this batch = 0.07375662957673568\n",
      "Cost on val dataset after 858 epochs is = 0.09457186333365468\n",
      "Initial Cost on Val dataset for this epoch 858 = 0.09457186333365468\n",
      "learning rate for this epoch =  0.09238430210261095\n",
      "Error on this batch = 0.043579965933914624\n",
      "Error on this batch = 0.07372781115289992\n",
      "Cost on val dataset after 859 epochs is = 0.09455661165144201\n",
      "Initial Cost on Val dataset for this epoch 859 = 0.09455661165144201\n",
      "learning rate for this epoch =  0.09235740319100984\n",
      "Error on this batch = 0.043554509476383625\n",
      "Error on this batch = 0.07369905641201457\n",
      "Cost on val dataset after 860 epochs is = 0.09454139238760258\n",
      "Initial Cost on Val dataset for this epoch 860 = 0.09454139238760258\n",
      "learning rate for this epoch =  0.09233054339372707\n",
      "Error on this batch = 0.04352911674692745\n",
      "Error on this batch = 0.07367036510445049\n",
      "Cost on val dataset after 861 epochs is = 0.09452620543388965\n",
      "Initial Cost on Val dataset for this epoch 861 = 0.09452620543388965\n",
      "learning rate for this epoch =  0.09230372260850297\n",
      "Error on this batch = 0.043503787526862896\n",
      "Error on this batch = 0.07364173698099989\n",
      "Cost on val dataset after 862 epochs is = 0.09451105068257754\n",
      "Initial Cost on Val dataset for this epoch 862 = 0.09451105068257754\n",
      "learning rate for this epoch =  0.09227694073346356\n",
      "Error on this batch = 0.0434785215977889\n",
      "Error on this batch = 0.0736131717928757\n",
      "Cost on val dataset after 863 epochs is = 0.09449592802645913\n",
      "Initial Cost on Val dataset for this epoch 863 = 0.09449592802645913\n",
      "learning rate for this epoch =  0.09225019766711869\n",
      "Error on this batch = 0.043453318741579566\n",
      "Error on this batch = 0.07358466929171095\n",
      "Cost on val dataset after 864 epochs is = 0.09448083735884315\n",
      "Initial Cost on Val dataset for this epoch 864 = 0.09448083735884315\n",
      "learning rate for this epoch =  0.09222349330836013\n",
      "Error on this batch = 0.04342817874037669\n",
      "Error on this batch = 0.0735562292295582\n",
      "Cost on val dataset after 865 epochs is = 0.09446577857355173\n",
      "Initial Cost on Val dataset for this epoch 865 = 0.09446577857355173\n",
      "learning rate for this epoch =  0.09219682755645973\n",
      "Error on this batch = 0.04340310137658277\n",
      "Error on this batch = 0.07352785135888952\n",
      "Cost on val dataset after 866 epochs is = 0.09445075156491796\n",
      "Initial Cost on Val dataset for this epoch 866 = 0.09445075156491796\n",
      "learning rate for this epoch =  0.09217020031106751\n",
      "Error on this batch = 0.04337808643285392\n",
      "Error on this batch = 0.07349953543259617\n",
      "Cost on val dataset after 867 epochs is = 0.09443575622778337\n",
      "Initial Cost on Val dataset for this epoch 867 = 0.09443575622778337\n",
      "learning rate for this epoch =  0.09214361147220981\n",
      "Error on this batch = 0.04335313369209292\n",
      "Error on this batch = 0.07347128120398899\n",
      "Cost on val dataset after 868 epochs is = 0.09442079245749568\n",
      "Initial Cost on Val dataset for this epoch 868 = 0.09442079245749568\n",
      "learning rate for this epoch =  0.09211706094028746\n",
      "Error on this batch = 0.0433282429374426\n",
      "Error on this batch = 0.0734430884267984\n",
      "Cost on val dataset after 869 epochs is = 0.09440586014990622\n",
      "Initial Cost on Val dataset for this epoch 869 = 0.09440586014990622\n",
      "learning rate for this epoch =  0.09209054861607395\n",
      "Error on this batch = 0.04330341395227892\n",
      "Error on this batch = 0.07341495685517516\n",
      "Cost on val dataset after 870 epochs is = 0.09439095920136781\n",
      "Initial Cost on Val dataset for this epoch 870 = 0.09439095920136781\n",
      "learning rate for this epoch =  0.0920640744007136\n",
      "Error on this batch = 0.04327864652020466\n",
      "Error on this batch = 0.0733868862436908\n",
      "Cost on val dataset after 871 epochs is = 0.09437608950873232\n",
      "Initial Cost on Val dataset for this epoch 871 = 0.09437608950873232\n",
      "learning rate for this epoch =  0.09203763819571976\n",
      "Error on this batch = 0.04325394042504274\n",
      "Error on this batch = 0.07335887634733866\n",
      "Cost on val dataset after 872 epochs is = 0.09436125096934858\n",
      "Initial Cost on Val dataset for this epoch 872 = 0.09436125096934858\n",
      "learning rate for this epoch =  0.09201123990297302\n",
      "Error on this batch = 0.043229295450830034\n",
      "Error on this batch = 0.07333092692153458\n",
      "Cost on val dataset after 873 epochs is = 0.09434644348105992\n",
      "Initial Cost on Val dataset for this epoch 873 = 0.09434644348105992\n",
      "learning rate for this epoch =  0.09198487942471935\n",
      "Error on this batch = 0.043204711381811124\n",
      "Error on this batch = 0.07330303772211826\n",
      "Cost on val dataset after 874 epochs is = 0.09433166694220213\n",
      "Initial Cost on Val dataset for this epoch 874 = 0.09433166694220213\n",
      "learning rate for this epoch =  0.09195855666356846\n",
      "Error on this batch = 0.04318018800243237\n",
      "Error on this batch = 0.0732752085053545\n",
      "Cost on val dataset after 875 epochs is = 0.09431692125160122\n",
      "Initial Cost on Val dataset for this epoch 875 = 0.09431692125160122\n",
      "learning rate for this epoch =  0.09193227152249185\n",
      "Error on this batch = 0.04315572509733571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07324743902793468\n",
      "Cost on val dataset after 876 epochs is = 0.0943022063085712\n",
      "Initial Cost on Val dataset for this epoch 876 = 0.0943022063085712\n",
      "learning rate for this epoch =  0.09190602390482124\n",
      "Error on this batch = 0.04313132245135311\n",
      "Error on this batch = 0.07321972904697821\n",
      "Cost on val dataset after 877 epochs is = 0.09428752201291199\n",
      "Initial Cost on Val dataset for this epoch 877 = 0.09428752201291199\n",
      "learning rate for this epoch =  0.09187981371424671\n",
      "Error on this batch = 0.04310697984950077\n",
      "Error on this batch = 0.07319207832003445\n",
      "Cost on val dataset after 878 epochs is = 0.09427286826490723\n",
      "Initial Cost on Val dataset for this epoch 878 = 0.09427286826490723\n",
      "learning rate for this epoch =  0.091853640854815\n",
      "Error on this batch = 0.04308269707697363\n",
      "Error on this batch = 0.07316448660508451\n",
      "Cost on val dataset after 879 epochs is = 0.09425824496532224\n",
      "Initial Cost on Val dataset for this epoch 879 = 0.09425824496532224\n",
      "learning rate for this epoch =  0.09182750523092773\n",
      "Error on this batch = 0.04305847391914003\n",
      "Error on this batch = 0.07313695366054336\n",
      "Cost on val dataset after 880 epochs is = 0.09424365201540183\n",
      "Initial Cost on Val dataset for this epoch 880 = 0.09424365201540183\n",
      "learning rate for this epoch =  0.0918014067473398\n",
      "Error on this batch = 0.04303431016153637\n",
      "Error on this batch = 0.07310947924526175\n",
      "Cost on val dataset after 881 epochs is = 0.09422908931686826\n",
      "Initial Cost on Val dataset for this epoch 881 = 0.09422908931686826\n",
      "learning rate for this epoch =  0.09177534530915758\n",
      "Error on this batch = 0.0430102055898621\n",
      "Error on this batch = 0.07308206311852877\n",
      "Cost on val dataset after 882 epochs is = 0.09421455677191903\n",
      "Initial Cost on Val dataset for this epoch 882 = 0.09421455677191903\n",
      "learning rate for this epoch =  0.09174932082183727\n",
      "Error on this batch = 0.04298615998997482\n",
      "Error on this batch = 0.07305470504007415\n",
      "Cost on val dataset after 883 epochs is = 0.094200054283225\n",
      "Initial Cost on Val dataset for this epoch 883 = 0.094200054283225\n",
      "learning rate for this epoch =  0.09172333319118318\n",
      "Error on this batch = 0.0429621731478854\n",
      "Error on this batch = 0.07302740477007064\n",
      "Cost on val dataset after 884 epochs is = 0.09418558175392812\n",
      "Initial Cost on Val dataset for this epoch 884 = 0.09418558175392812\n",
      "learning rate for this epoch =  0.0916973823233461\n",
      "Error on this batch = 0.042938244849753344\n",
      "Error on this batch = 0.07300016206913688\n",
      "Cost on val dataset after 885 epochs is = 0.09417113908763948\n",
      "Initial Cost on Val dataset for this epoch 885 = 0.09417113908763948\n",
      "learning rate for this epoch =  0.09167146812482159\n",
      "Error on this batch = 0.04291437488188241\n",
      "Error on this batch = 0.07297297669833999\n",
      "Cost on val dataset after 886 epochs is = 0.09415672618843708\n",
      "Initial Cost on Val dataset for this epoch 886 = 0.09415672618843708\n",
      "learning rate for this epoch =  0.09164559050244833\n",
      "Error on this batch = 0.04289056303071634\n",
      "Error on this batch = 0.0729458484191985\n",
      "Cost on val dataset after 887 epochs is = 0.094142342960864\n",
      "Initial Cost on Val dataset for this epoch 887 = 0.094142342960864\n",
      "learning rate for this epoch =  0.09161974936340654\n",
      "Error on this batch = 0.04286680908283449\n",
      "Error on this batch = 0.07291877699368532\n",
      "Cost on val dataset after 888 epochs is = 0.09412798930992607\n",
      "Initial Cost on Val dataset for this epoch 888 = 0.09412798930992607\n",
      "learning rate for this epoch =  0.09159394461521626\n",
      "Error on this batch = 0.042843112824948085\n",
      "Error on this batch = 0.07289176218423067\n",
      "Cost on val dataset after 889 epochs is = 0.09411366514108993\n",
      "Initial Cost on Val dataset for this epoch 889 = 0.09411366514108993\n",
      "learning rate for this epoch =  0.09156817616573577\n",
      "Error on this batch = 0.04281947404389632\n",
      "Error on this batch = 0.07286480375372537\n",
      "Cost on val dataset after 890 epochs is = 0.09409937036028089\n",
      "Initial Cost on Val dataset for this epoch 890 = 0.09409937036028089\n",
      "learning rate for this epoch =  0.09154244392315995\n",
      "Error on this batch = 0.042795892526642676\n",
      "Error on this batch = 0.07283790146552399\n",
      "Cost on val dataset after 891 epochs is = 0.09408510487388087\n",
      "Initial Cost on Val dataset for this epoch 891 = 0.09408510487388087\n",
      "learning rate for this epoch =  0.09151674779601875\n",
      "Error on this batch = 0.0427723680602716\n",
      "Error on this batch = 0.07281105508344816\n",
      "Cost on val dataset after 892 epochs is = 0.09407086858872626\n",
      "Initial Cost on Val dataset for this epoch 892 = 0.09407086858872626\n",
      "learning rate for this epoch =  0.0914910876931754\n",
      "Error on this batch = 0.04274890043198504\n",
      "Error on this batch = 0.07278426437179009\n",
      "Cost on val dataset after 893 epochs is = 0.09405666141210581\n",
      "Initial Cost on Val dataset for this epoch 893 = 0.09405666141210581\n",
      "learning rate for this epoch =  0.09146546352382512\n",
      "Error on this batch = 0.042725489429099435\n",
      "Error on this batch = 0.07275752909531578\n",
      "Cost on val dataset after 894 epochs is = 0.09404248325175861\n",
      "Initial Cost on Val dataset for this epoch 894 = 0.09404248325175861\n",
      "learning rate for this epoch =  0.09143987519749323\n",
      "Error on this batch = 0.042702134839042866\n",
      "Error on this batch = 0.07273084901926889\n",
      "Cost on val dataset after 895 epochs is = 0.09402833401587177\n",
      "Initial Cost on Val dataset for this epoch 895 = 0.09402833401587177\n",
      "learning rate for this epoch =  0.09141432262403383\n",
      "Error on this batch = 0.042678836449352206\n",
      "Error on this batch = 0.07270422390937405\n",
      "Cost on val dataset after 896 epochs is = 0.0940142136130784\n",
      "Initial Cost on Val dataset for this epoch 896 = 0.0940142136130784\n",
      "learning rate for this epoch =  0.09138880571362809\n",
      "Error on this batch = 0.042655594047670484\n",
      "Error on this batch = 0.07267765353184066\n",
      "Cost on val dataset after 897 epochs is = 0.09400012195245544\n",
      "Initial Cost on Val dataset for this epoch 897 = 0.09400012195245544\n",
      "learning rate for this epoch =  0.09136332437678274\n",
      "Error on this batch = 0.042632407421744775\n",
      "Error on this batch = 0.07265113765336662\n",
      "Cost on val dataset after 898 epochs is = 0.09398605894352147\n",
      "Initial Cost on Val dataset for this epoch 898 = 0.09398605894352147\n",
      "learning rate for this epoch =  0.09133787852432855\n",
      "Error on this batch = 0.042609276359423756\n",
      "Error on this batch = 0.07262467604114202\n",
      "Cost on val dataset after 899 epochs is = 0.09397202449623444\n",
      "Initial Cost on Val dataset for this epoch 899 = 0.09397202449623444\n",
      "learning rate for this epoch =  0.09131246806741879\n",
      "Error on this batch = 0.04258620064865587\n",
      "Error on this batch = 0.07259826846285304\n",
      "Cost on val dataset after 900 epochs is = 0.0939580185209896\n",
      "Initial Cost on Val dataset for this epoch 900 = 0.0939580185209896\n",
      "learning rate for this epoch =  0.09128709291752768\n",
      "Error on this batch = 0.04256318007748748\n",
      "Error on this batch = 0.07257191468668574\n",
      "Cost on val dataset after 901 epochs is = 0.09394404092861712\n",
      "Initial Cost on Val dataset for this epoch 901 = 0.09394404092861712\n",
      "learning rate for this epoch =  0.09126175298644894\n",
      "Error on this batch = 0.04254021443406126\n",
      "Error on this batch = 0.07254561448133001\n",
      "Cost on val dataset after 902 epochs is = 0.09393009163038003\n",
      "Initial Cost on Val dataset for this epoch 902 = 0.09393009163038003\n",
      "learning rate for this epoch =  0.09123644818629414\n",
      "Error on this batch = 0.04251730350661487\n",
      "Error on this batch = 0.07251936761598349\n",
      "Cost on val dataset after 903 epochs is = 0.09391617053797167\n",
      "Initial Cost on Val dataset for this epoch 903 = 0.09391617053797167\n",
      "learning rate for this epoch =  0.09121117842949143\n",
      "Error on this batch = 0.04249444708347954\n",
      "Error on this batch = 0.0724931738603555\n",
      "Cost on val dataset after 904 epochs is = 0.0939022775635137\n",
      "Initial Cost on Val dataset for this epoch 904 = 0.0939022775635137\n",
      "learning rate for this epoch =  0.09118594362878382\n",
      "Error on this batch = 0.04247164495307937\n",
      "Error on this batch = 0.07246703298467104\n",
      "Cost on val dataset after 905 epochs is = 0.09388841261955355\n",
      "Initial Cost on Val dataset for this epoch 905 = 0.09388841261955355\n",
      "learning rate for this epoch =  0.09116074369722786\n",
      "Error on this batch = 0.04244889690393025\n",
      "Error on this batch = 0.07244094475967479\n",
      "Cost on val dataset after 906 epochs is = 0.09387457561906228\n",
      "Initial Cost on Val dataset for this epoch 906 = 0.09387457561906228\n",
      "learning rate for this epoch =  0.09113557854819211\n",
      "Error on this batch = 0.0424262027246394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07241490895663515\n",
      "Cost on val dataset after 907 epochs is = 0.09386076647543204\n",
      "Initial Cost on Val dataset for this epoch 907 = 0.09386076647543204\n",
      "learning rate for this epoch =  0.09111044809535562\n",
      "Error on this batch = 0.042403562203904815\n",
      "Error on this batch = 0.07238892534734825\n",
      "Cost on val dataset after 908 epochs is = 0.09384698510247381\n",
      "Initial Cost on Val dataset for this epoch 908 = 0.09384698510247381\n",
      "learning rate for this epoch =  0.09108535225270664\n",
      "Error on this batch = 0.04238097513051527\n",
      "Error on this batch = 0.07236299370414208\n",
      "Cost on val dataset after 909 epochs is = 0.093833231414415\n",
      "Initial Cost on Val dataset for this epoch 909 = 0.093833231414415\n",
      "learning rate for this epoch =  0.09106029093454096\n",
      "Error on this batch = 0.04235844129335014\n",
      "Error on this batch = 0.07233711379988048\n",
      "Cost on val dataset after 910 epochs is = 0.0938195053258969\n",
      "Initial Cost on Val dataset for this epoch 910 = 0.0938195053258969\n",
      "learning rate for this epoch =  0.09103526405546067\n",
      "Error on this batch = 0.04233596048137972\n",
      "Error on this batch = 0.07231128540796707\n",
      "Cost on val dataset after 911 epochs is = 0.09380580675197234\n",
      "Initial Cost on Val dataset for this epoch 911 = 0.09380580675197234\n",
      "learning rate for this epoch =  0.09101027153037257\n",
      "Error on this batch = 0.042313532483665525\n",
      "Error on this batch = 0.07228550830234952\n",
      "Cost on val dataset after 912 epochs is = 0.09379213560810323\n",
      "Initial Cost on Val dataset for this epoch 912 = 0.09379213560810323\n",
      "learning rate for this epoch =  0.09098531327448692\n",
      "Error on this batch = 0.042291157089361014\n",
      "Error on this batch = 0.07225978225752351\n",
      "Cost on val dataset after 913 epochs is = 0.09377849181015795\n",
      "Initial Cost on Val dataset for this epoch 913 = 0.09377849181015795\n",
      "learning rate for this epoch =  0.09096038920331581\n",
      "Error on this batch = 0.04226883408771227\n",
      "Error on this batch = 0.07223410704853676\n",
      "Cost on val dataset after 914 epochs is = 0.09376487527440888\n",
      "Initial Cost on Val dataset for this epoch 914 = 0.09376487527440888\n",
      "learning rate for this epoch =  0.09093549923267195\n",
      "Error on this batch = 0.042246563268059215\n",
      "Error on this batch = 0.072208482450993\n",
      "Cost on val dataset after 915 epochs is = 0.09375128591752988\n",
      "Initial Cost on Val dataset for this epoch 915 = 0.09375128591752988\n",
      "learning rate for this epoch =  0.0909106432786672\n",
      "Error on this batch = 0.04222434441983662\n",
      "Error on this batch = 0.07218290824105601\n",
      "Cost on val dataset after 916 epochs is = 0.0937377236565936\n",
      "Initial Cost on Val dataset for this epoch 916 = 0.0937377236565936\n",
      "learning rate for this epoch =  0.09088582125771116\n",
      "Error on this batch = 0.04220217733257573\n",
      "Error on this batch = 0.07215738419545378\n",
      "Cost on val dataset after 917 epochs is = 0.09372418840906906\n",
      "Initial Cost on Val dataset for this epoch 917 = 0.09372418840906906\n",
      "learning rate for this epoch =  0.09086103308650982\n",
      "Error on this batch = 0.04218006179590573\n",
      "Error on this batch = 0.07213191009148215\n",
      "Cost on val dataset after 918 epochs is = 0.0937106800928188\n",
      "Initial Cost on Val dataset for this epoch 918 = 0.0937106800928188\n",
      "learning rate for this epoch =  0.09083627868206413\n",
      "Error on this batch = 0.04215799759955575\n",
      "Error on this batch = 0.07210648570700907\n",
      "Cost on val dataset after 919 epochs is = 0.09369719862609646\n",
      "Initial Cost on Val dataset for this epoch 919 = 0.09369719862609646\n",
      "learning rate for this epoch =  0.09081155796166877\n",
      "Error on this batch = 0.042135984533356804\n",
      "Error on this batch = 0.0720811108204783\n",
      "Cost on val dataset after 920 epochs is = 0.09368374392754389\n",
      "Initial Cost on Val dataset for this epoch 920 = 0.09368374392754389\n",
      "learning rate for this epoch =  0.09078687084291064\n",
      "Error on this batch = 0.04211402238724409\n",
      "Error on this batch = 0.07205578521091348\n",
      "Cost on val dataset after 921 epochs is = 0.09367031591618855\n",
      "Initial Cost on Val dataset for this epoch 921 = 0.09367031591618855\n",
      "learning rate for this epoch =  0.09076221724366758\n",
      "Error on this batch = 0.04209211095125939\n",
      "Error on this batch = 0.07203050865792171\n",
      "Cost on val dataset after 922 epochs is = 0.09365691451144077\n",
      "Initial Cost on Val dataset for this epoch 922 = 0.09365691451144077\n",
      "learning rate for this epoch =  0.09073759708210706\n",
      "Error on this batch = 0.04207025001555385\n",
      "Error on this batch = 0.07200528094169775\n",
      "Cost on val dataset after 923 epochs is = 0.09364353963309108\n",
      "Initial Cost on Val dataset for this epoch 923 = 0.09364353963309108\n",
      "learning rate for this epoch =  0.09071301027668477\n",
      "Error on this batch = 0.04204843937039067\n",
      "Error on this batch = 0.07198010184302742\n",
      "Cost on val dataset after 924 epochs is = 0.09363019120130722\n",
      "Initial Cost on Val dataset for this epoch 924 = 0.09363019120130722\n",
      "learning rate for this epoch =  0.09068845674614334\n",
      "Error on this batch = 0.042026678806148306\n",
      "Error on this batch = 0.07195497114329164\n",
      "Cost on val dataset after 925 epochs is = 0.09361686913663159\n",
      "Initial Cost on Val dataset for this epoch 925 = 0.09361686913663159\n",
      "learning rate for this epoch =  0.09066393640951106\n",
      "Error on this batch = 0.04200496811332366\n",
      "Error on this batch = 0.07192988862446989\n",
      "Cost on val dataset after 926 epochs is = 0.09360357335997829\n",
      "Initial Cost on Val dataset for this epoch 926 = 0.09360357335997829\n",
      "learning rate for this epoch =  0.09063944918610045\n",
      "Error on this batch = 0.041983307082535504\n",
      "Error on this batch = 0.07190485406914401\n",
      "Cost on val dataset after 927 epochs is = 0.09359030379263028\n",
      "Initial Cost on Val dataset for this epoch 927 = 0.09359030379263028\n",
      "learning rate for this epoch =  0.0906149949955071\n",
      "Error on this batch = 0.041961695504528225\n",
      "Error on this batch = 0.0718798672605018\n",
      "Cost on val dataset after 928 epochs is = 0.09357706035623661\n",
      "Initial Cost on Val dataset for this epoch 928 = 0.09357706035623661\n",
      "learning rate for this epoch =  0.09059057375760825\n",
      "Error on this batch = 0.04194013317017555\n",
      "Error on this batch = 0.07185492798234057\n",
      "Cost on val dataset after 929 epochs is = 0.09356384297280942\n",
      "Initial Cost on Val dataset for this epoch 929 = 0.09356384297280942\n",
      "learning rate for this epoch =  0.09056618539256157\n",
      "Error on this batch = 0.04191861987048478\n",
      "Error on this batch = 0.07183003601907048\n",
      "Cost on val dataset after 930 epochs is = 0.09355065156472106\n",
      "Initial Cost on Val dataset for this epoch 930 = 0.09355065156472106\n",
      "learning rate for this epoch =  0.09054182982080389\n",
      "Error on this batch = 0.04189715539660073\n",
      "Error on this batch = 0.07180519115571828\n",
      "Cost on val dataset after 931 epochs is = 0.09353748605470141\n",
      "Initial Cost on Val dataset for this epoch 931 = 0.09353748605470141\n",
      "learning rate for this epoch =  0.09051750696304985\n",
      "Error on this batch = 0.041875739539810504\n",
      "Error on this batch = 0.07178039317793056\n",
      "Cost on val dataset after 932 epochs is = 0.0935243463658345\n",
      "Initial Cost on Val dataset for this epoch 932 = 0.0935243463658345\n",
      "learning rate for this epoch =  0.0904932167402907\n",
      "Error on this batch = 0.041854372091547756\n",
      "Error on this batch = 0.07175564187197703\n",
      "Cost on val dataset after 933 epochs is = 0.09351123242155596\n",
      "Initial Cost on Val dataset for this epoch 933 = 0.09351123242155596\n",
      "learning rate for this epoch =  0.09046895907379304\n",
      "Error on this batch = 0.04183305284339772\n",
      "Error on this batch = 0.071730937024754\n",
      "Cost on val dataset after 934 epochs is = 0.09349814414564983\n",
      "Initial Cost on Val dataset for this epoch 934 = 0.09349814414564983\n",
      "learning rate for this epoch =  0.09044473388509751\n",
      "Error on this batch = 0.04181178158710215\n",
      "Error on this batch = 0.07170627842378748\n",
      "Cost on val dataset after 935 epochs is = 0.09348508146224564\n",
      "Initial Cost on Val dataset for this epoch 935 = 0.09348508146224564\n",
      "learning rate for this epoch =  0.0904205410960176\n",
      "Error on this batch = 0.04179055811456436\n",
      "Error on this batch = 0.07168166585723636\n",
      "Cost on val dataset after 936 epochs is = 0.09347204429581546\n",
      "Initial Cost on Val dataset for this epoch 936 = 0.09347204429581546\n",
      "learning rate for this epoch =  0.09039638062863838\n",
      "Error on this batch = 0.04176938221785475\n",
      "Error on this batch = 0.07165709911389563\n",
      "Cost on val dataset after 937 epochs is = 0.09345903257117079\n",
      "Initial Cost on Val dataset for this epoch 937 = 0.09345903257117079\n",
      "learning rate for this epoch =  0.09037225240531528\n",
      "Error on this batch = 0.041748253689216135\n",
      "Error on this batch = 0.07163257798319936\n",
      "Cost on val dataset after 938 epochs is = 0.09344604621345957\n",
      "Initial Cost on Val dataset for this epoch 938 = 0.09344604621345957\n",
      "learning rate for this epoch =  0.09034815634867288\n",
      "Error on this batch = 0.041727172321069615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07160810225522365\n",
      "Cost on val dataset after 939 epochs is = 0.09343308514816326\n",
      "Initial Cost on Val dataset for this epoch 939 = 0.09343308514816326\n",
      "learning rate for this epoch =  0.09032409238160365\n",
      "Error on this batch = 0.04170613790602018\n",
      "Error on this batch = 0.07158367172068977\n",
      "Cost on val dataset after 940 epochs is = 0.09342014930109364\n",
      "Initial Cost on Val dataset for this epoch 940 = 0.09342014930109364\n",
      "learning rate for this epoch =  0.09030006042726675\n",
      "Error on this batch = 0.041685150236863075\n",
      "Error on this batch = 0.07155928617096684\n",
      "Cost on val dataset after 941 epochs is = 0.09340723859838986\n",
      "Initial Cost on Val dataset for this epoch 941 = 0.09340723859838986\n",
      "learning rate for this epoch =  0.0902760604090869\n",
      "Error on this batch = 0.041664209106589745\n",
      "Error on this batch = 0.07153494539807467\n",
      "Cost on val dataset after 942 epochs is = 0.09339435296651531\n",
      "Initial Cost on Val dataset for this epoch 942 = 0.09339435296651531\n",
      "learning rate for this epoch =  0.09025209225075301\n",
      "Error on this batch = 0.041643314308394255\n",
      "Error on this batch = 0.0715106491946867\n",
      "Cost on val dataset after 943 epochs is = 0.09338149233225472\n",
      "Initial Cost on Val dataset for this epoch 943 = 0.09338149233225472\n",
      "learning rate for this epoch =  0.09022815587621721\n",
      "Error on this batch = 0.04162246563567978\n",
      "Error on this batch = 0.07148639735413244\n",
      "Cost on val dataset after 944 epochs is = 0.09336865662271086\n",
      "Initial Cost on Val dataset for this epoch 944 = 0.09336865662271086\n",
      "learning rate for this epoch =  0.0902042512096935\n",
      "Error on this batch = 0.0416016628820654\n",
      "Error on this batch = 0.07146218967040029\n",
      "Cost on val dataset after 945 epochs is = 0.09335584576530169\n",
      "Initial Cost on Val dataset for this epoch 945 = 0.09335584576530169\n",
      "learning rate for this epoch =  0.09018037817565662\n",
      "Error on this batch = 0.041580905841392804\n",
      "Error on this batch = 0.07143802593813994\n",
      "Cost on val dataset after 946 epochs is = 0.09334305968775714\n",
      "Initial Cost on Val dataset for this epoch 946 = 0.09334305968775714\n",
      "learning rate for this epoch =  0.09015653669884087\n",
      "Error on this batch = 0.041560194307733334\n",
      "Error on this batch = 0.0714139059526652\n",
      "Cost on val dataset after 947 epochs is = 0.09333029831811608\n",
      "Initial Cost on Val dataset for this epoch 947 = 0.09333029831811608\n",
      "learning rate for this epoch =  0.09013272670423898\n",
      "Error on this batch = 0.041539528075394995\n",
      "Error on this batch = 0.07138982950995597\n",
      "Cost on val dataset after 948 epochs is = 0.09331756158472344\n",
      "Initial Cost on Val dataset for this epoch 948 = 0.09331756158472344\n",
      "learning rate for this epoch =  0.09010894811710093\n",
      "Error on this batch = 0.04151890693892993\n",
      "Error on this batch = 0.07136579640666105\n",
      "Cost on val dataset after 949 epochs is = 0.09330484941622685\n",
      "Initial Cost on Val dataset for this epoch 949 = 0.09330484941622685\n",
      "learning rate for this epoch =  0.09008520086293277\n",
      "Error on this batch = 0.04149833069314158\n",
      "Error on this batch = 0.07134180644010017\n",
      "Cost on val dataset after 950 epochs is = 0.09329216174157375\n",
      "Initial Cost on Val dataset for this epoch 950 = 0.09329216174157375\n",
      "learning rate for this epoch =  0.09006148486749553\n",
      "Error on this batch = 0.041477799133092505\n",
      "Error on this batch = 0.07131785940826649\n",
      "Cost on val dataset after 951 epochs is = 0.09327949849000827\n",
      "Initial Cost on Val dataset for this epoch 951 = 0.09327949849000827\n",
      "learning rate for this epoch =  0.09003780005680402\n",
      "Error on this batch = 0.041457312054111774\n",
      "Error on this batch = 0.07129395510982862\n",
      "Cost on val dataset after 952 epochs is = 0.09326685959106838\n",
      "Initial Cost on Val dataset for this epoch 952 = 0.09326685959106838\n",
      "learning rate for this epoch =  0.09001414635712576\n",
      "Error on this batch = 0.041436869251802955\n",
      "Error on this batch = 0.07127009334413285\n",
      "Cost on val dataset after 953 epochs is = 0.09325424497458257\n",
      "Initial Cost on Val dataset for this epoch 953 = 0.09325424497458257\n",
      "learning rate for this epoch =  0.08999052369497976\n",
      "Error on this batch = 0.04141647052205199\n",
      "Error on this batch = 0.07124627391120515\n",
      "Cost on val dataset after 954 epochs is = 0.093241654570667\n",
      "Initial Cost on Val dataset for this epoch 954 = 0.093241654570667\n",
      "learning rate for this epoch =  0.08996693199713549\n",
      "Error on this batch = 0.041396115661035265\n",
      "Error on this batch = 0.07122249661175332\n",
      "Cost on val dataset after 955 epochs is = 0.09322908830972246\n",
      "Initial Cost on Val dataset for this epoch 955 = 0.09322908830972246\n",
      "learning rate for this epoch =  0.08994337119061177\n",
      "Error on this batch = 0.041375804465227775\n",
      "Error on this batch = 0.07119876124716883\n",
      "Cost on val dataset after 956 epochs is = 0.09321654612243134\n",
      "Initial Cost on Val dataset for this epoch 956 = 0.09321654612243134\n",
      "learning rate for this epoch =  0.08991984120267553\n",
      "Error on this batch = 0.041355536731411395\n",
      "Error on this batch = 0.07117506761952877\n",
      "Cost on val dataset after 957 epochs is = 0.09320402793975474\n",
      "Initial Cost on Val dataset for this epoch 957 = 0.09320402793975474\n",
      "learning rate for this epoch =  0.08989634196084093\n",
      "Error on this batch = 0.041335312256683264\n",
      "Error on this batch = 0.07115141553159779\n",
      "Cost on val dataset after 958 epochs is = 0.09319153369292933\n",
      "Initial Cost on Val dataset for this epoch 958 = 0.09319153369292933\n",
      "learning rate for this epoch =  0.089872873392868\n",
      "Error on this batch = 0.041315130838464297\n",
      "Error on this batch = 0.07112780478682973\n",
      "Cost on val dataset after 959 epochs is = 0.09317906331346468\n",
      "Initial Cost on Val dataset for this epoch 959 = 0.09317906331346468\n",
      "learning rate for this epoch =  0.08984943542676176\n",
      "Error on this batch = 0.041294992274507863\n",
      "Error on this batch = 0.07110423518936947\n",
      "Cost on val dataset after 960 epochs is = 0.09316661673313997\n",
      "Initial Cost on Val dataset for this epoch 960 = 0.09316661673313997\n",
      "learning rate for this epoch =  0.08982602799077107\n",
      "Error on this batch = 0.041274896362908306\n",
      "Error on this batch = 0.07108070654405457\n",
      "Cost on val dataset after 961 epochs is = 0.09315419388400141\n",
      "Initial Cost on Val dataset for this epoch 961 = 0.09315419388400141\n",
      "learning rate for this epoch =  0.08980265101338746\n",
      "Error on this batch = 0.04125484290210992\n",
      "Error on this batch = 0.071057218656417\n",
      "Cost on val dataset after 962 epochs is = 0.09314179469835918\n",
      "Initial Cost on Val dataset for this epoch 962 = 0.09314179469835918\n",
      "learning rate for this epoch =  0.0897793044233442\n",
      "Error on this batch = 0.04123483169091571\n",
      "Error on this batch = 0.07103377133268453\n",
      "Cost on val dataset after 963 epochs is = 0.09312941910878461\n",
      "Initial Cost on Val dataset for this epoch 963 = 0.09312941910878461\n",
      "learning rate for this epoch =  0.0897559881496152\n",
      "Error on this batch = 0.041214862528496446\n",
      "Error on this batch = 0.07101036437978249\n",
      "Cost on val dataset after 964 epochs is = 0.09311706704810738\n",
      "Initial Cost on Val dataset for this epoch 964 = 0.09311706704810738\n",
      "learning rate for this epoch =  0.08973270212141383\n",
      "Error on this batch = 0.041194935214399625\n",
      "Error on this batch = 0.07098699760533506\n",
      "Cost on val dataset after 965 epochs is = 0.09310473844941268\n",
      "Initial Cost on Val dataset for this epoch 965 = 0.09310473844941268\n",
      "learning rate for this epoch =  0.08970944626819201\n",
      "Error on this batch = 0.04117504954855867\n",
      "Error on this batch = 0.07096367081766679\n",
      "Cost on val dataset after 966 epochs is = 0.0930924332460384\n",
      "Initial Cost on Val dataset for this epoch 966 = 0.0930924332460384\n",
      "learning rate for this epoch =  0.0896862205196391\n",
      "Error on this batch = 0.04115520533130208\n",
      "Error on this batch = 0.07094038382580398\n",
      "Cost on val dataset after 967 epochs is = 0.0930801513715725\n",
      "Initial Cost on Val dataset for this epoch 967 = 0.0930801513715725\n",
      "learning rate for this epoch =  0.08966302480568086\n",
      "Error on this batch = 0.0411354023633627\n",
      "Error on this batch = 0.07091713643947602\n",
      "Cost on val dataset after 968 epochs is = 0.0930678927598501\n",
      "Initial Cost on Val dataset for this epoch 968 = 0.0930678927598501\n",
      "learning rate for this epoch =  0.08963985905647841\n",
      "Error on this batch = 0.04111564044588705\n",
      "Error on this batch = 0.0708939284691167\n",
      "Cost on val dataset after 969 epochs is = 0.09305565734495101\n",
      "Initial Cost on Val dataset for this epoch 969 = 0.09305565734495101\n",
      "learning rate for this epoch =  0.08961672320242715\n",
      "Error on this batch = 0.04109591938044474\n",
      "Error on this batch = 0.07087075972586539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 970 epochs is = 0.09304344506119694\n",
      "Initial Cost on Val dataset for this epoch 970 = 0.09304344506119694\n",
      "learning rate for this epoch =  0.08959361717415586\n",
      "Error on this batch = 0.04107623896903794\n",
      "Error on this batch = 0.07084763002156837\n",
      "Cost on val dataset after 971 epochs is = 0.0930312558431489\n",
      "Initial Cost on Val dataset for this epoch 971 = 0.0930312558431489\n",
      "learning rate for this epoch =  0.08957054090252553\n",
      "Error on this batch = 0.04105659901411074\n",
      "Error on this batch = 0.07082453916877979\n",
      "Cost on val dataset after 972 epochs is = 0.0930190896256047\n",
      "Initial Cost on Val dataset for this epoch 972 = 0.0930190896256047\n",
      "learning rate for this epoch =  0.08954749431862849\n",
      "Error on this batch = 0.04103699931855877\n",
      "Error on this batch = 0.07080148698076301\n",
      "Cost on val dataset after 973 epochs is = 0.09300694634359633\n",
      "Initial Cost on Val dataset for this epoch 973 = 0.09300694634359633\n",
      "learning rate for this epoch =  0.08952447735378725\n",
      "Error on this batch = 0.041017439685738837\n",
      "Error on this batch = 0.0707784732714916\n",
      "Cost on val dataset after 974 epochs is = 0.09299482593238746\n",
      "Initial Cost on Val dataset for this epoch 974 = 0.09299482593238746\n",
      "learning rate for this epoch =  0.08950148993955362\n",
      "Error on this batch = 0.04099791991947841\n",
      "Error on this batch = 0.07075549785565034\n",
      "Cost on val dataset after 975 epochs is = 0.09298272832747101\n",
      "Initial Cost on Val dataset for this epoch 975 = 0.09298272832747101\n",
      "learning rate for this epoch =  0.08947853200770761\n",
      "Error on this batch = 0.04097843982408543\n",
      "Error on this batch = 0.07073256054863632\n",
      "Cost on val dataset after 976 epochs is = 0.09297065346456673\n",
      "Initial Cost on Val dataset for this epoch 976 = 0.09297065346456673\n",
      "learning rate for this epoch =  0.08945560349025655\n",
      "Error on this batch = 0.04095899920435784\n",
      "Error on this batch = 0.07070966116655984\n",
      "Cost on val dataset after 977 epochs is = 0.09295860127961882\n",
      "Initial Cost on Val dataset for this epoch 977 = 0.09295860127961882\n",
      "learning rate for this epoch =  0.08943270431943395\n",
      "Error on this batch = 0.040939597865593313\n",
      "Error on this batch = 0.0706867995262454\n",
      "Cost on val dataset after 978 epochs is = 0.09294657170879358\n",
      "Initial Cost on Val dataset for this epoch 978 = 0.09294657170879358\n",
      "learning rate for this epoch =  0.08940983442769869\n",
      "Error on this batch = 0.04092023561359905\n",
      "Error on this batch = 0.07066397544523252\n",
      "Cost on val dataset after 979 epochs is = 0.09293456468847715\n",
      "Initial Cost on Val dataset for this epoch 979 = 0.09293456468847715\n",
      "learning rate for this epoch =  0.08938699374773387\n",
      "Error on this batch = 0.04090091225470143\n",
      "Error on this batch = 0.07064118874177673\n",
      "Cost on val dataset after 980 epochs is = 0.09292258015527313\n",
      "Initial Cost on Val dataset for this epoch 980 = 0.09292258015527313\n",
      "learning rate for this epoch =  0.089364182212446\n",
      "Error on this batch = 0.04088162759575576\n",
      "Error on this batch = 0.07061843923485037\n",
      "Cost on val dataset after 981 epochs is = 0.09291061804600065\n",
      "Initial Cost on Val dataset for this epoch 981 = 0.09291061804600065\n",
      "learning rate for this epoch =  0.08934139975496388\n",
      "Error on this batch = 0.04086238144415605\n",
      "Error on this batch = 0.07059572674414331\n",
      "Cost on val dataset after 982 epochs is = 0.09289867829769194\n",
      "Initial Cost on Val dataset for this epoch 982 = 0.09289867829769194\n",
      "learning rate for this epoch =  0.08931864630863778\n",
      "Error on this batch = 0.04084317360784476\n",
      "Error on this batch = 0.07057305109006388\n",
      "Cost on val dataset after 983 epochs is = 0.09288676084759041\n",
      "Initial Cost on Val dataset for this epoch 983 = 0.09288676084759041\n",
      "learning rate for this epoch =  0.08929592180703835\n",
      "Error on this batch = 0.040824003895322515\n",
      "Error on this batch = 0.07055041209373947\n",
      "Cost on val dataset after 984 epochs is = 0.09287486563314852\n",
      "Initial Cost on Val dataset for this epoch 984 = 0.09287486563314852\n",
      "learning rate for this epoch =  0.08927322618395579\n",
      "Error on this batch = 0.040804872115657885\n",
      "Error on this batch = 0.07052780957701744\n",
      "Cost on val dataset after 985 epochs is = 0.09286299259202574\n",
      "Initial Cost on Val dataset for this epoch 985 = 0.09286299259202574\n",
      "learning rate for this epoch =  0.08925055937339876\n",
      "Error on this batch = 0.040785778078497065\n",
      "Error on this batch = 0.07050524336246565\n",
      "Cost on val dataset after 986 epochs is = 0.09285114166208668\n",
      "Initial Cost on Val dataset for this epoch 986 = 0.09285114166208668\n",
      "learning rate for this epoch =  0.08922792130959359\n",
      "Error on this batch = 0.04076672159407356\n",
      "Error on this batch = 0.07048271327337313\n",
      "Cost on val dataset after 987 epochs is = 0.09283931278139912\n",
      "Initial Cost on Val dataset for this epoch 987 = 0.09283931278139912\n",
      "learning rate for this epoch =  0.08920531192698324\n",
      "Error on this batch = 0.04074770247321793\n",
      "Error on this batch = 0.07046021913375089\n",
      "Cost on val dataset after 988 epochs is = 0.0928275058882322\n",
      "Initial Cost on Val dataset for this epoch 988 = 0.0928275058882322\n",
      "learning rate for this epoch =  0.08918273116022643\n",
      "Error on this batch = 0.040728720527367396\n",
      "Error on this batch = 0.07043776076833241\n",
      "Cost on val dataset after 989 epochs is = 0.0928157209210546\n",
      "Initial Cost on Val dataset for this epoch 989 = 0.0928157209210546\n",
      "learning rate for this epoch =  0.08916017894419664\n",
      "Error on this batch = 0.04070977556857552\n",
      "Error on this batch = 0.07041533800257431\n",
      "Cost on val dataset after 990 epochs is = 0.09280395781853272\n",
      "Initial Cost on Val dataset for this epoch 990 = 0.09280395781853272\n",
      "learning rate for this epoch =  0.08913765521398127\n",
      "Error on this batch = 0.04069086740952172\n",
      "Error on this batch = 0.07039295066265681\n",
      "Cost on val dataset after 991 epochs is = 0.09279221651952918\n",
      "Initial Cost on Val dataset for this epoch 991 = 0.09279221651952918\n",
      "learning rate for this epoch =  0.08911515990488066\n",
      "Error on this batch = 0.04067199586352092\n",
      "Error on this batch = 0.07037059857548447\n",
      "Cost on val dataset after 992 epochs is = 0.09278049696310094\n",
      "Initial Cost on Val dataset for this epoch 992 = 0.09278049696310094\n",
      "learning rate for this epoch =  0.0890926929524072\n",
      "Error on this batch = 0.040653160744532936\n",
      "Error on this batch = 0.07034828156868655\n",
      "Cost on val dataset after 993 epochs is = 0.09276879908849779\n",
      "Initial Cost on Val dataset for this epoch 993 = 0.09276879908849779\n",
      "learning rate for this epoch =  0.08907025429228442\n",
      "Error on this batch = 0.040634361867172085\n",
      "Error on this batch = 0.07032599947061761\n",
      "Cost on val dataset after 994 epochs is = 0.09275712283516095\n",
      "Initial Cost on Val dataset for this epoch 994 = 0.09275712283516095\n",
      "learning rate for this epoch =  0.08904784386044612\n",
      "Error on this batch = 0.040615599046716466\n",
      "Error on this batch = 0.07030375211035808\n",
      "Cost on val dataset after 995 epochs is = 0.09274546814272146\n",
      "Initial Cost on Val dataset for this epoch 995 = 0.09274546814272146\n",
      "learning rate for this epoch =  0.08902546159303537\n",
      "Error on this batch = 0.040596872099117345\n",
      "Error on this batch = 0.07028153931771451\n",
      "Cost on val dataset after 996 epochs is = 0.09273383495099864\n",
      "Initial Cost on Val dataset for this epoch 996 = 0.09273383495099864\n",
      "learning rate for this epoch =  0.0890031074264038\n",
      "Error on this batch = 0.040578180841008456\n",
      "Error on this batch = 0.07025936092322038\n",
      "Cost on val dataset after 997 epochs is = 0.09272222319999902\n",
      "Initial Cost on Val dataset for this epoch 997 = 0.09272222319999902\n",
      "learning rate for this epoch =  0.08898078129711047\n",
      "Error on this batch = 0.040559525089715276\n",
      "Error on this batch = 0.0702372167581361\n",
      "Cost on val dataset after 998 epochs is = 0.09271063282991475\n",
      "Initial Cost on Val dataset for this epoch 998 = 0.09271063282991475\n",
      "learning rate for this epoch =  0.08895848314192122\n",
      "Error on this batch = 0.04054090466326409\n",
      "Error on this batch = 0.0702151066544498\n",
      "Cost on val dataset after 999 epochs is = 0.09269906378112244\n",
      "Initial Cost on Val dataset for this epoch 999 = 0.09269906378112244\n",
      "learning rate for this epoch =  0.08893621289780759\n",
      "Error on this batch = 0.04052231938039118\n",
      "Error on this batch = 0.07019303044487758\n",
      "Cost on val dataset after 1000 epochs is = 0.09268751599418197\n",
      "Initial Cost on Val dataset for this epoch 1000 = 0.09268751599418197\n",
      "learning rate for this epoch =  0.08891397050194613\n",
      "Error on this batch = 0.040503769060551705\n",
      "Error on this batch = 0.07017098796286395\n",
      "Cost on val dataset after 1001 epochs is = 0.09267598940983528\n",
      "Initial Cost on Val dataset for this epoch 1001 = 0.09267598940983528\n",
      "learning rate for this epoch =  0.0888917558917174\n",
      "Error on this batch = 0.04048525352392874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.07014897904258209\n",
      "Cost on val dataset after 1002 epochs is = 0.09266448396900528\n",
      "Initial Cost on Val dataset for this epoch 1002 = 0.09266448396900528\n",
      "learning rate for this epoch =  0.0888695690047051\n",
      "Error on this batch = 0.04046677259144205\n",
      "Error on this batch = 0.07012700351893433\n",
      "Cost on val dataset after 1003 epochs is = 0.09265299961279483\n",
      "Initial Cost on Val dataset for this epoch 1003 = 0.09265299961279483\n",
      "learning rate for this epoch =  0.08884740977869533\n",
      "Error on this batch = 0.04044832608475691\n",
      "Error on this batch = 0.07010506122755243\n",
      "Cost on val dataset after 1004 epochs is = 0.09264153628248578\n",
      "Initial Cost on Val dataset for this epoch 1004 = 0.09264153628248578\n",
      "learning rate for this epoch =  0.0888252781516756\n",
      "Error on this batch = 0.04042991382629268\n",
      "Error on this batch = 0.07008315200479799\n",
      "Cost on val dataset after 1005 epochs is = 0.09263009391953785\n",
      "Initial Cost on Val dataset for this epoch 1005 = 0.09263009391953785\n",
      "learning rate for this epoch =  0.08880317406183406\n",
      "Error on this batch = 0.04041153563923142\n",
      "Error on this batch = 0.07006127568776259\n",
      "Cost on val dataset after 1006 epochs is = 0.09261867246558801\n",
      "Initial Cost on Val dataset for this epoch 1006 = 0.09261867246558801\n",
      "learning rate for this epoch =  0.08878109744755859\n",
      "Error on this batch = 0.040393191347526385\n",
      "Error on this batch = 0.07003943211426822\n",
      "Cost on val dataset after 1007 epochs is = 0.09260727186244937\n",
      "Initial Cost on Val dataset for this epoch 1007 = 0.09260727186244937\n",
      "learning rate for this epoch =  0.08875904824743605\n",
      "Error on this batch = 0.0403748807759103\n",
      "Error on this batch = 0.07001762112286751\n",
      "Cost on val dataset after 1008 epochs is = 0.09259589205211066\n",
      "Initial Cost on Val dataset for this epoch 1008 = 0.09259589205211066\n",
      "learning rate for this epoch =  0.08873702640025133\n",
      "Error on this batch = 0.04035660374990371\n",
      "Error on this batch = 0.06999584255284404\n",
      "Cost on val dataset after 1009 epochs is = 0.09258453297673525\n",
      "Initial Cost on Val dataset for this epoch 1009 = 0.09258453297673525\n",
      "learning rate for this epoch =  0.08871503184498658\n",
      "Error on this batch = 0.04033836009582302\n",
      "Error on this batch = 0.06997409624421243\n",
      "Cost on val dataset after 1010 epochs is = 0.0925731945786606\n",
      "Initial Cost on Val dataset for this epoch 1010 = 0.0925731945786606\n",
      "learning rate for this epoch =  0.08869306452082039\n",
      "Error on this batch = 0.04032014964078865\n",
      "Error on this batch = 0.06995238203771882\n",
      "Cost on val dataset after 1011 epochs is = 0.09256187680039774\n",
      "Initial Cost on Val dataset for this epoch 1011 = 0.09256187680039774\n",
      "learning rate for this epoch =  0.0886711243671269\n",
      "Error on this batch = 0.0403019722127328\n",
      "Error on this batch = 0.06993069977484088\n",
      "Cost on val dataset after 1012 epochs is = 0.09255057958463038\n",
      "Initial Cost on Val dataset for this epoch 1012 = 0.09255057958463038\n",
      "learning rate for this epoch =  0.08864921132347509\n",
      "Error on this batch = 0.040283827640407346\n",
      "Error on this batch = 0.06990904929778814\n",
      "Cost on val dataset after 1013 epochs is = 0.09253930287421469\n",
      "Initial Cost on Val dataset for this epoch 1013 = 0.09253930287421469\n",
      "learning rate for this epoch =  0.0886273253296278\n",
      "Error on this batch = 0.040265715753391496\n",
      "Error on this batch = 0.06988743044950199\n",
      "Cost on val dataset after 1014 epochs is = 0.0925280466121786\n",
      "Initial Cost on Val dataset for this epoch 1014 = 0.0925280466121786\n",
      "learning rate for this epoch =  0.08860546632554109\n",
      "Error on this batch = 0.04024763638209926\n",
      "Error on this batch = 0.06986584307365613\n",
      "Cost on val dataset after 1015 epochs is = 0.09251681074172151\n",
      "Initial Cost on Val dataset for this epoch 1015 = 0.09251681074172151\n",
      "learning rate for this epoch =  0.0885836342513633\n",
      "Error on this batch = 0.04022958935778693\n",
      "Error on this batch = 0.0698442870146564\n",
      "Cost on val dataset after 1016 epochs is = 0.09250559520621385\n",
      "Initial Cost on Val dataset for this epoch 1016 = 0.09250559520621385\n",
      "learning rate for this epoch =  0.08856182904743433\n",
      "Error on this batch = 0.040211574512560355\n",
      "Error on this batch = 0.06982276211764125\n",
      "Cost on val dataset after 1017 epochs is = 0.09249439994919664\n",
      "Initial Cost on Val dataset for this epoch 1017 = 0.09249439994919664\n",
      "learning rate for this epoch =  0.08854005065428476\n",
      "Error on this batch = 0.04019359167938205\n",
      "Error on this batch = 0.0698012682284816\n",
      "Cost on val dataset after 1018 epochs is = 0.09248322491438139\n",
      "Initial Cost on Val dataset for this epoch 1018 = 0.09248322491438139\n",
      "learning rate for this epoch =  0.08851829901263515\n",
      "Error on this batch = 0.04017564069207818\n",
      "Error on this batch = 0.06977980519378099\n",
      "Cost on val dataset after 1019 epochs is = 0.09247207004564964\n",
      "Initial Cost on Val dataset for this epoch 1019 = 0.09247207004564964\n",
      "learning rate for this epoch =  0.08849657406339513\n",
      "Error on this batch = 0.040157721385345485\n",
      "Error on this batch = 0.06975837286087579\n",
      "Cost on val dataset after 1020 epochs is = 0.09246093528705296\n",
      "Initial Cost on Val dataset for this epoch 1020 = 0.09246093528705296\n",
      "learning rate for this epoch =  0.08847487574766279\n",
      "Error on this batch = 0.040139833594757875\n",
      "Error on this batch = 0.06973697107783516\n",
      "Cost on val dataset after 1021 epochs is = 0.09244982058281256\n",
      "Initial Cost on Val dataset for this epoch 1021 = 0.09244982058281256\n",
      "learning rate for this epoch =  0.08845320400672366\n",
      "Error on this batch = 0.040121977156773174\n",
      "Error on this batch = 0.06971559969346111\n",
      "Cost on val dataset after 1022 epochs is = 0.09243872587731931\n",
      "Initial Cost on Val dataset for this epoch 1022 = 0.09243872587731931\n",
      "learning rate for this epoch =  0.0884315587820501\n",
      "Error on this batch = 0.04010415190873934\n",
      "Error on this batch = 0.06969425855728856\n",
      "Cost on val dataset after 1023 epochs is = 0.09242765111513368\n",
      "Initial Cost on Val dataset for this epoch 1023 = 0.09242765111513368\n",
      "learning rate for this epoch =  0.08840994001530049\n",
      "Error on this batch = 0.04008635768890095\n",
      "Error on this batch = 0.0696729475195853\n",
      "Cost on val dataset after 1024 epochs is = 0.09241659624098558\n",
      "Initial Cost on Val dataset for this epoch 1024 = 0.09241659624098558\n",
      "learning rate for this epoch =  0.08838834764831843\n",
      "Error on this batch = 0.040068594336405104\n",
      "Error on this batch = 0.0696516664313521\n",
      "Cost on val dataset after 1025 epochs is = 0.09240556119977433\n",
      "Initial Cost on Val dataset for this epoch 1025 = 0.09240556119977433\n",
      "learning rate for this epoch =  0.08836678162313201\n",
      "Error on this batch = 0.04005086169130744\n",
      "Error on this batch = 0.06963041514432253\n",
      "Cost on val dataset after 1026 epochs is = 0.0923945459365689\n",
      "Initial Cost on Val dataset for this epoch 1026 = 0.0923945459365689\n",
      "learning rate for this epoch =  0.088345241881953\n",
      "Error on this batch = 0.04003315959457807\n",
      "Error on this batch = 0.06960919351096302\n",
      "Cost on val dataset after 1027 epochs is = 0.09238355039660776\n",
      "Initial Cost on Val dataset for this epoch 1027 = 0.09238355039660776\n",
      "learning rate for this epoch =  0.0883237283671761\n",
      "Error on this batch = 0.04001548788810699\n",
      "Error on this batch = 0.0695880013844728\n",
      "Cost on val dataset after 1028 epochs is = 0.09237257452529901\n",
      "Initial Cost on Val dataset for this epoch 1028 = 0.09237257452529901\n",
      "learning rate for this epoch =  0.0883022410213782\n",
      "Error on this batch = 0.03999784641470977\n",
      "Error on this batch = 0.06956683861878364\n",
      "Cost on val dataset after 1029 epochs is = 0.09236161826822067\n",
      "Initial Cost on Val dataset for this epoch 1029 = 0.09236161826822067\n",
      "learning rate for this epoch =  0.08828077978731765\n",
      "Error on this batch = 0.03998023501813266\n",
      "Error on this batch = 0.06954570506856002\n",
      "Cost on val dataset after 1030 epochs is = 0.09235068157112068\n",
      "Initial Cost on Val dataset for this epoch 1030 = 0.09235068157112068\n",
      "learning rate for this epoch =  0.08825934460793343\n",
      "Error on this batch = 0.039962653543057974\n",
      "Error on this batch = 0.06952460058919878\n",
      "Cost on val dataset after 1031 epochs is = 0.09233976437991707\n",
      "Initial Cost on Val dataset for this epoch 1031 = 0.09233976437991707\n",
      "learning rate for this epoch =  0.08823793542634452\n",
      "Error on this batch = 0.039945101835108805\n",
      "Error on this batch = 0.06950352503682905\n",
      "Cost on val dataset after 1032 epochs is = 0.0923288666406984\n",
      "Initial Cost on Val dataset for this epoch 1032 = 0.0923288666406984\n",
      "learning rate for this epoch =  0.08821655218584905\n",
      "Error on this batch = 0.039927579740854\n",
      "Error on this batch = 0.06948247826831208\n",
      "Cost on val dataset after 1033 epochs is = 0.09231798829972375\n",
      "Initial Cost on Val dataset for this epoch 1033 = 0.09231798829972375\n",
      "learning rate for this epoch =  0.08819519482992363\n",
      "Error on this batch = 0.03991008710781276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06946146014124097\n",
      "Cost on val dataset after 1034 epochs is = 0.09230712930342323\n",
      "Initial Cost on Val dataset for this epoch 1034 = 0.09230712930342323\n",
      "learning rate for this epoch =  0.08817386330222259\n",
      "Error on this batch = 0.03989262378445911\n",
      "Error on this batch = 0.06944047051394049\n",
      "Cost on val dataset after 1035 epochs is = 0.09229628959839808\n",
      "Initial Cost on Val dataset for this epoch 1035 = 0.09229628959839808\n",
      "learning rate for this epoch =  0.08815255754657725\n",
      "Error on this batch = 0.03987518962022612\n",
      "Error on this batch = 0.0694195092454669\n",
      "Cost on val dataset after 1036 epochs is = 0.09228546913142123\n",
      "Initial Cost on Val dataset for this epoch 1036 = 0.09228546913142123\n",
      "learning rate for this epoch =  0.08813127750699522\n",
      "Error on this batch = 0.03985778446551016\n",
      "Error on this batch = 0.06939857619560746\n",
      "Cost on val dataset after 1037 epochs is = 0.0922746678494374\n",
      "Initial Cost on Val dataset for this epoch 1037 = 0.0922746678494374\n",
      "learning rate for this epoch =  0.08811002312765961\n",
      "Error on this batch = 0.039840408171674634\n",
      "Error on this batch = 0.06937767122488048\n",
      "Cost on val dataset after 1038 epochs is = 0.09226388569956373\n",
      "Initial Cost on Val dataset for this epoch 1038 = 0.09226388569956373\n",
      "learning rate for this epoch =  0.08808879435292839\n",
      "Error on this batch = 0.03982306059105404\n",
      "Error on this batch = 0.06935679419453454\n",
      "Cost on val dataset after 1039 epochs is = 0.09225312262908998\n",
      "Initial Cost on Val dataset for this epoch 1039 = 0.09225312262908998\n",
      "learning rate for this epoch =  0.08806759112733367\n",
      "Error on this batch = 0.03980574157695719\n",
      "Error on this batch = 0.06933594496654853\n",
      "Cost on val dataset after 1040 epochs is = 0.09224237858547903\n",
      "Initial Cost on Val dataset for this epoch 1040 = 0.09224237858547903\n",
      "learning rate for this epoch =  0.0880464133955809\n",
      "Error on this batch = 0.039788450983671\n",
      "Error on this batch = 0.06931512340363107\n",
      "Cost on val dataset after 1041 epochs is = 0.09223165351636739\n",
      "Initial Cost on Val dataset for this epoch 1041 = 0.09223165351636739\n",
      "learning rate for this epoch =  0.08802526110254827\n",
      "Error on this batch = 0.0397711886664634\n",
      "Error on this batch = 0.06929432936922013\n",
      "Cost on val dataset after 1042 epochs is = 0.09222094736956546\n",
      "Initial Cost on Val dataset for this epoch 1042 = 0.09222094736956546\n",
      "learning rate for this epoch =  0.0880041341932859\n",
      "Error on this batch = 0.039753954481586556\n",
      "Error on this batch = 0.06927356272748254\n",
      "Cost on val dataset after 1043 epochs is = 0.09221026009305817\n",
      "Initial Cost on Val dataset for this epoch 1043 = 0.09221026009305817\n",
      "learning rate for this epoch =  0.08798303261301525\n",
      "Error on this batch = 0.03973674828627976\n",
      "Error on this batch = 0.06925282334331367\n",
      "Cost on val dataset after 1044 epochs is = 0.09219959163500543\n",
      "Initial Cost on Val dataset for this epoch 1044 = 0.09219959163500543\n",
      "learning rate for this epoch =  0.08796195630712837\n",
      "Error on this batch = 0.03971956993877198\n",
      "Error on this batch = 0.06923211108233673\n",
      "Cost on val dataset after 1045 epochs is = 0.09218894194374254\n",
      "Initial Cost on Val dataset for this epoch 1045 = 0.09218894194374254\n",
      "learning rate for this epoch =  0.08794090522118717\n",
      "Error on this batch = 0.039702419298284525\n",
      "Error on this batch = 0.0692114258109024\n",
      "Cost on val dataset after 1046 epochs is = 0.09217831096778081\n",
      "Initial Cost on Val dataset for this epoch 1046 = 0.09217831096778081\n",
      "learning rate for this epoch =  0.08791987930092278\n",
      "Error on this batch = 0.03968529622503329\n",
      "Error on this batch = 0.06919076739608818\n",
      "Cost on val dataset after 1047 epochs is = 0.09216769865580801\n",
      "Initial Cost on Val dataset for this epoch 1047 = 0.09216769865580801\n",
      "learning rate for this epoch =  0.08789887849223484\n",
      "Error on this batch = 0.03966820058023085\n",
      "Error on this batch = 0.06917013570569779\n",
      "Cost on val dataset after 1048 epochs is = 0.0921571049566889\n",
      "Initial Cost on Val dataset for this epoch 1048 = 0.0921571049566889\n",
      "learning rate for this epoch =  0.08787790274119082\n",
      "Error on this batch = 0.03965113222608863\n",
      "Error on this batch = 0.06914953060826068\n",
      "Cost on val dataset after 1049 epochs is = 0.09214652981946572\n",
      "Initial Cost on Val dataset for this epoch 1049 = 0.09214652981946572\n",
      "learning rate for this epoch =  0.08785695199402538\n",
      "Error on this batch = 0.0396340910258185\n",
      "Error on this batch = 0.06912895197303112\n",
      "Cost on val dataset after 1050 epochs is = 0.0921359731933589\n",
      "Initial Cost on Val dataset for this epoch 1050 = 0.0921359731933589\n",
      "learning rate for this epoch =  0.08783602619713961\n",
      "Error on this batch = 0.03961707684363444\n",
      "Error on this batch = 0.0691083996699877\n",
      "Cost on val dataset after 1051 epochs is = 0.0921254350277674\n",
      "Initial Cost on Val dataset for this epoch 1051 = 0.0921254350277674\n",
      "learning rate for this epoch =  0.08781512529710042\n",
      "Error on this batch = 0.03960008954475397\n",
      "Error on this batch = 0.06908787356983269\n",
      "Cost on val dataset after 1052 epochs is = 0.0921149152722694\n",
      "Initial Cost on Val dataset for this epoch 1052 = 0.0921149152722694\n",
      "learning rate for this epoch =  0.08779424924063986\n",
      "Error on this batch = 0.03958312899539947\n",
      "Error on this batch = 0.06906737354399094\n",
      "Cost on val dataset after 1053 epochs is = 0.09210441387662274\n",
      "Initial Cost on Val dataset for this epoch 1053 = 0.09210441387662274\n",
      "learning rate for this epoch =  0.08777339797465443\n",
      "Error on this batch = 0.03956619506279915\n",
      "Error on this batch = 0.06904689946460936\n",
      "Cost on val dataset after 1054 epochs is = 0.0920939307907656\n",
      "Initial Cost on Val dataset for this epoch 1054 = 0.0920939307907656\n",
      "learning rate for this epoch =  0.08775257144620446\n",
      "Error on this batch = 0.039549287615188\n",
      "Error on this batch = 0.06902645120455608\n",
      "Cost on val dataset after 1055 epochs is = 0.092083465964817\n",
      "Initial Cost on Val dataset for this epoch 1055 = 0.092083465964817\n",
      "learning rate for this epoch =  0.08773176960251337\n",
      "Error on this batch = 0.03953240652180846\n",
      "Error on this batch = 0.06900602863741953\n",
      "Cost on val dataset after 1056 epochs is = 0.0920730193490772\n",
      "Initial Cost on Val dataset for this epoch 1056 = 0.0920730193490772\n",
      "learning rate for this epoch =  0.08771099239096714\n",
      "Error on this batch = 0.03951555165291101\n",
      "Error on this batch = 0.06898563163750747\n",
      "Cost on val dataset after 1057 epochs is = 0.0920625908940286\n",
      "Initial Cost on Val dataset for this epoch 1057 = 0.0920625908940286\n",
      "learning rate for this epoch =  0.08769023975911351\n",
      "Error on this batch = 0.039498722879754554\n",
      "Error on this batch = 0.0689652600798462\n",
      "Cost on val dataset after 1058 epochs is = 0.09205218055033597\n",
      "Initial Cost on Val dataset for this epoch 1058 = 0.09205218055033597\n",
      "learning rate for this epoch =  0.08766951165466147\n",
      "Error on this batch = 0.03948192007460648\n",
      "Error on this batch = 0.06894491384017946\n",
      "Cost on val dataset after 1059 epochs is = 0.09204178826884704\n",
      "Initial Cost on Val dataset for this epoch 1059 = 0.09204178826884704\n",
      "learning rate for this epoch =  0.08764880802548045\n",
      "Error on this batch = 0.03946514311074284\n",
      "Error on this batch = 0.06892459279496752\n",
      "Cost on val dataset after 1060 epochs is = 0.0920314140005933\n",
      "Initial Cost on Val dataset for this epoch 1060 = 0.0920314140005933\n",
      "learning rate for this epoch =  0.08762812881959987\n",
      "Error on this batch = 0.03944839186244804\n",
      "Error on this batch = 0.06890429682138612\n",
      "Cost on val dataset after 1061 epochs is = 0.09202105769679013\n",
      "Initial Cost on Val dataset for this epoch 1061 = 0.09202105769679013\n",
      "learning rate for this epoch =  0.08760747398520836\n",
      "Error on this batch = 0.03943166620501464\n",
      "Error on this batch = 0.06888402579732533\n",
      "Cost on val dataset after 1062 epochs is = 0.09201071930883768\n",
      "Initial Cost on Val dataset for this epoch 1062 = 0.09201071930883768\n",
      "learning rate for this epoch =  0.08758684347065314\n",
      "Error on this batch = 0.03941496601474276\n",
      "Error on this batch = 0.06886377960138845\n",
      "Cost on val dataset after 1063 epochs is = 0.09200039878832117\n",
      "Initial Cost on Val dataset for this epoch 1063 = 0.09200039878832117\n",
      "learning rate for this epoch =  0.08756623722443944\n",
      "Error on this batch = 0.03939829116893942\n",
      "Error on this batch = 0.06884355811289095\n",
      "Cost on val dataset after 1064 epochs is = 0.09199009608701146\n",
      "Initial Cost on Val dataset for this epoch 1064 = 0.09199009608701146\n",
      "learning rate for this epoch =  0.08754565519522983\n",
      "Error on this batch = 0.0393816415459178\n",
      "Error on this batch = 0.06882336121185915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1065 epochs is = 0.0919798111568656\n",
      "Initial Cost on Val dataset for this epoch 1065 = 0.0919798111568656\n",
      "learning rate for this epoch =  0.08752509733184359\n",
      "Error on this batch = 0.03936501702499607\n",
      "Error on this batch = 0.06880318877902909\n",
      "Cost on val dataset after 1066 epochs is = 0.09196954395002725\n",
      "Initial Cost on Val dataset for this epoch 1066 = 0.09196954395002725\n",
      "learning rate for this epoch =  0.0875045635832561\n",
      "Error on this batch = 0.03934841748649636\n",
      "Error on this batch = 0.06878304069584525\n",
      "Cost on val dataset after 1067 epochs is = 0.09195929441882714\n",
      "Initial Cost on Val dataset for this epoch 1067 = 0.09195929441882714\n",
      "learning rate for this epoch =  0.08748405389859822\n",
      "Error on this batch = 0.03933184281174341\n",
      "Error on this batch = 0.06876291684445915\n",
      "Cost on val dataset after 1068 epochs is = 0.09194906251578362\n",
      "Initial Cost on Val dataset for this epoch 1068 = 0.09194906251578362\n",
      "learning rate for this epoch =  0.08746356822715562\n",
      "Error on this batch = 0.039315292883063\n",
      "Error on this batch = 0.06874281710772814\n",
      "Cost on val dataset after 1069 epochs is = 0.091938848193603\n",
      "Initial Cost on Val dataset for this epoch 1069 = 0.091938848193603\n",
      "learning rate for this epoch =  0.08744310651836827\n",
      "Error on this batch = 0.03929876758378037\n",
      "Error on this batch = 0.06872274136921394\n",
      "Cost on val dataset after 1070 epochs is = 0.0919286514051801\n",
      "Initial Cost on Val dataset for this epoch 1070 = 0.0919286514051801\n",
      "learning rate for this epoch =  0.08742266872182974\n",
      "Error on this batch = 0.039282266798218377\n",
      "Error on this batch = 0.06870268951318126\n",
      "Cost on val dataset after 1071 epochs is = 0.0919184721035985\n",
      "Initial Cost on Val dataset for this epoch 1071 = 0.0919184721035985\n",
      "learning rate for this epoch =  0.08740225478728658\n",
      "Error on this batch = 0.039265790411695554\n",
      "Error on this batch = 0.06868266142459631\n",
      "Cost on val dataset after 1072 epochs is = 0.09190831024213114\n",
      "Initial Cost on Val dataset for this epoch 1072 = 0.09190831024213114\n",
      "learning rate for this epoch =  0.0873818646646378\n",
      "Error on this batch = 0.039249338310524025\n",
      "Error on this batch = 0.06866265698912542\n",
      "Cost on val dataset after 1073 epochs is = 0.09189816577424054\n",
      "Initial Cost on Val dataset for this epoch 1073 = 0.09189816577424054\n",
      "learning rate for this epoch =  0.08736149830393418\n",
      "Error on this batch = 0.0392329103820071\n",
      "Error on this batch = 0.0686426760931333\n",
      "Cost on val dataset after 1074 epochs is = 0.09188803865357924\n",
      "Initial Cost on Val dataset for this epoch 1074 = 0.09188803865357924\n",
      "learning rate for this epoch =  0.0873411556553777\n",
      "Error on this batch = 0.03921650651443701\n",
      "Error on this batch = 0.06862271862368173\n",
      "Cost on val dataset after 1075 epochs is = 0.09187792883399014\n",
      "Initial Cost on Val dataset for this epoch 1075 = 0.09187792883399014\n",
      "learning rate for this epoch =  0.087320836669321\n",
      "Error on this batch = 0.03920012659709227\n",
      "Error on this batch = 0.06860278446852776\n",
      "Cost on val dataset after 1076 epochs is = 0.09186783626950681\n",
      "Initial Cost on Val dataset for this epoch 1076 = 0.09186783626950681\n",
      "learning rate for this epoch =  0.08730054129626662\n",
      "Error on this batch = 0.03918377052023497\n",
      "Error on this batch = 0.06858287351612213\n",
      "Cost on val dataset after 1077 epochs is = 0.09185776091435384\n",
      "Initial Cost on Val dataset for this epoch 1077 = 0.09185776091435384\n",
      "learning rate for this epoch =  0.08728026948686665\n",
      "Error on this batch = 0.039167438175107885\n",
      "Error on this batch = 0.06856298565560769\n",
      "Cost on val dataset after 1078 epochs is = 0.09184770272294707\n",
      "Initial Cost on Val dataset for this epoch 1078 = 0.09184770272294707\n",
      "learning rate for this epoch =  0.0872600211919219\n",
      "Error on this batch = 0.03915112945393158\n",
      "Error on this batch = 0.06854312077681753\n",
      "Cost on val dataset after 1079 epochs is = 0.09183766164989389\n",
      "Initial Cost on Val dataset for this epoch 1079 = 0.09183766164989389\n",
      "learning rate for this epoch =  0.08723979636238147\n",
      "Error on this batch = 0.03913484424990114\n",
      "Error on this batch = 0.06852327877027332\n",
      "Cost on val dataset after 1080 epochs is = 0.09182763764999353\n",
      "Initial Cost on Val dataset for this epoch 1080 = 0.09182763764999353\n",
      "learning rate for this epoch =  0.08721959494934213\n",
      "Error on this batch = 0.039118582457183075\n",
      "Error on this batch = 0.06850345952718355\n",
      "Cost on val dataset after 1081 epochs is = 0.09181763067823714\n",
      "Initial Cost on Val dataset for this epoch 1081 = 0.09181763067823714\n",
      "learning rate for this epoch =  0.0871994169040477\n",
      "Error on this batch = 0.03910234397091168\n",
      "Error on this batch = 0.06848366293944164\n",
      "Cost on val dataset after 1082 epochs is = 0.09180764068980819\n",
      "Initial Cost on Val dataset for this epoch 1082 = 0.09180764068980819\n",
      "learning rate for this epoch =  0.08717926217788849\n",
      "Error on this batch = 0.03908612868718576\n",
      "Error on this batch = 0.06846388889962417\n",
      "Cost on val dataset after 1083 epochs is = 0.09179766764008249\n",
      "Initial Cost on Val dataset for this epoch 1083 = 0.09179766764008249\n",
      "learning rate for this epoch =  0.0871591307224008\n",
      "Error on this batch = 0.039069936503064756\n",
      "Error on this batch = 0.06844413730098886\n",
      "Cost on val dataset after 1084 epochs is = 0.0917877114846284\n",
      "Initial Cost on Val dataset for this epoch 1084 = 0.0917877114846284\n",
      "learning rate for this epoch =  0.08713902248926618\n",
      "Error on this batch = 0.03905376731656503\n",
      "Error on this batch = 0.06842440803747285\n",
      "Cost on val dataset after 1085 epochs is = 0.09177777217920703\n",
      "Initial Cost on Val dataset for this epoch 1085 = 0.09177777217920703\n",
      "learning rate for this epoch =  0.08711893743031107\n",
      "Error on this batch = 0.03903762102665602\n",
      "Error on this batch = 0.0684047010036905\n",
      "Cost on val dataset after 1086 epochs is = 0.09176784967977222\n",
      "Initial Cost on Val dataset for this epoch 1086 = 0.09176784967977222\n",
      "learning rate for this epoch =  0.08709887549750603\n",
      "Error on this batch = 0.03902149753325613\n",
      "Error on this batch = 0.0683850160949316\n",
      "Cost on val dataset after 1087 epochs is = 0.09175794394247079\n",
      "Initial Cost on Val dataset for this epoch 1087 = 0.09175794394247079\n",
      "learning rate for this epoch =  0.08707883664296534\n",
      "Error on this batch = 0.03900539673722848\n",
      "Error on this batch = 0.06836535320715921\n",
      "Cost on val dataset after 1088 epochs is = 0.09174805492364238\n",
      "Initial Cost on Val dataset for this epoch 1088 = 0.09174805492364238\n",
      "learning rate for this epoch =  0.08705882081894635\n",
      "Error on this batch = 0.03898931854037685\n",
      "Error on this batch = 0.06834571223700775\n",
      "Cost on val dataset after 1089 epochs is = 0.0917381825798197\n",
      "Initial Cost on Val dataset for this epoch 1089 = 0.0917381825798197\n",
      "learning rate for this epoch =  0.08703882797784893\n",
      "Error on this batch = 0.038973262845441135\n",
      "Error on this batch = 0.06832609308178075\n",
      "Cost on val dataset after 1090 epochs is = 0.09172832686772843\n",
      "Initial Cost on Val dataset for this epoch 1090 = 0.09172832686772843\n",
      "learning rate for this epoch =  0.08701885807221492\n",
      "Error on this batch = 0.038957229556092876\n",
      "Error on this batch = 0.06830649563944881\n",
      "Cost on val dataset after 1091 epochs is = 0.09171848774428724\n",
      "cost initial= 0.09172832686772843 , cost final=0.09171848774428724 , change in cost= -9.839123441185427e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 50 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 1091\n",
      "The training time = 146.514sec\n",
      "The training accuracy is = 93.937%\n",
      "The validation accuracy is = 89.436%\n",
      "The test accuracy is = 87.969%\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Training the network with 1 hidden layer with 100 units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.370728911030039\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 3.363770892805095\n",
      "Error on this batch = 0.48067879758586357\n",
      "Cost on val dataset after 2 epochs is = 0.4802318170924747\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4802318170924747\n",
      "learning rate for this epoch =  0.4204482076268573\n",
      "Error on this batch = 0.479842758856616\n",
      "Error on this batch = 0.47966407883254564\n",
      "Cost on val dataset after 3 epochs is = 0.47927062800767084\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47927062800767084\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.47884417322346323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4787282769517532\n",
      "Cost on val dataset after 4 epochs is = 0.47824564889975324\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.47824564889975324\n",
      "learning rate for this epoch =  0.35355339059327373\n",
      "Error on this batch = 0.4777848800488793\n",
      "Error on this batch = 0.47770924976589857\n",
      "Cost on val dataset after 5 epochs is = 0.47709144120701924\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.47709144120701924\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.4765945876337596\n",
      "Error on this batch = 0.4765494042482638\n",
      "Cost on val dataset after 6 epochs is = 0.4757397611061292\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4757397611061292\n",
      "learning rate for this epoch =  0.3194715521231362\n",
      "Error on this batch = 0.475199805630595\n",
      "Error on this batch = 0.4751879256101107\n",
      "Cost on val dataset after 7 epochs is = 0.47410113223493877\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.47410113223493877\n",
      "learning rate for this epoch =  0.3073940764756322\n",
      "Error on this batch = 0.4735058211038954\n",
      "Error on this batch = 0.4735499116307421\n",
      "Cost on val dataset after 8 epochs is = 0.472047399083848\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.472047399083848\n",
      "learning rate for this epoch =  0.29730177875068026\n",
      "Error on this batch = 0.4713778960238949\n",
      "Error on this batch = 0.4715369478113701\n",
      "Cost on val dataset after 9 epochs is = 0.4693869837272503\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4693869837272503\n",
      "learning rate for this epoch =  0.2886751345948129\n",
      "Error on this batch = 0.46861618865571253\n",
      "Error on this batch = 0.4690117439247193\n",
      "Cost on val dataset after 10 epochs is = 0.46584126588197455\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.46584126588197455\n",
      "learning rate for this epoch =  0.28117066259517454\n",
      "Error on this batch = 0.46493235476781425\n",
      "Error on this batch = 0.4657681639211792\n",
      "Cost on val dataset after 11 epochs is = 0.4610741375666753\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4610741375666753\n",
      "learning rate for this epoch =  0.2745502433880562\n",
      "Error on this batch = 0.4599783433030107\n",
      "Error on this batch = 0.4615071146151465\n",
      "Cost on val dataset after 12 epochs is = 0.45482226446235235\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.45482226446235235\n",
      "learning rate for this epoch =  0.2686424829558855\n",
      "Error on this batch = 0.45348764352657017\n",
      "Error on this batch = 0.45590628181357146\n",
      "Cost on val dataset after 13 epochs is = 0.4469406097375683\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4469406097375683\n",
      "learning rate for this epoch =  0.2633201939239633\n",
      "Error on this batch = 0.4453773444099979\n",
      "Error on this batch = 0.44874959220882693\n",
      "Cost on val dataset after 14 epochs is = 0.43739331089450806\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.43739331089450806\n",
      "learning rate for this epoch =  0.2584865769785853\n",
      "Error on this batch = 0.4357808341994803\n",
      "Error on this batch = 0.440053193384169\n",
      "Cost on val dataset after 15 epochs is = 0.4265749950714816\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4265749950714816\n",
      "learning rate for this epoch =  0.25406637407730737\n",
      "Error on this batch = 0.42525810295305483\n",
      "Error on this batch = 0.4302420203988283\n",
      "Cost on val dataset after 16 epochs is = 0.4152972452295895\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4152972452295895\n",
      "learning rate for this epoch =  0.25\n",
      "Error on this batch = 0.4146149133937853\n",
      "Error on this batch = 0.42002080164665173\n",
      "Cost on val dataset after 17 epochs is = 0.40425965620782445\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.40425965620782445\n",
      "learning rate for this epoch =  0.24623953025272619\n",
      "Error on this batch = 0.4043986797227748\n",
      "Error on this batch = 0.40998380575070115\n",
      "Cost on val dataset after 18 epochs is = 0.393740234901034\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.393740234901034\n",
      "learning rate for this epoch =  0.24274588585366172\n",
      "Error on this batch = 0.3947039063516128\n",
      "Error on this batch = 0.40039816421656016\n",
      "Cost on val dataset after 19 epochs is = 0.3836835866058639\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.3836835866058639\n",
      "learning rate for this epoch =  0.23948681272178735\n",
      "Error on this batch = 0.3853212415768353\n",
      "Error on this batch = 0.3912893586469578\n",
      "Cost on val dataset after 20 epochs is = 0.37393747235826674\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.37393747235826674\n",
      "learning rate for this epoch =  0.23643540225079396\n",
      "Error on this batch = 0.3759856531087897\n",
      "Error on this batch = 0.3825847027260326\n",
      "Cost on val dataset after 21 epochs is = 0.36438027073349943\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.36438027073349943\n",
      "learning rate for this epoch =  0.23356898886410005\n",
      "Error on this batch = 0.3665046109085726\n",
      "Error on this batch = 0.37418289510517455\n",
      "Cost on val dataset after 22 epochs is = 0.35495362451780443\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.35495362451780443\n",
      "learning rate for this epoch =  0.2308683154720513\n",
      "Error on this batch = 0.3567920924227019\n",
      "Error on this batch = 0.3659856073609785\n",
      "Cost on val dataset after 23 epochs is = 0.34566377928052405\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.34566377928052405\n",
      "learning rate for this epoch =  0.22831689274836564\n",
      "Error on this batch = 0.34686698693594586\n",
      "Error on this batch = 0.3579210361739119\n",
      "Cost on val dataset after 24 epochs is = 0.3365657723287254\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.3365657723287254\n",
      "learning rate for this epoch =  0.22590050090246122\n",
      "Error on this batch = 0.3368280127850001\n",
      "Error on this batch = 0.34995602893543265\n",
      "Cost on val dataset after 25 epochs is = 0.3277319457748633\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.3277319457748633\n",
      "learning rate for this epoch =  0.22360679774997896\n",
      "Error on this batch = 0.32681021986570585\n",
      "Error on this batch = 0.3420911988178588\n",
      "Cost on val dataset after 26 epochs is = 0.319221293095659\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.319221293095659\n",
      "learning rate for this epoch =  0.2214250071345737\n",
      "Error on this batch = 0.3169440827488775\n",
      "Error on this batch = 0.3343467417398063\n",
      "Cost on val dataset after 27 epochs is = 0.3110664800190103\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.3110664800190103\n",
      "learning rate for this epoch =  0.21934566882541542\n",
      "Error on this batch = 0.30733452695148333\n",
      "Error on this batch = 0.3267504027338844\n",
      "Cost on val dataset after 28 epochs is = 0.30327769997832726\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.30327769997832726\n",
      "learning rate for this epoch =  0.2173604359724957\n",
      "Error on this batch = 0.298057844652173\n",
      "Error on this batch = 0.31933171170904606\n",
      "Cost on val dataset after 29 epochs is = 0.2958524139334724\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.2958524139334724\n",
      "learning rate for this epoch =  0.215461909729453\n",
      "Error on this batch = 0.2891658948466859\n",
      "Error on this batch = 0.3121202679413458\n",
      "Cost on val dataset after 30 epochs is = 0.28878319811616293\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.28878319811616293\n",
      "learning rate for this epoch =  0.21364350319811704\n",
      "Error on this batch = 0.2806907946506973\n",
      "Error on this batch = 0.3051449469785089\n",
      "Cost on val dataset after 31 epochs is = 0.2820617564386109\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.2820617564386109\n",
      "learning rate for this epoch =  0.21189932870751083\n",
      "Error on this batch = 0.2726484221031019\n",
      "Error on this batch = 0.29843252985834207\n",
      "Cost on val dataset after 32 epochs is = 0.27567999902652063\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.27567999902652063\n",
      "learning rate for this epoch =  0.21022410381342865\n",
      "Error on this batch = 0.2650412436901205\n",
      "Error on this batch = 0.2920057466392179\n",
      "Cost on val dataset after 33 epochs is = 0.2696296162276538\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.2696296162276538\n",
      "learning rate for this epoch =  0.2086130724305753\n",
      "Error on this batch = 0.25786120047370126\n",
      "Error on this batch = 0.28588140981588395\n",
      "Cost on val dataset after 34 epochs is = 0.26390128880955344\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.26390128880955344\n",
      "learning rate for this epoch =  0.20706193828327601\n",
      "Error on this batch = 0.25109288372398103\n",
      "Error on this batch = 0.28006930346818865\n",
      "Cost on val dataset after 35 epochs is = 0.2584841846335774\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.2584841846335774\n",
      "learning rate for this epoch =  0.20556680845025985\n",
      "Error on this batch = 0.2447167006674939\n",
      "Error on this batch = 0.27457209132402977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 36 epochs is = 0.2533659223580663\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.2533659223580663\n",
      "learning rate for this epoch =  0.20412414523193154\n",
      "Error on this batch = 0.238711536932313\n",
      "Error on this batch = 0.2693860788508927\n",
      "Cost on val dataset after 37 epochs is = 0.2485328835588622\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.2485328835588622\n",
      "learning rate for this epoch =  0.2027307249193849\n",
      "Error on this batch = 0.233056573570794\n",
      "Error on this batch = 0.26450245283255475\n",
      "Cost on val dataset after 38 epochs is = 0.24397066476137078\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.24397066476137078\n",
      "learning rate for this epoch =  0.20138360231828867\n",
      "Error on this batch = 0.2277322009504202\n",
      "Error on this batch = 0.2599086389855709\n",
      "Cost on val dataset after 39 epochs is = 0.23966450807873055\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.23966450807873055\n",
      "learning rate for this epoch =  0.20008008009612496\n",
      "Error on this batch = 0.22272020204683793\n",
      "Error on this batch = 0.2555895469859843\n",
      "Cost on val dataset after 40 epochs is = 0.23559963649044724\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.23559963649044724\n",
      "learning rate for this epoch =  0.19881768219176266\n",
      "Error on this batch = 0.2180034867206912\n",
      "Error on this batch = 0.25152860393262527\n",
      "Cost on val dataset after 41 epochs is = 0.23176148730197074\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.23176148730197074\n",
      "learning rate for this epoch =  0.19759413066220238\n",
      "Error on this batch = 0.2135656584910171\n",
      "Error on this batch = 0.24770856345532838\n",
      "Cost on val dataset after 42 epochs is = 0.2281358687021009\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.2281358687021009\n",
      "learning rate for this epoch =  0.1964073254502565\n",
      "Error on this batch = 0.2093906248182994\n",
      "Error on this batch = 0.24411211675173344\n",
      "Cost on val dataset after 43 epochs is = 0.22470906815490901\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.22470906815490901\n",
      "learning rate for this epoch =  0.19525532664475806\n",
      "Error on this batch = 0.2054623636737709\n",
      "Error on this batch = 0.24072234083348043\n",
      "Cost on val dataset after 44 epochs is = 0.22146793252709576\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.22146793252709576\n",
      "learning rate for this epoch =  0.19413633887611162\n",
      "Error on this batch = 0.20176486974366484\n",
      "Error on this batch = 0.23752301542367732\n",
      "Cost on val dataset after 45 epochs is = 0.218399929544623\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.218399929544623\n",
      "learning rate for this epoch =  0.19304869754804485\n",
      "Error on this batch = 0.19828224477354894\n",
      "Error on this batch = 0.23449883377504338\n",
      "Cost on val dataset after 46 epochs is = 0.21549319341035916\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.21549319341035916\n",
      "learning rate for this epoch =  0.19199085665396748\n",
      "Error on this batch = 0.1949988723626575\n",
      "Error on this batch = 0.23163552811545324\n",
      "Cost on val dataset after 47 epochs is = 0.21273655470051608\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.21273655470051608\n",
      "learning rate for this epoch =  0.1909613779654767\n",
      "Error on this batch = 0.1918996194225195\n",
      "Error on this batch = 0.22891992767979644\n",
      "Cost on val dataset after 48 epochs is = 0.2101195545592473\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.2101195545592473\n",
      "learning rate for this epoch =  0.18995892141289814\n",
      "Error on this batch = 0.1889700218527882\n",
      "Error on this batch = 0.22633996539291734\n",
      "Cost on val dataset after 49 epochs is = 0.2076324441519232\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.2076324441519232\n",
      "learning rate for this epoch =  0.1889822365046136\n",
      "Error on this batch = 0.18619643030624616\n",
      "Error on this batch = 0.22388464743442554\n",
      "Cost on val dataset after 50 epochs is = 0.20526617131036312\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.20526617131036312\n",
      "learning rate for this epoch =  0.1880301546543197\n",
      "Error on this batch = 0.18356610725273537\n",
      "Error on this batch = 0.2215439978410836\n",
      "Cost on val dataset after 51 epochs is = 0.2030123568905061\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.2030123568905061\n",
      "learning rate for this epoch =  0.18710158230410626\n",
      "Error on this batch = 0.1810672768609169\n",
      "Error on this batch = 0.2193089880400556\n",
      "Cost on val dataset after 52 epochs is = 0.20086326351768255\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.20086326351768255\n",
      "learning rate for this epoch =  0.1861954947469912\n",
      "Error on this batch = 0.1786891347907742\n",
      "Error on this batch = 0.21717145894904896\n",
      "Cost on val dataset after 53 epochs is = 0.19881175922765884\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.19881175922765884\n",
      "learning rate for this epoch =  0.18531093056582568\n",
      "Error on this batch = 0.17642182706601856\n",
      "Error on this batch = 0.21512404121290496\n",
      "Cost on val dataset after 54 epochs is = 0.1968512781628266\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.1968512781628266\n",
      "learning rate for this epoch =  0.18444698661672027\n",
      "Error on this batch = 0.17425640710638055\n",
      "Error on this batch = 0.21316007738864298\n",
      "Cost on val dataset after 55 epochs is = 0.19497578006571661\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.19497578006571661\n",
      "learning rate for this epoch =  0.1836028134946796\n",
      "Error on this batch = 0.1721847788036391\n",
      "Error on this batch = 0.2112735484871849\n",
      "Cost on val dataset after 56 epochs is = 0.1931797099005366\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.1931797099005366\n",
      "learning rate for this epoch =  0.18277761142725618\n",
      "Error on this batch = 0.17019963192865534\n",
      "Error on this batch = 0.20945900621960145\n",
      "Cost on val dataset after 57 epochs is = 0.19145795856772718\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.19145795856772718\n",
      "learning rate for this epoch =  0.18197062654897384\n",
      "Error on this batch = 0.1682943745672349\n",
      "Error on this batch = 0.2077115115360176\n",
      "Cost on val dataset after 58 epochs is = 0.1898058253727849\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.1898058253727849\n",
      "learning rate for this epoch =  0.1811811475152165\n",
      "Error on this batch = 0.16646306589749146\n",
      "Error on this batch = 0.20602657953022377\n",
      "Cost on val dataset after 59 epochs is = 0.18821898267033874\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.18821898267033874\n",
      "learning rate for this epoch =  0.180408502419387\n",
      "Error on this batch = 0.16470035150780177\n",
      "Error on this batch = 0.2044001304558344\n",
      "Cost on val dataset after 60 epochs is = 0.18669344292148193\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.18669344292148193\n",
      "learning rate for this epoch =  0.17965205598154213\n",
      "Error on this batch = 0.1630014026089211\n",
      "Error on this batch = 0.20282844641012696\n",
      "Cost on val dataset after 61 epochs is = 0.18522552826723243\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.18522552826723243\n",
      "learning rate for this epoch =  0.1789112069805131\n",
      "Error on this batch = 0.16136185988028953\n",
      "Error on this batch = 0.2013081331482607\n",
      "Cost on val dataset after 62 epochs is = 0.18381184262384548\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.18381184262384548\n",
      "learning rate for this epoch =  0.1781853859048144\n",
      "Error on this batch = 0.15977778226269948\n",
      "Error on this batch = 0.19983608646165668\n",
      "Cost on val dataset after 63 epochs is = 0.18244924623762604\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.18244924623762604\n",
      "learning rate for this epoch =  0.17747405280050266\n",
      "Error on this batch = 0.15824560072240548\n",
      "Error on this batch = 0.19840946256652117\n",
      "Cost on val dataset after 64 epochs is = 0.1811348325905737\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.1811348325905737\n",
      "learning rate for this epoch =  0.17677669529663687\n",
      "Error on this batch = 0.15676207682713372\n",
      "Error on this batch = 0.1970256519852165\n",
      "Cost on val dataset after 65 epochs is = 0.1798659075180016\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.1798659075180016\n",
      "learning rate for this epoch =  0.1760928267911618\n",
      "Error on this batch = 0.15532426586203213\n",
      "Error on this batch = 0.19568225645296497\n",
      "Cost on val dataset after 66 epochs is = 0.1786399703810307\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.1786399703810307\n",
      "learning rate for this epoch =  0.17542198478193427\n",
      "Error on this batch = 0.1539294841507801\n",
      "Error on this batch = 0.19437706843753105\n",
      "Cost on val dataset after 67 epochs is = 0.17745469712755943\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.17745469712755943\n",
      "learning rate for this epoch =  0.1747637293292756\n",
      "Error on this batch = 0.15257528021763386\n",
      "Error on this batch = 0.19310805291501582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 68 epochs is = 0.17630792507276774\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.17630792507276774\n",
      "learning rate for this epoch =  0.1741176416378927\n",
      "Error on this batch = 0.15125940941885968\n",
      "Error on this batch = 0.19187333109752353\n",
      "Cost on val dataset after 69 epochs is = 0.17519763923279572\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.17519763923279572\n",
      "learning rate for this epoch =  0.1734833227472955\n",
      "Error on this batch = 0.14997981167913602\n",
      "Error on this batch = 0.190671165856325\n",
      "Cost on val dataset after 70 epochs is = 0.17412196005168065\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.17412196005168065\n",
      "learning rate for this epoch =  0.1728603923209705\n",
      "Error on this batch = 0.1487345919849273\n",
      "Error on this batch = 0.18949994862623581\n",
      "Cost on val dataset after 71 epochs is = 0.17307913237087885\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.17307913237087885\n",
      "learning rate for this epoch =  0.17224848752556968\n",
      "Error on this batch = 0.14752200330904133\n",
      "Error on this batch = 0.18835818761290476\n",
      "Cost on val dataset after 72 epochs is = 0.1720675155018553\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.1720675155018553\n",
      "learning rate for this epoch =  0.17164726199225983\n",
      "Error on this batch = 0.1463404316661608\n",
      "Error on this batch = 0.18724449715467195\n",
      "Cost on val dataset after 73 epochs is = 0.17108557427451276\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.17108557427451276\n",
      "learning rate for this epoch =  0.17105638485316074\n",
      "Error on this batch = 0.14518838302637244\n",
      "Error on this batch = 0.18615758811502758\n",
      "Cost on val dataset after 74 epochs is = 0.1701318709470048\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.1701318709470048\n",
      "learning rate for this epoch =  0.1704755398464977\n",
      "Error on this batch = 0.14406447184135052\n",
      "Error on this batch = 0.18509625920110848\n",
      "Cost on val dataset after 75 epochs is = 0.16920505787518125\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.16920505787518125\n",
      "learning rate for this epoch =  0.16990442448471224\n",
      "Error on this batch = 0.14296741096496848\n",
      "Error on this batch = 0.1840593891188428\n",
      "Cost on val dataset after 76 epochs is = 0.16830387085213075\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.16830387085213075\n",
      "learning rate for this epoch =  0.16934274928032858\n",
      "Error on this batch = 0.14189600277603892\n",
      "Error on this batch = 0.18304592948705994\n",
      "Cost on val dataset after 77 epochs is = 0.1674271230397038\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.1674271230397038\n",
      "learning rate for this epoch =  0.16879023702486318\n",
      "Error on this batch = 0.14084913133515245\n",
      "Error on this batch = 0.18205489844185815\n",
      "Cost on val dataset after 78 epochs is = 0.16657369942431405\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.16657369942431405\n",
      "learning rate for this epoch =  0.16824662211650757\n",
      "Error on this batch = 0.13982575542989717\n",
      "Error on this batch = 0.18108537486943185\n",
      "Cost on val dataset after 79 epochs is = 0.16574255173861935\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.16574255173861935\n",
      "learning rate for this epoch =  0.1677116499327062\n",
      "Error on this batch = 0.13882490238293485\n",
      "Error on this batch = 0.18013649321098243\n",
      "Cost on val dataset after 80 epochs is = 0.16493269379884856\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.16493269379884856\n",
      "learning rate for this epoch =  0.1671850762441055\n",
      "Error on this batch = 0.13784566251543967\n",
      "Error on this batch = 0.1792074387877264\n",
      "Cost on val dataset after 81 epochs is = 0.16414319721458925\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.16414319721458925\n",
      "learning rate for this epoch =  0.16666666666666666\n",
      "Error on this batch = 0.13688718417431506\n",
      "Error on this batch = 0.17829744359773603\n",
      "Cost on val dataset after 82 epochs is = 0.16337318743386484\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.16337318743386484\n",
      "learning rate for this epoch =  0.16615619614902008\n",
      "Error on this batch = 0.13594866924549687\n",
      "Error on this batch = 0.17740578253966324\n",
      "Cost on val dataset after 83 epochs is = 0.16262184009140274\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.16262184009140274\n",
      "learning rate for this epoch =  0.16565344849239508\n",
      "Error on this batch = 0.1350293690876767\n",
      "Error on this batch = 0.17653177002147988\n",
      "Cost on val dataset after 84 epochs is = 0.16188837763224057\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.16188837763224057\n",
      "learning rate for this epoch =  0.16515821590069035\n",
      "Error on this batch = 0.1341285808311091\n",
      "Error on this batch = 0.17567475691532378\n",
      "Cost on val dataset after 85 epochs is = 0.1611720661863528\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.1611720661863528\n",
      "learning rate for this epoch =  0.164670298558459\n",
      "Error on this batch = 0.13324564399498\n",
      "Error on this batch = 0.17483412782243624\n",
      "Cost on val dataset after 86 epochs is = 0.1604722126729211\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.1604722126729211\n",
      "learning rate for this epoch =  0.16418950423477013\n",
      "Error on this batch = 0.1323799373842913\n",
      "Error on this batch = 0.17400929861502193\n",
      "Cost on val dataset after 87 epochs is = 0.1597881621153106\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.1597881621153106\n",
      "learning rate for this epoch =  0.16371564791108048\n",
      "Error on this batch = 0.13153087623352774\n",
      "Error on this batch = 0.17319971422465957\n",
      "Cost on val dataset after 88 epochs is = 0.1591192951498562\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.1591192951498562\n",
      "learning rate for this epoch =  0.16324855143140263\n",
      "Error on this batch = 0.13069790956967392\n",
      "Error on this batch = 0.17240484664962175\n",
      "Cost on val dataset after 89 epochs is = 0.1584650257132713\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1584650257132713\n",
      "learning rate for this epoch =  0.1627880431731981\n",
      "Error on this batch = 0.12988051777158102\n",
      "Error on this batch = 0.17162419315609945\n",
      "Cost on val dataset after 90 epochs is = 0.1578247988949438\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.1578247988949438\n",
      "learning rate for this epoch =  0.16233395773754944\n",
      "Error on this batch = 0.12907821030637406\n",
      "Error on this batch = 0.1708572746508513\n",
      "Cost on val dataset after 91 epochs is = 0.15719808894162335\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.15719808894162335\n",
      "learning rate for this epoch =  0.16188613565728216\n",
      "Error on this batch = 0.12829052362664567\n",
      "Error on this batch = 0.17010363420517977\n",
      "Cost on val dataset after 92 epochs is = 0.15658439740307936\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.15658439740307936\n",
      "learning rate for this epoch =  0.161444423121811\n",
      "Error on this batch = 0.12751701921470165\n",
      "Error on this batch = 0.1693628357123677\n",
      "Cost on val dataset after 93 epochs is = 0.15598325140825237\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.15598325140825237\n",
      "learning rate for this epoch =  0.16100867171758368\n",
      "Error on this batch = 0.12675728176218726\n",
      "Error on this batch = 0.16863446266277204\n",
      "Cost on val dataset after 94 epochs is = 0.15539420206225524\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.15539420206225524\n",
      "learning rate for this epoch =  0.160578738183079\n",
      "Error on this batch = 0.12601091747510348\n",
      "Error on this batch = 0.16791811702266066\n",
      "Cost on val dataset after 95 epochs is = 0.1548168229553294\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.1548168229553294\n",
      "learning rate for this epoch =  0.16015448417739933\n",
      "Error on this batch = 0.1252775524955818\n",
      "Error on this batch = 0.1672134182045961\n",
      "Cost on val dataset after 96 epochs is = 0.15425070877554056\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.15425070877554056\n",
      "learning rate for this epoch =  0.1597357760615681\n",
      "Error on this batch = 0.12455683143287619\n",
      "Error on this batch = 0.1665200021187146\n",
      "Cost on val dataset after 97 epochs is = 0.153695474017613\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.153695474017613\n",
      "learning rate for this epoch =  0.15932248469171095\n",
      "Error on this batch = 0.12384841599690093\n",
      "Error on this batch = 0.16583752029562845\n",
      "Cost on val dataset after 98 epochs is = 0.15315075178086737\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.15315075178086737\n",
      "learning rate for this epoch =  0.15891448522335927\n",
      "Error on this batch = 0.1231519837283273\n",
      "Error on this batch = 0.1651656390729049\n",
      "Cost on val dataset after 99 epochs is = 0.15261619264975096\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.15261619264975096\n",
      "learning rate for this epoch =  0.15851165692617153\n",
      "Error on this batch = 0.12246722681979189\n",
      "Error on this batch = 0.1645040388381536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 100 epochs is = 0.1520914636509267\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.1520914636509267\n",
      "learning rate for this epoch =  0.15811388300841897\n",
      "Error on this batch = 0.12179385102318711\n",
      "Error on this batch = 0.16385241332269865\n",
      "Cost on val dataset after 101 epochs is = 0.15157624728133715\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.15157624728133715\n",
      "learning rate for this epoch =  0.1577210504506286\n",
      "Error on this batch = 0.12113157463833028\n",
      "Error on this batch = 0.16321046894063387\n",
      "Cost on val dataset after 102 epochs is = 0.15107024060206975\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.15107024060206975\n",
      "learning rate for this epoch =  0.1573330498478208\n",
      "Error on this batch = 0.12048012757855965\n",
      "Error on this batch = 0.1625779241687749\n",
      "Cost on val dataset after 103 epochs is = 0.1505731543932366\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.1505731543932366\n",
      "learning rate for this epoch =  0.15694977525981785\n",
      "Error on this batch = 0.11983925050900403\n",
      "Error on this batch = 0.1619545089636327\n",
      "Cost on val dataset after 104 epochs is = 0.15008471236543644\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.15008471236543644\n",
      "learning rate for this epoch =  0.15657112406913673\n",
      "Error on this batch = 0.11920869405342979\n",
      "Error on this batch = 0.16133996421206453\n",
      "Cost on val dataset after 105 epochs is = 0.14960465042369664\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.14960465042369664\n",
      "learning rate for this epoch =  0.1561969968460128\n",
      "Error on this batch = 0.11858821806569977\n",
      "Error on this batch = 0.16073404121270685\n",
      "Cost on val dataset after 106 epochs is = 0.14913271598010236\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.14913271598010236\n",
      "learning rate for this epoch =  0.15582729722013278\n",
      "Error on this batch = 0.11797759096199081\n",
      "Error on this batch = 0.1601365011856797\n",
      "Cost on val dataset after 107 epochs is = 0.1486686673116011\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.1486686673116011\n",
      "learning rate for this epoch =  0.15546193175868359\n",
      "Error on this batch = 0.1173765891100185\n",
      "Error on this batch = 0.15954711480837927\n",
      "Cost on val dataset after 108 epochs is = 0.1482122729597372\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.1482122729597372\n",
      "learning rate for this epoch =  0.15510080985034994\n",
      "Error on this batch = 0.11678499627161688\n",
      "Error on this batch = 0.15896566177544905\n",
      "Cost on val dataset after 109 epochs is = 0.14776331116931332\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.14776331116931332\n",
      "learning rate for this epoch =  0.1547438435949191\n",
      "Error on this batch = 0.11620260309511864\n",
      "Error on this batch = 0.15839193038125568\n",
      "Cost on val dataset after 110 epochs is = 0.14732156936320226\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.14732156936320226\n",
      "learning rate for this epoch =  0.1543909476981724\n",
      "Error on this batch = 0.11562920665408397\n",
      "Error on this batch = 0.1578257171233903\n",
      "Cost on val dataset after 111 epochs is = 0.1468868436507419\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.1468868436507419\n",
      "learning rate for this epoch =  0.15404203937176525\n",
      "Error on this batch = 0.11506461002903452\n",
      "Error on this batch = 0.15726682632588193\n",
      "Cost on val dataset after 112 epochs is = 0.14645893836733784\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.14645893836733784\n",
      "learning rate for this epoch =  0.1536970382378161\n",
      "Error on this batch = 0.11450862192896243\n",
      "Error on this batch = 0.15671506978094812\n",
      "Cost on val dataset after 113 epochs is = 0.14603766564307855\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.14603766564307855\n",
      "learning rate for this epoch =  0.15335586623794323\n",
      "Error on this batch = 0.11396105634950583\n",
      "Error on this batch = 0.15617026640822623\n",
      "Cost on val dataset after 114 epochs is = 0.14562284499833092\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.14562284499833092\n",
      "learning rate for this epoch =  0.1530184475465045\n",
      "Error on this batch = 0.11342173226481234\n",
      "Error on this batch = 0.15563224193052505\n",
      "Cost on val dataset after 115 epochs is = 0.1452143029644364\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.1452143029644364\n",
      "learning rate for this epoch =  0.15268470848781107\n",
      "Error on this batch = 0.11289047335024321\n",
      "Error on this batch = 0.15510082856522175\n",
      "Cost on val dataset after 116 epochs is = 0.14481187272777044\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.14481187272777044\n",
      "learning rate for this epoch =  0.1523545774571\n",
      "Error on this batch = 0.11236710773321404\n",
      "Error on this batch = 0.15457586473049786\n",
      "Cost on val dataset after 117 epochs is = 0.14441539379555318\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.14441539379555318\n",
      "learning rate for this epoch =  0.15202798484506466\n",
      "Error on this batch = 0.11185146776960853\n",
      "Error on this batch = 0.15405719476567029\n",
      "Cost on val dataset after 118 epochs is = 0.14402471168192305\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.14402471168192305\n",
      "learning rate for this epoch =  0.15170486296575364\n",
      "Error on this batch = 0.11134338984335092\n",
      "Error on this batch = 0.15354466866492142\n",
      "Cost on val dataset after 119 epochs is = 0.14363967761289215\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.14363967761289215\n",
      "learning rate for this epoch =  0.1513851459876605\n",
      "Error on this batch = 0.11084271418686895\n",
      "Error on this batch = 0.1530381418237815\n",
      "Cost on val dataset after 120 epochs is = 0.1432601482489054\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.1432601482489054\n",
      "learning rate for this epoch =  0.1510687698678384\n",
      "Error on this batch = 0.11034928472032768\n",
      "Error on this batch = 0.15253747479775046\n",
      "Cost on val dataset after 121 epochs is = 0.1428859854238178\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.1428859854238178\n",
      "learning rate for this epoch =  0.15075567228888181\n",
      "Error on this batch = 0.10986294890766245\n",
      "Error on this batch = 0.15204253307248544\n",
      "Cost on val dataset after 122 epochs is = 0.14251705589919167\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.14251705589919167\n",
      "learning rate for this epoch =  0.1504457925986288\n",
      "Error on this batch = 0.10938355762758274\n",
      "Error on this batch = 0.15155318684500654\n",
      "Cost on val dataset after 123 epochs is = 0.14215323113289488\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.14215323113289488\n",
      "learning rate for this epoch =  0.15013907175244492\n",
      "Error on this batch = 0.10891096505786127\n",
      "Error on this batch = 0.15106931081540467\n",
      "Cost on val dataset after 124 epochs is = 0.14179438706105443\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.14179438706105443\n",
      "learning rate for this epoch =  0.1498354522579582\n",
      "Error on this batch = 0.108445028571359\n",
      "Error on this batch = 0.15059078398855685\n",
      "Cost on val dataset after 125 epochs is = 0.1414404038924879\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.1414404038924879\n",
      "learning rate for this epoch =  0.14953487812212204\n",
      "Error on this batch = 0.10798560864236954\n",
      "Error on this batch = 0.15011748948538156\n",
      "Cost on val dataset after 126 epochs is = 0.1410911659147975\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.1410911659147975\n",
      "learning rate for this epoch =  0.14923729480049114\n",
      "Error on this batch = 0.10753256876199271\n",
      "Error on this batch = 0.14964931436318393\n",
      "Cost on val dataset after 127 epochs is = 0.1407465613113697\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.1407465613113697\n",
      "learning rate for this epoch =  0.14894264914859962\n",
      "Error on this batch = 0.10708577536136783\n",
      "Error on this batch = 0.14918614944466405\n",
      "Cost on val dataset after 128 epochs is = 0.14040648198857697\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.14040648198857697\n",
      "learning rate for this epoch =  0.14865088937534013\n",
      "Error on this batch = 0.1066450977417103\n",
      "Error on this batch = 0.1487278891551791\n",
      "Cost on val dataset after 129 epochs is = 0.14007082341252647\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.14007082341252647\n",
      "learning rate for this epoch =  0.14836196499824542\n",
      "Error on this batch = 0.10621040801020364\n",
      "Error on this batch = 0.14827443136786733\n",
      "Cost on val dataset after 130 epochs is = 0.13973948445474751\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.13973948445474751\n",
      "learning rate for this epoch =  0.14807582680058123\n",
      "Error on this batch = 0.10578158102089781\n",
      "Error on this batch = 0.14782567725626167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 131 epochs is = 0.13941236724625145\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.13941236724625145\n",
      "learning rate for this epoch =  0.14779242679016388\n",
      "Error on this batch = 0.10535849431985927\n",
      "Error on this batch = 0.14738153115403305\n",
      "Cost on val dataset after 132 epochs is = 0.139089377039436\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.139089377039436\n",
      "learning rate for this epoch =  0.1475117181598202\n",
      "Error on this batch = 0.10494102809390367\n",
      "Error on this batch = 0.1469419004215231\n",
      "Cost on val dataset after 133 epochs is = 0.1387704220773431\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.1387704220773431\n",
      "learning rate for this epoch =  0.147233655249413\n",
      "Error on this batch = 0.10452906512232256\n",
      "Error on this batch = 0.1465066953187384\n",
      "Cost on val dataset after 134 epochs is = 0.13845541346981355\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.13845541346981355\n",
      "learning rate for this epoch =  0.1469581935093583\n",
      "Error on this batch = 0.10412249073108817\n",
      "Error on this batch = 0.1460758288844931\n",
      "Cost on val dataset after 135 epochs is = 0.13814426507610986\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.13814426507610986\n",
      "learning rate for this epoch =  0.14668528946556555\n",
      "Error on this batch = 0.10372119274908688\n",
      "Error on this batch = 0.14564921682140158\n",
      "Cost on val dataset after 136 epochs is = 0.13783689339361227\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.13783689339361227\n",
      "learning rate for this epoch =  0.14641490068573487\n",
      "Error on this batch = 0.10332506146599338\n",
      "Error on this batch = 0.14522677738643489\n",
      "Cost on val dataset after 137 epochs is = 0.13753321745221492\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.13753321745221492\n",
      "learning rate for this epoch =  0.14614698574694937\n",
      "Error on this batch = 0.10293398959145204\n",
      "Error on this batch = 0.14480843128676793\n",
      "Cost on val dataset after 138 epochs is = 0.13723315871407746\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.13723315871407746\n",
      "learning rate for this epoch =  0.145881504204504\n",
      "Error on this batch = 0.10254787221528154\n",
      "Error on this batch = 0.14439410158065652\n",
      "Cost on val dataset after 139 epochs is = 0.13693664097840869\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.13693664097840869\n",
      "learning rate for this epoch =  0.14561841656191457\n",
      "Error on this batch = 0.10216660676846345\n",
      "Error on this batch = 0.14398371358309525\n",
      "Cost on val dataset after 140 epochs is = 0.13664359029098103\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.13664359029098103\n",
      "learning rate for this epoch =  0.14535768424205484\n",
      "Error on this batch = 0.10179009298471516\n",
      "Error on this batch = 0.14357719477601777\n",
      "Cost on val dataset after 141 epochs is = 0.1363539348580941\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.1363539348580941\n",
      "learning rate for this epoch =  0.14509926955937089\n",
      "Error on this batch = 0.10141823286248258\n",
      "Error on this batch = 0.14317447472281322\n",
      "Cost on val dataset after 142 epochs is = 0.13606760496472486\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.13606760496472486\n",
      "learning rate for this epoch =  0.1448431356931257\n",
      "Error on this batch = 0.10105093062722009\n",
      "Error on this batch = 0.1427754849869411\n",
      "Cost on val dataset after 143 epochs is = 0.1357845328966182\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.1357845328966182\n",
      "learning rate for this epoch =  0.14458924666162856\n",
      "Error on this batch = 0.10068809269385096\n",
      "Error on this batch = 0.14238015905443893\n",
      "Cost on val dataset after 144 epochs is = 0.13550465286608923\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.13550465286608923\n",
      "learning rate for this epoch =  0.14433756729740646\n",
      "Error on this batch = 0.10032962762932819\n",
      "Error on this batch = 0.14198843226012484\n",
      "Cost on val dataset after 145 epochs is = 0.1352279009413213\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.1352279009413213\n",
      "learning rate for this epoch =  0.14408806322327672\n",
      "Error on this batch = 0.0999754461152339\n",
      "Error on this batch = 0.14160024171730765\n",
      "Cost on val dataset after 146 epochs is = 0.13495421497896062\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.13495421497896062\n",
      "learning rate for this epoch =  0.14384070082928266\n",
      "Error on this batch = 0.0996254609103755\n",
      "Error on this batch = 0.1412155262508256\n",
      "Cost on val dataset after 147 epochs is = 0.13468353455981855\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.13468353455981855\n",
      "learning rate for this epoch =  0.1435954472504545\n",
      "Error on this batch = 0.09927958681335167\n",
      "Error on this batch = 0.14083422633324325\n",
      "Cost on val dataset after 148 epochs is = 0.1344158009275065\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.1344158009275065\n",
      "learning rate for this epoch =  0.1433522703453617\n",
      "Error on this batch = 0.09893774062507422\n",
      "Error on this batch = 0.14045628402404428\n",
      "Cost on val dataset after 149 epochs is = 0.13415095692983925\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.13415095692983925\n",
      "learning rate for this epoch =  0.1431111386754225\n",
      "Error on this batch = 0.09859984111124385\n",
      "Error on this batch = 0.14008164291166617\n",
      "Cost on val dataset after 150 epochs is = 0.13388894696285203\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.13388894696285203\n",
      "learning rate for this epoch =  0.14287202148493997\n",
      "Error on this batch = 0.0982658089647862\n",
      "Error on this batch = 0.13971024805823018\n",
      "Cost on val dataset after 151 epochs is = 0.13362971691728806\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.13362971691728806\n",
      "learning rate for this epoch =  0.14263488868183333\n",
      "Error on this batch = 0.09793556676826327\n",
      "Error on this batch = 0.13934204594682714\n",
      "Cost on val dataset after 152 epochs is = 0.13337321412742142\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.13337321412742142\n",
      "learning rate for this epoch =  0.14239971081903682\n",
      "Error on this batch = 0.09760903895628062\n",
      "Error on this batch = 0.13897698443122689\n",
      "Cost on val dataset after 153 epochs is = 0.13311938732208828\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.13311938732208828\n",
      "learning rate for this epoch =  0.14216645907653844\n",
      "Error on this batch = 0.09728615177791632\n",
      "Error on this batch = 0.13861501268788584\n",
      "Cost on val dataset after 154 epochs is = 0.13286818657780866\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.13286818657780866\n",
      "learning rate for this epoch =  0.14193510524403224\n",
      "Error on this batch = 0.09696683325920129\n",
      "Error on this batch = 0.13825608117013327\n",
      "Cost on val dataset after 155 epochs is = 0.13261956327388713\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.13261956327388713\n",
      "learning rate for this epoch =  0.1417056217041599\n",
      "Error on this batch = 0.09665101316568322\n",
      "Error on this batch = 0.1379001415644241\n",
      "Cost on val dataset after 156 epochs is = 0.13237347004938838\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.13237347004938838\n",
      "learning rate for this epoch =  0.14147798141631754\n",
      "Error on this batch = 0.09633862296510852\n",
      "Error on this batch = 0.13754714674855045\n",
      "Cost on val dataset after 157 epochs is = 0.13212986076188996\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.13212986076188996\n",
      "learning rate for this epoch =  0.14125215790100537\n",
      "Error on this batch = 0.09602959579025785\n",
      "Error on this batch = 0.13719705075171085\n",
      "Cost on val dataset after 158 epochs is = 0.13188869044792\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.13188869044792\n",
      "learning rate for this epoch =  0.14102812522469854\n",
      "Error on this batch = 0.09572386640197122\n",
      "Error on this batch = 0.13684980871634186\n",
      "Cost on val dataset after 159 epochs is = 0.1316499152849945\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.1316499152849945\n",
      "learning rate for this epoch =  0.1408058579852188\n",
      "Error on this batch = 0.09542137115239914\n",
      "Error on this batch = 0.13650537686162018\n",
      "Cost on val dataset after 160 epochs is = 0.1314134925551727\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.1314134925551727\n",
      "learning rate for this epoch =  0.14058533129758727\n",
      "Error on this batch = 0.0951220479485149\n",
      "Error on this batch = 0.1361637124485506\n",
      "Cost on val dataset after 161 epochs is = 0.13117938061005446\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.13117938061005446\n",
      "learning rate for this epoch =  0.14036652078033962\n",
      "Error on this batch = 0.09482583621592339\n",
      "Error on this batch = 0.1358247737465576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 162 epochs is = 0.1309475388371484\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.1309475388371484\n",
      "learning rate for this epoch =  0.14014940254228575\n",
      "Error on this batch = 0.09453267686300006\n",
      "Error on this batch = 0.1354885200015047\n",
      "Cost on val dataset after 163 epochs is = 0.13071792762754408\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.13071792762754408\n",
      "learning rate for this epoch =  0.13993395316969692\n",
      "Error on this batch = 0.09424251224539187\n",
      "Error on this batch = 0.13515491140506847\n",
      "Cost on val dataset after 164 epochs is = 0.13049050834482376\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.13049050834482376\n",
      "learning rate for this epoch =  0.13972014971390403\n",
      "Error on this batch = 0.09395528613091166\n",
      "Error on this batch = 0.13482390906539887\n",
      "Cost on val dataset after 165 epochs is = 0.13026524329515562\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.13026524329515562\n",
      "learning rate for this epoch =  0.13950796967929133\n",
      "Error on this batch = 0.0936709436648541\n",
      "Error on this batch = 0.13449547497900122\n",
      "Cost on val dataset after 166 epochs is = 0.13004209569851155\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.13004209569851155\n",
      "learning rate for this epoch =  0.13929739101167085\n",
      "Error on this batch = 0.0933894313357608\n",
      "Error on this batch = 0.13416957200377816\n",
      "Cost on val dataset after 167 epochs is = 0.12982102966095707\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.12982102966095707\n",
      "learning rate for this epoch =  0.13908839208702292\n",
      "Error on this batch = 0.09311069694165951\n",
      "Error on this batch = 0.13384616383317435\n",
      "Cost on val dataset after 168 epochs is = 0.12960201014796363\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.12960201014796363\n",
      "learning rate for this epoch =  0.13888095170058953\n",
      "Error on this batch = 0.09283468955679997\n",
      "Error on this batch = 0.13352521497136827\n",
      "Cost on val dataset after 169 epochs is = 0.12938500295869643\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.12938500295869643\n",
      "learning rate for this epoch =  0.1386750490563073\n",
      "Error on this batch = 0.09256135949890824\n",
      "Error on this batch = 0.13320669070946026\n",
      "Cost on val dataset after 170 epochs is = 0.1291699747012336\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.1291699747012336\n",
      "learning rate for this epoch =  0.13847066375656708\n",
      "Error on this batch = 0.0922906582969777\n",
      "Error on this batch = 0.1328905571026071\n",
      "Cost on val dataset after 171 epochs is = 0.12895689276867472\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.12895689276867472\n",
      "learning rate for this epoch =  0.1382677757922894\n",
      "Error on this batch = 0.09202253865961392\n",
      "Error on this batch = 0.13257678094805708\n",
      "Cost on val dataset after 172 epochs is = 0.12874572531609974\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.12874572531609974\n",
      "learning rate for this epoch =  0.1380663655333028\n",
      "Error on this batch = 0.09175695444394834\n",
      "Error on this batch = 0.1322653297640412\n",
      "Cost on val dataset after 173 epochs is = 0.12853644123834068\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.12853644123834068\n",
      "learning rate for this epoch =  0.13786641371901512\n",
      "Error on this batch = 0.0914938606251335\n",
      "Error on this batch = 0.13195617176947938\n",
      "Cost on val dataset after 174 epochs is = 0.12832901014853085\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.12832901014853085\n",
      "learning rate for this epoch =  0.13766790144936686\n",
      "Error on this batch = 0.09123321326643152\n",
      "Error on this batch = 0.13164927586446182\n",
      "Cost on val dataset after 175 epochs is = 0.12812340235739886\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.12812340235739886\n",
      "learning rate for this epoch =  0.1374708101760565\n",
      "Error on this batch = 0.09097496948990383\n",
      "Error on this batch = 0.13134461161146793\n",
      "Cost on val dataset after 176 epochs is = 0.12791958885327528\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.12791958885327528\n",
      "learning rate for this epoch =  0.1372751216940281\n",
      "Error on this batch = 0.09071908744771104\n",
      "Error on this batch = 0.13104214921728718\n",
      "Cost on val dataset after 177 epochs is = 0.12771754128278232\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.12771754128278232\n",
      "learning rate for this epoch =  0.1370808181332119\n",
      "Error on this batch = 0.09046552629402797\n",
      "Error on this batch = 0.13074185951560854\n",
      "Cost on val dataset after 178 epochs is = 0.12751723193217826\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.12751723193217826\n",
      "learning rate for this epoch =  0.13688788195050916\n",
      "Error on this batch = 0.09021424615757809\n",
      "Error on this batch = 0.1304437139502454\n",
      "Cost on val dataset after 179 epochs is = 0.1273186337093301\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.1273186337093301\n",
      "learning rate for this epoch =  0.13669629592201246\n",
      "Error on this batch = 0.08996520811479047\n",
      "Error on this batch = 0.13014768455896622\n",
      "Cost on val dataset after 180 epochs is = 0.1271217201262884\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.1271217201262884\n",
      "learning rate for this epoch =  0.13650604313545334\n",
      "Error on this batch = 0.08971837416358046\n",
      "Error on this batch = 0.12985374395790097\n",
      "Cost on val dataset after 181 epochs is = 0.12692646528244048\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.12692646528244048\n",
      "learning rate for this epoch =  0.13631710698286975\n",
      "Error on this batch = 0.0894737071977539\n",
      "Error on this batch = 0.12956186532649627\n",
      "Cost on val dataset after 182 epochs is = 0.1267328438482193\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.1267328438482193\n",
      "learning rate for this epoch =  0.1361294711534851\n",
      "Error on this batch = 0.08923117098203381\n",
      "Error on this batch = 0.12927202239299207\n",
      "Cost on val dataset after 183 epochs is = 0.1265408310493458\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.1265408310493458\n",
      "learning rate for this epoch =  0.13594311962679215\n",
      "Error on this batch = 0.08899073012770738\n",
      "Error on this batch = 0.1289841894203949\n",
      "Cost on val dataset after 184 epochs is = 0.1263504026515837\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.1263504026515837\n",
      "learning rate for this epoch =  0.13575803666583477\n",
      "Error on this batch = 0.08875235006888943\n",
      "Error on this batch = 0.12869834119292378\n",
      "Cost on val dataset after 185 epochs is = 0.12616153494598809\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.12616153494598809\n",
      "learning rate for this epoch =  0.13557420681068058\n",
      "Error on this batch = 0.08851599703939822\n",
      "Error on this batch = 0.12841445300290533\n",
      "Cost on val dataset after 186 epochs is = 0.1259742047346279\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.1259742047346279\n",
      "learning rate for this epoch =  0.13539161487207826\n",
      "Error on this batch = 0.08828163805023827\n",
      "Error on this batch = 0.12813250063809645\n",
      "Cost on val dataset after 187 epochs is = 0.1257883893167646\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.1257883893167646\n",
      "learning rate for this epoch =  0.13521024592529318\n",
      "Error on this batch = 0.08804924086768397\n",
      "Error on this batch = 0.1278524603694135\n",
      "Cost on val dataset after 188 epochs is = 0.12560406647547068\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.12560406647547068\n",
      "learning rate for this epoch =  0.1350300853041159\n",
      "Error on this batch = 0.08781877399195694\n",
      "Error on this batch = 0.12757430893904823\n",
      "Cost on val dataset after 189 epochs is = 0.1254212144646705\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.1254212144646705\n",
      "learning rate for this epoch =  0.13485111859503687\n",
      "Error on this batch = 0.08759020663649014\n",
      "Error on this batch = 0.1272980235489508\n",
      "Cost on val dataset after 190 epochs is = 0.12523981199658915\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.12523981199658915\n",
      "learning rate for this epoch =  0.13467333163158285\n",
      "Error on this batch = 0.08736350870776988\n",
      "Error on this batch = 0.12702358184966245\n",
      "Cost on val dataset after 191 epochs is = 0.1250598382295932\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.1250598382295932\n",
      "learning rate for this epoch =  0.13449671048880912\n",
      "Error on this batch = 0.08713865078574731\n",
      "Error on this batch = 0.12675096192947993\n",
      "Cost on val dataset after 192 epochs is = 0.12488127275641034\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.12488127275641034\n",
      "learning rate for this epoch =  0.13432124147794275\n",
      "Error on this batch = 0.08691560410481029\n",
      "Error on this batch = 0.12648014230393562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 193 epochs is = 0.12470409559271328\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.12470409559271328\n",
      "learning rate for this epoch =  0.1341469111411715\n",
      "Error on this batch = 0.08669434053530578\n",
      "Error on this batch = 0.12621110190557708\n",
      "Cost on val dataset after 194 epochs is = 0.1245282871660557\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.1245282871660557\n",
      "learning rate for this epoch =  0.13397370624657456\n",
      "Error on this batch = 0.08647483256560286\n",
      "Error on this batch = 0.12594382007403188\n",
      "Cost on val dataset after 195 epochs is = 0.12435382830514706\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.12435382830514706\n",
      "learning rate for this epoch =  0.13380161378318955\n",
      "Error on this batch = 0.08625705328468598\n",
      "Error on this batch = 0.12567827654634287\n",
      "Cost on val dataset after 196 epochs is = 0.12418070022945499\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.12418070022945499\n",
      "learning rate for this epoch =  0.1336306209562122\n",
      "Error on this batch = 0.0860409763652678\n",
      "Error on this batch = 0.1254144514475604\n",
      "Cost on val dataset after 197 epochs is = 0.1240088845391234\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.1240088845391234\n",
      "learning rate for this epoch =  0.13346071518232402\n",
      "Error on this batch = 0.08582657604741087\n",
      "Error on this batch = 0.1251523252815796\n",
      "Cost on val dataset after 198 epochs is = 0.12383836320519546\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.12383836320519546\n",
      "learning rate for this epoch =  0.13329188408514428\n",
      "Error on this batch = 0.08561382712264708\n",
      "Error on this batch = 0.12489187892220985\n",
      "Cost on val dataset after 199 epochs is = 0.1236691185601309\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.1236691185601309\n",
      "learning rate for this epoch =  0.13312411549080203\n",
      "Error on this batch = 0.08540270491858351\n",
      "Error on this batch = 0.12463309360446508\n",
      "Cost on val dataset after 200 epochs is = 0.12350113328860753\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.12350113328860753\n",
      "learning rate for this epoch =  0.13295739742362472\n",
      "Error on this batch = 0.08519318528398355\n",
      "Error on this batch = 0.1243759509160647\n",
      "Cost on val dataset after 201 epochs is = 0.12333439041859741\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.12333439041859741\n",
      "learning rate for this epoch =  0.13279171810193946\n",
      "Error on this batch = 0.08498524457431202\n",
      "Error on this batch = 0.12412043278913495\n",
      "Cost on val dataset after 202 epochs is = 0.12316887331270805\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.12316887331270805\n",
      "learning rate for this epoch =  0.13262706593398382\n",
      "Error on this batch = 0.08477885963773257\n",
      "Error on this batch = 0.12386652149210071\n",
      "Cost on val dataset after 203 epochs is = 0.12300456565977984\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.12300456565977984\n",
      "learning rate for this epoch =  0.13246342951392248\n",
      "Error on this batch = 0.08457400780154588\n",
      "Error on this batch = 0.12361419962175965\n",
      "Cost on val dataset after 204 epochs is = 0.12284145146673124\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.12284145146673124\n",
      "learning rate for this epoch =  0.13230079761796648\n",
      "Error on this batch = 0.08437066685905763\n",
      "Error on this batch = 0.12336345009552989\n",
      "Cost on val dataset after 205 epochs is = 0.12267951505064313\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.12267951505064313\n",
      "learning rate for this epoch =  0.13213915920059222\n",
      "Error on this batch = 0.08416881505686431\n",
      "Error on this batch = 0.12311425614386397\n",
      "Cost on val dataset after 206 epochs is = 0.12251874103107457\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.12251874103107457\n",
      "learning rate for this epoch =  0.13197850339085695\n",
      "Error on this batch = 0.08396843108254594\n",
      "Error on this batch = 0.12286660130282136\n",
      "Cost on val dataset after 207 epochs is = 0.12235911432260242\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.12235911432260242\n",
      "learning rate for this epoch =  0.1318188194888078\n",
      "Error on this batch = 0.08376949405275369\n",
      "Error on this batch = 0.12262046940679376\n",
      "Cost on val dataset after 208 epochs is = 0.12220062012757676\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.12220062012757676\n",
      "learning rate for this epoch =  0.13166009696198164\n",
      "Error on this batch = 0.08357198350168227\n",
      "Error on this batch = 0.12237584458137643\n",
      "Cost on val dataset after 209 epochs is = 0.12204324392908598\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.12204324392908598\n",
      "learning rate for this epoch =  0.1315023254419931\n",
      "Error on this batch = 0.08337587936991504\n",
      "Error on this batch = 0.12213271123638018\n",
      "Cost on val dataset after 210 epochs is = 0.1218869714841239\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.1218869714841239\n",
      "learning rate for this epoch =  0.1313454947212079\n",
      "Error on this batch = 0.08318116199363114\n",
      "Error on this batch = 0.12189105405897906\n",
      "Cost on val dataset after 211 epochs is = 0.12173178881695275\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.12173178881695275\n",
      "learning rate for this epoch =  0.13118959474949932\n",
      "Error on this batch = 0.08298781209416418\n",
      "Error on this batch = 0.1216508580069889\n",
      "Cost on val dataset after 212 epochs is = 0.12157768221265533\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.12157768221265533\n",
      "learning rate for this epoch =  0.1310346156310848\n",
      "Error on this batch = 0.08279581076790116\n",
      "Error on this batch = 0.12141210830227298\n",
      "Cost on val dataset after 213 epochs is = 0.12142463821087045\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.12142463821087045\n",
      "learning rate for this epoch =  0.13088054762144102\n",
      "Error on this batch = 0.08260513947651152\n",
      "Error on this batch = 0.12117479042427015\n",
      "Cost on val dataset after 214 epochs is = 0.1212726435997058\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.1212726435997058\n",
      "learning rate for this epoch =  0.13072738112429463\n",
      "Error on this batch = 0.08241578003749613\n",
      "Error on this batch = 0.12093889010364314\n",
      "Cost on val dataset after 215 epochs is = 0.12112168540982214\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.12112168540982214\n",
      "learning rate for this epoch =  0.1305751066886864\n",
      "Error on this batch = 0.0822277146150453\n",
      "Error on this batch = 0.12070439331604334\n",
      "Cost on val dataset after 216 epochs is = 0.1209717509086838\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.1209717509086838\n",
      "learning rate for this epoch =  0.13042371500610728\n",
      "Error on this batch = 0.08204092571119677\n",
      "Error on this batch = 0.12047128627598962\n",
      "Cost on val dataset after 217 epochs is = 0.12082282759496984\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.12082282759496984\n",
      "learning rate for this epoch =  0.13027319690770342\n",
      "Error on this batch = 0.08185539615728317\n",
      "Error on this batch = 0.12023955543085892\n",
      "Cost on val dataset after 218 epochs is = 0.12067490319314104\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.12067490319314104\n",
      "learning rate for this epoch =  0.13012354336154894\n",
      "Error on this batch = 0.08167110910565972\n",
      "Error on this batch = 0.12000918745498687\n",
      "Cost on val dataset after 219 epochs is = 0.1205279656481574\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.1205279656481574\n",
      "learning rate for this epoch =  0.12997474546998408\n",
      "Error on this batch = 0.08148804802170281\n",
      "Error on this batch = 0.11978016924387618\n",
      "Cost on val dataset after 220 epochs is = 0.12038200312034167\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.12038200312034167\n",
      "learning rate for this epoch =  0.12982679446701692\n",
      "Error on this batch = 0.08130619667607009\n",
      "Error on this batch = 0.11955248790851225\n",
      "Cost on val dataset after 221 epochs is = 0.1202370039803844\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.1202370039803844\n",
      "learning rate for this epoch =  0.12967968171578698\n",
      "Error on this batch = 0.08112553913721325\n",
      "Error on this batch = 0.11932613076978403\n",
      "Cost on val dataset after 222 epochs is = 0.12009295680448595\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.12009295680448595\n",
      "learning rate for this epoch =  0.12953339870608896\n",
      "Error on this batch = 0.08094605976413487\n",
      "Error on this batch = 0.1191010853530098\n",
      "Cost on val dataset after 223 epochs is = 0.11994985036963061\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.11994985036963061\n",
      "learning rate for this epoch =  0.12938793705195484\n",
      "Error on this batch = 0.0807677431993807\n",
      "Error on this batch = 0.11887733938256698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 224 epochs is = 0.11980767364899003\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.11980767364899003\n",
      "learning rate for this epoch =  0.12924328848929265\n",
      "Error on this batch = 0.08059057436225889\n",
      "Error on this batch = 0.11865488077662534\n",
      "Cost on val dataset after 225 epochs is = 0.11966641580745065\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.11966641580745065\n",
      "learning rate for this epoch =  0.12909944487358055\n",
      "Error on this batch = 0.08041453844227882\n",
      "Error on this batch = 0.1184336976419835\n",
      "Cost on val dataset after 226 epochs is = 0.11952606619726189\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.11952606619726189\n",
      "learning rate for this epoch =  0.1289563981776146\n",
      "Error on this batch = 0.08023962089280079\n",
      "Error on this batch = 0.11821377826900857\n",
      "Cost on val dataset after 227 epochs is = 0.11938661435380152\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.11938661435380152\n",
      "learning rate for this epoch =  0.12881414048930848\n",
      "Error on this batch = 0.08006580742488957\n",
      "Error on this batch = 0.11799511112667833\n",
      "Cost on val dataset after 228 epochs is = 0.11924804999145415\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.11924804999145415\n",
      "learning rate for this epoch =  0.1286726640095442\n",
      "Error on this batch = 0.07989308400136431\n",
      "Error on this batch = 0.11777768485772688\n",
      "Cost on val dataset after 229 epochs is = 0.11911036299959973\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.11911036299959973\n",
      "learning rate for this epoch =  0.12853196105007209\n",
      "Error on this batch = 0.07972143683103747\n",
      "Error on this batch = 0.11756148827389311\n",
      "Cost on val dataset after 230 epochs is = 0.11897354343870861\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.11897354343870861\n",
      "learning rate for this epoch =  0.12839202403145872\n",
      "Error on this batch = 0.07955085236313582\n",
      "Error on this batch = 0.11734651035127262\n",
      "Cost on val dataset after 231 epochs is = 0.11883758153654005\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.11883758153654005\n",
      "learning rate for this epoch =  0.12825284548108173\n",
      "Error on this batch = 0.0793813172818974\n",
      "Error on this batch = 0.11713274022577348\n",
      "Cost on val dataset after 232 epochs is = 0.11870246768444057\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.11870246768444057\n",
      "learning rate for this epoch =  0.1281144180311698\n",
      "Error on this batch = 0.0792128185013369\n",
      "Error on this batch = 0.11692016718867562\n",
      "Cost on val dataset after 233 epochs is = 0.1185681924337399\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.1185681924337399\n",
      "learning rate for this epoch =  0.12797673441688712\n",
      "Error on this batch = 0.07904534316017393\n",
      "Error on this batch = 0.1167087806822945\n",
      "Cost on val dataset after 234 epochs is = 0.11843474649224124\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.11843474649224124\n",
      "learning rate for this epoch =  0.12783978747446093\n",
      "Error on this batch = 0.07887887861691803\n",
      "Error on this batch = 0.1164985702957499\n",
      "Cost on val dataset after 235 epochs is = 0.11830212072080253\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.11830212072080253\n",
      "learning rate for this epoch =  0.12770357013935066\n",
      "Error on this batch = 0.07871341244510405\n",
      "Error on this batch = 0.11628952576083883\n",
      "Cost on val dataset after 236 epochs is = 0.11817030613000688\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.11817030613000688\n",
      "learning rate for this epoch =  0.12756807544445822\n",
      "Error on this batch = 0.07854893242867289\n",
      "Error on this batch = 0.11608163694801447\n",
      "Cost on val dataset after 237 epochs is = 0.11803929387691932\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.11803929387691932\n",
      "learning rate for this epoch =  0.1274332965183777\n",
      "Error on this batch = 0.0783854265574917\n",
      "Error on this batch = 0.11587489386247019\n",
      "Cost on val dataset after 238 epochs is = 0.11790907526192657\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.11790907526192657\n",
      "learning rate for this epoch =  0.12729922658368395\n",
      "Error on this batch = 0.07822288302300831\n",
      "Error on this batch = 0.11566928664032929\n",
      "Cost on val dataset after 239 epochs is = 0.11777964172565855\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.11777964172565855\n",
      "learning rate for this epoch =  0.12716585895525878\n",
      "Error on this batch = 0.07806129021403495\n",
      "Error on this batch = 0.11546480554494112\n",
      "Cost on val dataset after 240 epochs is = 0.11765098484598838\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.11765098484598838\n",
      "learning rate for this epoch =  0.12703318703865368\n",
      "Error on this batch = 0.0779006367126564\n",
      "Error on this batch = 0.1152614409632826\n",
      "Cost on val dataset after 241 epochs is = 0.11752309633510914\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.11752309633510914\n",
      "learning rate for this epoch =  0.12690120432848842\n",
      "Error on this batch = 0.07774091129025759\n",
      "Error on this batch = 0.11505918340246624\n",
      "Cost on val dataset after 242 epochs is = 0.11739596803668469\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.11739596803668469\n",
      "learning rate for this epoch =  0.12676990440688446\n",
      "Error on this batch = 0.07758210290366649\n",
      "Error on this batch = 0.11485802348635399\n",
      "Cost on val dataset after 243 epochs is = 0.1172695919230729\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.1172695919230729\n",
      "learning rate for this epoch =  0.12663928094193208\n",
      "Error on this batch = 0.07742420069140753\n",
      "Error on this batch = 0.11465795195227702\n",
      "Cost on val dataset after 244 epochs is = 0.11714396009261892\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.11714396009261892\n",
      "learning rate for this epoch =  0.12650932768619078\n",
      "Error on this batch = 0.07726719397006188\n",
      "Error on this batch = 0.11445895964786088\n",
      "Cost on val dataset after 245 epochs is = 0.1170190647670167\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.1170190647670167\n",
      "learning rate for this epoch =  0.12638003847522164\n",
      "Error on this batch = 0.0771110722307301\n",
      "Error on this batch = 0.11426103752795624\n",
      "Cost on val dataset after 246 epochs is = 0.11689489828873662\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.11689489828873662\n",
      "learning rate for this epoch =  0.1262514072261512\n",
      "Error on this batch = 0.0769558251355936\n",
      "Error on this batch = 0.114064176651674\n",
      "Cost on val dataset after 247 epochs is = 0.11677145311851728\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.11677145311851728\n",
      "learning rate for this epoch =  0.12612342793626585\n",
      "Error on this batch = 0.07680144251457104\n",
      "Error on this batch = 0.11386836817952511\n",
      "Cost on val dataset after 248 epochs is = 0.11664872183292047\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.11664872183292047\n",
      "learning rate for this epoch =  0.1259960946816361\n",
      "Error on this batch = 0.0766479143620664\n",
      "Error on this batch = 0.11367360337066339\n",
      "Cost on val dataset after 249 epochs is = 0.11652669712194631\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.11652669712194631\n",
      "learning rate for this epoch =  0.12586940161576976\n",
      "Error on this batch = 0.07649523083380488\n",
      "Error on this batch = 0.11347987358023154\n",
      "Cost on val dataset after 250 epochs is = 0.11640537178670783\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.11640537178670783\n",
      "learning rate for this epoch =  0.12574334296829354\n",
      "Error on this batch = 0.07634338224375395\n",
      "Error on this batch = 0.11328717025680864\n",
      "Cost on val dataset after 251 epochs is = 0.11628473873716297\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.11628473873716297\n",
      "learning rate for this epoch =  0.1256179130436622\n",
      "Error on this batch = 0.07619235906112598\n",
      "Error on this batch = 0.11309548493995852\n",
      "Cost on val dataset after 252 epochs is = 0.11616479098990261\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.11616479098990261\n",
      "learning rate for this epoch =  0.12549310621989482\n",
      "Error on this batch = 0.07604215190745955\n",
      "Error on this batch = 0.11290480925787803\n",
      "Cost on val dataset after 253 epochs is = 0.11604552166599286\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.11604552166599286\n",
      "learning rate for this epoch =  0.125368916947337\n",
      "Error on this batch = 0.07589275155377685\n",
      "Error on this batch = 0.11271513492514319\n",
      "Cost on val dataset after 254 epochs is = 0.11592692398887043\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.11592692398887043\n",
      "learning rate for this epoch =  0.12524533974744914\n",
      "Error on this batch = 0.0757441489178141\n",
      "Error on this batch = 0.11252645374055266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 255 epochs is = 0.11580899128228916\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.11580899128228916\n",
      "learning rate for this epoch =  0.12512236921161915\n",
      "Error on this batch = 0.0755963350613228\n",
      "Error on this batch = 0.1123387575850667\n",
      "Cost on val dataset after 256 epochs is = 0.11569171696831704\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.11569171696831704\n",
      "learning rate for this epoch =  0.125\n",
      "Error on this batch = 0.07544930118743873\n",
      "Error on this batch = 0.11215203841983996\n",
      "Cost on val dataset after 257 epochs is = 0.11557509456538176\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.11557509456538176\n",
      "learning rate for this epoch =  0.12487822684037092\n",
      "Error on this batch = 0.07530303863811691\n",
      "Error on this batch = 0.11196628828434638\n",
      "Cost on val dataset after 258 epochs is = 0.11545911768636377\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.11545911768636377\n",
      "learning rate for this epoch =  0.12475704452702165\n",
      "Error on this batch = 0.07515753889162995\n",
      "Error on this batch = 0.11178149929459476\n",
      "Cost on val dataset after 259 epochs is = 0.11534378003673534\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.11534378003673534\n",
      "learning rate for this epoch =  0.12463644791965951\n",
      "Error on this batch = 0.07501279356012754\n",
      "Error on this batch = 0.11159766364143271\n",
      "Cost on val dataset after 260 epochs is = 0.11522907541274482\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.11522907541274482\n",
      "learning rate for this epoch =  0.12451643194233865\n",
      "Error on this batch = 0.07486879438725529\n",
      "Error on this batch = 0.1114147735889371\n",
      "Cost on val dataset after 261 epochs is = 0.11511499769964464\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.11511499769964464\n",
      "learning rate for this epoch =  0.12439699158241055\n",
      "Error on this batch = 0.0747255332458306\n",
      "Error on this batch = 0.11123282147288899\n",
      "Cost on val dataset after 262 epochs is = 0.1150015408699614\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.1150015408699614\n",
      "learning rate for this epoch =  0.12427812188949586\n",
      "Error on this batch = 0.07458300213557414\n",
      "Error on this batch = 0.11105179969933109\n",
      "Cost on val dataset after 263 epochs is = 0.11488869898180833\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.11488869898180833\n",
      "learning rate for this epoch =  0.1241598179744767\n",
      "Error on this batch = 0.0744411931808943\n",
      "Error on this batch = 0.11087170074320507\n",
      "Cost on val dataset after 264 epochs is = 0.11477646617723729\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.11477646617723729\n",
      "learning rate for this epoch =  0.12404207500850907\n",
      "Error on this batch = 0.07430009862872394\n",
      "Error on this batch = 0.11069251714706697\n",
      "Cost on val dataset after 265 epochs is = 0.11466483668063056\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.11466483668063056\n",
      "learning rate for this epoch =  0.12392488822205483\n",
      "Error on this batch = 0.07415971084640699\n",
      "Error on this batch = 0.11051424151987782\n",
      "Cost on val dataset after 266 epochs is = 0.1145538047971307\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.1145538047971307\n",
      "learning rate for this epoch =  0.12380825290393263\n",
      "Error on this batch = 0.07402002231963366\n",
      "Error on this batch = 0.1103368665358677\n",
      "Cost on val dataset after 267 epochs is = 0.11444336491110786\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.11444336491110786\n",
      "learning rate for this epoch =  0.12369216440038802\n",
      "Error on this batch = 0.07388102565042264\n",
      "Error on this batch = 0.11016038493347022\n",
      "Cost on val dataset after 268 epochs is = 0.11433351148466313\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.11433351148466313\n",
      "learning rate for this epoch =  0.1235766181141811\n",
      "Error on this batch = 0.07374271355514898\n",
      "Error on this batch = 0.10998478951432525\n",
      "Cost on val dataset after 269 epochs is = 0.1142242390561677\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.1142242390561677\n",
      "learning rate for this epoch =  0.12346160950369273\n",
      "Error on this batch = 0.07360507886261612\n",
      "Error on this batch = 0.10981007314234756\n",
      "Cost on val dataset after 270 epochs is = 0.1141155422388359\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.1141155422388359\n",
      "learning rate for this epoch =  0.12334713408204756\n",
      "Error on this batch = 0.07346811451217092\n",
      "Error on this batch = 0.10963622874285817\n",
      "Cost on val dataset after 271 epochs is = 0.11400741571933222\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.11400741571933222\n",
      "learning rate for this epoch =  0.12323318741625437\n",
      "Error on this batch = 0.07333181355186008\n",
      "Error on this batch = 0.10946324930177678\n",
      "Cost on val dataset after 272 epochs is = 0.1138998542564106\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.1138998542564106\n",
      "learning rate for this epoch =  0.12311976512636309\n",
      "Error on this batch = 0.07319616913662749\n",
      "Error on this batch = 0.10929112786487187\n",
      "Cost on val dataset after 273 epochs is = 0.113792852679586\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.113792852679586\n",
      "learning rate for this epoch =  0.12300686288463769\n",
      "Error on this batch = 0.0730611745265504\n",
      "Error on this batch = 0.10911985753706638\n",
      "Cost on val dataset after 274 epochs is = 0.11368640588783659\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.11368640588783659\n",
      "learning rate for this epoch =  0.12289447641474543\n",
      "Error on this batch = 0.0729268230851139\n",
      "Error on this batch = 0.10894943148179635\n",
      "Cost on val dataset after 275 epochs is = 0.11358050884833619\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.11358050884833619\n",
      "learning rate for this epoch =  0.12278260149096118\n",
      "Error on this batch = 0.07279310827752287\n",
      "Error on this batch = 0.1087798429204198\n",
      "Cost on val dataset after 276 epochs is = 0.11347515659521593\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.11347515659521593\n",
      "learning rate for this epoch =  0.12267123393738709\n",
      "Error on this batch = 0.07266002366904946\n",
      "Error on this batch = 0.10861108513167328\n",
      "Cost on val dataset after 277 epochs is = 0.11337034422835504\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.11337034422835504\n",
      "learning rate for this epoch =  0.12256036962718717\n",
      "Error on this batch = 0.0725275629234163\n",
      "Error on this batch = 0.1084431514511738\n",
      "Cost on val dataset after 278 epochs is = 0.11326606691219902\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.11326606691219902\n",
      "learning rate for this epoch =  0.12245000448183609\n",
      "Error on this batch = 0.07239571980121338\n",
      "Error on this batch = 0.10827603527096351\n",
      "Cost on val dataset after 279 epochs is = 0.11316231987460487\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.11316231987460487\n",
      "learning rate for this epoch =  0.12234013447038239\n",
      "Error on this batch = 0.07226448815834872\n",
      "Error on this batch = 0.10810973003909423\n",
      "Cost on val dataset after 280 epochs is = 0.11305909840571332\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.11305909840571332\n",
      "learning rate for this epoch =  0.12223075560872526\n",
      "Error on this batch = 0.07213386194453111\n",
      "Error on this batch = 0.1079442292592504\n",
      "Cost on val dataset after 281 epochs is = 0.11295639785684626\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.11295639785684626\n",
      "learning rate for this epoch =  0.12212186395890517\n",
      "Error on this batch = 0.0720038352017847\n",
      "Error on this batch = 0.10777952649040672\n",
      "Cost on val dataset after 282 epochs is = 0.1128542136394294\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.1128542136394294\n",
      "learning rate for this epoch =  0.12201345562840739\n",
      "Error on this batch = 0.07187440206299404\n",
      "Error on this batch = 0.10761561534651921\n",
      "Cost on val dataset after 283 epochs is = 0.11275254122393938\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.11275254122393938\n",
      "learning rate for this epoch =  0.12190552676947876\n",
      "Error on this batch = 0.07174555675047986\n",
      "Error on this batch = 0.10745248949624685\n",
      "Cost on val dataset after 284 epochs is = 0.11265137613887473\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.11265137613887473\n",
      "learning rate for this epoch =  0.12179807357845675\n",
      "Error on this batch = 0.07161729357460296\n",
      "Error on this batch = 0.10729014266270148\n",
      "Cost on val dataset after 285 epochs is = 0.11255071396974964\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.11255071396974964\n",
      "learning rate for this epoch =  0.12169109229511134\n",
      "Error on this batch = 0.07148960693239798\n",
      "Error on this batch = 0.10712856862322406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 286 epochs is = 0.11245055035811069\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.11245055035811069\n",
      "learning rate for this epoch =  0.12158457920199858\n",
      "Error on this batch = 0.07136249130623389\n",
      "Error on this batch = 0.10696776120918486\n",
      "Cost on val dataset after 287 epochs is = 0.11235088100057516\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.11235088100057516\n",
      "learning rate for this epoch =  0.1214785306238262\n",
      "Error on this batch = 0.07123594126250225\n",
      "Error on this batch = 0.10680771430580538\n",
      "Cost on val dataset after 288 epochs is = 0.11225170164789094\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.11225170164789094\n",
      "learning rate for this epoch =  0.12137294292683086\n",
      "Error on this batch = 0.07110995145033171\n",
      "Error on this batch = 0.10664842185200073\n",
      "Cost on val dataset after 289 epochs is = 0.11215300810401718\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.11215300810401718\n",
      "learning rate for this epoch =  0.12126781251816648\n",
      "Error on this batch = 0.0709845166003285\n",
      "Error on this batch = 0.10648987784023894\n",
      "Cost on val dataset after 290 epochs is = 0.11205479622522511\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.11205479622522511\n",
      "learning rate for this epoch =  0.121163135845304\n",
      "Error on this batch = 0.07085963152334188\n",
      "Error on this batch = 0.10633207631641733\n",
      "Cost on val dataset after 291 epochs is = 0.11195706191921871\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.11195706191921871\n",
      "learning rate for this epoch =  0.12105890939544156\n",
      "Error on this batch = 0.07073529110925436\n",
      "Error on this batch = 0.10617501137975208\n",
      "Cost on val dataset after 292 epochs is = 0.1118598011442746\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.1118598011442746\n",
      "learning rate for this epoch =  0.1209551296949258\n",
      "Error on this batch = 0.07061149032579593\n",
      "Error on this batch = 0.10601867718268082\n",
      "Cost on val dataset after 293 epochs is = 0.11176300990840043\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.11176300990840043\n",
      "learning rate for this epoch =  0.12085179330868305\n",
      "Error on this batch = 0.07048822421738146\n",
      "Error on this batch = 0.10586306793077563\n",
      "Cost on val dataset after 294 epochs is = 0.11166668426851178\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.11166668426851178\n",
      "learning rate for this epoch =  0.12074889683966107\n",
      "Error on this batch = 0.07036548790397118\n",
      "Error on this batch = 0.10570817788266482\n",
      "Cost on val dataset after 295 epochs is = 0.11157082032962659\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.11157082032962659\n",
      "learning rate for this epoch =  0.12064643692828043\n",
      "Error on this batch = 0.07024327657995313\n",
      "Error on this batch = 0.10555400134996276\n",
      "Cost on val dataset after 296 epochs is = 0.11147541424407693\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.11147541424407693\n",
      "learning rate for this epoch =  0.120544410251896\n",
      "Error on this batch = 0.07012158551304747\n",
      "Error on this batch = 0.10540053269720517\n",
      "Cost on val dataset after 297 epochs is = 0.11138046221073757\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.11138046221073757\n",
      "learning rate for this epoch =  0.12044281352426756\n",
      "Error on this batch = 0.07000041004323183\n",
      "Error on this batch = 0.10524776634178906\n",
      "Cost on val dataset after 298 epochs is = 0.11128596047427106\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.11128596047427106\n",
      "learning rate for this epoch =  0.12034164349504001\n",
      "Error on this batch = 0.06987974558168733\n",
      "Error on this batch = 0.10509569675391617\n",
      "Cost on val dataset after 299 epochs is = 0.11119190532438865\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.11119190532438865\n",
      "learning rate for this epoch =  0.12024089694923273\n",
      "Error on this batch = 0.06975958760976445\n",
      "Error on this batch = 0.10494431845653784\n",
      "Cost on val dataset after 300 epochs is = 0.11109829309512674\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.11109829309512674\n",
      "learning rate for this epoch =  0.12014057070673773\n",
      "Error on this batch = 0.06963993167796868\n",
      "Error on this batch = 0.10479362602530123\n",
      "Cost on val dataset after 301 epochs is = 0.11100512016413855\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.11100512016413855\n",
      "learning rate for this epoch =  0.1200406616218266\n",
      "Error on this batch = 0.06952077340496492\n",
      "Error on this batch = 0.10464361408849435\n",
      "Cost on val dataset after 302 epochs is = 0.11091238295200057\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.11091238295200057\n",
      "learning rate for this epoch =  0.11994116658266626\n",
      "Error on this batch = 0.06940210847660044\n",
      "Error on this batch = 0.10449427732699024\n",
      "Cost on val dataset after 303 epochs is = 0.11082007792153327\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.11082007792153327\n",
      "learning rate for this epoch =  0.1198420825108428\n",
      "Error on this batch = 0.06928393264494581\n",
      "Error on this batch = 0.10434561047418833\n",
      "Cost on val dataset after 304 epochs is = 0.1107282015771361\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.1107282015771361\n",
      "learning rate for this epoch =  0.11974340636089367\n",
      "Error on this batch = 0.06916624172735328\n",
      "Error on this batch = 0.10419760831595241\n",
      "Cost on val dataset after 305 epochs is = 0.11063675046413562\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.11063675046413562\n",
      "learning rate for this epoch =  0.11964513511984808\n",
      "Error on this batch = 0.06904903160553183\n",
      "Error on this batch = 0.10405026569054421\n",
      "Cost on val dataset after 306 epochs is = 0.11054572116814755\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.11054572116814755\n",
      "learning rate for this epoch =  0.11954726580677509\n",
      "Error on this batch = 0.06893229822463916\n",
      "Error on this batch = 0.10390357748855206\n",
      "Cost on val dataset after 307 epochs is = 0.11045511031445135\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.11045511031445135\n",
      "learning rate for this epoch =  0.11944979547233951\n",
      "Error on this batch = 0.06881603759238906\n",
      "Error on this batch = 0.10375753865281336\n",
      "Cost on val dataset after 308 epochs is = 0.11036491456737771\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.11036491456737771\n",
      "learning rate for this epoch =  0.1193527211983654\n",
      "Error on this batch = 0.06870024577817456\n",
      "Error on this batch = 0.10361214417833058\n",
      "Cost on val dataset after 309 epochs is = 0.11027513062970808\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.11027513062970808\n",
      "learning rate for this epoch =  0.11925604009740705\n",
      "Error on this batch = 0.06858491891220574\n",
      "Error on this batch = 0.10346738911218023\n",
      "Cost on val dataset after 310 epochs is = 0.11018575524208662\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.11018575524208662\n",
      "learning rate for this epoch =  0.11915974931232703\n",
      "Error on this batch = 0.06847005318466214\n",
      "Error on this batch = 0.1033232685534136\n",
      "Cost on val dataset after 311 epochs is = 0.11009678518244342\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.11009678518244342\n",
      "learning rate for this epoch =  0.1190638460158816\n",
      "Error on this batch = 0.068355644844859\n",
      "Error on this batch = 0.10317977765294951\n",
      "Cost on val dataset after 312 epochs is = 0.11000821726542943\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.11000821726542943\n",
      "learning rate for this epoch =  0.11896832741031306\n",
      "Error on this batch = 0.0682416902004271\n",
      "Error on this batch = 0.10303691161345802\n",
      "Cost on val dataset after 313 epochs is = 0.10992004834186257\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.10992004834186257\n",
      "learning rate for this epoch =  0.11887319072694875\n",
      "Error on this batch = 0.06812818561650523\n",
      "Error on this batch = 0.10289466568923512\n",
      "Cost on val dataset after 314 epochs is = 0.10983227529818444\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.10983227529818444\n",
      "learning rate for this epoch =  0.11877843322580707\n",
      "Error on this batch = 0.06801512751494554\n",
      "Error on this batch = 0.10275303518606745\n",
      "Cost on val dataset after 315 epochs is = 0.10974489505592784\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.10974489505592784\n",
      "learning rate for this epoch =  0.11868405219520976\n",
      "Error on this batch = 0.06790251237353041\n",
      "Error on this batch = 0.1026120154610872\n",
      "Cost on val dataset after 316 epochs is = 0.10965790457119465\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.10965790457119465\n",
      "learning rate for this epoch =  0.11859004495140096\n",
      "Error on this batch = 0.0677903367252013\n",
      "Error on this batch = 0.10247160192261694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 317 epochs is = 0.10957130083414365\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.10957130083414365\n",
      "learning rate for this epoch =  0.11849640883817222\n",
      "Error on this batch = 0.06767859715729818\n",
      "Error on this batch = 0.10233179003000346\n",
      "Cost on val dataset after 318 epochs is = 0.10948508086848825\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.10948508086848825\n",
      "learning rate for this epoch =  0.11840314122649412\n",
      "Error on this batch = 0.06756729031080998\n",
      "Error on this batch = 0.1021925752934413\n",
      "Cost on val dataset after 319 epochs is = 0.10939924173100386\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.10939924173100386\n",
      "learning rate for this epoch =  0.11831023951415345\n",
      "Error on this batch = 0.06745641287963457\n",
      "Error on this batch = 0.10205395327378515\n",
      "Cost on val dataset after 320 epochs is = 0.10931378051104451\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.10931378051104451\n",
      "learning rate for this epoch =  0.11821770112539698\n",
      "Error on this batch = 0.06734596160984899\n",
      "Error on this batch = 0.10191591958235108\n",
      "Cost on val dataset after 321 epochs is = 0.10922869433006883\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.10922869433006883\n",
      "learning rate for this epoch =  0.11812552351058042\n",
      "Error on this batch = 0.06723593329898822\n",
      "Error on this batch = 0.10177846988070695\n",
      "Cost on val dataset after 322 epochs is = 0.10914398034117462\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.10914398034117462\n",
      "learning rate for this epoch =  0.11803370414582362\n",
      "Error on this batch = 0.06712632479533323\n",
      "Error on this batch = 0.10164159988045106\n",
      "Cost on val dataset after 323 epochs is = 0.10905963572864241\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.10905963572864241\n",
      "learning rate for this epoch =  0.11794224053267104\n",
      "Error on this batch = 0.06701713299720698\n",
      "Error on this batch = 0.10150530534298004\n",
      "Cost on val dataset after 324 epochs is = 0.10897565770748745\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.10897565770748745\n",
      "learning rate for this epoch =  0.11785113019775793\n",
      "Error on this batch = 0.06690835485227822\n",
      "Error on this batch = 0.10136958207924504\n",
      "Cost on val dataset after 325 epochs is = 0.10889204352301983\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.10889204352301983\n",
      "learning rate for this epoch =  0.11776037069248181\n",
      "Error on this batch = 0.06679998735687302\n",
      "Error on this batch = 0.10123442594949665\n",
      "Cost on val dataset after 326 epochs is = 0.10880879045041274\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.10880879045041274\n",
      "learning rate for this epoch =  0.11766995959267931\n",
      "Error on this batch = 0.0666920275552928\n",
      "Error on this batch = 0.1010998328630189\n",
      "Cost on val dataset after 327 epochs is = 0.10872589579427884\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.10872589579427884\n",
      "learning rate for this epoch =  0.11757989449830816\n",
      "Error on this batch = 0.06658447253913956\n",
      "Error on this batch = 0.10096579877785145\n",
      "Cost on val dataset after 328 epochs is = 0.10864335688825404\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.10864335688825404\n",
      "learning rate for this epoch =  0.11749017303313421\n",
      "Error on this batch = 0.06647731944664657\n",
      "Error on this batch = 0.1008323197005011\n",
      "Cost on val dataset after 329 epochs is = 0.1085611710945888\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.1085611710945888\n",
      "learning rate for this epoch =  0.11740079284442367\n",
      "Error on this batch = 0.06637056546201553\n",
      "Error on this batch = 0.10069939168564229\n",
      "Cost on val dataset after 330 epochs is = 0.10847933580374702\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.10847933580374702\n",
      "learning rate for this epoch =  0.11731175160264\n",
      "Error on this batch = 0.06626420781475856\n",
      "Error on this batch = 0.10056701083580614\n",
      "Cost on val dataset after 331 epochs is = 0.10839784843401185\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.10839784843401185\n",
      "learning rate for this epoch =  0.11722304700114572\n",
      "Error on this batch = 0.06615824377904564\n",
      "Error on this batch = 0.1004351733010596\n",
      "Cost on val dataset after 332 epochs is = 0.10831670643109839\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.10831670643109839\n",
      "learning rate for this epoch =  0.11713467675590904\n",
      "Error on this batch = 0.06605267067305651\n",
      "Error on this batch = 0.10030387527867303\n",
      "Cost on val dataset after 333 epochs is = 0.10823590726777355\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.10823590726777355\n",
      "learning rate for this epoch =  0.11704663860521486\n",
      "Error on this batch = 0.06594748585833701\n",
      "Error on this batch = 0.10017311301277804\n",
      "Cost on val dataset after 334 epochs is = 0.10815544844348211\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.10815544844348211\n",
      "learning rate for this epoch =  0.1169589303093807\n",
      "Error on this batch = 0.06584268673915937\n",
      "Error on this batch = 0.10004288279401476\n",
      "Cost on val dataset after 335 epochs is = 0.10807532748397963\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.10807532748397963\n",
      "learning rate for this epoch =  0.11687154965047665\n",
      "Error on this batch = 0.06573827076188629\n",
      "Error on this batch = 0.09991318095916903\n",
      "Cost on val dataset after 336 epochs is = 0.10799554194097129\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.10799554194097129\n",
      "learning rate for this epoch =  0.11678449443205002\n",
      "Error on this batch = 0.0656342354143383\n",
      "Error on this batch = 0.09978400389080004\n",
      "Cost on val dataset after 337 epochs is = 0.10791608939175737\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.10791608939175737\n",
      "learning rate for this epoch =  0.11669776247885426\n",
      "Error on this batch = 0.06553057822516445\n",
      "Error on this batch = 0.09965534801685795\n",
      "Cost on val dataset after 338 epochs is = 0.10783696743888423\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.10783696743888423\n",
      "learning rate for this epoch =  0.1166113516365818\n",
      "Error on this batch = 0.0654272967632157\n",
      "Error on this batch = 0.09952720981029249\n",
      "Cost on val dataset after 339 epochs is = 0.10775817370980154\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.10775817370980154\n",
      "learning rate for this epoch =  0.1165252597716015\n",
      "Error on this batch = 0.06532438863692092\n",
      "Error on this batch = 0.09939958578865216\n",
      "Cost on val dataset after 340 epochs is = 0.10767970585652493\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.10767970585652493\n",
      "learning rate for this epoch =  0.11643948477069971\n",
      "Error on this batch = 0.06522185149366554\n",
      "Error on this batch = 0.0992724725136749\n",
      "Cost on val dataset after 341 epochs is = 0.10760156155530444\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.10760156155530444\n",
      "learning rate for this epoch =  0.11635402454082565\n",
      "Error on this batch = 0.06511968301917213\n",
      "Error on this batch = 0.09914586659086976\n",
      "Cost on val dataset after 342 epochs is = 0.10752373850629837\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.10752373850629837\n",
      "learning rate for this epoch =  0.1162688770088405\n",
      "Error on this batch = 0.06501788093688296\n",
      "Error on this batch = 0.09901976466909058\n",
      "Cost on val dataset after 343 epochs is = 0.10744623443325217\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.10744623443325217\n",
      "learning rate for this epoch =  0.11618404012127041\n",
      "Error on this batch = 0.06491644300734474\n",
      "Error on this batch = 0.09889416344010163\n",
      "Cost on val dataset after 344 epochs is = 0.10736904708318301\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.10736904708318301\n",
      "learning rate for this epoch =  0.11609951184406334\n",
      "Error on this batch = 0.06481536702759458\n",
      "Error on this batch = 0.0987690596381352\n",
      "Cost on val dataset after 345 epochs is = 0.10729217422606883\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.10729217422606883\n",
      "learning rate for this epoch =  0.11601529016234945\n",
      "Error on this batch = 0.06471465083054782\n",
      "Error on this batch = 0.09864445003944215\n",
      "Cost on val dataset after 346 epochs is = 0.10721561365454271\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.10721561365454271\n",
      "learning rate for this epoch =  0.11593137308020533\n",
      "Error on this batch = 0.06461429228438728\n",
      "Error on this batch = 0.09852033146183505\n",
      "Cost on val dataset after 347 epochs is = 0.10713936318359198\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.10713936318359198\n",
      "learning rate for this epoch =  0.11584775862042163\n",
      "Error on this batch = 0.06451428929195373\n",
      "Error on this batch = 0.09839670076422471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 348 epochs is = 0.10706342065026185\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.10706342065026185\n",
      "learning rate for this epoch =  0.11576444482427425\n",
      "Error on this batch = 0.06441463979013755\n",
      "Error on this batch = 0.09827355484614987\n",
      "Cost on val dataset after 349 epochs is = 0.10698778391336378\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.10698778391336378\n",
      "learning rate for this epoch =  0.11568142975129903\n",
      "Error on this batch = 0.06431534174927196\n",
      "Error on this batch = 0.0981508906473012\n",
      "Cost on val dataset after 350 epochs is = 0.1069124508531883\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.1069124508531883\n",
      "learning rate for this epoch =  0.11559871147906978\n",
      "Error on this batch = 0.06421639317252716\n",
      "Error on this batch = 0.098028705147039\n",
      "Cost on val dataset after 351 epochs is = 0.10683741937122232\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.10683741937122232\n",
      "learning rate for this epoch =  0.11551628810297963\n",
      "Error on this batch = 0.06411779209530559\n",
      "Error on this batch = 0.09790699536390558\n",
      "Cost on val dataset after 352 epochs is = 0.10676268738987026\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.10676268738987026\n",
      "learning rate for this epoch =  0.11543415773602565\n",
      "Error on this batch = 0.06401953658463874\n",
      "Error on this batch = 0.09778575835513229\n",
      "Cost on val dataset after 353 epochs is = 0.10668825285217992\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.10668825285217992\n",
      "learning rate for this epoch =  0.11535231850859669\n",
      "Error on this batch = 0.06392162473858462\n",
      "Error on this batch = 0.09766499121614189\n",
      "Cost on val dataset after 354 epochs is = 0.10661411372157213\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.10661411372157213\n",
      "learning rate for this epoch =  0.11527076856826429\n",
      "Error on this batch = 0.06382405468562698\n",
      "Error on this batch = 0.09754469108004621\n",
      "Cost on val dataset after 355 epochs is = 0.10654026798157444\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.10654026798157444\n",
      "learning rate for this epoch =  0.1151895060795769\n",
      "Error on this batch = 0.06372682458407551\n",
      "Error on this batch = 0.09742485511713948\n",
      "Cost on val dataset after 356 epochs is = 0.10646671363555862\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.10646671363555862\n",
      "learning rate for this epoch =  0.11510852922385682\n",
      "Error on this batch = 0.06362993262146763\n",
      "Error on this batch = 0.0973054805343882\n",
      "Cost on val dataset after 357 epochs is = 0.10639344870648233\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.10639344870648233\n",
      "learning rate for this epoch =  0.11502783619900045\n",
      "Error on this batch = 0.06353337701397142\n",
      "Error on this batch = 0.09718656457491705\n",
      "Cost on val dataset after 358 epochs is = 0.10632047123663403\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.10632047123663403\n",
      "learning rate for this epoch =  0.11494742521928122\n",
      "Error on this batch = 0.06343715600579068\n",
      "Error on this batch = 0.0970681045174917\n",
      "Cost on val dataset after 359 epochs is = 0.10624777928738194\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.10624777928738194\n",
      "learning rate for this epoch =  0.11486729451515557\n",
      "Error on this batch = 0.06334126786857101\n",
      "Error on this batch = 0.09695009767599899\n",
      "Cost on val dataset after 360 epochs is = 0.10617537093892655\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.10617537093892655\n",
      "learning rate for this epoch =  0.11478744233307164\n",
      "Error on this batch = 0.06324571090080842\n",
      "Error on this batch = 0.09683254139892405\n",
      "Cost on val dataset after 361 epochs is = 0.10610324429005648\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.10610324429005648\n",
      "learning rate for this epoch =  0.11470786693528087\n",
      "Error on this batch = 0.06315048342725922\n",
      "Error on this batch = 0.0967154330688259\n",
      "Cost on val dataset after 362 epochs is = 0.10603139745790803\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.10603139745790803\n",
      "learning rate for this epoch =  0.11462856659965227\n",
      "Error on this batch = 0.06305558379835283\n",
      "Error on this batch = 0.0965987701018106\n",
      "Cost on val dataset after 363 epochs is = 0.10595982857772798\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.10595982857772798\n",
      "learning rate for this epoch =  0.11454953961948931\n",
      "Error on this batch = 0.06296101038960616\n",
      "Error on this batch = 0.09648254994700306\n",
      "Cost on val dataset after 364 epochs is = 0.10588853580263978\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.10588853580263978\n",
      "learning rate for this epoch =  0.11447078430334955\n",
      "Error on this batch = 0.06286676160104111\n",
      "Error on this batch = 0.09636677008601761\n",
      "Cost on val dataset after 365 epochs is = 0.10581751730341307\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.10581751730341307\n",
      "learning rate for this epoch =  0.11439229897486693\n",
      "Error on this batch = 0.0627728358566044\n",
      "Error on this batch = 0.09625142803242763\n",
      "Cost on val dataset after 366 epochs is = 0.10574677126823648\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.10574677126823648\n",
      "learning rate for this epoch =  0.11431408197257639\n",
      "Error on this batch = 0.0626792316035905\n",
      "Error on this batch = 0.0961365213312347\n",
      "Cost on val dataset after 367 epochs is = 0.10567629590249339\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.10567629590249339\n",
      "learning rate for this epoch =  0.11423613164974125\n",
      "Error on this batch = 0.06258594731206749\n",
      "Error on this batch = 0.09602204755833718\n",
      "Cost on val dataset after 368 epochs is = 0.10560608942854115\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.10560608942854115\n",
      "learning rate for this epoch =  0.11415844637418282\n",
      "Error on this batch = 0.06249298147430658\n",
      "Error on this batch = 0.0959080043199991\n",
      "Cost on val dataset after 369 epochs is = 0.10553615008549326\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.10553615008549326\n",
      "learning rate for this epoch =  0.11408102452811265\n",
      "Error on this batch = 0.06240033260421502\n",
      "Error on this batch = 0.09579438925231927\n",
      "Cost on val dataset after 370 epochs is = 0.10546647612900432\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.10546647612900432\n",
      "learning rate for this epoch =  0.11400386450796704\n",
      "Error on this batch = 0.062307999236772584\n",
      "Error on this batch = 0.09568120002070077\n",
      "Cost on val dataset after 371 epochs is = 0.10539706583105878\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.10539706583105878\n",
      "learning rate for this epoch =  0.11392696472424395\n",
      "Error on this batch = 0.06221597992747256\n",
      "Error on this batch = 0.09556843431932185\n",
      "Cost on val dataset after 372 epochs is = 0.1053279174797616\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.1053279174797616\n",
      "learning rate for this epoch =  0.11385032360134212\n",
      "Error on this batch = 0.06212427325176664\n",
      "Error on this batch = 0.09545608987060757\n",
      "Cost on val dataset after 373 epochs is = 0.10525902937913278\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.10525902937913278\n",
      "learning rate for this epoch =  0.11377393957740255\n",
      "Error on this batch = 0.06203287780451446\n",
      "Error on this batch = 0.09534416442470298\n",
      "Cost on val dataset after 374 epochs is = 0.10519039984890435\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.10519039984890435\n",
      "learning rate for this epoch =  0.11369781110415222\n",
      "Error on this batch = 0.06194179219943798\n",
      "Error on this batch = 0.09523265575894818\n",
      "Cost on val dataset after 375 epochs is = 0.10512202722432022\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.10512202722432022\n",
      "learning rate for this epoch =  0.11362193664674994\n",
      "Error on this batch = 0.06185101506858055\n",
      "Error on this batch = 0.09512156167735533\n",
      "Cost on val dataset after 376 epochs is = 0.10505390985593914\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.10505390985593914\n",
      "learning rate for this epoch =  0.11354631468363437\n",
      "Error on this batch = 0.061760545061771685\n",
      "Error on this batch = 0.09501088001008767\n",
      "Cost on val dataset after 377 epochs is = 0.1049860461094402\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.1049860461094402\n",
      "learning rate for this epoch =  0.1134709437063741\n",
      "Error on this batch = 0.06167038084609687\n",
      "Error on this batch = 0.09490060861294154\n",
      "Cost on val dataset after 378 epochs is = 0.10491843436543129\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.10491843436543129\n",
      "learning rate for this epoch =  0.11339582221952002\n",
      "Error on this batch = 0.06158052110537333\n",
      "Error on this batch = 0.09479074536683045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 379 epochs is = 0.10485107301926028\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.10485107301926028\n",
      "learning rate for this epoch =  0.11332094874045952\n",
      "Error on this batch = 0.061490964539631605\n",
      "Error on this batch = 0.09468128817727282\n",
      "Cost on val dataset after 380 epochs is = 0.10478396048082896\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.10478396048082896\n",
      "learning rate for this epoch =  0.1132463217992727\n",
      "Error on this batch = 0.06140170986460351\n",
      "Error on this batch = 0.09457223497388231\n",
      "Cost on val dataset after 381 epochs is = 0.10471709517440966\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.10471709517440966\n",
      "learning rate for this epoch =  0.11317193993859079\n",
      "Error on this batch = 0.0613127558112163\n",
      "Error on this batch = 0.09446358370986206\n",
      "Cost on val dataset after 382 epochs is = 0.10465047553846464\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.10465047553846464\n",
      "learning rate for this epoch =  0.11309780171345626\n",
      "Error on this batch = 0.06122410112509334\n",
      "Error on this batch = 0.09435533236150206\n",
      "Cost on val dataset after 383 epochs is = 0.10458410002546799\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.10458410002546799\n",
      "learning rate for this epoch =  0.11302390569118509\n",
      "Error on this batch = 0.06113574456606213\n",
      "Error on this batch = 0.09424747892768068\n",
      "Cost on val dataset after 384 epochs is = 0.10451796710173043\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.10451796710173043\n",
      "learning rate for this epoch =  0.11295025045123061\n",
      "Error on this batch = 0.06104768490766881\n",
      "Error on this batch = 0.09414002142936996\n",
      "Cost on val dataset after 385 epochs is = 0.10445207524722655\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.10445207524722655\n",
      "learning rate for this epoch =  0.11287683458504956\n",
      "Error on this batch = 0.06095992093670018\n",
      "Error on this batch = 0.09403295790914537\n",
      "Cost on val dataset after 386 epochs is = 0.10438642295542468\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.10438642295542468\n",
      "learning rate for this epoch =  0.11280365669596971\n",
      "Error on this batch = 0.060872451452713125\n",
      "Error on this batch = 0.09392628643069958\n",
      "Cost on val dataset after 387 epochs is = 0.10432100873311954\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.10432100873311954\n",
      "learning rate for this epoch =  0.11273071539905938\n",
      "Error on this batch = 0.0607852752675718\n",
      "Error on this batch = 0.09382000507836079\n",
      "Cost on val dataset after 388 epochs is = 0.10425583110026708\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.10425583110026708\n",
      "learning rate for this epoch =  0.11265800932099873\n",
      "Error on this batch = 0.06069839120499223\n",
      "Error on this batch = 0.09371411195661607\n",
      "Cost on val dataset after 389 epochs is = 0.1041908885898223\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.1041908885898223\n",
      "learning rate for this epoch =  0.11258553709995278\n",
      "Error on this batch = 0.060611798100095406\n",
      "Error on this batch = 0.09360860518963897\n",
      "Cost on val dataset after 390 epochs is = 0.1041261797475794\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.1041261797475794\n",
      "learning rate for this epoch =  0.11251329738544609\n",
      "Error on this batch = 0.06052549479896815\n",
      "Error on this batch = 0.09350348292082253\n",
      "Cost on val dataset after 391 epochs is = 0.10406170313201425\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.10406170313201425\n",
      "learning rate for this epoch =  0.11244128883823923\n",
      "Error on this batch = 0.06043948015823235\n",
      "Error on this batch = 0.09339874331231701\n",
      "Cost on val dataset after 392 epochs is = 0.1039974573141298\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.1039974573141298\n",
      "learning rate for this epoch =  0.11236951013020673\n",
      "Error on this batch = 0.06035375304462276\n",
      "Error on this batch = 0.09329438454457323\n",
      "Cost on val dataset after 393 epochs is = 0.10393344087730354\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.10393344087730354\n",
      "learning rate for this epoch =  0.11229795994421696\n",
      "Error on this batch = 0.06026831233457312\n",
      "Error on this batch = 0.0931904048158906\n",
      "Cost on val dataset after 394 epochs is = 0.10386965241713768\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.10386965241713768\n",
      "learning rate for this epoch =  0.11222663697401325\n",
      "Error on this batch = 0.06018315691381121\n",
      "Error on this batch = 0.09308680234197121\n",
      "Cost on val dataset after 395 epochs is = 0.10380609054131158\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.10380609054131158\n",
      "learning rate for this epoch =  0.11215553992409688\n",
      "Error on this batch = 0.0600982856769625\n",
      "Error on this batch = 0.0929835753554789\n",
      "Cost on val dataset after 396 epochs is = 0.10374275386943672\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.10374275386943672\n",
      "learning rate for this epoch =  0.11208466750961145\n",
      "Error on this batch = 0.06001369752716278\n",
      "Error on this batch = 0.09288072210560433\n",
      "Cost on val dataset after 397 epochs is = 0.10367964103291405\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.10367964103291405\n",
      "learning rate for this epoch =  0.11201401845622891\n",
      "Error on this batch = 0.05992939137567985\n",
      "Error on this batch = 0.09277824085763532\n",
      "Cost on val dataset after 398 epochs is = 0.10361675067479341\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.10361675067479341\n",
      "learning rate for this epoch =  0.11194359150003692\n",
      "Error on this batch = 0.05984536614154411\n",
      "Error on this batch = 0.0926761298925333\n",
      "Cost on val dataset after 399 epochs is = 0.10355408144963597\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.10355408144963597\n",
      "learning rate for this epoch =  0.11187338538742793\n",
      "Error on this batch = 0.05976162075118834\n",
      "Error on this batch = 0.09257438750651524\n",
      "Cost on val dataset after 400 epochs is = 0.10349163202337813\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.10349163202337813\n",
      "learning rate for this epoch =  0.11180339887498948\n",
      "Error on this batch = 0.05967815413809688\n",
      "Error on this batch = 0.09247301201064176\n",
      "Cost on val dataset after 401 epochs is = 0.10342940107319835\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.10342940107319835\n",
      "learning rate for this epoch =  0.11173363072939616\n",
      "Error on this batch = 0.05959496524246369\n",
      "Error on this batch = 0.09237200173041087\n",
      "Cost on val dataset after 402 epochs is = 0.10336738728738604\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.10336738728738604\n",
      "learning rate for this epoch =  0.11166407972730269\n",
      "Error on this batch = 0.059512053010859996\n",
      "Error on this batch = 0.09227135500535802\n",
      "Cost on val dataset after 403 epochs is = 0.10330558936521253\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.10330558936521253\n",
      "learning rate for this epoch =  0.1115947446552388\n",
      "Error on this batch = 0.059429416395911136\n",
      "Error on this batch = 0.09217107018866165\n",
      "Cost on val dataset after 404 epochs is = 0.1032440060168046\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.1032440060168046\n",
      "learning rate for this epoch =  0.11152562430950505\n",
      "Error on this batch = 0.059347054355982753\n",
      "Error on this batch = 0.09207114564675538\n",
      "Cost on val dataset after 405 epochs is = 0.10318263596301988\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.10318263596301988\n",
      "learning rate for this epoch =  0.11145671749607033\n",
      "Error on this batch = 0.05926496585487627\n",
      "Error on this batch = 0.09197157975894582\n",
      "Cost on val dataset after 406 epochs is = 0.10312147793532456\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.10312147793532456\n",
      "learning rate for this epoch =  0.1113880230304705\n",
      "Error on this batch = 0.05918314986153393\n",
      "Error on this batch = 0.09187237091703672\n",
      "Cost on val dataset after 407 epochs is = 0.10306053067567322\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.10306053067567322\n",
      "learning rate for this epoch =  0.11131953973770842\n",
      "Error on this batch = 0.05910160534975289\n",
      "Error on this batch = 0.09177351752495914\n",
      "Cost on val dataset after 408 epochs is = 0.1029997929363908\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.1029997929363908\n",
      "learning rate for this epoch =  0.11125126645215519\n",
      "Error on this batch = 0.05902033129790873\n",
      "Error on this batch = 0.09167501799840778\n",
      "Cost on val dataset after 409 epochs is = 0.10293926348005632\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.10293926348005632\n",
      "learning rate for this epoch =  0.11118320201745278\n",
      "Error on this batch = 0.058939326688688516\n",
      "Error on this batch = 0.09157687076448344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 410 epochs is = 0.10287894107938934\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.10287894107938934\n",
      "learning rate for this epoch =  0.11111534528641788\n",
      "Error on this batch = 0.05885859050883257\n",
      "Error on this batch = 0.09147907426134182\n",
      "Cost on val dataset after 411 epochs is = 0.10281882451713764\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.10281882451713764\n",
      "learning rate for this epoch =  0.11104769512094681\n",
      "Error on this batch = 0.05877812174888618\n",
      "Error on this batch = 0.091381626937848\n",
      "Cost on val dataset after 412 epochs is = 0.10275891258596727\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.10275891258596727\n",
      "learning rate for this epoch =  0.11098025039192183\n",
      "Error on this batch = 0.05869791940295971\n",
      "Error on this batch = 0.09128452725323782\n",
      "Cost on val dataset after 413 epochs is = 0.10269920408835466\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.10269920408835466\n",
      "learning rate for this epoch =  0.11091300997911864\n",
      "Error on this batch = 0.05861798246849847\n",
      "Error on this batch = 0.09118777367678466\n",
      "Cost on val dataset after 414 epochs is = 0.10263969783648039\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.10263969783648039\n",
      "learning rate for this epoch =  0.11084597277111498\n",
      "Error on this batch = 0.05853830994606114\n",
      "Error on this batch = 0.0910913646874729\n",
      "Cost on val dataset after 415 epochs is = 0.10258039265212485\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.10258039265212485\n",
      "learning rate for this epoch =  0.11077913766520031\n",
      "Error on this batch = 0.05845890083910744\n",
      "Error on this batch = 0.09099529877367735\n",
      "Cost on val dataset after 416 epochs is = 0.10252128736656588\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.10252128736656588\n",
      "learning rate for this epoch =  0.11071250356728685\n",
      "Error on this batch = 0.05837975415379465\n",
      "Error on this batch = 0.09089957443284878\n",
      "Cost on val dataset after 417 epochs is = 0.10246238082047812\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.10246238082047812\n",
      "learning rate for this epoch =  0.11064606939182157\n",
      "Error on this batch = 0.058300868898782804\n",
      "Error on this batch = 0.09080419017120558\n",
      "Cost on val dataset after 418 epochs is = 0.10240367186383409\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.10240367186383409\n",
      "learning rate for this epoch =  0.11057983406169934\n",
      "Error on this batch = 0.058222244085048704\n",
      "Error on this batch = 0.09070914450343179\n",
      "Cost on val dataset after 419 epochs is = 0.10234515935580724\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.10234515935580724\n",
      "learning rate for this epoch =  0.11051379650817714\n",
      "Error on this batch = 0.05814387872570841\n",
      "Error on this batch = 0.09061443595238078\n",
      "Cost on val dataset after 420 epochs is = 0.10228684216467612\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.10228684216467612\n",
      "learning rate for this epoch =  0.11044795567078942\n",
      "Error on this batch = 0.05806577183584845\n",
      "Error on this batch = 0.09052006304878538\n",
      "Cost on val dataset after 421 epochs is = 0.1022287191677311\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.1022287191677311\n",
      "learning rate for this epoch =  0.1103823104972644\n",
      "Error on this batch = 0.057987922432365106\n",
      "Error on this batch = 0.09042602433097412\n",
      "Cost on val dataset after 422 epochs is = 0.10217078925118164\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.10217078925118164\n",
      "learning rate for this epoch =  0.11031685994344151\n",
      "Error on this batch = 0.057910329533812255\n",
      "Error on this batch = 0.09033231834459306\n",
      "Cost on val dataset after 423 epochs is = 0.10211305131006616\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.10211305131006616\n",
      "learning rate for this epoch =  0.11025160297318981\n",
      "Error on this batch = 0.057832992160257175\n",
      "Error on this batch = 0.0902389436423343\n",
      "Cost on val dataset after 424 epochs is = 0.10205550424816257\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.10205550424816257\n",
      "learning rate for this epoch =  0.11018653855832754\n",
      "Error on this batch = 0.05775590933314453\n",
      "Error on this batch = 0.09014589878366998\n",
      "Cost on val dataset after 425 epochs is = 0.10199814697790105\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.10199814697790105\n",
      "learning rate for this epoch =  0.11012166567854233\n",
      "Error on this batch = 0.057679080075167914\n",
      "Error on this batch = 0.09005318233459257\n",
      "Cost on val dataset after 426 epochs is = 0.10194097842027763\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.10194097842027763\n",
      "learning rate for this epoch =  0.11005698332131283\n",
      "Error on this batch = 0.05760250341014972\n",
      "Error on this batch = 0.08996079286736107\n",
      "Cost on val dataset after 427 epochs is = 0.10188399750476967\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.10188399750476967\n",
      "learning rate for this epoch =  0.10999249048183099\n",
      "Error on this batch = 0.05752617836292807\n",
      "Error on this batch = 0.08986872896025318\n",
      "Cost on val dataset after 428 epochs is = 0.10182720316925255\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.10182720316925255\n",
      "learning rate for this epoch =  0.10992818616292545\n",
      "Error on this batch = 0.05745010395925146\n",
      "Error on this batch = 0.08977698919732341\n",
      "Cost on val dataset after 429 epochs is = 0.10177059435991748\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.10177059435991748\n",
      "learning rate for this epoch =  0.10986406937498579\n",
      "Error on this batch = 0.05737427922568086\n",
      "Error on this batch = 0.0896855721681671\n",
      "Cost on val dataset after 430 epochs is = 0.10171417003119108\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.10171417003119108\n",
      "learning rate for this epoch =  0.10980013913588772\n",
      "Error on this batch = 0.05729870318949889\n",
      "Error on this batch = 0.08959447646769046\n",
      "Cost on val dataset after 431 epochs is = 0.10165792914565575\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.10165792914565575\n",
      "learning rate for this epoch =  0.10973639447091926\n",
      "Error on this batch = 0.05722337487862584\n",
      "Error on this batch = 0.08950370069588644\n",
      "Cost on val dataset after 432 epochs is = 0.10160187067397163\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.10160187067397163\n",
      "learning rate for this epoch =  0.10967283441270771\n",
      "Error on this batch = 0.05714829332154308\n",
      "Error on this batch = 0.08941324345761632\n",
      "Cost on val dataset after 433 epochs is = 0.10154599359479932\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.10154599359479932\n",
      "learning rate for this epoch =  0.10960945800114749\n",
      "Error on this batch = 0.0570734575472226\n",
      "Error on this batch = 0.08932310336239771\n",
      "Cost on val dataset after 434 epochs is = 0.10149029689472429\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.10149029689472429\n",
      "learning rate for this epoch =  0.10954626428332909\n",
      "Error on this batch = 0.05699886658506364\n",
      "Error on this batch = 0.08923327902419756\n",
      "Cost on val dataset after 435 epochs is = 0.10143477956818181\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.10143477956818181\n",
      "learning rate for this epoch =  0.10948325231346849\n",
      "Error on this batch = 0.056924519464835455\n",
      "Error on this batch = 0.08914376906123188\n",
      "Cost on val dataset after 436 epochs is = 0.10137944061738338\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.10137944061738338\n",
      "learning rate for this epoch =  0.1094204211528378\n",
      "Error on this batch = 0.05685041521662654\n",
      "Error on this batch = 0.08905457209577085\n",
      "Cost on val dataset after 437 epochs is = 0.10132427905224405\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.10132427905224405\n",
      "learning rate for this epoch =  0.1093577698696965\n",
      "Error on this batch = 0.05677655287079971\n",
      "Error on this batch = 0.08896568675394964\n",
      "Cost on val dataset after 438 epochs is = 0.10126929389031056\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.10126929389031056\n",
      "learning rate for this epoch =  0.1092952975392236\n",
      "Error on this batch = 0.05670293145795345\n",
      "Error on this batch = 0.08887711166558541\n",
      "Cost on val dataset after 439 epochs is = 0.10121448415669058\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.10121448415669058\n",
      "learning rate for this epoch =  0.10923300324345062\n",
      "Error on this batch = 0.056629550008888786\n",
      "Error on this batch = 0.08878884546399989\n",
      "Cost on val dataset after 440 epochs is = 0.10115984888398301\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.10115984888398301\n",
      "learning rate for this epoch =  0.10917088607119531\n",
      "Error on this batch = 0.056556407554581946\n",
      "Error on this batch = 0.08870088678584777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 441 epochs is = 0.10110538711220882\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.10110538711220882\n",
      "learning rate for this epoch =  0.1091089451179962\n",
      "Error on this batch = 0.056483503126162446\n",
      "Error on this batch = 0.08861323427095105\n",
      "Cost on val dataset after 442 epochs is = 0.10105109788874292\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.10105109788874292\n",
      "learning rate for this epoch =  0.10904717948604793\n",
      "Error on this batch = 0.056410835754896346\n",
      "Error on this batch = 0.08852588656213893\n",
      "Cost on val dataset after 443 epochs is = 0.10099698026824695\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.10099698026824695\n",
      "learning rate for this epoch =  0.10898558828413735\n",
      "Error on this batch = 0.056338404472175085\n",
      "Error on this batch = 0.08843884230509376\n",
      "Cost on val dataset after 444 epochs is = 0.10094303331260256\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.10094303331260256\n",
      "learning rate for this epoch =  0.10892417062758035\n",
      "Error on this batch = 0.056266208309508674\n",
      "Error on this batch = 0.08835210014820245\n",
      "Cost on val dataset after 445 epochs is = 0.1008892560908457\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.1008892560908457\n",
      "learning rate for this epoch =  0.10886292563815944\n",
      "Error on this batch = 0.05619424629852426\n",
      "Error on this batch = 0.0882656587424141\n",
      "Cost on val dataset after 446 epochs is = 0.10083564767910137\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.10083564767910137\n",
      "learning rate for this epoch =  0.10880185244406208\n",
      "Error on this batch = 0.056122517470969024\n",
      "Error on this batch = 0.08817951674110301\n",
      "Cost on val dataset after 447 epochs is = 0.10078220716051936\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.10078220716051936\n",
      "learning rate for this epoch =  0.10874095017981981\n",
      "Error on this batch = 0.05605102085871783\n",
      "Error on this batch = 0.08809367279993775\n",
      "Cost on val dataset after 448 epochs is = 0.10072893362521027\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.10072893362521027\n",
      "learning rate for this epoch =  0.10868021798624786\n",
      "Error on this batch = 0.055979755493784956\n",
      "Error on this batch = 0.08800812557675577\n",
      "Cost on val dataset after 449 epochs is = 0.10067582617018243\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.10067582617018243\n",
      "learning rate for this epoch =  0.10861965501038574\n",
      "Error on this batch = 0.05590872040834029\n",
      "Error on this batch = 0.08792287373144418\n",
      "Cost on val dataset after 450 epochs is = 0.10062288389927943\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.10062288389927943\n",
      "learning rate for this epoch =  0.10855926040543842\n",
      "Error on this batch = 0.05583791463472938\n",
      "Error on this batch = 0.08783791592582581\n",
      "Cost on val dataset after 451 epochs is = 0.10057010592311783\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.10057010592311783\n",
      "learning rate for this epoch =  0.1084990333307181\n",
      "Error on this batch = 0.05576733720549738\n",
      "Error on this batch = 0.08775325082355155\n",
      "Cost on val dataset after 452 epochs is = 0.10051749135902603\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.10051749135902603\n",
      "learning rate for this epoch =  0.10843897295158678\n",
      "Error on this batch = 0.05569698715341694\n",
      "Error on this batch = 0.0876688770899982\n",
      "Cost on val dataset after 453 epochs is = 0.1004650393309831\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.1004650393309831\n",
      "learning rate for this epoch =  0.10837907843939941\n",
      "Error on this batch = 0.05562686351151926\n",
      "Error on this batch = 0.0875847933921722\n",
      "Cost on val dataset after 454 epochs is = 0.10041274896955833\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.10041274896955833\n",
      "learning rate for this epoch =  0.10831934897144786\n",
      "Error on this batch = 0.05555696531312911\n",
      "Error on this batch = 0.08750099839861929\n",
      "Cost on val dataset after 455 epochs is = 0.10036061941185155\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.10036061941185155\n",
      "learning rate for this epoch =  0.10825978373090529\n",
      "Error on this batch = 0.05548729159190252\n",
      "Error on this batch = 0.08741749077933962\n",
      "Cost on val dataset after 456 epochs is = 0.1003086498014332\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.1003086498014332\n",
      "learning rate for this epoch =  0.10820038190677136\n",
      "Error on this batch = 0.05541784138186815\n",
      "Error on this batch = 0.0873342692057092\n",
      "Cost on val dataset after 457 epochs is = 0.10025683928828556\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.10025683928828556\n",
      "learning rate for this epoch =  0.10814114269381797\n",
      "Error on this batch = 0.055348613717471365\n",
      "Error on this batch = 0.08725133235040668\n",
      "Cost on val dataset after 458 epochs is = 0.10020518702874412\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.10020518702874412\n",
      "learning rate for this epoch =  0.10808206529253567\n",
      "Error on this batch = 0.05527960763362123\n",
      "Error on this batch = 0.08716867888734627\n",
      "Cost on val dataset after 459 epochs is = 0.10015369218543917\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.10015369218543917\n",
      "learning rate for this epoch =  0.10802314890908067\n",
      "Error on this batch = 0.055210822165740046\n",
      "Error on this batch = 0.08708630749161636\n",
      "Cost on val dataset after 460 epochs is = 0.10010235392723812\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.10010235392723812\n",
      "learning rate for this epoch =  0.10796439275522242\n",
      "Error on this batch = 0.055142256349815816\n",
      "Error on this batch = 0.08700421683942387\n",
      "Cost on val dataset after 461 epochs is = 0.10005117142918814\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.10005117142918814\n",
      "learning rate for this epoch =  0.10790579604829184\n",
      "Error on this batch = 0.05507390922245674\n",
      "Error on this batch = 0.08692240560804473\n",
      "Cost on val dataset after 462 epochs is = 0.10000014387245887\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.10000014387245887\n",
      "learning rate for this epoch =  0.10784735801113018\n",
      "Error on this batch = 0.055005779820948314\n",
      "Error on this batch = 0.08684087247577976\n",
      "Cost on val dataset after 463 epochs is = 0.099949270444286\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.099949270444286\n",
      "learning rate for this epoch =  0.10778907787203826\n",
      "Error on this batch = 0.054937867183312304\n",
      "Error on this batch = 0.08675961612191672\n",
      "Cost on val dataset after 464 epochs is = 0.09989855033791487\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.09989855033791487\n",
      "learning rate for this epoch =  0.1077309548647265\n",
      "Error on this batch = 0.054870170348368025\n",
      "Error on this batch = 0.08667863522669801\n",
      "Cost on val dataset after 465 epochs is = 0.09984798275254445\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.09984798275254445\n",
      "learning rate for this epoch =  0.10767298822826553\n",
      "Error on this batch = 0.05480268835579543\n",
      "Error on this batch = 0.08659792847129424\n",
      "Cost on val dataset after 466 epochs is = 0.09979756689327193\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.09979756689327193\n",
      "learning rate for this epoch =  0.10761517720703706\n",
      "Error on this batch = 0.054735420246199824\n",
      "Error on this batch = 0.08651749453778351\n",
      "Cost on val dataset after 467 epochs is = 0.09974730197103734\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.09974730197103734\n",
      "learning rate for this epoch =  0.10755752105068565\n",
      "Error on this batch = 0.05466836506117846\n",
      "Error on this batch = 0.0864373321091365\n",
      "Cost on val dataset after 468 epochs is = 0.0996971872025688\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.0996971872025688\n",
      "learning rate for this epoch =  0.1075000190140709\n",
      "Error on this batch = 0.054601521843388526\n",
      "Error on this batch = 0.0863574398692075\n",
      "Cost on val dataset after 469 epochs is = 0.09964722181032791\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.09964722181032791\n",
      "learning rate for this epoch =  0.10744267035722005\n",
      "Error on this batch = 0.054534889636616575\n",
      "Error on this batch = 0.086277816502731\n",
      "Cost on val dataset after 470 epochs is = 0.09959740502245583\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.09959740502245583\n",
      "learning rate for this epoch =  0.10738547434528128\n",
      "Error on this batch = 0.05446846748584933\n",
      "Error on this batch = 0.08619846069532397\n",
      "Cost on val dataset after 471 epochs is = 0.09954773607271931\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.09954773607271931\n",
      "learning rate for this epoch =  0.10732843024847744\n",
      "Error on this batch = 0.05440225443734553\n",
      "Error on this batch = 0.08611937113349404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 472 epochs is = 0.09949821420045747\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.09949821420045747\n",
      "learning rate for this epoch =  0.10727153734206031\n",
      "Error on this batch = 0.05433624953870902\n",
      "Error on this batch = 0.0860405465046533\n",
      "Cost on val dataset after 473 epochs is = 0.09944883865052873\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.09944883865052873\n",
      "learning rate for this epoch =  0.1072147949062655\n",
      "Error on this batch = 0.05427045183896258\n",
      "Error on this batch = 0.08596198549713761\n",
      "Cost on val dataset after 474 epochs is = 0.09939960867325832\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.09939960867325832\n",
      "learning rate for this epoch =  0.10715820222626746\n",
      "Error on this batch = 0.05420486038862296\n",
      "Error on this batch = 0.08588368680023177\n",
      "Cost on val dataset after 475 epochs is = 0.099350523524386\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.099350523524386\n",
      "learning rate for this epoch =  0.1071017585921356\n",
      "Error on this batch = 0.05413947423977631\n",
      "Error on this batch = 0.08580564910419995\n",
      "Cost on val dataset after 476 epochs is = 0.0993015824650145\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.0993015824650145\n",
      "learning rate for this epoch =  0.1070454632987902\n",
      "Error on this batch = 0.05407429244615445\n",
      "Error on this batch = 0.08572787110032191\n",
      "Cost on val dataset after 477 epochs is = 0.09925278476155798\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.09925278476155798\n",
      "learning rate for this epoch =  0.10698931564595948\n",
      "Error on this batch = 0.05400931406321172\n",
      "Error on this batch = 0.08565035148093467\n",
      "Cost on val dataset after 478 epochs is = 0.09920412968569144\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.09920412968569144\n",
      "learning rate for this epoch =  0.1069333149381366\n",
      "Error on this batch = 0.05394453814820214\n",
      "Error on this batch = 0.08557308893947922\n",
      "Cost on val dataset after 479 epochs is = 0.09915561651430015\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.09915561651430015\n",
      "learning rate for this epoch =  0.10687746048453738\n",
      "Error on this batch = 0.05387996376025713\n",
      "Error on this batch = 0.08549608217055323\n",
      "Cost on val dataset after 480 epochs is = 0.09910724452942989\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.09910724452942989\n",
      "learning rate for this epoch =  0.10682175159905852\n",
      "Error on this batch = 0.05381558996046337\n",
      "Error on this batch = 0.08541932986996843\n",
      "Cost on val dataset after 481 epochs is = 0.09905901301823754\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.09905901301823754\n",
      "learning rate for this epoch =  0.1067661876002362\n",
      "Error on this batch = 0.05375141581194089\n",
      "Error on this batch = 0.08534283073481348\n",
      "Cost on val dataset after 482 epochs is = 0.09901092127294227\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.09901092127294227\n",
      "learning rate for this epoch =  0.1067107678112051\n",
      "Error on this batch = 0.05368744037992123\n",
      "Error on this batch = 0.08526658346352207\n",
      "Cost on val dataset after 483 epochs is = 0.09896296859077713\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.09896296859077713\n",
      "learning rate for this epoch =  0.10665549155965787\n",
      "Error on this batch = 0.053623662731825644\n",
      "Error on this batch = 0.08519058675594574\n",
      "Cost on val dataset after 484 epochs is = 0.09891515427394167\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.09891515427394167\n",
      "learning rate for this epoch =  0.10660035817780521\n",
      "Error on this batch = 0.05356008193734324\n",
      "Error on this batch = 0.08511483931343189\n",
      "Cost on val dataset after 485 epochs is = 0.09886747762955439\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.09886747762955439\n",
      "learning rate for this epoch =  0.10654536700233612\n",
      "Error on this batch = 0.05349669706850893\n",
      "Error on this batch = 0.08503933983890667\n",
      "Cost on val dataset after 486 epochs is = 0.09881993796960659\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.09881993796960659\n",
      "learning rate for this epoch =  0.10649051737437876\n",
      "Error on this batch = 0.053433507199781245\n",
      "Error on this batch = 0.08496408703696215\n",
      "Cost on val dataset after 487 epochs is = 0.09877253461091628\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.09877253461091628\n",
      "learning rate for this epoch =  0.10643580863946162\n",
      "Error on this batch = 0.05337051140811973\n",
      "Error on this batch = 0.08488907961394869\n",
      "Cost on val dataset after 488 epochs is = 0.09872526687508336\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.09872526687508336\n",
      "learning rate for this epoch =  0.10638124014747533\n",
      "Error on this batch = 0.05330770877306206\n",
      "Error on this batch = 0.08481431627807146\n",
      "Cost on val dataset after 489 epochs is = 0.09867813408844466\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.09867813408844466\n",
      "learning rate for this epoch =  0.1063268112526345\n",
      "Error on this batch = 0.0532450983768006\n",
      "Error on this batch = 0.0847397957394913\n",
      "Cost on val dataset after 490 epochs is = 0.09863113558203059\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.09863113558203059\n",
      "learning rate for this epoch =  0.10627252131344038\n",
      "Error on this batch = 0.05318267930425869\n",
      "Error on this batch = 0.08466551671042986\n",
      "Cost on val dataset after 491 epochs is = 0.09858427069152183\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.09858427069152183\n",
      "learning rate for this epoch =  0.10621836969264359\n",
      "Error on this batch = 0.053120450643166034\n",
      "Error on this batch = 0.08459147790527888\n",
      "Cost on val dataset after 492 epochs is = 0.09853753875720728\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.09853753875720728\n",
      "learning rate for this epoch =  0.10616435575720744\n",
      "Error on this batch = 0.05305841148413361\n",
      "Error on this batch = 0.0845176780407132\n",
      "Cost on val dataset after 493 epochs is = 0.09849093912394255\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.09849093912394255\n",
      "learning rate for this epoch =  0.1061104788782716\n",
      "Error on this batch = 0.05299656092072788\n",
      "Error on this batch = 0.08444411583580749\n",
      "Cost on val dataset after 494 epochs is = 0.09844447114110925\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.09844447114110925\n",
      "learning rate for this epoch =  0.10605673843111615\n",
      "Error on this batch = 0.05293489804954437\n",
      "Error on this batch = 0.0843707900121568\n",
      "Cost on val dataset after 495 epochs is = 0.0983981341625753\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.0983981341625753\n",
      "learning rate for this epoch =  0.10600313379512592\n",
      "Error on this batch = 0.05287342197027991\n",
      "Error on this batch = 0.0842976992940003\n",
      "Cost on val dataset after 496 epochs is = 0.09835192754665596\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.09835192754665596\n",
      "learning rate for this epoch =  0.10594966435375541\n",
      "Error on this batch = 0.0528121317858047\n",
      "Error on this batch = 0.08422484240834799\n",
      "Cost on val dataset after 497 epochs is = 0.09830585065607582\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.09830585065607582\n",
      "learning rate for this epoch =  0.10589632949449389\n",
      "Error on this batch = 0.05275102660223288\n",
      "Error on this batch = 0.08415221808511093\n",
      "Cost on val dataset after 498 epochs is = 0.09825990285793168\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.09825990285793168\n",
      "learning rate for this epoch =  0.10584312860883092\n",
      "Error on this batch = 0.05269010552899232\n",
      "Error on this batch = 0.08407982505723391\n",
      "Cost on val dataset after 499 epochs is = 0.09821408352365632\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.09821408352365632\n",
      "learning rate for this epoch =  0.10579006109222232\n",
      "Error on this batch = 0.052629367678893486\n",
      "Error on this batch = 0.08400766206083045\n",
      "Cost on val dataset after 500 epochs is = 0.09816839202898338\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.09816839202898338\n",
      "learning rate for this epoch =  0.10573712634405641\n",
      "Error on this batch = 0.05256881216819686\n",
      "Error on this batch = 0.08393572783532084\n",
      "Cost on val dataset after 501 epochs is = 0.09812282775391311\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.09812282775391311\n",
      "learning rate for this epoch =  0.1056843237676206\n",
      "Error on this batch = 0.05250843811667967\n",
      "Error on this batch = 0.08386402112357175\n",
      "Cost on val dataset after 502 epochs is = 0.09807739008267904\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.09807739008267904\n",
      "learning rate for this epoch =  0.10563165277006838\n",
      "Error on this batch = 0.052448244647701085\n",
      "Error on this batch = 0.08379254067203797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 503 epochs is = 0.09803207840371585\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.09803207840371585\n",
      "learning rate for this epoch =  0.10557911276238661\n",
      "Error on this batch = 0.05238823088826632\n",
      "Error on this batch = 0.08372128523090547\n",
      "Cost on val dataset after 504 epochs is = 0.09798689210962809\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.09798689210962809\n",
      "learning rate for this epoch =  0.10552670315936317\n",
      "Error on this batch = 0.0523283959690895\n",
      "Error on this batch = 0.08365025355423658\n",
      "Cost on val dataset after 505 epochs is = 0.09794183059716018\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.09794183059716018\n",
      "learning rate for this epoch =  0.105474423379555\n",
      "Error on this batch = 0.05226873902465508\n",
      "Error on this batch = 0.08357944440011565\n",
      "Cost on val dataset after 506 epochs is = 0.0978968932671671\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.0978968932671671\n",
      "learning rate for this epoch =  0.10542227284525636\n",
      "Error on this batch = 0.052209259193278096\n",
      "Error on this batch = 0.0835088565307958\n",
      "Cost on val dataset after 507 epochs is = 0.09785207952458669\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.09785207952458669\n",
      "learning rate for this epoch =  0.10537025098246748\n",
      "Error on this batch = 0.052149955617162846\n",
      "Error on this batch = 0.08343848871284658\n",
      "Cost on val dataset after 508 epochs is = 0.09780738877841244\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.09780738877841244\n",
      "learning rate for this epoch =  0.10531835722086355\n",
      "Error on this batch = 0.05209082744246038\n",
      "Error on this batch = 0.08336833971730172\n",
      "Cost on val dataset after 509 epochs is = 0.09776282044166786\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.09776282044166786\n",
      "learning rate for this epoch =  0.10526659099376405\n",
      "Error on this batch = 0.05203187381932416\n",
      "Error on this batch = 0.08329840831980713\n",
      "Cost on val dataset after 510 epochs is = 0.09771837393138158\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.09771837393138158\n",
      "learning rate for this epoch =  0.10521495173810227\n",
      "Error on this batch = 0.051973093901964716\n",
      "Error on this batch = 0.08322869330076861\n",
      "Cost on val dataset after 511 epochs is = 0.09767404866856393\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.09767404866856393\n",
      "learning rate for this epoch =  0.10516343889439533\n",
      "Error on this batch = 0.05191448684870232\n",
      "Error on this batch = 0.08315919344549944\n",
      "Cost on val dataset after 512 epochs is = 0.0976298440781843\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.0976298440781843\n",
      "learning rate for this epoch =  0.10511205190671433\n",
      "Error on this batch = 0.051856051822018454\n",
      "Error on this batch = 0.08308990754436697\n",
      "Cost on val dataset after 513 epochs is = 0.0975857595891497\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.0975857595891497\n",
      "learning rate for this epoch =  0.10506079022265488\n",
      "Error on this batch = 0.0517977879886055\n",
      "Error on this batch = 0.08302083439293842\n",
      "Cost on val dataset after 514 epochs is = 0.0975417946342846\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.0975417946342846\n",
      "learning rate for this epoch =  0.10500965329330811\n",
      "Error on this batch = 0.05173969451941504\n",
      "Error on this batch = 0.08295197279212527\n",
      "Cost on val dataset after 515 epochs is = 0.09749794865031165\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.09749794865031165\n",
      "learning rate for this epoch =  0.10495864057323148\n",
      "Error on this batch = 0.05168177058970417\n",
      "Error on this batch = 0.08288332154832645\n",
      "Cost on val dataset after 516 epochs is = 0.09745422107783365\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.09745422107783365\n",
      "learning rate for this epoch =  0.10490775152042053\n",
      "Error on this batch = 0.0516240153790806\n",
      "Error on this batch = 0.0828148794735694\n",
      "Cost on val dataset after 517 epochs is = 0.09741061136131642\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.09741061136131642\n",
      "learning rate for this epoch =  0.10485698559628044\n",
      "Error on this batch = 0.051566428071545836\n",
      "Error on this batch = 0.08274664538564952\n",
      "Cost on val dataset after 518 epochs is = 0.09736711894907317\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.09736711894907317\n",
      "learning rate for this epoch =  0.10480634226559798\n",
      "Error on this batch = 0.05150900785553669\n",
      "Error on this batch = 0.08267861810826668\n",
      "Cost on val dataset after 519 epochs is = 0.09732374329324939\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.09732374329324939\n",
      "learning rate for this epoch =  0.10475582099651397\n",
      "Error on this batch = 0.05145175392396519\n",
      "Error on this batch = 0.08261079647115988\n",
      "Cost on val dataset after 520 epochs is = 0.09728048384980918\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.09728048384980918\n",
      "learning rate for this epoch =  0.10470542126049572\n",
      "Error on this batch = 0.05139466547425669\n",
      "Error on this batch = 0.08254317931023857\n",
      "Cost on val dataset after 521 epochs is = 0.09723734007852258\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.09723734007852258\n",
      "learning rate for this epoch =  0.10465514253230984\n",
      "Error on this batch = 0.051337741708386356\n",
      "Error on this batch = 0.08247576546771117\n",
      "Cost on val dataset after 522 epochs is = 0.09719431144295386\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.09719431144295386\n",
      "learning rate for this epoch =  0.10460498428999554\n",
      "Error on this batch = 0.05128098183291373\n",
      "Error on this batch = 0.08240855379221017\n",
      "Cost on val dataset after 523 epochs is = 0.09715139741045062\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.09715139741045062\n",
      "learning rate for this epoch =  0.10455494601483782\n",
      "Error on this batch = 0.05122438505901584\n",
      "Error on this batch = 0.08234154313891383\n",
      "Cost on val dataset after 524 epochs is = 0.09710859745213439\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.09710859745213439\n",
      "learning rate for this epoch =  0.10450502719134125\n",
      "Error on this batch = 0.051167950602518206\n",
      "Error on this batch = 0.0822747323696639\n",
      "Cost on val dataset after 525 epochs is = 0.09706591104289168\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.09706591104289168\n",
      "learning rate for this epoch =  0.10445522730720382\n",
      "Error on this batch = 0.05111167768392437\n",
      "Error on this batch = 0.08220812035307958\n",
      "Cost on val dataset after 526 epochs is = 0.0970233376613661\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.0970233376613661\n",
      "learning rate for this epoch =  0.10440554585329116\n",
      "Error on this batch = 0.05105556552844359\n",
      "Error on this batch = 0.08214170596466716\n",
      "Cost on val dataset after 527 epochs is = 0.09698087678995168\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.09698087678995168\n",
      "learning rate for this epoch =  0.10435598232361096\n",
      "Error on this batch = 0.05099961336601657\n",
      "Error on this batch = 0.08207548808692522\n",
      "Cost on val dataset after 528 epochs is = 0.09693852791478659\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.09693852791478659\n",
      "learning rate for this epoch =  0.10430653621528765\n",
      "Error on this batch = 0.050943820431339826\n",
      "Error on this batch = 0.08200946560944558\n",
      "Cost on val dataset after 529 epochs is = 0.09689629052574802\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.09689629052574802\n",
      "learning rate for this epoch =  0.10425720702853739\n",
      "Error on this batch = 0.050888185963887785\n",
      "Error on this batch = 0.08194363742900912\n",
      "Cost on val dataset after 530 epochs is = 0.09685416411644786\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.09685416411644786\n",
      "learning rate for this epoch =  0.10420799426664315\n",
      "Error on this batch = 0.05083270920793364\n",
      "Error on this batch = 0.08187800244967679\n",
      "Cost on val dataset after 531 epochs is = 0.09681214818422892\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.09681214818422892\n",
      "learning rate for this epoch =  0.10415889743593033\n",
      "Error on this batch = 0.05077738941256795\n",
      "Error on this batch = 0.08181255958287591\n",
      "Cost on val dataset after 532 epochs is = 0.09677024223016219\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.09677024223016219\n",
      "learning rate for this epoch =  0.10410991604574225\n",
      "Error on this batch = 0.05072222583171592\n",
      "Error on this batch = 0.08174730774748074\n",
      "Cost on val dataset after 533 epochs is = 0.09672844575904453\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.09672844575904453\n",
      "learning rate for this epoch =  0.10406104960841617\n",
      "Error on this batch = 0.050667217724152634\n",
      "Error on this batch = 0.08168224586988825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 534 epochs is = 0.09668675827939725\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.09668675827939725\n",
      "learning rate for this epoch =  0.1040122976392594\n",
      "Error on this batch = 0.05061236435351666\n",
      "Error on this batch = 0.08161737288408795\n",
      "Cost on val dataset after 535 epochs is = 0.09664517930346496\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.09664517930346496\n",
      "learning rate for this epoch =  0.10396365965652576\n",
      "Error on this batch = 0.050557664988322044\n",
      "Error on this batch = 0.08155268773172686\n",
      "Cost on val dataset after 536 epochs is = 0.09660370834721553\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.09660370834721553\n",
      "learning rate for this epoch =  0.10391513518139214\n",
      "Error on this batch = 0.0505031189019683\n",
      "Error on this batch = 0.08148818936216821\n",
      "Cost on val dataset after 537 epochs is = 0.09656234493033995\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.09656234493033995\n",
      "learning rate for this epoch =  0.10386672373793533\n",
      "Error on this batch = 0.050448725372748984\n",
      "Error on this batch = 0.08142387673254495\n",
      "Cost on val dataset after 538 epochs is = 0.09652108857625319\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.09652108857625319\n",
      "learning rate for this epoch =  0.10381842485310916\n",
      "Error on this batch = 0.050394483683858536\n",
      "Error on this batch = 0.08135974880780741\n",
      "Cost on val dataset after 539 epochs is = 0.09647993881209514\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.09647993881209514\n",
      "learning rate for this epoch =  0.10377023805672174\n",
      "Error on this batch = 0.0503403931233973\n",
      "Error on this batch = 0.0812958045607652\n",
      "Cost on val dataset after 540 epochs is = 0.09643889516873211\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.09643889516873211\n",
      "learning rate for this epoch =  0.10372216288141306\n",
      "Error on this batch = 0.050286452984375014\n",
      "Error on this batch = 0.08123204297212326\n",
      "Cost on val dataset after 541 epochs is = 0.09639795718075861\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.09639795718075861\n",
      "learning rate for this epoch =  0.10367419886263263\n",
      "Error on this batch = 0.05023266256471271\n",
      "Error on this batch = 0.08116846303051248\n",
      "Cost on val dataset after 542 epochs is = 0.09635712438649953\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.09635712438649953\n",
      "learning rate for this epoch =  0.10362634553861746\n",
      "Error on this batch = 0.05017902116724292\n",
      "Error on this batch = 0.08110506373251405\n",
      "Cost on val dataset after 543 epochs is = 0.09631639632801221\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.09631639632801221\n",
      "learning rate for this epoch =  0.10357860245037034\n",
      "Error on this batch = 0.05012552809970833\n",
      "Error on this batch = 0.08104184408267863\n",
      "Cost on val dataset after 544 epochs is = 0.09627577255108925\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.09627577255108925\n",
      "learning rate for this epoch =  0.10353096914163801\n",
      "Error on this batch = 0.05007218267475889\n",
      "Error on this batch = 0.0809788030935394\n",
      "Cost on val dataset after 545 epochs is = 0.09623525260526089\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.09623525260526089\n",
      "learning rate for this epoch =  0.10348344515888994\n",
      "Error on this batch = 0.05001898420994742\n",
      "Error on this batch = 0.08091593978561971\n",
      "Cost on val dataset after 546 epochs is = 0.09619483604379783\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.09619483604379783\n",
      "learning rate for this epoch =  0.10343603005129703\n",
      "Error on this batch = 0.049965932027723564\n",
      "Error on this batch = 0.0808532531874349\n",
      "Cost on val dataset after 547 epochs is = 0.09615452242371393\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.09615452242371393\n",
      "learning rate for this epoch =  0.1033887233707106\n",
      "Error on this batch = 0.04991302545542643\n",
      "Error on this batch = 0.08079074233548912\n",
      "Cost on val dataset after 548 epochs is = 0.096114311305769\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.096114311305769\n",
      "learning rate for this epoch =  0.10334152467164161\n",
      "Error on this batch = 0.04986026382527569\n",
      "Error on this batch = 0.0807284062742661\n",
      "Cost on val dataset after 549 epochs is = 0.09607420225447134\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.09607420225447134\n",
      "learning rate for this epoch =  0.10329443351124007\n",
      "Error on this batch = 0.04980764647436127\n",
      "Error on this batch = 0.08066624405621507\n",
      "Cost on val dataset after 550 epochs is = 0.09603419483808039\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.09603419483808039\n",
      "learning rate for this epoch =  0.10324744944927464\n",
      "Error on this batch = 0.049755172744631614\n",
      "Error on this batch = 0.08060425474173144\n",
      "Cost on val dataset after 551 epochs is = 0.09599428862860887\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.09599428862860887\n",
      "learning rate for this epoch =  0.10320057204811232\n",
      "Error on this batch = 0.04970284198288065\n",
      "Error on this batch = 0.08054243739913224\n",
      "Cost on val dataset after 552 epochs is = 0.09595448320182512\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.09595448320182512\n",
      "learning rate for this epoch =  0.10315380087269863\n",
      "Error on this batch = 0.049650653540733336\n",
      "Error on this batch = 0.08048079110462669\n",
      "Cost on val dataset after 553 epochs is = 0.09591477813725477\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.09591477813725477\n",
      "learning rate for this epoch =  0.10310713549053749\n",
      "Error on this batch = 0.04959860677462991\n",
      "Error on this batch = 0.0804193149422823\n",
      "Cost on val dataset after 554 epochs is = 0.09587517301818226\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.09587517301818226\n",
      "learning rate for this epoch =  0.10306057547167191\n",
      "Error on this batch = 0.049546701045809056\n",
      "Error on this batch = 0.08035800800398576\n",
      "Cost on val dataset after 555 epochs is = 0.09583566743165205\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.09583566743165205\n",
      "learning rate for this epoch =  0.1030141203886643\n",
      "Error on this batch = 0.04949493572028945\n",
      "Error on this batch = 0.08029686938940002\n",
      "Cost on val dataset after 556 epochs is = 0.09579626096846913\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.09579626096846913\n",
      "learning rate for this epoch =  0.10296776981657725\n",
      "Error on this batch = 0.0494433101688504\n",
      "Error on this batch = 0.08023589820591658\n",
      "Cost on val dataset after 557 epochs is = 0.09575695322319941\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.09575695322319941\n",
      "learning rate for this epoch =  0.10292152333295448\n",
      "Error on this batch = 0.049391823767011386\n",
      "Error on this batch = 0.08017509356860397\n",
      "Cost on val dataset after 558 epochs is = 0.09571774379416921\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.09571774379416921\n",
      "learning rate for this epoch =  0.10287538051780193\n",
      "Error on this batch = 0.04934047589500998\n",
      "Error on this batch = 0.08011445460015221\n",
      "Cost on val dataset after 559 epochs is = 0.09567863228346447\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.09567863228346447\n",
      "learning rate for this epoch =  0.10282934095356899\n",
      "Error on this batch = 0.049289265937779304\n",
      "Error on this batch = 0.08005398043081352\n",
      "Cost on val dataset after 560 epochs is = 0.09563961829692919\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.09563961829692919\n",
      "learning rate for this epoch =  0.10278340422512992\n",
      "Error on this batch = 0.04923819328492388\n",
      "Error on this batch = 0.07999367019833957\n",
      "Cost on val dataset after 561 epochs is = 0.09560070144416316\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.09560070144416316\n",
      "learning rate for this epoch =  0.10273756991976561\n",
      "Error on this batch = 0.04918725733069474\n",
      "Error on this batch = 0.07993352304791534\n",
      "Cost on val dataset after 562 epochs is = 0.0955618813385191\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.0955618813385191\n",
      "learning rate for this epoch =  0.10269183762714515\n",
      "Error on this batch = 0.04913645747396338\n",
      "Error on this batch = 0.0798735381320898\n",
      "Cost on val dataset after 563 epochs is = 0.09552315759709906\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.09552315759709906\n",
      "learning rate for this epoch =  0.10264620693930798\n",
      "Error on this batch = 0.04908579311819491\n",
      "Error on this batch = 0.0798137146107038\n",
      "Cost on val dataset after 564 epochs is = 0.09548452984074975\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.09548452984074975\n",
      "learning rate for this epoch =  0.10260067745064594\n",
      "Error on this batch = 0.04903526367142003\n",
      "Error on this batch = 0.0797540516508151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 565 epochs is = 0.09544599769405729\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.09544599769405729\n",
      "learning rate for this epoch =  0.10255524875788552\n",
      "Error on this batch = 0.0489848685462063\n",
      "Error on this batch = 0.079694548426621\n",
      "Cost on val dataset after 566 epochs is = 0.09540756078534124\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.09540756078534124\n",
      "learning rate for this epoch =  0.10250992046007043\n",
      "Error on this batch = 0.04893460715962851\n",
      "Error on this batch = 0.07963520411937848\n",
      "Cost on val dataset after 567 epochs is = 0.09536921874664708\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.09536921874664708\n",
      "learning rate for this epoch =  0.10246469215854406\n",
      "Error on this batch = 0.04888447893323813\n",
      "Error on this batch = 0.07957601791732241\n",
      "Cost on val dataset after 568 epochs is = 0.09533097121373846\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.09533097121373846\n",
      "learning rate for this epoch =  0.10241956345693246\n",
      "Error on this batch = 0.04883448329303193\n",
      "Error on this batch = 0.07951698901558187\n",
      "Cost on val dataset after 569 epochs is = 0.09529281782608795\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.09529281782608795\n",
      "learning rate for this epoch =  0.1023745339611271\n",
      "Error on this batch = 0.04878461966942016\n",
      "Error on this batch = 0.07945811661609452\n",
      "Cost on val dataset after 570 epochs is = 0.09525475822686712\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.09525475822686712\n",
      "learning rate for this epoch =  0.10232960327926806\n",
      "Error on this batch = 0.04873488749719351\n",
      "Error on this batch = 0.07939939992751978\n",
      "Cost on val dataset after 571 epochs is = 0.09521679206293521\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.09521679206293521\n",
      "learning rate for this epoch =  0.10228477102172728\n",
      "Error on this batch = 0.048685286215489704\n",
      "Error on this batch = 0.07934083816515057\n",
      "Cost on val dataset after 572 epochs is = 0.09517891898482707\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.09517891898482707\n",
      "learning rate for this epoch =  0.10224003680109194\n",
      "Error on this batch = 0.048635815267759314\n",
      "Error on this batch = 0.07928243055082379\n",
      "Cost on val dataset after 573 epochs is = 0.09514113864673968\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.09514113864673968\n",
      "learning rate for this epoch =  0.10219540023214801\n",
      "Error on this batch = 0.04858647410173099\n",
      "Error on this batch = 0.07922417631283027\n",
      "Cost on val dataset after 574 epochs is = 0.09510345070651784\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.09510345070651784\n",
      "learning rate for this epoch =  0.10215086093186404\n",
      "Error on this batch = 0.04853726216937606\n",
      "Error on this batch = 0.07916607468582347\n",
      "Cost on val dataset after 575 epochs is = 0.09506585482563831\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.09506585482563831\n",
      "learning rate for this epoch =  0.10210641851937487\n",
      "Error on this batch = 0.04848817892687246\n",
      "Error on this batch = 0.0791081249107281\n",
      "Cost on val dataset after 576 epochs is = 0.09502835066919328\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.09502835066919328\n",
      "learning rate for this epoch =  0.10206207261596577\n",
      "Error on this batch = 0.048439223834568355\n",
      "Error on this batch = 0.07905032623464811\n",
      "Cost on val dataset after 577 epochs is = 0.09499093790587206\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.09499093790587206\n",
      "learning rate for this epoch =  0.10201782284505649\n",
      "Error on this batch = 0.048390396356945045\n",
      "Error on this batch = 0.07899267791077437\n",
      "Cost on val dataset after 578 epochs is = 0.09495361620794196\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.09495361620794196\n",
      "learning rate for this epoch =  0.10197366883218573\n",
      "Error on this batch = 0.04834169596257949\n",
      "Error on this batch = 0.07893517919829261\n",
      "Cost on val dataset after 579 epochs is = 0.09491638525122789\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.09491638525122789\n",
      "learning rate for this epoch =  0.1019296102049953\n",
      "Error on this batch = 0.04829312212410634\n",
      "Error on this batch = 0.07887782936229108\n",
      "Cost on val dataset after 580 epochs is = 0.09487924471509043\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.09487924471509043\n",
      "learning rate for this epoch =  0.10188564659321496\n",
      "Error on this batch = 0.048244674318179616\n",
      "Error on this batch = 0.07882062767366886\n",
      "Cost on val dataset after 581 epochs is = 0.09484219428240297\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.09484219428240297\n",
      "learning rate for this epoch =  0.10184177762864698\n",
      "Error on this batch = 0.048196352025433986\n",
      "Error on this batch = 0.0787635734090442\n",
      "Cost on val dataset after 582 epochs is = 0.0948052336395274\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.0948052336395274\n",
      "learning rate for this epoch =  0.10179800294515103\n",
      "Error on this batch = 0.04814815473044567\n",
      "Error on this batch = 0.07870666585066355\n",
      "Cost on val dataset after 583 epochs is = 0.09476836247628857\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.09476836247628857\n",
      "learning rate for this epoch =  0.10175432217862923\n",
      "Error on this batch = 0.04810008192169292\n",
      "Error on this batch = 0.07864990428631131\n",
      "Cost on val dataset after 584 epochs is = 0.09473158048594742\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.09473158048594742\n",
      "learning rate for this epoch =  0.10171073496701123\n",
      "Error on this batch = 0.048052133091516444\n",
      "Error on this batch = 0.07859328800922018\n",
      "Cost on val dataset after 585 epochs is = 0.0946948873651729\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.0946948873651729\n",
      "learning rate for this epoch =  0.10166724095023941\n",
      "Error on this batch = 0.04800430773607939\n",
      "Error on this batch = 0.07853681631798251\n",
      "Cost on val dataset after 586 epochs is = 0.0946582828140126\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.0946582828140126\n",
      "learning rate for this epoch =  0.10162383977025442\n",
      "Error on this batch = 0.047956605355327094\n",
      "Error on this batch = 0.07848048851646262\n",
      "Cost on val dataset after 587 epochs is = 0.09462176653586193\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.09462176653586193\n",
      "learning rate for this epoch =  0.10158053107098057\n",
      "Error on this batch = 0.047909025452946584\n",
      "Error on this batch = 0.07842430391371016\n",
      "Cost on val dataset after 588 epochs is = 0.09458533823743237\n",
      "Initial Cost on Val dataset for this epoch 588 = 0.09458533823743237\n",
      "learning rate for this epoch =  0.10153731449831156\n",
      "Error on this batch = 0.04786156753632617\n",
      "Error on this batch = 0.07836826182387464\n",
      "Cost on val dataset after 589 epochs is = 0.09454899762871809\n",
      "Initial Cost on Val dataset for this epoch 589 = 0.09454899762871809\n",
      "learning rate for this epoch =  0.1014941897000962\n",
      "Error on this batch = 0.047814231116514366\n",
      "Error on this batch = 0.0783123615661213\n",
      "Cost on val dataset after 590 epochs is = 0.09451274442296152\n",
      "Initial Cost on Val dataset for this epoch 590 = 0.09451274442296152\n",
      "learning rate for this epoch =  0.10145115632612439\n",
      "Error on this batch = 0.04776701570817929\n",
      "Error on this batch = 0.0782566024645482\n",
      "Cost on val dataset after 591 epochs is = 0.09447657833661753\n",
      "Initial Cost on Val dataset for this epoch 591 = 0.09447657833661753\n",
      "learning rate for this epoch =  0.10140821402811308\n",
      "Error on this batch = 0.04771992082956745\n",
      "Error on this batch = 0.07820098384810488\n",
      "Cost on val dataset after 592 epochs is = 0.0944404990893167\n",
      "Initial Cost on Val dataset for this epoch 592 = 0.0944404990893167\n",
      "learning rate for this epoch =  0.10136536245969245\n",
      "Error on this batch = 0.04767294600246271\n",
      "Error on this batch = 0.07814550505051208\n",
      "Cost on val dataset after 593 epochs is = 0.09440450640382687\n",
      "Initial Cost on Val dataset for this epoch 593 = 0.09440450640382687\n",
      "learning rate for this epoch =  0.10132260127639228\n",
      "Error on this batch = 0.04762609075214519\n",
      "Error on this batch = 0.07809016541018364\n",
      "Cost on val dataset after 594 epochs is = 0.09436860000601398\n",
      "Initial Cost on Val dataset for this epoch 594 = 0.09436860000601398\n",
      "learning rate for this epoch =  0.10127993013562818\n",
      "Error on this batch = 0.047579354607350036\n",
      "Error on this batch = 0.07803496427014922\n",
      "Cost on val dataset after 595 epochs is = 0.09433277962480148\n",
      "Initial Cost on Val dataset for this epoch 595 = 0.09433277962480148\n",
      "learning rate for this epoch =  0.10123734869668825\n",
      "Error on this batch = 0.04753273710022621\n",
      "Error on this batch = 0.07797990097797912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 596 epochs is = 0.09429704499212856\n",
      "Initial Cost on Val dataset for this epoch 596 = 0.09429704499212856\n",
      "learning rate for this epoch =  0.10119485662071964\n",
      "Error on this batch = 0.04748623776629552\n",
      "Error on this batch = 0.07792497488571058\n",
      "Cost on val dataset after 597 epochs is = 0.09426139584290745\n",
      "Initial Cost on Val dataset for this epoch 597 = 0.09426139584290745\n",
      "learning rate for this epoch =  0.10115245357071535\n",
      "Error on this batch = 0.04743985614441126\n",
      "Error on this batch = 0.07787018534977555\n",
      "Cost on val dataset after 598 epochs is = 0.0942258319149795\n",
      "Initial Cost on Val dataset for this epoch 598 = 0.0942258319149795\n",
      "learning rate for this epoch =  0.10111013921150111\n",
      "Error on this batch = 0.04739359177671737\n",
      "Error on this batch = 0.07781553173093057\n",
      "Cost on val dataset after 599 epochs is = 0.09419035294907036\n",
      "Initial Cost on Val dataset for this epoch 599 = 0.09419035294907036\n",
      "learning rate for this epoch =  0.1010679132097223\n",
      "Error on this batch = 0.04734744420860738\n",
      "Error on this batch = 0.0777610133941879\n",
      "Cost on val dataset after 600 epochs is = 0.0941549586887437\n",
      "Initial Cost on Val dataset for this epoch 600 = 0.0941549586887437\n",
      "learning rate for this epoch =  0.10102577523383117\n",
      "Error on this batch = 0.047301412988683594\n",
      "Error on this batch = 0.0777066297087486\n",
      "Cost on val dataset after 601 epochs is = 0.09411964888035454\n",
      "Initial Cost on Val dataset for this epoch 601 = 0.09411964888035454\n",
      "learning rate for this epoch =  0.10098372495407393\n",
      "Error on this batch = 0.04725549766871638\n",
      "Error on this batch = 0.07765238004793722\n",
      "Cost on val dataset after 602 epochs is = 0.09408442327300132\n",
      "Initial Cost on Val dataset for this epoch 602 = 0.09408442327300132\n",
      "learning rate for this epoch =  0.10094176204247814\n",
      "Error on this batch = 0.04720969780360363\n",
      "Error on this batch = 0.07759826378913819\n",
      "Cost on val dataset after 603 epochs is = 0.09404928161847691\n",
      "Initial Cost on Val dataset for this epoch 603 = 0.09404928161847691\n",
      "learning rate for this epoch =  0.10089988617284017\n",
      "Error on this batch = 0.047164012951330464\n",
      "Error on this batch = 0.07754428031373402\n",
      "Cost on val dataset after 604 epochs is = 0.09401422367121909\n",
      "Initial Cost on Val dataset for this epoch 604 = 0.09401422367121909\n",
      "learning rate for this epoch =  0.10085809702071269\n",
      "Error on this batch = 0.04711844267292893\n",
      "Error on this batch = 0.07749042900704516\n",
      "Cost on val dataset after 605 epochs is = 0.09397924918826002\n",
      "Initial Cost on Val dataset for this epoch 605 = 0.09397924918826002\n",
      "learning rate for this epoch =  0.10081639426339235\n",
      "Error on this batch = 0.04707298653243811\n",
      "Error on this batch = 0.07743670925827116\n",
      "Cost on val dataset after 606 epochs is = 0.09394435792917487\n",
      "Initial Cost on Val dataset for this epoch 606 = 0.09394435792917487\n",
      "learning rate for this epoch =  0.10077477757990758\n",
      "Error on this batch = 0.04702764409686444\n",
      "Error on this batch = 0.07738312046043433\n",
      "Cost on val dataset after 607 epochs is = 0.0939095496560299\n",
      "Initial Cost on Val dataset for this epoch 607 = 0.0939095496560299\n",
      "learning rate for this epoch =  0.10073324665100637\n",
      "Error on this batch = 0.04698241493614228\n",
      "Error on this batch = 0.07732966201032401\n",
      "Cost on val dataset after 608 epochs is = 0.09387482413332976\n",
      "Initial Cost on Val dataset for this epoch 608 = 0.09387482413332976\n",
      "learning rate for this epoch =  0.10069180115914433\n",
      "Error on this batch = 0.04693729862309463\n",
      "Error on this batch = 0.07727633330844327\n",
      "Cost on val dataset after 609 epochs is = 0.09384018112796405\n",
      "Initial Cost on Val dataset for this epoch 609 = 0.09384018112796405\n",
      "learning rate for this epoch =  0.1006504407884727\n",
      "Error on this batch = 0.046892294733394346\n",
      "Error on this batch = 0.07722313375895669\n",
      "Cost on val dataset after 610 epochs is = 0.09380562040915363\n",
      "Initial Cost on Val dataset for this epoch 610 = 0.09380562040915363\n",
      "learning rate for this epoch =  0.10060916522482655\n",
      "Error on this batch = 0.046847402845525486\n",
      "Error on this batch = 0.07717006276964002\n",
      "Cost on val dataset after 611 epochs is = 0.09377114174839597\n",
      "Initial Cost on Val dataset for this epoch 611 = 0.09377114174839597\n",
      "learning rate for this epoch =  0.10056797415571314\n",
      "Error on this batch = 0.04680262254074521\n",
      "Error on this batch = 0.07711711975183104\n",
      "Cost on val dataset after 612 epochs is = 0.09373674491941032\n",
      "Initial Cost on Val dataset for this epoch 612 = 0.09373674491941032\n",
      "learning rate for this epoch =  0.10052686727030014\n",
      "Error on this batch = 0.04675795340304574\n",
      "Error on this batch = 0.07706430412038216\n",
      "Cost on val dataset after 613 epochs is = 0.09370242969808251\n",
      "Initial Cost on Val dataset for this epoch 613 = 0.09370242969808251\n",
      "learning rate for this epoch =  0.10048584425940424\n",
      "Error on this batch = 0.04671339501911685\n",
      "Error on this batch = 0.07701161529361437\n",
      "Cost on val dataset after 614 epochs is = 0.09366819586240911\n",
      "Initial Cost on Val dataset for this epoch 614 = 0.09366819586240911\n",
      "learning rate for this epoch =  0.10044490481547967\n",
      "Error on this batch = 0.046668946978308784\n",
      "Error on this batch = 0.07695905269327247\n",
      "Cost on val dataset after 615 epochs is = 0.09363404319244148\n",
      "Initial Cost on Val dataset for this epoch 615 = 0.09363404319244148\n",
      "learning rate for this epoch =  0.10040404863260693\n",
      "Error on this batch = 0.04662460887259544\n",
      "Error on this batch = 0.07690661574448182\n",
      "Cost on val dataset after 616 epochs is = 0.09359997147022954\n",
      "Initial Cost on Val dataset for this epoch 616 = 0.09359997147022954\n",
      "learning rate for this epoch =  0.10036327540648149\n",
      "Error on this batch = 0.046580380296538\n",
      "Error on this batch = 0.07685430387570634\n",
      "Cost on val dataset after 617 epochs is = 0.09356598047976546\n",
      "Initial Cost on Val dataset for this epoch 617 = 0.09356598047976546\n",
      "learning rate for this epoch =  0.10032258483440272\n",
      "Error on this batch = 0.04653626084724902\n",
      "Error on this batch = 0.07680211651870775\n",
      "Cost on val dataset after 618 epochs is = 0.09353207000692687\n",
      "Initial Cost on Val dataset for this epoch 618 = 0.09353207000692687\n",
      "learning rate for this epoch =  0.10028197661526282\n",
      "Error on this batch = 0.046492250124356926\n",
      "Error on this batch = 0.0767500531085062\n",
      "Cost on val dataset after 619 epochs is = 0.09349823983942053\n",
      "Initial Cost on Val dataset for this epoch 619 = 0.09349823983942053\n",
      "learning rate for this epoch =  0.10024145044953589\n",
      "Error on this batch = 0.04644834772997088\n",
      "Error on this batch = 0.07669811308334165\n",
      "Cost on val dataset after 620 epochs is = 0.09346448976672539\n",
      "Initial Cost on Val dataset for this epoch 620 = 0.09346448976672539\n",
      "learning rate for this epoch =  0.10020100603926707\n",
      "Error on this batch = 0.04640455326864622\n",
      "Error on this batch = 0.07664629588463696\n",
      "Cost on val dataset after 621 epochs is = 0.09343081958003618\n",
      "Initial Cost on Val dataset for this epoch 621 = 0.09343081958003618\n",
      "learning rate for this epoch =  0.1001606430880618\n",
      "Error on this batch = 0.04636086634735035\n",
      "Error on this batch = 0.07659460095696156\n",
      "Cost on val dataset after 622 epochs is = 0.093397229072207\n",
      "Initial Cost on Val dataset for this epoch 622 = 0.093397229072207\n",
      "learning rate for this epoch =  0.10012036130107511\n",
      "Error on this batch = 0.046317286575428974\n",
      "Error on this batch = 0.07654302774799641\n",
      "Cost on val dataset after 623 epochs is = 0.09336371803769458\n",
      "Initial Cost on Val dataset for this epoch 623 = 0.09336371803769458\n",
      "learning rate for this epoch =  0.10008016038500113\n",
      "Error on this batch = 0.04627381356457301\n",
      "Error on this batch = 0.07649157570850004\n",
      "Cost on val dataset after 624 epochs is = 0.09333028627250267\n",
      "Initial Cost on Val dataset for this epoch 624 = 0.09333028627250267\n",
      "learning rate for this epoch =  0.10004004004806248\n",
      "Error on this batch = 0.04623044692878582\n",
      "Error on this batch = 0.07644024429227511\n",
      "Cost on val dataset after 625 epochs is = 0.09329693357412591\n",
      "Initial Cost on Val dataset for this epoch 625 = 0.09329693357412591\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 0.04618718628435102\n",
      "Error on this batch = 0.0763890329561365\n",
      "Cost on val dataset after 626 epochs is = 0.09326365974149431\n",
      "Initial Cost on Val dataset for this epoch 626 = 0.09326365974149431\n",
      "learning rate for this epoch =  0.09996003995206232\n",
      "Error on this batch = 0.046144031249800876\n",
      "Error on this batch = 0.07633794115987948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 627 epochs is = 0.09323046457491825\n",
      "Initial Cost on Val dataset for this epoch 627 = 0.09323046457491825\n",
      "learning rate for this epoch =  0.0999201596169957\n",
      "Error on this batch = 0.04610098144588509\n",
      "Error on this batch = 0.07628696836624949\n",
      "Cost on val dataset after 628 epochs is = 0.09319734787603373\n",
      "Initial Cost on Val dataset for this epoch 628 = 0.09319734787603373\n",
      "learning rate for this epoch =  0.09988035870903386\n",
      "Error on this batch = 0.04605803649554013\n",
      "Error on this batch = 0.07623611404091199\n",
      "Cost on val dataset after 629 epochs is = 0.09316430944774816\n",
      "Initial Cost on Val dataset for this epoch 629 = 0.09316430944774816\n",
      "learning rate for this epoch =  0.09984063694388798\n",
      "Error on this batch = 0.04601519602385912\n",
      "Error on this batch = 0.07618537765242339\n",
      "Cost on val dataset after 630 epochs is = 0.09313134909418677\n",
      "Initial Cost on Val dataset for this epoch 630 = 0.09313134909418677\n",
      "learning rate for this epoch =  0.09980099403873664\n",
      "Error on this batch = 0.045972459658062285\n",
      "Error on this batch = 0.0761347586722027\n",
      "Cost on val dataset after 631 epochs is = 0.09309846662063952\n",
      "Initial Cost on Val dataset for this epoch 631 = 0.09309846662063952\n",
      "learning rate for this epoch =  0.099761429712216\n",
      "Error on this batch = 0.04592982702746789\n",
      "Error on this batch = 0.07608425657450346\n",
      "Cost on val dataset after 632 epochs is = 0.09306566183350866\n",
      "Initial Cost on Val dataset for this epoch 632 = 0.09306566183350866\n",
      "learning rate for this epoch =  0.09972194368440992\n",
      "Error on this batch = 0.04588729776346366\n",
      "Error on this batch = 0.07603387083638667\n",
      "Cost on val dataset after 633 epochs is = 0.09303293454025713\n",
      "Initial Cost on Val dataset for this epoch 633 = 0.09303293454025713\n",
      "learning rate for this epoch =  0.09968253567684038\n",
      "Error on this batch = 0.0458448714994789\n",
      "Error on this batch = 0.07598360093769399\n",
      "Cost on val dataset after 634 epochs is = 0.09300028454935748\n",
      "Initial Cost on Val dataset for this epoch 634 = 0.09300028454935748\n",
      "learning rate for this epoch =  0.09964320541245761\n",
      "Error on this batch = 0.04580254787095703\n",
      "Error on this batch = 0.07593344636102152\n",
      "Cost on val dataset after 635 epochs is = 0.09296771167024179\n",
      "Initial Cost on Val dataset for this epoch 635 = 0.09296771167024179\n",
      "learning rate for this epoch =  0.09960395261563074\n",
      "Error on this batch = 0.04576032651532861\n",
      "Error on this batch = 0.07588340659169408\n",
      "Cost on val dataset after 636 epochs is = 0.09293521571325211\n",
      "Initial Cost on Val dataset for this epoch 636 = 0.09293521571325211\n",
      "learning rate for this epoch =  0.0995647770121382\n",
      "Error on this batch = 0.045718207071985144\n",
      "Error on this batch = 0.0758334811177399\n",
      "Cost on val dataset after 637 epochs is = 0.09290279648959225\n",
      "Initial Cost on Val dataset for this epoch 637 = 0.09290279648959225\n",
      "learning rate for this epoch =  0.0995256783291583\n",
      "Error on this batch = 0.04567618918225309\n",
      "Error on this batch = 0.07578366942986584\n",
      "Cost on val dataset after 638 epochs is = 0.09287045381128\n",
      "Initial Cost on Val dataset for this epoch 638 = 0.09287045381128\n",
      "learning rate for this epoch =  0.09948665629526\n",
      "Error on this batch = 0.045634272489368834\n",
      "Error on this batch = 0.07573397102143266\n",
      "Cost on val dataset after 639 epochs is = 0.09283818749110043\n",
      "Initial Cost on Val dataset for this epoch 639 = 0.09283818749110043\n",
      "learning rate for this epoch =  0.09944771064039355\n",
      "Error on this batch = 0.04559245663845369\n",
      "Error on this batch = 0.075684385388431\n",
      "Cost on val dataset after 640 epochs is = 0.09280599734256048\n",
      "Initial Cost on Val dataset for this epoch 640 = 0.09280599734256048\n",
      "learning rate for this epoch =  0.09940884109588133\n",
      "Error on this batch = 0.045550741276489934\n",
      "Error on this batch = 0.07563491202945744\n",
      "Cost on val dataset after 641 epochs is = 0.09277388317984407\n",
      "Initial Cost on Val dataset for this epoch 641 = 0.09277388317984407\n",
      "learning rate for this epoch =  0.09937004739440881\n",
      "Error on this batch = 0.04550912605229703\n",
      "Error on this batch = 0.0755855504456909\n",
      "Cost on val dataset after 642 epochs is = 0.09274184481776855\n",
      "Initial Cost on Val dataset for this epoch 642 = 0.09274184481776855\n",
      "learning rate for this epoch =  0.09933132927001546\n",
      "Error on this batch = 0.04546761061650862\n",
      "Error on this batch = 0.07553630014086936\n",
      "Cost on val dataset after 643 epochs is = 0.09270988207174218\n",
      "Initial Cost on Val dataset for this epoch 643 = 0.09270988207174218\n",
      "learning rate for this epoch =  0.09929268645808582\n",
      "Error on this batch = 0.045426194621549815\n",
      "Error on this batch = 0.07548716062126663\n",
      "Cost on val dataset after 644 epochs is = 0.09267799475772268\n",
      "Initial Cost on Val dataset for this epoch 644 = 0.09267799475772268\n",
      "learning rate for this epoch =  0.09925411869534059\n",
      "Error on this batch = 0.045384877721615195\n",
      "Error on this batch = 0.07543813139566957\n",
      "Cost on val dataset after 645 epochs is = 0.09264618269217689\n",
      "Initial Cost on Val dataset for this epoch 645 = 0.09264618269217689\n",
      "learning rate for this epoch =  0.0992156257198279\n",
      "Error on this batch = 0.04534365957264727\n",
      "Error on this batch = 0.07538921197535542\n",
      "Cost on val dataset after 646 epochs is = 0.0926144456920416\n",
      "Initial Cost on Val dataset for this epoch 646 = 0.0926144456920416\n",
      "learning rate for this epoch =  0.09917720727091442\n",
      "Error on this batch = 0.04530253983231544\n",
      "Error on this batch = 0.07534040187406893\n",
      "Cost on val dataset after 647 epochs is = 0.09258278357468545\n",
      "Initial Cost on Val dataset for this epoch 647 = 0.09258278357468545\n",
      "learning rate for this epoch =  0.09913886308927693\n",
      "Error on this batch = 0.045261518159995455\n",
      "Error on this batch = 0.07529170060800033\n",
      "Cost on val dataset after 648 epochs is = 0.09255119615787216\n",
      "Initial Cost on Val dataset for this epoch 648 = 0.09255119615787216\n",
      "learning rate for this epoch =  0.09910059291689342\n",
      "Error on this batch = 0.04522059421674933\n",
      "Error on this batch = 0.07524310769576292\n",
      "Cost on val dataset after 649 epochs is = 0.09251968325972484\n",
      "Initial Cost on Val dataset for this epoch 649 = 0.09251968325972484\n",
      "learning rate for this epoch =  0.09906239649703485\n",
      "Error on this batch = 0.04517976766530603\n",
      "Error on this batch = 0.07519462265837078\n",
      "Cost on val dataset after 650 epochs is = 0.0924882446986916\n",
      "Initial Cost on Val dataset for this epoch 650 = 0.0924882446986916\n",
      "learning rate for this epoch =  0.09902427357425653\n",
      "Error on this batch = 0.04513903817004211\n",
      "Error on this batch = 0.07514624501921685\n",
      "Cost on val dataset after 651 epochs is = 0.09245688029351219\n",
      "Initial Cost on Val dataset for this epoch 651 = 0.09245688029351219\n",
      "learning rate for this epoch =  0.09898622389438974\n",
      "Error on this batch = 0.04509840539696346\n",
      "Error on this batch = 0.07509797430405092\n",
      "Cost on val dataset after 652 epochs is = 0.09242558986318611\n",
      "Initial Cost on Val dataset for this epoch 652 = 0.09242558986318611\n",
      "learning rate for this epoch =  0.09894824720453346\n",
      "Error on this batch = 0.04505786901368703\n",
      "Error on this batch = 0.07504981004095777\n",
      "Cost on val dataset after 653 epochs is = 0.09239437322694176\n",
      "Initial Cost on Val dataset for this epoch 653 = 0.09239437322694176\n",
      "learning rate for this epoch =  0.09891034325304611\n",
      "Error on this batch = 0.04501742868942324\n",
      "Error on this batch = 0.07500175176033523\n",
      "Cost on val dataset after 654 epochs is = 0.09236323020420698\n",
      "Initial Cost on Val dataset for this epoch 654 = 0.09236323020420698\n",
      "learning rate for this epoch =  0.09887251178953727\n",
      "Error on this batch = 0.04497708409495884\n",
      "Error on this batch = 0.07495379899487242\n",
      "Cost on val dataset after 655 epochs is = 0.09233216061458065\n",
      "Initial Cost on Val dataset for this epoch 655 = 0.09233216061458065\n",
      "learning rate for this epoch =  0.09883475256485971\n",
      "Error on this batch = 0.04493683490264013\n",
      "Error on this batch = 0.07490595127952816\n",
      "Cost on val dataset after 656 epochs is = 0.09230116427780566\n",
      "Initial Cost on Val dataset for this epoch 656 = 0.09230116427780566\n",
      "learning rate for this epoch =  0.09879706533110119\n",
      "Error on this batch = 0.04489668078635675\n",
      "Error on this batch = 0.07485820815150912\n",
      "Cost on val dataset after 657 epochs is = 0.09227024101374315\n",
      "Initial Cost on Val dataset for this epoch 657 = 0.09227024101374315\n",
      "learning rate for this epoch =  0.09875944984157659\n",
      "Error on this batch = 0.04485662142152576\n",
      "Error on this batch = 0.07481056915024821\n",
      "Cost on val dataset after 658 epochs is = 0.09223939064234782\n",
      "Initial Cost on Val dataset for this epoch 658 = 0.09223939064234782\n",
      "learning rate for this epoch =  0.09872190585081982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04481665648507617\n",
      "Error on this batch = 0.07476303381738308\n",
      "Cost on val dataset after 659 epochs is = 0.09220861298364459\n",
      "Initial Cost on Val dataset for this epoch 659 = 0.09220861298364459\n",
      "learning rate for this epoch =  0.09868443311457611\n",
      "Error on this batch = 0.04477678565543397\n",
      "Error on this batch = 0.07471560169673441\n",
      "Cost on val dataset after 660 epochs is = 0.09217790785770649\n",
      "Initial Cost on Val dataset for this epoch 660 = 0.09217790785770649\n",
      "learning rate for this epoch =  0.09864703138979418\n",
      "Error on this batch = 0.044737008612507526\n",
      "Error on this batch = 0.07466827233428447\n",
      "Cost on val dataset after 661 epochs is = 0.09214727508463366\n",
      "Initial Cost on Val dataset for this epoch 661 = 0.09214727508463366\n",
      "learning rate for this epoch =  0.09860970043461836\n",
      "Error on this batch = 0.044697325037673145\n",
      "Error on this batch = 0.07462104527815552\n",
      "Cost on val dataset after 662 epochs is = 0.09211671448453367\n",
      "Initial Cost on Val dataset for this epoch 662 = 0.09211671448453367\n",
      "learning rate for this epoch =  0.09857244000838114\n",
      "Error on this batch = 0.04465773461376144\n",
      "Error on this batch = 0.07457392007858839\n",
      "Cost on val dataset after 663 epochs is = 0.09208622587750284\n",
      "Initial Cost on Val dataset for this epoch 663 = 0.09208622587750284\n",
      "learning rate for this epoch =  0.09853524987159529\n",
      "Error on this batch = 0.04461823702504367\n",
      "Error on this batch = 0.074526896287921\n",
      "Cost on val dataset after 664 epochs is = 0.09205580908360915\n",
      "Initial Cost on Val dataset for this epoch 664 = 0.09205580908360915\n",
      "learning rate for this epoch =  0.0984981297859465\n",
      "Error on this batch = 0.04457883195721864\n",
      "Error on this batch = 0.07447997346056696\n",
      "Cost on val dataset after 665 epochs is = 0.09202546392287561\n",
      "Initial Cost on Val dataset for this epoch 665 = 0.09202546392287561\n",
      "learning rate for this epoch =  0.09846107951428583\n",
      "Error on this batch = 0.044539519097399886\n",
      "Error on this batch = 0.07443315115299426\n",
      "Cost on val dataset after 666 epochs is = 0.0919951902152656\n",
      "Initial Cost on Val dataset for this epoch 666 = 0.0919951902152656\n",
      "learning rate for this epoch =  0.09842409882062221\n",
      "Error on this batch = 0.044500298134103264\n",
      "Error on this batch = 0.07438642892370383\n",
      "Cost on val dataset after 667 epochs is = 0.0919649877806686\n",
      "Initial Cost on Val dataset for this epoch 667 = 0.0919649877806686\n",
      "learning rate for this epoch =  0.09838718747011513\n",
      "Error on this batch = 0.04446116875723472\n",
      "Error on this batch = 0.07433980633320834\n",
      "Cost on val dataset after 668 epochs is = 0.09193485643888748\n",
      "Initial Cost on Val dataset for this epoch 668 = 0.09193485643888748\n",
      "learning rate for this epoch =  0.09835034522906724\n",
      "Error on this batch = 0.044422130658078575\n",
      "Error on this batch = 0.07429328294401107\n",
      "Cost on val dataset after 669 epochs is = 0.09190479600962678\n",
      "Initial Cost on Val dataset for this epoch 669 = 0.09190479600962678\n",
      "learning rate for this epoch =  0.09831357186491718\n",
      "Error on this batch = 0.04438318352928589\n",
      "Error on this batch = 0.07424685832058446\n",
      "Cost on val dataset after 670 epochs is = 0.09187480631248192\n",
      "Initial Cost on Val dataset for this epoch 670 = 0.09187480631248192\n",
      "learning rate for this epoch =  0.09827686714623232\n",
      "Error on this batch = 0.04434432706486339\n",
      "Error on this batch = 0.07420053202934934\n",
      "Cost on val dataset after 671 epochs is = 0.09184488716692953\n",
      "Initial Cost on Val dataset for this epoch 671 = 0.09184488716692953\n",
      "learning rate for this epoch =  0.09824023084270153\n",
      "Error on this batch = 0.04430556096016229\n",
      "Error on this batch = 0.07415430363865375\n",
      "Cost on val dataset after 672 epochs is = 0.09181503839231897\n",
      "Initial Cost on Val dataset for this epoch 672 = 0.09181503839231897\n",
      "learning rate for this epoch =  0.09820366272512825\n",
      "Error on this batch = 0.044266884911867914\n",
      "Error on this batch = 0.07410817271875192\n",
      "Cost on val dataset after 673 epochs is = 0.0917852598078645\n",
      "Initial Cost on Val dataset for this epoch 673 = 0.0917852598078645\n",
      "learning rate for this epoch =  0.0981671625654233\n",
      "Error on this batch = 0.0442282986179891\n",
      "Error on this batch = 0.07406213884178371\n",
      "Cost on val dataset after 674 epochs is = 0.0917555512326387\n",
      "Initial Cost on Val dataset for this epoch 674 = 0.0917555512326387\n",
      "learning rate for this epoch =  0.09813073013659797\n",
      "Error on this batch = 0.04418980177784811\n",
      "Error on this batch = 0.0740162015817535\n",
      "Cost on val dataset after 675 epochs is = 0.09172591248556676\n",
      "Initial Cost on Val dataset for this epoch 675 = 0.09172591248556676\n",
      "learning rate for this epoch =  0.09809436521275706\n",
      "Error on this batch = 0.04415139409207067\n",
      "Error on this batch = 0.07397036051450985\n",
      "Cost on val dataset after 676 epochs is = 0.09169634338542164\n",
      "Initial Cost on Val dataset for this epoch 676 = 0.09169634338542164\n",
      "learning rate for this epoch =  0.09805806756909202\n",
      "Error on this batch = 0.0441130752625764\n",
      "Error on this batch = 0.07392461521772485\n",
      "Cost on val dataset after 677 epochs is = 0.0916668437508202\n",
      "Initial Cost on Val dataset for this epoch 677 = 0.0916668437508202\n",
      "learning rate for this epoch =  0.09802183698187408\n",
      "Error on this batch = 0.04407484499256922\n",
      "Error on this batch = 0.07387896527087368\n",
      "Cost on val dataset after 678 epochs is = 0.09163741340022004\n",
      "Initial Cost on Val dataset for this epoch 678 = 0.09163741340022004\n",
      "learning rate for this epoch =  0.09798567322844758\n",
      "Error on this batch = 0.044036702986528294\n",
      "Error on this batch = 0.07383341025521448\n",
      "Cost on val dataset after 679 epochs is = 0.0916080521519175\n",
      "Initial Cost on Val dataset for this epoch 679 = 0.0916080521519175\n",
      "learning rate for this epoch =  0.09794957608722307\n",
      "Error on this batch = 0.043998648950198865\n",
      "Error on this batch = 0.07378794975376816\n",
      "Cost on val dataset after 680 epochs is = 0.0915787598240461\n",
      "Initial Cost on Val dataset for this epoch 680 = 0.0915787598240461\n",
      "learning rate for this epoch =  0.09791354533767088\n",
      "Error on this batch = 0.043960682590583375\n",
      "Error on this batch = 0.07374258335129856\n",
      "Cost on val dataset after 681 epochs is = 0.09154953623457598\n",
      "Initial Cost on Val dataset for this epoch 681 = 0.09154953623457598\n",
      "learning rate for this epoch =  0.09787758076031428\n",
      "Error on this batch = 0.043922803615933044\n",
      "Error on this batch = 0.07369731063429244\n",
      "Cost on val dataset after 682 epochs is = 0.09152038120131409\n",
      "Initial Cost on Val dataset for this epoch 682 = 0.09152038120131409\n",
      "learning rate for this epoch =  0.09784168213672302\n",
      "Error on this batch = 0.04388501173573909\n",
      "Error on this batch = 0.07365213119094016\n",
      "Cost on val dataset after 683 epochs is = 0.09149129454190509\n",
      "Initial Cost on Val dataset for this epoch 683 = 0.09149129454190509\n",
      "learning rate for this epoch =  0.09780584924950686\n",
      "Error on this batch = 0.04384730666072472\n",
      "Error on this batch = 0.07360704461111615\n",
      "Cost on val dataset after 684 epochs is = 0.09146227607383284\n",
      "Initial Cost on Val dataset for this epoch 684 = 0.09146227607383284\n",
      "learning rate for this epoch =  0.09777008188230901\n",
      "Error on this batch = 0.043809688102836704\n",
      "Error on this batch = 0.07356205048635961\n",
      "Cost on val dataset after 685 epochs is = 0.09143332561442277\n",
      "Initial Cost on Val dataset for this epoch 685 = 0.09143332561442277\n",
      "learning rate for this epoch =  0.09773437981979974\n",
      "Error on this batch = 0.0437721557752376\n",
      "Error on this batch = 0.07351714840985575\n",
      "Cost on val dataset after 686 epochs is = 0.09140444298084477\n",
      "Initial Cost on Val dataset for this epoch 686 = 0.09140444298084477\n",
      "learning rate for this epoch =  0.09769874284767002\n",
      "Error on this batch = 0.0437347093922978\n",
      "Error on this batch = 0.07347233797641682\n",
      "Cost on val dataset after 687 epochs is = 0.09137562799011673\n",
      "Initial Cost on Val dataset for this epoch 687 = 0.09137562799011673\n",
      "learning rate for this epoch =  0.0976631707526253\n",
      "Error on this batch = 0.04369734866958784\n",
      "Error on this batch = 0.07342761878246361\n",
      "Cost on val dataset after 688 epochs is = 0.09134688045910855\n",
      "Initial Cost on Val dataset for this epoch 688 = 0.09134688045910855\n",
      "learning rate for this epoch =  0.09762766332237903\n",
      "Error on this batch = 0.04366007332387084\n",
      "Error on this batch = 0.0733829904260073\n",
      "Cost on val dataset after 689 epochs is = 0.09131820020454703\n",
      "Initial Cost on Val dataset for this epoch 689 = 0.09131820020454703\n",
      "learning rate for this epoch =  0.09759222034564662\n",
      "Error on this batch = 0.04362288307309495\n",
      "Error on this batch = 0.07333845250663128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 690 epochs is = 0.091289587043021\n",
      "Initial Cost on Val dataset for this epoch 690 = 0.091289587043021\n",
      "learning rate for this epoch =  0.09755684161213918\n",
      "Error on this batch = 0.04358577763638607\n",
      "Error on this batch = 0.07329400462547342\n",
      "Cost on val dataset after 691 epochs is = 0.09126104079098704\n",
      "Initial Cost on Val dataset for this epoch 691 = 0.09126104079098704\n",
      "learning rate for this epoch =  0.09752152691255746\n",
      "Error on this batch = 0.04354875673404064\n",
      "Error on this batch = 0.0732496463852086\n",
      "Cost on val dataset after 692 epochs is = 0.09123256126477577\n",
      "Initial Cost on Val dataset for this epoch 692 = 0.09123256126477577\n",
      "learning rate for this epoch =  0.09748627603858566\n",
      "Error on this batch = 0.043511820087518346\n",
      "Error on this batch = 0.07320537739003158\n",
      "Cost on val dataset after 693 epochs is = 0.09120414828059853\n",
      "Initial Cost on Val dataset for this epoch 693 = 0.09120414828059853\n",
      "learning rate for this epoch =  0.09745108878288547\n",
      "Error on this batch = 0.043474967419435226\n",
      "Error on this batch = 0.07316119724563987\n",
      "Cost on val dataset after 694 epochs is = 0.09117580165455456\n",
      "Initial Cost on Val dataset for this epoch 694 = 0.09117580165455456\n",
      "learning rate for this epoch =  0.09741596493909016\n",
      "Error on this batch = 0.04343819845355659\n",
      "Error on this batch = 0.07311710555921741\n",
      "Cost on val dataset after 695 epochs is = 0.09114752120263842\n",
      "Initial Cost on Val dataset for this epoch 695 = 0.09114752120263842\n",
      "learning rate for this epoch =  0.09738090430179841\n",
      "Error on this batch = 0.04340151291479018\n",
      "Error on this batch = 0.0730731019394181\n",
      "Cost on val dataset after 696 epochs is = 0.09111930674074804\n",
      "Initial Cost on Val dataset for this epoch 696 = 0.09111930674074804\n",
      "learning rate for this epoch =  0.09734590666656863\n",
      "Error on this batch = 0.04336491052917928\n",
      "Error on this batch = 0.07302918599634999\n",
      "Cost on val dataset after 697 epochs is = 0.09109115808469301\n",
      "Initial Cost on Val dataset for this epoch 697 = 0.09109115808469301\n",
      "learning rate for this epoch =  0.09731097182991302\n",
      "Error on this batch = 0.04332839102389613\n",
      "Error on this batch = 0.07298535734155942\n",
      "Cost on val dataset after 698 epochs is = 0.09106307505020311\n",
      "Initial Cost on Val dataset for this epoch 698 = 0.09106307505020311\n",
      "learning rate for this epoch =  0.09727609958929176\n",
      "Error on this batch = 0.043291954127235084\n",
      "Error on this batch = 0.07294161558801603\n",
      "Cost on val dataset after 699 epochs is = 0.09103505745293743\n",
      "Initial Cost on Val dataset for this epoch 699 = 0.09103505745293743\n",
      "learning rate for this epoch =  0.09724128974310718\n",
      "Error on this batch = 0.04325559956860598\n",
      "Error on this batch = 0.07289796035009773\n",
      "Cost on val dataset after 700 epochs is = 0.09100710510849351\n",
      "Initial Cost on Val dataset for this epoch 700 = 0.09100710510849351\n",
      "learning rate for this epoch =  0.09720654209069819\n",
      "Error on this batch = 0.04321932707852771\n",
      "Error on this batch = 0.07285439124357597\n",
      "Cost on val dataset after 701 epochs is = 0.0909792178324168\n",
      "Initial Cost on Val dataset for this epoch 701 = 0.0909792178324168\n",
      "learning rate for this epoch =  0.09717185643233449\n",
      "Error on this batch = 0.04318313638862153\n",
      "Error on this batch = 0.07281090788560182\n",
      "Cost on val dataset after 702 epochs is = 0.09095139544021065\n",
      "Initial Cost on Val dataset for this epoch 702 = 0.09095139544021065\n",
      "learning rate for this epoch =  0.09713723256921088\n",
      "Error on this batch = 0.043147027231604594\n",
      "Error on this batch = 0.072767509894692\n",
      "Cost on val dataset after 703 epochs is = 0.09092363774734605\n",
      "Initial Cost on Val dataset for this epoch 703 = 0.09092363774734605\n",
      "learning rate for this epoch =  0.09710267030344186\n",
      "Error on this batch = 0.043110999341283665\n",
      "Error on this batch = 0.07272419689071546\n",
      "Cost on val dataset after 704 epochs is = 0.09089594456927212\n",
      "Initial Cost on Val dataset for this epoch 704 = 0.09089594456927212\n",
      "learning rate for this epoch =  0.09706816943805581\n",
      "Error on this batch = 0.0430750524525485\n",
      "Error on this batch = 0.07268096849488036\n",
      "Cost on val dataset after 705 epochs is = 0.09086831572142626\n",
      "Initial Cost on Val dataset for this epoch 705 = 0.09086831572142626\n",
      "learning rate for this epoch =  0.09703372977698975\n",
      "Error on this batch = 0.04303918630136552\n",
      "Error on this batch = 0.07263782432972142\n",
      "Cost on val dataset after 706 epochs is = 0.09084075101924494\n",
      "Initial Cost on Val dataset for this epoch 706 = 0.09084075101924494\n",
      "learning rate for this epoch =  0.09699935112508366\n",
      "Error on this batch = 0.043003400624771565\n",
      "Error on this batch = 0.0725947640190877\n",
      "Cost on val dataset after 707 epochs is = 0.0908132502781743\n",
      "Initial Cost on Val dataset for this epoch 707 = 0.0908132502781743\n",
      "learning rate for this epoch =  0.09696503328807513\n",
      "Error on this batch = 0.04296769516086733\n",
      "Error on this batch = 0.07255178718813063\n",
      "Cost on val dataset after 708 epochs is = 0.09078581331368112\n",
      "Initial Cost on Val dataset for this epoch 708 = 0.09078581331368112\n",
      "learning rate for this epoch =  0.09693077607259398\n",
      "Error on this batch = 0.04293206964881128\n",
      "Error on this batch = 0.07250889346329291\n",
      "Cost on val dataset after 709 epochs is = 0.09075843994126379\n",
      "Initial Cost on Val dataset for this epoch 709 = 0.09075843994126379\n",
      "learning rate for this epoch =  0.09689657928615694\n",
      "Error on this batch = 0.042896523828813184\n",
      "Error on this batch = 0.07246608247229709\n",
      "Cost on val dataset after 710 epochs is = 0.0907311299764634\n",
      "Initial Cost on Val dataset for this epoch 710 = 0.0907311299764634\n",
      "learning rate for this epoch =  0.09686244273716216\n",
      "Error on this batch = 0.04286105744212785\n",
      "Error on this batch = 0.0724233538441354\n",
      "Cost on val dataset after 711 epochs is = 0.09070388323487492\n",
      "Initial Cost on Val dataset for this epoch 711 = 0.09070388323487492\n",
      "learning rate for this epoch =  0.09682836623488422\n",
      "Error on this batch = 0.042825670231048926\n",
      "Error on this batch = 0.07238070720905926\n",
      "Cost on val dataset after 712 epochs is = 0.09067669953215854\n",
      "Initial Cost on Val dataset for this epoch 712 = 0.09067669953215854\n",
      "learning rate for this epoch =  0.09679434958946864\n",
      "Error on this batch = 0.04279036193890242\n",
      "Error on this batch = 0.07233814219856981\n",
      "Cost on val dataset after 713 epochs is = 0.09064957868405087\n",
      "Initial Cost on Val dataset for this epoch 713 = 0.09064957868405087\n",
      "learning rate for this epoch =  0.09676039261192684\n",
      "Error on this batch = 0.04275513231004066\n",
      "Error on this batch = 0.0722956584454086\n",
      "Cost on val dataset after 714 epochs is = 0.09062252050637642\n",
      "Initial Cost on Val dataset for this epoch 714 = 0.09062252050637642\n",
      "learning rate for this epoch =  0.09672649511413095\n",
      "Error on this batch = 0.04271998108983583\n",
      "Error on this batch = 0.07225325558354855\n",
      "Cost on val dataset after 715 epochs is = 0.09059552481505903\n",
      "Initial Cost on Val dataset for this epoch 715 = 0.09059552481505903\n",
      "learning rate for this epoch =  0.0966926569088086\n",
      "Error on this batch = 0.04268490802467385\n",
      "Error on this batch = 0.07221093324818577\n",
      "Cost on val dataset after 716 epochs is = 0.09056859142613309\n",
      "Initial Cost on Val dataset for this epoch 716 = 0.09056859142613309\n",
      "learning rate for this epoch =  0.09665887780953801\n",
      "Error on this batch = 0.04264991286194784\n",
      "Error on this batch = 0.07216869107573151\n",
      "Cost on val dataset after 717 epochs is = 0.09054172015575519\n",
      "Initial Cost on Val dataset for this epoch 717 = 0.09054172015575519\n",
      "learning rate for this epoch =  0.09662515763074277\n",
      "Error on this batch = 0.04261499535005212\n",
      "Error on this batch = 0.07212652870380469\n",
      "Cost on val dataset after 718 epochs is = 0.0905149108202155\n",
      "Initial Cost on Val dataset for this epoch 718 = 0.0905149108202155\n",
      "learning rate for this epoch =  0.09659149618768699\n",
      "Error on this batch = 0.04258015523837573\n",
      "Error on this batch = 0.07208444577122473\n",
      "Cost on val dataset after 719 epochs is = 0.09048816323594905\n",
      "Initial Cost on Val dataset for this epoch 719 = 0.09048816323594905\n",
      "learning rate for this epoch =  0.09655789329647017\n",
      "Error on this batch = 0.042545392277296125\n",
      "Error on this batch = 0.07204244191800507\n",
      "Cost on val dataset after 720 epochs is = 0.09046147721954721\n",
      "Initial Cost on Val dataset for this epoch 720 = 0.09046147721954721\n",
      "learning rate for this epoch =  0.09652434877402243\n",
      "Error on this batch = 0.04251070621817291\n",
      "Error on this batch = 0.07200051678534687\n",
      "Cost on val dataset after 721 epochs is = 0.09043485258776904\n",
      "Initial Cost on Val dataset for this epoch 721 = 0.09043485258776904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate for this epoch =  0.09649086243809947\n",
      "Error on this batch = 0.04247609681334148\n",
      "Error on this batch = 0.07195867001563326\n",
      "Cost on val dataset after 722 epochs is = 0.0904082891575526\n",
      "Initial Cost on Val dataset for this epoch 722 = 0.0904082891575526\n",
      "learning rate for this epoch =  0.09645743410727778\n",
      "Error on this batch = 0.04244156381610668\n",
      "Error on this batch = 0.07191690125242424\n",
      "Cost on val dataset after 723 epochs is = 0.09038178674602597\n",
      "Initial Cost on Val dataset for this epoch 723 = 0.09038178674602597\n",
      "learning rate for this epoch =  0.09642406360094986\n",
      "Error on this batch = 0.04240710698073641\n",
      "Error on this batch = 0.07187521014045156\n",
      "Cost on val dataset after 724 epochs is = 0.09035534517051884\n",
      "Initial Cost on Val dataset for this epoch 724 = 0.09035534517051884\n",
      "learning rate for this epoch =  0.09639075073931928\n",
      "Error on this batch = 0.04237272606245521\n",
      "Error on this batch = 0.07183359632561455\n",
      "Cost on val dataset after 725 epochs is = 0.09032896424857319\n",
      "Initial Cost on Val dataset for this epoch 725 = 0.09032896424857319\n",
      "learning rate for this epoch =  0.09635749534339606\n",
      "Error on this batch = 0.042338420817437966\n",
      "Error on this batch = 0.07179205945497606\n",
      "Cost on val dataset after 726 epochs is = 0.09030264379795451\n",
      "Initial Cost on Val dataset for this epoch 726 = 0.09030264379795451\n",
      "learning rate for this epoch =  0.0963242972349919\n",
      "Error on this batch = 0.04230419100280338\n",
      "Error on this batch = 0.07175059917675884\n",
      "Cost on val dataset after 727 epochs is = 0.09027638363666272\n",
      "Initial Cost on Val dataset for this epoch 727 = 0.09027638363666272\n",
      "learning rate for this epoch =  0.09629115623671548\n",
      "Error on this batch = 0.04227003637660758\n",
      "Error on this batch = 0.07170921514034262\n",
      "Cost on val dataset after 728 epochs is = 0.09025018358294302\n",
      "Initial Cost on Val dataset for this epoch 728 = 0.09025018358294302\n",
      "learning rate for this epoch =  0.09625807217196783\n",
      "Error on this batch = 0.042235956697837626\n",
      "Error on this batch = 0.07166790699626134\n",
      "Cost on val dataset after 729 epochs is = 0.09022404345529647\n",
      "Initial Cost on Val dataset for this epoch 729 = 0.09022404345529647\n",
      "learning rate for this epoch =  0.09622504486493763\n",
      "Error on this batch = 0.04220195172640507\n",
      "Error on this batch = 0.0716266743962009\n",
      "Cost on val dataset after 730 epochs is = 0.09019796307249077\n",
      "Initial Cost on Val dataset for this epoch 730 = 0.09019796307249077\n",
      "learning rate for this epoch =  0.09619207414059677\n",
      "Error on this batch = 0.04216802122313944\n",
      "Error on this batch = 0.0715855169929974\n",
      "Cost on val dataset after 731 epochs is = 0.09017194225357072\n",
      "Initial Cost on Val dataset for this epoch 731 = 0.09017194225357072\n",
      "learning rate for this epoch =  0.09615915982469565\n",
      "Error on this batch = 0.04213416494978167\n",
      "Error on this batch = 0.07154443444063567\n",
      "Cost on val dataset after 732 epochs is = 0.09014598081786855\n",
      "Initial Cost on Val dataset for this epoch 732 = 0.09014598081786855\n",
      "learning rate for this epoch =  0.09612630174375877\n",
      "Error on this batch = 0.04210038266897764\n",
      "Error on this batch = 0.07150342639424839\n",
      "Cost on val dataset after 733 epochs is = 0.09012007858501415\n",
      "Initial Cost on Val dataset for this epoch 733 = 0.09012007858501415\n",
      "learning rate for this epoch =  0.09609349972508012\n",
      "Error on this batch = 0.04206667414427151\n",
      "Error on this batch = 0.07146249251011537\n",
      "Cost on val dataset after 734 epochs is = 0.09009423537494533\n",
      "Initial Cost on Val dataset for this epoch 734 = 0.09009423537494533\n",
      "learning rate for this epoch =  0.09606075359671883\n",
      "Error on this batch = 0.04203303914009921\n",
      "Error on this batch = 0.07142163244566344\n",
      "Cost on val dataset after 735 epochs is = 0.09006845100791763\n",
      "Initial Cost on Val dataset for this epoch 735 = 0.09006845100791763\n",
      "learning rate for this epoch =  0.09602806318749467\n",
      "Error on this batch = 0.04199947742178178\n",
      "Error on this batch = 0.07138084585946676\n",
      "Cost on val dataset after 736 epochs is = 0.09004272530451435\n",
      "Initial Cost on Val dataset for this epoch 736 = 0.09004272530451435\n",
      "learning rate for this epoch =  0.09599542832698374\n",
      "Error on this batch = 0.04196598875551876\n",
      "Error on this batch = 0.07134013241124722\n",
      "Cost on val dataset after 737 epochs is = 0.09001705808565602\n",
      "Initial Cost on Val dataset for this epoch 737 = 0.09001705808565602\n",
      "learning rate for this epoch =  0.095962848845514\n",
      "Error on this batch = 0.041932572908381587\n",
      "Error on this batch = 0.07129949176187551\n",
      "Cost on val dataset after 738 epochs is = 0.08999144917261012\n",
      "Initial Cost on Val dataset for this epoch 738 = 0.08999144917261012\n",
      "learning rate for this epoch =  0.09593032457416101\n",
      "Error on this batch = 0.04189922964830684\n",
      "Error on this batch = 0.07125892357337253\n",
      "Cost on val dataset after 739 epochs is = 0.08996589838700048\n",
      "Initial Cost on Val dataset for this epoch 739 = 0.08996589838700048\n",
      "learning rate for this epoch =  0.09589785534474361\n",
      "Error on this batch = 0.04186595874408962\n",
      "Error on this batch = 0.07121842750891105\n",
      "Cost on val dataset after 740 epochs is = 0.08994040555081628\n",
      "Initial Cost on Val dataset for this epoch 740 = 0.08994040555081628\n",
      "learning rate for this epoch =  0.09586544098981967\n",
      "Error on this batch = 0.0418327599653768\n",
      "Error on this batch = 0.07117800323281777\n",
      "Cost on val dataset after 741 epochs is = 0.08991497048642155\n",
      "Initial Cost on Val dataset for this epoch 741 = 0.08991497048642155\n",
      "learning rate for this epoch =  0.09583308134268179\n",
      "Error on this batch = 0.041799633082660374\n",
      "Error on this batch = 0.07113765041057578\n",
      "Cost on val dataset after 742 epochs is = 0.08988959301656363\n",
      "Initial Cost on Val dataset for this epoch 742 = 0.08988959301656363\n",
      "learning rate for this epoch =  0.09580077623735313\n",
      "Error on this batch = 0.04176657786727061\n",
      "Error on this batch = 0.0710973687088272\n",
      "Cost on val dataset after 743 epochs is = 0.08986427296438222\n",
      "Initial Cost on Val dataset for this epoch 743 = 0.08986427296438222\n",
      "learning rate for this epoch =  0.09576852550858327\n",
      "Error on this batch = 0.041733594091369376\n",
      "Error on this batch = 0.07105715779537644\n",
      "Cost on val dataset after 744 epochs is = 0.08983901015341782\n",
      "Initial Cost on Val dataset for this epoch 744 = 0.08983901015341782\n",
      "learning rate for this epoch =  0.09573632899184395\n",
      "Error on this batch = 0.04170068152794336\n",
      "Error on this batch = 0.07101701733919351\n",
      "Cost on val dataset after 745 epochs is = 0.08981380440762023\n",
      "Initial Cost on Val dataset for this epoch 745 = 0.08981380440762023\n",
      "learning rate for this epoch =  0.09570418652332507\n",
      "Error on this batch = 0.04166783995079736\n",
      "Error on this batch = 0.07097694701041773\n",
      "Cost on val dataset after 746 epochs is = 0.08978865555135672\n",
      "Initial Cost on Val dataset for this epoch 746 = 0.08978865555135672\n",
      "learning rate for this epoch =  0.0956720979399305\n",
      "Error on this batch = 0.04163506913454732\n",
      "Error on this batch = 0.07093694648036179\n",
      "Cost on val dataset after 747 epochs is = 0.08976356340942003\n",
      "Initial Cost on Val dataset for this epoch 747 = 0.08976356340942003\n",
      "learning rate for this epoch =  0.0956400630792741\n",
      "Error on this batch = 0.04160236885461368\n",
      "Error on this batch = 0.07089701542151597\n",
      "Cost on val dataset after 748 epochs is = 0.08973852780703644\n",
      "Initial Cost on Val dataset for this epoch 748 = 0.08973852780703644\n",
      "learning rate for this epoch =  0.09560808177967559\n",
      "Error on this batch = 0.041569738887214526\n",
      "Error on this batch = 0.07085715350755285\n",
      "Cost on val dataset after 749 epochs is = 0.0897135485698733\n",
      "Initial Cost on Val dataset for this epoch 749 = 0.0897135485698733\n",
      "learning rate for this epoch =  0.09557615388015658\n",
      "Error on this batch = 0.04153717900935879\n",
      "Error on this batch = 0.07081736041333196\n",
      "Cost on val dataset after 750 epochs is = 0.08968862552404665\n",
      "Initial Cost on Val dataset for this epoch 750 = 0.08968862552404665\n",
      "learning rate for this epoch =  0.09554427922043668\n",
      "Error on this batch = 0.04150468899883949\n",
      "Error on this batch = 0.07077763581490512\n",
      "Cost on val dataset after 751 epochs is = 0.08966375849612848\n",
      "Initial Cost on Val dataset for this epoch 751 = 0.08966375849612848\n",
      "learning rate for this epoch =  0.0955124576409294\n",
      "Error on this batch = 0.041472268634226685\n",
      "Error on this batch = 0.07073797938952167\n",
      "Cost on val dataset after 752 epochs is = 0.08963894731315392\n",
      "Initial Cost on Val dataset for this epoch 752 = 0.08963894731315392\n",
      "learning rate for this epoch =  0.09548068898273834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04143991769486098\n",
      "Error on this batch = 0.07069839081563395\n",
      "Cost on val dataset after 753 epochs is = 0.08961419180262829\n",
      "Initial Cost on Val dataset for this epoch 753 = 0.08961419180262829\n",
      "learning rate for this epoch =  0.09544897308765321\n",
      "Error on this batch = 0.04140763596084643\n",
      "Error on this batch = 0.07065886977290335\n",
      "Cost on val dataset after 754 epochs is = 0.08958949179253375\n",
      "Initial Cost on Val dataset for this epoch 754 = 0.08958949179253375\n",
      "learning rate for this epoch =  0.09541730979814601\n",
      "Error on this batch = 0.04137542321304399\n",
      "Error on this batch = 0.07061941594220607\n",
      "Cost on val dataset after 755 epochs is = 0.08956484711133601\n",
      "Initial Cost on Val dataset for this epoch 755 = 0.08956484711133601\n",
      "learning rate for this epoch =  0.09538569895736723\n",
      "Error on this batch = 0.04134327923306444\n",
      "Error on this batch = 0.07058002900563952\n",
      "Cost on val dataset after 756 epochs is = 0.08954025758799071\n",
      "Initial Cost on Val dataset for this epoch 756 = 0.08954025758799071\n",
      "learning rate for this epoch =  0.0953541404091419\n",
      "Error on this batch = 0.0413112038032618\n",
      "Error on this batch = 0.07054070864652863\n",
      "Cost on val dataset after 757 epochs is = 0.08951572305194955\n",
      "Initial Cost on Val dataset for this epoch 757 = 0.08951572305194955\n",
      "learning rate for this epoch =  0.09532263399796595\n",
      "Error on this batch = 0.0412791967067264\n",
      "Error on this batch = 0.07050145454943238\n",
      "Cost on val dataset after 758 epochs is = 0.08949124333316641\n",
      "Initial Cost on Val dataset for this epoch 758 = 0.08949124333316641\n",
      "learning rate for this epoch =  0.09529117956900235\n",
      "Error on this batch = 0.041247257727278205\n",
      "Error on this batch = 0.07046226640015069\n",
      "Cost on val dataset after 759 epochs is = 0.08946681826210326\n",
      "Initial Cost on Val dataset for this epoch 759 = 0.08946681826210326\n",
      "learning rate for this epoch =  0.09525977696807737\n",
      "Error on this batch = 0.04121538664946004\n",
      "Error on this batch = 0.07042314388573108\n",
      "Cost on val dataset after 760 epochs is = 0.08944244766973566\n",
      "Initial Cost on Val dataset for this epoch 760 = 0.08944244766973566\n",
      "learning rate for this epoch =  0.095228426041677\n",
      "Error on this batch = 0.04118358325853081\n",
      "Error on this batch = 0.07038408669447581\n",
      "Cost on val dataset after 761 epochs is = 0.08941813138755832\n",
      "Initial Cost on Val dataset for this epoch 761 = 0.08941813138755832\n",
      "learning rate for this epoch =  0.09519712663694305\n",
      "Error on this batch = 0.04115184734045879\n",
      "Error on this batch = 0.07034509451594911\n",
      "Cost on val dataset after 762 epochs is = 0.08939386924759028\n",
      "Initial Cost on Val dataset for this epoch 762 = 0.08939386924759028\n",
      "learning rate for this epoch =  0.09516587860166968\n",
      "Error on this batch = 0.04112017868191499\n",
      "Error on this batch = 0.07030616704098423\n",
      "Cost on val dataset after 763 epochs is = 0.08936966108238015\n",
      "Initial Cost on Val dataset for this epoch 763 = 0.08936966108238015\n",
      "learning rate for this epoch =  0.09513468178429965\n",
      "Error on this batch = 0.041088577070266405\n",
      "Error on this batch = 0.07026730396169088\n",
      "Cost on val dataset after 764 epochs is = 0.08934550672501076\n",
      "Initial Cost on Val dataset for this epoch 764 = 0.08934550672501076\n",
      "learning rate for this epoch =  0.0951035360339208\n",
      "Error on this batch = 0.041057042293569455\n",
      "Error on this batch = 0.07022850497146271\n",
      "Cost on val dataset after 765 epochs is = 0.08932140600910411\n",
      "Initial Cost on Val dataset for this epoch 765 = 0.08932140600910411\n",
      "learning rate for this epoch =  0.09507244120026234\n",
      "Error on this batch = 0.04102557414056335\n",
      "Error on this batch = 0.07018976976498484\n",
      "Cost on val dataset after 766 epochs is = 0.08929735876882562\n",
      "Initial Cost on Val dataset for this epoch 766 = 0.08929735876882562\n",
      "learning rate for this epoch =  0.09504139713369145\n",
      "Error on this batch = 0.04099417240066347\n",
      "Error on this batch = 0.07015109803824122\n",
      "Cost on val dataset after 767 epochs is = 0.08927336483888863\n",
      "Initial Cost on Val dataset for this epoch 767 = 0.08927336483888863\n",
      "learning rate for this epoch =  0.09501040368520958\n",
      "Error on this batch = 0.04096283686395495\n",
      "Error on this batch = 0.07011248948852256\n",
      "Cost on val dataset after 768 epochs is = 0.08924942405455848\n",
      "Initial Cost on Val dataset for this epoch 768 = 0.08924942405455848\n",
      "learning rate for this epoch =  0.09497946070644907\n",
      "Error on this batch = 0.04093156732118608\n",
      "Error on this batch = 0.07007394381443369\n",
      "Cost on val dataset after 769 epochs is = 0.08922553625165629\n",
      "Initial Cost on Val dataset for this epoch 769 = 0.08922553625165629\n",
      "learning rate for this epoch =  0.09494856804966957\n",
      "Error on this batch = 0.04090036356376194\n",
      "Error on this batch = 0.07003546071590154\n",
      "Cost on val dataset after 770 epochs is = 0.08920170126656288\n",
      "Initial Cost on Val dataset for this epoch 770 = 0.08920170126656288\n",
      "learning rate for this epoch =  0.09491772556775467\n",
      "Error on this batch = 0.040869225383737925\n",
      "Error on this batch = 0.06999703989418257\n",
      "Cost on val dataset after 771 epochs is = 0.08917791893622228\n",
      "Initial Cost on Val dataset for this epoch 771 = 0.08917791893622228\n",
      "learning rate for this epoch =  0.09488693311420834\n",
      "Error on this batch = 0.04083815257381346\n",
      "Error on this batch = 0.06995868105187059\n",
      "Cost on val dataset after 772 epochs is = 0.08915418909814497\n",
      "Initial Cost on Val dataset for this epoch 772 = 0.08915418909814497\n",
      "learning rate for this epoch =  0.0948561905431516\n",
      "Error on this batch = 0.040807144927325734\n",
      "Error on this batch = 0.06992038389290439\n",
      "Cost on val dataset after 773 epochs is = 0.0891305115904112\n",
      "Initial Cost on Val dataset for this epoch 773 = 0.0891305115904112\n",
      "learning rate for this epoch =  0.09482549770931908\n",
      "Error on this batch = 0.040776202238243346\n",
      "Error on this batch = 0.06988214812257565\n",
      "Cost on val dataset after 774 epochs is = 0.08910688625167382\n",
      "Initial Cost on Val dataset for this epoch 774 = 0.08910688625167382\n",
      "learning rate for this epoch =  0.09479485446805574\n",
      "Error on this batch = 0.040745324301160304\n",
      "Error on this batch = 0.06984397344753612\n",
      "Cost on val dataset after 775 epochs is = 0.0890833129211612\n",
      "Initial Cost on Val dataset for this epoch 775 = 0.0890833129211612\n",
      "learning rate for this epoch =  0.09476426067531338\n",
      "Error on this batch = 0.04071451091128976\n",
      "Error on this batch = 0.06980585957580564\n",
      "Cost on val dataset after 776 epochs is = 0.08905979143867983\n",
      "Initial Cost on Val dataset for this epoch 776 = 0.08905979143867983\n",
      "learning rate for this epoch =  0.0947337161876474\n",
      "Error on this batch = 0.04068376186445804\n",
      "Error on this batch = 0.06976780621677948\n",
      "Cost on val dataset after 777 epochs is = 0.08903632164461654\n",
      "Initial Cost on Val dataset for this epoch 777 = 0.08903632164461654\n",
      "learning rate for this epoch =  0.09470322086221351\n",
      "Error on this batch = 0.04065307695709871\n",
      "Error on this batch = 0.06972981308123577\n",
      "Cost on val dataset after 778 epochs is = 0.08901290337994106\n",
      "Initial Cost on Val dataset for this epoch 778 = 0.08901290337994106\n",
      "learning rate for this epoch =  0.09467277455676439\n",
      "Error on this batch = 0.040622455986246545\n",
      "Error on this batch = 0.06969187988134304\n",
      "Cost on val dataset after 779 epochs is = 0.08898953648620772\n",
      "Initial Cost on Val dataset for this epoch 779 = 0.08898953648620772\n",
      "learning rate for this epoch =  0.0946423771296465\n",
      "Error on this batch = 0.040591898749531834\n",
      "Error on this batch = 0.06965400633066741\n",
      "Cost on val dataset after 780 epochs is = 0.0889662208055577\n",
      "Initial Cost on Val dataset for this epoch 780 = 0.0889662208055577\n",
      "learning rate for this epoch =  0.09461202843979676\n",
      "Error on this batch = 0.040561405045174616\n",
      "Error on this batch = 0.06961619214417986\n",
      "Cost on val dataset after 781 epochs is = 0.08894295618072033\n",
      "Initial Cost on Val dataset for this epoch 781 = 0.08894295618072033\n",
      "learning rate for this epoch =  0.09458172834673945\n",
      "Error on this batch = 0.040530974671979025\n",
      "Error on this batch = 0.06957843703826334\n",
      "Cost on val dataset after 782 epochs is = 0.08891974245501494\n",
      "Initial Cost on Val dataset for this epoch 782 = 0.08891974245501494\n",
      "learning rate for this epoch =  0.09455147671058287\n",
      "Error on this batch = 0.040500607429327616\n",
      "Error on this batch = 0.06954074073071977\n",
      "Cost on val dataset after 783 epochs is = 0.088896579472352\n",
      "Initial Cost on Val dataset for this epoch 783 = 0.088896579472352\n",
      "learning rate for this epoch =  0.09452127339201631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04047030311717604\n",
      "Error on this batch = 0.06950310294077687\n",
      "Cost on val dataset after 784 epochs is = 0.08887346707723427\n",
      "Initial Cost on Val dataset for this epoch 784 = 0.08887346707723427\n",
      "learning rate for this epoch =  0.0944911182523068\n",
      "Error on this batch = 0.04044006153604761\n",
      "Error on this batch = 0.06946552338909504\n",
      "Cost on val dataset after 785 epochs is = 0.08885040511475797\n",
      "Initial Cost on Val dataset for this epoch 785 = 0.08885040511475797\n",
      "learning rate for this epoch =  0.09446101115329605\n",
      "Error on this batch = 0.040409882487027884\n",
      "Error on this batch = 0.06942800179777377\n",
      "Cost on val dataset after 786 epochs is = 0.08882739343061337\n",
      "Initial Cost on Val dataset for this epoch 786 = 0.08882739343061337\n",
      "learning rate for this epoch =  0.09443095195739727\n",
      "Error on this batch = 0.04037976577175965\n",
      "Error on this batch = 0.06939053789035826\n",
      "Cost on val dataset after 787 epochs is = 0.08880443187108558\n",
      "Initial Cost on Val dataset for this epoch 787 = 0.08880443187108558\n",
      "learning rate for this epoch =  0.09440094052759214\n",
      "Error on this batch = 0.04034971119243771\n",
      "Error on this batch = 0.06935313139184567\n",
      "Cost on val dataset after 788 epochs is = 0.08878152028305504\n",
      "Initial Cost on Val dataset for this epoch 788 = 0.08878152028305504\n",
      "learning rate for this epoch =  0.09437097672742772\n",
      "Error on this batch = 0.040319718551804044\n",
      "Error on this batch = 0.06931578202869129\n",
      "Cost on val dataset after 789 epochs is = 0.08875865851399771\n",
      "Initial Cost on Val dataset for this epoch 789 = 0.08875865851399771\n",
      "learning rate for this epoch =  0.09434106042101341\n",
      "Error on this batch = 0.04028978765314269\n",
      "Error on this batch = 0.06927848952881449\n",
      "Cost on val dataset after 790 epochs is = 0.08873584641198538\n",
      "Initial Cost on Val dataset for this epoch 790 = 0.08873584641198538\n",
      "learning rate for this epoch =  0.09431119147301793\n",
      "Error on this batch = 0.040259918300275345\n",
      "Error on this batch = 0.06924125362160446\n",
      "Cost on val dataset after 791 epochs is = 0.08871308382568557\n",
      "Initial Cost on Val dataset for this epoch 791 = 0.08871308382568557\n",
      "learning rate for this epoch =  0.09428136974866627\n",
      "Error on this batch = 0.04023011029755624\n",
      "Error on this batch = 0.0692040740379261\n",
      "Cost on val dataset after 792 epochs is = 0.08869037060436133\n",
      "Initial Cost on Val dataset for this epoch 792 = 0.08869037060436133\n",
      "learning rate for this epoch =  0.09425159511373676\n",
      "Error on this batch = 0.04020036344986811\n",
      "Error on this batch = 0.06916695051012506\n",
      "Cost on val dataset after 793 epochs is = 0.08866770659787111\n",
      "Initial Cost on Val dataset for this epoch 793 = 0.08866770659787111\n",
      "learning rate for this epoch =  0.09422186743455808\n",
      "Error on this batch = 0.040170677562617385\n",
      "Error on this batch = 0.06912988277203332\n",
      "Cost on val dataset after 794 epochs is = 0.08864509165666802\n",
      "Initial Cost on Val dataset for this epoch 794 = 0.08864509165666802\n",
      "learning rate for this epoch =  0.0941921865780063\n",
      "Error on this batch = 0.04014105244173012\n",
      "Error on this batch = 0.06909287055897409\n",
      "Cost on val dataset after 795 epochs is = 0.08862252563179947\n",
      "Initial Cost on Val dataset for this epoch 795 = 0.08862252563179947\n",
      "learning rate for this epoch =  0.09416255241150198\n",
      "Error on this batch = 0.04011148789364784\n",
      "Error on this batch = 0.0690559136077667\n",
      "Cost on val dataset after 796 epochs is = 0.08860000837490625\n",
      "Initial Cost on Val dataset for this epoch 796 = 0.08860000837490625\n",
      "learning rate for this epoch =  0.09413296480300724\n",
      "Error on this batch = 0.04008198372532334\n",
      "Error on this batch = 0.06901901165673127\n",
      "Cost on val dataset after 797 epochs is = 0.08857753973822169\n",
      "Initial Cost on Val dataset for this epoch 797 = 0.08857753973822169\n",
      "learning rate for this epoch =  0.09410342362102285\n",
      "Error on this batch = 0.040052539744216915\n",
      "Error on this batch = 0.06898216444569306\n",
      "Cost on val dataset after 798 epochs is = 0.08855511957457056\n",
      "Initial Cost on Val dataset for this epoch 798 = 0.08855511957457056\n",
      "learning rate for this epoch =  0.09407392873458542\n",
      "Error on this batch = 0.04002315575829262\n",
      "Error on this batch = 0.06894537171598683\n",
      "Cost on val dataset after 799 epochs is = 0.088532747737368\n",
      "Initial Cost on Val dataset for this epoch 799 = 0.088532747737368\n",
      "learning rate for this epoch =  0.09404448001326453\n",
      "Error on this batch = 0.039993831576014466\n",
      "Error on this batch = 0.06890863321046073\n",
      "Cost on val dataset after 800 epochs is = 0.08851042408061807\n",
      "Initial Cost on Val dataset for this epoch 800 = 0.08851042408061807\n",
      "learning rate for this epoch =  0.09401507732715984\n",
      "Error on this batch = 0.03996456700634311\n",
      "Error on this batch = 0.06887194867348022\n",
      "Cost on val dataset after 801 epochs is = 0.08848814845891247\n",
      "Initial Cost on Val dataset for this epoch 801 = 0.08848814845891247\n",
      "learning rate for this epoch =  0.09398572054689833\n",
      "Error on this batch = 0.039935361858732386\n",
      "Error on this batch = 0.06883531785093147\n",
      "Cost on val dataset after 802 epochs is = 0.08846592072742879\n",
      "Initial Cost on Val dataset for this epoch 802 = 0.08846592072742879\n",
      "learning rate for this epoch =  0.09395640954363149\n",
      "Error on this batch = 0.039906215943126114\n",
      "Error on this batch = 0.06879874049022497\n",
      "Cost on val dataset after 803 epochs is = 0.08844374074192896\n",
      "Initial Cost on Val dataset for this epoch 803 = 0.08844374074192896\n",
      "learning rate for this epoch =  0.09392714418903259\n",
      "Error on this batch = 0.03987712906995502\n",
      "Error on this batch = 0.06876221634029843\n",
      "Cost on val dataset after 804 epochs is = 0.08842160835875745\n",
      "Initial Cost on Val dataset for this epoch 804 = 0.08842160835875745\n",
      "learning rate for this epoch =  0.0938979243552938\n",
      "Error on this batch = 0.03984810105013385\n",
      "Error on this batch = 0.06872574515161972\n",
      "Cost on val dataset after 805 epochs is = 0.08839952343483923\n",
      "Initial Cost on Val dataset for this epoch 805 = 0.08839952343483923\n",
      "learning rate for this epoch =  0.0938687499151236\n",
      "Error on this batch = 0.0398191316950585\n",
      "Error on this batch = 0.06868932667618984\n",
      "Cost on val dataset after 806 epochs is = 0.08837748582767785\n",
      "Initial Cost on Val dataset for this epoch 806 = 0.08837748582767785\n",
      "learning rate for this epoch =  0.09383962074174393\n",
      "Error on this batch = 0.039790220816603404\n",
      "Error on this batch = 0.06865296066754495\n",
      "Cost on val dataset after 807 epochs is = 0.0883554953953533\n",
      "Initial Cost on Val dataset for this epoch 807 = 0.0883554953953533\n",
      "learning rate for this epoch =  0.09381053670888753\n",
      "Error on this batch = 0.039761368227119176\n",
      "Error on this batch = 0.06861664688075894\n",
      "Cost on val dataset after 808 epochs is = 0.08833355199651968\n",
      "Initial Cost on Val dataset for this epoch 808 = 0.08833355199651968\n",
      "learning rate for this epoch =  0.09378149769079532\n",
      "Error on this batch = 0.039732573739430066\n",
      "Error on this batch = 0.06858038507244528\n",
      "Cost on val dataset after 809 epochs is = 0.08831165549040296\n",
      "Initial Cost on Val dataset for this epoch 809 = 0.08831165549040296\n",
      "learning rate for this epoch =  0.09375250356221361\n",
      "Error on this batch = 0.0397038371668319\n",
      "Error on this batch = 0.06854417500075885\n",
      "Cost on val dataset after 810 epochs is = 0.0882898057367985\n",
      "Initial Cost on Val dataset for this epoch 810 = 0.0882898057367985\n",
      "learning rate for this epoch =  0.09372355419839151\n",
      "Error on this batch = 0.039675158323090105\n",
      "Error on this batch = 0.06850801642539744\n",
      "Cost on val dataset after 811 epochs is = 0.08826800259606855\n",
      "Initial Cost on Val dataset for this epoch 811 = 0.08826800259606855\n",
      "learning rate for this epoch =  0.09369464947507833\n",
      "Error on this batch = 0.03964653702243766\n",
      "Error on this batch = 0.06847190910760333\n",
      "Cost on val dataset after 812 epochs is = 0.0882462459291397\n",
      "Initial Cost on Val dataset for this epoch 812 = 0.0882462459291397\n",
      "learning rate for this epoch =  0.09366578926852086\n",
      "Error on this batch = 0.039617973079573494\n",
      "Error on this batch = 0.06843585281016402\n",
      "Cost on val dataset after 813 epochs is = 0.08822453559750003\n",
      "Initial Cost on Val dataset for this epoch 813 = 0.08822453559750003\n",
      "learning rate for this epoch =  0.09363697345546085\n",
      "Error on this batch = 0.039589466309660884\n",
      "Error on this batch = 0.06839984729741354\n",
      "Cost on val dataset after 814 epochs is = 0.08820287146319652\n",
      "Initial Cost on Val dataset for this epoch 814 = 0.08820287146319652\n",
      "learning rate for this epoch =  0.09360820191313243\n",
      "Error on this batch = 0.03956101652832604\n",
      "Error on this batch = 0.06836389233523275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 815 epochs is = 0.08818125338883208\n",
      "Initial Cost on Val dataset for this epoch 815 = 0.08818125338883208\n",
      "learning rate for this epoch =  0.09357947451925948\n",
      "Error on this batch = 0.03953262355165684\n",
      "Error on this batch = 0.06832798769105017\n",
      "Cost on val dataset after 816 epochs is = 0.08815968123756283\n",
      "Initial Cost on Val dataset for this epoch 816 = 0.08815968123756283\n",
      "learning rate for this epoch =  0.09355079115205313\n",
      "Error on this batch = 0.03950428719620174\n",
      "Error on this batch = 0.06829213313384193\n",
      "Cost on val dataset after 817 epochs is = 0.08813815487309483\n",
      "Initial Cost on Val dataset for this epoch 817 = 0.08813815487309483\n",
      "learning rate for this epoch =  0.09352215169020917\n",
      "Error on this batch = 0.039476007278968786\n",
      "Error on this batch = 0.068256328434132\n",
      "Cost on val dataset after 818 epochs is = 0.08811667415968136\n",
      "Initial Cost on Val dataset for this epoch 818 = 0.08811667415968136\n",
      "learning rate for this epoch =  0.09349355601290561\n",
      "Error on this batch = 0.03944778361742489\n",
      "Error on this batch = 0.068220573363992\n",
      "Cost on val dataset after 819 epochs is = 0.08809523896211963\n",
      "Initial Cost on Val dataset for this epoch 819 = 0.08809523896211963\n",
      "learning rate for this epoch =  0.09346500399980012\n",
      "Error on this batch = 0.03941961602949511\n",
      "Error on this batch = 0.06818486769704075\n",
      "Cost on val dataset after 820 epochs is = 0.08807384914574774\n",
      "Initial Cost on Val dataset for this epoch 820 = 0.08807384914574774\n",
      "learning rate for this epoch =  0.09343649553102754\n",
      "Error on this batch = 0.03939150433356216\n",
      "Error on this batch = 0.06814921120844382\n",
      "Cost on val dataset after 821 epochs is = 0.08805250457644148\n",
      "Initial Cost on Val dataset for this epoch 821 = 0.08805250457644148\n",
      "learning rate for this epoch =  0.0934080304871974\n",
      "Error on this batch = 0.0393634483484662\n",
      "Error on this batch = 0.06811360367491269\n",
      "Cost on val dataset after 822 epochs is = 0.08803120512061102\n",
      "Initial Cost on Val dataset for this epoch 822 = 0.08803120512061102\n",
      "learning rate for this epoch =  0.09337960874939158\n",
      "Error on this batch = 0.0393354478935045\n",
      "Error on this batch = 0.06807804487470377\n",
      "Cost on val dataset after 823 epochs is = 0.08800995064519783\n",
      "Initial Cost on Val dataset for this epoch 823 = 0.08800995064519783\n",
      "learning rate for this epoch =  0.09335123019916165\n",
      "Error on this batch = 0.03930750278843154\n",
      "Error on this batch = 0.06804253458761741\n",
      "Cost on val dataset after 824 epochs is = 0.0879887410176712\n",
      "Initial Cost on Val dataset for this epoch 824 = 0.0879887410176712\n",
      "learning rate for this epoch =  0.09332289471852671\n",
      "Error on this batch = 0.039279612853458976\n",
      "Error on this batch = 0.06800707259499632\n",
      "Cost on val dataset after 825 epochs is = 0.08796757610602497\n",
      "Initial Cost on Val dataset for this epoch 825 = 0.08796757610602497\n",
      "learning rate for this epoch =  0.09329460218997072\n",
      "Error on this batch = 0.039251777909256054\n",
      "Error on this batch = 0.06797165867972421\n",
      "Cost on val dataset after 826 epochs is = 0.08794645577877423\n",
      "Initial Cost on Val dataset for this epoch 826 = 0.08794645577877423\n",
      "learning rate for this epoch =  0.09326635249644033\n",
      "Error on this batch = 0.03922399777695001\n",
      "Error on this batch = 0.06793629262622412\n",
      "Cost on val dataset after 827 epochs is = 0.08792537990495194\n",
      "Initial Cost on Val dataset for this epoch 827 = 0.08792537990495194\n",
      "learning rate for this epoch =  0.09323814552134235\n",
      "Error on this batch = 0.039196272278126526\n",
      "Error on this batch = 0.06790097422045649\n",
      "Cost on val dataset after 828 epochs is = 0.0879043483541054\n",
      "Initial Cost on Val dataset for this epoch 828 = 0.0879043483541054\n",
      "learning rate for this epoch =  0.09320998114854143\n",
      "Error on this batch = 0.03916860123483055\n",
      "Error on this batch = 0.0678657032499171\n",
      "Cost on val dataset after 829 epochs is = 0.08788336099629304\n",
      "Initial Cost on Val dataset for this epoch 829 = 0.08788336099629304\n",
      "learning rate for this epoch =  0.09318185926235777\n",
      "Error on this batch = 0.03914098446956709\n",
      "Error on this batch = 0.06783047950363494\n",
      "Cost on val dataset after 830 epochs is = 0.08786241770208086\n",
      "Initial Cost on Val dataset for this epoch 830 = 0.08786241770208086\n",
      "learning rate for this epoch =  0.09315377974756468\n",
      "Error on this batch = 0.03911342180530222\n",
      "Error on this batch = 0.06779530277216983\n",
      "Cost on val dataset after 831 epochs is = 0.08784151834253917\n",
      "Initial Cost on Val dataset for this epoch 831 = 0.08784151834253917\n",
      "learning rate for this epoch =  0.09312574248938638\n",
      "Error on this batch = 0.03908591306546421\n",
      "Error on this batch = 0.06776017284760981\n",
      "Cost on val dataset after 832 epochs is = 0.08782066278923899\n",
      "Initial Cost on Val dataset for this epoch 832 = 0.08782066278923899\n",
      "learning rate for this epoch =  0.0930977473734956\n",
      "Error on this batch = 0.03905845807394478\n",
      "Error on this batch = 0.06772508952356868\n",
      "Cost on val dataset after 833 epochs is = 0.08779985091424869\n",
      "Initial Cost on Val dataset for this epoch 833 = 0.08779985091424869\n",
      "learning rate for this epoch =  0.09306979428601131\n",
      "Error on this batch = 0.03903105665510048\n",
      "Error on this batch = 0.067690052595183\n",
      "Cost on val dataset after 834 epochs is = 0.0877790825901307\n",
      "Initial Cost on Val dataset for this epoch 834 = 0.0877790825901307\n",
      "learning rate for this epoch =  0.0930418831134965\n",
      "Error on this batch = 0.039003708633754235\n",
      "Error on this batch = 0.06765506185910918\n",
      "Cost on val dataset after 835 epochs is = 0.087758357689938\n",
      "Initial Cost on Val dataset for this epoch 835 = 0.087758357689938\n",
      "learning rate for this epoch =  0.09301401374295587\n",
      "Error on this batch = 0.03897641383519706\n",
      "Error on this batch = 0.06762011711352042\n",
      "Cost on val dataset after 836 epochs is = 0.08773767608721071\n",
      "Initial Cost on Val dataset for this epoch 836 = 0.08773767608721071\n",
      "learning rate for this epoch =  0.09298618606183358\n",
      "Error on this batch = 0.0389491720851897\n",
      "Error on this batch = 0.06758521815810353\n",
      "Cost on val dataset after 837 epochs is = 0.08771703765597284\n",
      "Initial Cost on Val dataset for this epoch 837 = 0.08771703765597284\n",
      "learning rate for this epoch =  0.09295839995801103\n",
      "Error on this batch = 0.03892198320996464\n",
      "Error on this batch = 0.06755036479405549\n",
      "Cost on val dataset after 838 epochs is = 0.08769644227072881\n",
      "Initial Cost on Val dataset for this epoch 838 = 0.08769644227072881\n",
      "learning rate for this epoch =  0.09293065531980463\n",
      "Error on this batch = 0.03889484703622809\n",
      "Error on this batch = 0.06751555682408002\n",
      "Cost on val dataset after 839 epochs is = 0.0876758898064602\n",
      "Initial Cost on Val dataset for this epoch 839 = 0.0876758898064602\n",
      "learning rate for this epoch =  0.09290295203596367\n",
      "Error on this batch = 0.038867763391162116\n",
      "Error on this batch = 0.06748079405238402\n",
      "Cost on val dataset after 840 epochs is = 0.08765538013862251\n",
      "Initial Cost on Val dataset for this epoch 840 = 0.08765538013862251\n",
      "learning rate for this epoch =  0.09287528999566799\n",
      "Error on this batch = 0.038840732102426896\n",
      "Error on this batch = 0.06744607628467378\n",
      "Cost on val dataset after 841 epochs is = 0.0876349131431418\n",
      "Initial Cost on Val dataset for this epoch 841 = 0.0876349131431418\n",
      "learning rate for this epoch =  0.09284766908852593\n",
      "Error on this batch = 0.03881375299816305\n",
      "Error on this batch = 0.06741140332815135\n",
      "Cost on val dataset after 842 epochs is = 0.08761448869641149\n",
      "Initial Cost on Val dataset for this epoch 842 = 0.08761448869641149\n",
      "learning rate for this epoch =  0.09282008920457209\n",
      "Error on this batch = 0.038786825906994116\n",
      "Error on this batch = 0.0673767749915104\n",
      "Cost on val dataset after 843 epochs is = 0.08759410667528916\n",
      "Initial Cost on Val dataset for this epoch 843 = 0.08759410667528916\n",
      "learning rate for this epoch =  0.09279255023426522\n",
      "Error on this batch = 0.03875995065802916\n",
      "Error on this batch = 0.06734219108493235\n",
      "Cost on val dataset after 844 epochs is = 0.08757376695709346\n",
      "Initial Cost on Val dataset for this epoch 844 = 0.08757376695709346\n",
      "learning rate for this epoch =  0.09276505206848605\n",
      "Error on this batch = 0.03873312708086528\n",
      "Error on this batch = 0.06730765142008233\n",
      "Cost on val dataset after 845 epochs is = 0.08755346941960086\n",
      "Initial Cost on Val dataset for this epoch 845 = 0.08755346941960086\n",
      "learning rate for this epoch =  0.09273759459853521\n",
      "Error on this batch = 0.03870635500559049\n",
      "Error on this batch = 0.06727315581010476\n",
      "Cost on val dataset after 846 epochs is = 0.08753321394104278\n",
      "Initial Cost on Val dataset for this epoch 846 = 0.08753321394104278\n",
      "learning rate for this epoch =  0.0927101777161311\n",
      "Error on this batch = 0.038679634262786575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06723870406961922\n",
      "Cost on val dataset after 847 epochs is = 0.08751300040010236\n",
      "Initial Cost on Val dataset for this epoch 847 = 0.08751300040010236\n",
      "learning rate for this epoch =  0.09268280131340775\n",
      "Error on this batch = 0.03865296468353184\n",
      "Error on this batch = 0.06720429601471622\n",
      "Cost on val dataset after 848 epochs is = 0.08749282867591164\n",
      "Initial Cost on Val dataset for this epoch 848 = 0.08749282867591164\n",
      "learning rate for this epoch =  0.09265546528291284\n",
      "Error on this batch = 0.03862634609940432\n",
      "Error on this batch = 0.0671699314629524\n",
      "Cost on val dataset after 849 epochs is = 0.0874726986480486\n",
      "Initial Cost on Val dataset for this epoch 849 = 0.0874726986480486\n",
      "learning rate for this epoch =  0.09262816951760545\n",
      "Error on this batch = 0.03859977834248471\n",
      "Error on this batch = 0.06713561023334641\n",
      "Cost on val dataset after 850 epochs is = 0.08745261019653422\n",
      "Initial Cost on Val dataset for this epoch 850 = 0.08745261019653422\n",
      "learning rate for this epoch =  0.09260091391085426\n",
      "Error on this batch = 0.03857326124535952\n",
      "Error on this batch = 0.06710133214637401\n",
      "Cost on val dataset after 851 epochs is = 0.08743256320182978\n",
      "Initial Cost on Val dataset for this epoch 851 = 0.08743256320182978\n",
      "learning rate for this epoch =  0.09257369835643524\n",
      "Error on this batch = 0.038546794641124336\n",
      "Error on this batch = 0.06706709702396363\n",
      "Cost on val dataset after 852 epochs is = 0.08741255754483403\n",
      "Initial Cost on Val dataset for this epoch 852 = 0.08741255754483403\n",
      "learning rate for this epoch =  0.09254652274852981\n",
      "Error on this batch = 0.03852037836338717\n",
      "Error on this batch = 0.06703290468949157\n",
      "Cost on val dataset after 853 epochs is = 0.08739259310688055\n",
      "Initial Cost on Val dataset for this epoch 853 = 0.08739259310688055\n",
      "learning rate for this epoch =  0.0925193869817227\n",
      "Error on this batch = 0.038494012246271574\n",
      "Error on this batch = 0.06699875496777727\n",
      "Cost on val dataset after 854 epochs is = 0.08737266976973504\n",
      "Initial Cost on Val dataset for this epoch 854 = 0.08737266976973504\n",
      "learning rate for this epoch =  0.092492290951\n",
      "Error on this batch = 0.038467696124420254\n",
      "Error on this batch = 0.06696464768507852\n",
      "Cost on val dataset after 855 epochs is = 0.08735278741559288\n",
      "Initial Cost on Val dataset for this epoch 855 = 0.08735278741559288\n",
      "learning rate for this epoch =  0.09246523455174717\n",
      "Error on this batch = 0.03844142983299828\n",
      "Error on this batch = 0.06693058266908648\n",
      "Cost on val dataset after 856 epochs is = 0.08733294592707642\n",
      "Initial Cost on Val dataset for this epoch 856 = 0.08733294592707642\n",
      "learning rate for this epoch =  0.092438217679747\n",
      "Error on this batch = 0.038415213207696794\n",
      "Error on this batch = 0.06689655974892088\n",
      "Cost on val dataset after 857 epochs is = 0.08731314518723275\n",
      "Initial Cost on Val dataset for this epoch 857 = 0.08731314518723275\n",
      "learning rate for this epoch =  0.09241124023117771\n",
      "Error on this batch = 0.03838904608473629\n",
      "Error on this batch = 0.06686257875512495\n",
      "Cost on val dataset after 858 epochs is = 0.08729338507953122\n",
      "Initial Cost on Val dataset for this epoch 858 = 0.08729338507953122\n",
      "learning rate for this epoch =  0.09238430210261095\n",
      "Error on this batch = 0.038362928300870285\n",
      "Error on this batch = 0.06682863951966056\n",
      "Cost on val dataset after 859 epochs is = 0.08727366548786109\n",
      "Initial Cost on Val dataset for this epoch 859 = 0.08727366548786109\n",
      "learning rate for this epoch =  0.09235740319100984\n",
      "Error on this batch = 0.03833685969338899\n",
      "Error on this batch = 0.06679474187590308\n",
      "Cost on val dataset after 860 epochs is = 0.08725398629652933\n",
      "Initial Cost on Val dataset for this epoch 860 = 0.08725398629652933\n",
      "learning rate for this epoch =  0.09233054339372707\n",
      "Error on this batch = 0.0383108401001226\n",
      "Error on this batch = 0.06676088565863626\n",
      "Cost on val dataset after 861 epochs is = 0.08723434739025847\n",
      "Initial Cost on Val dataset for this epoch 861 = 0.08723434739025847\n",
      "learning rate for this epoch =  0.09230372260850297\n",
      "Error on this batch = 0.03828486935944519\n",
      "Error on this batch = 0.06672707070404732\n",
      "Cost on val dataset after 862 epochs is = 0.08721474865418449\n",
      "Initial Cost on Val dataset for this epoch 862 = 0.08721474865418449\n",
      "learning rate for this epoch =  0.09227694073346356\n",
      "Error on this batch = 0.03825894731027817\n",
      "Error on this batch = 0.06669329684972156\n",
      "Cost on val dataset after 863 epochs is = 0.08719518997385474\n",
      "Initial Cost on Val dataset for this epoch 863 = 0.08719518997385474\n",
      "learning rate for this epoch =  0.09225019766711869\n",
      "Error on this batch = 0.03823307379209405\n",
      "Error on this batch = 0.06665956393463736\n",
      "Cost on val dataset after 864 epochs is = 0.08717567123522593\n",
      "Initial Cost on Val dataset for this epoch 864 = 0.08717567123522593\n",
      "learning rate for this epoch =  0.09222349330836013\n",
      "Error on this batch = 0.038207248644919874\n",
      "Error on this batch = 0.066625871799161\n",
      "Cost on val dataset after 865 epochs is = 0.08715619232466244\n",
      "Initial Cost on Val dataset for this epoch 865 = 0.08715619232466244\n",
      "learning rate for this epoch =  0.09219682755645973\n",
      "Error on this batch = 0.03818147170934104\n",
      "Error on this batch = 0.06659222028504135\n",
      "Cost on val dataset after 866 epochs is = 0.08713675312893422\n",
      "Initial Cost on Val dataset for this epoch 866 = 0.08713675312893422\n",
      "learning rate for this epoch =  0.09217020031106751\n",
      "Error on this batch = 0.03815574282650482\n",
      "Error on this batch = 0.06655860923540476\n",
      "Cost on val dataset after 867 epochs is = 0.08711735353521519\n",
      "Initial Cost on Val dataset for this epoch 867 = 0.08711735353521519\n",
      "learning rate for this epoch =  0.09214361147220981\n",
      "Error on this batch = 0.03813006183812395\n",
      "Error on this batch = 0.06652503849474962\n",
      "Cost on val dataset after 868 epochs is = 0.08709799343108154\n",
      "Initial Cost on Val dataset for this epoch 868 = 0.08709799343108154\n",
      "learning rate for this epoch =  0.09211706094028746\n",
      "Error on this batch = 0.03810442858648034\n",
      "Error on this batch = 0.06649150790894137\n",
      "Cost on val dataset after 869 epochs is = 0.08707867270451011\n",
      "Initial Cost on Val dataset for this epoch 869 = 0.08707867270451011\n",
      "learning rate for this epoch =  0.09209054861607395\n",
      "Error on this batch = 0.03807884291442841\n",
      "Error on this batch = 0.06645801732520697\n",
      "Cost on val dataset after 870 epochs is = 0.0870593912438768\n",
      "Initial Cost on Val dataset for this epoch 870 = 0.0870593912438768\n",
      "learning rate for this epoch =  0.0920640744007136\n",
      "Error on this batch = 0.03805330466539886\n",
      "Error on this batch = 0.06642456659212978\n",
      "Cost on val dataset after 871 epochs is = 0.08704014893795506\n",
      "Initial Cost on Val dataset for this epoch 871 = 0.08704014893795506\n",
      "learning rate for this epoch =  0.09203763819571976\n",
      "Error on this batch = 0.03802781368340197\n",
      "Error on this batch = 0.06639115555964412\n",
      "Cost on val dataset after 872 epochs is = 0.08702094567591466\n",
      "Initial Cost on Val dataset for this epoch 872 = 0.08702094567591466\n",
      "learning rate for this epoch =  0.09201123990297302\n",
      "Error on this batch = 0.03800236981303125\n",
      "Error on this batch = 0.06635778407903006\n",
      "Cost on val dataset after 873 epochs is = 0.0870017813473201\n",
      "Initial Cost on Val dataset for this epoch 873 = 0.0870017813473201\n",
      "learning rate for this epoch =  0.09198487942471935\n",
      "Error on this batch = 0.03797697289946667\n",
      "Error on this batch = 0.06632445200290807\n",
      "Cost on val dataset after 874 epochs is = 0.0869826558421295\n",
      "Initial Cost on Val dataset for this epoch 874 = 0.0869826558421295\n",
      "learning rate for this epoch =  0.09195855666356846\n",
      "Error on this batch = 0.03795162278847816\n",
      "Error on this batch = 0.06629115918523372\n",
      "Cost on val dataset after 875 epochs is = 0.08696356905069343\n",
      "Initial Cost on Val dataset for this epoch 875 = 0.08696356905069343\n",
      "learning rate for this epoch =  0.09193227152249185\n",
      "Error on this batch = 0.037926319326428856\n",
      "Error on this batch = 0.06625790548129225\n",
      "Cost on val dataset after 876 epochs is = 0.0869445208637535\n",
      "Initial Cost on Val dataset for this epoch 876 = 0.0869445208637535\n",
      "learning rate for this epoch =  0.09190602390482124\n",
      "Error on this batch = 0.037901062360278355\n",
      "Error on this batch = 0.0662246907476933\n",
      "Cost on val dataset after 877 epochs is = 0.08692551117244164\n",
      "Initial Cost on Val dataset for this epoch 877 = 0.08692551117244164\n",
      "learning rate for this epoch =  0.09187981371424671\n",
      "Error on this batch = 0.03787585173758593\n",
      "Error on this batch = 0.06619151484236561\n",
      "Cost on val dataset after 878 epochs is = 0.08690653986827883\n",
      "Initial Cost on Val dataset for this epoch 878 = 0.08690653986827883\n",
      "learning rate for this epoch =  0.091853640854815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.03785068730651366\n",
      "Error on this batch = 0.06615837762455161\n",
      "Cost on val dataset after 879 epochs is = 0.08688760684317419\n",
      "Initial Cost on Val dataset for this epoch 879 = 0.08688760684317419\n",
      "learning rate for this epoch =  0.09182750523092773\n",
      "Error on this batch = 0.03782556891582947\n",
      "Error on this batch = 0.06612527895480211\n",
      "Cost on val dataset after 880 epochs is = 0.08686871198942425\n",
      "Initial Cost on Val dataset for this epoch 880 = 0.08686871198942425\n",
      "learning rate for this epoch =  0.0918014067473398\n",
      "Error on this batch = 0.037800496414910026\n",
      "Error on this batch = 0.06609221869497085\n",
      "Cost on val dataset after 881 epochs is = 0.08684985519971189\n",
      "Initial Cost on Val dataset for this epoch 881 = 0.08684985519971189\n",
      "learning rate for this epoch =  0.09177534530915758\n",
      "Error on this batch = 0.037775469653743746\n",
      "Error on this batch = 0.06605919670820934\n",
      "Cost on val dataset after 882 epochs is = 0.08683103636710578\n",
      "Initial Cost on Val dataset for this epoch 882 = 0.08683103636710578\n",
      "learning rate for this epoch =  0.09174932082183727\n",
      "Error on this batch = 0.0377504884829335\n",
      "Error on this batch = 0.0660262128589613\n",
      "Cost on val dataset after 883 epochs is = 0.08681225538505946\n",
      "Initial Cost on Val dataset for this epoch 883 = 0.08681225538505946\n",
      "learning rate for this epoch =  0.09172333319118318\n",
      "Error on this batch = 0.037725552753699425\n",
      "Error on this batch = 0.06599326701295746\n",
      "Cost on val dataset after 884 epochs is = 0.08679351214741086\n",
      "Initial Cost on Val dataset for this epoch 884 = 0.08679351214741086\n",
      "learning rate for this epoch =  0.0916973823233461\n",
      "Error on this batch = 0.03770066231788144\n",
      "Error on this batch = 0.06596035903721019\n",
      "Cost on val dataset after 885 epochs is = 0.08677480654838164\n",
      "Initial Cost on Val dataset for this epoch 885 = 0.08677480654838164\n",
      "learning rate for this epoch =  0.09167146812482159\n",
      "Error on this batch = 0.037675817027941816\n",
      "Error on this batch = 0.06592748880000804\n",
      "Cost on val dataset after 886 epochs is = 0.08675613848257663\n",
      "Initial Cost on Val dataset for this epoch 886 = 0.08675613848257663\n",
      "learning rate for this epoch =  0.09164559050244833\n",
      "Error on this batch = 0.037651016736967614\n",
      "Error on this batch = 0.06589465617091046\n",
      "Cost on val dataset after 887 epochs is = 0.08673750784498334\n",
      "Initial Cost on Val dataset for this epoch 887 = 0.08673750784498334\n",
      "learning rate for this epoch =  0.09161974936340654\n",
      "Error on this batch = 0.0376262612986729\n",
      "Error on this batch = 0.06586186102074257\n",
      "Cost on val dataset after 888 epochs is = 0.08671891453097151\n",
      "Initial Cost on Val dataset for this epoch 888 = 0.08671891453097151\n",
      "learning rate for this epoch =  0.09159394461521626\n",
      "Error on this batch = 0.03760155056740105\n",
      "Error on this batch = 0.06582910322158965\n",
      "Cost on val dataset after 889 epochs is = 0.08670035843629277\n",
      "Initial Cost on Val dataset for this epoch 889 = 0.08670035843629277\n",
      "learning rate for this epoch =  0.09156817616573577\n",
      "Error on this batch = 0.037576884398126786\n",
      "Error on this batch = 0.06579638264679176\n",
      "Cost on val dataset after 890 epochs is = 0.0866818394570802\n",
      "Initial Cost on Val dataset for this epoch 890 = 0.0866818394570802\n",
      "learning rate for this epoch =  0.09154244392315995\n",
      "Error on this batch = 0.037552262646458154\n",
      "Error on this batch = 0.06576369917093862\n",
      "Cost on val dataset after 891 epochs is = 0.08666335748984816\n",
      "Initial Cost on Val dataset for this epoch 891 = 0.08666335748984816\n",
      "learning rate for this epoch =  0.09151674779601875\n",
      "Error on this batch = 0.03752768516863832\n",
      "Error on this batch = 0.06573105266986401\n",
      "Cost on val dataset after 892 epochs is = 0.08664491243149183\n",
      "Initial Cost on Val dataset for this epoch 892 = 0.08664491243149183\n",
      "learning rate for this epoch =  0.0914910876931754\n",
      "Error on this batch = 0.03750315182154735\n",
      "Error on this batch = 0.0656984430206406\n",
      "Cost on val dataset after 893 epochs is = 0.08662650417928729\n",
      "Initial Cost on Val dataset for this epoch 893 = 0.08662650417928729\n",
      "learning rate for this epoch =  0.09146546352382512\n",
      "Error on this batch = 0.03747866246270374\n",
      "Error on this batch = 0.0656658701015745\n",
      "Cost on val dataset after 894 epochs is = 0.08660813263089102\n",
      "Initial Cost on Val dataset for this epoch 894 = 0.08660813263089102\n",
      "learning rate for this epoch =  0.09143987519749323\n",
      "Error on this batch = 0.037454216950265976\n",
      "Error on this batch = 0.06563333379219999\n",
      "Cost on val dataset after 895 epochs is = 0.08658979768434004\n",
      "Initial Cost on Val dataset for this epoch 895 = 0.08658979768434004\n",
      "learning rate for this epoch =  0.09141432262403383\n",
      "Error on this batch = 0.03742981514303376\n",
      "Error on this batch = 0.06560083397327414\n",
      "Cost on val dataset after 896 epochs is = 0.08657149923805167\n",
      "Initial Cost on Val dataset for this epoch 896 = 0.08657149923805167\n",
      "learning rate for this epoch =  0.09138880571362809\n",
      "Error on this batch = 0.0374054569004492\n",
      "Error on this batch = 0.06556837052677147\n",
      "Cost on val dataset after 897 epochs is = 0.08655323719082347\n",
      "Initial Cost on Val dataset for this epoch 897 = 0.08655323719082347\n",
      "learning rate for this epoch =  0.09136332437678274\n",
      "Error on this batch = 0.03738114208259794\n",
      "Error on this batch = 0.06553594333587866\n",
      "Cost on val dataset after 898 epochs is = 0.08653501144183329\n",
      "Initial Cost on Val dataset for this epoch 898 = 0.08653501144183329\n",
      "learning rate for this epoch =  0.09133787852432855\n",
      "Error on this batch = 0.03735687055020997\n",
      "Error on this batch = 0.06550355228498903\n",
      "Cost on val dataset after 899 epochs is = 0.08651682189063921\n",
      "Initial Cost on Val dataset for this epoch 899 = 0.08651682189063921\n",
      "learning rate for this epoch =  0.09131246806741879\n",
      "Error on this batch = 0.03733264216466047\n",
      "Error on this batch = 0.06547119725969738\n",
      "Cost on val dataset after 900 epochs is = 0.08649866843717956\n",
      "Initial Cost on Val dataset for this epoch 900 = 0.08649866843717956\n",
      "learning rate for this epoch =  0.09128709291752768\n",
      "Error on this batch = 0.03730845678797042\n",
      "Error on this batch = 0.06543887814679458\n",
      "Cost on val dataset after 901 epochs is = 0.08648055098177311\n",
      "Initial Cost on Val dataset for this epoch 901 = 0.08648055098177311\n",
      "learning rate for this epoch =  0.09126175298644894\n",
      "Error on this batch = 0.03728431428280696\n",
      "Error on this batch = 0.06540659483426219\n",
      "Cost on val dataset after 902 epochs is = 0.08646246942511901\n",
      "Initial Cost on Val dataset for this epoch 902 = 0.08646246942511901\n",
      "learning rate for this epoch =  0.09123644818629414\n",
      "Error on this batch = 0.037260214512483854\n",
      "Error on this batch = 0.06537434721126703\n",
      "Cost on val dataset after 903 epochs is = 0.086444423668297\n",
      "Initial Cost on Val dataset for this epoch 903 = 0.086444423668297\n",
      "learning rate for this epoch =  0.09121117842949143\n",
      "Error on this batch = 0.03723615734096155\n",
      "Error on this batch = 0.06534213516815605\n",
      "Cost on val dataset after 904 epochs is = 0.08642641361276747\n",
      "Initial Cost on Val dataset for this epoch 904 = 0.08642641361276747\n",
      "learning rate for this epoch =  0.09118594362878382\n",
      "Error on this batch = 0.03721214263284728\n",
      "Error on this batch = 0.06530995859645071\n",
      "Cost on val dataset after 905 epochs is = 0.08640843916037175\n",
      "Initial Cost on Val dataset for this epoch 905 = 0.08640843916037175\n",
      "learning rate for this epoch =  0.09116074369722786\n",
      "Error on this batch = 0.0371881702533948\n",
      "Error on this batch = 0.06527781738884171\n",
      "Cost on val dataset after 906 epochs is = 0.08639050021333222\n",
      "Initial Cost on Val dataset for this epoch 906 = 0.08639050021333222\n",
      "learning rate for this epoch =  0.09113557854819211\n",
      "Error on this batch = 0.03716424006850417\n",
      "Error on this batch = 0.06524571143918365\n",
      "Cost on val dataset after 907 epochs is = 0.0863725966742524\n",
      "Initial Cost on Val dataset for this epoch 907 = 0.0863725966742524\n",
      "learning rate for this epoch =  0.09111044809535562\n",
      "Error on this batch = 0.03714035194472132\n",
      "Error on this batch = 0.06521364064248956\n",
      "Cost on val dataset after 908 epochs is = 0.08635472844611744\n",
      "Initial Cost on Val dataset for this epoch 908 = 0.08635472844611744\n",
      "learning rate for this epoch =  0.09108535225270664\n",
      "Error on this batch = 0.037116505749237326\n",
      "Error on this batch = 0.06518160489492558\n",
      "Cost on val dataset after 909 epochs is = 0.08633689543229402\n",
      "Initial Cost on Val dataset for this epoch 909 = 0.08633689543229402\n",
      "learning rate for this epoch =  0.09106029093454096\n",
      "Error on this batch = 0.037092701349887694\n",
      "Error on this batch = 0.06514960409380552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 910 epochs is = 0.08631909753653096\n",
      "Initial Cost on Val dataset for this epoch 910 = 0.08631909753653096\n",
      "learning rate for this epoch =  0.09103526405546067\n",
      "Error on this batch = 0.03706893861515147\n",
      "Error on this batch = 0.0651176381375854\n",
      "Cost on val dataset after 911 epochs is = 0.0863013346629591\n",
      "Initial Cost on Val dataset for this epoch 911 = 0.0863013346629591\n",
      "learning rate for this epoch =  0.09101027153037257\n",
      "Error on this batch = 0.03704521741415007\n",
      "Error on this batch = 0.06508570692585816\n",
      "Cost on val dataset after 912 epochs is = 0.08628360671609187\n",
      "Initial Cost on Val dataset for this epoch 912 = 0.08628360671609187\n",
      "learning rate for this epoch =  0.09098531327448692\n",
      "Error on this batch = 0.03702153761664605\n",
      "Error on this batch = 0.06505381035934807\n",
      "Cost on val dataset after 913 epochs is = 0.08626591360082544\n",
      "Initial Cost on Val dataset for this epoch 913 = 0.08626591360082544\n",
      "learning rate for this epoch =  0.09096038920331581\n",
      "Error on this batch = 0.03699789909304165\n",
      "Error on this batch = 0.06502194833990534\n",
      "Cost on val dataset after 914 epochs is = 0.08624825522243905\n",
      "Initial Cost on Val dataset for this epoch 914 = 0.08624825522243905\n",
      "learning rate for this epoch =  0.09093549923267195\n",
      "Error on this batch = 0.03697430171437728\n",
      "Error on this batch = 0.06499012077050077\n",
      "Cost on val dataset after 915 epochs is = 0.08623063148659514\n",
      "Initial Cost on Val dataset for this epoch 915 = 0.08623063148659514\n",
      "learning rate for this epoch =  0.0909106432786672\n",
      "Error on this batch = 0.03695074535232971\n",
      "Error on this batch = 0.06495832755522012\n",
      "Cost on val dataset after 916 epochs is = 0.08621304229933996\n",
      "Initial Cost on Val dataset for this epoch 916 = 0.08621304229933996\n",
      "learning rate for this epoch =  0.09088582125771116\n",
      "Error on this batch = 0.03692722987921024\n",
      "Error on this batch = 0.06492656859925862\n",
      "Cost on val dataset after 917 epochs is = 0.08619548756710359\n",
      "Initial Cost on Val dataset for this epoch 917 = 0.08619548756710359\n",
      "learning rate for this epoch =  0.09086103308650982\n",
      "Error on this batch = 0.03690375516796255\n",
      "Error on this batch = 0.06489484380891565\n",
      "Cost on val dataset after 918 epochs is = 0.08617796719670036\n",
      "Initial Cost on Val dataset for this epoch 918 = 0.08617796719670036\n",
      "learning rate for this epoch =  0.09083627868206413\n",
      "Error on this batch = 0.03688032109216054\n",
      "Error on this batch = 0.06486315309158894\n",
      "Cost on val dataset after 919 epochs is = 0.08616048109532916\n",
      "Initial Cost on Val dataset for this epoch 919 = 0.08616048109532916\n",
      "learning rate for this epoch =  0.09081155796166877\n",
      "Error on this batch = 0.0368569275260059\n",
      "Error on this batch = 0.0648314963557693\n",
      "Cost on val dataset after 920 epochs is = 0.08614302917057366\n",
      "Initial Cost on Val dataset for this epoch 920 = 0.08614302917057366\n",
      "learning rate for this epoch =  0.09078687084291064\n",
      "Error on this batch = 0.036833574344325694\n",
      "Error on this batch = 0.06479987351103489\n",
      "Cost on val dataset after 921 epochs is = 0.0861256113304027\n",
      "Initial Cost on Val dataset for this epoch 921 = 0.0861256113304027\n",
      "learning rate for this epoch =  0.09076221724366758\n",
      "Error on this batch = 0.03681026142256948\n",
      "Error on this batch = 0.06476828446804567\n",
      "Cost on val dataset after 922 epochs is = 0.0861082274831706\n",
      "Initial Cost on Val dataset for this epoch 922 = 0.0861082274831706\n",
      "learning rate for this epoch =  0.09073759708210706\n",
      "Error on this batch = 0.03678698863680664\n",
      "Error on this batch = 0.06473672913853783\n",
      "Cost on val dataset after 923 epochs is = 0.0860908775376173\n",
      "Initial Cost on Val dataset for this epoch 923 = 0.0860908775376173\n",
      "learning rate for this epoch =  0.09071301027668477\n",
      "Error on this batch = 0.03676375586372327\n",
      "Error on this batch = 0.06470520743531813\n",
      "Cost on val dataset after 924 epochs is = 0.08607356140286881\n",
      "Initial Cost on Val dataset for this epoch 924 = 0.08607356140286881\n",
      "learning rate for this epoch =  0.09068845674614334\n",
      "Error on this batch = 0.0367405629806191\n",
      "Error on this batch = 0.06467371927225829\n",
      "Cost on val dataset after 925 epochs is = 0.08605627898843744\n",
      "Initial Cost on Val dataset for this epoch 925 = 0.08605627898843744\n",
      "learning rate for this epoch =  0.09066393640951106\n",
      "Error on this batch = 0.036717409865404095\n",
      "Error on this batch = 0.06464226456428925\n",
      "Cost on val dataset after 926 epochs is = 0.08603903020422202\n",
      "Initial Cost on Val dataset for this epoch 926 = 0.08603903020422202\n",
      "learning rate for this epoch =  0.09063944918610045\n",
      "Error on this batch = 0.03669429639659513\n",
      "Error on this batch = 0.06461084322739549\n",
      "Cost on val dataset after 927 epochs is = 0.08602181496050817\n",
      "Initial Cost on Val dataset for this epoch 927 = 0.08602181496050817\n",
      "learning rate for this epoch =  0.0906149949955071\n",
      "Error on this batch = 0.036671222453312356\n",
      "Error on this batch = 0.06457945517860933\n",
      "Cost on val dataset after 928 epochs is = 0.08600463316796873\n",
      "Initial Cost on Val dataset for this epoch 928 = 0.08600463316796873\n",
      "learning rate for this epoch =  0.09059057375760825\n",
      "Error on this batch = 0.0366481879152754\n",
      "Error on this batch = 0.06454810033600519\n",
      "Cost on val dataset after 929 epochs is = 0.08598748473766368\n",
      "Initial Cost on Val dataset for this epoch 929 = 0.08598748473766368\n",
      "learning rate for this epoch =  0.09056618539256157\n",
      "Error on this batch = 0.03662519266279962\n",
      "Error on this batch = 0.06451677861869363\n",
      "Cost on val dataset after 930 epochs is = 0.08597036958104065\n",
      "Initial Cost on Val dataset for this epoch 930 = 0.08597036958104065\n",
      "learning rate for this epoch =  0.09054182982080389\n",
      "Error on this batch = 0.036602236576791944\n",
      "Error on this batch = 0.06448548994681576\n",
      "Cost on val dataset after 931 epochs is = 0.085953287609935\n",
      "Initial Cost on Val dataset for this epoch 931 = 0.085953287609935\n",
      "learning rate for this epoch =  0.09051750696304985\n",
      "Error on this batch = 0.03657931953874693\n",
      "Error on this batch = 0.0644542342415372\n",
      "Cost on val dataset after 932 epochs is = 0.08593623873657003\n",
      "Initial Cost on Val dataset for this epoch 932 = 0.08593623873657003\n",
      "learning rate for this epoch =  0.0904932167402907\n",
      "Error on this batch = 0.03655644143074222\n",
      "Error on this batch = 0.06442301142504228\n",
      "Cost on val dataset after 933 epochs is = 0.08591922287355722\n",
      "Initial Cost on Val dataset for this epoch 933 = 0.08591922287355722\n",
      "learning rate for this epoch =  0.09046895907379304\n",
      "Error on this batch = 0.036533602135434495\n",
      "Error on this batch = 0.06439182142052802\n",
      "Cost on val dataset after 934 epochs is = 0.08590223993389638\n",
      "Initial Cost on Val dataset for this epoch 934 = 0.08590223993389638\n",
      "learning rate for this epoch =  0.09044473388509751\n",
      "Error on this batch = 0.03651080153605456\n",
      "Error on this batch = 0.0643606641521982\n",
      "Cost on val dataset after 935 epochs is = 0.08588528983097579\n",
      "Initial Cost on Val dataset for this epoch 935 = 0.08588528983097579\n",
      "learning rate for this epoch =  0.0904205410960176\n",
      "Error on this batch = 0.03648803951640305\n",
      "Error on this batch = 0.06432953954525743\n",
      "Cost on val dataset after 936 epochs is = 0.08586837247857237\n",
      "Initial Cost on Val dataset for this epoch 936 = 0.08586837247857237\n",
      "learning rate for this epoch =  0.09039638062863838\n",
      "Error on this batch = 0.036465315960845436\n",
      "Error on this batch = 0.06429844752590494\n",
      "Cost on val dataset after 937 epochs is = 0.08585148779085178\n",
      "Initial Cost on Val dataset for this epoch 937 = 0.08585148779085178\n",
      "learning rate for this epoch =  0.09037225240531528\n",
      "Error on this batch = 0.03644263075430727\n",
      "Error on this batch = 0.06426738802132856\n",
      "Cost on val dataset after 938 epochs is = 0.08583463568236856\n",
      "Initial Cost on Val dataset for this epoch 938 = 0.08583463568236856\n",
      "learning rate for this epoch =  0.09034815634867288\n",
      "Error on this batch = 0.03641998378226922\n",
      "Error on this batch = 0.06423636095969852\n",
      "Cost on val dataset after 939 epochs is = 0.08581781606806613\n",
      "Initial Cost on Val dataset for this epoch 939 = 0.08581781606806613\n",
      "learning rate for this epoch =  0.09032409238160365\n",
      "Error on this batch = 0.03639737493076189\n",
      "Error on this batch = 0.06420536627016137\n",
      "Cost on val dataset after 940 epochs is = 0.08580102886327699\n",
      "Initial Cost on Val dataset for this epoch 940 = 0.08580102886327699\n",
      "learning rate for this epoch =  0.09030006042726675\n",
      "Error on this batch = 0.03637480408636073\n",
      "Error on this batch = 0.06417440388283355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 941 epochs is = 0.08578427398372264\n",
      "Initial Cost on Val dataset for this epoch 941 = 0.08578427398372264\n",
      "learning rate for this epoch =  0.0902760604090869\n",
      "Error on this batch = 0.03635227113618075\n",
      "Error on this batch = 0.06414347372879518\n",
      "Cost on val dataset after 942 epochs is = 0.08576755134551367\n",
      "Initial Cost on Val dataset for this epoch 942 = 0.08576755134551367\n",
      "learning rate for this epoch =  0.09025209225075301\n",
      "Error on this batch = 0.0363297759678711\n",
      "Error on this batch = 0.06411257574008372\n",
      "Cost on val dataset after 943 epochs is = 0.08575086086514978\n",
      "Initial Cost on Val dataset for this epoch 943 = 0.08575086086514978\n",
      "learning rate for this epoch =  0.09022815587621721\n",
      "Error on this batch = 0.03630731846960971\n",
      "Error on this batch = 0.06408170984968753\n",
      "Cost on val dataset after 944 epochs is = 0.08573420245951975\n",
      "Initial Cost on Val dataset for this epoch 944 = 0.08573420245951975\n",
      "learning rate for this epoch =  0.0902042512096935\n",
      "Error on this batch = 0.03628489853009769\n",
      "Error on this batch = 0.0640508759915394\n",
      "Cost on val dataset after 945 epochs is = 0.08571757604590133\n",
      "Initial Cost on Val dataset for this epoch 945 = 0.08571757604590133\n",
      "learning rate for this epoch =  0.09018037817565662\n",
      "Error on this batch = 0.0362625160385538\n",
      "Error on this batch = 0.06402007410050994\n",
      "Cost on val dataset after 946 epochs is = 0.08570098154196129\n",
      "Initial Cost on Val dataset for this epoch 946 = 0.08570098154196129\n",
      "learning rate for this epoch =  0.09015653669884087\n",
      "Error on this batch = 0.03624017088470866\n",
      "Error on this batch = 0.06398930411240109\n",
      "Cost on val dataset after 947 epochs is = 0.08568441886575526\n",
      "Initial Cost on Val dataset for this epoch 947 = 0.08568441886575526\n",
      "learning rate for this epoch =  0.09013272670423898\n",
      "Error on this batch = 0.03621786295879921\n",
      "Error on this batch = 0.0639585659639393\n",
      "Cost on val dataset after 948 epochs is = 0.08566788793572762\n",
      "Initial Cost on Val dataset for this epoch 948 = 0.08566788793572762\n",
      "learning rate for this epoch =  0.09010894811710093\n",
      "Error on this batch = 0.03619559215156273\n",
      "Error on this batch = 0.06392785959276898\n",
      "Cost on val dataset after 949 epochs is = 0.08565138867071144\n",
      "Initial Cost on Val dataset for this epoch 949 = 0.08565138867071144\n",
      "learning rate for this epoch =  0.09008520086293277\n",
      "Error on this batch = 0.03617335835423109\n",
      "Error on this batch = 0.06389718493744552\n",
      "Cost on val dataset after 950 epochs is = 0.0856349209899282\n",
      "Initial Cost on Val dataset for this epoch 950 = 0.0856349209899282\n",
      "learning rate for this epoch =  0.09006148486749553\n",
      "Error on this batch = 0.036151161458524844\n",
      "Error on this batch = 0.06386654193742843\n",
      "Cost on val dataset after 951 epochs is = 0.0856184848129877\n",
      "Initial Cost on Val dataset for this epoch 951 = 0.0856184848129877\n",
      "learning rate for this epoch =  0.09003780005680402\n",
      "Error on this batch = 0.03612900135664734\n",
      "Error on this batch = 0.06383593053307436\n",
      "Cost on val dataset after 952 epochs is = 0.08560208005988783\n",
      "Initial Cost on Val dataset for this epoch 952 = 0.08560208005988783\n",
      "learning rate for this epoch =  0.09001414635712576\n",
      "Error on this batch = 0.03610687794127874\n",
      "Error on this batch = 0.06380535066563017\n",
      "Cost on val dataset after 953 epochs is = 0.08558570665101431\n",
      "Initial Cost on Val dataset for this epoch 953 = 0.08558570665101431\n",
      "learning rate for this epoch =  0.08999052369497976\n",
      "Error on this batch = 0.03608479110556994\n",
      "Error on this batch = 0.0637748022772256\n",
      "Cost on val dataset after 954 epochs is = 0.08556936450714044\n",
      "Initial Cost on Val dataset for this epoch 954 = 0.08556936450714044\n",
      "learning rate for this epoch =  0.08996693199713549\n",
      "Error on this batch = 0.036062740743136784\n",
      "Error on this batch = 0.0637442853108662\n",
      "Cost on val dataset after 955 epochs is = 0.0855530535494268\n",
      "Initial Cost on Val dataset for this epoch 955 = 0.0855530535494268\n",
      "learning rate for this epoch =  0.08994337119061177\n",
      "Error on this batch = 0.0360407267480538\n",
      "Error on this batch = 0.06371379971042596\n",
      "Cost on val dataset after 956 epochs is = 0.0855367736994209\n",
      "Initial Cost on Val dataset for this epoch 956 = 0.0855367736994209\n",
      "learning rate for this epoch =  0.08991984120267553\n",
      "Error on this batch = 0.036018749014848306\n",
      "Error on this batch = 0.06368334542063978\n",
      "Cost on val dataset after 957 epochs is = 0.08552052487905693\n",
      "Initial Cost on Val dataset for this epoch 957 = 0.08552052487905693\n",
      "learning rate for this epoch =  0.08989634196084093\n",
      "Error on this batch = 0.03599680743849441\n",
      "Error on this batch = 0.06365292238709619\n",
      "Cost on val dataset after 958 epochs is = 0.08550430701065527\n",
      "Initial Cost on Val dataset for this epoch 958 = 0.08550430701065527\n",
      "learning rate for this epoch =  0.089872873392868\n",
      "Error on this batch = 0.03597490191440686\n",
      "Error on this batch = 0.06362253055622959\n",
      "Cost on val dataset after 959 epochs is = 0.08548812001692212\n",
      "Initial Cost on Val dataset for this epoch 959 = 0.08548812001692212\n",
      "learning rate for this epoch =  0.08984943542676176\n",
      "Error on this batch = 0.035953032338435185\n",
      "Error on this batch = 0.06359216987531259\n",
      "Cost on val dataset after 960 epochs is = 0.08547196382094908\n",
      "Initial Cost on Val dataset for this epoch 960 = 0.08547196382094908\n",
      "learning rate for this epoch =  0.08982602799077107\n",
      "Error on this batch = 0.03593119860685752\n",
      "Error on this batch = 0.06356184029244809\n",
      "Cost on val dataset after 961 epochs is = 0.08545583834621268\n",
      "Initial Cost on Val dataset for this epoch 961 = 0.08545583834621268\n",
      "learning rate for this epoch =  0.08980265101338746\n",
      "Error on this batch = 0.035909400616374876\n",
      "Error on this batch = 0.06353154175656153\n",
      "Cost on val dataset after 962 epochs is = 0.08543974351657385\n",
      "Initial Cost on Val dataset for this epoch 962 = 0.08543974351657385\n",
      "learning rate for this epoch =  0.0897793044233442\n",
      "Error on this batch = 0.03588763826410506\n",
      "Error on this batch = 0.06350127421739264\n",
      "Cost on val dataset after 963 epochs is = 0.0854236792562774\n",
      "Initial Cost on Val dataset for this epoch 963 = 0.0854236792562774\n",
      "learning rate for this epoch =  0.0897559881496152\n",
      "Error on this batch = 0.0358659114475768\n",
      "Error on this batch = 0.06347103762548752\n",
      "Cost on val dataset after 964 epochs is = 0.0854076454899515\n",
      "Initial Cost on Val dataset for this epoch 964 = 0.0854076454899515\n",
      "learning rate for this epoch =  0.08973270212141383\n",
      "Error on this batch = 0.03584422006472395\n",
      "Error on this batch = 0.06344083193219006\n",
      "Cost on val dataset after 965 epochs is = 0.08539164214260699\n",
      "Initial Cost on Val dataset for this epoch 965 = 0.08539164214260699\n",
      "learning rate for this epoch =  0.08970944626819201\n",
      "Error on this batch = 0.035822564013879746\n",
      "Error on this batch = 0.06341065708963384\n",
      "Cost on val dataset after 966 epochs is = 0.0853756691396368\n",
      "Initial Cost on Val dataset for this epoch 966 = 0.0853756691396368\n",
      "learning rate for this epoch =  0.0896862205196391\n",
      "Error on this batch = 0.03580094319377103\n",
      "Error on this batch = 0.06338051305073328\n",
      "Cost on val dataset after 967 epochs is = 0.08535972640681533\n",
      "Initial Cost on Val dataset for this epoch 967 = 0.08535972640681533\n",
      "learning rate for this epoch =  0.08966302480568086\n",
      "Error on this batch = 0.035779357503512584\n",
      "Error on this batch = 0.06335039976917521\n",
      "Cost on val dataset after 968 epochs is = 0.08534381387029764\n",
      "Initial Cost on Val dataset for this epoch 968 = 0.08534381387029764\n",
      "learning rate for this epoch =  0.08963985905647841\n",
      "Error on this batch = 0.035757806842601714\n",
      "Error on this batch = 0.06332031719941\n",
      "Cost on val dataset after 969 epochs is = 0.08532793145661882\n",
      "Initial Cost on Val dataset for this epoch 969 = 0.08532793145661882\n",
      "learning rate for this epoch =  0.08961672320242715\n",
      "Error on this batch = 0.03573629111091261\n",
      "Error on this batch = 0.06329026529664253\n",
      "Cost on val dataset after 970 epochs is = 0.0853120790926931\n",
      "Initial Cost on Val dataset for this epoch 970 = 0.0853120790926931\n",
      "learning rate for this epoch =  0.08959361717415586\n",
      "Error on this batch = 0.035714810208691085\n",
      "Error on this batch = 0.06326024401682317\n",
      "Cost on val dataset after 971 epochs is = 0.08529625670581314\n",
      "Initial Cost on Val dataset for this epoch 971 = 0.08529625670581314\n",
      "learning rate for this epoch =  0.08957054090252553\n",
      "Error on this batch = 0.03569336403654923\n",
      "Error on this batch = 0.06323025331663856\n",
      "Cost on val dataset after 972 epochs is = 0.08528046422364917\n",
      "Initial Cost on Val dataset for this epoch 972 = 0.08528046422364917\n",
      "learning rate for this epoch =  0.08954749431862849\n",
      "Error on this batch = 0.0356719524954603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.0632002931535022\n",
      "Cost on val dataset after 973 epochs is = 0.08526470157424802\n",
      "Initial Cost on Val dataset for this epoch 973 = 0.08526470157424802\n",
      "learning rate for this epoch =  0.08952447735378725\n",
      "Error on this batch = 0.03565057548675363\n",
      "Error on this batch = 0.06317036348554485\n",
      "Cost on val dataset after 974 epochs is = 0.08524896868603217\n",
      "Initial Cost on Val dataset for this epoch 974 = 0.08524896868603217\n",
      "learning rate for this epoch =  0.08950148993955362\n",
      "Error on this batch = 0.035629232912109725\n",
      "Error on this batch = 0.06314046427160486\n",
      "Cost on val dataset after 975 epochs is = 0.08523326548779898\n",
      "Initial Cost on Val dataset for this epoch 975 = 0.08523326548779898\n",
      "learning rate for this epoch =  0.08947853200770761\n",
      "Error on this batch = 0.03560792467355544\n",
      "Error on this batch = 0.06311059547121835\n",
      "Cost on val dataset after 976 epochs is = 0.08521759190871946\n",
      "Initial Cost on Val dataset for this epoch 976 = 0.08521759190871946\n",
      "learning rate for this epoch =  0.08945560349025655\n",
      "Error on this batch = 0.03558665067345942\n",
      "Error on this batch = 0.06308075704460922\n",
      "Cost on val dataset after 977 epochs is = 0.08520194787833724\n",
      "Initial Cost on Val dataset for this epoch 977 = 0.08520194787833724\n",
      "learning rate for this epoch =  0.08943270431943395\n",
      "Error on this batch = 0.03556541081452752\n",
      "Error on this batch = 0.06305094895267875\n",
      "Cost on val dataset after 978 epochs is = 0.08518633332656761\n",
      "Initial Cost on Val dataset for this epoch 978 = 0.08518633332656761\n",
      "learning rate for this epoch =  0.08940983442769869\n",
      "Error on this batch = 0.03554420499979845\n",
      "Error on this batch = 0.06302117115699545\n",
      "Cost on val dataset after 979 epochs is = 0.0851707481836962\n",
      "Initial Cost on Val dataset for this epoch 979 = 0.0851707481836962\n",
      "learning rate for this epoch =  0.08938699374773387\n",
      "Error on this batch = 0.03552303313263964\n",
      "Error on this batch = 0.06299142361978442\n",
      "Cost on val dataset after 980 epochs is = 0.08515519238037789\n",
      "Initial Cost on Val dataset for this epoch 980 = 0.08515519238037789\n",
      "learning rate for this epoch =  0.089364182212446\n",
      "Error on this batch = 0.03550189511674318\n",
      "Error on this batch = 0.0629617063039166\n",
      "Cost on val dataset after 981 epochs is = 0.08513966584763545\n",
      "Initial Cost on Val dataset for this epoch 981 = 0.08513966584763545\n",
      "learning rate for this epoch =  0.08934139975496388\n",
      "Error on this batch = 0.03548079085612207\n",
      "Error on this batch = 0.06293201917289795\n",
      "Cost on val dataset after 982 epochs is = 0.0851241685168585\n",
      "Initial Cost on Val dataset for this epoch 982 = 0.0851241685168585\n",
      "learning rate for this epoch =  0.08931864630863778\n",
      "Error on this batch = 0.035459720255106436\n",
      "Error on this batch = 0.06290236219085828\n",
      "Cost on val dataset after 983 epochs is = 0.08510870031980189\n",
      "Initial Cost on Val dataset for this epoch 983 = 0.08510870031980189\n",
      "learning rate for this epoch =  0.08929592180703835\n",
      "Error on this batch = 0.0354386832183401\n",
      "Error on this batch = 0.06287273532254002\n",
      "Cost on val dataset after 984 epochs is = 0.08509326118858442\n",
      "Initial Cost on Val dataset for this epoch 984 = 0.08509326118858442\n",
      "learning rate for this epoch =  0.08927322618395579\n",
      "Error on this batch = 0.035417679650777446\n",
      "Error on this batch = 0.0628431385332868\n",
      "Cost on val dataset after 985 epochs is = 0.0850778510556874\n",
      "Initial Cost on Val dataset for this epoch 985 = 0.0850778510556874\n",
      "learning rate for this epoch =  0.08925055937339876\n",
      "Error on this batch = 0.035396709457680225\n",
      "Error on this batch = 0.0628135717890316\n",
      "Cost on val dataset after 986 epochs is = 0.08506246985395323\n",
      "Initial Cost on Val dataset for this epoch 986 = 0.08506246985395323\n",
      "learning rate for this epoch =  0.08922792130959359\n",
      "Error on this batch = 0.035375772544614666\n",
      "Error on this batch = 0.06278403505628523\n",
      "Cost on val dataset after 987 epochs is = 0.08504711751658363\n",
      "Initial Cost on Val dataset for this epoch 987 = 0.08504711751658363\n",
      "learning rate for this epoch =  0.08920531192698324\n",
      "Error on this batch = 0.035354868817449\n",
      "Error on this batch = 0.06275452830212394\n",
      "Cost on val dataset after 988 epochs is = 0.08503179397713825\n",
      "Initial Cost on Val dataset for this epoch 988 = 0.08503179397713825\n",
      "learning rate for this epoch =  0.08918273116022643\n",
      "Error on this batch = 0.03533399818235086\n",
      "Error on this batch = 0.0627250514941774\n",
      "Cost on val dataset after 989 epochs is = 0.0850164991695329\n",
      "Initial Cost on Val dataset for this epoch 989 = 0.0850164991695329\n",
      "learning rate for this epoch =  0.08916017894419664\n",
      "Error on this batch = 0.03531316054578527\n",
      "Error on this batch = 0.06269560460061617\n",
      "Cost on val dataset after 990 epochs is = 0.0850012330280378\n",
      "Initial Cost on Val dataset for this epoch 990 = 0.0850012330280378\n",
      "learning rate for this epoch =  0.08913765521398127\n",
      "Error on this batch = 0.03529235581451261\n",
      "Error on this batch = 0.06266618759013907\n",
      "Cost on val dataset after 991 epochs is = 0.08498599548727594\n",
      "Initial Cost on Val dataset for this epoch 991 = 0.08498599548727594\n",
      "learning rate for this epoch =  0.08911515990488066\n",
      "Error on this batch = 0.03527158389558676\n",
      "Error on this batch = 0.06263680043196045\n",
      "Cost on val dataset after 992 epochs is = 0.08497078648222102\n",
      "Initial Cost on Val dataset for this epoch 992 = 0.08497078648222102\n",
      "learning rate for this epoch =  0.0890926929524072\n",
      "Error on this batch = 0.035250844696353964\n",
      "Error on this batch = 0.06260744309579681\n",
      "Cost on val dataset after 993 epochs is = 0.08495560594819565\n",
      "Initial Cost on Val dataset for this epoch 993 = 0.08495560594819565\n",
      "learning rate for this epoch =  0.08907025429228442\n",
      "Error on this batch = 0.03523013812445131\n",
      "Error on this batch = 0.06257811555185397\n",
      "Cost on val dataset after 994 epochs is = 0.08494045382086941\n",
      "Initial Cost on Val dataset for this epoch 994 = 0.08494045382086941\n",
      "learning rate for this epoch =  0.08904784386044612\n",
      "Error on this batch = 0.03520946408780594\n",
      "Error on this batch = 0.06254881777081332\n",
      "Cost on val dataset after 995 epochs is = 0.08492533003625681\n",
      "Initial Cost on Val dataset for this epoch 995 = 0.08492533003625681\n",
      "learning rate for this epoch =  0.08902546159303537\n",
      "Error on this batch = 0.035188822494634196\n",
      "Error on this batch = 0.06251954972381833\n",
      "Cost on val dataset after 996 epochs is = 0.084910234530715\n",
      "Initial Cost on Val dataset for this epoch 996 = 0.084910234530715\n",
      "learning rate for this epoch =  0.0890031074264038\n",
      "Error on this batch = 0.0351682132534413\n",
      "Error on this batch = 0.06249031138246059\n",
      "Cost on val dataset after 997 epochs is = 0.08489516724094189\n",
      "Initial Cost on Val dataset for this epoch 997 = 0.08489516724094189\n",
      "learning rate for this epoch =  0.08898078129711047\n",
      "Error on this batch = 0.03514763627302109\n",
      "Error on this batch = 0.06246110271876577\n",
      "Cost on val dataset after 998 epochs is = 0.08488012810397359\n",
      "Initial Cost on Val dataset for this epoch 998 = 0.08488012810397359\n",
      "learning rate for this epoch =  0.08895848314192122\n",
      "Error on this batch = 0.03512709146245614\n",
      "Error on this batch = 0.06243192370517941\n",
      "Cost on val dataset after 999 epochs is = 0.08486511705718243\n",
      "Initial Cost on Val dataset for this epoch 999 = 0.08486511705718243\n",
      "learning rate for this epoch =  0.08893621289780759\n",
      "Error on this batch = 0.035106578731118145\n",
      "Error on this batch = 0.062402774314552455\n",
      "Cost on val dataset after 1000 epochs is = 0.08485013403827413\n",
      "Initial Cost on Val dataset for this epoch 1000 = 0.08485013403827413\n",
      "learning rate for this epoch =  0.08891397050194613\n",
      "Error on this batch = 0.03508609798866845\n",
      "Error on this batch = 0.06237365452012654\n",
      "Cost on val dataset after 1001 epochs is = 0.08483517898528582\n",
      "Initial Cost on Val dataset for this epoch 1001 = 0.08483517898528582\n",
      "learning rate for this epoch =  0.0888917558917174\n",
      "Error on this batch = 0.03506564914505904\n",
      "Error on this batch = 0.06234456429551918\n",
      "Cost on val dataset after 1002 epochs is = 0.08482025183658318\n",
      "Initial Cost on Val dataset for this epoch 1002 = 0.08482025183658318\n",
      "learning rate for this epoch =  0.0888695690047051\n",
      "Error on this batch = 0.03504523211053371\n",
      "Error on this batch = 0.062315503614708674\n",
      "Cost on val dataset after 1003 epochs is = 0.08480535253085786\n",
      "Initial Cost on Val dataset for this epoch 1003 = 0.08480535253085786\n",
      "learning rate for this epoch =  0.08884740977869533\n",
      "Error on this batch = 0.03502484679562946\n",
      "Error on this batch = 0.06228647245201908\n",
      "Cost on val dataset after 1004 epochs is = 0.08479048100712488\n",
      "Initial Cost on Val dataset for this epoch 1004 = 0.08479048100712488\n",
      "learning rate for this epoch =  0.0888252781516756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.03500449311117833\n",
      "Error on this batch = 0.06225747078210447\n",
      "Cost on val dataset after 1005 epochs is = 0.08477563720471981\n",
      "Initial Cost on Val dataset for this epoch 1005 = 0.08477563720471981\n",
      "learning rate for this epoch =  0.08880317406183406\n",
      "Error on this batch = 0.03498417096830931\n",
      "Error on this batch = 0.062228498579933685\n",
      "Cost on val dataset after 1006 epochs is = 0.08476082106329588\n",
      "Initial Cost on Val dataset for this epoch 1006 = 0.08476082106329588\n",
      "learning rate for this epoch =  0.08878109744755859\n",
      "Error on this batch = 0.03496388027845069\n",
      "Error on this batch = 0.062199555820774285\n",
      "Cost on val dataset after 1007 epochs is = 0.08474603252282109\n",
      "Initial Cost on Val dataset for this epoch 1007 = 0.08474603252282109\n",
      "learning rate for this epoch =  0.08875904824743605\n",
      "Error on this batch = 0.03494362095333266\n",
      "Error on this batch = 0.062170642480176806\n",
      "Cost on val dataset after 1008 epochs is = 0.08473127152357518\n",
      "Initial Cost on Val dataset for this epoch 1008 = 0.08473127152357518\n",
      "learning rate for this epoch =  0.08873702640025133\n",
      "Error on this batch = 0.03492339290499008\n",
      "Error on this batch = 0.06214175853395847\n",
      "Cost on val dataset after 1009 epochs is = 0.0847165380061465\n",
      "Initial Cost on Val dataset for this epoch 1009 = 0.0847165380061465\n",
      "learning rate for this epoch =  0.08871503184498658\n",
      "Error on this batch = 0.03490319604576566\n",
      "Error on this batch = 0.0621129039581872\n",
      "Cost on val dataset after 1010 epochs is = 0.08470183191142883\n",
      "Initial Cost on Val dataset for this epoch 1010 = 0.08470183191142883\n",
      "learning rate for this epoch =  0.08869306452082039\n",
      "Error on this batch = 0.03488303028831336\n",
      "Error on this batch = 0.06208407872916487\n",
      "Cost on val dataset after 1011 epochs is = 0.08468715318061812\n",
      "Initial Cost on Val dataset for this epoch 1011 = 0.08468715318061812\n",
      "learning rate for this epoch =  0.0886711243671269\n",
      "Error on this batch = 0.03486289554560202\n",
      "Error on this batch = 0.06205528282341101\n",
      "Cost on val dataset after 1012 epochs is = 0.08467250175520921\n",
      "Initial Cost on Val dataset for this epoch 1012 = 0.08467250175520921\n",
      "learning rate for this epoch =  0.08864921132347509\n",
      "Error on this batch = 0.03484279173091928\n",
      "Error on this batch = 0.06202651621764599\n",
      "Cost on val dataset after 1013 epochs is = 0.08465787757699217\n",
      "Initial Cost on Val dataset for this epoch 1013 = 0.08465787757699217\n",
      "learning rate for this epoch =  0.0886273253296278\n",
      "Error on this batch = 0.03482271875787587\n",
      "Error on this batch = 0.06199777888877418\n",
      "Cost on val dataset after 1014 epochs is = 0.08464328058804896\n",
      "Initial Cost on Val dataset for this epoch 1014 = 0.08464328058804896\n",
      "learning rate for this epoch =  0.08860546632554109\n",
      "Error on this batch = 0.03480267654040995\n",
      "Error on this batch = 0.06196907081386711\n",
      "Cost on val dataset after 1015 epochs is = 0.08462871073074972\n",
      "Initial Cost on Val dataset for this epoch 1015 = 0.08462871073074972\n",
      "learning rate for this epoch =  0.0885836342513633\n",
      "Error on this batch = 0.03478266499279188\n",
      "Error on this batch = 0.06194039197014622\n",
      "Cost on val dataset after 1016 epochs is = 0.08461416794774916\n",
      "Initial Cost on Val dataset for this epoch 1016 = 0.08461416794774916\n",
      "learning rate for this epoch =  0.08856182904743433\n",
      "Error on this batch = 0.034762684029629246\n",
      "Error on this batch = 0.0619117423349659\n",
      "Cost on val dataset after 1017 epochs is = 0.08459965218198252\n",
      "Initial Cost on Val dataset for this epoch 1017 = 0.08459965218198252\n",
      "learning rate for this epoch =  0.08854005065428476\n",
      "Error on this batch = 0.03474273356587188\n",
      "Error on this batch = 0.061883121885796144\n",
      "Cost on val dataset after 1018 epochs is = 0.084585163376662\n",
      "Initial Cost on Val dataset for this epoch 1018 = 0.084585163376662\n",
      "learning rate for this epoch =  0.08851829901263515\n",
      "Error on this batch = 0.03472281351681757\n",
      "Error on this batch = 0.06185453060020517\n",
      "Cost on val dataset after 1019 epochs is = 0.08457070147527254\n",
      "Initial Cost on Val dataset for this epoch 1019 = 0.08457070147527254\n",
      "learning rate for this epoch =  0.08849657406339513\n",
      "Error on this batch = 0.0347029237981174\n",
      "Error on this batch = 0.06182596845584204\n",
      "Cost on val dataset after 1020 epochs is = 0.08455626642156785\n",
      "Initial Cost on Val dataset for this epoch 1020 = 0.08455626642156785\n",
      "learning rate for this epoch =  0.08847487574766279\n",
      "Error on this batch = 0.03468306432578193\n",
      "Error on this batch = 0.06179743543041931\n",
      "Cost on val dataset after 1021 epochs is = 0.08454185815956623\n",
      "Initial Cost on Val dataset for this epoch 1021 = 0.08454185815956623\n",
      "learning rate for this epoch =  0.08845320400672366\n",
      "Error on this batch = 0.034663235016187184\n",
      "Error on this batch = 0.061768931501695275\n",
      "Cost on val dataset after 1022 epochs is = 0.08452747663354632\n",
      "Initial Cost on Val dataset for this epoch 1022 = 0.08452747663354632\n",
      "learning rate for this epoch =  0.0884315587820501\n",
      "Error on this batch = 0.03464343578608103\n",
      "Error on this batch = 0.06174045664745667\n",
      "Cost on val dataset after 1023 epochs is = 0.08451312178804277\n",
      "Initial Cost on Val dataset for this epoch 1023 = 0.08451312178804277\n",
      "learning rate for this epoch =  0.08840994001530049\n",
      "Error on this batch = 0.03462366655258947\n",
      "Error on this batch = 0.06171201084550086\n",
      "Cost on val dataset after 1024 epochs is = 0.08449879356784183\n",
      "Initial Cost on Val dataset for this epoch 1024 = 0.08449879356784183\n",
      "learning rate for this epoch =  0.08838834764831843\n",
      "Error on this batch = 0.034603927233223725\n",
      "Error on this batch = 0.06168359407361848\n",
      "Cost on val dataset after 1025 epochs is = 0.08448449191797686\n",
      "Initial Cost on Val dataset for this epoch 1025 = 0.08448449191797686\n",
      "learning rate for this epoch =  0.08836678162313201\n",
      "Error on this batch = 0.0345842177458868\n",
      "Error on this batch = 0.06165520630957573\n",
      "Cost on val dataset after 1026 epochs is = 0.08447021678372357\n",
      "Initial Cost on Val dataset for this epoch 1026 = 0.08447021678372357\n",
      "learning rate for this epoch =  0.088345241881953\n",
      "Error on this batch = 0.03456453800888062\n",
      "Error on this batch = 0.061626847531096804\n",
      "Cost on val dataset after 1027 epochs is = 0.08445596811059562\n",
      "Initial Cost on Val dataset for this epoch 1027 = 0.08445596811059562\n",
      "learning rate for this epoch =  0.0883237283671761\n",
      "Error on this batch = 0.03454488794091331\n",
      "Error on this batch = 0.061598517715846415\n",
      "Cost on val dataset after 1028 epochs is = 0.0844417458443396\n",
      "Initial Cost on Val dataset for this epoch 1028 = 0.0844417458443396\n",
      "learning rate for this epoch =  0.0883022410213782\n",
      "Error on this batch = 0.03452526746110642\n",
      "Error on this batch = 0.06157021684141229\n",
      "Cost on val dataset after 1029 epochs is = 0.08442754993093025\n",
      "Initial Cost on Val dataset for this epoch 1029 = 0.08442754993093025\n",
      "learning rate for this epoch =  0.08828077978731765\n",
      "Error on this batch = 0.034505676489002574\n",
      "Error on this batch = 0.06154194488528777\n",
      "Cost on val dataset after 1030 epochs is = 0.0844133803165656\n",
      "Initial Cost on Val dataset for this epoch 1030 = 0.0844133803165656\n",
      "learning rate for this epoch =  0.08825934460793343\n",
      "Error on this batch = 0.03448611494457285\n",
      "Error on this batch = 0.061513701824854404\n",
      "Cost on val dataset after 1031 epochs is = 0.08439923694766185\n",
      "Initial Cost on Val dataset for this epoch 1031 = 0.08439923694766185\n",
      "learning rate for this epoch =  0.08823793542634452\n",
      "Error on this batch = 0.03446658274822469\n",
      "Error on this batch = 0.06148548763736485\n",
      "Cost on val dataset after 1032 epochs is = 0.08438511977084837\n",
      "Initial Cost on Val dataset for this epoch 1032 = 0.08438511977084837\n",
      "learning rate for this epoch =  0.08821655218584905\n",
      "Error on this batch = 0.03444707982080965\n",
      "Error on this batch = 0.06145730229992559\n",
      "Cost on val dataset after 1033 epochs is = 0.08437102873296239\n",
      "Initial Cost on Val dataset for this epoch 1033 = 0.08437102873296239\n",
      "learning rate for this epoch =  0.08819519482992363\n",
      "Error on this batch = 0.034427606083631206\n",
      "Error on this batch = 0.06142914578947995\n",
      "Cost on val dataset after 1034 epochs is = 0.0843569637810439\n",
      "Initial Cost on Val dataset for this epoch 1034 = 0.0843569637810439\n",
      "learning rate for this epoch =  0.08817386330222259\n",
      "Error on this batch = 0.03440816145845286\n",
      "Error on this batch = 0.06140101808279131\n",
      "Cost on val dataset after 1035 epochs is = 0.08434292486233029\n",
      "Initial Cost on Val dataset for this epoch 1035 = 0.08434292486233029\n",
      "learning rate for this epoch =  0.08815255754657725\n",
      "Error on this batch = 0.03438874586750605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.061372919156426314\n",
      "Cost on val dataset after 1036 epochs is = 0.08432891192425086\n",
      "Initial Cost on Val dataset for this epoch 1036 = 0.08432891192425086\n",
      "learning rate for this epoch =  0.08813127750699522\n",
      "Error on this batch = 0.03436935923349822\n",
      "Error on this batch = 0.06134484898673836\n",
      "Cost on val dataset after 1037 epochs is = 0.08431492491442148\n",
      "Initial Cost on Val dataset for this epoch 1037 = 0.08431492491442148\n",
      "learning rate for this epoch =  0.08811002312765961\n",
      "Error on this batch = 0.03435000147962089\n",
      "Error on this batch = 0.06131680754985125\n",
      "Cost on val dataset after 1038 epochs is = 0.08430096378063896\n",
      "Initial Cost on Val dataset for this epoch 1038 = 0.08430096378063896\n",
      "learning rate for this epoch =  0.08808879435292839\n",
      "Error on this batch = 0.03433067252955789\n",
      "Error on this batch = 0.061288794821643074\n",
      "Cost on val dataset after 1039 epochs is = 0.08428702847087562\n",
      "Initial Cost on Val dataset for this epoch 1039 = 0.08428702847087562\n",
      "learning rate for this epoch =  0.08806759112733367\n",
      "Error on this batch = 0.03431137230749317\n",
      "Error on this batch = 0.061260810777730254\n",
      "Cost on val dataset after 1040 epochs is = 0.08427311893327345\n",
      "Initial Cost on Val dataset for this epoch 1040 = 0.08427311893327345\n",
      "learning rate for this epoch =  0.0880464133955809\n",
      "Error on this batch = 0.034292100738119106\n",
      "Error on this batch = 0.06123285539345192\n",
      "Cost on val dataset after 1041 epochs is = 0.08425923511613849\n",
      "Initial Cost on Val dataset for this epoch 1041 = 0.08425923511613849\n",
      "learning rate for this epoch =  0.08802526110254827\n",
      "Error on this batch = 0.034272857746644465\n",
      "Error on this batch = 0.06120492864385449\n",
      "Cost on val dataset after 1042 epochs is = 0.0842453769679351\n",
      "Initial Cost on Val dataset for this epoch 1042 = 0.0842453769679351\n",
      "learning rate for this epoch =  0.0880041341932859\n",
      "Error on this batch = 0.03425364325880235\n",
      "Error on this batch = 0.06117703050367648\n",
      "Cost on val dataset after 1043 epochs is = 0.08423154443728016\n",
      "Initial Cost on Val dataset for this epoch 1043 = 0.08423154443728016\n",
      "learning rate for this epoch =  0.08798303261301525\n",
      "Error on this batch = 0.03423445720085813\n",
      "Error on this batch = 0.06114916094733377\n",
      "Cost on val dataset after 1044 epochs is = 0.08421773747293708\n",
      "Initial Cost on Val dataset for this epoch 1044 = 0.08421773747293708\n",
      "learning rate for this epoch =  0.08796195630712837\n",
      "Error on this batch = 0.034215299499617303\n",
      "Error on this batch = 0.0611213199489049\n",
      "Cost on val dataset after 1045 epochs is = 0.08420395602381009\n",
      "Initial Cost on Val dataset for this epoch 1045 = 0.08420395602381009\n",
      "learning rate for this epoch =  0.08794090522118717\n",
      "Error on this batch = 0.03419617008243326\n",
      "Error on this batch = 0.06109350748211703\n",
      "Cost on val dataset after 1046 epochs is = 0.08419020003893814\n",
      "Initial Cost on Val dataset for this epoch 1046 = 0.08419020003893814\n",
      "learning rate for this epoch =  0.08791987930092278\n",
      "Error on this batch = 0.034177068877214827\n",
      "Error on this batch = 0.06106572352033195\n",
      "Cost on val dataset after 1047 epochs is = 0.08417646946748907\n",
      "Initial Cost on Val dataset for this epoch 1047 = 0.08417646946748907\n",
      "learning rate for this epoch =  0.08789887849223484\n",
      "Error on this batch = 0.03415799581243384\n",
      "Error on this batch = 0.06103796803653262\n",
      "Cost on val dataset after 1048 epochs is = 0.0841627642587535\n",
      "Initial Cost on Val dataset for this epoch 1048 = 0.0841627642587535\n",
      "learning rate for this epoch =  0.08787790274119082\n",
      "Error on this batch = 0.03413895081713253\n",
      "Error on this batch = 0.06101024100330994\n",
      "Cost on val dataset after 1049 epochs is = 0.08414908436213883\n",
      "Initial Cost on Val dataset for this epoch 1049 = 0.08414908436213883\n",
      "learning rate for this epoch =  0.08785695199402538\n",
      "Error on this batch = 0.03411993382093058\n",
      "Error on this batch = 0.06098254239285008\n",
      "Cost on val dataset after 1050 epochs is = 0.08413542972716322\n",
      "Initial Cost on Val dataset for this epoch 1050 = 0.08413542972716322\n",
      "learning rate for this epoch =  0.08783602619713961\n",
      "Error on this batch = 0.03410094475403235\n",
      "Error on this batch = 0.06095487217692197\n",
      "Cost on val dataset after 1051 epochs is = 0.0841218003034495\n",
      "Initial Cost on Val dataset for this epoch 1051 = 0.0841218003034495\n",
      "learning rate for this epoch =  0.08781512529710042\n",
      "Error on this batch = 0.03408198354723361\n",
      "Error on this batch = 0.0609272303268656\n",
      "Cost on val dataset after 1052 epochs is = 0.08410819604071912\n",
      "Initial Cost on Val dataset for this epoch 1052 = 0.08410819604071912\n",
      "learning rate for this epoch =  0.08779424924063986\n",
      "Error on this batch = 0.03406305013192815\n",
      "Error on this batch = 0.060899616813580186\n",
      "Cost on val dataset after 1053 epochs is = 0.084094616888786\n",
      "Initial Cost on Val dataset for this epoch 1053 = 0.084094616888786\n",
      "learning rate for this epoch =  0.08777339797465443\n",
      "Error on this batch = 0.034044144440114325\n",
      "Error on this batch = 0.0608720316075133\n",
      "Cost on val dataset after 1054 epochs is = 0.0840810627975505\n",
      "Initial Cost on Val dataset for this epoch 1054 = 0.0840810627975505\n",
      "learning rate for this epoch =  0.08775257144620446\n",
      "Error on this batch = 0.034025266404401115\n",
      "Error on this batch = 0.06084447467865011\n",
      "Cost on val dataset after 1055 epochs is = 0.08406753371699328\n",
      "Initial Cost on Val dataset for this epoch 1055 = 0.08406753371699328\n",
      "learning rate for this epoch =  0.08773176960251337\n",
      "Error on this batch = 0.03400641595801418\n",
      "Error on this batch = 0.0608169459965033\n",
      "Cost on val dataset after 1056 epochs is = 0.0840540295971693\n",
      "Initial Cost on Val dataset for this epoch 1056 = 0.0840540295971693\n",
      "learning rate for this epoch =  0.08771099239096714\n",
      "Error on this batch = 0.03398759303480155\n",
      "Error on this batch = 0.06078944553010338\n",
      "Cost on val dataset after 1057 epochs is = 0.08404055038820173\n",
      "Initial Cost on Val dataset for this epoch 1057 = 0.08404055038820173\n",
      "learning rate for this epoch =  0.08769023975911351\n",
      "Error on this batch = 0.03396879756923899\n",
      "Error on this batch = 0.060761973247989286\n",
      "Cost on val dataset after 1058 epochs is = 0.08402709604027571\n",
      "Initial Cost on Val dataset for this epoch 1058 = 0.08402709604027571\n",
      "learning rate for this epoch =  0.08766951165466147\n",
      "Error on this batch = 0.033950029496435205\n",
      "Error on this batch = 0.06073452911819992\n",
      "Cost on val dataset after 1059 epochs is = 0.0840136665036327\n",
      "Initial Cost on Val dataset for this epoch 1059 = 0.0840136665036327\n",
      "learning rate for this epoch =  0.08764880802548045\n",
      "Error on this batch = 0.033931288752136676\n",
      "Error on this batch = 0.06070711310826582\n",
      "Cost on val dataset after 1060 epochs is = 0.08400026172856408\n",
      "Initial Cost on Val dataset for this epoch 1060 = 0.08400026172856408\n",
      "learning rate for this epoch =  0.08762812881959987\n",
      "Error on this batch = 0.03391257527273224\n",
      "Error on this batch = 0.060679725185201434\n",
      "Cost on val dataset after 1061 epochs is = 0.0839868816654055\n",
      "Initial Cost on Val dataset for this epoch 1061 = 0.0839868816654055\n",
      "learning rate for this epoch =  0.08760747398520836\n",
      "Error on this batch = 0.03389388899525727\n",
      "Error on this batch = 0.06065236531549801\n",
      "Cost on val dataset after 1062 epochs is = 0.08397352626453072\n",
      "Initial Cost on Val dataset for this epoch 1062 = 0.08397352626453072\n",
      "learning rate for this epoch =  0.08758684347065314\n",
      "Error on this batch = 0.03387522985739763\n",
      "Error on this batch = 0.06062503346511698\n",
      "Cost on val dataset after 1063 epochs is = 0.08396019547634591\n",
      "Initial Cost on Val dataset for this epoch 1063 = 0.08396019547634591\n",
      "learning rate for this epoch =  0.08756623722443944\n",
      "Error on this batch = 0.03385659779749326\n",
      "Error on this batch = 0.060597729599483736\n",
      "Cost on val dataset after 1064 epochs is = 0.08394688925128366\n",
      "Initial Cost on Val dataset for this epoch 1064 = 0.08394688925128366\n",
      "learning rate for this epoch =  0.08754565519522983\n",
      "Error on this batch = 0.03383799275454139\n",
      "Error on this batch = 0.06057045368348219\n",
      "Cost on val dataset after 1065 epochs is = 0.08393360753979735\n",
      "Initial Cost on Val dataset for this epoch 1065 = 0.08393360753979735\n",
      "learning rate for this epoch =  0.08752509733184359\n",
      "Error on this batch = 0.03381941466819945\n",
      "Error on this batch = 0.060543205681449656\n",
      "Cost on val dataset after 1066 epochs is = 0.08392035029235528\n",
      "Initial Cost on Val dataset for this epoch 1066 = 0.08392035029235528\n",
      "learning rate for this epoch =  0.0875045635832561\n",
      "Error on this batch = 0.033800863478787586\n",
      "Error on this batch = 0.06051598555717248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1067 epochs is = 0.0839071174594351\n",
      "Initial Cost on Val dataset for this epoch 1067 = 0.0839071174594351\n",
      "learning rate for this epoch =  0.08748405389859822\n",
      "Error on this batch = 0.03378233912729079\n",
      "Error on this batch = 0.060488793273882076\n",
      "Cost on val dataset after 1068 epochs is = 0.08389390899151827\n",
      "Initial Cost on Val dataset for this epoch 1068 = 0.08389390899151827\n",
      "learning rate for this epoch =  0.08746356822715562\n",
      "Error on this batch = 0.03376384155536074\n",
      "Error on this batch = 0.06046162879425156\n",
      "Cost on val dataset after 1069 epochs is = 0.08388072483908446\n",
      "Initial Cost on Val dataset for this epoch 1069 = 0.08388072483908446\n",
      "learning rate for this epoch =  0.08744310651836827\n",
      "Error on this batch = 0.033745370705317156\n",
      "Error on this batch = 0.06043449208039295\n",
      "Cost on val dataset after 1070 epochs is = 0.08386756495260618\n",
      "Initial Cost on Val dataset for this epoch 1070 = 0.08386756495260618\n",
      "learning rate for this epoch =  0.08742266872182974\n",
      "Error on this batch = 0.0337269265201489\n",
      "Error on this batch = 0.06040738309385496\n",
      "Cost on val dataset after 1071 epochs is = 0.08385442928254341\n",
      "Initial Cost on Val dataset for this epoch 1071 = 0.08385442928254341\n",
      "learning rate for this epoch =  0.08740225478728658\n",
      "Error on this batch = 0.03370850894351455\n",
      "Error on this batch = 0.06038030179562133\n",
      "Cost on val dataset after 1072 epochs is = 0.08384131777933838\n",
      "Initial Cost on Val dataset for this epoch 1072 = 0.08384131777933838\n",
      "learning rate for this epoch =  0.0873818646646378\n",
      "Error on this batch = 0.03369011791974273\n",
      "Error on this batch = 0.06035324814610954\n",
      "Cost on val dataset after 1073 epochs is = 0.08382823039341049\n",
      "Initial Cost on Val dataset for this epoch 1073 = 0.08382823039341049\n",
      "learning rate for this epoch =  0.08736149830393418\n",
      "Error on this batch = 0.03367175339383187\n",
      "Error on this batch = 0.06032622210517055\n",
      "Cost on val dataset after 1074 epochs is = 0.08381516707515106\n",
      "Initial Cost on Val dataset for this epoch 1074 = 0.08381516707515106\n",
      "learning rate for this epoch =  0.0873411556553777\n",
      "Error on this batch = 0.03365341531144977\n",
      "Error on this batch = 0.06029922363208848\n",
      "Cost on val dataset after 1075 epochs is = 0.08380212777491865\n",
      "Initial Cost on Val dataset for this epoch 1075 = 0.08380212777491865\n",
      "learning rate for this epoch =  0.087320836669321\n",
      "Error on this batch = 0.03363510361893256\n",
      "Error on this batch = 0.06027225268558128\n",
      "Cost on val dataset after 1076 epochs is = 0.08378911244303397\n",
      "Initial Cost on Val dataset for this epoch 1076 = 0.08378911244303397\n",
      "learning rate for this epoch =  0.08730054129626662\n",
      "Error on this batch = 0.0336168182632835\n",
      "Error on this batch = 0.06024530922380185\n",
      "Cost on val dataset after 1077 epochs is = 0.08377612102977539\n",
      "Initial Cost on Val dataset for this epoch 1077 = 0.08377612102977539\n",
      "learning rate for this epoch =  0.08728026948686665\n",
      "Error on this batch = 0.03359855919217122\n",
      "Error on this batch = 0.060218393204339596\n",
      "Cost on val dataset after 1078 epochs is = 0.08376315348537428\n",
      "Initial Cost on Val dataset for this epoch 1078 = 0.08376315348537428\n",
      "learning rate for this epoch =  0.0872600211919219\n",
      "Error on this batch = 0.03358032635392753\n",
      "Error on this batch = 0.06019150458422253\n",
      "Cost on val dataset after 1079 epochs is = 0.08375020976001042\n",
      "Initial Cost on Val dataset for this epoch 1079 = 0.08375020976001042\n",
      "learning rate for this epoch =  0.08723979636238147\n",
      "Error on this batch = 0.033562119697544975\n",
      "Error on this batch = 0.0601646433199201\n",
      "Cost on val dataset after 1080 epochs is = 0.08373728980380787\n",
      "Initial Cost on Val dataset for this epoch 1080 = 0.08373728980380787\n",
      "learning rate for this epoch =  0.08721959494934213\n",
      "Error on this batch = 0.033543939172673974\n",
      "Error on this batch = 0.06013780936734625\n",
      "Cost on val dataset after 1081 epochs is = 0.08372439356683059\n",
      "Initial Cost on Val dataset for this epoch 1081 = 0.08372439356683059\n",
      "learning rate for this epoch =  0.0871994169040477\n",
      "Error on this batch = 0.03352578472961949\n",
      "Error on this batch = 0.06011100268186331\n",
      "Cost on val dataset after 1082 epochs is = 0.08371152099907848\n",
      "Initial Cost on Val dataset for this epoch 1082 = 0.08371152099907848\n",
      "learning rate for this epoch =  0.08717926217788849\n",
      "Error on this batch = 0.033507656319337324\n",
      "Error on this batch = 0.06008422321828594\n",
      "Cost on val dataset after 1083 epochs is = 0.08369867205048348\n",
      "Initial Cost on Val dataset for this epoch 1083 = 0.08369867205048348\n",
      "learning rate for this epoch =  0.0871591307224008\n",
      "Error on this batch = 0.033489553893430106\n",
      "Error on this batch = 0.06005747093088616\n",
      "Cost on val dataset after 1084 epochs is = 0.08368584667090559\n",
      "Initial Cost on Val dataset for this epoch 1084 = 0.08368584667090559\n",
      "learning rate for this epoch =  0.08713902248926618\n",
      "Error on this batch = 0.03347147740414296\n",
      "Error on this batch = 0.0600307457733984\n",
      "Cost on val dataset after 1085 epochs is = 0.08367304481012958\n",
      "Initial Cost on Val dataset for this epoch 1085 = 0.08367304481012958\n",
      "learning rate for this epoch =  0.08711893743031107\n",
      "Error on this batch = 0.03345342680435852\n",
      "Error on this batch = 0.06000404769902506\n",
      "Cost on val dataset after 1086 epochs is = 0.08366026641786116\n",
      "Initial Cost on Val dataset for this epoch 1086 = 0.08366026641786116\n",
      "learning rate for this epoch =  0.08709887549750603\n",
      "Error on this batch = 0.03343540204759202\n",
      "Error on this batch = 0.05997737666044291\n",
      "Cost on val dataset after 1087 epochs is = 0.0836475114437239\n",
      "Initial Cost on Val dataset for this epoch 1087 = 0.0836475114437239\n",
      "learning rate for this epoch =  0.08707883664296534\n",
      "Error on this batch = 0.03341740308798557\n",
      "Error on this batch = 0.05995073260980943\n",
      "Cost on val dataset after 1088 epochs is = 0.08363477983725595\n",
      "Initial Cost on Val dataset for this epoch 1088 = 0.08363477983725595\n",
      "learning rate for this epoch =  0.08705882081894635\n",
      "Error on this batch = 0.033399429880302506\n",
      "Error on this batch = 0.05992411549877004\n",
      "Cost on val dataset after 1089 epochs is = 0.08362207154790709\n",
      "Initial Cost on Val dataset for this epoch 1089 = 0.08362207154790709\n",
      "learning rate for this epoch =  0.08703882797784893\n",
      "Error on this batch = 0.03338148237992097\n",
      "Error on this batch = 0.05989752527846541\n",
      "Cost on val dataset after 1090 epochs is = 0.08360938652503584\n",
      "Initial Cost on Val dataset for this epoch 1090 = 0.08360938652503584\n",
      "learning rate for this epoch =  0.08701885807221492\n",
      "Error on this batch = 0.03336356054282768\n",
      "Error on this batch = 0.059870961899539346\n",
      "Cost on val dataset after 1091 epochs is = 0.0835967247179069\n",
      "Initial Cost on Val dataset for this epoch 1091 = 0.0835967247179069\n",
      "learning rate for this epoch =  0.08699891105472762\n",
      "Error on this batch = 0.03334566432561087\n",
      "Error on this batch = 0.059844425312147155\n",
      "Cost on val dataset after 1092 epochs is = 0.08358408607568839\n",
      "Initial Cost on Val dataset for this epoch 1092 = 0.08358408607568839\n",
      "learning rate for this epoch =  0.08697898687821116\n",
      "Error on this batch = 0.03332779368545324\n",
      "Error on this batch = 0.059817915465964176\n",
      "Cost on val dataset after 1093 epochs is = 0.08357147054744983\n",
      "Initial Cost on Val dataset for this epoch 1093 = 0.08357147054744983\n",
      "learning rate for this epoch =  0.08695908549563003\n",
      "Error on this batch = 0.03330994858012451\n",
      "Error on this batch = 0.05979143231019487\n",
      "Cost on val dataset after 1094 epochs is = 0.08355887808215975\n",
      "Initial Cost on Val dataset for this epoch 1094 = 0.08355887808215975\n",
      "learning rate for this epoch =  0.08693920686008848\n",
      "Error on this batch = 0.03329212896797364\n",
      "Error on this batch = 0.05976497579358217\n",
      "Cost on val dataset after 1095 epochs is = 0.08354630862868383\n",
      "Initial Cost on Val dataset for this epoch 1095 = 0.08354630862868383\n",
      "learning rate for this epoch =  0.08691935092482998\n",
      "Error on this batch = 0.03327433480792088\n",
      "Error on this batch = 0.05973854586441718\n",
      "Cost on val dataset after 1096 epochs is = 0.08353376213578291\n",
      "Initial Cost on Val dataset for this epoch 1096 = 0.08353376213578291\n",
      "learning rate for this epoch =  0.08689951764323674\n",
      "Error on this batch = 0.03325656605944946\n",
      "Error on this batch = 0.059712142470549234\n",
      "Cost on val dataset after 1097 epochs is = 0.08352123855211162\n",
      "Initial Cost on Val dataset for this epoch 1097 = 0.08352123855211162\n",
      "learning rate for this epoch =  0.08687970696882906\n",
      "Error on this batch = 0.033238822682597084\n",
      "Error on this batch = 0.05968576555939622\n",
      "Cost on val dataset after 1098 epochs is = 0.08350873782621661\n",
      "Initial Cost on Val dataset for this epoch 1098 = 0.08350873782621661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate for this epoch =  0.08685991885526495\n",
      "Error on this batch = 0.03322110463794709\n",
      "Error on this batch = 0.05965941507795528\n",
      "Cost on val dataset after 1099 epochs is = 0.08349625990653549\n",
      "Initial Cost on Val dataset for this epoch 1099 = 0.08349625990653549\n",
      "learning rate for this epoch =  0.08684015325633943\n",
      "Error on this batch = 0.03320341188661948\n",
      "Error on this batch = 0.05963309097281366\n",
      "Cost on val dataset after 1100 epochs is = 0.08348380474139559\n",
      "Initial Cost on Val dataset for this epoch 1100 = 0.08348380474139559\n",
      "learning rate for this epoch =  0.08682041012598414\n",
      "Error on this batch = 0.03318574439026177\n",
      "Error on this batch = 0.059606793190159844\n",
      "Cost on val dataset after 1101 epochs is = 0.08347137227901312\n",
      "Initial Cost on Val dataset for this epoch 1101 = 0.08347137227901312\n",
      "learning rate for this epoch =  0.08680068941826673\n",
      "Error on this batch = 0.033168102111039446\n",
      "Error on this batch = 0.0595805216757951\n",
      "Cost on val dataset after 1102 epochs is = 0.08345896246749232\n",
      "Initial Cost on Val dataset for this epoch 1102 = 0.08345896246749232\n",
      "learning rate for this epoch =  0.08678099108739035\n",
      "Error on this batch = 0.033150485011626325\n",
      "Error on this batch = 0.059554276375145036\n",
      "Cost on val dataset after 1103 epochs is = 0.083446575254825\n",
      "Initial Cost on Val dataset for this epoch 1103 = 0.083446575254825\n",
      "learning rate for this epoch =  0.08676131508769315\n",
      "Error on this batch = 0.033132893055194935\n",
      "Error on this batch = 0.05952805723327148\n",
      "Cost on val dataset after 1104 epochs is = 0.08343421058889\n",
      "Initial Cost on Val dataset for this epoch 1104 = 0.08343421058889\n",
      "learning rate for this epoch =  0.08674166137364775\n",
      "Error on this batch = 0.03311532620540633\n",
      "Error on this batch = 0.05950186419488448\n",
      "Cost on val dataset after 1105 epochs is = 0.08342186841745314\n",
      "Initial Cost on Val dataset for this epoch 1105 = 0.08342186841745314\n",
      "learning rate for this epoch =  0.0867220298998607\n",
      "Error on this batch = 0.03309778442640015\n",
      "Error on this batch = 0.059475697204354604\n",
      "Cost on val dataset after 1106 epochs is = 0.08340954868816698\n",
      "Initial Cost on Val dataset for this epoch 1106 = 0.08340954868816698\n",
      "learning rate for this epoch =  0.08670242062107203\n",
      "Error on this batch = 0.0330802676827842\n",
      "Error on this batch = 0.059449556205725375\n",
      "Cost on val dataset after 1107 epochs is = 0.08339725134857111\n",
      "Initial Cost on Val dataset for this epoch 1107 = 0.08339725134857111\n",
      "learning rate for this epoch =  0.08668283349215462\n",
      "Error on this batch = 0.033062775939624194\n",
      "Error on this batch = 0.059423441142725596\n",
      "Cost on val dataset after 1108 epochs is = 0.08338497634609238\n",
      "Initial Cost on Val dataset for this epoch 1108 = 0.08338497634609238\n",
      "learning rate for this epoch =  0.08666326846811381\n",
      "Error on this batch = 0.03304530916243322\n",
      "Error on this batch = 0.05939735195878221\n",
      "Cost on val dataset after 1109 epochs is = 0.0833727236280455\n",
      "Initial Cost on Val dataset for this epoch 1109 = 0.0833727236280455\n",
      "learning rate for this epoch =  0.08664372550408686\n",
      "Error on this batch = 0.03302786731716112\n",
      "Error on this batch = 0.05937128859703305\n",
      "Cost on val dataset after 1110 epochs is = 0.08336049314163346\n",
      "Initial Cost on Val dataset for this epoch 1110 = 0.08336049314163346\n",
      "learning rate for this epoch =  0.0866242045553424\n",
      "Error on this batch = 0.03301045037018376\n",
      "Error on this batch = 0.05934525100033955\n",
      "Cost on val dataset after 1111 epochs is = 0.08334828483394865\n",
      "Initial Cost on Val dataset for this epoch 1111 = 0.08334828483394865\n",
      "learning rate for this epoch =  0.08660470557727994\n",
      "Error on this batch = 0.03299305828829244\n",
      "Error on this batch = 0.05931923911129992\n",
      "Cost on val dataset after 1112 epochs is = 0.08333609865197351\n",
      "Initial Cost on Val dataset for this epoch 1112 = 0.08333609865197351\n",
      "learning rate for this epoch =  0.08658522852542944\n",
      "Error on this batch = 0.03297569103868289\n",
      "Error on this batch = 0.05929325287226206\n",
      "Cost on val dataset after 1113 epochs is = 0.08332393454258208\n",
      "Initial Cost on Val dataset for this epoch 1113 = 0.08332393454258208\n",
      "learning rate for this epoch =  0.0865657733554507\n",
      "Error on this batch = 0.03295834858894455\n",
      "Error on this batch = 0.05926729222533654\n",
      "Cost on val dataset after 1114 epochs is = 0.08331179245254097\n",
      "Initial Cost on Val dataset for this epoch 1114 = 0.08331179245254097\n",
      "learning rate for this epoch =  0.08654634002313295\n",
      "Error on this batch = 0.03294103090704963\n",
      "Error on this batch = 0.0592413571124098\n",
      "Cost on val dataset after 1115 epochs is = 0.08329967232851111\n",
      "Initial Cost on Val dataset for this epoch 1115 = 0.08329967232851111\n",
      "learning rate for this epoch =  0.08652692848439436\n",
      "Error on this batch = 0.03292373796134214\n",
      "Error on this batch = 0.059215447475157286\n",
      "Cost on val dataset after 1116 epochs is = 0.08328757411704929\n",
      "Initial Cost on Val dataset for this epoch 1116 = 0.08328757411704929\n",
      "learning rate for this epoch =  0.08650753869528147\n",
      "Error on this batch = 0.03290646972052706\n",
      "Error on this batch = 0.05918956325505648\n",
      "Cost on val dataset after 1117 epochs is = 0.08327549776460992\n",
      "Initial Cost on Val dataset for this epoch 1117 = 0.08327549776460992\n",
      "learning rate for this epoch =  0.08648817061196874\n",
      "Error on this batch = 0.032889226153659364\n",
      "Error on this batch = 0.059163704393400136\n",
      "Cost on val dataset after 1118 epochs is = 0.08326344321754708\n",
      "Initial Cost on Val dataset for this epoch 1118 = 0.08326344321754708\n",
      "learning rate for this epoch =  0.08646882419075813\n",
      "Error on this batch = 0.03287200723013318\n",
      "Error on this batch = 0.05913787083130925\n",
      "Cost on val dataset after 1119 epochs is = 0.08325141042211663\n",
      "Initial Cost on Val dataset for this epoch 1119 = 0.08325141042211663\n",
      "learning rate for this epoch =  0.08644949938807851\n",
      "Error on this batch = 0.032854812919670795\n",
      "Error on this batch = 0.059112062509746155\n",
      "Cost on val dataset after 1120 epochs is = 0.08323939932447848\n",
      "Initial Cost on Val dataset for this epoch 1120 = 0.08323939932447848\n",
      "learning rate for this epoch =  0.08643019616048525\n",
      "Error on this batch = 0.03283764319231196\n",
      "Error on this batch = 0.05908627936952758\n",
      "Cost on val dataset after 1121 epochs is = 0.08322740987069889\n",
      "Initial Cost on Val dataset for this epoch 1121 = 0.08322740987069889\n",
      "learning rate for this epoch =  0.0864109144646597\n",
      "Error on this batch = 0.03282049801840306\n",
      "Error on this batch = 0.05906052135133752\n",
      "Cost on val dataset after 1122 epochs is = 0.0832154420067532\n",
      "Initial Cost on Val dataset for this epoch 1122 = 0.0832154420067532\n",
      "learning rate for this epoch =  0.08639165425740875\n",
      "Error on this batch = 0.0328033773685863\n",
      "Error on this batch = 0.05903478839574012\n",
      "Cost on val dataset after 1123 epochs is = 0.08320349567852846\n",
      "Initial Cost on Val dataset for this epoch 1123 = 0.08320349567852846\n",
      "learning rate for this epoch =  0.08637241549566431\n",
      "Error on this batch = 0.032786281213789306\n",
      "Error on this batch = 0.059009080443192474\n",
      "Cost on val dataset after 1124 epochs is = 0.08319157083182617\n",
      "Initial Cost on Val dataset for this epoch 1124 = 0.08319157083182617\n",
      "learning rate for this epoch =  0.08635319813648287\n",
      "Error on this batch = 0.032769209525214234\n",
      "Error on this batch = 0.0589833974340572\n",
      "Cost on val dataset after 1125 epochs is = 0.0831796674123654\n",
      "Initial Cost on Val dataset for this epoch 1125 = 0.0831796674123654\n",
      "learning rate for this epoch =  0.08633400213704505\n",
      "Error on this batch = 0.03275216227432757\n",
      "Error on this batch = 0.0589577393086152\n",
      "Cost on val dataset after 1126 epochs is = 0.08316778536578585\n",
      "Initial Cost on Val dataset for this epoch 1126 = 0.08316778536578585\n",
      "learning rate for this epoch =  0.08631482745465505\n",
      "Error on this batch = 0.032735139432849614\n",
      "Error on this batch = 0.05893210600707789\n",
      "Cost on val dataset after 1127 epochs is = 0.08315592463765102\n",
      "Initial Cost on Val dataset for this epoch 1127 = 0.08315592463765102\n",
      "learning rate for this epoch =  0.08629567404674027\n",
      "Error on this batch = 0.03271814097274432\n",
      "Error on this batch = 0.05890649746959961\n",
      "Cost on val dataset after 1128 epochs is = 0.08314408517345162\n",
      "Initial Cost on Val dataset for this epoch 1128 = 0.08314408517345162\n",
      "learning rate for this epoch =  0.0862765418708508\n",
      "Error on this batch = 0.032701166866209046\n",
      "Error on this batch = 0.05888091363628981\n",
      "Cost on val dataset after 1129 epochs is = 0.08313226691860898\n",
      "Initial Cost on Val dataset for this epoch 1129 = 0.08313226691860898\n",
      "learning rate for this epoch =  0.08625743088465897\n",
      "Error on this batch = 0.03268421708566472\n",
      "Error on this batch = 0.05885535444722497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1130 epochs is = 0.08312046981847872\n",
      "Initial Cost on Val dataset for this epoch 1130 = 0.08312046981847872\n",
      "learning rate for this epoch =  0.0862383410459589\n",
      "Error on this batch = 0.03266729160374576\n",
      "Error on this batch = 0.05882981984246053\n",
      "Cost on val dataset after 1131 epochs is = 0.0831086938183544\n",
      "Initial Cost on Val dataset for this epoch 1131 = 0.0831086938183544\n",
      "learning rate for this epoch =  0.08621927231266602\n",
      "Error on this batch = 0.03265039039329053\n",
      "Error on this batch = 0.058804309762042505\n",
      "Cost on val dataset after 1132 epochs is = 0.0830969388634713\n",
      "Initial Cost on Val dataset for this epoch 1132 = 0.0830969388634713\n",
      "learning rate for this epoch =  0.08620022464281663\n",
      "Error on this batch = 0.03263351342733173\n",
      "Error on this batch = 0.05877882414601903\n",
      "Cost on val dataset after 1133 epochs is = 0.08308520489901049\n",
      "Initial Cost on Val dataset for this epoch 1133 = 0.08308520489901049\n",
      "learning rate for this epoch =  0.08618119799456743\n",
      "Error on this batch = 0.03261666067908694\n",
      "Error on this batch = 0.05875336293445156\n",
      "Cost on val dataset after 1134 epochs is = 0.08307349187010257\n",
      "Initial Cost on Val dataset for this epoch 1134 = 0.08307349187010257\n",
      "learning rate for this epoch =  0.0861621923261951\n",
      "Error on this batch = 0.03259983212194943\n",
      "Error on this batch = 0.058727926067426085\n",
      "Cost on val dataset after 1135 epochs is = 0.08306179972183206\n",
      "Initial Cost on Val dataset for this epoch 1135 = 0.08306179972183206\n",
      "learning rate for this epoch =  0.08614320759609581\n",
      "Error on this batch = 0.03258302772947913\n",
      "Error on this batch = 0.05870251348506399\n",
      "Cost on val dataset after 1136 epochs is = 0.08305012839924135\n",
      "Initial Cost on Val dataset for this epoch 1136 = 0.08305012839924135\n",
      "learning rate for this epoch =  0.08612424376278484\n",
      "Error on this batch = 0.0325662474753936\n",
      "Error on this batch = 0.05867712512753272\n",
      "Cost on val dataset after 1137 epochs is = 0.08303847784733522\n",
      "Initial Cost on Val dataset for this epoch 1137 = 0.08303847784733522\n",
      "learning rate for this epoch =  0.08610530078489602\n",
      "Error on this batch = 0.03254949133355954\n",
      "Error on this batch = 0.05865176093505625\n",
      "Cost on val dataset after 1138 epochs is = 0.08302684801108508\n",
      "Initial Cost on Val dataset for this epoch 1138 = 0.08302684801108508\n",
      "learning rate for this epoch =  0.08608637862118143\n",
      "Error on this batch = 0.03253275927798408\n",
      "Error on this batch = 0.05862642084792539\n",
      "Cost on val dataset after 1139 epochs is = 0.08301523883543344\n",
      "Initial Cost on Val dataset for this epoch 1139 = 0.08301523883543344\n",
      "learning rate for this epoch =  0.08606747723051081\n",
      "Error on this batch = 0.03251605128280664\n",
      "Error on this batch = 0.05860110480650765\n",
      "Cost on val dataset after 1140 epochs is = 0.08300365026529848\n",
      "Initial Cost on Val dataset for this epoch 1140 = 0.08300365026529848\n",
      "learning rate for this epoch =  0.08604859657187126\n",
      "Error on this batch = 0.03249936732229066\n",
      "Error on this batch = 0.05857581275125714\n",
      "Cost on val dataset after 1141 epochs is = 0.08299208224557861\n",
      "Initial Cost on Val dataset for this epoch 1141 = 0.08299208224557861\n",
      "learning rate for this epoch =  0.0860297366043667\n",
      "Error on this batch = 0.03248270737081577\n",
      "Error on this batch = 0.05855054462272414\n",
      "Cost on val dataset after 1142 epochs is = 0.08298053472115716\n",
      "Initial Cost on Val dataset for this epoch 1142 = 0.08298053472115716\n",
      "learning rate for this epoch =  0.08601089728721749\n",
      "Error on this batch = 0.03246607140287011\n",
      "Error on this batch = 0.0585253003615642\n",
      "Cost on val dataset after 1143 epochs is = 0.08296900763690712\n",
      "Initial Cost on Val dataset for this epoch 1143 = 0.08296900763690712\n",
      "learning rate for this epoch =  0.08599207857975999\n",
      "Error on this batch = 0.03244945939304279\n",
      "Error on this batch = 0.05850007990854735\n",
      "Cost on val dataset after 1144 epochs is = 0.08295750093769594\n",
      "Initial Cost on Val dataset for this epoch 1144 = 0.08295750093769594\n",
      "learning rate for this epoch =  0.08597328044144606\n",
      "Error on this batch = 0.03243287131601656\n",
      "Error on this batch = 0.05847488320456675\n",
      "Cost on val dataset after 1145 epochs is = 0.0829460145683904\n",
      "Initial Cost on Val dataset for this epoch 1145 = 0.0829460145683904\n",
      "learning rate for this epoch =  0.08595450283184279\n",
      "Error on this batch = 0.03241630714656091\n",
      "Error on this batch = 0.05844971019064722\n",
      "Cost on val dataset after 1146 epochs is = 0.0829345484738614\n",
      "Initial Cost on Val dataset for this epoch 1146 = 0.0829345484738614\n",
      "learning rate for this epoch =  0.08593574571063191\n",
      "Error on this batch = 0.032399766859525\n",
      "Error on this batch = 0.05842456080795365\n",
      "Cost on val dataset after 1147 epochs is = 0.08292310259898908\n",
      "Initial Cost on Val dataset for this epoch 1147 = 0.08292310259898908\n",
      "learning rate for this epoch =  0.08591700903760942\n",
      "Error on this batch = 0.03238325042983125\n",
      "Error on this batch = 0.058399434997798726\n",
      "Cost on val dataset after 1148 epochs is = 0.08291167688866762\n",
      "Initial Cost on Val dataset for this epoch 1148 = 0.08291167688866762\n",
      "learning rate for this epoch =  0.0858982927726852\n",
      "Error on this batch = 0.03236675783246873\n",
      "Error on this batch = 0.05837433270165089\n",
      "Cost on val dataset after 1149 epochs is = 0.08290027128781048\n",
      "Initial Cost on Val dataset for this epoch 1149 = 0.08290027128781048\n",
      "learning rate for this epoch =  0.08587959687588255\n",
      "Error on this batch = 0.032350289042487136\n",
      "Error on this batch = 0.058349253861141606\n",
      "Cost on val dataset after 1150 epochs is = 0.08288888574135535\n",
      "Initial Cost on Val dataset for this epoch 1150 = 0.08288888574135535\n",
      "learning rate for this epoch =  0.08586092130733781\n",
      "Error on this batch = 0.03233384403499072\n",
      "Error on this batch = 0.058324198418072515\n",
      "Cost on val dataset after 1151 epochs is = 0.08287752019426921\n",
      "Initial Cost on Val dataset for this epoch 1151 = 0.08287752019426921\n",
      "learning rate for this epoch =  0.0858422660272999\n",
      "Error on this batch = 0.032317422785132645\n",
      "Error on this batch = 0.058299166314422515\n",
      "Cost on val dataset after 1152 epochs is = 0.0828661745915535\n",
      "Initial Cost on Val dataset for this epoch 1152 = 0.0828661745915535\n",
      "learning rate for this epoch =  0.08582363099612991\n",
      "Error on this batch = 0.03230102526810943\n",
      "Error on this batch = 0.05827415749235419\n",
      "Cost on val dataset after 1153 epochs is = 0.08285484887824934\n",
      "Initial Cost on Val dataset for this epoch 1153 = 0.08285484887824934\n",
      "learning rate for this epoch =  0.08580501617430071\n",
      "Error on this batch = 0.03228465145915556\n",
      "Error on this batch = 0.05824917189422021\n",
      "Cost on val dataset after 1154 epochs is = 0.08284354299944263\n",
      "Initial Cost on Val dataset for this epoch 1154 = 0.08284354299944263\n",
      "learning rate for this epoch =  0.08578642152239652\n",
      "Error on this batch = 0.032268301333538627\n",
      "Error on this batch = 0.0582242094625693\n",
      "Cost on val dataset after 1155 epochs is = 0.08283225690026923\n",
      "Initial Cost on Val dataset for this epoch 1155 = 0.08283225690026923\n",
      "learning rate for this epoch =  0.08576784700111252\n",
      "Error on this batch = 0.03225197486655426\n",
      "Error on this batch = 0.05819927014015219\n",
      "Cost on val dataset after 1156 epochs is = 0.08282099052592014\n",
      "Initial Cost on Val dataset for this epoch 1156 = 0.08282099052592014\n",
      "learning rate for this epoch =  0.08574929257125441\n",
      "Error on this batch = 0.0322356720335217\n",
      "Error on this batch = 0.05817435386992689\n",
      "Cost on val dataset after 1157 epochs is = 0.08280974382164677\n",
      "Initial Cost on Val dataset for this epoch 1157 = 0.08280974382164677\n",
      "learning rate for this epoch =  0.08573075819373804\n",
      "Error on this batch = 0.032219392809779306\n",
      "Error on this batch = 0.058149460595064005\n",
      "Cost on val dataset after 1158 epochs is = 0.08279851673276617\n",
      "Initial Cost on Val dataset for this epoch 1158 = 0.08279851673276617\n",
      "learning rate for this epoch =  0.085712243829589\n",
      "Error on this batch = 0.032203137170680296\n",
      "Error on this batch = 0.058124590258951586\n",
      "Cost on val dataset after 1159 epochs is = 0.08278730920466612\n",
      "Initial Cost on Val dataset for this epoch 1159 = 0.08278730920466612\n",
      "learning rate for this epoch =  0.08569374943994214\n",
      "Error on this batch = 0.03218690509158897\n",
      "Error on this batch = 0.058099742805199875\n",
      "Cost on val dataset after 1160 epochs is = 0.0827761211828104\n",
      "Initial Cost on Val dataset for this epoch 1160 = 0.0827761211828104\n",
      "learning rate for this epoch =  0.0856752749860413\n",
      "Error on this batch = 0.032170696547876784\n",
      "Error on this batch = 0.05807491817764543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 1161 epochs is = 0.08276495261274412\n",
      "Initial Cost on Val dataset for this epoch 1161 = 0.08276495261274412\n",
      "learning rate for this epoch =  0.08565682042923882\n",
      "Error on this batch = 0.032154511514918986\n",
      "Error on this batch = 0.05805011632035546\n",
      "Cost on val dataset after 1162 epochs is = 0.08275380344009876\n",
      "Initial Cost on Val dataset for this epoch 1162 = 0.08275380344009876\n",
      "learning rate for this epoch =  0.08563838573099518\n",
      "Error on this batch = 0.032138349968091035\n",
      "Error on this batch = 0.058025337177631364\n",
      "Cost on val dataset after 1163 epochs is = 0.08274267361059734\n",
      "Initial Cost on Val dataset for this epoch 1163 = 0.08274267361059734\n",
      "learning rate for this epoch =  0.08561997085287859\n",
      "Error on this batch = 0.032122211882765817\n",
      "Error on this batch = 0.05800058069401241\n",
      "Cost on val dataset after 1164 epochs is = 0.08273156307005963\n",
      "Initial Cost on Val dataset for this epoch 1164 = 0.08273156307005963\n",
      "learning rate for this epoch =  0.08560157575656459\n",
      "Error on this batch = 0.0321060972343105\n",
      "Error on this batch = 0.0579758468142788\n",
      "Cost on val dataset after 1165 epochs is = 0.08272047176440747\n",
      "Initial Cost on Val dataset for this epoch 1165 = 0.08272047176440747\n",
      "learning rate for this epoch =  0.08558320040383566\n",
      "Error on this batch = 0.03209000599808388\n",
      "Error on this batch = 0.05795113548345471\n",
      "Cost on val dataset after 1166 epochs is = 0.0827093996396696\n",
      "Initial Cost on Val dataset for this epoch 1166 = 0.0827093996396696\n",
      "learning rate for this epoch =  0.08556484475658087\n",
      "Error on this batch = 0.032073938149433934\n",
      "Error on this batch = 0.05792644664681088\n",
      "Cost on val dataset after 1167 epochs is = 0.08269834664198691\n",
      "Initial Cost on Val dataset for this epoch 1167 = 0.08269834664198691\n",
      "learning rate for this epoch =  0.08554650877679544\n",
      "Error on this batch = 0.032057893663695505\n",
      "Error on this batch = 0.05790178024986704\n",
      "Cost on val dataset after 1168 epochs is = 0.08268731271761758\n",
      "Initial Cost on Val dataset for this epoch 1168 = 0.08268731271761758\n",
      "learning rate for this epoch =  0.08552819242658037\n",
      "Error on this batch = 0.032041872516188105\n",
      "Error on this batch = 0.05787713623839398\n",
      "Cost on val dataset after 1169 epochs is = 0.08267629781294193\n",
      "Initial Cost on Val dataset for this epoch 1169 = 0.08267629781294193\n",
      "learning rate for this epoch =  0.08550989566814209\n",
      "Error on this batch = 0.032025874682214066\n",
      "Error on this batch = 0.05785251455841541\n",
      "Cost on val dataset after 1170 epochs is = 0.08266530187446763\n",
      "Initial Cost on Val dataset for this epoch 1170 = 0.08266530187446763\n",
      "learning rate for this epoch =  0.08549161846379197\n",
      "Error on this batch = 0.032009900137056804\n",
      "Error on this batch = 0.05782791515620943\n",
      "Cost on val dataset after 1171 epochs is = 0.08265432484883455\n",
      "Initial Cost on Val dataset for this epoch 1171 = 0.08265432484883455\n",
      "learning rate for this epoch =  0.08547336077594611\n",
      "Error on this batch = 0.03199394885597929\n",
      "Error on this batch = 0.05780333797830998\n",
      "Cost on val dataset after 1172 epochs is = 0.08264336668281964\n",
      "Initial Cost on Val dataset for this epoch 1172 = 0.08264336668281964\n",
      "learning rate for this epoch =  0.08545512256712481\n",
      "Error on this batch = 0.031978020814222595\n",
      "Error on this batch = 0.05777878297150766\n",
      "Cost on val dataset after 1173 epochs is = 0.08263242732334192\n",
      "Initial Cost on Val dataset for this epoch 1173 = 0.08263242732334192\n",
      "learning rate for this epoch =  0.08543690379995225\n",
      "Error on this batch = 0.03196211598700472\n",
      "Error on this batch = 0.057754250082850664\n",
      "Cost on val dataset after 1174 epochs is = 0.08262150671746737\n",
      "Initial Cost on Val dataset for this epoch 1174 = 0.08262150671746737\n",
      "learning rate for this epoch =  0.08541870443715613\n",
      "Error on this batch = 0.03194623434951967\n",
      "Error on this batch = 0.05772973925964514\n",
      "Cost on val dataset after 1175 epochs is = 0.08261060481241352\n",
      "Initial Cost on Val dataset for this epoch 1175 = 0.08261060481241352\n",
      "learning rate for this epoch =  0.08540052444156727\n",
      "Error on this batch = 0.0319303758769364\n",
      "Error on this batch = 0.057705250449455486\n",
      "Cost on val dataset after 1176 epochs is = 0.08259972155555435\n",
      "Initial Cost on Val dataset for this epoch 1176 = 0.08259972155555435\n",
      "learning rate for this epoch =  0.0853823637761192\n",
      "Error on this batch = 0.031914540544398344\n",
      "Error on this batch = 0.057680783600104285\n",
      "Cost on val dataset after 1177 epochs is = 0.0825888568944249\n",
      "Initial Cost on Val dataset for this epoch 1177 = 0.0825888568944249\n",
      "learning rate for this epoch =  0.08536422240384793\n",
      "Error on this batch = 0.03189872832702266\n",
      "Error on this batch = 0.057656338659672124\n",
      "Cost on val dataset after 1178 epochs is = 0.08257801077672598\n",
      "Initial Cost on Val dataset for this epoch 1178 = 0.08257801077672598\n",
      "learning rate for this epoch =  0.08534610028789137\n",
      "Error on this batch = 0.03188293919989995\n",
      "Error on this batch = 0.05763191557649689\n",
      "Cost on val dataset after 1179 epochs is = 0.0825671831503286\n",
      "Initial Cost on Val dataset for this epoch 1179 = 0.0825671831503286\n",
      "learning rate for this epoch =  0.08532799739148918\n",
      "Error on this batch = 0.03186717313809412\n",
      "Error on this batch = 0.05760751429917317\n",
      "Cost on val dataset after 1180 epochs is = 0.08255637396327874\n",
      "Initial Cost on Val dataset for this epoch 1180 = 0.08255637396327874\n",
      "learning rate for this epoch =  0.0853099136779822\n",
      "Error on this batch = 0.031851430116642036\n",
      "Error on this batch = 0.05758313477655109\n",
      "Cost on val dataset after 1181 epochs is = 0.08254558316380146\n",
      "Initial Cost on Val dataset for this epoch 1181 = 0.08254558316380146\n",
      "learning rate for this epoch =  0.08529184911081227\n",
      "Error on this batch = 0.03183571011055381\n",
      "Error on this batch = 0.057558776957735154\n",
      "Cost on val dataset after 1182 epochs is = 0.08253481070030563\n",
      "Initial Cost on Val dataset for this epoch 1182 = 0.08253481070030563\n",
      "learning rate for this epoch =  0.08527380365352172\n",
      "Error on this batch = 0.031820013094812895\n",
      "Error on this batch = 0.05753444079208271\n",
      "Cost on val dataset after 1183 epochs is = 0.08252405652138796\n",
      "Initial Cost on Val dataset for this epoch 1183 = 0.08252405652138796\n",
      "learning rate for this epoch =  0.08525577726975313\n",
      "Error on this batch = 0.03180433904437638\n",
      "Error on this batch = 0.05751012622920215\n",
      "Cost on val dataset after 1184 epochs is = 0.08251332057583748\n",
      "Initial Cost on Val dataset for this epoch 1184 = 0.08251332057583748\n",
      "learning rate for this epoch =  0.08523776992324884\n",
      "Error on this batch = 0.0317886879341754\n",
      "Error on this batch = 0.05748583321895108\n",
      "Cost on val dataset after 1185 epochs is = 0.08250260281263959\n",
      "Initial Cost on Val dataset for this epoch 1185 = 0.08250260281263959\n",
      "learning rate for this epoch =  0.08521978157785072\n",
      "Error on this batch = 0.03177305973911584\n",
      "Error on this batch = 0.05746156171143401\n",
      "Cost on val dataset after 1186 epochs is = 0.0824919031809802\n",
      "Initial Cost on Val dataset for this epoch 1186 = 0.0824919031809802\n",
      "learning rate for this epoch =  0.08520181219749971\n",
      "Error on this batch = 0.03175745443407879\n",
      "Error on this batch = 0.057437311656999966\n",
      "Cost on val dataset after 1187 epochs is = 0.08248122163024985\n",
      "Initial Cost on Val dataset for this epoch 1187 = 0.08248122163024985\n",
      "learning rate for this epoch =  0.08518386174623557\n",
      "Error on this batch = 0.03174187199392162\n",
      "Error on this batch = 0.05741308300623991\n",
      "Cost on val dataset after 1188 epochs is = 0.08247055811004751\n",
      "Initial Cost on Val dataset for this epoch 1188 = 0.08247055811004751\n",
      "learning rate for this epoch =  0.0851659301881964\n",
      "Error on this batch = 0.03172631239347864\n",
      "Error on this batch = 0.05738887570998394\n",
      "Cost on val dataset after 1189 epochs is = 0.08245991257018474\n",
      "Initial Cost on Val dataset for this epoch 1189 = 0.08245991257018474\n",
      "learning rate for this epoch =  0.0851480174876184\n",
      "Error on this batch = 0.031710775607562136\n",
      "Error on this batch = 0.05736468971929805\n",
      "Cost on val dataset after 1190 epochs is = 0.08244928496068914\n",
      "Initial Cost on Val dataset for this epoch 1190 = 0.08244928496068914\n",
      "learning rate for this epoch =  0.08513012360883546\n",
      "Error on this batch = 0.03169526161096362\n",
      "Error on this batch = 0.05734052498548108\n",
      "Cost on val dataset after 1191 epochs is = 0.08243867523180844\n",
      "Initial Cost on Val dataset for this epoch 1191 = 0.08243867523180844\n",
      "learning rate for this epoch =  0.08511224851627883\n",
      "Error on this batch = 0.03167977037845489\n",
      "Error on this batch = 0.05731638146006115\n",
      "Cost on val dataset after 1192 epochs is = 0.0824280833340139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost on Val dataset for this epoch 1192 = 0.0824280833340139\n",
      "learning rate for this epoch =  0.08509439217447677\n",
      "Error on this batch = 0.03166430188478931\n",
      "Error on this batch = 0.05729225909479205\n",
      "Cost on val dataset after 1193 epochs is = 0.08241750921800405\n",
      "Initial Cost on Val dataset for this epoch 1193 = 0.08241750921800405\n",
      "learning rate for this epoch =  0.08507655454805418\n",
      "Error on this batch = 0.03164885610470324\n",
      "Error on this batch = 0.05726815784164934\n",
      "Cost on val dataset after 1194 epochs is = 0.08240695283470806\n",
      "Initial Cost on Val dataset for this epoch 1194 = 0.08240695283470806\n",
      "learning rate for this epoch =  0.08505873560173234\n",
      "Error on this batch = 0.03163343301291743\n",
      "Error on this batch = 0.05724407765282646\n",
      "Cost on val dataset after 1195 epochs is = 0.08239641413528927\n",
      "Initial Cost on Val dataset for this epoch 1195 = 0.08239641413528927\n",
      "learning rate for this epoch =  0.08504093530032843\n",
      "Error on this batch = 0.031618032584138575\n",
      "Error on this batch = 0.057220018480730356\n",
      "Cost on val dataset after 1196 epochs is = 0.0823858930711484\n",
      "Initial Cost on Val dataset for this epoch 1196 = 0.0823858930711484\n",
      "learning rate for this epoch =  0.08502315360875533\n",
      "Error on this batch = 0.03160265479306088\n",
      "Error on this batch = 0.05719598027797719\n",
      "Cost on val dataset after 1197 epochs is = 0.0823753895939268\n",
      "Initial Cost on Val dataset for this epoch 1197 = 0.0823753895939268\n",
      "learning rate for this epoch =  0.08500539049202116\n",
      "Error on this batch = 0.0315872996143677\n",
      "Error on this batch = 0.05717196299738781\n",
      "Cost on val dataset after 1198 epochs is = 0.08236490365550979\n",
      "Initial Cost on Val dataset for this epoch 1198 = 0.08236490365550979\n",
      "learning rate for this epoch =  0.08498764591522903\n",
      "Error on this batch = 0.03157196702273333\n",
      "Error on this batch = 0.05714796659198296\n",
      "Cost on val dataset after 1199 epochs is = 0.08235443520802938\n",
      "Initial Cost on Val dataset for this epoch 1199 = 0.08235443520802938\n",
      "learning rate for this epoch =  0.08496991984357669\n",
      "Error on this batch = 0.03155665699282466\n",
      "Error on this batch = 0.05712399101497843\n",
      "Cost on val dataset after 1200 epochs is = 0.08234398420386768\n",
      "Initial Cost on Val dataset for this epoch 1200 = 0.08234398420386768\n",
      "learning rate for this epoch =  0.08495221224235612\n",
      "Error on this batch = 0.031541369499303126\n",
      "Error on this batch = 0.057100036219780013\n",
      "Cost on val dataset after 1201 epochs is = 0.08233355059565942\n",
      "Initial Cost on Val dataset for this epoch 1201 = 0.08233355059565942\n",
      "learning rate for this epoch =  0.08493452307695332\n",
      "Error on this batch = 0.03152610451682649\n",
      "Error on this batch = 0.0570761021599784\n",
      "Cost on val dataset after 1202 epochs is = 0.08232313433629496\n",
      "Initial Cost on Val dataset for this epoch 1202 = 0.08232313433629496\n",
      "learning rate for this epoch =  0.08491685231284785\n",
      "Error on this batch = 0.03151086202005081\n",
      "Error on this batch = 0.05705218878934368\n",
      "Cost on val dataset after 1203 epochs is = 0.08231273537892292\n",
      "Initial Cost on Val dataset for this epoch 1203 = 0.08231273537892292\n",
      "learning rate for this epoch =  0.08489919991561257\n",
      "Error on this batch = 0.03149564198363237\n",
      "Error on this batch = 0.057028296061820076\n",
      "Cost on val dataset after 1204 epochs is = 0.08230235367695293\n",
      "Initial Cost on Val dataset for this epoch 1204 = 0.08230235367695293\n",
      "learning rate for this epoch =  0.08488156585091333\n",
      "Error on this batch = 0.03148044438222963\n",
      "Error on this batch = 0.05700442393152014\n",
      "Cost on val dataset after 1205 epochs is = 0.08229198918405808\n",
      "Initial Cost on Val dataset for this epoch 1205 = 0.08229198918405808\n",
      "learning rate for this epoch =  0.0848639500845086\n",
      "Error on this batch = 0.03146526919050538\n",
      "Error on this batch = 0.0569805723527193\n",
      "Cost on val dataset after 1206 epochs is = 0.08228164185417727\n",
      "Initial Cost on Val dataset for this epoch 1206 = 0.08228164185417727\n",
      "learning rate for this epoch =  0.08484635258224914\n",
      "Error on this batch = 0.031450116383128675\n",
      "Error on this batch = 0.05695674127984967\n",
      "Cost on val dataset after 1207 epochs is = 0.08227131164151784\n",
      "Initial Cost on Val dataset for this epoch 1207 = 0.08227131164151784\n",
      "learning rate for this epoch =  0.08482877331007768\n",
      "Error on this batch = 0.03143498593477688\n",
      "Error on this batch = 0.05693293066749437\n",
      "Cost on val dataset after 1208 epochs is = 0.08226099850055758\n",
      "Initial Cost on Val dataset for this epoch 1208 = 0.08226099850055758\n",
      "learning rate for this epoch =  0.08481121223402864\n",
      "Error on this batch = 0.03141987782013793\n",
      "Error on this batch = 0.05690914047038139\n",
      "Cost on val dataset after 1209 epochs is = 0.08225070238604716\n",
      "Initial Cost on Val dataset for this epoch 1209 = 0.08225070238604716\n",
      "learning rate for this epoch =  0.08479366932022776\n",
      "Error on this batch = 0.03140479201391224\n",
      "Error on this batch = 0.05688537064337726\n",
      "Cost on val dataset after 1210 epochs is = 0.08224042325301197\n",
      "Initial Cost on Val dataset for this epoch 1210 = 0.08224042325301197\n",
      "learning rate for this epoch =  0.08477614453489178\n",
      "Error on this batch = 0.03138972849081496\n",
      "Error on this batch = 0.056861621141481\n",
      "Cost on val dataset after 1211 epochs is = 0.0822301610567543\n",
      "Initial Cost on Val dataset for this epoch 1211 = 0.0822301610567543\n",
      "learning rate for this epoch =  0.08475863784432815\n",
      "Error on this batch = 0.03137468722557801\n",
      "Error on this batch = 0.05683789191981761\n",
      "Cost on val dataset after 1212 epochs is = 0.08221991575285528\n",
      "Initial Cost on Val dataset for this epoch 1212 = 0.08221991575285528\n",
      "learning rate for this epoch =  0.08474114921493468\n",
      "Error on this batch = 0.03135966819295232\n",
      "Error on this batch = 0.056814182933631656\n",
      "Cost on val dataset after 1213 epochs is = 0.08220968729717656\n",
      "Initial Cost on Val dataset for this epoch 1213 = 0.08220968729717656\n",
      "learning rate for this epoch =  0.08472367861319927\n",
      "Error on this batch = 0.031344671367709846\n",
      "Error on this batch = 0.05679049413828079\n",
      "Cost on val dataset after 1214 epochs is = 0.08219947564586222\n",
      "Initial Cost on Val dataset for this epoch 1214 = 0.08219947564586222\n",
      "learning rate for this epoch =  0.0847062260056995\n",
      "Error on this batch = 0.031329696724645764\n",
      "Error on this batch = 0.05676682548922907\n",
      "Cost on val dataset after 1215 epochs is = 0.08218928075534028\n",
      "Initial Cost on Val dataset for this epoch 1215 = 0.08218928075534028\n",
      "learning rate for this epoch =  0.08468879135910246\n",
      "Error on this batch = 0.03131474423858059\n",
      "Error on this batch = 0.05674317694204035\n",
      "Cost on val dataset after 1216 epochs is = 0.08217910258232443\n",
      "Initial Cost on Val dataset for this epoch 1216 = 0.08217910258232443\n",
      "learning rate for this epoch =  0.08467137464016429\n",
      "Error on this batch = 0.0312998138843623\n",
      "Error on this batch = 0.056719548452371565\n",
      "Cost on val dataset after 1217 epochs is = 0.08216894108381535\n",
      "Initial Cost on Val dataset for this epoch 1217 = 0.08216894108381535\n",
      "learning rate for this epoch =  0.08465397581572995\n",
      "Error on this batch = 0.03128490563686834\n",
      "Error on this batch = 0.05669593997596588\n",
      "Cost on val dataset after 1218 epochs is = 0.08215879621710219\n",
      "Initial Cost on Val dataset for this epoch 1218 = 0.08215879621710219\n",
      "learning rate for this epoch =  0.08463659485273294\n",
      "Error on this batch = 0.03127001947100784\n",
      "Error on this batch = 0.056672351468645916\n",
      "Cost on val dataset after 1219 epochs is = 0.08214866793976386\n",
      "Initial Cost on Val dataset for this epoch 1219 = 0.08214866793976386\n",
      "learning rate for this epoch =  0.0846192317181949\n",
      "Error on this batch = 0.03125515536172365\n",
      "Error on this batch = 0.05664878288630687\n",
      "Cost on val dataset after 1220 epochs is = 0.08213855620967037\n",
      "Initial Cost on Val dataset for this epoch 1220 = 0.08213855620967037\n",
      "learning rate for this epoch =  0.08460188637922533\n",
      "Error on this batch = 0.03124031328399428\n",
      "Error on this batch = 0.05662523418490961\n",
      "Cost on val dataset after 1221 epochs is = 0.08212846098498372\n",
      "Initial Cost on Val dataset for this epoch 1221 = 0.08212846098498372\n",
      "learning rate for this epoch =  0.08458455880302138\n",
      "Error on this batch = 0.031225493212836044\n",
      "Error on this batch = 0.05660170532047377\n",
      "Cost on val dataset after 1222 epochs is = 0.08211838222415925\n",
      "Initial Cost on Val dataset for this epoch 1222 = 0.08211838222415925\n",
      "learning rate for this epoch =  0.08456724895686739\n",
      "Error on this batch = 0.03121069512330499\n",
      "Error on this batch = 0.0565781962490707\n",
      "Cost on val dataset after 1223 epochs is = 0.08210831988594637\n",
      "Initial Cost on Val dataset for this epoch 1223 = 0.08210831988594637\n",
      "learning rate for this epoch =  0.08454995680813471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.031195918990498842\n",
      "Error on this batch = 0.056554706926816606\n",
      "Cost on val dataset after 1224 epochs is = 0.08209827392938956\n",
      "Initial Cost on Val dataset for this epoch 1224 = 0.08209827392938956\n",
      "learning rate for this epoch =  0.08453268232428135\n",
      "Error on this batch = 0.031181164789558992\n",
      "Error on this batch = 0.05653123730986552\n",
      "Cost on val dataset after 1225 epochs is = 0.0820882443138293\n",
      "Initial Cost on Val dataset for this epoch 1225 = 0.0820882443138293\n",
      "learning rate for this epoch =  0.08451542547285165\n",
      "Error on this batch = 0.031166432495672344\n",
      "Error on this batch = 0.05650778735440229\n",
      "Cost on val dataset after 1226 epochs is = 0.08207823099890256\n",
      "Initial Cost on Val dataset for this epoch 1226 = 0.08207823099890256\n",
      "learning rate for this epoch =  0.08449818622147606\n",
      "Error on this batch = 0.031151722084073165\n",
      "Error on this batch = 0.05648435701663568\n",
      "Cost on val dataset after 1227 epochs is = 0.08206823394454364\n",
      "Initial Cost on Val dataset for this epoch 1227 = 0.08206823394454364\n",
      "learning rate for this epoch =  0.08448096453787077\n",
      "Error on this batch = 0.03113703353004488\n",
      "Error on this batch = 0.05646094625279126\n",
      "Cost on val dataset after 1228 epochs is = 0.0820582531109847\n",
      "Initial Cost on Val dataset for this epoch 1228 = 0.0820582531109847\n",
      "learning rate for this epoch =  0.08446376038983743\n",
      "Error on this batch = 0.03112236680892192\n",
      "Error on this batch = 0.05643755501910462\n",
      "Cost on val dataset after 1229 epochs is = 0.08204828845875617\n",
      "Initial Cost on Val dataset for this epoch 1229 = 0.08204828845875617\n",
      "learning rate for this epoch =  0.08444657374526286\n",
      "Error on this batch = 0.03110772189609133\n",
      "Error on this batch = 0.05641418327181434\n",
      "Cost on val dataset after 1230 epochs is = 0.08203833994868735\n",
      "Initial Cost on Val dataset for this epoch 1230 = 0.08203833994868735\n",
      "learning rate for this epoch =  0.08442940457211878\n",
      "Error on this batch = 0.031093098766994554\n",
      "Error on this batch = 0.05639083096715506\n",
      "Cost on val dataset after 1231 epochs is = 0.08202840754190657\n",
      "Initial Cost on Val dataset for this epoch 1231 = 0.08202840754190657\n",
      "learning rate for this epoch =  0.0844122528384615\n",
      "Error on this batch = 0.031078497397128972\n",
      "Error on this batch = 0.05636749806135073\n",
      "Cost on val dataset after 1232 epochs is = 0.08201849119984153\n",
      "Initial Cost on Val dataset for this epoch 1232 = 0.08201849119984153\n",
      "learning rate for this epoch =  0.08439511851243159\n",
      "Error on this batch = 0.031063917762049514\n",
      "Error on this batch = 0.0563441845106076\n",
      "Cost on val dataset after 1233 epochs is = 0.08200859088421966\n",
      "Initial Cost on Val dataset for this epoch 1233 = 0.08200859088421966\n",
      "learning rate for this epoch =  0.08437800156225363\n",
      "Error on this batch = 0.031049359837370206\n",
      "Error on this batch = 0.056320890271107635\n",
      "Cost on val dataset after 1234 epochs is = 0.08199870655706795\n",
      "Initial Cost on Val dataset for this epoch 1234 = 0.08199870655706795\n",
      "learning rate for this epoch =  0.08436090195623593\n",
      "Error on this batch = 0.031034823598765575\n",
      "Error on this batch = 0.056297615299001666\n",
      "Cost on val dataset after 1235 epochs is = 0.08198883818071322\n",
      "Initial Cost on Val dataset for this epoch 1235 = 0.08198883818071322\n",
      "learning rate for this epoch =  0.08434381966277021\n",
      "Error on this batch = 0.03102030902197206\n",
      "Error on this batch = 0.056274359550402706\n",
      "Cost on val dataset after 1236 epochs is = 0.08197898571778207\n",
      "cost initial= 0.08198883818071322 , cost final=0.08197898571778207 , change in cost= -9.852462931142503e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = 100 are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 1236\n",
      "The training time = 249.345sec\n",
      "The training accuracy is = 95.719%\n",
      "The validation accuracy is = 90.769%\n",
      "The test accuracy is = 89.631%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []\n",
    "\n",
    "lr0=0.5\n",
    "\n",
    "for i in range(len(arch_test)):\n",
    "    theta = theta_init([arch_test[i]], 'normal')\n",
    "    #print(theta[0].shape, theta[1].shape, theta[2].shape)\n",
    "    print(\"Training the network with {} hidden layer with {} units\".format(len([arch_test[i]]), arch_test[i]))\n",
    "    print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "    for j in range(len(theta)):\n",
    "        print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "\n",
    "    start = time.time()\n",
    "    epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr0, 'sigmoid', 'adaptive')\n",
    "    epochs.append(epoch)\n",
    "    train_time.append(time.time()-start)\n",
    "    train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "    valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "    test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "    print(\"\\n------------------------------------------------------------------------------\")\n",
    "    print(\"The stats for number of units in the hidden layer = {} are as below:\".format(arch_test[i]))\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(\"The number of epochs = {}\".format(epochs[-1]))\n",
    "    print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "    print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "    print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "    print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "    print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph for 100 hidden units with different adaptive strategy\n",
    "#lr0=1.5\n",
    "data = [' ', '1.5/ep^1/2',' ','1.5/ep^1/3',' ', '1.5/ep^1/4', ' ','0.5/ep^1/2', ' ', '0.5/ep^1/3']\n",
    "train_acc = [94.15, 96.5, 97.18, 90, 95.72]\n",
    "valid_acc =[90.72, 91.69, 92, 86.72, 90.77]\n",
    "test_acc = [89.34, 90.23, 90.54, 85.91, 89.63]\n",
    "epoch = [1189, 782, 602, 2014, 1236]\n",
    "tt=[240, 158, 118, 404, 250]\n",
    "x = [0,1,2, 3, 4]\n",
    "fig, ax = plt.subplots()\n",
    "color = 'k'\n",
    "ax.plot(x, train_acc, marker='o', label='train accuracy')\n",
    "ax.plot(x, valid_acc, marker='o', label='validation acc')\n",
    "ax.plot(x, test_acc, marker='o', label='test accuracy')\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_xlabel(\"Adaptive Learning Rate Degradation Policy\")\n",
    "ax.set_ylabel(\"Accuracy(%)\", color=color)\n",
    "ax.tick_params(axis='y', labelcolor=color, labelsize=12)\n",
    "ax.legend()\n",
    "#ax.set_ylim(80,100)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Number of Epochs\")\n",
    "ax2.plot(x, epoch, marker='o', color='m',label='Epochs')\n",
    "ax2.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "\n",
    "plt.title(\"Accuracy, Epochs and Train Time Comparison with\\n different adaptive policy for learning rate\")\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig(\"plots/partc/comp_diff_adapt_policy.png\", dpi=1000, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------Plotting Graphs for Part C - Adaptive LR - One Hidden Layer ------------------\")\n",
    "\n",
    "plot_accuracy(arch_test, train_accuracy, test_accuracy, valid_accuracy)\n",
    "plot_epoch(arch_test, epochs, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D - Implementation of ReLU activation for Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with Sigmoid activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with Sigmoid activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.1780035860814895\n",
      "learning rate for this epoch =  1.5\n",
      "Error on this batch = 3.1806180505079364\n",
      "Error on this batch = 0.48203578957422544\n",
      "Cost on val dataset after 2 epochs is = 0.4808339398047266\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4808339398047266\n",
      "learning rate for this epoch =  1.2613446228805718\n",
      "Error on this batch = 0.48046701314875434\n",
      "Error on this batch = 0.4808183331072243\n",
      "Cost on val dataset after 3 epochs is = 0.4807737308497501\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4807737308497501\n",
      "learning rate for this epoch =  1.139753528477389\n",
      "Error on this batch = 0.48074550390127635\n",
      "Error on this batch = 0.480730850529431\n",
      "Cost on val dataset after 4 epochs is = 0.4807174428359504\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4807174428359504\n",
      "learning rate for this epoch =  1.0606601717798212\n",
      "Error on this batch = 0.4806855213090552\n",
      "Error on this batch = 0.4806794113958541\n",
      "Cost on val dataset after 5 epochs is = 0.4806626932445742\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4806626932445742\n",
      "learning rate for this epoch =  1.003110457464633\n",
      "Error on this batch = 0.48062353715283884\n",
      "Error on this batch = 0.4806294408869147\n",
      "Cost on val dataset after 6 epochs is = 0.4806081679854291\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4806081679854291\n",
      "learning rate for this epoch =  0.9584146563694087\n",
      "Error on this batch = 0.4805645164437039\n",
      "Error on this batch = 0.48057869810030457\n",
      "Cost on val dataset after 7 epochs is = 0.4805525622945742\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4805525622945742\n",
      "learning rate for this epoch =  0.9221822294268966\n",
      "Error on this batch = 0.4805062113944112\n",
      "Error on this batch = 0.48052610650921046\n",
      "Cost on val dataset after 8 epochs is = 0.4804948466571749\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.4804948466571749\n",
      "learning rate for this epoch =  0.8919053362520408\n",
      "Error on this batch = 0.48044700277318847\n",
      "Error on this batch = 0.4804707410198371\n",
      "Cost on val dataset after 9 epochs is = 0.48043409471279236\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.48043409471279236\n",
      "learning rate for this epoch =  0.8660254037844387\n",
      "Error on this batch = 0.4803856424024068\n",
      "Error on this batch = 0.480411697994731\n",
      "Cost on val dataset after 10 epochs is = 0.48036938581181193\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.48036938581181193\n",
      "learning rate for this epoch =  0.8435119877855236\n",
      "Error on this batch = 0.48032102410542027\n",
      "Error on this batch = 0.48034802874029037\n",
      "Cost on val dataset after 11 epochs is = 0.4802997404649988\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4802997404649988\n",
      "learning rate for this epoch =  0.8236507301641687\n",
      "Error on this batch = 0.48025205664275467\n",
      "Error on this batch = 0.48027868668181584\n",
      "Cost on val dataset after 12 epochs is = 0.48022406635906967\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.48022406635906967\n",
      "learning rate for this epoch =  0.8059274488676564\n",
      "Error on this batch = 0.48017757870614247\n",
      "Error on this batch = 0.4802024760066476\n",
      "Cost on val dataset after 13 epochs is = 0.4801411038039137\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4801411038039137\n",
      "learning rate for this epoch =  0.7899605817718899\n",
      "Error on this batch = 0.48009628748144395\n",
      "Error on this batch = 0.48011799460104415\n",
      "Cost on val dataset after 14 epochs is = 0.4800493631357027\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.4800493631357027\n",
      "learning rate for this epoch =  0.7754597309357558\n",
      "Error on this batch = 0.48000666585702717\n",
      "Error on this batch = 0.48002356506288507\n",
      "Cost on val dataset after 15 epochs is = 0.4799470471056532\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.4799470471056532\n",
      "learning rate for this epoch =  0.7621991222319221\n",
      "Error on this batch = 0.47990689777035334\n",
      "Error on this batch = 0.4799171468517563\n",
      "Cost on val dataset after 16 epochs is = 0.4798319499949591\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.4798319499949591\n",
      "learning rate for this epoch =  0.75\n",
      "Error on this batch = 0.4797947614783533\n",
      "Error on this batch = 0.47979622058637234\n",
      "Cost on val dataset after 17 epochs is = 0.4797013222867505\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.4797013222867505\n",
      "learning rate for this epoch =  0.7387185907581786\n",
      "Error on this batch = 0.4796674882186567\n",
      "Error on this batch = 0.47965763188778754\n",
      "Cost on val dataset after 18 epochs is = 0.479551684739324\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.479551684739324\n",
      "learning rate for this epoch =  0.7282376575609851\n",
      "Error on this batch = 0.4795215688079227\n",
      "Error on this batch = 0.4794973763224384\n",
      "Cost on val dataset after 19 epochs is = 0.47937856757166286\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.47937856757166286\n",
      "learning rate for this epoch =  0.718460438165362\n",
      "Error on this batch = 0.479352482246975\n",
      "Error on this batch = 0.47931029767023103\n",
      "Cost on val dataset after 20 epochs is = 0.4791761372246056\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.4791761372246056\n",
      "learning rate for this epoch =  0.7093062067523819\n",
      "Error on this batch = 0.479154306319292\n",
      "Error on this batch = 0.47908965675893134\n",
      "Cost on val dataset after 21 epochs is = 0.4789366512990844\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.4789366512990844\n",
      "learning rate for this epoch =  0.7007069665923001\n",
      "Error on this batch = 0.478919146694341\n",
      "Error on this batch = 0.4788265037483801\n",
      "Cost on val dataset after 22 epochs is = 0.4786496455576033\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.4786496455576033\n",
      "learning rate for this epoch =  0.6926049464161539\n",
      "Error on this batch = 0.4786362813412721\n",
      "Error on this batch = 0.4785087466832096\n",
      "Cost on val dataset after 23 epochs is = 0.4783006941198922\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.4783006941198922\n",
      "learning rate for this epoch =  0.6849506782450969\n",
      "Error on this batch = 0.4782908487703277\n",
      "Error on this batch = 0.47811974278551816\n",
      "Cost on val dataset after 24 epochs is = 0.4778694752333287\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.4778694752333287\n",
      "learning rate for this epoch =  0.6777015027073837\n",
      "Error on this batch = 0.47786178962732406\n",
      "Error on this batch = 0.47763612971696506\n",
      "Cost on val dataset after 25 epochs is = 0.4773266859180431\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.4773266859180431\n",
      "learning rate for this epoch =  0.6708203932499369\n",
      "Error on this batch = 0.47731854347704394\n",
      "Error on this batch = 0.47702444027448343\n",
      "Cost on val dataset after 26 epochs is = 0.47662902720580824\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.47662902720580824\n",
      "learning rate for this epoch =  0.6642750214037211\n",
      "Error on this batch = 0.47661564980522003\n",
      "Error on this batch = 0.47623579626539086\n",
      "Cost on val dataset after 27 epochs is = 0.47571098164373365\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.47571098164373365\n",
      "learning rate for this epoch =  0.6580370064762463\n",
      "Error on this batch = 0.4756838641670532\n",
      "Error on this batch = 0.47519774109208196\n",
      "Cost on val dataset after 28 epochs is = 0.4744715547563294\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.4744715547563294\n",
      "learning rate for this epoch =  0.6520813079174872\n",
      "Error on this batch = 0.4744158819810691\n",
      "Error on this batch = 0.473802520112063\n",
      "Cost on val dataset after 29 epochs is = 0.47275460284491083\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.47275460284491083\n",
      "learning rate for this epoch =  0.646385729188359\n",
      "Error on this batch = 0.4726457331297818\n",
      "Error on this batch = 0.47189345763435214\n",
      "Cost on val dataset after 30 epochs is = 0.4703271754109011\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.4703271754109011\n",
      "learning rate for this epoch =  0.640930509594351\n",
      "Error on this batch = 0.4701293167947715\n",
      "Error on this batch = 0.4692588285139411\n",
      "Cost on val dataset after 31 epochs is = 0.4668826033385239\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.4668826033385239\n",
      "learning rate for this epoch =  0.6356979861225325\n",
      "Error on this batch = 0.46656278695044245\n",
      "Error on this batch = 0.46565713540677617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 0.46214546900527304\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.46214546900527304\n",
      "learning rate for this epoch =  0.6306723114402859\n",
      "Error on this batch = 0.4617205847204111\n",
      "Error on this batch = 0.4609108214161979\n",
      "Cost on val dataset after 33 epochs is = 0.4561849517122284\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.4561849517122284\n",
      "learning rate for this epoch =  0.625839217291726\n",
      "Error on this batch = 0.4557577711846323\n",
      "Error on this batch = 0.4550811649107847\n",
      "Cost on val dataset after 34 epochs is = 0.4495904479667797\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.4495904479667797\n",
      "learning rate for this epoch =  0.621185814849828\n",
      "Error on this batch = 0.44932648221716376\n",
      "Error on this batch = 0.4485420389495889\n",
      "Cost on val dataset after 35 epochs is = 0.4428887769270945\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.4428887769270945\n",
      "learning rate for this epoch =  0.6167004253507795\n",
      "Error on this batch = 0.44304805167249833\n",
      "Error on this batch = 0.4418431452991752\n",
      "Cost on val dataset after 36 epochs is = 0.4363578136338461\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.4363578136338461\n",
      "learning rate for this epoch =  0.6123724356957946\n",
      "Error on this batch = 0.43724515543484044\n",
      "Error on this batch = 0.43546807902259227\n",
      "Cost on val dataset after 37 epochs is = 0.4301586164985867\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.4301586164985867\n",
      "learning rate for this epoch =  0.6081921747581548\n",
      "Error on this batch = 0.4319518896652383\n",
      "Error on this batch = 0.4295582947456644\n",
      "Cost on val dataset after 38 epochs is = 0.42424918844609244\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.42424918844609244\n",
      "learning rate for this epoch =  0.604150806954866\n",
      "Error on this batch = 0.426979831977703\n",
      "Error on this batch = 0.4240010699219878\n",
      "Cost on val dataset after 39 epochs is = 0.4184857135222278\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.4184857135222278\n",
      "learning rate for this epoch =  0.6002402402883749\n",
      "Error on this batch = 0.42212853062653494\n",
      "Error on this batch = 0.4186643129878489\n",
      "Cost on val dataset after 40 epochs is = 0.4127903805626072\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.4127903805626072\n",
      "learning rate for this epoch =  0.596453046575288\n",
      "Error on this batch = 0.4173076263896251\n",
      "Error on this batch = 0.41350034746655245\n",
      "Cost on val dataset after 41 epochs is = 0.40717218341600375\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.40717218341600375\n",
      "learning rate for this epoch =  0.5927823919866072\n",
      "Error on this batch = 0.41251953481743064\n",
      "Error on this batch = 0.40851658404892094\n",
      "Cost on val dataset after 42 epochs is = 0.40162953985171584\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.40162953985171584\n",
      "learning rate for this epoch =  0.5892219763507696\n",
      "Error on this batch = 0.4077624989388404\n",
      "Error on this batch = 0.4037050996705729\n",
      "Cost on val dataset after 43 epochs is = 0.3960735739525162\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.3960735739525162\n",
      "learning rate for this epoch =  0.5857659799342742\n",
      "Error on this batch = 0.40296286413482607\n",
      "Error on this batch = 0.3990053190491058\n",
      "Cost on val dataset after 44 epochs is = 0.3903151349952498\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.3903151349952498\n",
      "learning rate for this epoch =  0.5824090166283349\n",
      "Error on this batch = 0.39796857394236795\n",
      "Error on this batch = 0.3943012463994565\n",
      "Cost on val dataset after 45 epochs is = 0.384074665283585\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.384074665283585\n",
      "learning rate for this epoch =  0.5791460926441345\n",
      "Error on this batch = 0.3925627888014617\n",
      "Error on this batch = 0.38942456860697094\n",
      "Cost on val dataset after 46 epochs is = 0.3770331651521426\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.3770331651521426\n",
      "learning rate for this epoch =  0.5759725699619024\n",
      "Error on this batch = 0.3865107532377543\n",
      "Error on this batch = 0.3842070848727157\n",
      "Cost on val dataset after 47 epochs is = 0.36908452021819294\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.36908452021819294\n",
      "learning rate for this epoch =  0.57288413389643\n",
      "Error on this batch = 0.3797511171797001\n",
      "Error on this batch = 0.3786845464880686\n",
      "Cost on val dataset after 48 epochs is = 0.36067133008027674\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.36067133008027674\n",
      "learning rate for this epoch =  0.5698767642386945\n",
      "Error on this batch = 0.37258001471764807\n",
      "Error on this batch = 0.3731332009564741\n",
      "Cost on val dataset after 49 epochs is = 0.35238236402129663\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.35238236402129663\n",
      "learning rate for this epoch =  0.5669467095138409\n",
      "Error on this batch = 0.3652790641596077\n",
      "Error on this batch = 0.3676427990154102\n",
      "Cost on val dataset after 50 epochs is = 0.3443359688343112\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.3443359688343112\n",
      "learning rate for this epoch =  0.564090463962959\n",
      "Error on this batch = 0.3577688080805095\n",
      "Error on this batch = 0.36199355717691917\n",
      "Cost on val dataset after 51 epochs is = 0.33635335356489626\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.33635335356489626\n",
      "learning rate for this epoch =  0.5613047469123187\n",
      "Error on this batch = 0.34987171786301374\n",
      "Error on this batch = 0.3559286068769007\n",
      "Cost on val dataset after 52 epochs is = 0.3282986473539619\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.3282986473539619\n",
      "learning rate for this epoch =  0.5585864842409736\n",
      "Error on this batch = 0.3416177567674935\n",
      "Error on this batch = 0.3493729431669997\n",
      "Cost on val dataset after 53 epochs is = 0.32020939185749914\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.32020939185749914\n",
      "learning rate for this epoch =  0.555932791697477\n",
      "Error on this batch = 0.3332633258436431\n",
      "Error on this batch = 0.34247702247387524\n",
      "Cost on val dataset after 54 epochs is = 0.31224209487324855\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.31224209487324855\n",
      "learning rate for this epoch =  0.5533409598501609\n",
      "Error on this batch = 0.32508496275886317\n",
      "Error on this batch = 0.335478735462048\n",
      "Cost on val dataset after 55 epochs is = 0.30453974667782957\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.30453974667782957\n",
      "learning rate for this epoch =  0.5508084404840388\n",
      "Error on this batch = 0.3172081671068301\n",
      "Error on this batch = 0.3285448126159169\n",
      "Cost on val dataset after 56 epochs is = 0.2971622992656115\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.2971622992656115\n",
      "learning rate for this epoch =  0.5483328342817686\n",
      "Error on this batch = 0.30959697119147833\n",
      "Error on this batch = 0.32173265982741206\n",
      "Cost on val dataset after 57 epochs is = 0.2900983722308993\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.2900983722308993\n",
      "learning rate for this epoch =  0.5459118796469214\n",
      "Error on this batch = 0.3021353154661259\n",
      "Error on this batch = 0.3150346657543561\n",
      "Cost on val dataset after 58 epochs is = 0.28330524767686116\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.28330524767686116\n",
      "learning rate for this epoch =  0.5435434425456495\n",
      "Error on this batch = 0.2947101360842521\n",
      "Error on this batch = 0.3084287733321291\n",
      "Cost on val dataset after 59 epochs is = 0.27673981937231035\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.27673981937231035\n",
      "learning rate for this epoch =  0.541225507258161\n",
      "Error on this batch = 0.28725485559963665\n",
      "Error on this batch = 0.3019039309291198\n",
      "Cost on val dataset after 60 epochs is = 0.27037051532480105\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.27037051532480105\n",
      "learning rate for this epoch =  0.5389561679446264\n",
      "Error on this batch = 0.2797543925796152\n",
      "Error on this batch = 0.2954616763629382\n",
      "Cost on val dataset after 61 epochs is = 0.26417560013383307\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.26417560013383307\n",
      "learning rate for this epoch =  0.5367336209415393\n",
      "Error on this batch = 0.272228712327728\n",
      "Error on this batch = 0.2891063280125668\n",
      "Cost on val dataset after 62 epochs is = 0.2581367635678747\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.2581367635678747\n",
      "learning rate for this epoch =  0.5345561577144432\n",
      "Error on this batch = 0.2647103490611657\n",
      "Error on this batch = 0.28283584082023927\n",
      "Cost on val dataset after 63 epochs is = 0.25223475952509383\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.25223475952509383\n",
      "learning rate for this epoch =  0.532422158401508\n",
      "Error on this batch = 0.25722641205839286\n",
      "Error on this batch = 0.2766400175329997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 64 epochs is = 0.2464495501965756\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.2464495501965756\n",
      "learning rate for this epoch =  0.5303300858899106\n",
      "Error on this batch = 0.24979054225774328\n",
      "Error on this batch = 0.2705061703411241\n",
      "Cost on val dataset after 65 epochs is = 0.24076350193907645\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.24076350193907645\n",
      "learning rate for this epoch =  0.5282784803734853\n",
      "Error on this batch = 0.24240519081944586\n",
      "Error on this batch = 0.2644275198872543\n",
      "Cost on val dataset after 66 epochs is = 0.23516498681230885\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.23516498681230885\n",
      "learning rate for this epoch =  0.5262659543458028\n",
      "Error on this batch = 0.23507057372473047\n",
      "Error on this batch = 0.25840913702434726\n",
      "Cost on val dataset after 67 epochs is = 0.22965095566376117\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.22965095566376117\n",
      "learning rate for this epoch =  0.5242911879878268\n",
      "Error on this batch = 0.22779482827012273\n",
      "Error on this batch = 0.2524695296640362\n",
      "Cost on val dataset after 68 epochs is = 0.22422843534301512\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.22422843534301512\n",
      "learning rate for this epoch =  0.522352924913678\n",
      "Error on this batch = 0.22060101281094036\n",
      "Error on this batch = 0.2466387334069323\n",
      "Cost on val dataset after 69 epochs is = 0.21891511437904523\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.21891511437904523\n",
      "learning rate for this epoch =  0.5204499682418865\n",
      "Error on this batch = 0.21352962112680662\n",
      "Error on this batch = 0.2409541237721767\n",
      "Cost on val dataset after 70 epochs is = 0.2137386182381084\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.2137386182381084\n",
      "learning rate for this epoch =  0.5185811769629115\n",
      "Error on this batch = 0.2066372901132837\n",
      "Error on this batch = 0.23545496885184336\n",
      "Cost on val dataset after 71 epochs is = 0.20873377772350707\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.20873377772350707\n",
      "learning rate for this epoch =  0.5167454625767091\n",
      "Error on this batch = 0.19999199807829388\n",
      "Error on this batch = 0.23017704106740985\n",
      "Cost on val dataset after 72 epochs is = 0.2039377622795004\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.2039377622795004\n",
      "learning rate for this epoch =  0.5149417859767794\n",
      "Error on this batch = 0.19366439233678925\n",
      "Error on this batch = 0.2251486660868768\n",
      "Cost on val dataset after 73 epochs is = 0.19938406468898393\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.19938406468898393\n",
      "learning rate for this epoch =  0.5131691545594822\n",
      "Error on this batch = 0.18771624130993939\n",
      "Error on this batch = 0.22038875921205836\n",
      "Cost on val dataset after 74 epochs is = 0.19509709047410773\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.19509709047410773\n",
      "learning rate for this epoch =  0.5114266195394931\n",
      "Error on this batch = 0.18218946128150776\n",
      "Error on this batch = 0.21590635246618267\n",
      "Cost on val dataset after 75 epochs is = 0.19108898247293665\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.19108898247293665\n",
      "learning rate for this epoch =  0.5097132734541368\n",
      "Error on this batch = 0.17709993684579867\n",
      "Error on this batch = 0.2117009220307845\n",
      "Cost on val dataset after 76 epochs is = 0.18735941254110947\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.18735941254110947\n",
      "learning rate for this epoch =  0.5080282478409857\n",
      "Error on this batch = 0.1724382059513115\n",
      "Error on this batch = 0.20776334984175315\n",
      "Cost on val dataset after 77 epochs is = 0.18389786975811817\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.18389786975811817\n",
      "learning rate for this epoch =  0.5063707110745895\n",
      "Error on this batch = 0.16817564432028215\n",
      "Error on this batch = 0.2040776266131248\n",
      "Cost on val dataset after 78 epochs is = 0.1806871398854133\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.1806871398854133\n",
      "learning rate for this epoch =  0.5047398663495227\n",
      "Error on this batch = 0.16427274625643418\n",
      "Error on this batch = 0.2006231504008506\n",
      "Cost on val dataset after 79 epochs is = 0.17770666085625428\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.17770666085625428\n",
      "learning rate for this epoch =  0.5031349497981186\n",
      "Error on this batch = 0.1606864558203213\n",
      "Error on this batch = 0.1973771702518315\n",
      "Cost on val dataset after 80 epochs is = 0.17493502971031805\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.17493502971031805\n",
      "learning rate for this epoch =  0.5015552287323165\n",
      "Error on this batch = 0.15737513042588216\n",
      "Error on this batch = 0.19431689305490732\n",
      "Cost on val dataset after 81 epochs is = 0.17235155127834725\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.17235155127834725\n",
      "learning rate for this epoch =  0.5\n",
      "Error on this batch = 0.15430114967957498\n",
      "Error on this batch = 0.19142096684922016\n",
      "Cost on val dataset after 82 epochs is = 0.169937039116166\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.169937039116166\n",
      "learning rate for this epoch =  0.49846858844706027\n",
      "Error on this batch = 0.1514318419579805\n",
      "Error on this batch = 0.18867030338790935\n",
      "Cost on val dataset after 83 epochs is = 0.16767413657432834\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.16767413657432834\n",
      "learning rate for this epoch =  0.4969603454771852\n",
      "Error on this batch = 0.14873945549994497\n",
      "Error on this batch = 0.1860483717496504\n",
      "Cost on val dataset after 84 epochs is = 0.16554736615914672\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.16554736615914672\n",
      "learning rate for this epoch =  0.4954746477020711\n",
      "Error on this batch = 0.1462006973656523\n",
      "Error on this batch = 0.18354114674624883\n",
      "Cost on val dataset after 85 epochs is = 0.16354303904875941\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.16354303904875941\n",
      "learning rate for this epoch =  0.494010895675377\n",
      "Error on this batch = 0.14379613818780068\n",
      "Error on this batch = 0.18113687070290646\n",
      "Cost on val dataset after 86 epochs is = 0.1616491002359492\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.1616491002359492\n",
      "learning rate for this epoch =  0.4925685127043104\n",
      "Error on this batch = 0.14150962257527444\n",
      "Error on this batch = 0.1788257377537702\n",
      "Cost on val dataset after 87 epochs is = 0.15985495066885438\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.15985495066885438\n",
      "learning rate for this epoch =  0.4911469437332414\n",
      "Error on this batch = 0.1393277379364591\n",
      "Error on this batch = 0.1765995659891965\n",
      "Cost on val dataset after 88 epochs is = 0.15815126872096555\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.15815126872096555\n",
      "learning rate for this epoch =  0.48974565429420786\n",
      "Error on this batch = 0.1372393543104536\n",
      "Error on this batch = 0.17445149246394454\n",
      "Cost on val dataset after 89 epochs is = 0.15652984273795917\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.15652984273795917\n",
      "learning rate for this epoch =  0.48836412951959424\n",
      "Error on this batch = 0.13523523205111146\n",
      "Error on this batch = 0.17237570723853854\n",
      "Cost on val dataset after 90 epochs is = 0.1549834203109892\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.1549834203109892\n",
      "learning rate for this epoch =  0.4870018732126484\n",
      "Error on this batch = 0.13330768933266846\n",
      "Error on this batch = 0.17036723149702518\n",
      "Cost on val dataset after 91 epochs is = 0.15350557628403988\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.15350557628403988\n",
      "learning rate for this epoch =  0.4856584069718464\n",
      "Error on this batch = 0.131450320926869\n",
      "Error on this batch = 0.16842173848180564\n",
      "Cost on val dataset after 92 epochs is = 0.15209059931509775\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.15209059931509775\n",
      "learning rate for this epoch =  0.48433326936543303\n",
      "Error on this batch = 0.12965776078601063\n",
      "Error on this batch = 0.1665354127141125\n",
      "Cost on val dataset after 93 epochs is = 0.15073339555501733\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.15073339555501733\n",
      "learning rate for this epoch =  0.48302601515275106\n",
      "Error on this batch = 0.1279254824739915\n",
      "Error on this batch = 0.1647048416176222\n",
      "Cost on val dataset after 94 epochs is = 0.14942940738095653\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.14942940738095653\n",
      "learning rate for this epoch =  0.48173621454923704\n",
      "Error on this batch = 0.12624963283612325\n",
      "Error on this batch = 0.16292693349347293\n",
      "Cost on val dataset after 95 epochs is = 0.14817454492320514\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.14817454492320514\n",
      "learning rate for this epoch =  0.48046345253219797\n",
      "Error on this batch = 0.12462689520024163\n",
      "Error on this batch = 0.16119885628641448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 96 epochs is = 0.1469651282067927\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.1469651282067927\n",
      "learning rate for this epoch =  0.47920732818470435\n",
      "Error on this batch = 0.12305437879429391\n",
      "Error on this batch = 0.15951799237292577\n",
      "Cost on val dataset after 97 epochs is = 0.14579783797526857\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.14579783797526857\n",
      "learning rate for this epoch =  0.4779674540751329\n",
      "Error on this batch = 0.1215295310652531\n",
      "Error on this batch = 0.15788190546357111\n",
      "Cost on val dataset after 98 epochs is = 0.1446696735822591\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.1446696735822591\n",
      "learning rate for this epoch =  0.4767434556700778\n",
      "Error on this batch = 0.12005006940519315\n",
      "Error on this batch = 0.15628831651763583\n",
      "Cost on val dataset after 99 epochs is = 0.14357791666133224\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.14357791666133224\n",
      "learning rate for this epoch =  0.4755349707785146\n",
      "Error on this batch = 0.11861392865250026\n",
      "Error on this batch = 0.15473508626361576\n",
      "Cost on val dataset after 100 epochs is = 0.14252009957562164\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.14252009957562164\n",
      "learning rate for this epoch =  0.4743416490252569\n",
      "Error on this batch = 0.11721922079436661\n",
      "Error on this batch = 0.15322020249200194\n",
      "Cost on val dataset after 101 epochs is = 0.1414939778859998\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.1414939778859998\n",
      "learning rate for this epoch =  0.47316315135188575\n",
      "Error on this batch = 0.11586420361054799\n",
      "Error on this batch = 0.15174177074511033\n",
      "Cost on val dataset after 102 epochs is = 0.14049750625633967\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.14049750625633967\n",
      "learning rate for this epoch =  0.4719991495434624\n",
      "Error on this batch = 0.11454725553973068\n",
      "Error on this batch = 0.15029800738816032\n",
      "Cost on val dataset after 103 epochs is = 0.13952881734224054\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.13952881734224054\n",
      "learning rate for this epoch =  0.4708493257794535\n",
      "Error on this batch = 0.1132668547328051\n",
      "Error on this batch = 0.14888723432328038\n",
      "Cost on val dataset after 104 epochs is = 0.1385862032958514\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.1385862032958514\n",
      "learning rate for this epoch =  0.46971337220741016\n",
      "Error on this batch = 0.11202156097387335\n",
      "Error on this batch = 0.147507874819094\n",
      "Cost on val dataset after 105 epochs is = 0.13766809957556211\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.13766809957556211\n",
      "learning rate for this epoch =  0.4685909905380384\n",
      "Error on this batch = 0.1108099997997729\n",
      "Error on this batch = 0.14615845008626765\n",
      "Cost on val dataset after 106 epochs is = 0.13677307078577952\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.13677307078577952\n",
      "learning rate for this epoch =  0.4674818916603984\n",
      "Error on this batch = 0.109630848659047\n",
      "Error on this batch = 0.14483757634478775\n",
      "Cost on val dataset after 107 epochs is = 0.13589979829715193\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.13589979829715193\n",
      "learning rate for this epoch =  0.46638579527605073\n",
      "Error on this batch = 0.10848282528338939\n",
      "Error on this batch = 0.14354396221043345\n",
      "Cost on val dataset after 108 epochs is = 0.13504706941752556\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.13504706941752556\n",
      "learning rate for this epoch =  0.4653024295510498\n",
      "Error on this batch = 0.10736467859452505\n",
      "Error on this batch = 0.14227640628264537\n",
      "Cost on val dataset after 109 epochs is = 0.13421376790245684\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.13421376790245684\n",
      "learning rate for this epoch =  0.4642315307847573\n",
      "Error on this batch = 0.10627518246039858\n",
      "Error on this batch = 0.1410337948489046\n",
      "Cost on val dataset after 110 epochs is = 0.13339886561321618\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.13339886561321618\n",
      "learning rate for this epoch =  0.46317284309451723\n",
      "Error on this batch = 0.10521313248672119\n",
      "Error on this batch = 0.13981509963594033\n",
      "Cost on val dataset after 111 epochs is = 0.1326014151503719\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.1326014151503719\n",
      "learning rate for this epoch =  0.46212611811529575\n",
      "Error on this batch = 0.10417734583022022\n",
      "Error on this batch = 0.13861937553921064\n",
      "Cost on val dataset after 112 epochs is = 0.1318205433116793\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.1318205433116793\n",
      "learning rate for this epoch =  0.4610911147134483\n",
      "Error on this batch = 0.10316666379290265\n",
      "Error on this batch = 0.13744575825288308\n",
      "Cost on val dataset after 113 epochs is = 0.13105544524302523\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.13105544524302523\n",
      "learning rate for this epoch =  0.4600675987138297\n",
      "Error on this batch = 0.10217995673901807\n",
      "Error on this batch = 0.13629346170734996\n",
      "Cost on val dataset after 114 epochs is = 0.13030537916945065\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.13030537916945065\n",
      "learning rate for this epoch =  0.4590553426395135\n",
      "Error on this batch = 0.10121613069524416\n",
      "Error on this batch = 0.13516177520541703\n",
      "Cost on val dataset after 115 epochs is = 0.12956966160897185\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.12956966160897185\n",
      "learning rate for this epoch =  0.4580541254634332\n",
      "Error on this batch = 0.10027413486838548\n",
      "Error on this batch = 0.13405006013777807\n",
      "Cost on val dataset after 116 epochs is = 0.12884766298485245\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.12884766298485245\n",
      "learning rate for this epoch =  0.4570637323713\n",
      "Error on this batch = 0.09935296925578463\n",
      "Error on this batch = 0.1329577461594657\n",
      "Cost on val dataset after 117 epochs is = 0.12813880356263144\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.12813880356263144\n",
      "learning rate for this epoch =  0.456083954535194\n",
      "Error on this batch = 0.09845169153935433\n",
      "Error on this batch = 0.13188432672686268\n",
      "Cost on val dataset after 118 epochs is = 0.12744254964765223\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.12744254964765223\n",
      "learning rate for this epoch =  0.45511458889726086\n",
      "Error on this batch = 0.09756942254753959\n",
      "Error on this batch = 0.13082935393226752\n",
      "Cost on val dataset after 119 epochs is = 0.12675840998839258\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.12675840998839258\n",
      "learning rate for this epoch =  0.4541554379629815\n",
      "Error on this batch = 0.09670534973643953\n",
      "Error on this batch = 0.12979243262879164\n",
      "Cost on val dataset after 120 epochs is = 0.12608593234171794\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.12608593234171794\n",
      "learning rate for this epoch =  0.4532063096035152\n",
      "Error on this batch = 0.09585872836756024\n",
      "Error on this batch = 0.12877321390697524\n",
      "Cost on val dataset after 121 epochs is = 0.1254247001688403\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.1254247001688403\n",
      "learning rate for this epoch =  0.45226701686664544\n",
      "Error on this batch = 0.09502888031949926\n",
      "Error on this batch = 0.12777138805666294\n",
      "Cost on val dataset after 122 epochs is = 0.12477432944495713\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.12477432944495713\n",
      "learning rate for this epoch =  0.4513373777958864\n",
      "Error on this batch = 0.09421519072913363\n",
      "Error on this batch = 0.12678667721230008\n",
      "Cost on val dataset after 123 epochs is = 0.12413446558010288\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.12413446558010288\n",
      "learning rate for this epoch =  0.4504172152573348\n",
      "Error on this batch = 0.09341710287629805\n",
      "Error on this batch = 0.1258188279266725\n",
      "Cost on val dataset after 124 epochs is = 0.12350478046192649\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.12350478046192649\n",
      "learning rate for this epoch =  0.4495063567738745\n",
      "Error on this batch = 0.09263411187202363\n",
      "Error on this batch = 0.12486760394033425\n",
      "Cost on val dataset after 125 epochs is = 0.12288496964111922\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.12288496964111922\n",
      "learning rate for this epoch =  0.44860463436636616\n",
      "Error on this batch = 0.09186575776588\n",
      "Error on this batch = 0.12393277940937619\n",
      "Cost on val dataset after 126 epochs is = 0.12227474968574102\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.12227474968574102\n",
      "learning rate for this epoch =  0.4477118844014734\n",
      "Error on this batch = 0.09111161865324986\n",
      "Error on this batch = 0.1230141328252682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 127 epochs is = 0.1216738557312804\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.1216738557312804\n",
      "learning rate for this epoch =  0.44682794744579885\n",
      "Error on this batch = 0.09037130425636537\n",
      "Error on this batch = 0.12211144181309087\n",
      "Cost on val dataset after 128 epochs is = 0.12108203924940909\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.12108203924940909\n",
      "learning rate for this epoch =  0.4459526681260204\n",
      "Error on this batch = 0.08964445030288416\n",
      "Error on this batch = 0.12122447893593481\n",
      "Cost on val dataset after 129 epochs is = 0.1204990660512571\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.1204990660512571\n",
      "learning rate for this epoch =  0.4450858949947362\n",
      "Error on this batch = 0.0889307138647382\n",
      "Error on this batch = 0.12035300857084676\n",
      "Cost on val dataset after 130 epochs is = 0.11992471453217866\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.11992471453217866\n",
      "learning rate for this epoch =  0.4442274804017437\n",
      "Error on this batch = 0.0882297696752301\n",
      "Error on this batch = 0.1194967848615263\n",
      "Cost on val dataset after 131 epochs is = 0.11935877415588211\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.11935877415588211\n",
      "learning rate for this epoch =  0.4433772803704916\n",
      "Error on this batch = 0.08754130733175419\n",
      "Error on this batch = 0.118655550699505\n",
      "Cost on val dataset after 132 epochs is = 0.11880104416760366\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.11880104416760366\n",
      "learning rate for this epoch =  0.4425351544794606\n",
      "Error on this batch = 0.08686502922249874\n",
      "Error on this batch = 0.11782903764163821\n",
      "Cost on val dataset after 133 epochs is = 0.11825133251941197\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.11825133251941197\n",
      "learning rate for this epoch =  0.441700965748239\n",
      "Error on this batch = 0.08620064898666943\n",
      "Error on this batch = 0.11701696663889703\n",
      "Cost on val dataset after 134 epochs is = 0.11770945498600646\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.11770945498600646\n",
      "learning rate for this epoch =  0.44087458052807493\n",
      "Error on this batch = 0.08554789032200986\n",
      "Error on this batch = 0.11621904943000366\n",
      "Cost on val dataset after 135 epochs is = 0.11717523444648664\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.11717523444648664\n",
      "learning rate for this epoch =  0.4400558683966967\n",
      "Error on this batch = 0.08490648598082505\n",
      "Error on this batch = 0.11543499044288634\n",
      "Cost on val dataset after 136 epochs is = 0.11664850030631581\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.11664850030631581\n",
      "learning rate for this epoch =  0.4392447020572046\n",
      "Error on this batch = 0.08427617683620606\n",
      "Error on this batch = 0.11466448904605268\n",
      "Cost on val dataset after 137 epochs is = 0.11612908803381118\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.11612908803381118\n",
      "learning rate for this epoch =  0.43844095724084814\n",
      "Error on this batch = 0.08365671094480877\n",
      "Error on this batch = 0.11390724199919142\n",
      "Cost on val dataset after 138 epochs is = 0.11561683878670456\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.11561683878670456\n",
      "learning rate for this epoch =  0.437644512613512\n",
      "Error on this batch = 0.08304784257446876\n",
      "Error on this batch = 0.11316294596579336\n",
      "Cost on val dataset after 139 epochs is = 0.11511159910639211\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.11511159910639211\n",
      "learning rate for this epoch =  0.4368552496857437\n",
      "Error on this batch = 0.08244933119945728\n",
      "Error on this batch = 0.11243129996848185\n",
      "Cost on val dataset after 140 epochs is = 0.11461322066022955\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.11461322066022955\n",
      "learning rate for this epoch =  0.4360730527261645\n",
      "Error on this batch = 0.08186094049074213\n",
      "Error on this batch = 0.11171200768832665\n",
      "Cost on val dataset after 141 epochs is = 0.11412156001542183\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.11412156001542183\n",
      "learning rate for this epoch =  0.4352978086781127\n",
      "Error on this batch = 0.08128243734249402\n",
      "Error on this batch = 0.11100477953114947\n",
      "Cost on val dataset after 142 epochs is = 0.11363647843151088\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.11363647843151088\n",
      "learning rate for this epoch =  0.43452940707937715\n",
      "Error on this batch = 0.08071359098003217\n",
      "Error on this batch = 0.11030933440542631\n",
      "Cost on val dataset after 143 epochs is = 0.11315784166196999\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.11315784166196999\n",
      "learning rate for this epoch =  0.4337677399848857\n",
      "Error on this batch = 0.08015417219024248\n",
      "Error on this batch = 0.10962540117683231\n",
      "Cost on val dataset after 144 epochs is = 0.11268551975876297\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.11268551975876297\n",
      "learning rate for this epoch =  0.43301270189221935\n",
      "Error on this batch = 0.07960395270564458\n",
      "Error on this batch = 0.10895271978298192\n",
      "Cost on val dataset after 145 epochs is = 0.11221938687673857\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.11221938687673857\n",
      "learning rate for this epoch =  0.43226418966983016\n",
      "Error on this batch = 0.07906270476032716\n",
      "Error on this batch = 0.10829104200796102\n",
      "Cost on val dataset after 146 epochs is = 0.11175932107724858\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.11175932107724858\n",
      "learning rate for this epoch =  0.431522102487848\n",
      "Error on this batch = 0.07853020082231052\n",
      "Error on this batch = 0.10764013192951197\n",
      "Cost on val dataset after 147 epochs is = 0.11130520413231651\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.11130520413231651\n",
      "learning rate for this epoch =  0.4307863417513635\n",
      "Error on this batch = 0.07800621349446685\n",
      "Error on this batch = 0.10699976606210494\n",
      "Cost on val dataset after 148 epochs is = 0.11085692133199661\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.11085692133199661\n",
      "learning rate for this epoch =  0.43005681103608506\n",
      "Error on this batch = 0.07749051556623891\n",
      "Error on this batch = 0.10636973322667334\n",
      "Cost on val dataset after 149 epochs is = 0.1104143612982836\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.1104143612982836\n",
      "learning rate for this epoch =  0.4293334160262675\n",
      "Error on this batch = 0.07698288019170828\n",
      "Error on this batch = 0.10574983418271171\n",
      "Cost on val dataset after 150 epochs is = 0.10997741580912644\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.10997741580912644\n",
      "learning rate for this epoch =  0.4286160644548199\n",
      "Error on this batch = 0.07648308116614809\n",
      "Error on this batch = 0.10513988106105089\n",
      "Cost on val dataset after 151 epochs is = 0.10954597963586794\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.10954597963586794\n",
      "learning rate for this epoch =  0.4279046660455\n",
      "Error on this batch = 0.07599089327269615\n",
      "Error on this batch = 0.10453969663631009\n",
      "Cost on val dataset after 152 epochs is = 0.10911995039689326\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.10911995039689326\n",
      "learning rate for this epoch =  0.4271991324571105\n",
      "Error on this batch = 0.07550609267256032\n",
      "Error on this batch = 0.10394911347718426\n",
      "Cost on val dataset after 153 epochs is = 0.10869922842953131\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.10869922842953131\n",
      "learning rate for this epoch =  0.42649937722961534\n",
      "Error on this batch = 0.07502845731548571\n",
      "Error on this batch = 0.10336797301073784\n",
      "Cost on val dataset after 154 epochs is = 0.10828371668141674\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.10828371668141674\n",
      "learning rate for this epoch =  0.4258053157320967\n",
      "Error on this batch = 0.07455776735134638\n",
      "Error on this batch = 0.10279612453408966\n",
      "Cost on val dataset after 155 epochs is = 0.10787332062165668\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.10787332062165668\n",
      "learning rate for this epoch =  0.4251168651124797\n",
      "Error on this batch = 0.07409380552807358\n",
      "Error on this batch = 0.10223342420356694\n",
      "Cost on val dataset after 156 epochs is = 0.1074679481713201\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.1074679481713201\n",
      "learning rate for this epoch =  0.4244339442489526\n",
      "Error on this batch = 0.073636357565252\n",
      "Error on this batch = 0.10167973402780517\n",
      "Cost on val dataset after 157 epochs is = 0.10706750965200622\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.10706750965200622\n",
      "learning rate for this epoch =  0.4237564737030161\n",
      "Error on this batch = 0.07318521249632365\n",
      "Error on this batch = 0.10113492088752639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 158 epochs is = 0.10667191775058309\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.10667191775058309\n",
      "learning rate for this epoch =  0.42308437567409557\n",
      "Error on this batch = 0.07274016297531187\n",
      "Error on this batch = 0.10059885560096417\n",
      "Cost on val dataset after 159 epochs is = 0.10628108749762628\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.10628108749762628\n",
      "learning rate for this epoch =  0.4224175739556564\n",
      "Error on this batch = 0.07230100554629747\n",
      "Error on this batch = 0.10007141205018458\n",
      "Cost on val dataset after 160 epochs is = 0.1058949362566426\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.1058949362566426\n",
      "learning rate for this epoch =  0.4217559938927618\n",
      "Error on this batch = 0.0718675408756064\n",
      "Error on this batch = 0.09955246637994311\n",
      "Cost on val dataset after 161 epochs is = 0.10551338372083792\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.10551338372083792\n",
      "learning rate for this epoch =  0.42109956234101886\n",
      "Error on this batch = 0.07143957394790944\n",
      "Error on this batch = 0.0990418962772587\n",
      "Cost on val dataset after 162 epochs is = 0.10513635191398743\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.10513635191398743\n",
      "learning rate for this epoch =  0.42044820762685725\n",
      "Error on this batch = 0.07101691422829533\n",
      "Error on this batch = 0.09853958033662678\n",
      "Cost on val dataset after 163 epochs is = 0.10476376519189314\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.10476376519189314\n",
      "learning rate for this epoch =  0.41980185950909077\n",
      "Error on this batch = 0.07059937579296603\n",
      "Error on this batch = 0.09804539751277812\n",
      "Cost on val dataset after 164 epochs is = 0.10439555024096679\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.10439555024096679\n",
      "learning rate for this epoch =  0.41916044914171213\n",
      "Error on this batch = 0.0701867774315925\n",
      "Error on this batch = 0.09755922666017527\n",
      "Cost on val dataset after 165 epochs is = 0.1040316360706535\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.1040316360706535\n",
      "learning rate for this epoch =  0.418523909037874\n",
      "Error on this batch = 0.06977894272461757\n",
      "Error on this batch = 0.09708094615607385\n",
      "Cost on val dataset after 166 epochs is = 0.10367195399671036\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.10367195399671036\n",
      "learning rate for this epoch =  0.4178921730350126\n",
      "Error on this batch = 0.06937570009892531\n",
      "Error on this batch = 0.09661043360201277\n",
      "Cost on val dataset after 167 epochs is = 0.10331643761275974\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.10331643761275974\n",
      "learning rate for this epoch =  0.4172651762610688\n",
      "Error on this batch = 0.06897688286532354\n",
      "Error on this batch = 0.09614756559708014\n",
      "Cost on val dataset after 168 epochs is = 0.10296502274804387\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.10296502274804387\n",
      "learning rate for this epoch =  0.4166428551017686\n",
      "Error on this batch = 0.06858232924120211\n",
      "Error on this batch = 0.09569221757525402\n",
      "Cost on val dataset after 169 epochs is = 0.10261764740989916\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.10261764740989916\n",
      "learning rate for this epoch =  0.41602514716892186\n",
      "Error on this batch = 0.06819188236152719\n",
      "Error on this batch = 0.0952442636985619\n",
      "Cost on val dataset after 170 epochs is = 0.10227425171013206\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.10227425171013206\n",
      "learning rate for this epoch =  0.4154119912697013\n",
      "Error on this batch = 0.06780539028099926\n",
      "Error on this batch = 0.09480357679772201\n",
      "Cost on val dataset after 171 epochs is = 0.10193477777520053\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.10193477777520053\n",
      "learning rate for this epoch =  0.41480332737686826\n",
      "Error on this batch = 0.06742270596974405\n",
      "Error on this batch = 0.09437002835231091\n",
      "Cost on val dataset after 172 epochs is = 0.1015991696408711\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.1015991696408711\n",
      "learning rate for this epoch =  0.4141990965999084\n",
      "Error on this batch = 0.06704368730433258\n",
      "Error on this batch = 0.09394348850328874\n",
      "Cost on val dataset after 173 epochs is = 0.10126737313281474\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.10126737313281474\n",
      "learning rate for this epoch =  0.4135992411570453\n",
      "Error on this batch = 0.06666819705526664\n",
      "Error on this batch = 0.09352382609185034\n",
      "Cost on val dataset after 174 epochs is = 0.1009393357354089\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.1009393357354089\n",
      "learning rate for this epoch =  0.4130037043481005\n",
      "Error on this batch = 0.06629610287137037\n",
      "Error on this batch = 0.093110908719969\n",
      "Cost on val dataset after 175 epochs is = 0.10061500645179816\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.10061500645179816\n",
      "learning rate for this epoch =  0.4124124305281695\n",
      "Error on this batch = 0.06592727726085251\n",
      "Error on this batch = 0.09270460282956357\n",
      "Cost on val dataset after 176 epochs is = 0.10029433565900321\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.10029433565900321\n",
      "learning rate for this epoch =  0.41182536508208434\n",
      "Error on this batch = 0.06556159756822731\n",
      "Error on this batch = 0.09230477379883345\n",
      "Cost on val dataset after 177 epochs is = 0.09997727496250454\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.09997727496250454\n",
      "learning rate for this epoch =  0.41124245439963575\n",
      "Error on this batch = 0.065198945945879\n",
      "Error on this batch = 0.09191128605583863\n",
      "Cost on val dataset after 178 epochs is = 0.099663777055209\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.099663777055209\n",
      "learning rate for this epoch =  0.41066364585152754\n",
      "Error on this batch = 0.06483920931890139\n",
      "Error on this batch = 0.0915240032107199\n",
      "Cost on val dataset after 179 epochs is = 0.09935379558596091\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.09935379558596091\n",
      "learning rate for this epoch =  0.41008888776603736\n",
      "Error on this batch = 0.0644822793419953\n",
      "Error on this batch = 0.09114278820890861\n",
      "Cost on val dataset after 180 epochs is = 0.0990472850427144\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.0990472850427144\n",
      "learning rate for this epoch =  0.40951812940636\n",
      "Error on this batch = 0.06412805234768901\n",
      "Error on this batch = 0.09076750350814067\n",
      "Cost on val dataset after 181 epochs is = 0.09874420065507138\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.09874420065507138\n",
      "learning rate for this epoch =  0.40895132094860925\n",
      "Error on this batch = 0.0637764292859446\n",
      "Error on this batch = 0.09039801128194544\n",
      "Cost on val dataset after 182 epochs is = 0.09844449832007211\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.09844449832007211\n",
      "learning rate for this epoch =  0.40838841346045524\n",
      "Error on this batch = 0.06342731565626358\n",
      "Error on this batch = 0.09003417365146602\n",
      "Cost on val dataset after 183 epochs is = 0.09814813455389615\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.09814813455389615\n",
      "learning rate for this epoch =  0.40782935888037647\n",
      "Error on this batch = 0.06308062143459295\n",
      "Error on this batch = 0.08967585294597102\n",
      "Cost on val dataset after 184 epochs is = 0.09785506647054729\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.09785506647054729\n",
      "learning rate for this epoch =  0.40727410999750435\n",
      "Error on this batch = 0.06273626099850774\n",
      "Error on this batch = 0.08932291199032175\n",
      "Cost on val dataset after 185 epochs is = 0.09756525178676816\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.09756525178676816\n",
      "learning rate for this epoch =  0.40672262043204177\n",
      "Error on this batch = 0.062394153055135446\n",
      "Error on this batch = 0.088975214415132\n",
      "Cost on val dataset after 186 epochs is = 0.09727864885052802\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.09727864885052802\n",
      "learning rate for this epoch =  0.40617484461623476\n",
      "Error on this batch = 0.0620542205769232\n",
      "Error on this batch = 0.08863262498266496\n",
      "Cost on val dataset after 187 epochs is = 0.09699521668866037\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.09699521668866037\n",
      "learning rate for this epoch =  0.4056307377758796\n",
      "Error on this batch = 0.061716390750498513\n",
      "Error on this batch = 0.08829500991898093\n",
      "Cost on val dataset after 188 epochs is = 0.09671491506780557\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.09671491506780557\n",
      "learning rate for this epoch =  0.4050902559123477\n",
      "Error on this batch = 0.06138059494346848\n",
      "Error on this batch = 0.08796223724084312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 189 epochs is = 0.09643770456191984\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.09643770456191984\n",
      "learning rate for this epoch =  0.40455335578511065\n",
      "Error on this batch = 0.06104676869303978\n",
      "Error on this batch = 0.08763417706472731\n",
      "Cost on val dataset after 190 epochs is = 0.09616354661936237\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.09616354661936237\n",
      "learning rate for this epoch =  0.4040199948947485\n",
      "Error on this batch = 0.0607148517189054\n",
      "Error on this batch = 0.08731070188520386\n",
      "Cost on val dataset after 191 epochs is = 0.0958924036229878\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.0958924036229878\n",
      "learning rate for this epoch =  0.4034901314664274\n",
      "Error on this batch = 0.06038478796107702\n",
      "Error on this batch = 0.0869916868110596\n",
      "Cost on val dataset after 192 epochs is = 0.09562423893768275\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.09562423893768275\n",
      "learning rate for this epoch =  0.4029637244338282\n",
      "Error on this batch = 0.06005652564142053\n",
      "Error on this batch = 0.08667700974972999\n",
      "Cost on val dataset after 193 epochs is = 0.09535901694124153\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.09535901694124153\n",
      "learning rate for this epoch =  0.4024407334235145\n",
      "Error on this batch = 0.05973001734577313\n",
      "Error on this batch = 0.08636655153369233\n",
      "Cost on val dataset after 194 epochs is = 0.09509670303617153\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.09509670303617153\n",
      "learning rate for this epoch =  0.4019211187397237\n",
      "Error on this batch = 0.05940522012184249\n",
      "Error on this batch = 0.0860601959860779\n",
      "Cost on val dataset after 195 epochs is = 0.09483726364174268\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.09483726364174268\n",
      "learning rate for this epoch =  0.40140484134956866\n",
      "Error on this batch = 0.059082095586744536\n",
      "Error on this batch = 0.08575782992649401\n",
      "Cost on val dataset after 196 epochs is = 0.09458066616715657\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.09458066616715657\n",
      "learning rate for this epoch =  0.4008918628686366\n",
      "Error on this batch = 0.058760610037094464\n",
      "Error on this batch = 0.08545934312151776\n",
      "Cost on val dataset after 197 epochs is = 0.0943268789679725\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.0943268789679725\n",
      "learning rate for this epoch =  0.40038214554697205\n",
      "Error on this batch = 0.058440734554053526\n",
      "Error on this batch = 0.08516462818721078\n",
      "Cost on val dataset after 198 epochs is = 0.09407587128881406\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.09407587128881406\n",
      "learning rate for this epoch =  0.3998756522554328\n",
      "Error on this batch = 0.058122445095632996\n",
      "Error on this batch = 0.08487358045310703\n",
      "Cost on val dataset after 199 epochs is = 0.09382761319587957\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.09382761319587957\n",
      "learning rate for this epoch =  0.3993723464724061\n",
      "Error on this batch = 0.05780572256882449\n",
      "Error on this batch = 0.0845860977983556\n",
      "Cost on val dataset after 200 epochs is = 0.09358207550292756\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.09358207550292756\n",
      "learning rate for this epoch =  0.39887219227087417\n",
      "Error on this batch = 0.05749055287470869\n",
      "Error on this batch = 0.08430208047108606\n",
      "Cost on val dataset after 201 epochs is = 0.09333922969427068\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.09333922969427068\n",
      "learning rate for this epoch =  0.3983751543058184\n",
      "Error on this batch = 0.05717692692053387\n",
      "Error on this batch = 0.08402143090171764\n",
      "Cost on val dataset after 202 epochs is = 0.09309904784796903\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.09309904784796903\n",
      "learning rate for this epoch =  0.39788119780195147\n",
      "Error on this batch = 0.05686484059379948\n",
      "Error on this batch = 0.08374405352001008\n",
      "Cost on val dataset after 203 epochs is = 0.0928615025619403\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.0928615025619403\n",
      "learning rate for this epoch =  0.39739028854176744\n",
      "Error on this batch = 0.05655429469457973\n",
      "Error on this batch = 0.08346985458433392\n",
      "Cost on val dataset after 204 epochs is = 0.09262656688516968\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.09262656688516968\n",
      "learning rate for this epoch =  0.39690239285389944\n",
      "Error on this batch = 0.05624529482363059\n",
      "Error on this batch = 0.08319874203008686\n",
      "Cost on val dataset after 205 epochs is = 0.09239421425565329\n",
      "Initial Cost on Val dataset for this epoch 205 = 0.09239421425565329\n",
      "learning rate for this epoch =  0.39641747760177665\n",
      "Error on this batch = 0.05593785122519952\n",
      "Error on this batch = 0.08293062534253971\n",
      "Cost on val dataset after 206 epochs is = 0.09216441844618138\n",
      "Initial Cost on Val dataset for this epoch 206 = 0.09216441844618138\n",
      "learning rate for this epoch =  0.3959355101725709\n",
      "Error on this batch = 0.055631978584848606\n",
      "Error on this batch = 0.08266541545777396\n",
      "Cost on val dataset after 207 epochs is = 0.0919371535185855\n",
      "Initial Cost on Val dataset for this epoch 207 = 0.0919371535185855\n",
      "learning rate for this epoch =  0.39545645846642347\n",
      "Error on this batch = 0.05532769578396498\n",
      "Error on this batch = 0.08240302469384587\n",
      "Cost on val dataset after 208 epochs is = 0.0917123937866471\n",
      "Initial Cost on Val dataset for this epoch 208 = 0.0917123937866471\n",
      "learning rate for this epoch =  0.39498029088594494\n",
      "Error on this batch = 0.05502502561391148\n",
      "Error on this batch = 0.0821433667129263\n",
      "Cost on val dataset after 209 epochs is = 0.09149011378750178\n",
      "Initial Cost on Val dataset for this epoch 209 = 0.09149011378750178\n",
      "learning rate for this epoch =  0.3945069763259793\n",
      "Error on this batch = 0.05472399445392281\n",
      "Error on this batch = 0.08188635651394843\n",
      "Cost on val dataset after 210 epochs is = 0.09127028826107905\n",
      "Initial Cost on Val dataset for this epoch 210 = 0.09127028826107905\n",
      "learning rate for this epoch =  0.39403648416362375\n",
      "Error on this batch = 0.054424631917828405\n",
      "Error on this batch = 0.08163191045424745\n",
      "Cost on val dataset after 211 epochs is = 0.09105289213688768\n",
      "Initial Cost on Val dataset for this epoch 211 = 0.09105289213688768\n",
      "learning rate for this epoch =  0.39356878424849795\n",
      "Error on this batch = 0.05412697047545473\n",
      "Error on this batch = 0.08137994629779914\n",
      "Cost on val dataset after 212 epochs is = 0.09083790052729827\n",
      "Initial Cost on Val dataset for this epoch 212 = 0.09083790052729827\n",
      "learning rate for this epoch =  0.39310384689325434\n",
      "Error on this batch = 0.05383104505510044\n",
      "Error on this batch = 0.08113038328694015\n",
      "Cost on val dataset after 213 epochs is = 0.09062528872637822\n",
      "Initial Cost on Val dataset for this epoch 213 = 0.09062528872637822\n",
      "learning rate for this epoch =  0.39264164286432307\n",
      "Error on this batch = 0.053536892633778685\n",
      "Error on this batch = 0.08088314223386654\n",
      "Cost on val dataset after 214 epochs is = 0.09041503221330188\n",
      "Initial Cost on Val dataset for this epoch 214 = 0.09041503221330188\n",
      "learning rate for this epoch =  0.3921821433728839\n",
      "Error on this batch = 0.05324455182199049\n",
      "Error on this batch = 0.08063814562774392\n",
      "Cost on val dataset after 215 epochs is = 0.09020710665938085\n",
      "Initial Cost on Val dataset for this epoch 215 = 0.09020710665938085\n",
      "learning rate for this epoch =  0.3917253200660592\n",
      "Error on this batch = 0.05295406244964176\n",
      "Error on this batch = 0.08039531775290369\n",
      "Cost on val dataset after 216 epochs is = 0.090001487937828\n",
      "Initial Cost on Val dataset for this epoch 216 = 0.090001487937828\n",
      "learning rate for this epoch =  0.39127114501832183\n",
      "Error on this batch = 0.05266546515937774\n",
      "Error on this batch = 0.08015458481333142\n",
      "Cost on val dataset after 217 epochs is = 0.0897981521354763\n",
      "Initial Cost on Val dataset for this epoch 217 = 0.0897981521354763\n",
      "learning rate for this epoch =  0.39081959072311023\n",
      "Error on this batch = 0.052378801013112\n",
      "Error on this batch = 0.07991587505847285\n",
      "Cost on val dataset after 218 epochs is = 0.08959707556580031\n",
      "Initial Cost on Val dataset for this epoch 218 = 0.08959707556580031\n",
      "learning rate for this epoch =  0.39037063008464684\n",
      "Error on this batch = 0.05209411111691147\n",
      "Error on this batch = 0.07967911890528456\n",
      "Cost on val dataset after 219 epochs is = 0.0893982347827287\n",
      "Initial Cost on Val dataset for this epoch 219 = 0.0893982347827287\n",
      "learning rate for this epoch =  0.3899242364099523\n",
      "Error on this batch = 0.05181143626870517\n",
      "Error on this batch = 0.07944424905144623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 220 epochs is = 0.08920160659486648\n",
      "Initial Cost on Val dataset for this epoch 220 = 0.08920160659486648\n",
      "learning rate for this epoch =  0.38948038340105073\n",
      "Error on this batch = 0.05153081663254503\n",
      "Error on this batch = 0.07921120057474652\n",
      "Cost on val dataset after 221 epochs is = 0.08900716807985527\n",
      "Initial Cost on Val dataset for this epoch 221 = 0.08900716807985527\n",
      "learning rate for this epoch =  0.3890390451473609\n",
      "Error on this batch = 0.05125229144239907\n",
      "Error on this batch = 0.07897991101386904\n",
      "Cost on val dataset after 222 epochs is = 0.0888148965986735\n",
      "Initial Cost on Val dataset for this epoch 222 = 0.0888148965986735\n",
      "learning rate for this epoch =  0.3886001961182669\n",
      "Error on this batch = 0.05097589873772236\n",
      "Error on this batch = 0.0787503204261602\n",
      "Cost on val dataset after 223 epochs is = 0.08862476980970267\n",
      "Initial Cost on Val dataset for this epoch 223 = 0.08862476980970267\n",
      "learning rate for this epoch =  0.3881638111558645\n",
      "Error on this batch = 0.05070167513235593\n",
      "Error on this batch = 0.07852237141847956\n",
      "Cost on val dataset after 224 epochs is = 0.08843676568235292\n",
      "Initial Cost on Val dataset for this epoch 224 = 0.08843676568235292\n",
      "learning rate for this epoch =  0.3877298654678779\n",
      "Error on this batch = 0.05042965561765291\n",
      "Error on this batch = 0.07829600914792295\n",
      "Cost on val dataset after 225 epochs is = 0.08825086250994767\n",
      "Initial Cost on Val dataset for this epoch 225 = 0.08825086250994767\n",
      "learning rate for this epoch =  0.3872983346207417\n",
      "Error on this batch = 0.05015987340014316\n",
      "Error on this batch = 0.07807118129007742\n",
      "Cost on val dataset after 226 epochs is = 0.08806703892141608\n",
      "Initial Cost on Val dataset for this epoch 226 = 0.08806703892141608\n",
      "learning rate for this epoch =  0.3868691945328438\n",
      "Error on this batch = 0.04989235977351253\n",
      "Error on this batch = 0.07784783797349155\n",
      "Cost on val dataset after 227 epochs is = 0.0878852738911415\n",
      "Initial Cost on Val dataset for this epoch 227 = 0.0878852738911415\n",
      "learning rate for this epoch =  0.3864424214679254\n",
      "Error on this batch = 0.04962714402419666\n",
      "Error on this batch = 0.07762593168019878\n",
      "Cost on val dataset after 228 epochs is = 0.08770554674608087\n",
      "Initial Cost on Val dataset for this epoch 228 = 0.08770554674608087\n",
      "learning rate for this epoch =  0.3860179920286326\n",
      "Error on this batch = 0.049364253369462076\n",
      "Error on this batch = 0.07740541711334938\n",
      "Cost on val dataset after 229 epochs is = 0.08752783716902923\n",
      "Initial Cost on Val dataset for this epoch 229 = 0.08752783716902923\n",
      "learning rate for this epoch =  0.38559588315021626\n",
      "Error on this batch = 0.049103712926460326\n",
      "Error on this batch = 0.07718625103422057\n",
      "Cost on val dataset after 230 epochs is = 0.08735212519667718\n",
      "Initial Cost on Val dataset for this epoch 230 = 0.08735212519667718\n",
      "learning rate for this epoch =  0.38517607209437615\n",
      "Error on this batch = 0.048845545710386865\n",
      "Error on this batch = 0.07696839207199228\n",
      "Cost on val dataset after 231 epochs is = 0.08717839121093297\n",
      "Initial Cost on Val dataset for this epoch 231 = 0.08717839121093297\n",
      "learning rate for this epoch =  0.3847585364432452\n",
      "Error on this batch = 0.048589772659546844\n",
      "Error on this batch = 0.07675180051060672\n",
      "Cost on val dataset after 232 epochs is = 0.08700661592187965\n",
      "Initial Cost on Val dataset for this epoch 232 = 0.08700661592187965\n",
      "learning rate for this epoch =  0.38434325409350933\n",
      "Error on this batch = 0.04833641268481419\n",
      "Error on this batch = 0.07653643805769211\n",
      "Cost on val dataset after 233 epochs is = 0.0868367803407387\n",
      "Initial Cost on Val dataset for this epoch 233 = 0.0868367803407387\n",
      "learning rate for this epoch =  0.38393020325066135\n",
      "Error on this batch = 0.048085482740669705\n",
      "Error on this batch = 0.07632226760086408\n",
      "Cost on val dataset after 234 epochs is = 0.08666886574133606\n",
      "Initial Cost on Val dataset for this epoch 234 = 0.08666886574133606\n",
      "learning rate for this epoch =  0.38351936242338275\n",
      "Error on this batch = 0.047836997914709106\n",
      "Error on this batch = 0.07610925295669545\n",
      "Cost on val dataset after 235 epochs is = 0.08650285360882161\n",
      "Initial Cost on Val dataset for this epoch 235 = 0.08650285360882161\n",
      "learning rate for this epoch =  0.383110710418052\n",
      "Error on this batch = 0.04759097153223172\n",
      "Error on this batch = 0.07589735861728951\n",
      "Cost on val dataset after 236 epochs is = 0.08633872557478944\n",
      "Initial Cost on Val dataset for this epoch 236 = 0.08633872557478944\n",
      "learning rate for this epoch =  0.38270422633337464\n",
      "Error on this batch = 0.047347415272254355\n",
      "Error on this batch = 0.07568654949876658\n",
      "Cost on val dataset after 237 epochs is = 0.08617646333847372\n",
      "Initial Cost on Val dataset for this epoch 237 = 0.08617646333847372\n",
      "learning rate for this epoch =  0.38229988955513305\n",
      "Error on this batch = 0.0471063392910539\n",
      "Error on this batch = 0.07547679069519476\n",
      "Cost on val dataset after 238 epochs is = 0.08601604857435036\n",
      "Initial Cost on Val dataset for this epoch 238 = 0.08601604857435036\n",
      "learning rate for this epoch =  0.3818976797510519\n",
      "Error on this batch = 0.04686775234913554\n",
      "Error on this batch = 0.07526804724071486\n",
      "Cost on val dataset after 239 epochs is = 0.08585746282724223\n",
      "Initial Cost on Val dataset for this epoch 239 = 0.08585746282724223\n",
      "learning rate for this epoch =  0.38149757686577634\n",
      "Error on this batch = 0.046631661937362935\n",
      "Error on this batch = 0.07506028388199065\n",
      "Cost on val dataset after 240 epochs is = 0.08570068739689475\n",
      "Initial Cost on Val dataset for this epoch 240 = 0.08570068739689475\n",
      "learning rate for this epoch =  0.38109956111596105\n",
      "Error on this batch = 0.046398074397885035\n",
      "Error on this batch = 0.07485346486283871\n",
      "Cost on val dataset after 241 epochs is = 0.08554570321493904\n",
      "Initial Cost on Val dataset for this epoch 241 = 0.08554570321493904\n",
      "learning rate for this epoch =  0.3807036129854653\n",
      "Error on this batch = 0.046166995035464335\n",
      "Error on this batch = 0.07464755372309624\n",
      "Cost on val dataset after 242 epochs is = 0.08539249071817634\n",
      "Initial Cost on Val dataset for this epoch 242 = 0.08539249071817634\n",
      "learning rate for this epoch =  0.3803097132206534\n",
      "Error on this batch = 0.04593842821486886\n",
      "Error on this batch = 0.07444251311457142\n",
      "Cost on val dataset after 243 epochs is = 0.0852410297231597\n",
      "Initial Cost on Val dataset for this epoch 243 = 0.0852410297231597\n",
      "learning rate for this epoch =  0.37991784282579627\n",
      "Error on this batch = 0.045712377440152496\n",
      "Error on this batch = 0.07423830463831811\n",
      "Cost on val dataset after 244 epochs is = 0.08509129930807552\n",
      "Initial Cost on Val dataset for this epoch 244 = 0.08509129930807552\n",
      "learning rate for this epoch =  0.3795279830585723\n",
      "Error on this batch = 0.04548884541193612\n",
      "Error on this batch = 0.0740348887094097\n",
      "Cost on val dataset after 245 epochs is = 0.08494327770885292\n",
      "Initial Cost on Val dataset for this epoch 245 = 0.08494327770885292\n",
      "learning rate for this epoch =  0.3791401154256649\n",
      "Error on this batch = 0.04526783405924819\n",
      "Error on this batch = 0.07383222445768312\n",
      "Cost on val dataset after 246 epochs is = 0.08479694223714389\n",
      "Initial Cost on Val dataset for this epoch 246 = 0.08479694223714389\n",
      "learning rate for this epoch =  0.3787542216784535\n",
      "Error on this batch = 0.0450493445431173\n",
      "Error on this batch = 0.07363026967527707\n",
      "Cost on val dataset after 247 epochs is = 0.08465226922817497\n",
      "Initial Cost on Val dataset for this epoch 247 = 0.08465226922817497\n",
      "learning rate for this epoch =  0.3783702838087975\n",
      "Error on this batch = 0.0448333772299727\n",
      "Error on this batch = 0.0734289808237931\n",
      "Cost on val dataset after 248 epochs is = 0.08450923402629115\n",
      "Initial Cost on Val dataset for this epoch 248 = 0.08450923402629115\n",
      "learning rate for this epoch =  0.3779882840449083\n",
      "Error on this batch = 0.04461993163403068\n",
      "Error on this batch = 0.07322831311505096\n",
      "Cost on val dataset after 249 epochs is = 0.08436781101511777\n",
      "Initial Cost on Val dataset for this epoch 249 = 0.08436781101511777\n",
      "learning rate for this epoch =  0.37760820484730934\n",
      "Error on this batch = 0.044409006329240996\n",
      "Error on this batch = 0.07302822067916347\n",
      "Cost on val dataset after 250 epochs is = 0.08422797369750094\n",
      "Initial Cost on Val dataset for this epoch 250 = 0.08422797369750094\n",
      "learning rate for this epoch =  0.37723002890488067\n",
      "Error on this batch = 0.04420059883301535\n",
      "Error on this batch = 0.07282865683152208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 251 epochs is = 0.08408969482768586\n",
      "Initial Cost on Val dataset for this epoch 251 = 0.08408969482768586\n",
      "learning rate for this epoch =  0.37685373913098663\n",
      "Error on this batch = 0.043994705465788535\n",
      "Error on this batch = 0.07262957444593703\n",
      "Cost on val dataset after 252 epochs is = 0.08395294659461892\n",
      "Initial Cost on Val dataset for this epoch 252 = 0.08395294659461892\n",
      "learning rate for this epoch =  0.3764793186596844\n",
      "Error on this batch = 0.04379132119233731\n",
      "Error on this batch = 0.0724309264345672\n",
      "Cost on val dataset after 253 epochs is = 0.08381770085105705\n",
      "Initial Cost on Val dataset for this epoch 253 = 0.08381770085105705\n",
      "learning rate for this epoch =  0.37610675084201106\n",
      "Error on this batch = 0.04359043945250466\n",
      "Error on this batch = 0.0722326663267504\n",
      "Cost on val dataset after 254 epochs is = 0.083683929378774\n",
      "Initial Cost on Val dataset for this epoch 254 = 0.083683929378774\n",
      "learning rate for this epoch =  0.37573601924234745\n",
      "Error on this batch = 0.04339205199031248\n",
      "Error on this batch = 0.07203474892919409\n",
      "Cost on val dataset after 255 epochs is = 0.08355160417614863\n",
      "Initial Cost on Val dataset for this epoch 255 = 0.08355160417614863\n",
      "learning rate for this epoch =  0.3753671076348574\n",
      "Error on this batch = 0.04319614869115041\n",
      "Error on this batch = 0.0718371310403984\n",
      "Cost on val dataset after 256 epochs is = 0.08342069775145909\n",
      "Initial Cost on Val dataset for this epoch 256 = 0.08342069775145909\n",
      "learning rate for this epoch =  0.375\n",
      "Error on this batch = 0.04300271743661447\n",
      "Error on this batch = 0.07163977218409769\n",
      "Cost on val dataset after 257 epochs is = 0.08329118340385938\n",
      "Initial Cost on Val dataset for this epoch 257 = 0.08329118340385938\n",
      "learning rate for this epoch =  0.37463468052111276\n",
      "Error on this batch = 0.04281174398555137\n",
      "Error on this batch = 0.07144263532133954\n",
      "Cost on val dataset after 258 epochs is = 0.0831630354746411\n",
      "Initial Cost on Val dataset for this epoch 258 = 0.0831630354746411\n",
      "learning rate for this epoch =  0.3742711335810649\n",
      "Error on this batch = 0.04262321188800172\n",
      "Error on this batch = 0.07124568749967046\n",
      "Cost on val dataset after 259 epochs is = 0.08303622955400983\n",
      "Initial Cost on Val dataset for this epoch 259 = 0.08303622955400983\n",
      "learning rate for this epoch =  0.37390934375897855\n",
      "Error on this batch = 0.042437102436240264\n",
      "Error on this batch = 0.07104890040125064\n",
      "Cost on val dataset after 260 epochs is = 0.08291074263289294\n",
      "Initial Cost on Val dataset for this epoch 260 = 0.08291074263289294\n",
      "learning rate for this epoch =  0.37354929582701596\n",
      "Error on this batch = 0.04225339465431073\n",
      "Error on this batch = 0.07085225075930136\n",
      "Cost on val dataset after 261 epochs is = 0.08278655319460541\n",
      "Initial Cost on Val dataset for this epoch 261 = 0.08278655319460541\n",
      "learning rate for this epoch =  0.3731909747472316\n",
      "Error on this batch = 0.04207206532472716\n",
      "Error on this batch = 0.07065572062309024\n",
      "Cost on val dataset after 262 epochs is = 0.08266364124671453\n",
      "Initial Cost on Val dataset for this epoch 262 = 0.08266364124671453\n",
      "learning rate for this epoch =  0.37283436566848754\n",
      "Error on this batch = 0.041893089048715616\n",
      "Error on this batch = 0.07045929746412759\n",
      "Cost on val dataset after 263 epochs is = 0.08254198829837925\n",
      "Initial Cost on Val dataset for this epoch 263 = 0.08254198829837925\n",
      "learning rate for this epoch =  0.3724794539234301\n",
      "Error on this batch = 0.04171643833475043\n",
      "Error on this batch = 0.07026297412864713\n",
      "Cost on val dataset after 264 epochs is = 0.08242157729217602\n",
      "Initial Cost on Val dataset for this epoch 264 = 0.08242157729217602\n",
      "learning rate for this epoch =  0.3721262250255272\n",
      "Error on this batch = 0.04154208370931055\n",
      "Error on this batch = 0.07006674865218095\n",
      "Cost on val dataset after 265 epochs is = 0.08230239250163203\n",
      "Initial Cost on Val dataset for this epoch 265 = 0.08230239250163203\n",
      "learning rate for this epoch =  0.3717746646661645\n",
      "Error on this batch = 0.04136999384371191\n",
      "Error on this batch = 0.06987062395997921\n",
      "Cost on val dataset after 266 epochs is = 0.08218441940634486\n",
      "Initial Cost on Val dataset for this epoch 266 = 0.08218441940634486\n",
      "learning rate for this epoch =  0.37142475871179786\n",
      "Error on this batch = 0.04120013569141962\n",
      "Error on this batch = 0.06967460748161447\n",
      "Cost on val dataset after 267 epochs is = 0.08206764455589526\n",
      "Initial Cost on Val dataset for this epoch 267 = 0.08206764455589526\n",
      "learning rate for this epoch =  0.37107649320116404\n",
      "Error on this batch = 0.04103247463120084\n",
      "Error on this batch = 0.06947871070938953\n",
      "Cost on val dataset after 268 epochs is = 0.08195205543213827\n",
      "Initial Cost on Val dataset for this epoch 268 = 0.08195205543213827\n",
      "learning rate for this epoch =  0.3707298543425433\n",
      "Error on this batch = 0.040866974612630926\n",
      "Error on this batch = 0.0692829487286309\n",
      "Cost on val dataset after 269 epochs is = 0.0818376403173082\n",
      "Initial Cost on Val dataset for this epoch 269 = 0.0818376403173082\n",
      "learning rate for this epoch =  0.3703848285110782\n",
      "Error on this batch = 0.04070359830161955\n",
      "Error on this batch = 0.06908733974436673\n",
      "Cost on val dataset after 270 epochs is = 0.08172438817308504\n",
      "Initial Cost on Val dataset for this epoch 270 = 0.08172438817308504\n",
      "learning rate for this epoch =  0.3700414022461427\n",
      "Error on this batch = 0.04054230722464393\n",
      "Error on this batch = 0.0688919046241018\n",
      "Cost on val dataset after 271 epochs is = 0.08161228853363374\n",
      "Initial Cost on Val dataset for this epoch 271 = 0.08161228853363374\n",
      "learning rate for this epoch =  0.3696995622487631\n",
      "Error on this batch = 0.04038306191117524\n",
      "Error on this batch = 0.0686966664711933\n",
      "Cost on val dataset after 272 epochs is = 0.08150133141383185\n",
      "Initial Cost on Val dataset for this epoch 272 = 0.08150133141383185\n",
      "learning rate for this epoch =  0.3693592953790893\n",
      "Error on this batch = 0.040225822034331254\n",
      "Error on this batch = 0.06850165023830186\n",
      "Cost on val dataset after 273 epochs is = 0.081391507232525\n",
      "Initial Cost on Val dataset for this epoch 273 = 0.081391507232525\n",
      "learning rate for this epoch =  0.3690205886539131\n",
      "Error on this batch = 0.04007054655008659\n",
      "Error on this batch = 0.0683068823859596\n",
      "Cost on val dataset after 274 epochs is = 0.08128280674969891\n",
      "Initial Cost on Val dataset for this epoch 274 = 0.08128280674969891\n",
      "learning rate for this epoch =  0.3686834292442363\n",
      "Error on this batch = 0.039917193835448644\n",
      "Error on this batch = 0.06811239058767588\n",
      "Cost on val dataset after 275 epochs is = 0.0811752210158846\n",
      "Initial Cost on Val dataset for this epoch 275 = 0.0811752210158846\n",
      "learning rate for this epoch =  0.36834780447288357\n",
      "Error on this batch = 0.03976572182591002\n",
      "Error on this batch = 0.06791820348025958\n",
      "Cost on val dataset after 276 epochs is = 0.08106874133184445\n",
      "Initial Cost on Val dataset for this epoch 276 = 0.08106874133184445\n",
      "learning rate for this epoch =  0.3680137018121613\n",
      "Error on this batch = 0.039616088152265964\n",
      "Error on this batch = 0.067724350456129\n",
      "Cost on val dataset after 277 epochs is = 0.08096335921654471\n",
      "Initial Cost on Val dataset for this epoch 277 = 0.08096335921654471\n",
      "learning rate for this epoch =  0.3676811088815615\n",
      "Error on this batch = 0.03946825027658836\n",
      "Error on this batch = 0.06753086149319808\n",
      "Cost on val dataset after 278 epochs is = 0.08085906638152776\n",
      "Initial Cost on Val dataset for this epoch 278 = 0.08085906638152776\n",
      "learning rate for this epoch =  0.3673500134455082\n",
      "Error on this batch = 0.03932216562682647\n",
      "Error on this batch = 0.0673377670173341\n",
      "Cost on val dataset after 279 epochs is = 0.08075585470999577\n",
      "Initial Cost on Val dataset for this epoch 279 = 0.08075585470999577\n",
      "learning rate for this epoch =  0.36702040341114717\n",
      "Error on this batch = 0.039177791729199545\n",
      "Error on this batch = 0.06714509779223077\n",
      "Cost on val dataset after 280 epochs is = 0.08065371623916001\n",
      "Initial Cost on Val dataset for this epoch 280 = 0.08065371623916001\n",
      "learning rate for this epoch =  0.3666922668261758\n",
      "Error on this batch = 0.039035086337294855\n",
      "Error on this batch = 0.06695288483170718\n",
      "Cost on val dataset after 281 epochs is = 0.08055264314466225\n",
      "Initial Cost on Val dataset for this epoch 281 = 0.08055264314466225\n",
      "learning rate for this epoch =  0.3663655918767155\n",
      "Error on this batch = 0.038894007556608316\n",
      "Error on this batch = 0.06676115932981351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 282 epochs is = 0.08045262772612015\n",
      "Initial Cost on Val dataset for this epoch 282 = 0.08045262772612015\n",
      "learning rate for this epoch =  0.3660403668852222\n",
      "Error on this batch = 0.03875451396318435\n",
      "Error on this batch = 0.06656995260461368\n",
      "Cost on val dataset after 283 epochs is = 0.0803536623930723\n",
      "Initial Cost on Val dataset for this epoch 283 = 0.0803536623930723\n",
      "learning rate for this epoch =  0.3657165803084363\n",
      "Error on this batch = 0.03861656471502746\n",
      "Error on this batch = 0.06637929605205667\n",
      "Cost on val dataset after 284 epochs is = 0.08025573965079848\n",
      "Initial Cost on Val dataset for this epoch 284 = 0.08025573965079848\n",
      "learning rate for this epoch =  0.36539422073537026\n",
      "Error on this batch = 0.03848011965506858\n",
      "Error on this batch = 0.06618922110689762\n",
      "Cost on val dataset after 285 epochs is = 0.08015885208566587\n",
      "Initial Cost on Val dataset for this epoch 285 = 0.08015885208566587\n",
      "learning rate for this epoch =  0.36507327688533403\n",
      "Error on this batch = 0.03834513940465935\n",
      "Error on this batch = 0.06599975920815228\n",
      "Cost on val dataset after 286 epochs is = 0.08006299234980394\n",
      "Initial Cost on Val dataset for this epoch 286 = 0.08006299234980394\n",
      "learning rate for this epoch =  0.3647537376059957\n",
      "Error on this batch = 0.03821158544682008\n",
      "Error on this batch = 0.06581094176704934\n",
      "Cost on val dataset after 287 epochs is = 0.07996815314504217\n",
      "Initial Cost on Val dataset for this epoch 287 = 0.07996815314504217\n",
      "learning rate for this epoch =  0.3644355918714786\n",
      "Error on this batch = 0.03807942019875496\n",
      "Error on this batch = 0.06562280013587092\n",
      "Cost on val dataset after 288 epochs is = 0.07987432720615854\n",
      "Initial Cost on Val dataset for this epoch 288 = 0.07987432720615854\n",
      "learning rate for this epoch =  0.36411882878049256\n",
      "Error on this batch = 0.037948607073450845\n",
      "Error on this batch = 0.0654353655764403\n",
      "Cost on val dataset after 289 epochs is = 0.07978150728358416\n",
      "Initial Cost on Val dataset for this epoch 289 = 0.07978150728358416\n",
      "learning rate for this epoch =  0.36380343755449945\n",
      "Error on this batch = 0.037819110530467485\n",
      "Error on this batch = 0.06524866922732958\n",
      "Cost on val dataset after 290 epochs is = 0.07968968612579147\n",
      "Initial Cost on Val dataset for this epoch 290 = 0.07968968612579147\n",
      "learning rate for this epoch =  0.36348940753591197\n",
      "Error on this batch = 0.037690896116289486\n",
      "Error on this batch = 0.0650627420691212\n",
      "Cost on val dataset after 291 epochs is = 0.07959885646166044\n",
      "Initial Cost on Val dataset for this epoch 291 = 0.07959885646166044\n",
      "learning rate for this epoch =  0.3631767281863247\n",
      "Error on this batch = 0.03756393049482986\n",
      "Error on this batch = 0.06487761488727146\n",
      "Cost on val dataset after 292 epochs is = 0.07950901098316758\n",
      "Initial Cost on Val dataset for this epoch 292 = 0.07950901098316758\n",
      "learning rate for this epoch =  0.3628653890847774\n",
      "Error on this batch = 0.03743818146884347\n",
      "Error on this batch = 0.06469331823230333\n",
      "Cost on val dataset after 293 epochs is = 0.07942014232877742\n",
      "Initial Cost on Val dataset for this epoch 293 = 0.07942014232877742\n",
      "learning rate for this epoch =  0.36255537992604914\n",
      "Error on this batch = 0.03731361799312319\n",
      "Error on this batch = 0.0645098823771996\n",
      "Cost on val dataset after 294 epochs is = 0.07933224306793067\n",
      "Initial Cost on Val dataset for this epoch 294 = 0.07933224306793067\n",
      "learning rate for this epoch =  0.36224669051898317\n",
      "Error on this batch = 0.03719021018041783\n",
      "Error on this batch = 0.06432733727199144\n",
      "Cost on val dataset after 295 epochs is = 0.07924530568702258\n",
      "Initial Cost on Val dataset for this epoch 295 = 0.07924530568702258\n",
      "learning rate for this epoch =  0.3619393107848413\n",
      "Error on this batch = 0.03706792930103229\n",
      "Error on this batch = 0.06414571249564126\n",
      "Cost on val dataset after 296 epochs is = 0.07915932257724242\n",
      "Initial Cost on Val dataset for this epoch 296 = 0.07915932257724242\n",
      "learning rate for this epoch =  0.361633230755688\n",
      "Error on this batch = 0.03694674777705927\n",
      "Error on this batch = 0.0639650372054134\n",
      "Cost on val dataset after 297 epochs is = 0.07907428602460707\n",
      "Initial Cost on Val dataset for this epoch 297 = 0.07907428602460707\n",
      "learning rate for this epoch =  0.36132844057280267\n",
      "Error on this batch = 0.03682663917215719\n",
      "Error on this batch = 0.06378534008401371\n",
      "Cost on val dataset after 298 epochs is = 0.07899018820246595\n",
      "Initial Cost on Val dataset for this epoch 298 = 0.07899018820246595\n",
      "learning rate for this epoch =  0.36102493048512\n",
      "Error on this batch = 0.036707578177739245\n",
      "Error on this batch = 0.06360664928486312\n",
      "Cost on val dataset after 299 epochs is = 0.07890702116668505\n",
      "Initial Cost on Val dataset for this epoch 299 = 0.07890702116668505\n",
      "learning rate for this epoch =  0.3607226908476982\n",
      "Error on this batch = 0.036589540596382496\n",
      "Error on this batch = 0.06342899237595473\n",
      "Cost on val dataset after 300 epochs is = 0.07882477685363713\n",
      "Initial Cost on Val dataset for this epoch 300 = 0.07882477685363713\n",
      "learning rate for this epoch =  0.3604217121202132\n",
      "Error on this batch = 0.036472503323207985\n",
      "Error on this batch = 0.0632523962828269\n",
      "Cost on val dataset after 301 epochs is = 0.07874344708103546\n",
      "Initial Cost on Val dataset for this epoch 301 = 0.07874344708103546\n",
      "learning rate for this epoch =  0.3601219848654798\n",
      "Error on this batch = 0.036356444325924143\n",
      "Error on this batch = 0.06307688723126922\n",
      "Cost on val dataset after 302 epochs is = 0.07866302355155473\n",
      "Initial Cost on Val dataset for this epoch 302 = 0.07866302355155473\n",
      "learning rate for this epoch =  0.35982349974799877\n",
      "Error on this batch = 0.036241342624166055\n",
      "Error on this batch = 0.06290249069045828\n",
      "Cost on val dataset after 303 epochs is = 0.07858349785908725\n",
      "Initial Cost on Val dataset for this epoch 303 = 0.07858349785908725\n",
      "learning rate for this epoch =  0.35952624753252843\n",
      "Error on this batch = 0.03612717826869752\n",
      "Error on this batch = 0.06272923131729634\n",
      "Cost on val dataset after 304 epochs is = 0.07850486149738875\n",
      "Initial Cost on Val dataset for this epoch 304 = 0.07850486149738875\n",
      "learning rate for this epoch =  0.359230219082681\n",
      "Error on this batch = 0.03601393232096541\n",
      "Error on this batch = 0.06255713290278904\n",
      "Cost on val dataset after 305 epochs is = 0.07842710587077825\n",
      "Initial Cost on Val dataset for this epoch 305 = 0.07842710587077825\n",
      "learning rate for this epoch =  0.3589354053595442\n",
      "Error on this batch = 0.03590158683340021\n",
      "Error on this batch = 0.06238621832134753\n",
      "Cost on val dataset after 306 epochs is = 0.07835022230647469\n",
      "Initial Cost on Val dataset for this epoch 306 = 0.07835022230647469\n",
      "learning rate for this epoch =  0.35864179742032526\n",
      "Error on this batch = 0.035790124830732406\n",
      "Error on this batch = 0.062216509483922385\n",
      "Cost on val dataset after 307 epochs is = 0.07827420206807995\n",
      "Initial Cost on Val dataset for this epoch 307 = 0.07827420206807995\n",
      "learning rate for this epoch =  0.3583493864170186\n",
      "Error on this batch = 0.035679530292439754\n",
      "Error on this batch = 0.06204802729586685\n",
      "Cost on val dataset after 308 epochs is = 0.07819903636965604\n",
      "Initial Cost on Val dataset for this epoch 308 = 0.07819903636965604\n",
      "learning rate for this epoch =  0.35805816359509623\n",
      "Error on this batch = 0.03556978813624781\n",
      "Error on this batch = 0.06188079162037563\n",
      "Cost on val dataset after 309 epochs is = 0.07812471638979715\n",
      "Initial Cost on Val dataset for this epoch 309 = 0.07812471638979715\n",
      "learning rate for this epoch =  0.35776812029222116\n",
      "Error on this batch = 0.03546088420237771\n",
      "Error on this batch = 0.061714821248242395\n",
      "Cost on val dataset after 310 epochs is = 0.07805123328506701\n",
      "Initial Cost on Val dataset for this epoch 310 = 0.07805123328506701\n",
      "learning rate for this epoch =  0.3574792479369811\n",
      "Error on this batch = 0.03535280523798008\n",
      "Error on this batch = 0.06155013387451705\n",
      "Cost on val dataset after 311 epochs is = 0.07797857820216197\n",
      "Initial Cost on Val dataset for this epoch 311 = 0.07797857820216197\n",
      "learning rate for this epoch =  0.3571915380476448\n",
      "Error on this batch = 0.03524553888092124\n",
      "Error on this batch = 0.061386746082419584\n",
      "Cost on val dataset after 312 epochs is = 0.07790674228817773\n",
      "Initial Cost on Val dataset for this epoch 312 = 0.07790674228817773\n",
      "learning rate for this epoch =  0.3569049822309392\n",
      "Error on this batch = 0.03513907364182641\n",
      "Error on this batch = 0.06122467333457527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 313 epochs is = 0.07783571669840679\n",
      "Initial Cost on Val dataset for this epoch 313 = 0.07783571669840679\n",
      "learning rate for this epoch =  0.3566195721808463\n",
      "Error on this batch = 0.035033398883060354\n",
      "Error on this batch = 0.06106392997128521\n",
      "Cost on val dataset after 314 epochs is = 0.07776549260118264\n",
      "Initial Cost on Val dataset for this epoch 314 = 0.07776549260118264\n",
      "learning rate for this epoch =  0.3563352996774212\n",
      "Error on this batch = 0.03492850479317861\n",
      "Error on this batch = 0.06090452921514494\n",
      "Cost on val dataset after 315 epochs is = 0.07769606117942528\n",
      "Initial Cost on Val dataset for this epoch 315 = 0.07769606117942528\n",
      "learning rate for this epoch =  0.3560521565856293\n",
      "Error on this batch = 0.03482438235535696\n",
      "Error on this batch = 0.06074648318089509\n",
      "Cost on val dataset after 316 epochs is = 0.07762741362873424\n",
      "Initial Cost on Val dataset for this epoch 316 = 0.07762741362873424\n",
      "learning rate for this epoch =  0.3557701348542029\n",
      "Error on this batch = 0.03472102330843984\n",
      "Error on this batch = 0.06058980288896338\n",
      "Cost on val dataset after 317 epochs is = 0.07755954115212715\n",
      "Initial Cost on Val dataset for this epoch 317 = 0.07755954115212715\n",
      "learning rate for this epoch =  0.3554892265145167\n",
      "Error on this batch = 0.03461842009958036\n",
      "Error on this batch = 0.06043449828077886\n",
      "Cost on val dataset after 318 epochs is = 0.07749243495183178\n",
      "Initial Cost on Val dataset for this epoch 318 = 0.07749243495183178\n",
      "learning rate for this epoch =  0.35520942367948233\n",
      "Error on this batch = 0.034516565827989336\n",
      "Error on this batch = 0.060280578233660495\n",
      "Cost on val dataset after 319 epochs is = 0.07742608621889555\n",
      "Initial Cost on Val dataset for this epoch 319 = 0.07742608621889555\n",
      "learning rate for this epoch =  0.35493071854246033\n",
      "Error on this batch = 0.034415454180066946\n",
      "Error on this batch = 0.06012805057296437\n",
      "Cost on val dataset after 320 epochs is = 0.07736048612175853\n",
      "Initial Cost on Val dataset for this epoch 320 = 0.07736048612175853\n",
      "learning rate for this epoch =  0.35465310337619094\n",
      "Error on this batch = 0.03431507935711592\n",
      "Error on this batch = 0.05997692207928056\n",
      "Cost on val dataset after 321 epochs is = 0.07729562579530569\n",
      "Initial Cost on Val dataset for this epoch 321 = 0.07729562579530569\n",
      "learning rate for this epoch =  0.35437657053174126\n",
      "Error on this batch = 0.034215435997854864\n",
      "Error on this batch = 0.05982719848885751\n",
      "Cost on val dataset after 322 epochs is = 0.0772314963322184\n",
      "Initial Cost on Val dataset for this epoch 322 = 0.0772314963322184\n",
      "learning rate for this epoch =  0.3541011124374709\n",
      "Error on this batch = 0.03411651909894621\n",
      "Error on this batch = 0.05967888448614225\n",
      "Cost on val dataset after 323 epochs is = 0.07716808877861879\n",
      "Initial Cost on Val dataset for this epoch 323 = 0.07716808877861879\n",
      "learning rate for this epoch =  0.3538267215980131\n",
      "Error on this batch = 0.03401832393757716\n",
      "Error on this batch = 0.059531983688361656\n",
      "Cost on val dataset after 324 epochs is = 0.07710539413597275\n",
      "Initial Cost on Val dataset for this epoch 324 = 0.07710539413597275\n",
      "learning rate for this epoch =  0.3535533905932738\n",
      "Error on this batch = 0.0339208460006187\n",
      "Error on this batch = 0.05938649862339505\n",
      "Cost on val dataset after 325 epochs is = 0.07704340337092284\n",
      "Initial Cost on Val dataset for this epoch 325 = 0.07704340337092284\n",
      "learning rate for this epoch =  0.35328111207744545\n",
      "Error on this batch = 0.033824080924883926\n",
      "Error on this batch = 0.059242430703699576\n",
      "Cost on val dataset after 326 epochs is = 0.0769821074341217\n",
      "Initial Cost on Val dataset for this epoch 326 = 0.0769821074341217\n",
      "learning rate for this epoch =  0.35300987877803797\n",
      "Error on this batch = 0.033728024452402465\n",
      "Error on this batch = 0.05909978020057688\n",
      "Cost on val dataset after 327 epochs is = 0.07692149728823959\n",
      "Initial Cost on Val dataset for this epoch 327 = 0.07692149728823959\n",
      "learning rate for this epoch =  0.3527396834949245\n",
      "Error on this batch = 0.03363267240339255\n",
      "Error on this batch = 0.05895854622439079\n",
      "Cost on val dataset after 328 epochs is = 0.07686156394418561\n",
      "Initial Cost on Val dataset for this epoch 328 = 0.07686156394418561\n",
      "learning rate for this epoch =  0.3524705190994026\n",
      "Error on this batch = 0.03353802066783061\n",
      "Error on this batch = 0.05881872671720146\n",
      "Cost on val dataset after 329 epochs is = 0.07680229850335146\n",
      "Initial Cost on Val dataset for this epoch 329 = 0.07680229850335146\n",
      "learning rate for this epoch =  0.352202378533271\n",
      "Error on this batch = 0.03344406521438382\n",
      "Error on this batch = 0.05868031846443207\n",
      "Cost on val dataset after 330 epochs is = 0.07674369220254397\n",
      "Initial Cost on Val dataset for this epoch 330 = 0.07674369220254397\n",
      "learning rate for this epoch =  0.35193525480792004\n",
      "Error on this batch = 0.03335080211329376\n",
      "Error on this batch = 0.05854331713145489\n",
      "Cost on val dataset after 331 epochs is = 0.07668573645743587\n",
      "Initial Cost on Val dataset for this epoch 331 = 0.07668573645743587\n",
      "learning rate for this epoch =  0.35166914100343716\n",
      "Error on this batch = 0.03325822756793153\n",
      "Error on this batch = 0.05840771732932622\n",
      "Cost on val dataset after 332 epochs is = 0.0766284229000267\n",
      "Initial Cost on Val dataset for this epoch 332 = 0.0766284229000267\n",
      "learning rate for this epoch =  0.3514040302677271\n",
      "Error on this batch = 0.033166337948529065\n",
      "Error on this batch = 0.05827351271142783\n",
      "Cost on val dataset after 333 epochs is = 0.07657174340589536\n",
      "Initial Cost on Val dataset for this epoch 333 = 0.07657174340589536\n",
      "learning rate for this epoch =  0.3511399158156446\n",
      "Error on this batch = 0.033075129821265634\n",
      "Error on this batch = 0.058140696099764036\n",
      "Cost on val dataset after 334 epochs is = 0.07651569010795609\n",
      "Initial Cost on Val dataset for this epoch 334 = 0.07651569010795609\n",
      "learning rate for this epoch =  0.3508767909281421\n",
      "Error on this batch = 0.0329845999665295\n",
      "Error on this batch = 0.0580092596365208\n",
      "Cost on val dataset after 335 epochs is = 0.07646025539489011\n",
      "Initial Cost on Val dataset for this epoch 335 = 0.07646025539489011\n",
      "learning rate for this epoch =  0.35061464895142996\n",
      "Error on this batch = 0.03289474538166612\n",
      "Error on this batch = 0.057879194953678124\n",
      "Cost on val dataset after 336 epochs is = 0.07640543189420078\n",
      "Initial Cost on Val dataset for this epoch 336 = 0.07640543189420078\n",
      "learning rate for this epoch =  0.35035348329615007\n",
      "Error on this batch = 0.03280556326558523\n",
      "Error on this batch = 0.057750493351392235\n",
      "Cost on val dataset after 337 epochs is = 0.07635121244164952\n",
      "Initial Cost on Val dataset for this epoch 337 = 0.07635121244164952\n",
      "learning rate for this epoch =  0.35009328743656276\n",
      "Error on this batch = 0.03271705098484702\n",
      "Error on this batch = 0.05762314597482465\n",
      "Cost on val dataset after 338 epochs is = 0.07629759004039631\n",
      "Initial Cost on Val dataset for this epoch 338 = 0.07629759004039631\n",
      "learning rate for this epoch =  0.3498340549097454\n",
      "Error on this batch = 0.03262920602289439\n",
      "Error on this batch = 0.057497143979197876\n",
      "Cost on val dataset after 339 epochs is = 0.07624455781427374\n",
      "Initial Cost on Val dataset for this epoch 339 = 0.07624455781427374\n",
      "learning rate for this epoch =  0.3495757793148045\n",
      "Error on this batch = 0.032542025915636555\n",
      "Error on this batch = 0.05737247867402247\n",
      "Cost on val dataset after 340 epochs is = 0.07619210896014612\n",
      "Initial Cost on Val dataset for this epoch 340 = 0.07619210896014612\n",
      "learning rate for this epoch =  0.3493184543120991\n",
      "Error on this batch = 0.03245550817744749\n",
      "Error on this batch = 0.05724914163942325\n",
      "Cost on val dataset after 341 epochs is = 0.0761402367042303\n",
      "Initial Cost on Val dataset for this epoch 341 = 0.0761402367042303\n",
      "learning rate for this epoch =  0.34906207362247693\n",
      "Error on this batch = 0.032369650221804165\n",
      "Error on this batch = 0.0571271248099537\n",
      "Cost on val dataset after 342 epochs is = 0.07608893426666526\n",
      "Initial Cost on Val dataset for this epoch 342 = 0.07608893426666526\n",
      "learning rate for this epoch =  0.3488066310265215\n",
      "Error on this batch = 0.03228444928036779\n",
      "Error on this batch = 0.05700642052386512\n",
      "Cost on val dataset after 343 epochs is = 0.07603819483764808\n",
      "Initial Cost on Val dataset for this epoch 343 = 0.07603819483764808\n",
      "learning rate for this epoch =  0.3485521203638112\n",
      "Error on this batch = 0.03219990232349925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.05688702153817074\n",
      "Cost on val dataset after 344 epochs is = 0.07598801156726837\n",
      "Initial Cost on Val dataset for this epoch 344 = 0.07598801156726837\n",
      "learning rate for this epoch =  0.34829853553219003\n",
      "Error on this batch = 0.03211600598422121\n",
      "Error on this batch = 0.05676892101177587\n",
      "Cost on val dataset after 345 epochs is = 0.07593837756991637\n",
      "Initial Cost on Val dataset for this epoch 345 = 0.07593837756991637\n",
      "learning rate for this epoch =  0.3480458704870483\n",
      "Error on this batch = 0.03203275648669414\n",
      "Error on this batch = 0.056652112460307456\n",
      "Cost on val dataset after 346 epochs is = 0.07588928594293122\n",
      "Initial Cost on Val dataset for this epoch 346 = 0.07588928594293122\n",
      "learning rate for this epoch =  0.347794119240616\n",
      "Error on this batch = 0.03195014957952002\n",
      "Error on this batch = 0.05653658968702986\n",
      "Cost on val dataset after 347 epochs is = 0.07584072979806791\n",
      "Initial Cost on Val dataset for this epoch 347 = 0.07584072979806791\n",
      "learning rate for this epoch =  0.3475432758612649\n",
      "Error on this batch = 0.031868180473719664\n",
      "Error on this batch = 0.05642234669443646\n",
      "Cost on val dataset after 348 epochs is = 0.07579270230342976\n",
      "Initial Cost on Val dataset for this epoch 348 = 0.07579270230342976\n",
      "learning rate for this epoch =  0.34729333447282273\n",
      "Error on this batch = 0.03178684378509388\n",
      "Error on this batch = 0.05630937758085434\n",
      "Cost on val dataset after 349 epochs is = 0.07574519673275006\n",
      "Initial Cost on Val dataset for this epoch 349 = 0.07574519673275006\n",
      "learning rate for this epoch =  0.3470442892538971\n",
      "Error on this batch = 0.03170613348087144\n",
      "Error on this batch = 0.05619767642583501\n",
      "Cost on val dataset after 350 epochs is = 0.0756982065182991\n",
      "Initial Cost on Val dataset for this epoch 350 = 0.0756982065182991\n",
      "learning rate for this epoch =  0.34679613443720936\n",
      "Error on this batch = 0.03162604283103344\n",
      "Error on this batch = 0.056087237167369894\n",
      "Cost on val dataset after 351 epochs is = 0.07565172530324152\n",
      "Initial Cost on Val dataset for this epoch 351 = 0.07565172530324152\n",
      "learning rate for this epoch =  0.3465488643089389\n",
      "Error on this batch = 0.03154656436542762\n",
      "Error on this batch = 0.05597805347321526\n",
      "Cost on val dataset after 352 epochs is = 0.07560574698897106\n",
      "Initial Cost on Val dataset for this epoch 352 = 0.07560574698897106\n",
      "learning rate for this epoch =  0.34630247320807694\n",
      "Error on this batch = 0.03146768983865819\n",
      "Error on this batch = 0.05587011860796874\n",
      "Cost on val dataset after 353 epochs is = 0.0755602657728355\n",
      "Initial Cost on Val dataset for this epoch 353 = 0.0755602657728355\n",
      "learning rate for this epoch =  0.34605695552579\n",
      "Error on this batch = 0.03138941020565499\n",
      "Error on this batch = 0.05576342529713005\n",
      "Cost on val dataset after 354 epochs is = 0.07551527617177331\n",
      "Initial Cost on Val dataset for this epoch 354 = 0.07551527617177331\n",
      "learning rate for this epoch =  0.3458123057047929\n",
      "Error on this batch = 0.03131171561164069\n",
      "Error on this batch = 0.05565796558929839\n",
      "Cost on val dataset after 355 epochs is = 0.07547077302777774\n",
      "Initial Cost on Val dataset for this epoch 355 = 0.07547077302777774\n",
      "learning rate for this epoch =  0.3455685182387307\n",
      "Error on this batch = 0.031234595400755263\n",
      "Error on this batch = 0.055553730717973614\n",
      "Cost on val dataset after 356 epochs is = 0.0754267514918425\n",
      "Initial Cost on Val dataset for this epoch 356 = 0.0754267514918425\n",
      "learning rate for this epoch =  0.3453255876715705\n",
      "Error on this batch = 0.03115803814765605\n",
      "Error on this batch = 0.055450710965164254\n",
      "Cost on val dataset after 357 epochs is = 0.07538320698416555\n",
      "Initial Cost on Val dataset for this epoch 357 = 0.07538320698416555\n",
      "learning rate for this epoch =  0.3450835085970013\n",
      "Error on this batch = 0.031082031715784834\n",
      "Error on this batch = 0.05534889553012588\n",
      "Cost on val dataset after 358 epochs is = 0.07534013512988272\n",
      "Initial Cost on Val dataset for this epoch 358 = 0.07534013512988272\n",
      "learning rate for this epoch =  0.34484227565784364\n",
      "Error on this batch = 0.031006563344519993\n",
      "Error on this batch = 0.05524827240795312\n",
      "Cost on val dataset after 359 epochs is = 0.07529753167140145\n",
      "Initial Cost on Val dataset for this epoch 359 = 0.07529753167140145\n",
      "learning rate for this epoch =  0.34460188354546667\n",
      "Error on this batch = 0.03093161976507094\n",
      "Error on this batch = 0.05514882828423796\n",
      "Cost on val dataset after 360 epochs is = 0.07525539236035192\n",
      "Initial Cost on Val dataset for this epoch 360 = 0.07525539236035192\n",
      "learning rate for this epoch =  0.34436232699921493\n",
      "Error on this batch = 0.030857187341876147\n",
      "Error on this batch = 0.055050548453318346\n",
      "Cost on val dataset after 361 epochs is = 0.07521371283407008\n",
      "Initial Cost on Val dataset for this epoch 361 = 0.07521371283407008\n",
      "learning rate for this epoch =  0.3441236008058426\n",
      "Error on this batch = 0.030783252232834128\n",
      "Error on this batch = 0.05495341676845009\n",
      "Cost on val dataset after 362 epochs is = 0.07517248848315135\n",
      "Initial Cost on Val dataset for this epoch 362 = 0.07517248848315135\n",
      "learning rate for this epoch =  0.34388569979895683\n",
      "Error on this batch = 0.030709800558561835\n",
      "Error on this batch = 0.05485741563221238\n",
      "Cost on val dataset after 363 epochs is = 0.0751317143177854\n",
      "Initial Cost on Val dataset for this epoch 363 = 0.0751317143177854\n",
      "learning rate for this epoch =  0.3436486188584679\n",
      "Error on this batch = 0.030636818568787715\n",
      "Error on this batch = 0.05476252603431814\n",
      "Cost on val dataset after 364 epochs is = 0.07509138484118655\n",
      "Initial Cost on Val dataset for this epoch 364 = 0.07509138484118655\n",
      "learning rate for this epoch =  0.3434123529100486\n",
      "Error on this batch = 0.03056429279360626\n",
      "Error on this batch = 0.054668727641607795\n",
      "Cost on val dataset after 365 epochs is = 0.07505149393844185\n",
      "Initial Cost on Val dataset for this epoch 365 = 0.07505149393844185\n",
      "learning rate for this epoch =  0.3431768969246008\n",
      "Error on this batch = 0.03049221016896146\n",
      "Error on this batch = 0.054575998941421164\n",
      "Cost on val dataset after 366 epochs is = 0.07501203478852599\n",
      "Initial Cost on Val dataset for this epoch 366 = 0.07501203478852599\n",
      "learning rate for this epoch =  0.3429422459177292\n",
      "Error on this batch = 0.030420558129180337\n",
      "Error on this batch = 0.05448431743510152\n",
      "Cost on val dataset after 367 epochs is = 0.07497299980609429\n",
      "Initial Cost on Val dataset for this epoch 367 = 0.07497299980609429\n",
      "learning rate for this epoch =  0.3427083949492237\n",
      "Error on this batch = 0.030349324663904415\n",
      "Error on this batch = 0.05439365987368051\n",
      "Cost on val dataset after 368 epochs is = 0.0749343806179781\n",
      "Initial Cost on Val dataset for this epoch 368 = 0.0749343806179781\n",
      "learning rate for this epoch =  0.34247533912254846\n",
      "Error on this batch = 0.030278498341312562\n",
      "Error on this batch = 0.05430400252358046\n",
      "Cost on val dataset after 369 epochs is = 0.07489616807708431\n",
      "Initial Cost on Val dataset for this epoch 369 = 0.07489616807708431\n",
      "learning rate for this epoch =  0.342243073584338\n",
      "Error on this batch = 0.030208068303070785\n",
      "Error on this batch = 0.05421532144723063\n",
      "Cost on val dataset after 370 epochs is = 0.07485835231374799\n",
      "Initial Cost on Val dataset for this epoch 370 = 0.07485835231374799\n",
      "learning rate for this epoch =  0.3420115935239011\n",
      "Error on this batch = 0.030138024238347546\n",
      "Error on this batch = 0.05412759278238385\n",
      "Cost on val dataset after 371 epochs is = 0.0748209228217255\n",
      "Initial Cost on Val dataset for this epoch 371 = 0.0748209228217255\n",
      "learning rate for this epoch =  0.34178089417273183\n",
      "Error on this batch = 0.030068356344407403\n",
      "Error on this batch = 0.05404079300485172\n",
      "Cost on val dataset after 372 epochs is = 0.0747838685732905\n",
      "Initial Cost on Val dataset for this epoch 372 = 0.0747838685732905\n",
      "learning rate for this epoch =  0.34155097080402635\n",
      "Error on this batch = 0.029999055280147697\n",
      "Error on this batch = 0.05395489916210879\n",
      "Cost on val dataset after 373 epochs is = 0.07474717815569977\n",
      "Initial Cost on Val dataset for this epoch 373 = 0.07474717815569977\n",
      "learning rate for this epoch =  0.3413218187322076\n",
      "Error on this batch = 0.02993011211713445\n",
      "Error on this batch = 0.05386988906915875\n",
      "Cost on val dataset after 374 epochs is = 0.07471083991995578\n",
      "Initial Cost on Val dataset for this epoch 374 = 0.07471083991995578\n",
      "learning rate for this epoch =  0.3410934333124567\n",
      "Error on this batch = 0.02986151829086528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.053785741462434804\n",
      "Cost on val dataset after 375 epochs is = 0.07467484213247692\n",
      "Initial Cost on Val dataset for this epoch 375 = 0.07467484213247692\n",
      "learning rate for this epoch =  0.34086580994024984\n",
      "Error on this batch = 0.029793265553567986\n",
      "Error on this batch = 0.05370243611157263\n",
      "Cost on val dataset after 376 epochs is = 0.07463917312096059\n",
      "Initial Cost on Val dataset for this epoch 376 = 0.07463917312096059\n",
      "learning rate for this epoch =  0.34063894405090306\n",
      "Error on this batch = 0.02972534592898753\n",
      "Error on this batch = 0.053619953892102536\n",
      "Cost on val dataset after 377 epochs is = 0.07460382140718484\n",
      "Initial Cost on Val dataset for this epoch 377 = 0.07460382140718484\n",
      "learning rate for this epoch =  0.3404128311191223\n",
      "Error on this batch = 0.02965775166925877\n",
      "Error on this batch = 0.05353827682418338\n",
      "Cost on val dataset after 378 epochs is = 0.07456877582142948\n",
      "Initial Cost on Val dataset for this epoch 378 = 0.07456877582142948\n",
      "learning rate for this epoch =  0.3401874666585601\n",
      "Error on this batch = 0.029590475213934847\n",
      "Error on this batch = 0.05345738808344257\n",
      "Cost on val dataset after 379 epochs is = 0.0745340255952858\n",
      "Initial Cost on Val dataset for this epoch 379 = 0.0745340255952858\n",
      "learning rate for this epoch =  0.3399628462213785\n",
      "Error on this batch = 0.029523509151354956\n",
      "Error on this batch = 0.05337727198998501\n",
      "Cost on val dataset after 380 epochs is = 0.07449956043158686\n",
      "Initial Cost on Val dataset for this epoch 380 = 0.07449956043158686\n",
      "learning rate for this epoch =  0.3397389653978181\n",
      "Error on this batch = 0.029456846182654674\n",
      "Error on this batch = 0.053297913980983457\n",
      "Cost on val dataset after 381 epochs is = 0.07446537055184495\n",
      "Initial Cost on Val dataset for this epoch 381 = 0.07446537055184495\n",
      "learning rate for this epoch =  0.3395158198157724\n",
      "Error on this batch = 0.029390479088777274\n",
      "Error on this batch = 0.05321930057126783\n",
      "Cost on val dataset after 382 epochs is = 0.07443144672283214\n",
      "Initial Cost on Val dataset for this epoch 382 = 0.07443144672283214\n",
      "learning rate for this epoch =  0.3392934051403688\n",
      "Error on this batch = 0.02932440070082314\n",
      "Error on this batch = 0.05314141930525883\n",
      "Cost on val dataset after 383 epochs is = 0.07439778026477684\n",
      "Initial Cost on Val dataset for this epoch 383 = 0.07439778026477684\n",
      "learning rate for this epoch =  0.33907171707355527\n",
      "Error on this batch = 0.029258603873997133\n",
      "Error on this batch = 0.053064258702625565\n",
      "Cost on val dataset after 384 epochs is = 0.07436436304411127\n",
      "Initial Cost on Val dataset for this epoch 384 = 0.07436436304411127\n",
      "learning rate for this epoch =  0.33885075135369186\n",
      "Error on this batch = 0.029193081465313676\n",
      "Error on this batch = 0.05298780819929535\n",
      "Cost on val dataset after 385 epochs is = 0.07433118745386691\n",
      "Initial Cost on Val dataset for this epoch 385 = 0.07433118745386691\n",
      "learning rate for this epoch =  0.3386305037551487\n",
      "Error on this batch = 0.02912782631512786\n",
      "Error on this batch = 0.05291205808494429\n",
      "Cost on val dataset after 386 epochs is = 0.07429824638475321\n",
      "Initial Cost on Val dataset for this epoch 386 = 0.07429824638475321\n",
      "learning rate for this epoch =  0.3384109700879091\n",
      "Error on this batch = 0.02906283123249775\n",
      "Error on this batch = 0.0528369994378321\n",
      "Cost on val dataset after 387 epochs is = 0.0742655331897477\n",
      "Initial Cost on Val dataset for this epoch 387 = 0.0742655331897477\n",
      "learning rate for this epoch =  0.33819214619717813\n",
      "Error on this batch = 0.028998088984353864\n",
      "Error on this batch = 0.052762624057766154\n",
      "Cost on val dataset after 388 epochs is = 0.0742330416447293\n",
      "Initial Cost on Val dataset for this epoch 388 = 0.0742330416447293\n",
      "learning rate for this epoch =  0.3379740279629962\n",
      "Error on this batch = 0.02893359228846049\n",
      "Error on this batch = 0.05268892439802439\n",
      "Cost on val dataset after 389 epochs is = 0.07420076590735165\n",
      "Initial Cost on Val dataset for this epoch 389 = 0.07420076590735165\n",
      "learning rate for this epoch =  0.33775661129985834\n",
      "Error on this batch = 0.028869333810183574\n",
      "Error on this batch = 0.05261589349716969\n",
      "Cost on val dataset after 390 epochs is = 0.07416870047600936\n",
      "Initial Cost on Val dataset for this epoch 390 = 0.07416870047600936\n",
      "learning rate for this epoch =  0.3375398921563383\n",
      "Error on this batch = 0.028805306163124593\n",
      "Error on this batch = 0.05254352491179076\n",
      "Cost on val dataset after 391 epochs is = 0.0741368401504173\n",
      "Initial Cost on Val dataset for this epoch 391 = 0.0741368401504173\n",
      "learning rate for this epoch =  0.3373238665147177\n",
      "Error on this batch = 0.028741501913724973\n",
      "Error on this batch = 0.052471812651263806\n",
      "Cost on val dataset after 392 epochs is = 0.07410517999501541\n",
      "Initial Cost on Val dataset for this epoch 392 = 0.07410517999501541\n",
      "learning rate for this epoch =  0.33710853039062016\n",
      "Error on this batch = 0.028677913589976768\n",
      "Error on this batch = 0.05240075111561387\n",
      "Cost on val dataset after 393 epochs is = 0.07407371530612927\n",
      "Initial Cost on Val dataset for this epoch 393 = 0.07407371530612927\n",
      "learning rate for this epoch =  0.3368938798326509\n",
      "Error on this batch = 0.02861453369438733\n",
      "Error on this batch = 0.05233033503745221\n",
      "Cost on val dataset after 394 epochs is = 0.07404244158356732\n",
      "Initial Cost on Val dataset for this epoch 394 = 0.07404244158356732\n",
      "learning rate for this epoch =  0.33667991092203975\n",
      "Error on this batch = 0.028551354721330333\n",
      "Error on this batch = 0.052260559428775506\n",
      "Cost on val dataset after 395 epochs is = 0.07401135450711101\n",
      "Initial Cost on Val dataset for this epoch 395 = 0.07401135450711101\n",
      "learning rate for this epoch =  0.33646661977229064\n",
      "Error on this batch = 0.02848836917887202\n",
      "Error on this batch = 0.05219141953314724\n",
      "Cost on val dataset after 396 epochs is = 0.07398044991815954\n",
      "Initial Cost on Val dataset for this epoch 396 = 0.07398044991815954\n",
      "learning rate for this epoch =  0.33625400252883436\n",
      "Error on this batch = 0.028425569615091347\n",
      "Error on this batch = 0.05212291078345888\n",
      "Cost on val dataset after 397 epochs is = 0.07394972380661753\n",
      "Initial Cost on Val dataset for this epoch 397 = 0.07394972380661753\n",
      "learning rate for this epoch =  0.33604205536868675\n",
      "Error on this batch = 0.02836294864882092\n",
      "Error on this batch = 0.05205502876512085\n",
      "Cost on val dataset after 398 epochs is = 0.07391917230296643\n",
      "Initial Cost on Val dataset for this epoch 398 = 0.07391917230296643\n",
      "learning rate for this epoch =  0.3358307745001108\n",
      "Error on this batch = 0.028300499004629966\n",
      "Error on this batch = 0.05198776918418254\n",
      "Cost on val dataset after 399 epochs is = 0.07388879167533331\n",
      "Initial Cost on Val dataset for this epoch 399 = 0.07388879167533331\n",
      "learning rate for this epoch =  0.3356201561622838\n",
      "Error on this batch = 0.02823821355176123\n",
      "Error on this batch = 0.051921127839564075\n",
      "Cost on val dataset after 400 epochs is = 0.07385857833126766\n",
      "Initial Cost on Val dataset for this epoch 400 = 0.07385857833126766\n",
      "learning rate for this epoch =  0.33541019662496846\n",
      "Error on this batch = 0.028176085346630356\n",
      "Error on this batch = 0.05185510059831952\n",
      "Cost on val dataset after 401 epochs is = 0.0738285288238576\n",
      "Initial Cost on Val dataset for this epoch 401 = 0.0738285288238576\n",
      "learning rate for this epoch =  0.33520089218818844\n",
      "Error on this batch = 0.02811410767841072\n",
      "Error on this batch = 0.051789683372666546\n",
      "Cost on val dataset after 402 epochs is = 0.07379863986176327\n",
      "Initial Cost on Val dataset for this epoch 402 = 0.07379863986176327\n",
      "learning rate for this epoch =  0.33499223918190807\n",
      "Error on this batch = 0.02805227411716821\n",
      "Error on this batch = 0.05172487209742022\n",
      "Cost on val dataset after 403 epochs is = 0.07376890832271947\n",
      "Initial Cost on Val dataset for this epoch 403 = 0.07376890832271947\n",
      "learning rate for this epoch =  0.3347842339657164\n",
      "Error on this batch = 0.02799057856398423\n",
      "Error on this batch = 0.05166066270646597\n",
      "Cost on val dataset after 404 epochs is = 0.07373933127006135\n",
      "Initial Cost on Val dataset for this epoch 404 = 0.07373933127006135\n",
      "learning rate for this epoch =  0.3345768729285152\n",
      "Error on this batch = 0.027929015302516517\n",
      "Error on this batch = 0.05159705110698914\n",
      "Cost on val dataset after 405 epochs is = 0.07370990597185863\n",
      "Initial Cost on Val dataset for this epoch 405 = 0.07370990597185863\n",
      "learning rate for this epoch =  0.334370152488211\n",
      "Error on this batch = 0.027867579051492685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.051534033150336944\n",
      "Cost on val dataset after 406 epochs is = 0.07368062992229875\n",
      "Initial Cost on Val dataset for this epoch 406 = 0.07368062992229875\n",
      "learning rate for this epoch =  0.3341640690914115\n",
      "Error on this batch = 0.027806265017704723\n",
      "Error on this batch = 0.051471604598602554\n",
      "Cost on val dataset after 407 epochs is = 0.07365150086503774\n",
      "Initial Cost on Val dataset for this epoch 407 = 0.07365150086503774\n",
      "learning rate for this epoch =  0.33395861921312525\n",
      "Error on this batch = 0.027745068949160626\n",
      "Error on this batch = 0.051409761086268546\n",
      "Cost on val dataset after 408 epochs is = 0.07362251681832642\n",
      "Initial Cost on Val dataset for this epoch 408 = 0.07362251681832642\n",
      "learning rate for this epoch =  0.33375379935646554\n",
      "Error on this batch = 0.027683987188136267\n",
      "Error on this batch = 0.051348498076511984\n",
      "Cost on val dataset after 409 epochs is = 0.07359367610181206\n",
      "Initial Cost on Val dataset for this epoch 409 = 0.07359367610181206\n",
      "learning rate for this epoch =  0.3335496060523584\n",
      "Error on this batch = 0.027623016723931634\n",
      "Error on this batch = 0.051287810812035706\n",
      "Cost on val dataset after 410 epochs is = 0.07356497736499397\n",
      "Initial Cost on Val dataset for this epoch 410 = 0.07356497736499397\n",
      "learning rate for this epoch =  0.33334603585925365\n",
      "Error on this batch = 0.027562155245150786\n",
      "Error on this batch = 0.05122769426054884\n",
      "Cost on val dataset after 411 epochs is = 0.07353641961735978\n",
      "Initial Cost on Val dataset for this epoch 411 = 0.07353641961735978\n",
      "learning rate for this epoch =  0.33314308536284043\n",
      "Error on this batch = 0.02750140119126443\n",
      "Error on this batch = 0.05116814305527281\n",
      "Cost on val dataset after 412 epochs is = 0.07350800226022679\n",
      "Initial Cost on Val dataset for this epoch 412 = 0.07350800226022679\n",
      "learning rate for this epoch =  0.3329407511757655\n",
      "Error on this batch = 0.02744075380305875\n",
      "Error on this batch = 0.05110915143111415\n",
      "Cost on val dataset after 413 epochs is = 0.07347972512024033\n",
      "Initial Cost on Val dataset for this epoch 413 = 0.07347972512024033\n",
      "learning rate for this epoch =  0.33273902993735593\n",
      "Error on this batch = 0.027380213171300932\n",
      "Error on this batch = 0.05105071315744592\n",
      "Cost on val dataset after 414 epochs is = 0.07345158848431463\n",
      "Initial Cost on Val dataset for this epoch 414 = 0.07345158848431463\n",
      "learning rate for this epoch =  0.33253791831334495\n",
      "Error on this batch = 0.027319780282551547\n",
      "Error on this batch = 0.050992821468810005\n",
      "Cost on val dataset after 415 epochs is = 0.07342359313552775\n",
      "Initial Cost on Val dataset for this epoch 415 = 0.07342359313552775\n",
      "learning rate for this epoch =  0.33233741299560093\n",
      "Error on this batch = 0.02725945706052404\n",
      "Error on this batch = 0.050935468995323946\n",
      "Cost on val dataset after 416 epochs is = 0.07339574038908651\n",
      "Initial Cost on Val dataset for this epoch 416 = 0.07339574038908651\n",
      "learning rate for this epoch =  0.33213751070186054\n",
      "Error on this batch = 0.027199246400748583\n",
      "Error on this batch = 0.05087864769518676\n",
      "Cost on val dataset after 417 epochs is = 0.07336803212696097\n",
      "Initial Cost on Val dataset for this epoch 417 = 0.07336803212696097\n",
      "learning rate for this epoch =  0.3319382081754647\n",
      "Error on this batch = 0.027139152195575784\n",
      "Error on this batch = 0.05082234879244086\n",
      "Cost on val dataset after 418 epochs is = 0.07334047082916789\n",
      "Initial Cost on Val dataset for this epoch 418 = 0.07334047082916789\n",
      "learning rate for this epoch =  0.331739502185098\n",
      "Error on this batch = 0.027079179345819566\n",
      "Error on this batch = 0.05076656272405793\n",
      "Cost on val dataset after 419 epochs is = 0.07331305959899258\n",
      "Initial Cost on Val dataset for this epoch 419 = 0.07331305959899258\n",
      "learning rate for this epoch =  0.33154138952453144\n",
      "Error on this batch = 0.027019333754676543\n",
      "Error on this batch = 0.050711279101430654\n",
      "Cost on val dataset after 420 epochs is = 0.07328580217874686\n",
      "Initial Cost on Val dataset for this epoch 420 = 0.07328580217874686\n",
      "learning rate for this epoch =  0.3313438670123683\n",
      "Error on this batch = 0.026959622299098283\n",
      "Error on this batch = 0.05065648669237083\n",
      "Cost on val dataset after 421 epochs is = 0.07325870295205865\n",
      "Initial Cost on Val dataset for this epoch 421 = 0.07325870295205865\n",
      "learning rate for this epoch =  0.3311469314917932\n",
      "Error on this batch = 0.026900052773679312\n",
      "Error on this batch = 0.05060217343057898\n",
      "Cost on val dataset after 422 epochs is = 0.07323176692829703\n",
      "Initial Cost on Val dataset for this epoch 422 = 0.07323176692829703\n",
      "learning rate for this epoch =  0.3309505798303245\n",
      "Error on this batch = 0.02684063380252445\n",
      "Error on this batch = 0.050548326460040316\n",
      "Cost on val dataset after 423 epochs is = 0.07320499970469961\n",
      "Initial Cost on Val dataset for this epoch 423 = 0.07320499970469961\n",
      "learning rate for this epoch =  0.33075480891956943\n",
      "Error on this batch = 0.026781374715625052\n",
      "Error on this batch = 0.050494932221640615\n",
      "Cost on val dataset after 424 epochs is = 0.07317840740222814\n",
      "Initial Cost on Val dataset for this epoch 424 = 0.07317840740222814\n",
      "learning rate for this epoch =  0.33055961567498265\n",
      "Error on this batch = 0.026722285388115163\n",
      "Error on this batch = 0.050441976588195686\n",
      "Cost on val dataset after 425 epochs is = 0.07315199657225353\n",
      "Initial Cost on Val dataset for this epoch 425 = 0.07315199657225353\n",
      "learning rate for this epoch =  0.330364997035627\n",
      "Error on this batch = 0.026663376043408977\n",
      "Error on this batch = 0.05038944505180065\n",
      "Cost on val dataset after 426 epochs is = 0.07312577407292443\n",
      "Initial Cost on Val dataset for this epoch 426 = 0.07312577407292443\n",
      "learning rate for this epoch =  0.33017094996393853\n",
      "Error on this batch = 0.026604657024521923\n",
      "Error on this batch = 0.050337322963802916\n",
      "Cost on val dataset after 427 epochs is = 0.07309974691646456\n",
      "Initial Cost on Val dataset for this epoch 427 = 0.07309974691646456\n",
      "learning rate for this epoch =  0.32997747144549294\n",
      "Error on this batch = 0.026546138541558906\n",
      "Error on this batch = 0.050285595822869004\n",
      "Cost on val dataset after 428 epochs is = 0.07307392209151256\n",
      "Initial Cost on Val dataset for this epoch 428 = 0.07307392209151256\n",
      "learning rate for this epoch =  0.32978455848877636\n",
      "Error on this batch = 0.02648783040695831\n",
      "Error on this batch = 0.050234249600916776\n",
      "Cost on val dataset after 429 epochs is = 0.07304830636766389\n",
      "Initial Cost on Val dataset for this epoch 429 = 0.07304830636766389\n",
      "learning rate for this epoch =  0.3295922081249574\n",
      "Error on this batch = 0.026429741773028433\n",
      "Error on this batch = 0.050183271090791445\n",
      "Cost on val dataset after 430 epochs is = 0.07302290609218584\n",
      "Initial Cost on Val dataset for this epoch 430 = 0.07302290609218584\n",
      "learning rate for this epoch =  0.3294004174076632\n",
      "Error on this batch = 0.026371880888002436\n",
      "Error on this batch = 0.05013264825440083\n",
      "Cost on val dataset after 431 epochs is = 0.07299772699098714\n",
      "Initial Cost on Val dataset for this epoch 431 = 0.07299772699098714\n",
      "learning rate for this epoch =  0.3292091834127578\n",
      "Error on this batch = 0.026314254886780974\n",
      "Error on this batch = 0.05008237054661773\n",
      "Cost on val dataset after 432 epochs is = 0.07297277398690329\n",
      "Initial Cost on Val dataset for this epoch 432 = 0.07297277398690329\n",
      "learning rate for this epoch =  0.32901850323812315\n",
      "Error on this batch = 0.026256869630499526\n",
      "Error on this batch = 0.05003242918950797\n",
      "Cost on val dataset after 433 epochs is = 0.07294805104791323\n",
      "Initial Cost on Val dataset for this epoch 433 = 0.07294805104791323\n",
      "learning rate for this epoch =  0.3288283740034425\n",
      "Error on this batch = 0.026199729605181698\n",
      "Error on this batch = 0.04998281737388181\n",
      "Cost on val dataset after 434 epochs is = 0.07292356107596534\n",
      "Initial Cost on Val dataset for this epoch 434 = 0.07292356107596534\n",
      "learning rate for this epoch =  0.32863879284998726\n",
      "Error on this batch = 0.026142837884526732\n",
      "Error on this batch = 0.049933530370757664\n",
      "Cost on val dataset after 435 epochs is = 0.07289930584385014\n",
      "Initial Cost on Val dataset for this epoch 435 = 0.07289930584385014\n",
      "learning rate for this epoch =  0.32844975694040546\n",
      "Error on this batch = 0.026086196156121157\n",
      "Error on this batch = 0.049884565543400344\n",
      "Cost on val dataset after 436 epochs is = 0.07287528598344904\n",
      "Initial Cost on Val dataset for this epoch 436 = 0.07287528598344904\n",
      "learning rate for this epoch =  0.3282612634585134\n",
      "Error on this batch = 0.02602980480495848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04983592225996308\n",
      "Cost on val dataset after 437 epochs is = 0.07285150102429301\n",
      "Initial Cost on Val dataset for this epoch 437 = 0.07285150102429301\n",
      "learning rate for this epoch =  0.3280733096090895\n",
      "Error on this batch = 0.025973663043891735\n",
      "Error on this batch = 0.04978760171596053\n",
      "Cost on val dataset after 438 epochs is = 0.07282794947729822\n",
      "Initial Cost on Val dataset for this epoch 438 = 0.07282794947729822\n",
      "learning rate for this epoch =  0.32788589261767076\n",
      "Error on this batch = 0.025917769078043863\n",
      "Error on this batch = 0.04973960668344571\n",
      "Cost on val dataset after 439 epochs is = 0.07280462895532418\n",
      "Initial Cost on Val dataset for this epoch 439 = 0.07280462895532418\n",
      "learning rate for this epoch =  0.3276990097303519\n",
      "Error on this batch = 0.02586212028940614\n",
      "Error on this batch = 0.04969194120883499\n",
      "Cost on val dataset after 440 epochs is = 0.07278153632015034\n",
      "Initial Cost on Val dataset for this epoch 440 = 0.07278153632015034\n",
      "learning rate for this epoch =  0.3275126582135859\n",
      "Error on this batch = 0.025806713428665803\n",
      "Error on this batch = 0.04964461028337093\n",
      "Cost on val dataset after 441 epochs is = 0.07275866784469305\n",
      "Initial Cost on Val dataset for this epoch 441 = 0.07275866784469305\n",
      "learning rate for this epoch =  0.3273268353539886\n",
      "Error on this batch = 0.025751544803278483\n",
      "Error on this batch = 0.049597619509353666\n",
      "Cost on val dataset after 442 epochs is = 0.07273601937967585\n",
      "Initial Cost on Val dataset for this epoch 442 = 0.07273601937967585\n",
      "learning rate for this epoch =  0.3271415384581438\n",
      "Error on this batch = 0.025696610453406807\n",
      "Error on this batch = 0.049550974782101104\n",
      "Cost on val dataset after 443 epochs is = 0.07271358651526669\n",
      "Initial Cost on Val dataset for this epoch 443 = 0.07271358651526669\n",
      "learning rate for this epoch =  0.32695676485241204\n",
      "Error on this batch = 0.025641906310085397\n",
      "Error on this batch = 0.04950468200296298\n",
      "Cost on val dataset after 444 epochs is = 0.07269136473007623\n",
      "Initial Cost on Val dataset for this epoch 444 = 0.07269136473007623\n",
      "learning rate for this epoch =  0.32677251188274103\n",
      "Error on this batch = 0.025587428332470453\n",
      "Error on this batch = 0.04945874683350479\n",
      "Cost on val dataset after 445 epochs is = 0.07266934952204214\n",
      "Initial Cost on Val dataset for this epoch 445 = 0.07266934952204214\n",
      "learning rate for this epoch =  0.3265887769144783\n",
      "Error on this batch = 0.02553317262307372\n",
      "Error on this batch = 0.04941317449595501\n",
      "Cost on val dataset after 446 epochs is = 0.07264753651782944\n",
      "Initial Cost on Val dataset for this epoch 446 = 0.07264753651782944\n",
      "learning rate for this epoch =  0.32640555733218624\n",
      "Error on this batch = 0.025479135521386125\n",
      "Error on this batch = 0.04936796962070672\n",
      "Cost on val dataset after 447 epochs is = 0.07262592155925862\n",
      "Initial Cost on Val dataset for this epoch 447 = 0.07262592155925862\n",
      "learning rate for this epoch =  0.32622285053945943\n",
      "Error on this batch = 0.02542531367729385\n",
      "Error on this batch = 0.049323136138368334\n",
      "Cost on val dataset after 448 epochs is = 0.07260450076681667\n",
      "Initial Cost on Val dataset for this epoch 448 = 0.07260450076681667\n",
      "learning rate for this epoch =  0.3260406539587436\n",
      "Error on this batch = 0.025371704106262404\n",
      "Error on this batch = 0.04927867721163184\n",
      "Cost on val dataset after 449 epochs is = 0.07258327058147343\n",
      "Initial Cost on Val dataset for this epoch 449 = 0.07258327058147343\n",
      "learning rate for this epoch =  0.32585896503115724\n",
      "Error on this batch = 0.025318304228517077\n",
      "Error on this batch = 0.04923459520098605\n",
      "Cost on val dataset after 450 epochs is = 0.07256222778682406\n",
      "Initial Cost on Val dataset for this epoch 450 = 0.07256222778682406\n",
      "learning rate for this epoch =  0.3256777812163153\n",
      "Error on this batch = 0.02526511189447983\n",
      "Error on this batch = 0.04919089165786417\n",
      "Cost on val dataset after 451 epochs is = 0.0725413695140612\n",
      "Initial Cost on Val dataset for this epoch 451 = 0.0725413695140612\n",
      "learning rate for this epoch =  0.3254970999921543\n",
      "Error on this batch = 0.025212125398616347\n",
      "Error on this batch = 0.049147567338968454\n",
      "Cost on val dataset after 452 epochs is = 0.07252069323250114\n",
      "Initial Cost on Val dataset for this epoch 452 = 0.07252069323250114\n",
      "learning rate for this epoch =  0.32531691885476033\n",
      "Error on this batch = 0.025159343483662156\n",
      "Error on this batch = 0.04910462223605888\n",
      "Cost on val dataset after 453 epochs is = 0.0725001967284194\n",
      "Initial Cost on Val dataset for this epoch 453 = 0.0725001967284194\n",
      "learning rate for this epoch =  0.32513723531819827\n",
      "Error on this batch = 0.025106765336975163\n",
      "Error on this batch = 0.04906205561624957\n",
      "Cost on val dataset after 454 epochs is = 0.07247987807484517\n",
      "Initial Cost on Val dataset for this epoch 454 = 0.07247987807484517\n",
      "learning rate for this epoch =  0.3249580469143436\n",
      "Error on this batch = 0.025054390580528753\n",
      "Error on this batch = 0.04901986606870086\n",
      "Cost on val dataset after 455 epochs is = 0.07245973559477578\n",
      "Initial Cost on Val dataset for this epoch 455 = 0.07245973559477578\n",
      "learning rate for this epoch =  0.32477935119271584\n",
      "Error on this batch = 0.025002219255830484\n",
      "Error on this batch = 0.04897805155443098\n",
      "Cost on val dataset after 456 epochs is = 0.07243976782003546\n",
      "Initial Cost on Val dataset for this epoch 456 = 0.07243976782003546\n",
      "learning rate for this epoch =  0.32460114572031407\n",
      "Error on this batch = 0.0249502518048343\n",
      "Error on this batch = 0.04893660945674811\n",
      "Cost on val dataset after 457 epochs is = 0.07241997344774773\n",
      "Initial Cost on Val dataset for this epoch 457 = 0.07241997344774773\n",
      "learning rate for this epoch =  0.3244234280814539\n",
      "Error on this batch = 0.0248984890477133\n",
      "Error on this batch = 0.04889553663049077\n",
      "Cost on val dataset after 458 epochs is = 0.07240035129613527\n",
      "Initial Cost on Val dataset for this epoch 458 = 0.07240035129613527\n",
      "learning rate for this epoch =  0.324246195877607\n",
      "Error on this batch = 0.024846932158178642\n",
      "Error on this batch = 0.04885482944885805\n",
      "Cost on val dataset after 459 epochs is = 0.07238090026111536\n",
      "Initial Cost on Val dataset for this epoch 459 = 0.07238090026111536\n",
      "learning rate for this epoch =  0.324069446727242\n",
      "Error on this batch = 0.02479558263686868\n",
      "Error on this batch = 0.0488144838471129\n",
      "Cost on val dataset after 460 epochs is = 0.07236161927492984\n",
      "Initial Cost on Val dataset for this epoch 460 = 0.07236161927492984\n",
      "learning rate for this epoch =  0.32389317826566727\n",
      "Error on this batch = 0.024744442283193738\n",
      "Error on this batch = 0.04877449536286514\n",
      "Cost on val dataset after 461 epochs is = 0.07234250726783772\n",
      "Initial Cost on Val dataset for this epoch 461 = 0.07234250726783772\n",
      "learning rate for this epoch =  0.32371738814487555\n",
      "Error on this batch = 0.02469351316590567\n",
      "Error on this batch = 0.04873485917299994\n",
      "Cost on val dataset after 462 epochs is = 0.07232356313370368\n",
      "Initial Cost on Val dataset for this epoch 462 = 0.07232356313370368\n",
      "learning rate for this epoch =  0.3235420740333905\n",
      "Error on this batch = 0.024642797592571312\n",
      "Error on this batch = 0.04869557012762495\n",
      "Cost on val dataset after 463 epochs is = 0.07230478570013828\n",
      "Initial Cost on Val dataset for this epoch 463 = 0.07230478570013828\n",
      "learning rate for this epoch =  0.3233672336161148\n",
      "Error on this batch = 0.02459229807806345\n",
      "Error on this batch = 0.048656622781675665\n",
      "Cost on val dataset after 464 epochs is = 0.07228617370367917\n",
      "Initial Cost on Val dataset for this epoch 464 = 0.07228617370367917\n",
      "learning rate for this epoch =  0.3231928645941795\n",
      "Error on this batch = 0.024542017312146006\n",
      "Error on this batch = 0.04861801142504943\n",
      "Cost on val dataset after 465 epochs is = 0.07226772577034642\n",
      "Initial Cost on Val dataset for this epoch 465 = 0.07226772577034642\n",
      "learning rate for this epoch =  0.3230189646847966\n",
      "Error on this batch = 0.02449195812622027\n",
      "Error on this batch = 0.0485797301123346\n",
      "Cost on val dataset after 466 epochs is = 0.07224944040175661\n",
      "Initial Cost on Val dataset for this epoch 466 = 0.07224944040175661\n",
      "learning rate for this epoch =  0.3228455316211112\n",
      "Error on this batch = 0.024442123459315727\n",
      "Error on this batch = 0.04854177269335587\n",
      "Cost on val dataset after 467 epochs is = 0.07223131596683714\n",
      "Initial Cost on Val dataset for this epoch 467 = 0.07223131596683714\n",
      "learning rate for this epoch =  0.32267256315205695\n",
      "Error on this batch = 0.024392516323451626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04850413284585956\n",
      "Cost on val dataset after 468 epochs is = 0.07221335069904308\n",
      "Initial Cost on Val dataset for this epoch 468 = 0.07221335069904308\n",
      "learning rate for this epoch =  0.3225000570422127\n",
      "Error on this batch = 0.024343139768559174\n",
      "Error on this batch = 0.048466804111696196\n",
      "Cost on val dataset after 469 epochs is = 0.07219554269884515\n",
      "Initial Cost on Val dataset for this epoch 469 = 0.07219554269884515\n",
      "learning rate for this epoch =  0.32232801107166015\n",
      "Error on this batch = 0.024293996847234687\n",
      "Error on this batch = 0.04842977993780318\n",
      "Cost on val dataset after 470 epochs is = 0.07217788994112728\n",
      "Initial Cost on Val dataset for this epoch 470 = 0.07217788994112728\n",
      "learning rate for this epoch =  0.32215642303584385\n",
      "Error on this batch = 0.024245090579683565\n",
      "Error on this batch = 0.04839305372312621\n",
      "Cost on val dataset after 471 epochs is = 0.0721603902870132\n",
      "Initial Cost on Val dataset for this epoch 471 = 0.0721603902870132\n",
      "learning rate for this epoch =  0.3219852907454323\n",
      "Error on this batch = 0.024196423919303607\n",
      "Error on this batch = 0.04835661887232821\n",
      "Cost on val dataset after 472 epochs is = 0.0721430414995293\n",
      "Initial Cost on Val dataset for this epoch 472 = 0.0721430414995293\n",
      "learning rate for this epoch =  0.32181461202618095\n",
      "Error on this batch = 0.02414799971943533\n",
      "Error on this batch = 0.048320468856707335\n",
      "Cost on val dataset after 473 epochs is = 0.07212584126241922\n",
      "Initial Cost on Val dataset for this epoch 473 = 0.07212584126241922\n",
      "learning rate for this epoch =  0.32164438471879647\n",
      "Error on this batch = 0.02409982070186258\n",
      "Error on this batch = 0.048284597282186294\n",
      "Cost on val dataset after 474 epochs is = 0.0721087872013513\n",
      "Initial Cost on Val dataset for this epoch 474 = 0.0721087872013513\n",
      "learning rate for this epoch =  0.3214746066788024\n",
      "Error on this batch = 0.024051889427671235\n",
      "Error on this batch = 0.048248997963561226\n",
      "Cost on val dataset after 475 epochs is = 0.07209187690671497\n",
      "Initial Cost on Val dataset for this epoch 475 = 0.07209187690671497\n",
      "learning rate for this epoch =  0.3213052757764068\n",
      "Error on this batch = 0.024004208271056662\n",
      "Error on this batch = 0.04821366500345324\n",
      "Cost on val dataset after 476 epochs is = 0.07207510795718705\n",
      "Initial Cost on Val dataset for this epoch 476 = 0.07207510795718705\n",
      "learning rate for this epoch =  0.3211363898963706\n",
      "Error on this batch = 0.02395677939661001\n",
      "Error on this batch = 0.04817859287364973\n",
      "Cost on val dataset after 477 epochs is = 0.07205847794327161\n",
      "Initial Cost on Val dataset for this epoch 477 = 0.07205847794327161\n",
      "learning rate for this epoch =  0.32096794693787845\n",
      "Error on this batch = 0.023909604740508003\n",
      "Error on this batch = 0.048143776495834935\n",
      "Cost on val dataset after 478 epochs is = 0.07204198449007712\n",
      "Initial Cost on Val dataset for this epoch 478 = 0.07204198449007712\n",
      "learning rate for this epoch =  0.32079994481440977\n",
      "Error on this batch = 0.023862685995892675\n",
      "Error on this batch = 0.048109211318179544\n",
      "Cost on val dataset after 479 epochs is = 0.07202562527869155\n",
      "Initial Cost on Val dataset for this epoch 479 = 0.07202562527869155\n",
      "learning rate for this epoch =  0.3206323814536121\n",
      "Error on this batch = 0.02381602460256527\n",
      "Error on this batch = 0.04807489338397183\n",
      "Cost on val dataset after 480 epochs is = 0.07200939806564874\n",
      "Initial Cost on Val dataset for this epoch 480 = 0.07200939806564874\n",
      "learning rate for this epoch =  0.3204652547971755\n",
      "Error on this batch = 0.023769621740955937\n",
      "Error on this batch = 0.04804081938849508\n",
      "Cost on val dataset after 481 epochs is = 0.0719933007001356\n",
      "Initial Cost on Val dataset for this epoch 481 = 0.0719933007001356\n",
      "learning rate for this epoch =  0.3202985628007086\n",
      "Error on this batch = 0.023723478330184164\n",
      "Error on this batch = 0.04800698672072492\n",
      "Cost on val dataset after 482 epochs is = 0.07197733113876274\n",
      "Initial Cost on Val dataset for this epoch 482 = 0.07197733113876274\n",
      "learning rate for this epoch =  0.32013230343361526\n",
      "Error on this batch = 0.023677595029915788\n",
      "Error on this batch = 0.04797339348712601\n",
      "Cost on val dataset after 483 epochs is = 0.07196148745789513\n",
      "Initial Cost on Val dataset for this epoch 483 = 0.07196148745789513\n",
      "learning rate for this epoch =  0.3199664746789736\n",
      "Error on this batch = 0.02363197224566176\n",
      "Error on this batch = 0.04794003851581798\n",
      "Cost on val dataset after 484 epochs is = 0.07194576786370162\n",
      "Initial Cost on Val dataset for this epoch 484 = 0.07194576786370162\n",
      "learning rate for this epoch =  0.31980107453341566\n",
      "Error on this batch = 0.02358661013715915\n",
      "Error on this batch = 0.04790692134055917\n",
      "Cost on val dataset after 485 epochs is = 0.07193017070021678\n",
      "Initial Cost on Val dataset for this epoch 485 = 0.07193017070021678\n",
      "learning rate for this epoch =  0.3196361010070084\n",
      "Error on this batch = 0.02354150862951825\n",
      "Error on this batch = 0.047874042165240285\n",
      "Cost on val dataset after 486 epochs is = 0.07191469445580762\n",
      "Initial Cost on Val dataset for this epoch 486 = 0.07191469445580762\n",
      "learning rate for this epoch =  0.31947155212313627\n",
      "Error on this batch = 0.02349666742690155\n",
      "Error on this batch = 0.047841401810755226\n",
      "Cost on val dataset after 487 epochs is = 0.07189933776848852\n",
      "Initial Cost on Val dataset for this epoch 487 = 0.07189933776848852\n",
      "learning rate for this epoch =  0.31930742591838485\n",
      "Error on this batch = 0.02345208602859834\n",
      "Error on this batch = 0.047809001647102126\n",
      "Cost on val dataset after 488 epochs is = 0.07188409943053437\n",
      "Initial Cost on Val dataset for this epoch 488 = 0.07188409943053437\n",
      "learning rate for this epoch =  0.31914372044242595\n",
      "Error on this batch = 0.02340776374745344\n",
      "Error on this batch = 0.04777684351427399\n",
      "Cost on val dataset after 489 epochs is = 0.07186897839280079\n",
      "Initial Cost on Val dataset for this epoch 489 = 0.07186897839280079\n",
      "learning rate for this epoch =  0.3189804337579035\n",
      "Error on this batch = 0.023363699730679734\n",
      "Error on this batch = 0.04774492963587329\n",
      "Cost on val dataset after 490 epochs is = 0.07185397376908169\n",
      "Initial Cost on Val dataset for this epoch 490 = 0.07185397376908169\n",
      "learning rate for this epoch =  0.3188175639403211\n",
      "Error on this batch = 0.02331989298311871\n",
      "Error on this batch = 0.04771326252942737\n",
      "Cost on val dataset after 491 epochs is = 0.07183908484073022\n",
      "Initial Cost on Val dataset for this epoch 491 = 0.07183908484073022\n",
      "learning rate for this epoch =  0.31865510907793076\n",
      "Error on this batch = 0.023276342393005134\n",
      "Error on this batch = 0.04768184491712228\n",
      "Cost on val dataset after 492 epochs is = 0.07182431106164804\n",
      "Initial Cost on Val dataset for this epoch 492 = 0.07182431106164804\n",
      "learning rate for this epoch =  0.3184930672716223\n",
      "Error on this batch = 0.023233046760241557\n",
      "Error on this batch = 0.04765067964017956\n",
      "Cost on val dataset after 493 epochs is = 0.07180965206362687\n",
      "Initial Cost on Val dataset for this epoch 493 = 0.07180965206362687\n",
      "learning rate for this epoch =  0.31833143663481483\n",
      "Error on this batch = 0.02319000482710501\n",
      "Error on this batch = 0.04761976957945034\n",
      "Cost on val dataset after 494 epochs is = 0.07179510766191272\n",
      "Initial Cost on Val dataset for this epoch 494 = 0.07179510766191272\n",
      "learning rate for this epoch =  0.31817021529334844\n",
      "Error on this batch = 0.023147215311200214\n",
      "Error on this batch = 0.047589117584076544\n",
      "Cost on val dataset after 495 epochs is = 0.07178067786076675\n",
      "Initial Cost on Val dataset for this epoch 495 = 0.07178067786076675\n",
      "learning rate for this epoch =  0.31800940138537775\n",
      "Error on this batch = 0.023104676940354847\n",
      "Error on this batch = 0.047558726409342\n",
      "Cost on val dataset after 496 epochs is = 0.07176636285872284\n",
      "Initial Cost on Val dataset for this epoch 496 = 0.07176636285872284\n",
      "learning rate for this epoch =  0.31784899306126624\n",
      "Error on this batch = 0.023062388489031953\n",
      "Error on this batch = 0.0475285986641641\n",
      "Cost on val dataset after 497 epochs is = 0.071752163053188\n",
      "Initial Cost on Val dataset for this epoch 497 = 0.071752163053188\n",
      "learning rate for this epoch =  0.31768898848348165\n",
      "Error on this batch = 0.0230203488157178\n",
      "Error on this batch = 0.047498736768095934\n",
      "Cost on val dataset after 498 epochs is = 0.07173807904399838\n",
      "Initial Cost on Val dataset for this epoch 498 = 0.07173807904399838\n",
      "learning rate for this epoch =  0.31752938582649276\n",
      "Error on this batch = 0.022978556900638214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.0474691429172411\n",
      "Cost on val dataset after 499 epochs is = 0.07172411163552334\n",
      "Initial Cost on Val dataset for this epoch 499 = 0.07172411163552334\n",
      "learning rate for this epoch =  0.31737018327666694\n",
      "Error on this batch = 0.022937011883056257\n",
      "Error on this batch = 0.04743981905812688\n",
      "Cost on val dataset after 500 epochs is = 0.07171026183689548\n",
      "Initial Cost on Val dataset for this epoch 500 = 0.07171026183689548\n",
      "learning rate for this epoch =  0.3172113790321692\n",
      "Error on this batch = 0.02289571309731282\n",
      "Error on this batch = 0.04741076686833097\n",
      "Cost on val dataset after 501 epochs is = 0.07169653085992805\n",
      "Initial Cost on Val dataset for this epoch 501 = 0.07169653085992805\n",
      "learning rate for this epoch =  0.3170529713028618\n",
      "Error on this batch = 0.022854660106680694\n",
      "Error on this batch = 0.047381987742487225\n",
      "Cost on val dataset after 502 epochs is = 0.07168292011425349\n",
      "Initial Cost on Val dataset for this epoch 502 = 0.07168292011425349\n",
      "learning rate for this epoch =  0.31689495831020514\n",
      "Error on this batch = 0.02281385273401069\n",
      "Error on this batch = 0.04735348278218504\n",
      "Cost on val dataset after 503 epochs is = 0.07166943119916963\n",
      "Initial Cost on Val dataset for this epoch 503 = 0.07166943119916963\n",
      "learning rate for this epoch =  0.31673733828715983\n",
      "Error on this batch = 0.022773291088050724\n",
      "Error on this batch = 0.04732525278819389\n",
      "Cost on val dataset after 504 epochs is = 0.07165606589160621\n",
      "Initial Cost on Val dataset for this epoch 504 = 0.07165606589160621\n",
      "learning rate for this epoch =  0.31658010947808957\n",
      "Error on this batch = 0.02273297558421377\n",
      "Error on this batch = 0.04729729825335879\n",
      "Cost on val dataset after 505 epochs is = 0.07164282612951706\n",
      "Initial Cost on Val dataset for this epoch 505 = 0.07164282612951706\n",
      "learning rate for this epoch =  0.316423270138665\n",
      "Error on this batch = 0.022692906958459897\n",
      "Error on this batch = 0.047269619354396775\n",
      "Cost on val dataset after 506 epochs is = 0.07162971398985757\n",
      "Initial Cost on Val dataset for this epoch 506 = 0.07162971398985757\n",
      "learning rate for this epoch =  0.3162668185357691\n",
      "Error on this batch = 0.02265308627284278\n",
      "Error on this batch = 0.04724221594064801\n",
      "Cost on val dataset after 507 epochs is = 0.07161673166012227\n",
      "Initial Cost on Val dataset for this epoch 507 = 0.07161673166012227\n",
      "learning rate for this epoch =  0.31611075294740243\n",
      "Error on this batch = 0.02261351491116023\n",
      "Error on this batch = 0.0472150875175803\n",
      "Cost on val dataset after 508 epochs is = 0.07160388140219082\n",
      "Initial Cost on Val dataset for this epoch 508 = 0.07160388140219082\n",
      "learning rate for this epoch =  0.3159550716625907\n",
      "Error on this batch = 0.022574194563051736\n",
      "Error on this batch = 0.04718823322249062\n",
      "Cost on val dataset after 509 epochs is = 0.07159116550697192\n",
      "Initial Cost on Val dataset for this epoch 509 = 0.07159116550697192\n",
      "learning rate for this epoch =  0.31579977298129214\n",
      "Error on this batch = 0.022535127194818864\n",
      "Error on this batch = 0.047161651789392335\n",
      "Cost on val dataset after 510 epochs is = 0.07157858623805104\n",
      "Initial Cost on Val dataset for this epoch 510 = 0.07157858623805104\n",
      "learning rate for this epoch =  0.31564485521430685\n",
      "Error on this batch = 0.02249631500522854\n",
      "Error on this batch = 0.04713534149952947\n",
      "Cost on val dataset after 511 epochs is = 0.07156614576226614\n",
      "Initial Cost on Val dataset for this epoch 511 = 0.07156614576226614\n",
      "learning rate for this epoch =  0.315490316683186\n",
      "Error on this batch = 0.022457760364624033\n",
      "Error on this batch = 0.04710930011335876\n",
      "Cost on val dataset after 512 epochs is = 0.07155384606488416\n",
      "Initial Cost on Val dataset for this epoch 512 = 0.07155384606488416\n",
      "learning rate for this epoch =  0.31533615572014295\n",
      "Error on this batch = 0.022419465735848344\n",
      "Error on this batch = 0.04708352477925841\n",
      "Cost on val dataset after 513 epochs is = 0.07154168884688636\n",
      "Initial Cost on Val dataset for this epoch 513 = 0.07154168884688636\n",
      "learning rate for this epoch =  0.3151823706679647\n",
      "Error on this batch = 0.022381433575829328\n",
      "Error on this batch = 0.047058011913783136\n",
      "Cost on val dataset after 514 epochs is = 0.07152967540186034\n",
      "Initial Cost on Val dataset for this epoch 514 = 0.07152967540186034\n",
      "learning rate for this epoch =  0.3150289598799243\n",
      "Error on this batch = 0.02234366621723632\n",
      "Error on this batch = 0.04703275704817525\n",
      "Cost on val dataset after 515 epochs is = 0.07151780647024443\n",
      "Initial Cost on Val dataset for this epoch 515 = 0.07151780647024443\n",
      "learning rate for this epoch =  0.3148759217196945\n",
      "Error on this batch = 0.022306165730460827\n",
      "Error on this batch = 0.04700775463632812\n",
      "Cost on val dataset after 516 epochs is = 0.07150608206929128\n",
      "Initial Cost on Val dataset for this epoch 516 = 0.07150608206929128\n",
      "learning rate for this epoch =  0.3147232545612616\n",
      "Error on this batch = 0.02226893376736471\n",
      "Error on this batch = 0.046982997820827564\n",
      "Cost on val dataset after 517 epochs is = 0.07149450129827396\n",
      "Initial Cost on Val dataset for this epoch 517 = 0.07149450129827396\n",
      "learning rate for this epoch =  0.3145709567888413\n",
      "Error on this batch = 0.022231971389845874\n",
      "Error on this batch = 0.0469584781564825\n",
      "Cost on val dataset after 518 epochs is = 0.0714830621203029\n",
      "Initial Cost on Val dataset for this epoch 518 = 0.0714830621203029\n",
      "learning rate for this epoch =  0.31441902679679395\n",
      "Error on this batch = 0.022195278888347145\n",
      "Error on this batch = 0.04693418529533034\n",
      "Cost on val dataset after 519 epochs is = 0.07147176112482803\n",
      "Initial Cost on Val dataset for this epoch 519 = 0.07147176112482803\n",
      "learning rate for this epoch =  0.3142674629895419\n",
      "Error on this batch = 0.022158855598003707\n",
      "Error on this batch = 0.04691010664382155\n",
      "Cost on val dataset after 520 epochs is = 0.0714605932785771\n",
      "Initial Cost on Val dataset for this epoch 520 = 0.0714605932785771\n",
      "learning rate for this epoch =  0.3141162637814871\n",
      "Error on this batch = 0.0221226997231605\n",
      "Error on this batch = 0.04688622701186481\n",
      "Cost on val dataset after 521 epochs is = 0.07144955167734932\n",
      "Initial Cost on Val dataset for this epoch 521 = 0.07144955167734932\n",
      "learning rate for this epoch =  0.3139654275969295\n",
      "Error on this batch = 0.02208680818437241\n",
      "Error on this batch = 0.04686252828431019\n",
      "Cost on val dataset after 522 epochs is = 0.07143862731656699\n",
      "Initial Cost on Val dataset for this epoch 522 = 0.07143862731656699\n",
      "learning rate for this epoch =  0.3138149528699866\n",
      "Error on this batch = 0.022051176505472777\n",
      "Error on this batch = 0.04683898915719688\n",
      "Cost on val dataset after 523 epochs is = 0.07142780890432544\n",
      "Initial Cost on Val dataset for this epoch 523 = 0.07142780890432544\n",
      "learning rate for this epoch =  0.31366483804451345\n",
      "Error on this batch = 0.022015798761403735\n",
      "Error on this batch = 0.04681558499170052\n",
      "Cost on val dataset after 524 epochs is = 0.07141708274601612\n",
      "Initial Cost on Val dataset for this epoch 524 = 0.07141708274601612\n",
      "learning rate for this epoch =  0.31351508157402375\n",
      "Error on this batch = 0.021980667609540518\n",
      "Error on this batch = 0.046792287845200405\n",
      "Cost on val dataset after 525 epochs is = 0.071406432733139\n",
      "Initial Cost on Val dataset for this epoch 525 = 0.071406432733139\n",
      "learning rate for this epoch =  0.31336568192161146\n",
      "Error on this batch = 0.02194577442722711\n",
      "Error on this batch = 0.04676906673758465\n",
      "Cost on val dataset after 526 epochs is = 0.07139584046898992\n",
      "Initial Cost on Val dataset for this epoch 526 = 0.07139584046898992\n",
      "learning rate for this epoch =  0.31321663755987345\n",
      "Error on this batch = 0.02191110957497549\n",
      "Error on this batch = 0.0467458881982705\n",
      "Cost on val dataset after 527 epochs is = 0.07138528555872763\n",
      "Initial Cost on Val dataset for this epoch 527 = 0.07138528555872763\n",
      "learning rate for this epoch =  0.3130679469708329\n",
      "Error on this batch = 0.021876662797073496\n",
      "Error on this batch = 0.04672271711331339\n",
      "Cost on val dataset after 528 epochs is = 0.07137474607949838\n",
      "Initial Cost on Val dataset for this epoch 528 = 0.07137474607949838\n",
      "learning rate for this epoch =  0.312919608645863\n",
      "Error on this batch = 0.021842423758435307\n",
      "Error on this batch = 0.046699517853280026\n",
      "Cost on val dataset after 529 epochs is = 0.07136419922754385\n",
      "Initial Cost on Val dataset for this epoch 529 = 0.07136419922754385\n",
      "learning rate for this epoch =  0.3127716210856122\n",
      "Error on this batch = 0.021808382698681524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.046676255616319454\n",
      "Cost on val dataset after 530 epochs is = 0.07135362211507199\n",
      "Initial Cost on Val dataset for this epoch 530 = 0.07135362211507199\n",
      "learning rate for this epoch =  0.3126239827999295\n",
      "Error on this batch = 0.02177453116353442\n",
      "Error on this batch = 0.04665289787629866\n",
      "Cost on val dataset after 531 epochs is = 0.07134299266384711\n",
      "Initial Cost on Val dataset for this epoch 531 = 0.07134299266384711\n",
      "learning rate for this epoch =  0.312476692307791\n",
      "Error on this batch = 0.02174086275339336\n",
      "Error on this batch = 0.04662941579447969\n",
      "Cost on val dataset after 532 epochs is = 0.07133229052044895\n",
      "Initial Cost on Val dataset for this epoch 532 = 0.07133229052044895\n",
      "learning rate for this epoch =  0.31232974813722675\n",
      "Error on this batch = 0.02170737381449217\n",
      "Error on this batch = 0.046605785445216395\n",
      "Cost on val dataset after 533 epochs is = 0.07132149790591424\n",
      "Initial Cost on Val dataset for this epoch 533 = 0.07132149790591424\n",
      "learning rate for this epoch =  0.3121831488252485\n",
      "Error on this batch = 0.02167406399438752\n",
      "Error on this batch = 0.04658198872636068\n",
      "Cost on val dataset after 534 epochs is = 0.0713106003144457\n",
      "Initial Cost on Val dataset for this epoch 534 = 0.0713106003144457\n",
      "learning rate for this epoch =  0.3120368929177782\n",
      "Error on this batch = 0.02164093659376755\n",
      "Error on this batch = 0.0465580138703222\n",
      "Cost on val dataset after 535 epochs is = 0.07129958699310768\n",
      "Initial Cost on Val dataset for this epoch 535 = 0.07129958699310768\n",
      "learning rate for this epoch =  0.3118909789695773\n",
      "Error on this batch = 0.0216079986701877\n",
      "Error on this batch = 0.04653385553129029\n",
      "Cost on val dataset after 536 epochs is = 0.07128845116379864\n",
      "Initial Cost on Val dataset for this epoch 536 = 0.07128845116379864\n",
      "learning rate for this epoch =  0.3117454055441764\n",
      "Error on this batch = 0.021575260881788207\n",
      "Error on this batch = 0.04650951448337432\n",
      "Cost on val dataset after 537 epochs is = 0.07127718998378182\n",
      "Initial Cost on Val dataset for this epoch 537 = 0.07127718998378182\n",
      "learning rate for this epoch =  0.311600171213806\n",
      "Error on this batch = 0.021542737093011466\n",
      "Error on this batch = 0.04648499701001429\n",
      "Cost on val dataset after 538 epochs is = 0.07126580427389888\n",
      "Initial Cost on Val dataset for this epoch 538 = 0.07126580427389888\n",
      "learning rate for this epoch =  0.3114552745593275\n",
      "Error on this batch = 0.021510443792207914\n",
      "Error on this batch = 0.04646031408918052\n",
      "Cost on val dataset after 539 epochs is = 0.07125429806779879\n",
      "Initial Cost on Val dataset for this epoch 539 = 0.07125429806779879\n",
      "learning rate for this epoch =  0.3113107141701652\n",
      "Error on this batch = 0.02147839938745341\n",
      "Error on this batch = 0.04643548048094894\n",
      "Cost on val dataset after 540 epochs is = 0.07124267804766465\n",
      "Initial Cost on Val dataset for this epoch 540 = 0.07124267804766465\n",
      "learning rate for this epoch =  0.3111664886442392\n",
      "Error on this batch = 0.02144662345029131\n",
      "Error on this batch = 0.04641051380904806\n",
      "Cost on val dataset after 541 epochs is = 0.07123095293211064\n",
      "Initial Cost on Val dataset for this epoch 541 = 0.07123095293211064\n",
      "learning rate for this epoch =  0.3110225965878979\n",
      "Error on this batch = 0.021415135969455736\n",
      "Error on this batch = 0.046385433703670195\n",
      "Cost on val dataset after 542 epochs is = 0.07121913287292525\n",
      "Initial Cost on Val dataset for this epoch 542 = 0.07121913287292525\n",
      "learning rate for this epoch =  0.31087903661585237\n",
      "Error on this batch = 0.0213839566621576\n",
      "Error on this batch = 0.046360261046641316\n",
      "Cost on val dataset after 543 epochs is = 0.07120722890315637\n",
      "Initial Cost on Val dataset for this epoch 543 = 0.07120722890315637\n",
      "learning rate for this epoch =  0.310735807351111\n",
      "Error on this batch = 0.021353104373881396\n",
      "Error on this batch = 0.04633501733718147\n",
      "Cost on val dataset after 544 epochs is = 0.07119525246350895\n",
      "Initial Cost on Val dataset for this epoch 544 = 0.07119525246350895\n",
      "learning rate for this epoch =  0.310592907424914\n",
      "Error on this batch = 0.021322596582529704\n",
      "Error on this batch = 0.04630972417950971\n",
      "Cost on val dataset after 545 epochs is = 0.07118321501997109\n",
      "Initial Cost on Val dataset for this epoch 545 = 0.07118321501997109\n",
      "learning rate for this epoch =  0.31045033547666984\n",
      "Error on this batch = 0.021292449011209438\n",
      "Error on this batch = 0.04628440288280432\n",
      "Cost on val dataset after 546 epochs is = 0.0711711277745209\n",
      "Initial Cost on Val dataset for this epoch 546 = 0.0711711277745209\n",
      "learning rate for this epoch =  0.3103080901538911\n",
      "Error on this batch = 0.02126267534645536\n",
      "Error on this batch = 0.04625907415855747\n",
      "Cost on val dataset after 547 epochs is = 0.07115900146310977\n",
      "Initial Cost on Val dataset for this epoch 547 = 0.07115900146310977\n",
      "learning rate for this epoch =  0.3101661701121318\n",
      "Error on this batch = 0.02123328705461899\n",
      "Error on this batch = 0.04623375789869364\n",
      "Cost on val dataset after 548 epochs is = 0.07114684623054199\n",
      "Initial Cost on Val dataset for this epoch 548 = 0.07114684623054199\n",
      "learning rate for this epoch =  0.31002457401492484\n",
      "Error on this batch = 0.021204293287414366\n",
      "Error on this batch = 0.04620847301852352\n",
      "Cost on val dataset after 549 epochs is = 0.07113467156970534\n",
      "Initial Cost on Val dataset for this epoch 549 = 0.07113467156970534\n",
      "learning rate for this epoch =  0.3098833005337202\n",
      "Error on this batch = 0.021175700867086374\n",
      "Error on this batch = 0.04618323735055034\n",
      "Cost on val dataset after 550 epochs is = 0.07112248631211807\n",
      "Initial Cost on Val dataset for this epoch 550 = 0.07112248631211807\n",
      "learning rate for this epoch =  0.3097423483478239\n",
      "Error on this batch = 0.021147514341514993\n",
      "Error on this batch = 0.04615806757755769\n",
      "Cost on val dataset after 551 epochs is = 0.07111029865730688\n",
      "Initial Cost on Val dataset for this epoch 551 = 0.07111029865730688\n",
      "learning rate for this epoch =  0.30960171614433696\n",
      "Error on this batch = 0.02111973609931896\n",
      "Error on this batch = 0.046132979195817894\n",
      "Cost on val dataset after 552 epochs is = 0.07109811622964611\n",
      "Initial Cost on Val dataset for this epoch 552 = 0.07109811622964611\n",
      "learning rate for this epoch =  0.30946140261809585\n",
      "Error on this batch = 0.021092366534550627\n",
      "Error on this batch = 0.046107986501418376\n",
      "Cost on val dataset after 553 epochs is = 0.07108594615265824\n",
      "Initial Cost on Val dataset for this epoch 553 = 0.07108594615265824\n",
      "learning rate for this epoch =  0.3093214064716125\n",
      "Error on this batch = 0.02106540424998145\n",
      "Error on this batch = 0.04608310259450169\n",
      "Cost on val dataset after 554 epochs is = 0.07107379513221321\n",
      "Initial Cost on Val dataset for this epoch 554 = 0.07107379513221321\n",
      "learning rate for this epoch =  0.30918172641501573\n",
      "Error on this batch = 0.021038846287482937\n",
      "Error on this batch = 0.04605833939763184\n",
      "Cost on val dataset after 555 epochs is = 0.0710616695414718\n",
      "Initial Cost on Val dataset for this epoch 555 = 0.0710616695414718\n",
      "learning rate for this epoch =  0.3090423611659929\n",
      "Error on this batch = 0.021012688373832012\n",
      "Error on this batch = 0.04603370768555236\n",
      "Cost on val dataset after 556 epochs is = 0.0710495755017553\n",
      "Initial Cost on Val dataset for this epoch 556 = 0.0710495755017553\n",
      "learning rate for this epoch =  0.30890330944973177\n",
      "Error on this batch = 0.020986925170571286\n",
      "Error on this batch = 0.04600921712434541\n",
      "Cost on val dataset after 557 epochs is = 0.07103751895477063\n",
      "Initial Cost on Val dataset for this epoch 557 = 0.07103751895477063\n",
      "learning rate for this epoch =  0.3087645699988635\n",
      "Error on this batch = 0.02096155051739485\n",
      "Error on this batch = 0.04598487631848577\n",
      "Cost on val dataset after 558 epochs is = 0.07102550572278335\n",
      "Initial Cost on Val dataset for this epoch 558 = 0.07102550572278335\n",
      "learning rate for this epoch =  0.3086261415534058\n",
      "Error on this batch = 0.02093655765988043\n",
      "Error on this batch = 0.04596069286457455\n",
      "Cost on val dataset after 559 epochs is = 0.0710135415544128\n",
      "Initial Cost on Val dataset for this epoch 559 = 0.0710135415544128\n",
      "learning rate for this epoch =  0.308488022860707\n",
      "Error on this batch = 0.02091193945414219\n",
      "Error on this batch = 0.04593667341068805\n",
      "Cost on val dataset after 560 epochs is = 0.07100163215473436\n",
      "Initial Cost on Val dataset for this epoch 560 = 0.07100163215473436\n",
      "learning rate for this epoch =  0.30835021267538976\n",
      "Error on this batch = 0.020887688542991337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04591282372033338\n",
      "Cost on val dataset after 561 epochs is = 0.07098978319931873\n",
      "Initial Cost on Val dataset for this epoch 561 = 0.07098978319931873\n",
      "learning rate for this epoch =  0.3082127097592968\n",
      "Error on this batch = 0.020863797500301914\n",
      "Error on this batch = 0.04588914873999956\n",
      "Cost on val dataset after 562 epochs is = 0.0709780003327173\n",
      "Initial Cost on Val dataset for this epoch 562 = 0.0709780003327173\n",
      "learning rate for this epoch =  0.3080755128814354\n",
      "Error on this batch = 0.020840258942338624\n",
      "Error on this batch = 0.04586565266925425\n",
      "Cost on val dataset after 563 epochs is = 0.07096628915270864\n",
      "Initial Cost on Val dataset for this epoch 563 = 0.07096628915270864\n",
      "learning rate for this epoch =  0.30793862081792395\n",
      "Error on this batch = 0.02081706560668268\n",
      "Error on this batch = 0.04584233903227464\n",
      "Cost on val dataset after 564 epochs is = 0.07095465518233618\n",
      "Initial Cost on Val dataset for this epoch 564 = 0.07095465518233618\n",
      "learning rate for this epoch =  0.3078020323519378\n",
      "Error on this batch = 0.020794210400991893\n",
      "Error on this batch = 0.04581921074962465\n",
      "Cost on val dataset after 565 epochs is = 0.07094310383236366\n",
      "Initial Cost on Val dataset for this epoch 565 = 0.07094310383236366\n",
      "learning rate for this epoch =  0.30766574627365656\n",
      "Error on this batch = 0.020771686425083008\n",
      "Error on this batch = 0.04579627020900262\n",
      "Cost on val dataset after 566 epochs is = 0.07093164035721822\n",
      "Initial Cost on Val dataset for this epoch 566 = 0.07093164035721822\n",
      "learning rate for this epoch =  0.30752976138021126\n",
      "Error on this batch = 0.02074948697068348\n",
      "Error on this batch = 0.04577351933358683\n",
      "Cost on val dataset after 567 epochs is = 0.07092026980774702\n",
      "Initial Cost on Val dataset for this epoch 567 = 0.07092026980774702\n",
      "learning rate for this epoch =  0.30739407647563216\n",
      "Error on this batch = 0.020727605503652626\n",
      "Error on this batch = 0.04575095964650758\n",
      "Cost on val dataset after 568 epochs is = 0.07090899698414964\n",
      "Initial Cost on Val dataset for this epoch 568 = 0.07090899698414964\n",
      "learning rate for this epoch =  0.3072586903707974\n",
      "Error on this batch = 0.020706035633523818\n",
      "Error on this batch = 0.04572859232987754\n",
      "Cost on val dataset after 569 epochs is = 0.07089782639225255\n",
      "Initial Cost on Val dataset for this epoch 569 = 0.07089782639225255\n",
      "learning rate for this epoch =  0.3071236018833813\n",
      "Error on this batch = 0.02068477107490823\n",
      "Error on this batch = 0.04570641827672592\n",
      "Cost on val dataset after 570 epochs is = 0.0708867622058641\n",
      "Initial Cost on Val dataset for this epoch 570 = 0.0708867622058641\n",
      "learning rate for this epoch =  0.3069888098378042\n",
      "Error on this batch = 0.020663805604680823\n",
      "Error on this batch = 0.04568443813411066\n",
      "Cost on val dataset after 571 epochs is = 0.07087580823732056\n",
      "Initial Cost on Val dataset for this epoch 571 = 0.07087580823732056\n",
      "learning rate for this epoch =  0.30685431306518185\n",
      "Error on this batch = 0.020643133018027796\n",
      "Error on this batch = 0.04566265233563237\n",
      "Cost on val dataset after 572 epochs is = 0.07086496791755009\n",
      "Initial Cost on Val dataset for this epoch 572 = 0.07086496791755009\n",
      "learning rate for this epoch =  0.3067201104032758\n",
      "Error on this batch = 0.02062274708546289\n",
      "Error on this batch = 0.045641061121545264\n",
      "Cost on val dataset after 573 epochs is = 0.07085424428611416\n",
      "Initial Cost on Val dataset for this epoch 573 = 0.07085424428611416\n",
      "learning rate for this epoch =  0.30658620069644404\n",
      "Error on this batch = 0.020602641511931932\n",
      "Error on this batch = 0.04561966454465789\n",
      "Cost on val dataset after 574 epochs is = 0.07084363999080621\n",
      "Initial Cost on Val dataset for this epoch 574 = 0.07084363999080621\n",
      "learning rate for this epoch =  0.3064525827955921\n",
      "Error on this batch = 0.02058280989821992\n",
      "Error on this batch = 0.04559846246024402\n",
      "Cost on val dataset after 575 epochs is = 0.07083315729557144\n",
      "Initial Cost on Val dataset for this epoch 575 = 0.07083315729557144\n",
      "learning rate for this epoch =  0.30631925555812456\n",
      "Error on this batch = 0.020563245704152643\n",
      "Error on this batch = 0.045577454498258806\n",
      "Cost on val dataset after 576 epochs is = 0.07082279809482021\n",
      "Initial Cost on Val dataset for this epoch 576 = 0.07082279809482021\n",
      "learning rate for this epoch =  0.3061862178478973\n",
      "Error on this batch = 0.020543942212615338\n",
      "Error on this batch = 0.045556640016301164\n",
      "Cost on val dataset after 577 epochs is = 0.070812563931694\n",
      "Initial Cost on Val dataset for this epoch 577 = 0.070812563931694\n",
      "learning rate for this epoch =  0.30605346853516946\n",
      "Error on this batch = 0.020524892493247942\n",
      "Error on this batch = 0.045536018032026865\n",
      "Cost on val dataset after 578 epochs is = 0.07080245601752791\n",
      "Initial Cost on Val dataset for this epoch 578 = 0.07080245601752791\n",
      "learning rate for this epoch =  0.3059210064965572\n",
      "Error on this batch = 0.020506089364845118\n",
      "Error on this batch = 0.045515587134159284\n",
      "Cost on val dataset after 579 epochs is = 0.07079247524966226\n",
      "Initial Cost on Val dataset for this epoch 579 = 0.07079247524966226\n",
      "learning rate for this epoch =  0.3057888306149859\n",
      "Error on this batch = 0.02048752535599534\n",
      "Error on this batch = 0.04549534537194921\n",
      "Cost on val dataset after 580 epochs is = 0.07078262222488509\n",
      "Initial Cost on Val dataset for this epoch 580 = 0.07078262222488509\n",
      "learning rate for this epoch =  0.3056569397796449\n",
      "Error on this batch = 0.02046919266432891\n",
      "Error on this batch = 0.04547529012398928\n",
      "Cost on val dataset after 581 epochs is = 0.07077289724614205\n",
      "Initial Cost on Val dataset for this epoch 581 = 0.07077289724614205\n",
      "learning rate for this epoch =  0.30552533288594097\n",
      "Error on this batch = 0.02045108311588736\n",
      "Error on this batch = 0.04545541794878218\n",
      "Cost on val dataset after 582 epochs is = 0.0707633003207333\n",
      "Initial Cost on Val dataset for this epoch 582 = 0.0707633003207333\n",
      "learning rate for this epoch =  0.3053940088354531\n",
      "Error on this batch = 0.020433188127545795\n",
      "Error on this batch = 0.04543572442145469\n",
      "Cost on val dataset after 583 epochs is = 0.07075383114903146\n",
      "Initial Cost on Val dataset for this epoch 583 = 0.07075383114903146\n",
      "learning rate for this epoch =  0.3052629665358877\n",
      "Error on this batch = 0.020415498677058545\n",
      "Error on this batch = 0.0454162039635036\n",
      "Cost on val dataset after 584 epochs is = 0.07074448910380046\n",
      "Initial Cost on Val dataset for this epoch 584 = 0.07074448910380046\n",
      "learning rate for this epoch =  0.3051322049010337\n",
      "Error on this batch = 0.020398005287065077\n",
      "Error on this batch = 0.04539684967535845\n",
      "Cost on val dataset after 585 epochs is = 0.07073527320145509\n",
      "Initial Cost on Val dataset for this epoch 585 = 0.07073527320145509\n",
      "learning rate for this epoch =  0.3050017228507182\n",
      "Error on this batch = 0.02038069803112666\n",
      "Error on this batch = 0.04537765318460922\n",
      "Cost on val dataset after 586 epochs is = 0.07072618206801774\n",
      "Initial Cost on Val dataset for this epoch 586 = 0.07072618206801774\n",
      "learning rate for this epoch =  0.3048715193107633\n",
      "Error on this batch = 0.020363566571310658\n",
      "Error on this batch = 0.045358604525556186\n",
      "Cost on val dataset after 587 epochs is = 0.07071721390398737\n",
      "Initial Cost on Val dataset for this epoch 587 = 0.07071721390398737\n",
      "learning rate for this epoch =  0.3047415932129417\n",
      "Error on this batch = 0.020346600237630904\n",
      "Error on this batch = 0.04533969206769492\n",
      "Cost on val dataset after 588 epochs is = 0.07070836645363895\n",
      "cost initial= 0.07071721390398737 , cost final=0.07070836645363895 , change in cost= -8.847450348417607e-06\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with Sigmoid are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with Sigmoid is = 588\n",
      "The training time with Sigmoid is = 216.609sec\n",
      "The training accuracy with Sigmoid is = 96.968%\n",
      "The validation accuracy with Sigmoid is = 91.590%\n",
      "The test accuracy with Sigmoid is = 90.431%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=1.5\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'sigmoid', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with Sigmoid are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with Sigmoid is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with Sigmoid is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with Sigmoid is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with Sigmoid is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with Sigmoid is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with ReLU activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with ReLU activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.2717755072245738\n",
      "learning rate for this epoch =  0.6\n",
      "Error on this batch = 3.27130630738948\n",
      "Error on this batch = 0.488196341243209\n",
      "Cost on val dataset after 2 epochs is = 0.48445491271444696\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.48445491271444696\n",
      "learning rate for this epoch =  0.5045378491522288\n",
      "Error on this batch = 0.4834083106142449\n",
      "Error on this batch = 0.4824993645737395\n",
      "Cost on val dataset after 3 epochs is = 0.4818508360608921\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.4818508360608921\n",
      "learning rate for this epoch =  0.4559014113909555\n",
      "Error on this batch = 0.4814382872543314\n",
      "Error on this batch = 0.48091320332848553\n",
      "Cost on val dataset after 4 epochs is = 0.4808355026035365\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.4808355026035365\n",
      "learning rate for this epoch =  0.42426406871192845\n",
      "Error on this batch = 0.480536088826859\n",
      "Error on this batch = 0.4801567494355972\n",
      "Cost on val dataset after 5 epochs is = 0.4800847704538034\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4800847704538034\n",
      "learning rate for this epoch =  0.40124418298585324\n",
      "Error on this batch = 0.47976919018391445\n",
      "Error on this batch = 0.47930647186031655\n",
      "Cost on val dataset after 6 epochs is = 0.4791654205798389\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4791654205798389\n",
      "learning rate for this epoch =  0.38336586254776345\n",
      "Error on this batch = 0.4787745031421852\n",
      "Error on this batch = 0.47808691777842044\n",
      "Cost on val dataset after 7 epochs is = 0.4777406868070918\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.4777406868070918\n",
      "learning rate for this epoch =  0.3688728917707586\n",
      "Error on this batch = 0.4772252497835313\n",
      "Error on this batch = 0.47601295839779356\n",
      "Cost on val dataset after 8 epochs is = 0.47537105972272603\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.47537105972272603\n",
      "learning rate for this epoch =  0.35676213450081634\n",
      "Error on this batch = 0.4747516235356934\n",
      "Error on this batch = 0.4722810694846385\n",
      "Cost on val dataset after 9 epochs is = 0.47078006739287837\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.47078006739287837\n",
      "learning rate for this epoch =  0.34641016151377546\n",
      "Error on this batch = 0.47001299808475083\n",
      "Error on this batch = 0.46453027072102077\n",
      "Cost on val dataset after 10 epochs is = 0.46032648500485546\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.46032648500485546\n",
      "learning rate for this epoch =  0.33740479511420945\n",
      "Error on this batch = 0.45926741467413423\n",
      "Error on this batch = 0.44976209372947784\n",
      "Cost on val dataset after 11 epochs is = 0.4417620272046159\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.4417620272046159\n",
      "learning rate for this epoch =  0.32946029206566746\n",
      "Error on this batch = 0.4395734077595635\n",
      "Error on this batch = 0.4312709370255676\n",
      "Cost on val dataset after 12 epochs is = 0.42235619380007616\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.42235619380007616\n",
      "learning rate for this epoch =  0.32237097954706256\n",
      "Error on this batch = 0.4187718527593255\n",
      "Error on this batch = 0.4112462052156965\n",
      "Cost on val dataset after 13 epochs is = 0.4023152123090884\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.4023152123090884\n",
      "learning rate for this epoch =  0.315984232708756\n",
      "Error on this batch = 0.4005359396161783\n",
      "Error on this batch = 0.39589198009394216\n",
      "Cost on val dataset after 14 epochs is = 0.3818502060467216\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.3818502060467216\n",
      "learning rate for this epoch =  0.31018389237430233\n",
      "Error on this batch = 0.3821396692691586\n",
      "Error on this batch = 0.3807615409473249\n",
      "Cost on val dataset after 15 epochs is = 0.36257366310174627\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.36257366310174627\n",
      "learning rate for this epoch =  0.30487964889276886\n",
      "Error on this batch = 0.36424548574211785\n",
      "Error on this batch = 0.3698157365611065\n",
      "Cost on val dataset after 16 epochs is = 0.34396295563275575\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.34396295563275575\n",
      "learning rate for this epoch =  0.3\n",
      "Error on this batch = 0.34743075293046427\n",
      "Error on this batch = 0.36140052789371313\n",
      "Cost on val dataset after 17 epochs is = 0.3286354378990106\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.3286354378990106\n",
      "learning rate for this epoch =  0.2954874363032714\n",
      "Error on this batch = 0.3315848553290167\n",
      "Error on this batch = 0.34057660604513573\n",
      "Cost on val dataset after 18 epochs is = 0.3145581642009133\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.3145581642009133\n",
      "learning rate for this epoch =  0.29129506302439406\n",
      "Error on this batch = 0.31728010357412684\n",
      "Error on this batch = 0.33148060601082036\n",
      "Cost on val dataset after 19 epochs is = 0.30241289793457715\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.30241289793457715\n",
      "learning rate for this epoch =  0.2873841752661448\n",
      "Error on this batch = 0.30489670970807636\n",
      "Error on this batch = 0.3148040789499899\n",
      "Cost on val dataset after 20 epochs is = 0.29161302093554275\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.29161302093554275\n",
      "learning rate for this epoch =  0.28372248270095274\n",
      "Error on this batch = 0.29396568255687217\n",
      "Error on this batch = 0.304977405914264\n",
      "Cost on val dataset after 21 epochs is = 0.28196588539423845\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.28196588539423845\n",
      "learning rate for this epoch =  0.28028278663692\n",
      "Error on this batch = 0.28399814217026353\n",
      "Error on this batch = 0.2932194261177641\n",
      "Cost on val dataset after 22 epochs is = 0.2731053793632825\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.2731053793632825\n",
      "learning rate for this epoch =  0.27704197856646157\n",
      "Error on this batch = 0.27507696271417365\n",
      "Error on this batch = 0.2831564248506052\n",
      "Cost on val dataset after 23 epochs is = 0.26492114185547777\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.26492114185547777\n",
      "learning rate for this epoch =  0.27398027129803876\n",
      "Error on this batch = 0.26678925186135694\n",
      "Error on this batch = 0.27482297691205426\n",
      "Cost on val dataset after 24 epochs is = 0.2569121055715842\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.2569121055715842\n",
      "learning rate for this epoch =  0.27108060108295345\n",
      "Error on this batch = 0.2592266123725394\n",
      "Error on this batch = 0.267415152832394\n",
      "Cost on val dataset after 25 epochs is = 0.24962864882208038\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.24962864882208038\n",
      "learning rate for this epoch =  0.2683281572999747\n",
      "Error on this batch = 0.2523066952139439\n",
      "Error on this batch = 0.26138386916172446\n",
      "Cost on val dataset after 26 epochs is = 0.2434991296320486\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.2434991296320486\n",
      "learning rate for this epoch =  0.2657100085614884\n",
      "Error on this batch = 0.24547108734308698\n",
      "Error on this batch = 0.25544159344824646\n",
      "Cost on val dataset after 27 epochs is = 0.23765970195194028\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.23765970195194028\n",
      "learning rate for this epoch =  0.2632148025904985\n",
      "Error on this batch = 0.23905606746966768\n",
      "Error on this batch = 0.25104925200990236\n",
      "Cost on val dataset after 28 epochs is = 0.23192525706309708\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.23192525706309708\n",
      "learning rate for this epoch =  0.26083252316699485\n",
      "Error on this batch = 0.23303432970347493\n",
      "Error on this batch = 0.24746315253065426\n",
      "Cost on val dataset after 29 epochs is = 0.22682127156528153\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.22682127156528153\n",
      "learning rate for this epoch =  0.2585542916753436\n",
      "Error on this batch = 0.22729603136370763\n",
      "Error on this batch = 0.24622799986694133\n",
      "Cost on val dataset after 30 epochs is = 0.22223580906608284\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.22223580906608284\n",
      "learning rate for this epoch =  0.2563722038377404\n",
      "Error on this batch = 0.22186542533021958\n",
      "Error on this batch = 0.24351373841191173\n",
      "Cost on val dataset after 31 epochs is = 0.21779975008222804\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.21779975008222804\n",
      "learning rate for this epoch =  0.254279194449013\n",
      "Error on this batch = 0.21669675497159968\n",
      "Error on this batch = 0.23864586415871902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 0.21376940151348495\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.21376940151348495\n",
      "learning rate for this epoch =  0.2522689245761144\n",
      "Error on this batch = 0.21185058784156702\n",
      "Error on this batch = 0.23420878757684205\n",
      "Cost on val dataset after 33 epochs is = 0.20994848046247755\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.20994848046247755\n",
      "learning rate for this epoch =  0.2503356869166904\n",
      "Error on this batch = 0.20718302919002504\n",
      "Error on this batch = 0.23000877356385718\n",
      "Cost on val dataset after 34 epochs is = 0.20635687646425233\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.20635687646425233\n",
      "learning rate for this epoch =  0.2484743259399312\n",
      "Error on this batch = 0.20261508152666427\n",
      "Error on this batch = 0.22622033511531953\n",
      "Cost on val dataset after 35 epochs is = 0.2030060994008411\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.2030060994008411\n",
      "learning rate for this epoch =  0.2466801701403118\n",
      "Error on this batch = 0.19831249389427796\n",
      "Error on this batch = 0.22240938269136754\n",
      "Cost on val dataset after 36 epochs is = 0.1999146441141075\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.1999146441141075\n",
      "learning rate for this epoch =  0.24494897427831783\n",
      "Error on this batch = 0.19410021050419324\n",
      "Error on this batch = 0.2190578729630896\n",
      "Cost on val dataset after 37 epochs is = 0.1969948127023137\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.1969948127023137\n",
      "learning rate for this epoch =  0.2432768699032619\n",
      "Error on this batch = 0.1901497675554757\n",
      "Error on this batch = 0.21575862820630548\n",
      "Cost on val dataset after 38 epochs is = 0.19424938238234515\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.19424938238234515\n",
      "learning rate for this epoch =  0.24166032278194638\n",
      "Error on this batch = 0.18637050696950694\n",
      "Error on this batch = 0.21271922987908107\n",
      "Cost on val dataset after 39 epochs is = 0.19171599341073145\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.19171599341073145\n",
      "learning rate for this epoch =  0.24009609611534996\n",
      "Error on this batch = 0.18270366015299438\n",
      "Error on this batch = 0.20988703493441263\n",
      "Cost on val dataset after 40 epochs is = 0.18938536976938505\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.18938536976938505\n",
      "learning rate for this epoch =  0.23858121863011517\n",
      "Error on this batch = 0.17917027037759403\n",
      "Error on this batch = 0.20716532556975709\n",
      "Cost on val dataset after 41 epochs is = 0.1871920539799026\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.1871920539799026\n",
      "learning rate for this epoch =  0.23711295679464287\n",
      "Error on this batch = 0.17580280725973338\n",
      "Error on this batch = 0.2044874262156808\n",
      "Cost on val dataset after 42 epochs is = 0.18509474839395063\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.18509474839395063\n",
      "learning rate for this epoch =  0.2356887905403078\n",
      "Error on this batch = 0.17252020748246188\n",
      "Error on this batch = 0.20190072835156617\n",
      "Cost on val dataset after 43 epochs is = 0.18313458806169677\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.18313458806169677\n",
      "learning rate for this epoch =  0.23430639197370967\n",
      "Error on this batch = 0.1695586726893076\n",
      "Error on this batch = 0.19923987881856228\n",
      "Cost on val dataset after 44 epochs is = 0.18124224313810966\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.18124224313810966\n",
      "learning rate for this epoch =  0.23296360665133395\n",
      "Error on this batch = 0.16656971025969897\n",
      "Error on this batch = 0.19673572337866277\n",
      "Cost on val dataset after 45 epochs is = 0.17941336204824906\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.17941336204824906\n",
      "learning rate for this epoch =  0.23165843705765382\n",
      "Error on this batch = 0.16365119053342367\n",
      "Error on this batch = 0.19443699900343034\n",
      "Cost on val dataset after 46 epochs is = 0.1776884432824532\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.1776884432824532\n",
      "learning rate for this epoch =  0.23038902798476096\n",
      "Error on this batch = 0.16072549251854704\n",
      "Error on this batch = 0.19216292264626575\n",
      "Cost on val dataset after 47 epochs is = 0.17604779915789007\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.17604779915789007\n",
      "learning rate for this epoch =  0.229153653558572\n",
      "Error on this batch = 0.15781884646958377\n",
      "Error on this batch = 0.1900128383337779\n",
      "Cost on val dataset after 48 epochs is = 0.1744884367618288\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.1744884367618288\n",
      "learning rate for this epoch =  0.22795070569547776\n",
      "Error on this batch = 0.1550331956529895\n",
      "Error on this batch = 0.1879032466058402\n",
      "Cost on val dataset after 49 epochs is = 0.1729830765605629\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.1729830765605629\n",
      "learning rate for this epoch =  0.2267786838055363\n",
      "Error on this batch = 0.15219420706410142\n",
      "Error on this batch = 0.1859503366814166\n",
      "Cost on val dataset after 50 epochs is = 0.1715883261215414\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.1715883261215414\n",
      "learning rate for this epoch =  0.2256361855851836\n",
      "Error on this batch = 0.14963185118993735\n",
      "Error on this batch = 0.18415189917299019\n",
      "Cost on val dataset after 51 epochs is = 0.17028991251291897\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.17028991251291897\n",
      "learning rate for this epoch =  0.22452189876492748\n",
      "Error on this batch = 0.1472380752303843\n",
      "Error on this batch = 0.18250739063997798\n",
      "Cost on val dataset after 52 epochs is = 0.1690820782721471\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.1690820782721471\n",
      "learning rate for this epoch =  0.22343459369638943\n",
      "Error on this batch = 0.1447986329286881\n",
      "Error on this batch = 0.18086547745500642\n",
      "Cost on val dataset after 53 epochs is = 0.16792175856233563\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.16792175856233563\n",
      "learning rate for this epoch =  0.2223731166789908\n",
      "Error on this batch = 0.14255544292344888\n",
      "Error on this batch = 0.1792216929240301\n",
      "Cost on val dataset after 54 epochs is = 0.16683685635975887\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.16683685635975887\n",
      "learning rate for this epoch =  0.22133638394006433\n",
      "Error on this batch = 0.14036080503968087\n",
      "Error on this batch = 0.17781040864939784\n",
      "Cost on val dataset after 55 epochs is = 0.16579581639548838\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.16579581639548838\n",
      "learning rate for this epoch =  0.2203233761936155\n",
      "Error on this batch = 0.13836278059405482\n",
      "Error on this batch = 0.17631344138517402\n",
      "Cost on val dataset after 56 epochs is = 0.1648220122317237\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.1648220122317237\n",
      "learning rate for this epoch =  0.21933313371270743\n",
      "Error on this batch = 0.1366817573091483\n",
      "Error on this batch = 0.17496386228309566\n",
      "Cost on val dataset after 57 epochs is = 0.16392716564698762\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.16392716564698762\n",
      "learning rate for this epoch =  0.21836475185876858\n",
      "Error on this batch = 0.13514288645266287\n",
      "Error on this batch = 0.17368520444769864\n",
      "Cost on val dataset after 58 epochs is = 0.16304692050331207\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.16304692050331207\n",
      "learning rate for this epoch =  0.21741737701825978\n",
      "Error on this batch = 0.1337056034984439\n",
      "Error on this batch = 0.17233648105382401\n",
      "Cost on val dataset after 59 epochs is = 0.1621917631366786\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.1621917631366786\n",
      "learning rate for this epoch =  0.2164902029032644\n",
      "Error on this batch = 0.13225060495944596\n",
      "Error on this batch = 0.1710842385101\n",
      "Cost on val dataset after 60 epochs is = 0.16139646622816828\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.16139646622816828\n",
      "learning rate for this epoch =  0.21558246717785054\n",
      "Error on this batch = 0.13097133260015184\n",
      "Error on this batch = 0.16989316157091813\n",
      "Cost on val dataset after 61 epochs is = 0.16063039263917206\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.16063039263917206\n",
      "learning rate for this epoch =  0.2146934483766157\n",
      "Error on this batch = 0.129680440708151\n",
      "Error on this batch = 0.16859631995065236\n",
      "Cost on val dataset after 62 epochs is = 0.1598940570975305\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.1598940570975305\n",
      "learning rate for this epoch =  0.21382246308577726\n",
      "Error on this batch = 0.12848520657329973\n",
      "Error on this batch = 0.16731116546145505\n",
      "Cost on val dataset after 63 epochs is = 0.1591641779676962\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.1591641779676962\n",
      "learning rate for this epoch =  0.21296886336060317\n",
      "Error on this batch = 0.12732824429591078\n",
      "Error on this batch = 0.16608750051342752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 64 epochs is = 0.1584845110803072\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.1584845110803072\n",
      "learning rate for this epoch =  0.21213203435596423\n",
      "Error on this batch = 0.1262739377929974\n",
      "Error on this batch = 0.16471787136835855\n",
      "Cost on val dataset after 65 epochs is = 0.1578605557281075\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.1578605557281075\n",
      "learning rate for this epoch =  0.21131139214939415\n",
      "Error on this batch = 0.12525162132806783\n",
      "Error on this batch = 0.1635288910005233\n",
      "Cost on val dataset after 66 epochs is = 0.15727132722622247\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.15727132722622247\n",
      "learning rate for this epoch =  0.21050638173832112\n",
      "Error on this batch = 0.12430420161916399\n",
      "Error on this batch = 0.1623425630484826\n",
      "Cost on val dataset after 67 epochs is = 0.1566843297995657\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.1566843297995657\n",
      "learning rate for this epoch =  0.20971647519513073\n",
      "Error on this batch = 0.12337274117546958\n",
      "Error on this batch = 0.1612190760876861\n",
      "Cost on val dataset after 68 epochs is = 0.1561079452876573\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.1561079452876573\n",
      "learning rate for this epoch =  0.2089411699654712\n",
      "Error on this batch = 0.12242656952969178\n",
      "Error on this batch = 0.1601787736844869\n",
      "Cost on val dataset after 69 epochs is = 0.15553532979014598\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.15553532979014598\n",
      "learning rate for this epoch =  0.2081799872967546\n",
      "Error on this batch = 0.12155178003967616\n",
      "Error on this batch = 0.15918268021777343\n",
      "Cost on val dataset after 70 epochs is = 0.1550199828206069\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.1550199828206069\n",
      "learning rate for this epoch =  0.2074324707851646\n",
      "Error on this batch = 0.12070018700963277\n",
      "Error on this batch = 0.15828888534911545\n",
      "Cost on val dataset after 71 epochs is = 0.15447204363143757\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.15447204363143757\n",
      "learning rate for this epoch =  0.2066981850306836\n",
      "Error on this batch = 0.11982143552563229\n",
      "Error on this batch = 0.15733707444334605\n",
      "Cost on val dataset after 72 epochs is = 0.15392015150798946\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.15392015150798946\n",
      "learning rate for this epoch =  0.20597671439071177\n",
      "Error on this batch = 0.11890912149852366\n",
      "Error on this batch = 0.15645207132126984\n",
      "Cost on val dataset after 73 epochs is = 0.1534239873056252\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.1534239873056252\n",
      "learning rate for this epoch =  0.20526766182379289\n",
      "Error on this batch = 0.11816382263752907\n",
      "Error on this batch = 0.1556484849550211\n",
      "Cost on val dataset after 74 epochs is = 0.15291415265724453\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.15291415265724453\n",
      "learning rate for this epoch =  0.20457064781579723\n",
      "Error on this batch = 0.11735634882360238\n",
      "Error on this batch = 0.15474946064615905\n",
      "Cost on val dataset after 75 epochs is = 0.15239193879201704\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.15239193879201704\n",
      "learning rate for this epoch =  0.2038853093816547\n",
      "Error on this batch = 0.11664019461430615\n",
      "Error on this batch = 0.15392047767463798\n",
      "Cost on val dataset after 76 epochs is = 0.15187634008891815\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.15187634008891815\n",
      "learning rate for this epoch =  0.20321129913639427\n",
      "Error on this batch = 0.11599561091222386\n",
      "Error on this batch = 0.15309090309292114\n",
      "Cost on val dataset after 77 epochs is = 0.15141458627236262\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.15141458627236262\n",
      "learning rate for this epoch =  0.2025482844298358\n",
      "Error on this batch = 0.11542335895309425\n",
      "Error on this batch = 0.15244008954909316\n",
      "Cost on val dataset after 78 epochs is = 0.15092848859522243\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.15092848859522243\n",
      "learning rate for this epoch =  0.20189594653980908\n",
      "Error on this batch = 0.11500333453083457\n",
      "Error on this batch = 0.15179936414971917\n",
      "Cost on val dataset after 79 epochs is = 0.15045001913967962\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.15045001913967962\n",
      "learning rate for this epoch =  0.20125397991924746\n",
      "Error on this batch = 0.11463690237635397\n",
      "Error on this batch = 0.15117487054062526\n",
      "Cost on val dataset after 80 epochs is = 0.14997909085573663\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.14997909085573663\n",
      "learning rate for this epoch =  0.20062209149292662\n",
      "Error on this batch = 0.11430087089238512\n",
      "Error on this batch = 0.15070635150136988\n",
      "Cost on val dataset after 81 epochs is = 0.1495045059075224\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.1495045059075224\n",
      "learning rate for this epoch =  0.19999999999999998\n",
      "Error on this batch = 0.11392183058670848\n",
      "Error on this batch = 0.15023743803793901\n",
      "Cost on val dataset after 82 epochs is = 0.14906149739961597\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.14906149739961597\n",
      "learning rate for this epoch =  0.19938743537882408\n",
      "Error on this batch = 0.11356892056682354\n",
      "Error on this batch = 0.14975213859874792\n",
      "Cost on val dataset after 83 epochs is = 0.14862457114661606\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.14862457114661606\n",
      "learning rate for this epoch =  0.1987841381908741\n",
      "Error on this batch = 0.1131205369571491\n",
      "Error on this batch = 0.1492399153051713\n",
      "Cost on val dataset after 84 epochs is = 0.14825751630947795\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.14825751630947795\n",
      "learning rate for this epoch =  0.19818985908082842\n",
      "Error on this batch = 0.11271488085605622\n",
      "Error on this batch = 0.14887283048255237\n",
      "Cost on val dataset after 85 epochs is = 0.14786505433901034\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.14786505433901034\n",
      "learning rate for this epoch =  0.1976043582701508\n",
      "Error on this batch = 0.11233527752582756\n",
      "Error on this batch = 0.1483914109501959\n",
      "Cost on val dataset after 86 epochs is = 0.14750167742309425\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.14750167742309425\n",
      "learning rate for this epoch =  0.19702740508172414\n",
      "Error on this batch = 0.11196240354552348\n",
      "Error on this batch = 0.1478724190720581\n",
      "Cost on val dataset after 87 epochs is = 0.14714519293384304\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.14714519293384304\n",
      "learning rate for this epoch =  0.19645877749329657\n",
      "Error on this batch = 0.11165325348809066\n",
      "Error on this batch = 0.1474247098742691\n",
      "Cost on val dataset after 88 epochs is = 0.14680519218642601\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.14680519218642601\n",
      "learning rate for this epoch =  0.19589826171768313\n",
      "Error on this batch = 0.11128488583879616\n",
      "Error on this batch = 0.14698790917759158\n",
      "Cost on val dataset after 89 epochs is = 0.1464777439606727\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.1464777439606727\n",
      "learning rate for this epoch =  0.1953456518078377\n",
      "Error on this batch = 0.1109668682265697\n",
      "Error on this batch = 0.14669262874314318\n",
      "Cost on val dataset after 90 epochs is = 0.1461916603174167\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.1461916603174167\n",
      "learning rate for this epoch =  0.19480074928505933\n",
      "Error on this batch = 0.11063930836456053\n",
      "Error on this batch = 0.1462772146733648\n",
      "Cost on val dataset after 91 epochs is = 0.14593654869080483\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.14593654869080483\n",
      "learning rate for this epoch =  0.19426336278873857\n",
      "Error on this batch = 0.11038303467846838\n",
      "Error on this batch = 0.14588427973118392\n",
      "Cost on val dataset after 92 epochs is = 0.14567444175936933\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.14567444175936933\n",
      "learning rate for this epoch =  0.1937333077461732\n",
      "Error on this batch = 0.11009774003863282\n",
      "Error on this batch = 0.14555242018042383\n",
      "Cost on val dataset after 93 epochs is = 0.1454488464030031\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.1454488464030031\n",
      "learning rate for this epoch =  0.19321040606110043\n",
      "Error on this batch = 0.10984855125576518\n",
      "Error on this batch = 0.14525541886384435\n",
      "Cost on val dataset after 94 epochs is = 0.14522530467276926\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.14522530467276926\n",
      "learning rate for this epoch =  0.1926944858196948\n",
      "Error on this batch = 0.10949967952181833\n",
      "Error on this batch = 0.14497332685955822\n",
      "Cost on val dataset after 95 epochs is = 0.14504943231872833\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.14504943231872833\n",
      "learning rate for this epoch =  0.1921853810128792\n",
      "Error on this batch = 0.10938931178416272\n",
      "Error on this batch = 0.14475737127615104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 96 epochs is = 0.14486215029120603\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.14486215029120603\n",
      "learning rate for this epoch =  0.19168293127388172\n",
      "Error on this batch = 0.10919964356684048\n",
      "Error on this batch = 0.14457114051793546\n",
      "Cost on val dataset after 97 epochs is = 0.14469185060503284\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.14469185060503284\n",
      "learning rate for this epoch =  0.19118698163005315\n",
      "Error on this batch = 0.10915179447962821\n",
      "Error on this batch = 0.14434729803851276\n",
      "Cost on val dataset after 98 epochs is = 0.14457785100888207\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.14457785100888207\n",
      "learning rate for this epoch =  0.19069738226803112\n",
      "Error on this batch = 0.10907026865843715\n",
      "Error on this batch = 0.14412488034190157\n",
      "Cost on val dataset after 99 epochs is = 0.1444346330843004\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.1444346330843004\n",
      "learning rate for this epoch =  0.19021398831140582\n",
      "Error on this batch = 0.10904276006396893\n",
      "Error on this batch = 0.14391829115624624\n",
      "Cost on val dataset after 100 epochs is = 0.14431326989153653\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.14431326989153653\n",
      "learning rate for this epoch =  0.18973665961010275\n",
      "Error on this batch = 0.10899884195482354\n",
      "Error on this batch = 0.14364990824667953\n",
      "Cost on val dataset after 101 epochs is = 0.14413280981579252\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.14413280981579252\n",
      "learning rate for this epoch =  0.1892652605407543\n",
      "Error on this batch = 0.10892274151842836\n",
      "Error on this batch = 0.14339979121344487\n",
      "Cost on val dataset after 102 epochs is = 0.14398810692000816\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.14398810692000816\n",
      "learning rate for this epoch =  0.18879965981738495\n",
      "Error on this batch = 0.10889166904718696\n",
      "Error on this batch = 0.14320423111855576\n",
      "Cost on val dataset after 103 epochs is = 0.14383952608920528\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.14383952608920528\n",
      "learning rate for this epoch =  0.1883397303117814\n",
      "Error on this batch = 0.10888192712540963\n",
      "Error on this batch = 0.1430221097482405\n",
      "Cost on val dataset after 104 epochs is = 0.14371387354246118\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.14371387354246118\n",
      "learning rate for this epoch =  0.18788534888296407\n",
      "Error on this batch = 0.1088703476062577\n",
      "Error on this batch = 0.14289255996882574\n",
      "Cost on val dataset after 105 epochs is = 0.14361962902632816\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.14361962902632816\n",
      "learning rate for this epoch =  0.18743639621521535\n",
      "Error on this batch = 0.10885550386790836\n",
      "Error on this batch = 0.1427538159902599\n",
      "Cost on val dataset after 106 epochs is = 0.14353591169380112\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.14353591169380112\n",
      "learning rate for this epoch =  0.18699275666415935\n",
      "Error on this batch = 0.10882448193540097\n",
      "Error on this batch = 0.14260129738577498\n",
      "Cost on val dataset after 107 epochs is = 0.14344714470308276\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.14344714470308276\n",
      "learning rate for this epoch =  0.18655431811042028\n",
      "Error on this batch = 0.10880776719090487\n",
      "Error on this batch = 0.14250700054221038\n",
      "Cost on val dataset after 108 epochs is = 0.143387762252719\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.143387762252719\n",
      "learning rate for this epoch =  0.18612097182041992\n",
      "Error on this batch = 0.10875463123442689\n",
      "Error on this batch = 0.14238845498364505\n",
      "Cost on val dataset after 109 epochs is = 0.14335633322445138\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.14335633322445138\n",
      "learning rate for this epoch =  0.1856926123139029\n",
      "Error on this batch = 0.10879141406940368\n",
      "Error on this batch = 0.14230687702305697\n",
      "Cost on val dataset after 110 epochs is = 0.1433412575407403\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.1433412575407403\n",
      "learning rate for this epoch =  0.18526913723780689\n",
      "Error on this batch = 0.10873839438069363\n",
      "Error on this batch = 0.1422091765506783\n",
      "Cost on val dataset after 111 epochs is = 0.14332580351607513\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.14332580351607513\n",
      "learning rate for this epoch =  0.1848504472461183\n",
      "Error on this batch = 0.10867440167669369\n",
      "Error on this batch = 0.14214478395360916\n",
      "Cost on val dataset after 112 epochs is = 0.1432803479825507\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.1432803479825507\n",
      "learning rate for this epoch =  0.1844364458853793\n",
      "Error on this batch = 0.10866373789988185\n",
      "Error on this batch = 0.14211463644613542\n",
      "Cost on val dataset after 113 epochs is = 0.14327392942609998\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.14327392942609998\n",
      "learning rate for this epoch =  0.18402703948553187\n",
      "Error on this batch = 0.10864986593386988\n",
      "Error on this batch = 0.1420202719668305\n",
      "Cost on val dataset after 114 epochs is = 0.14328289126172145\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.14328289126172145\n",
      "learning rate for this epoch =  0.18362213705580538\n",
      "Error on this batch = 0.10865824672307559\n",
      "Error on this batch = 0.14190036962933403\n",
      "Cost on val dataset after 115 epochs is = 0.14326977440871555\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.14326977440871555\n",
      "learning rate for this epoch =  0.18322165018537329\n",
      "Error on this batch = 0.10867202634038993\n",
      "Error on this batch = 0.14177490899778364\n",
      "Cost on val dataset after 116 epochs is = 0.14327514658294965\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.14327514658294965\n",
      "learning rate for this epoch =  0.18282549294852\n",
      "Error on this batch = 0.10864992192094576\n",
      "Error on this batch = 0.1416657373121224\n",
      "Cost on val dataset after 117 epochs is = 0.1432562392133079\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.1432562392133079\n",
      "learning rate for this epoch =  0.1824335818140776\n",
      "Error on this batch = 0.10869213137142358\n",
      "Error on this batch = 0.14149271188115461\n",
      "Cost on val dataset after 118 epochs is = 0.14326105892121516\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.14326105892121516\n",
      "learning rate for this epoch =  0.18204583555890436\n",
      "Error on this batch = 0.10860404837905495\n",
      "Error on this batch = 0.1414228945325197\n",
      "Cost on val dataset after 119 epochs is = 0.1432322002907666\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.1432322002907666\n",
      "learning rate for this epoch =  0.1816621751851926\n",
      "Error on this batch = 0.10858117983037385\n",
      "Error on this batch = 0.14130838493364248\n",
      "Cost on val dataset after 120 epochs is = 0.14322584411067968\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.14322584411067968\n",
      "learning rate for this epoch =  0.18128252384140608\n",
      "Error on this batch = 0.10851986120233495\n",
      "Error on this batch = 0.14127814006286182\n",
      "Cost on val dataset after 121 epochs is = 0.14322426910580724\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.14322426910580724\n",
      "learning rate for this epoch =  0.18090680674665816\n",
      "Error on this batch = 0.10851785373165626\n",
      "Error on this batch = 0.14133651923356713\n",
      "Cost on val dataset after 122 epochs is = 0.14321987227933372\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.14321987227933372\n",
      "learning rate for this epoch =  0.18053495111835455\n",
      "Error on this batch = 0.10844319720510172\n",
      "Error on this batch = 0.14134037169224065\n",
      "Cost on val dataset after 123 epochs is = 0.14319784126174026\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.14319784126174026\n",
      "learning rate for this epoch =  0.1801668861029339\n",
      "Error on this batch = 0.10835417831353579\n",
      "Error on this batch = 0.1413457749734864\n",
      "Cost on val dataset after 124 epochs is = 0.14318653804338452\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.14318653804338452\n",
      "learning rate for this epoch =  0.17980254270954982\n",
      "Error on this batch = 0.10830867391656991\n",
      "Error on this batch = 0.14131848347607126\n",
      "Cost on val dataset after 125 epochs is = 0.1431713664706737\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.1431713664706737\n",
      "learning rate for this epoch =  0.17944185374654648\n",
      "Error on this batch = 0.10823622426408026\n",
      "Error on this batch = 0.14127247029690387\n",
      "Cost on val dataset after 126 epochs is = 0.14317881147611738\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.14317881147611738\n",
      "learning rate for this epoch =  0.17908475376058935\n",
      "Error on this batch = 0.1081487579292271\n",
      "Error on this batch = 0.14127213539590652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 127 epochs is = 0.1431944094613226\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.1431944094613226\n",
      "learning rate for this epoch =  0.17873117897831953\n",
      "Error on this batch = 0.108010507805764\n",
      "Error on this batch = 0.14128567010822124\n",
      "Cost on val dataset after 128 epochs is = 0.14321079907365275\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.14321079907365275\n",
      "learning rate for this epoch =  0.17838106725040817\n",
      "Error on this batch = 0.10787404054159819\n",
      "Error on this batch = 0.14132080934091237\n",
      "Cost on val dataset after 129 epochs is = 0.14319558982856898\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.14319558982856898\n",
      "learning rate for this epoch =  0.1780343579978945\n",
      "Error on this batch = 0.10774590167954631\n",
      "Error on this batch = 0.14130957137747654\n",
      "Cost on val dataset after 130 epochs is = 0.14323520487923305\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.14323520487923305\n",
      "learning rate for this epoch =  0.17769099216069748\n",
      "Error on this batch = 0.10760215132609378\n",
      "Error on this batch = 0.14129680152317117\n",
      "Cost on val dataset after 131 epochs is = 0.14322718345698654\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.14322718345698654\n",
      "learning rate for this epoch =  0.17735091214819665\n",
      "Error on this batch = 0.10743004920431444\n",
      "Error on this batch = 0.14138884870206034\n",
      "Cost on val dataset after 132 epochs is = 0.14321877229932295\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.14321877229932295\n",
      "learning rate for this epoch =  0.17701406179178425\n",
      "Error on this batch = 0.10720919287695829\n",
      "Error on this batch = 0.14141389765787107\n",
      "Cost on val dataset after 133 epochs is = 0.14322614322906324\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.14322614322906324\n",
      "learning rate for this epoch =  0.1766803862992956\n",
      "Error on this batch = 0.10696649644728527\n",
      "Error on this batch = 0.14148589525397537\n",
      "Cost on val dataset after 134 epochs is = 0.14324546733022098\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.14324546733022098\n",
      "learning rate for this epoch =  0.17634983221122996\n",
      "Error on this batch = 0.1066974256026128\n",
      "Error on this batch = 0.14144911398467996\n",
      "Cost on val dataset after 135 epochs is = 0.14326426855546565\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.14326426855546565\n",
      "learning rate for this epoch =  0.17602234735867867\n",
      "Error on this batch = 0.10646161405058885\n",
      "Error on this batch = 0.141410878171216\n",
      "Cost on val dataset after 136 epochs is = 0.14328123773933113\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.14328123773933113\n",
      "learning rate for this epoch =  0.17569788082288185\n",
      "Error on this batch = 0.10623749973759351\n",
      "Error on this batch = 0.14142548947344324\n",
      "Cost on val dataset after 137 epochs is = 0.14335328478478046\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.14335328478478046\n",
      "learning rate for this epoch =  0.17537638289633925\n",
      "Error on this batch = 0.10604436582212294\n",
      "Error on this batch = 0.14141920524823431\n",
      "Cost on val dataset after 138 epochs is = 0.14340011007813508\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.14340011007813508\n",
      "learning rate for this epoch =  0.1750578050454048\n",
      "Error on this batch = 0.10578071380532744\n",
      "Error on this batch = 0.14140163263262998\n",
      "Cost on val dataset after 139 epochs is = 0.14347845367295767\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.14347845367295767\n",
      "learning rate for this epoch =  0.17474209987429748\n",
      "Error on this batch = 0.1055364130043497\n",
      "Error on this batch = 0.14140686154028476\n",
      "Cost on val dataset after 140 epochs is = 0.1435390701117154\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.1435390701117154\n",
      "learning rate for this epoch =  0.17442922109046577\n",
      "Error on this batch = 0.10523919395425065\n",
      "Error on this batch = 0.14145894489734398\n",
      "Cost on val dataset after 141 epochs is = 0.14358343139367347\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.14358343139367347\n",
      "learning rate for this epoch =  0.17411912347124506\n",
      "Error on this batch = 0.10499257762884018\n",
      "Error on this batch = 0.14146340818147216\n",
      "Cost on val dataset after 142 epochs is = 0.14362003610521218\n",
      "cost initial= 0.14358343139367347 , cost final=0.14362003610521218 , change in cost= 3.6604711538712476e-05\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with ReLU are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with ReLU is = 142\n",
      "The training time with ReLU is = 31.376sec\n",
      "The training accuracy with ReLU is = 87.493%\n",
      "The validation accuracy with ReLU is = 84.410%\n",
      "The test accuracy with ReLU is = 82.246%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.6\n",
    "theta = theta_init(arch, 'uniform')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'relu', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'relu'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'relu'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'relu'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with ReLU are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with ReLU is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with ReLU is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with ReLU is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with ReLU is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with ReLU is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part D-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with SoftPlus activation------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part D-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with SoftPlus activation------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 3.169749253249961\n",
      "learning rate for this epoch =  0.6\n",
      "Error on this batch = 3.1697818465240726\n",
      "Error on this batch = 0.4810979550928137\n",
      "Cost on val dataset after 2 epochs is = 0.4802139402961179\n",
      "Initial Cost on Val dataset for this epoch 2 = 0.4802139402961179\n",
      "learning rate for this epoch =  0.5045378491522288\n",
      "Error on this batch = 0.4802047533498978\n",
      "Error on this batch = 0.4799700796442059\n",
      "Cost on val dataset after 3 epochs is = 0.47946731702945616\n",
      "Initial Cost on Val dataset for this epoch 3 = 0.47946731702945616\n",
      "learning rate for this epoch =  0.4559014113909555\n",
      "Error on this batch = 0.47953634791844635\n",
      "Error on this batch = 0.4791782250440923\n",
      "Cost on val dataset after 4 epochs is = 0.47848492728053826\n",
      "Initial Cost on Val dataset for this epoch 4 = 0.47848492728053826\n",
      "learning rate for this epoch =  0.42426406871192845\n",
      "Error on this batch = 0.4786670279735221\n",
      "Error on this batch = 0.4779748829272543\n",
      "Cost on val dataset after 5 epochs is = 0.4768865395483664\n",
      "Initial Cost on Val dataset for this epoch 5 = 0.4768865395483664\n",
      "learning rate for this epoch =  0.40124418298585324\n",
      "Error on this batch = 0.4773992007937589\n",
      "Error on this batch = 0.47551965857622613\n",
      "Cost on val dataset after 6 epochs is = 0.4732518640025231\n",
      "Initial Cost on Val dataset for this epoch 6 = 0.4732518640025231\n",
      "learning rate for this epoch =  0.38336586254776345\n",
      "Error on this batch = 0.4750854674469506\n",
      "Error on this batch = 0.46723869252068284\n",
      "Cost on val dataset after 7 epochs is = 0.461986740408815\n",
      "Initial Cost on Val dataset for this epoch 7 = 0.461986740408815\n",
      "learning rate for this epoch =  0.3688728917707586\n",
      "Error on this batch = 0.46901417183139843\n",
      "Error on this batch = 0.4512820838197128\n",
      "Cost on val dataset after 8 epochs is = 0.44072409584153355\n",
      "Initial Cost on Val dataset for this epoch 8 = 0.44072409584153355\n",
      "learning rate for this epoch =  0.35676213450081634\n",
      "Error on this batch = 0.4507815405463617\n",
      "Error on this batch = 0.42917332213977705\n",
      "Cost on val dataset after 9 epochs is = 0.4069580407536897\n",
      "Initial Cost on Val dataset for this epoch 9 = 0.4069580407536897\n",
      "learning rate for this epoch =  0.34641016151377546\n",
      "Error on this batch = 0.41637226698125257\n",
      "Error on this batch = 0.39305763787974074\n",
      "Cost on val dataset after 10 epochs is = 0.3598866792160002\n",
      "Initial Cost on Val dataset for this epoch 10 = 0.3598866792160002\n",
      "learning rate for this epoch =  0.33740479511420945\n",
      "Error on this batch = 0.3677858343290349\n",
      "Error on this batch = 0.35938564032109666\n",
      "Cost on val dataset after 11 epochs is = 0.3168356542032035\n",
      "Initial Cost on Val dataset for this epoch 11 = 0.3168356542032035\n",
      "learning rate for this epoch =  0.32946029206566746\n",
      "Error on this batch = 0.31714228337769373\n",
      "Error on this batch = 0.32774528635087374\n",
      "Cost on val dataset after 12 epochs is = 0.28150535019178435\n",
      "Initial Cost on Val dataset for this epoch 12 = 0.28150535019178435\n",
      "learning rate for this epoch =  0.32237097954706256\n",
      "Error on this batch = 0.27821536791565016\n",
      "Error on this batch = 0.29939113713375\n",
      "Cost on val dataset after 13 epochs is = 0.2522369711728277\n",
      "Initial Cost on Val dataset for this epoch 13 = 0.2522369711728277\n",
      "learning rate for this epoch =  0.315984232708756\n",
      "Error on this batch = 0.24587694169034507\n",
      "Error on this batch = 0.27363004901615934\n",
      "Cost on val dataset after 14 epochs is = 0.2294174569124826\n",
      "Initial Cost on Val dataset for this epoch 14 = 0.2294174569124826\n",
      "learning rate for this epoch =  0.31018389237430233\n",
      "Error on this batch = 0.22052775116027767\n",
      "Error on this batch = 0.2530670297432253\n",
      "Cost on val dataset after 15 epochs is = 0.21107967555475698\n",
      "Initial Cost on Val dataset for this epoch 15 = 0.21107967555475698\n",
      "learning rate for this epoch =  0.30487964889276886\n",
      "Error on this batch = 0.20105853307243915\n",
      "Error on this batch = 0.2348087101417012\n",
      "Cost on val dataset after 16 epochs is = 0.19654320342185932\n",
      "Initial Cost on Val dataset for this epoch 16 = 0.19654320342185932\n",
      "learning rate for this epoch =  0.3\n",
      "Error on this batch = 0.18484965366822756\n",
      "Error on this batch = 0.21890060925321414\n",
      "Cost on val dataset after 17 epochs is = 0.18537813030506858\n",
      "Initial Cost on Val dataset for this epoch 17 = 0.18537813030506858\n",
      "learning rate for this epoch =  0.2954874363032714\n",
      "Error on this batch = 0.17189521234287392\n",
      "Error on this batch = 0.20658008171095632\n",
      "Cost on val dataset after 18 epochs is = 0.17685889443213876\n",
      "Initial Cost on Val dataset for this epoch 18 = 0.17685889443213876\n",
      "learning rate for this epoch =  0.29129506302439406\n",
      "Error on this batch = 0.1618162759993181\n",
      "Error on this batch = 0.19690742289355462\n",
      "Cost on val dataset after 19 epochs is = 0.1700527746633301\n",
      "Initial Cost on Val dataset for this epoch 19 = 0.1700527746633301\n",
      "learning rate for this epoch =  0.2873841752661448\n",
      "Error on this batch = 0.1537571316041333\n",
      "Error on this batch = 0.1887124791034018\n",
      "Cost on val dataset after 20 epochs is = 0.16441696443545825\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.16441696443545825\n",
      "learning rate for this epoch =  0.28372248270095274\n",
      "Error on this batch = 0.1471176966813967\n",
      "Error on this batch = 0.1815010469595436\n",
      "Cost on val dataset after 21 epochs is = 0.15966449148146633\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.15966449148146633\n",
      "learning rate for this epoch =  0.28028278663692\n",
      "Error on this batch = 0.1414534996104092\n",
      "Error on this batch = 0.17508281632456343\n",
      "Cost on val dataset after 22 epochs is = 0.15562976182758836\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.15562976182758836\n",
      "learning rate for this epoch =  0.27704197856646157\n",
      "Error on this batch = 0.1364905754462906\n",
      "Error on this batch = 0.16932248806579345\n",
      "Cost on val dataset after 23 epochs is = 0.15217419293780093\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.15217419293780093\n",
      "learning rate for this epoch =  0.27398027129803876\n",
      "Error on this batch = 0.13202578458043132\n",
      "Error on this batch = 0.1641154458125604\n",
      "Cost on val dataset after 24 epochs is = 0.14917013198197876\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.14917013198197876\n",
      "learning rate for this epoch =  0.27108060108295345\n",
      "Error on this batch = 0.12790631656046228\n",
      "Error on this batch = 0.15938024290911101\n",
      "Cost on val dataset after 25 epochs is = 0.14651034637245244\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.14651034637245244\n",
      "learning rate for this epoch =  0.2683281572999747\n",
      "Error on this batch = 0.12403454036811336\n",
      "Error on this batch = 0.15505716048222762\n",
      "Cost on val dataset after 26 epochs is = 0.1441155433274217\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.1441155433274217\n",
      "learning rate for this epoch =  0.2657100085614884\n",
      "Error on this batch = 0.12036834116135228\n",
      "Error on this batch = 0.15110658905531707\n",
      "Cost on val dataset after 27 epochs is = 0.1419359385241241\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.1419359385241241\n",
      "learning rate for this epoch =  0.2632148025904985\n",
      "Error on this batch = 0.11691234066909957\n",
      "Error on this batch = 0.14750098356838318\n",
      "Cost on val dataset after 28 epochs is = 0.13994312677240436\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.13994312677240436\n",
      "learning rate for this epoch =  0.26083252316699485\n",
      "Error on this batch = 0.11369268532332051\n",
      "Error on this batch = 0.14421515340350702\n",
      "Cost on val dataset after 29 epochs is = 0.13811834899776762\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.13811834899776762\n",
      "learning rate for this epoch =  0.2585542916753436\n",
      "Error on this batch = 0.11072694433868349\n",
      "Error on this batch = 0.14122027596983622\n",
      "Cost on val dataset after 30 epochs is = 0.13644510328360634\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.13644510328360634\n",
      "learning rate for this epoch =  0.2563722038377404\n",
      "Error on this batch = 0.10800907599397266\n",
      "Error on this batch = 0.13848358819918777\n",
      "Cost on val dataset after 31 epochs is = 0.1349068327613328\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.1349068327613328\n",
      "learning rate for this epoch =  0.254279194449013\n",
      "Error on this batch = 0.10551249428543592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1359714525268122\n",
      "Cost on val dataset after 32 epochs is = 0.1334873406811834\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.1334873406811834\n",
      "learning rate for this epoch =  0.2522689245761144\n",
      "Error on this batch = 0.10320101075596268\n",
      "Error on this batch = 0.13365218396668824\n",
      "Cost on val dataset after 33 epochs is = 0.13217177801331023\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.13217177801331023\n",
      "learning rate for this epoch =  0.2503356869166904\n",
      "Error on this batch = 0.10103859167442057\n",
      "Error on this batch = 0.1314972604796129\n",
      "Cost on val dataset after 34 epochs is = 0.1309471818972203\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.1309471818972203\n",
      "learning rate for this epoch =  0.2484743259399312\n",
      "Error on this batch = 0.0989949282852642\n",
      "Error on this batch = 0.12948160767668537\n",
      "Cost on val dataset after 35 epochs is = 0.12980237283762594\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.12980237283762594\n",
      "learning rate for this epoch =  0.2466801701403118\n",
      "Error on this batch = 0.09704726619984438\n",
      "Error on this batch = 0.1275837185945702\n",
      "Cost on val dataset after 36 epochs is = 0.1287274513051758\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.1287274513051758\n",
      "learning rate for this epoch =  0.24494897427831783\n",
      "Error on this batch = 0.09517957046923396\n",
      "Error on this batch = 0.1257856708222958\n",
      "Cost on val dataset after 37 epochs is = 0.1277132751523255\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.1277132751523255\n",
      "learning rate for this epoch =  0.2432768699032619\n",
      "Error on this batch = 0.09338020295518444\n",
      "Error on this batch = 0.124072948404619\n",
      "Cost on val dataset after 38 epochs is = 0.12675117051706755\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.12675117051706755\n",
      "learning rate for this epoch =  0.24166032278194638\n",
      "Error on this batch = 0.09163966076458266\n",
      "Error on this batch = 0.12243424781007411\n",
      "Cost on val dataset after 39 epochs is = 0.12583291786296966\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.12583291786296966\n",
      "learning rate for this epoch =  0.24009609611534996\n",
      "Error on this batch = 0.0899496518828857\n",
      "Error on this batch = 0.12086139641214576\n",
      "Cost on val dataset after 40 epochs is = 0.1249509259371227\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.1249509259371227\n",
      "learning rate for this epoch =  0.23858121863011517\n",
      "Error on this batch = 0.0883035898002632\n",
      "Error on this batch = 0.11934915154553903\n",
      "Cost on val dataset after 41 epochs is = 0.12409847149002273\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.12409847149002273\n",
      "learning rate for this epoch =  0.23711295679464287\n",
      "Error on this batch = 0.08669763564936617\n",
      "Error on this batch = 0.11789456811097265\n",
      "Cost on val dataset after 42 epochs is = 0.12326990031644137\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.12326990031644137\n",
      "learning rate for this epoch =  0.2356887905403078\n",
      "Error on this batch = 0.08513135284281736\n",
      "Error on this batch = 0.11649595429086407\n",
      "Cost on val dataset after 43 epochs is = 0.12246073523132428\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.12246073523132428\n",
      "learning rate for this epoch =  0.23430639197370967\n",
      "Error on this batch = 0.08360747751495731\n",
      "Error on this batch = 0.11515179014353645\n",
      "Cost on val dataset after 44 epochs is = 0.12166769370557266\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.12166769370557266\n",
      "learning rate for this epoch =  0.23296360665133395\n",
      "Error on this batch = 0.08213083064042563\n",
      "Error on this batch = 0.11386000659861009\n",
      "Cost on val dataset after 45 epochs is = 0.12088864114999169\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.12088864114999169\n",
      "learning rate for this epoch =  0.23165843705765382\n",
      "Error on this batch = 0.08070679304770291\n",
      "Error on this batch = 0.11261774524593214\n",
      "Cost on val dataset after 46 epochs is = 0.12012249427211728\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.12012249427211728\n",
      "learning rate for this epoch =  0.23038902798476096\n",
      "Error on this batch = 0.07933988481694768\n",
      "Error on this batch = 0.11142144924510809\n",
      "Cost on val dataset after 47 epochs is = 0.11936908158625543\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.11936908158625543\n",
      "learning rate for this epoch =  0.229153653558572\n",
      "Error on this batch = 0.07803284020380076\n",
      "Error on this batch = 0.11026706738745773\n",
      "Cost on val dataset after 48 epochs is = 0.11862897180779111\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.11862897180779111\n",
      "learning rate for this epoch =  0.22795070569547776\n",
      "Error on this batch = 0.07678630841771739\n",
      "Error on this batch = 0.10915024034731445\n",
      "Cost on val dataset after 49 epochs is = 0.11790326976557929\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.11790326976557929\n",
      "learning rate for this epoch =  0.2267786838055363\n",
      "Error on this batch = 0.07559908950220023\n",
      "Error on this batch = 0.10806645262351952\n",
      "Cost on val dataset after 50 epochs is = 0.11719336055150323\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.11719336055150323\n",
      "learning rate for this epoch =  0.2256361855851836\n",
      "Error on this batch = 0.07446867528315117\n",
      "Error on this batch = 0.10701118973227906\n",
      "Cost on val dataset after 51 epochs is = 0.11650059965376272\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.11650059965376272\n",
      "learning rate for this epoch =  0.22452189876492748\n",
      "Error on this batch = 0.0733918184031793\n",
      "Error on this batch = 0.10598012189280978\n",
      "Cost on val dataset after 52 epochs is = 0.11582600610504709\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.11582600610504709\n",
      "learning rate for this epoch =  0.22343459369638943\n",
      "Error on this batch = 0.07236493199163001\n",
      "Error on this batch = 0.1049692918547623\n",
      "Cost on val dataset after 53 epochs is = 0.11517005247196602\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.11517005247196602\n",
      "learning rate for this epoch =  0.2223731166789908\n",
      "Error on this batch = 0.07138428764019675\n",
      "Error on this batch = 0.1039752746902845\n",
      "Cost on val dataset after 54 epochs is = 0.1145326043212677\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.1145326043212677\n",
      "learning rate for this epoch =  0.22133638394006433\n",
      "Error on this batch = 0.07044609279192432\n",
      "Error on this batch = 0.10299530178293181\n",
      "Cost on val dataset after 55 epochs is = 0.11391297374193846\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.11391297374193846\n",
      "learning rate for this epoch =  0.2203233761936155\n",
      "Error on this batch = 0.06954652192245042\n",
      "Error on this batch = 0.10202735845238699\n",
      "Cost on val dataset after 56 epochs is = 0.11330998386290768\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.11330998386290768\n",
      "learning rate for this epoch =  0.21933313371270743\n",
      "Error on this batch = 0.06868171076517987\n",
      "Error on this batch = 0.10107026658128954\n",
      "Cost on val dataset after 57 epochs is = 0.11272192119113336\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.11272192119113336\n",
      "learning rate for this epoch =  0.21836475185876858\n",
      "Error on this batch = 0.06784767748670939\n",
      "Error on this batch = 0.10012378895859891\n",
      "Cost on val dataset after 58 epochs is = 0.11214632753951972\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.11214632753951972\n",
      "learning rate for this epoch =  0.21741737701825978\n",
      "Error on this batch = 0.0670401710005178\n",
      "Error on this batch = 0.09918882631767009\n",
      "Cost on val dataset after 59 epochs is = 0.11157992348057419\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.11157992348057419\n",
      "learning rate for this epoch =  0.2164902029032644\n",
      "Error on this batch = 0.06625466637937766\n",
      "Error on this batch = 0.09826751500511764\n",
      "Cost on val dataset after 60 epochs is = 0.11101932742491392\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.11101932742491392\n",
      "learning rate for this epoch =  0.21558246717785054\n",
      "Error on this batch = 0.0654869202776958\n",
      "Error on this batch = 0.09736235287859568\n",
      "Cost on val dataset after 61 epochs is = 0.11046231470562062\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.11046231470562062\n",
      "learning rate for this epoch =  0.2146934483766157\n",
      "Error on this batch = 0.0647337557901379\n",
      "Error on this batch = 0.09647438378623573\n",
      "Cost on val dataset after 62 epochs is = 0.10990815231451001\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.10990815231451001\n",
      "learning rate for this epoch =  0.21382246308577726\n",
      "Error on this batch = 0.06399303331551173\n",
      "Error on this batch = 0.09560250446544438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 63 epochs is = 0.10935697714041495\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.10935697714041495\n",
      "learning rate for this epoch =  0.21296886336060317\n",
      "Error on this batch = 0.06326312435793995\n",
      "Error on this batch = 0.09474424486710618\n",
      "Cost on val dataset after 64 epochs is = 0.10880915542331313\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.10880915542331313\n",
      "learning rate for this epoch =  0.21213203435596423\n",
      "Error on this batch = 0.06254264746887431\n",
      "Error on this batch = 0.09389662105754791\n",
      "Cost on val dataset after 65 epochs is = 0.10826487815365343\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.10826487815365343\n",
      "learning rate for this epoch =  0.21131139214939415\n",
      "Error on this batch = 0.0618303712683154\n",
      "Error on this batch = 0.09305657817836097\n",
      "Cost on val dataset after 66 epochs is = 0.10772411311404662\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.10772411311404662\n",
      "learning rate for this epoch =  0.21050638173832112\n",
      "Error on this batch = 0.06112520018037244\n",
      "Error on this batch = 0.09222088784676094\n",
      "Cost on val dataset after 67 epochs is = 0.10718705833365162\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.10718705833365162\n",
      "learning rate for this epoch =  0.20971647519513073\n",
      "Error on this batch = 0.06042629045420823\n",
      "Error on this batch = 0.09138489105045983\n",
      "Cost on val dataset after 68 epochs is = 0.10665506337886008\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.10665506337886008\n",
      "learning rate for this epoch =  0.2089411699654712\n",
      "Error on this batch = 0.059733319701897\n",
      "Error on this batch = 0.09054024214763173\n",
      "Cost on val dataset after 69 epochs is = 0.10613165502945528\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.10613165502945528\n",
      "learning rate for this epoch =  0.2081799872967546\n",
      "Error on this batch = 0.059046834310191657\n",
      "Error on this batch = 0.08967683191913556\n",
      "Cost on val dataset after 70 epochs is = 0.1056218853359305\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.1056218853359305\n",
      "learning rate for this epoch =  0.2074324707851646\n",
      "Error on this batch = 0.05836778818058047\n",
      "Error on this batch = 0.08879397358818306\n",
      "Cost on val dataset after 71 epochs is = 0.10512843157696922\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.10512843157696922\n",
      "learning rate for this epoch =  0.2066981850306836\n",
      "Error on this batch = 0.057695634309228104\n",
      "Error on this batch = 0.08790157736810032\n",
      "Cost on val dataset after 72 epochs is = 0.10465026937046637\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.10465026937046637\n",
      "learning rate for this epoch =  0.20597671439071177\n",
      "Error on this batch = 0.05702854086299674\n",
      "Error on this batch = 0.08700636858884646\n",
      "Cost on val dataset after 73 epochs is = 0.10418611719734559\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.10418611719734559\n",
      "learning rate for this epoch =  0.20526766182379289\n",
      "Error on this batch = 0.05636588470657827\n",
      "Error on this batch = 0.08610981996904618\n",
      "Cost on val dataset after 74 epochs is = 0.10373595895772605\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.10373595895772605\n",
      "learning rate for this epoch =  0.20457064781579723\n",
      "Error on this batch = 0.05570851623001657\n",
      "Error on this batch = 0.08521267747992452\n",
      "Cost on val dataset after 75 epochs is = 0.10330047674762013\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.10330047674762013\n",
      "learning rate for this epoch =  0.2038853093816547\n",
      "Error on this batch = 0.055057558973050556\n",
      "Error on this batch = 0.08431629608859467\n",
      "Cost on val dataset after 76 epochs is = 0.10288031775057017\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.10288031775057017\n",
      "learning rate for this epoch =  0.20321129913639427\n",
      "Error on this batch = 0.054413492955240984\n",
      "Error on this batch = 0.08342178298761324\n",
      "Cost on val dataset after 77 epochs is = 0.10247575756696772\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.10247575756696772\n",
      "learning rate for this epoch =  0.2025482844298358\n",
      "Error on this batch = 0.05377615029510681\n",
      "Error on this batch = 0.0825291811850729\n",
      "Cost on val dataset after 78 epochs is = 0.10208658174869227\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.10208658174869227\n",
      "learning rate for this epoch =  0.20189594653980908\n",
      "Error on this batch = 0.05314518647982871\n",
      "Error on this batch = 0.0816369299662993\n",
      "Cost on val dataset after 79 epochs is = 0.10171193793305897\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.10171193793305897\n",
      "learning rate for this epoch =  0.20125397991924746\n",
      "Error on this batch = 0.05252036221236986\n",
      "Error on this batch = 0.08074262687035344\n",
      "Cost on val dataset after 80 epochs is = 0.10135025682795067\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.10135025682795067\n",
      "learning rate for this epoch =  0.20062209149292662\n",
      "Error on this batch = 0.05190155527118202\n",
      "Error on this batch = 0.07984682642156285\n",
      "Cost on val dataset after 81 epochs is = 0.10099966471809645\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.10099966471809645\n",
      "learning rate for this epoch =  0.19999999999999998\n",
      "Error on this batch = 0.051288658033609935\n",
      "Error on this batch = 0.07895722928087047\n",
      "Cost on val dataset after 82 epochs is = 0.10065885738186901\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.10065885738186901\n",
      "learning rate for this epoch =  0.19938743537882408\n",
      "Error on this batch = 0.05068150003307741\n",
      "Error on this batch = 0.07808679998811503\n",
      "Cost on val dataset after 83 epochs is = 0.10032746832358583\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.10032746832358583\n",
      "learning rate for this epoch =  0.1987841381908741\n",
      "Error on this batch = 0.05007994571759161\n",
      "Error on this batch = 0.07724838314289247\n",
      "Cost on val dataset after 84 epochs is = 0.100005623508497\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.100005623508497\n",
      "learning rate for this epoch =  0.19818985908082842\n",
      "Error on this batch = 0.04948402112325673\n",
      "Error on this batch = 0.07645199379740177\n",
      "Cost on val dataset after 85 epochs is = 0.09969348642558346\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.09969348642558346\n",
      "learning rate for this epoch =  0.1976043582701508\n",
      "Error on this batch = 0.04889385571315285\n",
      "Error on this batch = 0.07570416519225438\n",
      "Cost on val dataset after 86 epochs is = 0.0993911417179877\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.0993911417179877\n",
      "learning rate for this epoch =  0.19702740508172414\n",
      "Error on this batch = 0.04830952470758545\n",
      "Error on this batch = 0.07500773755182176\n",
      "Cost on val dataset after 87 epochs is = 0.09909861732608892\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.09909861732608892\n",
      "learning rate for this epoch =  0.19645877749329657\n",
      "Error on this batch = 0.047730975904058434\n",
      "Error on this batch = 0.07436217976470615\n",
      "Cost on val dataset after 88 epochs is = 0.09881588856940006\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.09881588856940006\n",
      "learning rate for this epoch =  0.19589826171768313\n",
      "Error on this batch = 0.047158106104862596\n",
      "Error on this batch = 0.07376453433380281\n",
      "Cost on val dataset after 89 epochs is = 0.09854285504044505\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.09854285504044505\n",
      "learning rate for this epoch =  0.1953456518078377\n",
      "Error on this batch = 0.046590923046522924\n",
      "Error on this batch = 0.07321056058310647\n",
      "Cost on val dataset after 90 epochs is = 0.09827932961953408\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.09827932961953408\n",
      "learning rate for this epoch =  0.19480074928505933\n",
      "Error on this batch = 0.04602969798626472\n",
      "Error on this batch = 0.0726956343487511\n",
      "Cost on val dataset after 91 epochs is = 0.098025059318318\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.098025059318318\n",
      "learning rate for this epoch =  0.19426336278873857\n",
      "Error on this batch = 0.04547505177289974\n",
      "Error on this batch = 0.07221524311474431\n",
      "Cost on val dataset after 92 epochs is = 0.09777976955583226\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.09777976955583226\n",
      "learning rate for this epoch =  0.1937333077461732\n",
      "Error on this batch = 0.044927952575305935\n",
      "Error on this batch = 0.07176509667942775\n",
      "Cost on val dataset after 93 epochs is = 0.09754321537163228\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.09754321537163228\n",
      "learning rate for this epoch =  0.19321040606110043\n",
      "Error on this batch = 0.04438961291020798\n",
      "Error on this batch = 0.07134090009659753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 94 epochs is = 0.09731522878210733\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.09731522878210733\n",
      "learning rate for this epoch =  0.1926944858196948\n",
      "Error on this batch = 0.04386127598267702\n",
      "Error on this batch = 0.07093792970764955\n",
      "Cost on val dataset after 95 epochs is = 0.0970957483852666\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.0970957483852666\n",
      "learning rate for this epoch =  0.1921853810128792\n",
      "Error on this batch = 0.0433439118467432\n",
      "Error on this batch = 0.07055096849425196\n",
      "Cost on val dataset after 96 epochs is = 0.09688479179902848\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.09688479179902848\n",
      "learning rate for this epoch =  0.19168293127388172\n",
      "Error on this batch = 0.04283794619154053\n",
      "Error on this batch = 0.07017534819929719\n",
      "Cost on val dataset after 97 epochs is = 0.09668233270757927\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.09668233270757927\n",
      "learning rate for this epoch =  0.19118698163005315\n",
      "Error on this batch = 0.042343261592648236\n",
      "Error on this batch = 0.06980838785294072\n",
      "Cost on val dataset after 98 epochs is = 0.09648815290960064\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.09648815290960064\n",
      "learning rate for this epoch =  0.19069738226803112\n",
      "Error on this batch = 0.04185955797251152\n",
      "Error on this batch = 0.06944929204595449\n",
      "Cost on val dataset after 99 epochs is = 0.09630181913286227\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.09630181913286227\n",
      "learning rate for this epoch =  0.19021398831140582\n",
      "Error on this batch = 0.04138675418834478\n",
      "Error on this batch = 0.06909779872818987\n",
      "Cost on val dataset after 100 epochs is = 0.09612279343997411\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.09612279343997411\n",
      "learning rate for this epoch =  0.18973665961010275\n",
      "Error on this batch = 0.04092509380089578\n",
      "Error on this batch = 0.06875333890348748\n",
      "Cost on val dataset after 101 epochs is = 0.09595055323115935\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.09595055323115935\n",
      "learning rate for this epoch =  0.1892652605407543\n",
      "Error on this batch = 0.04047500104257629\n",
      "Error on this batch = 0.06841500194804785\n",
      "Cost on val dataset after 102 epochs is = 0.09578465030490269\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.09578465030490269\n",
      "learning rate for this epoch =  0.18879965981738495\n",
      "Error on this batch = 0.04003690161985577\n",
      "Error on this batch = 0.0680817384154247\n",
      "Cost on val dataset after 103 epochs is = 0.09562471907789225\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.09562471907789225\n",
      "learning rate for this epoch =  0.1883397303117814\n",
      "Error on this batch = 0.039611117327076006\n",
      "Error on this batch = 0.06775250205917255\n",
      "Cost on val dataset after 104 epochs is = 0.0954704612716345\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.0954704612716345\n",
      "learning rate for this epoch =  0.18788534888296407\n",
      "Error on this batch = 0.039197833891104025\n",
      "Error on this batch = 0.06742630650312502\n",
      "Cost on val dataset after 105 epochs is = 0.09532162364007\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.09532162364007\n",
      "learning rate for this epoch =  0.18743639621521535\n",
      "Error on this batch = 0.03879711094985732\n",
      "Error on this batch = 0.06710223698392023\n",
      "Cost on val dataset after 106 epochs is = 0.09517797621200659\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.09517797621200659\n",
      "learning rate for this epoch =  0.18699275666415935\n",
      "Error on this batch = 0.03840891048477671\n",
      "Error on this batch = 0.06677945607794596\n",
      "Cost on val dataset after 107 epochs is = 0.09503929443644847\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.09503929443644847\n",
      "learning rate for this epoch =  0.18655431811042028\n",
      "Error on this batch = 0.038033131953129164\n",
      "Error on this batch = 0.06645724728457186\n",
      "Cost on val dataset after 108 epochs is = 0.0949053461214647\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.0949053461214647\n",
      "learning rate for this epoch =  0.18612097182041992\n",
      "Error on this batch = 0.037669648875065034\n",
      "Error on this batch = 0.06613515477144637\n",
      "Cost on val dataset after 109 epochs is = 0.09477588215813118\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.09477588215813118\n",
      "learning rate for this epoch =  0.1856926123139029\n",
      "Error on this batch = 0.037318341116717495\n",
      "Error on this batch = 0.06581325681118975\n",
      "Cost on val dataset after 110 epochs is = 0.09465063155844598\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.09465063155844598\n",
      "learning rate for this epoch =  0.18526913723780689\n",
      "Error on this batch = 0.03697911202811236\n",
      "Error on this batch = 0.06549248782195523\n",
      "Cost on val dataset after 111 epochs is = 0.09452930722262995\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.09452930722262995\n",
      "learning rate for this epoch =  0.1848504472461183\n",
      "Error on this batch = 0.03665187971053287\n",
      "Error on this batch = 0.06517474212924006\n",
      "Cost on val dataset after 112 epochs is = 0.09441162926106102\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.09441162926106102\n",
      "learning rate for this epoch =  0.1844364458853793\n",
      "Error on this batch = 0.036336547219540674\n",
      "Error on this batch = 0.06486251908424669\n",
      "Cost on val dataset after 113 epochs is = 0.09429735761651292\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.09429735761651292\n",
      "learning rate for this epoch =  0.18402703948553187\n",
      "Error on this batch = 0.03603297622985071\n",
      "Error on this batch = 0.06455825569077732\n",
      "Cost on val dataset after 114 epochs is = 0.09418631141038676\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.09418631141038676\n",
      "learning rate for this epoch =  0.18362213705580538\n",
      "Error on this batch = 0.03574098444048806\n",
      "Error on this batch = 0.06426380860978652\n",
      "Cost on val dataset after 115 epochs is = 0.09407836384252383\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.09407836384252383\n",
      "learning rate for this epoch =  0.18322165018537329\n",
      "Error on this batch = 0.03546036085901245\n",
      "Error on this batch = 0.06398035484111157\n",
      "Cost on val dataset after 116 epochs is = 0.09397342618092275\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.09397342618092275\n",
      "learning rate for this epoch =  0.18282549294852\n",
      "Error on this batch = 0.035190878722027245\n",
      "Error on this batch = 0.06370859585033216\n",
      "Cost on val dataset after 117 epochs is = 0.09387144232075936\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.09387144232075936\n",
      "learning rate for this epoch =  0.1824335818140776\n",
      "Error on this batch = 0.03493229344874008\n",
      "Error on this batch = 0.06344902534463781\n",
      "Cost on val dataset after 118 epochs is = 0.09377240469502995\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.09377240469502995\n",
      "learning rate for this epoch =  0.18204583555890436\n",
      "Error on this batch = 0.03468432582031594\n",
      "Error on this batch = 0.06320209950508775\n",
      "Cost on val dataset after 119 epochs is = 0.09367638799516262\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.09367638799516262\n",
      "learning rate for this epoch =  0.1816621751851926\n",
      "Error on this batch = 0.03444663827329489\n",
      "Error on this batch = 0.06296821891240079\n",
      "Cost on val dataset after 120 epochs is = 0.09358358313208356\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.09358358313208356\n",
      "learning rate for this epoch =  0.18128252384140608\n",
      "Error on this batch = 0.0342188136889584\n",
      "Error on this batch = 0.06274748886130403\n",
      "Cost on val dataset after 121 epochs is = 0.09349429792116443\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.09349429792116443\n",
      "learning rate for this epoch =  0.18090680674665816\n",
      "Error on this batch = 0.03400034098027778\n",
      "Error on this batch = 0.06253939311928385\n",
      "Cost on val dataset after 122 epochs is = 0.09340888706552843\n",
      "Initial Cost on Val dataset for this epoch 122 = 0.09340888706552843\n",
      "learning rate for this epoch =  0.18053495111835455\n",
      "Error on this batch = 0.03379061878320913\n",
      "Error on this batch = 0.062342756647641995\n",
      "Cost on val dataset after 123 epochs is = 0.09332760979574255\n",
      "Initial Cost on Val dataset for this epoch 123 = 0.09332760979574255\n",
      "learning rate for this epoch =  0.1801668861029339\n",
      "Error on this batch = 0.03358904012305451\n",
      "Error on this batch = 0.06215628477929105\n",
      "Cost on val dataset after 124 epochs is = 0.09325047961040392\n",
      "Initial Cost on Val dataset for this epoch 124 = 0.09325047961040392\n",
      "learning rate for this epoch =  0.17980254270954982\n",
      "Error on this batch = 0.0333952453277852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.06197926670648881\n",
      "Cost on val dataset after 125 epochs is = 0.09317720606359066\n",
      "Initial Cost on Val dataset for this epoch 125 = 0.09317720606359066\n",
      "learning rate for this epoch =  0.17944185374654648\n",
      "Error on this batch = 0.03320944634139013\n",
      "Error on this batch = 0.06181144368922901\n",
      "Cost on val dataset after 126 epochs is = 0.0931072894884437\n",
      "Initial Cost on Val dataset for this epoch 126 = 0.0931072894884437\n",
      "learning rate for this epoch =  0.17908475376058935\n",
      "Error on this batch = 0.033032437640539355\n",
      "Error on this batch = 0.061651613188645885\n",
      "Cost on val dataset after 127 epochs is = 0.09304022194638885\n",
      "Initial Cost on Val dataset for this epoch 127 = 0.09304022194638885\n",
      "learning rate for this epoch =  0.17873117897831953\n",
      "Error on this batch = 0.03286496001165659\n",
      "Error on this batch = 0.06149606152030662\n",
      "Cost on val dataset after 128 epochs is = 0.09297565887907237\n",
      "Initial Cost on Val dataset for this epoch 128 = 0.09297565887907237\n",
      "learning rate for this epoch =  0.17838106725040817\n",
      "Error on this batch = 0.03270666162705551\n",
      "Error on this batch = 0.06133977040287279\n",
      "Cost on val dataset after 129 epochs is = 0.09291343490921357\n",
      "Initial Cost on Val dataset for this epoch 129 = 0.09291343490921357\n",
      "learning rate for this epoch =  0.1780343579978945\n",
      "Error on this batch = 0.032555882265888236\n",
      "Error on this batch = 0.061180687686570236\n",
      "Cost on val dataset after 130 epochs is = 0.09285346201023184\n",
      "Initial Cost on Val dataset for this epoch 130 = 0.09285346201023184\n",
      "learning rate for this epoch =  0.17769099216069748\n",
      "Error on this batch = 0.03241100466187441\n",
      "Error on this batch = 0.06102039334866044\n",
      "Cost on val dataset after 131 epochs is = 0.09279568717339177\n",
      "Initial Cost on Val dataset for this epoch 131 = 0.09279568717339177\n",
      "learning rate for this epoch =  0.17735091214819665\n",
      "Error on this batch = 0.03227146941523903\n",
      "Error on this batch = 0.06086062377326888\n",
      "Cost on val dataset after 132 epochs is = 0.09274008824472953\n",
      "Initial Cost on Val dataset for this epoch 132 = 0.09274008824472953\n",
      "learning rate for this epoch =  0.17701406179178425\n",
      "Error on this batch = 0.03213733193785527\n",
      "Error on this batch = 0.06070175831228075\n",
      "Cost on val dataset after 133 epochs is = 0.092686633571344\n",
      "Initial Cost on Val dataset for this epoch 133 = 0.092686633571344\n",
      "learning rate for this epoch =  0.1766803862992956\n",
      "Error on this batch = 0.03200864580096102\n",
      "Error on this batch = 0.06054344265699399\n",
      "Cost on val dataset after 134 epochs is = 0.09263525699286966\n",
      "Initial Cost on Val dataset for this epoch 134 = 0.09263525699286966\n",
      "learning rate for this epoch =  0.17634983221122996\n",
      "Error on this batch = 0.0318852718427005\n",
      "Error on this batch = 0.06038525649016975\n",
      "Cost on val dataset after 135 epochs is = 0.09258586740740177\n",
      "Initial Cost on Val dataset for this epoch 135 = 0.09258586740740177\n",
      "learning rate for this epoch =  0.17602234735867867\n",
      "Error on this batch = 0.03176688123812913\n",
      "Error on this batch = 0.060226978016418235\n",
      "Cost on val dataset after 136 epochs is = 0.09253836826352749\n",
      "Initial Cost on Val dataset for this epoch 136 = 0.09253836826352749\n",
      "learning rate for this epoch =  0.17569788082288185\n",
      "Error on this batch = 0.031652998222647034\n",
      "Error on this batch = 0.060068620924397076\n",
      "Cost on val dataset after 137 epochs is = 0.09249267023849773\n",
      "Initial Cost on Val dataset for this epoch 137 = 0.09249267023849773\n",
      "learning rate for this epoch =  0.17537638289633925\n",
      "Error on this batch = 0.031543052488079606\n",
      "Error on this batch = 0.05991037467510742\n",
      "Cost on val dataset after 138 epochs is = 0.0924486940494256\n",
      "Initial Cost on Val dataset for this epoch 138 = 0.0924486940494256\n",
      "learning rate for this epoch =  0.1750578050454048\n",
      "Error on this batch = 0.03143643460340492\n",
      "Error on this batch = 0.05975251058180896\n",
      "Cost on val dataset after 139 epochs is = 0.092406366619059\n",
      "Initial Cost on Val dataset for this epoch 139 = 0.092406366619059\n",
      "learning rate for this epoch =  0.17474209987429748\n",
      "Error on this batch = 0.03133254728108088\n",
      "Error on this batch = 0.059595287730549035\n",
      "Cost on val dataset after 140 epochs is = 0.09236561527989698\n",
      "Initial Cost on Val dataset for this epoch 140 = 0.09236561527989698\n",
      "learning rate for this epoch =  0.17442922109046577\n",
      "Error on this batch = 0.03123084583563139\n",
      "Error on this batch = 0.0594388769578911\n",
      "Cost on val dataset after 141 epochs is = 0.0923263637416998\n",
      "Initial Cost on Val dataset for this epoch 141 = 0.0923263637416998\n",
      "learning rate for this epoch =  0.17411912347124506\n",
      "Error on this batch = 0.03113086444018441\n",
      "Error on this batch = 0.059283310727092\n",
      "Cost on val dataset after 142 epochs is = 0.09228853157021524\n",
      "Initial Cost on Val dataset for this epoch 142 = 0.09228853157021524\n",
      "learning rate for this epoch =  0.17381176283175084\n",
      "Error on this batch = 0.031032229076807107\n",
      "Error on this batch = 0.05912846041233861\n",
      "Cost on val dataset after 143 epochs is = 0.09225203672990458\n",
      "Initial Cost on Val dataset for this epoch 143 = 0.09225203672990458\n",
      "learning rate for this epoch =  0.17350709599395428\n",
      "Error on this batch = 0.030934661220171744\n",
      "Error on this batch = 0.05897403818472285\n",
      "Cost on val dataset after 144 epochs is = 0.0922167988692177\n",
      "Initial Cost on Val dataset for this epoch 144 = 0.0922167988692177\n",
      "learning rate for this epoch =  0.17320508075688773\n",
      "Error on this batch = 0.030837976794401502\n",
      "Error on this batch = 0.05881961830038188\n",
      "Cost on val dataset after 145 epochs is = 0.09218274027499136\n",
      "Initial Cost on Val dataset for this epoch 145 = 0.09218274027499136\n",
      "learning rate for this epoch =  0.17290567586793207\n",
      "Error on this batch = 0.030742083090235708\n",
      "Error on this batch = 0.05866467214826212\n",
      "Cost on val dataset after 146 epochs is = 0.09214978261942569\n",
      "Initial Cost on Val dataset for this epoch 146 = 0.09214978261942569\n",
      "learning rate for this epoch =  0.1726088409951392\n",
      "Error on this batch = 0.030646973807404665\n",
      "Error on this batch = 0.05850861015176696\n",
      "Cost on val dataset after 147 epochs is = 0.0921178403385767\n",
      "Initial Cost on Val dataset for this epoch 147 = 0.0921178403385767\n",
      "learning rate for this epoch =  0.1723145367005454\n",
      "Error on this batch = 0.03055272031865917\n",
      "Error on this batch = 0.058350818871358734\n",
      "Cost on val dataset after 148 epochs is = 0.09208681317798824\n",
      "Initial Cost on Val dataset for this epoch 148 = 0.09208681317798824\n",
      "learning rate for this epoch =  0.172022724414434\n",
      "Error on this batch = 0.030459454356908063\n",
      "Error on this batch = 0.05819067822167497\n",
      "Cost on val dataset after 149 epochs is = 0.0920565770699405\n",
      "Initial Cost on Val dataset for this epoch 149 = 0.0920565770699405\n",
      "learning rate for this epoch =  0.171733366410507\n",
      "Error on this batch = 0.03036733136622297\n",
      "Error on this batch = 0.05802755294522845\n",
      "Cost on val dataset after 150 epochs is = 0.09202695864767144\n",
      "Initial Cost on Val dataset for this epoch 150 = 0.09202695864767144\n",
      "learning rate for this epoch =  0.17144642578192795\n",
      "Error on this batch = 0.03027645794065555\n",
      "Error on this batch = 0.05786077437878309\n",
      "Cost on val dataset after 151 epochs is = 0.09199765047775983\n",
      "Initial Cost on Val dataset for this epoch 151 = 0.09199765047775983\n",
      "learning rate for this epoch =  0.1711618664182\n",
      "Error on this batch = 0.030186774432801974\n",
      "Error on this batch = 0.057689638409834924\n",
      "Cost on val dataset after 152 epochs is = 0.09196801168180706\n",
      "Initial Cost on Val dataset for this epoch 152 = 0.09196801168180706\n",
      "learning rate for this epoch =  0.1708796529828442\n",
      "Error on this batch = 0.03009792012512405\n",
      "Error on this batch = 0.05751341433761952\n",
      "Cost on val dataset after 153 epochs is = 0.09193683820812378\n",
      "Initial Cost on Val dataset for this epoch 153 = 0.09193683820812378\n",
      "learning rate for this epoch =  0.17059975089184612\n",
      "Error on this batch = 0.030009176606452154\n",
      "Error on this batch = 0.05733129240160908\n",
      "Cost on val dataset after 154 epochs is = 0.0919025443480611\n",
      "Initial Cost on Val dataset for this epoch 154 = 0.0919025443480611\n",
      "learning rate for this epoch =  0.17032212629283866\n",
      "Error on this batch = 0.02991964507005072\n",
      "Error on this batch = 0.05714220435913946\n",
      "Cost on val dataset after 155 epochs is = 0.0918640134144788\n",
      "Initial Cost on Val dataset for this epoch 155 = 0.0918640134144788\n",
      "learning rate for this epoch =  0.17004674604499187\n",
      "Error on this batch = 0.02982866604683233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.056944707971705796\n",
      "Cost on val dataset after 156 epochs is = 0.09182115605094236\n",
      "Initial Cost on Val dataset for this epoch 156 = 0.09182115605094236\n",
      "learning rate for this epoch =  0.16977357769958104\n",
      "Error on this batch = 0.029736085622672607\n",
      "Error on this batch = 0.05673719503704308\n",
      "Cost on val dataset after 157 epochs is = 0.09177444394926682\n",
      "Initial Cost on Val dataset for this epoch 157 = 0.09177444394926682\n",
      "learning rate for this epoch =  0.16950258948120644\n",
      "Error on this batch = 0.029642074729940543\n",
      "Error on this batch = 0.05651813188395937\n",
      "Cost on val dataset after 158 epochs is = 0.0917243329458087\n",
      "Initial Cost on Val dataset for this epoch 158 = 0.0917243329458087\n",
      "learning rate for this epoch =  0.16923375026963824\n",
      "Error on this batch = 0.029546964416228342\n",
      "Error on this batch = 0.0562861037892163\n",
      "Cost on val dataset after 159 epochs is = 0.09167128003303004\n",
      "Initial Cost on Val dataset for this epoch 159 = 0.09167128003303004\n",
      "learning rate for this epoch =  0.16896702958226256\n",
      "Error on this batch = 0.02945175901622716\n",
      "Error on this batch = 0.05604009681487569\n",
      "Cost on val dataset after 160 epochs is = 0.09161604190014558\n",
      "Initial Cost on Val dataset for this epoch 160 = 0.09161604190014558\n",
      "learning rate for this epoch =  0.16870239755710473\n",
      "Error on this batch = 0.029358767736324606\n",
      "Error on this batch = 0.05578016992098058\n",
      "Cost on val dataset after 161 epochs is = 0.0915596443442758\n",
      "Initial Cost on Val dataset for this epoch 161 = 0.0915596443442758\n",
      "learning rate for this epoch =  0.16843982493640752\n",
      "Error on this batch = 0.029270624171062663\n",
      "Error on this batch = 0.055507866938253186\n",
      "Cost on val dataset after 162 epochs is = 0.0915030344698297\n",
      "Initial Cost on Val dataset for this epoch 162 = 0.0915030344698297\n",
      "learning rate for this epoch =  0.1681792830507429\n",
      "Error on this batch = 0.02918829484415775\n",
      "Error on this batch = 0.055225959433431095\n",
      "Cost on val dataset after 163 epochs is = 0.09144690348137881\n",
      "Initial Cost on Val dataset for this epoch 163 = 0.09144690348137881\n",
      "learning rate for this epoch =  0.1679207438036363\n",
      "Error on this batch = 0.029110637810888466\n",
      "Error on this batch = 0.054937869161876006\n",
      "Cost on val dataset after 164 epochs is = 0.09139170270315672\n",
      "Initial Cost on Val dataset for this epoch 164 = 0.09139170270315672\n",
      "learning rate for this epoch =  0.16766417965668484\n",
      "Error on this batch = 0.02903548726904668\n",
      "Error on this batch = 0.054647125913870574\n",
      "Cost on val dataset after 165 epochs is = 0.09133765025466885\n",
      "Initial Cost on Val dataset for this epoch 165 = 0.09133765025466885\n",
      "learning rate for this epoch =  0.1674095636151496\n",
      "Error on this batch = 0.02896077202628723\n",
      "Error on this batch = 0.05435695156187233\n",
      "Cost on val dataset after 166 epochs is = 0.09128470800759497\n",
      "Initial Cost on Val dataset for this epoch 166 = 0.09128470800759497\n",
      "learning rate for this epoch =  0.16715686921400502\n",
      "Error on this batch = 0.02888507305863555\n",
      "Error on this batch = 0.054069989491820174\n",
      "Cost on val dataset after 167 epochs is = 0.09123258509032724\n",
      "Initial Cost on Val dataset for this epoch 167 = 0.09123258509032724\n",
      "learning rate for this epoch =  0.16690607050442752\n",
      "Error on this batch = 0.02880767727827839\n",
      "Error on this batch = 0.05378817731583478\n",
      "Cost on val dataset after 168 epochs is = 0.09118080982684494\n",
      "Initial Cost on Val dataset for this epoch 168 = 0.09118080982684494\n",
      "learning rate for this epoch =  0.16665714204070745\n",
      "Error on this batch = 0.028728345865903036\n",
      "Error on this batch = 0.05351273028685522\n",
      "Cost on val dataset after 169 epochs is = 0.09112888971121857\n",
      "Initial Cost on Val dataset for this epoch 169 = 0.09112888971121857\n",
      "learning rate for this epoch =  0.16641005886756874\n",
      "Error on this batch = 0.028647056493701094\n",
      "Error on this batch = 0.05324421137641478\n",
      "Cost on val dataset after 170 epochs is = 0.09107650802378994\n",
      "Initial Cost on Val dataset for this epoch 170 = 0.09107650802378994\n",
      "learning rate for this epoch =  0.1661647965078805\n",
      "Error on this batch = 0.02856388667131894\n",
      "Error on this batch = 0.05298270079834249\n",
      "Cost on val dataset after 171 epochs is = 0.09102363021557522\n",
      "Initial Cost on Val dataset for this epoch 171 = 0.09102363021557522\n",
      "learning rate for this epoch =  0.1659213309507473\n",
      "Error on this batch = 0.028479016400446432\n",
      "Error on this batch = 0.052728046587209865\n",
      "Cost on val dataset after 172 epochs is = 0.0909704504781755\n",
      "Initial Cost on Val dataset for this epoch 172 = 0.0909704504781755\n",
      "learning rate for this epoch =  0.16567963863996335\n",
      "Error on this batch = 0.028392735044195573\n",
      "Error on this batch = 0.0524800954017042\n",
      "Cost on val dataset after 173 epochs is = 0.09091725478071216\n",
      "Initial Cost on Val dataset for this epoch 173 = 0.09091725478071216\n",
      "learning rate for this epoch =  0.16543969646281814\n",
      "Error on this batch = 0.028305398382047375\n",
      "Error on this batch = 0.05223881309352251\n",
      "Cost on val dataset after 174 epochs is = 0.09086431642299489\n",
      "Initial Cost on Val dataset for this epoch 174 = 0.09086431642299489\n",
      "learning rate for this epoch =  0.1652014817392402\n",
      "Error on this batch = 0.02821736439647082\n",
      "Error on this batch = 0.05200429639555121\n",
      "Cost on val dataset after 175 epochs is = 0.09081186226543525\n",
      "Initial Cost on Val dataset for this epoch 175 = 0.09081186226543525\n",
      "learning rate for this epoch =  0.1649649722112678\n",
      "Error on this batch = 0.028128948718148764\n",
      "Error on this batch = 0.05177672252181477\n",
      "Cost on val dataset after 176 epochs is = 0.09076008463384054\n",
      "Initial Cost on Val dataset for this epoch 176 = 0.09076008463384054\n",
      "learning rate for this epoch =  0.16473014603283373\n",
      "Error on this batch = 0.028040411719991734\n",
      "Error on this batch = 0.05155626249707597\n",
      "Cost on val dataset after 177 epochs is = 0.0907091700733739\n",
      "Initial Cost on Val dataset for this epoch 177 = 0.0907091700733739\n",
      "learning rate for this epoch =  0.16449698175985428\n",
      "Error on this batch = 0.027951965797286777\n",
      "Error on this batch = 0.051342957440186424\n",
      "Cost on val dataset after 178 epochs is = 0.09065933525057025\n",
      "Initial Cost on Val dataset for this epoch 178 = 0.09065933525057025\n",
      "learning rate for this epoch =  0.164265458340611\n",
      "Error on this batch = 0.02786378615205021\n",
      "Error on this batch = 0.051136569616256296\n",
      "Cost on val dataset after 179 epochs is = 0.09061086961687011\n",
      "Initial Cost on Val dataset for this epoch 179 = 0.09061086961687011\n",
      "learning rate for this epoch =  0.16403555510641493\n",
      "Error on this batch = 0.027776014743671702\n",
      "Error on this batch = 0.050936482299616906\n",
      "Cost on val dataset after 180 epochs is = 0.0905641738571289\n",
      "Initial Cost on Val dataset for this epoch 180 = 0.0905641738571289\n",
      "learning rate for this epoch =  0.163807251762544\n",
      "Error on this batch = 0.027688756022689685\n",
      "Error on this batch = 0.050741789123641814\n",
      "Cost on val dataset after 181 epochs is = 0.09051976261218517\n",
      "Initial Cost on Val dataset for this epoch 181 = 0.09051976261218517\n",
      "learning rate for this epoch =  0.1635805283794437\n",
      "Error on this batch = 0.027602071606281742\n",
      "Error on this batch = 0.050551657525833404\n",
      "Cost on val dataset after 182 epochs is = 0.0904781955968889\n",
      "Initial Cost on Val dataset for this epoch 182 = 0.0904781955968889\n",
      "learning rate for this epoch =  0.1633553653841821\n",
      "Error on this batch = 0.027515988689986583\n",
      "Error on this batch = 0.050365786978458615\n",
      "Cost on val dataset after 183 epochs is = 0.09043993557844307\n",
      "Initial Cost on Val dataset for this epoch 183 = 0.09043993557844307\n",
      "learning rate for this epoch =  0.16313174355215057\n",
      "Error on this batch = 0.027430531745130528\n",
      "Error on this batch = 0.05018454876240597\n",
      "Cost on val dataset after 184 epochs is = 0.0904051988737975\n",
      "Initial Cost on Val dataset for this epoch 184 = 0.0904051988737975\n",
      "learning rate for this epoch =  0.16290964399900174\n",
      "Error on this batch = 0.02734575920831826\n",
      "Error on this batch = 0.05000861814766808\n",
      "Cost on val dataset after 185 epochs is = 0.09037391643773891\n",
      "Initial Cost on Val dataset for this epoch 185 = 0.09037391643773891\n",
      "learning rate for this epoch =  0.1626890481728167\n",
      "Error on this batch = 0.027261770959341566\n",
      "Error on this batch = 0.04983843859003331\n",
      "Cost on val dataset after 186 epochs is = 0.09034587151402515\n",
      "Initial Cost on Val dataset for this epoch 186 = 0.09034587151402515\n",
      "learning rate for this epoch =  0.1624699378464939\n",
      "Error on this batch = 0.027178688533889973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.04967397541090739\n",
      "Cost on val dataset after 187 epochs is = 0.09032090674067936\n",
      "Initial Cost on Val dataset for this epoch 187 = 0.09032090674067936\n",
      "learning rate for this epoch =  0.16225229511035183\n",
      "Error on this batch = 0.027096646328807053\n",
      "Error on this batch = 0.049514826895372545\n",
      "Cost on val dataset after 188 epochs is = 0.09029901361070225\n",
      "Initial Cost on Val dataset for this epoch 188 = 0.09029901361070225\n",
      "learning rate for this epoch =  0.16203610236493907\n",
      "Error on this batch = 0.02701579937218618\n",
      "Error on this batch = 0.049360465205320586\n",
      "Cost on val dataset after 189 epochs is = 0.0902802722437449\n",
      "Initial Cost on Val dataset for this epoch 189 = 0.0902802722437449\n",
      "learning rate for this epoch =  0.16182134231404424\n",
      "Error on this batch = 0.026936313605255394\n",
      "Error on this batch = 0.04921042122719144\n",
      "Cost on val dataset after 190 epochs is = 0.09026475591376132\n",
      "Initial Cost on Val dataset for this epoch 190 = 0.09026475591376132\n",
      "learning rate for this epoch =  0.1616079979578994\n",
      "Error on this batch = 0.026858330465054498\n",
      "Error on this batch = 0.04906436664131147\n",
      "Cost on val dataset after 191 epochs is = 0.0902524813064591\n",
      "Initial Cost on Val dataset for this epoch 191 = 0.0902524813064591\n",
      "learning rate for this epoch =  0.16139605258657097\n",
      "Error on this batch = 0.02678193324087148\n",
      "Error on this batch = 0.04892211485789067\n",
      "Cost on val dataset after 192 epochs is = 0.09024340392230967\n",
      "Initial Cost on Val dataset for this epoch 192 = 0.09024340392230967\n",
      "learning rate for this epoch =  0.16118548977353128\n",
      "Error on this batch = 0.02670713746405184\n",
      "Error on this batch = 0.04878357633876565\n",
      "Cost on val dataset after 193 epochs is = 0.0902374317729188\n",
      "Initial Cost on Val dataset for this epoch 193 = 0.0902374317729188\n",
      "learning rate for this epoch =  0.1609762933694058\n",
      "Error on this batch = 0.026633907059491042\n",
      "Error on this batch = 0.04864870064841356\n",
      "Cost on val dataset after 194 epochs is = 0.090234440142209\n",
      "Initial Cost on Val dataset for this epoch 194 = 0.090234440142209\n",
      "learning rate for this epoch =  0.16076844749588948\n",
      "Error on this batch = 0.026562186109417008\n",
      "Error on this batch = 0.048517428794141546\n",
      "Cost on val dataset after 195 epochs is = 0.09023428253111881\n",
      "Initial Cost on Val dataset for this epoch 195 = 0.09023428253111881\n",
      "learning rate for this epoch =  0.16056193653982745\n",
      "Error on this batch = 0.026491932041840728\n",
      "Error on this batch = 0.048389668452374926\n",
      "Cost on val dataset after 196 epochs is = 0.09023679843028663\n",
      "Initial Cost on Val dataset for this epoch 196 = 0.09023679843028663\n",
      "learning rate for this epoch =  0.16035674514745463\n",
      "Error on this batch = 0.026423136475957582\n",
      "Error on this batch = 0.04826529355728239\n",
      "Cost on val dataset after 197 epochs is = 0.09024181882258486\n",
      "Initial Cost on Val dataset for this epoch 197 = 0.09024181882258486\n",
      "learning rate for this epoch =  0.1601528582187888\n",
      "Error on this batch = 0.02635582489701869\n",
      "Error on this batch = 0.04814416073435011\n",
      "Cost on val dataset after 198 epochs is = 0.09024916837494802\n",
      "Initial Cost on Val dataset for this epoch 198 = 0.09024916837494802\n",
      "learning rate for this epoch =  0.15995026090217312\n",
      "Error on this batch = 0.02629003476816695\n",
      "Error on this batch = 0.04802613075602177\n",
      "Cost on val dataset after 199 epochs is = 0.09025866121709698\n",
      "Initial Cost on Val dataset for this epoch 199 = 0.09025866121709698\n",
      "learning rate for this epoch =  0.15974893858896244\n",
      "Error on this batch = 0.02622577945205499\n",
      "Error on this batch = 0.04791108444855406\n",
      "Cost on val dataset after 200 epochs is = 0.09027008598041136\n",
      "Initial Cost on Val dataset for this epoch 200 = 0.09027008598041136\n",
      "learning rate for this epoch =  0.15954887690834965\n",
      "Error on this batch = 0.02616300770130943\n",
      "Error on this batch = 0.047798927511494525\n",
      "Cost on val dataset after 201 epochs is = 0.0902831760912793\n",
      "Initial Cost on Val dataset for this epoch 201 = 0.0902831760912793\n",
      "learning rate for this epoch =  0.15935006172232735\n",
      "Error on this batch = 0.02610156462609969\n",
      "Error on this batch = 0.04768958428708029\n",
      "Cost on val dataset after 202 epochs is = 0.09029756490374719\n",
      "Initial Cost on Val dataset for this epoch 202 = 0.09029756490374719\n",
      "learning rate for this epoch =  0.1591524791207806\n",
      "Error on this batch = 0.026041155413763246\n",
      "Error on this batch = 0.04758298360269013\n",
      "Cost on val dataset after 203 epochs is = 0.09031273505701139\n",
      "Initial Cost on Val dataset for this epoch 203 = 0.09031273505701139\n",
      "learning rate for this epoch =  0.15895611541670698\n",
      "Error on this batch = 0.025981317364312664\n",
      "Error on this batch = 0.04747903896846161\n",
      "Cost on val dataset after 204 epochs is = 0.0903279884331481\n",
      "Initial Cost on Val dataset for this epoch 204 = 0.0903279884331481\n",
      "learning rate for this epoch =  0.15876095714155977\n",
      "Error on this batch = 0.025921423897318736\n",
      "Error on this batch = 0.047377623484302474\n",
      "Cost on val dataset after 205 epochs is = 0.09034247883237552\n",
      "cost initial= 0.0903279884331481 , cost final=0.09034247883237552 , change in cost= 1.4490399227420903e-05\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with softplus are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with softplus is = 205\n",
      "The training time with softplus is = 144.683sec\n",
      "The training accuracy with softplus is = 95.131%\n",
      "The validation accuracy with softplus is = 90.000%\n",
      "The test accuracy with softplus is = 89.077%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.6\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'softplus', 'adaptive')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'softplus'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'softplus'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'softplus'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with softplus are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with softplus is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with softplus is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with softplus is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with softplus is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with softplus is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Plotting Graphs for Part D - ReLU of 2 Hidden Layer ARCH ------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"------------------Plotting Graphs for Part D - ReLU of 2 Hidden Layer ARCH ------------------\")\n",
    "x=[0,1,2]\n",
    "data = [' ','ReLU', ' ' ,' ' ,' ','Sigmoid', ' ',' ',' ','Softplus']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy and Epochs for Neural Network [100,100]\")\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Activation Function\")\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend()\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "ax1.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/partd/comp_diff_act.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F - Binary Cross Entropy With ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[]\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "test_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part F-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with ReLU activation and Cross Entropy------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part F-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with ReLU activation and Cross Entropy------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 17.901383893296945\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 17.89721578625675\n",
      "Error on this batch = 4.604033332206689\n",
      "Cost on val dataset after 2 epochs is = 4.171266974682238\n",
      "Initial Cost on Val dataset for this epoch 2 = 4.171266974682238\n",
      "learning rate for this epoch =  0.08408964152537146\n",
      "Error on this batch = 4.157265536554206\n",
      "Error on this batch = 3.474939642069099\n",
      "Cost on val dataset after 3 epochs is = 2.8478910470909926\n",
      "Initial Cost on Val dataset for this epoch 3 = 2.8478910470909926\n",
      "learning rate for this epoch =  0.07598356856515927\n",
      "Error on this batch = 2.774500042844477\n",
      "Error on this batch = 2.6790828682956356\n",
      "Cost on val dataset after 4 epochs is = 2.2040228179440255\n",
      "Initial Cost on Val dataset for this epoch 4 = 2.2040228179440255\n",
      "learning rate for this epoch =  0.07071067811865475\n",
      "Error on this batch = 2.1155773816588574\n",
      "Error on this batch = 2.2881330181942445\n",
      "Cost on val dataset after 5 epochs is = 1.8861889088055086\n",
      "Initial Cost on Val dataset for this epoch 5 = 1.8861889088055086\n",
      "learning rate for this epoch =  0.0668740304976422\n",
      "Error on this batch = 1.754164818806454\n",
      "Error on this batch = 2.015463651966893\n",
      "Cost on val dataset after 6 epochs is = 1.699219783334616\n",
      "Initial Cost on Val dataset for this epoch 6 = 1.699219783334616\n",
      "learning rate for this epoch =  0.06389431042462725\n",
      "Error on this batch = 1.5305504698600063\n",
      "Error on this batch = 1.8336445271220867\n",
      "Cost on val dataset after 7 epochs is = 1.5817035213588488\n",
      "Initial Cost on Val dataset for this epoch 7 = 1.5817035213588488\n",
      "learning rate for this epoch =  0.06147881529512644\n",
      "Error on this batch = 1.393411534253587\n",
      "Error on this batch = 1.7177173762148914\n",
      "Cost on val dataset after 8 epochs is = 1.4876664589062583\n",
      "Initial Cost on Val dataset for this epoch 8 = 1.4876664589062583\n",
      "learning rate for this epoch =  0.05946035575013606\n",
      "Error on this batch = 1.2761286613093268\n",
      "Error on this batch = 1.6289050182842173\n",
      "Cost on val dataset after 9 epochs is = 1.422604124373947\n",
      "Initial Cost on Val dataset for this epoch 9 = 1.422604124373947\n",
      "learning rate for this epoch =  0.05773502691896258\n",
      "Error on this batch = 1.1974401121902194\n",
      "Error on this batch = 1.5552322645261427\n",
      "Cost on val dataset after 10 epochs is = 1.3725259601355417\n",
      "Initial Cost on Val dataset for this epoch 10 = 1.3725259601355417\n",
      "learning rate for this epoch =  0.05623413251903491\n",
      "Error on this batch = 1.1370975743645209\n",
      "Error on this batch = 1.5026302679897452\n",
      "Cost on val dataset after 11 epochs is = 1.3326236121836055\n",
      "Initial Cost on Val dataset for this epoch 11 = 1.3326236121836055\n",
      "learning rate for this epoch =  0.05491004867761125\n",
      "Error on this batch = 1.0888923788288196\n",
      "Error on this batch = 1.460469338035764\n",
      "Cost on val dataset after 12 epochs is = 1.3002288689185864\n",
      "Initial Cost on Val dataset for this epoch 12 = 1.3002288689185864\n",
      "learning rate for this epoch =  0.0537284965911771\n",
      "Error on this batch = 1.0507538252371893\n",
      "Error on this batch = 1.4244396049094856\n",
      "Cost on val dataset after 13 epochs is = 1.273117398970834\n",
      "Initial Cost on Val dataset for this epoch 13 = 1.273117398970834\n",
      "learning rate for this epoch =  0.052664038784792665\n",
      "Error on this batch = 1.018989259159506\n",
      "Error on this batch = 1.3901729422065867\n",
      "Cost on val dataset after 14 epochs is = 1.2497065582810822\n",
      "Initial Cost on Val dataset for this epoch 14 = 1.2497065582810822\n",
      "learning rate for this epoch =  0.05169731539571706\n",
      "Error on this batch = 0.9938784428097175\n",
      "Error on this batch = 1.3610976738420058\n",
      "Cost on val dataset after 15 epochs is = 1.2300432078422268\n",
      "Initial Cost on Val dataset for this epoch 15 = 1.2300432078422268\n",
      "learning rate for this epoch =  0.05081327481546148\n",
      "Error on this batch = 0.9729204550346094\n",
      "Error on this batch = 1.3376602868608825\n",
      "Cost on val dataset after 16 epochs is = 1.2129163287057763\n",
      "Initial Cost on Val dataset for this epoch 16 = 1.2129163287057763\n",
      "learning rate for this epoch =  0.05\n",
      "Error on this batch = 0.9536727046513841\n",
      "Error on this batch = 1.3164892170538758\n",
      "Cost on val dataset after 17 epochs is = 1.197661272725907\n",
      "Initial Cost on Val dataset for this epoch 17 = 1.197661272725907\n",
      "learning rate for this epoch =  0.049247906050545236\n",
      "Error on this batch = 0.9374361704176275\n",
      "Error on this batch = 1.2972431618316704\n",
      "Cost on val dataset after 18 epochs is = 1.1841694400551483\n",
      "Initial Cost on Val dataset for this epoch 18 = 1.1841694400551483\n",
      "learning rate for this epoch =  0.048549177170732344\n",
      "Error on this batch = 0.9234819023584052\n",
      "Error on this batch = 1.2805743919437385\n",
      "Cost on val dataset after 19 epochs is = 1.1712288775946966\n",
      "Initial Cost on Val dataset for this epoch 19 = 1.1712288775946966\n",
      "learning rate for this epoch =  0.04789736254435747\n",
      "Error on this batch = 0.9104971374630492\n",
      "Error on this batch = 1.2644882724140858\n",
      "Cost on val dataset after 20 epochs is = 1.1597060058332262\n",
      "Initial Cost on Val dataset for this epoch 20 = 1.1597060058332262\n",
      "learning rate for this epoch =  0.047287080450158794\n",
      "Error on this batch = 0.8985239319695894\n",
      "Error on this batch = 1.2511405391626804\n",
      "Cost on val dataset after 21 epochs is = 1.1493385561191891\n",
      "Initial Cost on Val dataset for this epoch 21 = 1.1493385561191891\n",
      "learning rate for this epoch =  0.04671379777282001\n",
      "Error on this batch = 0.8875831216165618\n",
      "Error on this batch = 1.2386718359015116\n",
      "Cost on val dataset after 22 epochs is = 1.1403035641737094\n",
      "Initial Cost on Val dataset for this epoch 22 = 1.1403035641737094\n",
      "learning rate for this epoch =  0.04617366309441026\n",
      "Error on this batch = 0.8776541100492576\n",
      "Error on this batch = 1.2265250611019343\n",
      "Cost on val dataset after 23 epochs is = 1.132312168331301\n",
      "Initial Cost on Val dataset for this epoch 23 = 1.132312168331301\n",
      "learning rate for this epoch =  0.04566337854967313\n",
      "Error on this batch = 0.8689909761625018\n",
      "Error on this batch = 1.2165047901057002\n",
      "Cost on val dataset after 24 epochs is = 1.1248569108577087\n",
      "Initial Cost on Val dataset for this epoch 24 = 1.1248569108577087\n",
      "learning rate for this epoch =  0.04518010018049225\n",
      "Error on this batch = 0.8617387721550864\n",
      "Error on this batch = 1.2070469924445457\n",
      "Cost on val dataset after 25 epochs is = 1.1180005572633336\n",
      "Initial Cost on Val dataset for this epoch 25 = 1.1180005572633336\n",
      "learning rate for this epoch =  0.044721359549995794\n",
      "Error on this batch = 0.8552776212816522\n",
      "Error on this batch = 1.1980218418955106\n",
      "Cost on val dataset after 26 epochs is = 1.1120500415646468\n",
      "Initial Cost on Val dataset for this epoch 26 = 1.1120500415646468\n",
      "learning rate for this epoch =  0.04428500142691474\n",
      "Error on this batch = 0.849746873825257\n",
      "Error on this batch = 1.190627404878493\n",
      "Cost on val dataset after 27 epochs is = 1.1062264758338503\n",
      "Initial Cost on Val dataset for this epoch 27 = 1.1062264758338503\n",
      "learning rate for this epoch =  0.043869133765083085\n",
      "Error on this batch = 0.8443886786168893\n",
      "Error on this batch = 1.1828574479098266\n",
      "Cost on val dataset after 28 epochs is = 1.1009719258842023\n",
      "Initial Cost on Val dataset for this epoch 28 = 1.1009719258842023\n",
      "learning rate for this epoch =  0.043472087194499145\n",
      "Error on this batch = 0.8391220274307224\n",
      "Error on this batch = 1.1752798334577812\n",
      "Cost on val dataset after 29 epochs is = 1.095976094897564\n",
      "Initial Cost on Val dataset for this epoch 29 = 1.095976094897564\n",
      "learning rate for this epoch =  0.04309238194589061\n",
      "Error on this batch = 0.8339274551174343\n",
      "Error on this batch = 1.1694010850237464\n",
      "Cost on val dataset after 30 epochs is = 1.0915249394005708\n",
      "Initial Cost on Val dataset for this epoch 30 = 1.0915249394005708\n",
      "learning rate for this epoch =  0.042728700639623404\n",
      "Error on this batch = 0.8300343388539426\n",
      "Error on this batch = 1.1638204102865377\n",
      "Cost on val dataset after 31 epochs is = 1.0871472106427018\n",
      "Initial Cost on Val dataset for this epoch 31 = 1.0871472106427018\n",
      "learning rate for this epoch =  0.04237986574150217\n",
      "Error on this batch = 0.8257995855656249\n",
      "Error on this batch = 1.1573300936301267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 1.083082037159882\n",
      "Initial Cost on Val dataset for this epoch 32 = 1.083082037159882\n",
      "learning rate for this epoch =  0.04204482076268573\n",
      "Error on this batch = 0.8217006095139037\n",
      "Error on this batch = 1.1509390146976388\n",
      "Cost on val dataset after 33 epochs is = 1.0795678766906542\n",
      "Initial Cost on Val dataset for this epoch 33 = 1.0795678766906542\n",
      "learning rate for this epoch =  0.04172261448611506\n",
      "Error on this batch = 0.8181938630064265\n",
      "Error on this batch = 1.1446990640640704\n",
      "Cost on val dataset after 34 epochs is = 1.0761646018987852\n",
      "Initial Cost on Val dataset for this epoch 34 = 1.0761646018987852\n",
      "learning rate for this epoch =  0.041412387656655204\n",
      "Error on this batch = 0.8143973712134508\n",
      "Error on this batch = 1.1389130440668354\n",
      "Cost on val dataset after 35 epochs is = 1.0730155920483009\n",
      "Initial Cost on Val dataset for this epoch 35 = 1.0730155920483009\n",
      "learning rate for this epoch =  0.04111336169005197\n",
      "Error on this batch = 0.810668052379808\n",
      "Error on this batch = 1.132854177953819\n",
      "Cost on val dataset after 36 epochs is = 1.0698084960812462\n",
      "Initial Cost on Val dataset for this epoch 36 = 1.0698084960812462\n",
      "learning rate for this epoch =  0.040824829046386304\n",
      "Error on this batch = 0.8070801818916479\n",
      "Error on this batch = 1.1268965978961059\n",
      "Cost on val dataset after 37 epochs is = 1.0665993290611095\n",
      "Initial Cost on Val dataset for this epoch 37 = 1.0665993290611095\n",
      "learning rate for this epoch =  0.040546144983876986\n",
      "Error on this batch = 0.8033802333481547\n",
      "Error on this batch = 1.1207269196707454\n",
      "Cost on val dataset after 38 epochs is = 1.0638167326589634\n",
      "Initial Cost on Val dataset for this epoch 38 = 1.0638167326589634\n",
      "learning rate for this epoch =  0.04027672046365773\n",
      "Error on this batch = 0.8003212117979976\n",
      "Error on this batch = 1.1148095142152188\n",
      "Cost on val dataset after 39 epochs is = 1.0616410873073792\n",
      "Initial Cost on Val dataset for this epoch 39 = 1.0616410873073792\n",
      "learning rate for this epoch =  0.040016016019225\n",
      "Error on this batch = 0.7983471320613806\n",
      "Error on this batch = 1.109709788198642\n",
      "Cost on val dataset after 40 epochs is = 1.0592731546244043\n",
      "Initial Cost on Val dataset for this epoch 40 = 1.0592731546244043\n",
      "learning rate for this epoch =  0.03976353643835253\n",
      "Error on this batch = 0.7965085914944757\n",
      "Error on this batch = 1.1049480832523029\n",
      "Cost on val dataset after 41 epochs is = 1.056686331386001\n",
      "Initial Cost on Val dataset for this epoch 41 = 1.056686331386001\n",
      "learning rate for this epoch =  0.03951882613244048\n",
      "Error on this batch = 0.7934206652361553\n",
      "Error on this batch = 1.1000890974883935\n",
      "Cost on val dataset after 42 epochs is = 1.0544217596755034\n",
      "Initial Cost on Val dataset for this epoch 42 = 1.0544217596755034\n",
      "learning rate for this epoch =  0.0392814650900513\n",
      "Error on this batch = 0.7911898589855543\n",
      "Error on this batch = 1.0950261134145\n",
      "Cost on val dataset after 43 epochs is = 1.0524372723406148\n",
      "Initial Cost on Val dataset for this epoch 43 = 1.0524372723406148\n",
      "learning rate for this epoch =  0.03905106532895161\n",
      "Error on this batch = 0.7886576332458484\n",
      "Error on this batch = 1.091324602549052\n",
      "Cost on val dataset after 44 epochs is = 1.050412315246289\n",
      "Initial Cost on Val dataset for this epoch 44 = 1.050412315246289\n",
      "learning rate for this epoch =  0.03882726777522233\n",
      "Error on this batch = 0.7865703379462733\n",
      "Error on this batch = 1.0869660519788777\n",
      "Cost on val dataset after 45 epochs is = 1.0485556565252476\n",
      "Initial Cost on Val dataset for this epoch 45 = 1.0485556565252476\n",
      "learning rate for this epoch =  0.03860973950960897\n",
      "Error on this batch = 0.7840780219584538\n",
      "Error on this batch = 1.0827661277800347\n",
      "Cost on val dataset after 46 epochs is = 1.0465941753528787\n",
      "Initial Cost on Val dataset for this epoch 46 = 1.0465941753528787\n",
      "learning rate for this epoch =  0.0383981713307935\n",
      "Error on this batch = 0.7810991949953697\n",
      "Error on this batch = 1.079106819171264\n",
      "Cost on val dataset after 47 epochs is = 1.0446877156161392\n",
      "Initial Cost on Val dataset for this epoch 47 = 1.0446877156161392\n",
      "learning rate for this epoch =  0.03819227559309534\n",
      "Error on this batch = 0.778441243021037\n",
      "Error on this batch = 1.0753952979366463\n",
      "Cost on val dataset after 48 epochs is = 1.0432379862537278\n",
      "Initial Cost on Val dataset for this epoch 48 = 1.0432379862537278\n",
      "learning rate for this epoch =  0.037991784282579634\n",
      "Error on this batch = 0.7756339835936694\n",
      "Error on this batch = 1.0718233671112574\n",
      "Cost on val dataset after 49 epochs is = 1.0416102243098004\n",
      "Initial Cost on Val dataset for this epoch 49 = 1.0416102243098004\n",
      "learning rate for this epoch =  0.03779644730092272\n",
      "Error on this batch = 0.7732823449634312\n",
      "Error on this batch = 1.0688176885007534\n",
      "Cost on val dataset after 50 epochs is = 1.0400712409914417\n",
      "Initial Cost on Val dataset for this epoch 50 = 1.0400712409914417\n",
      "learning rate for this epoch =  0.03760603093086394\n",
      "Error on this batch = 0.7709889193008174\n",
      "Error on this batch = 1.0666524952899936\n",
      "Cost on val dataset after 51 epochs is = 1.038523796143003\n",
      "Initial Cost on Val dataset for this epoch 51 = 1.038523796143003\n",
      "learning rate for this epoch =  0.03742031646082125\n",
      "Error on this batch = 0.7691530508010922\n",
      "Error on this batch = 1.0634012566135485\n",
      "Cost on val dataset after 52 epochs is = 1.0371553287018391\n",
      "Initial Cost on Val dataset for this epoch 52 = 1.0371553287018391\n",
      "learning rate for this epoch =  0.03723909894939824\n",
      "Error on this batch = 0.7676060626651185\n",
      "Error on this batch = 1.0609682750976983\n",
      "Cost on val dataset after 53 epochs is = 1.0359812553032017\n",
      "Initial Cost on Val dataset for this epoch 53 = 1.0359812553032017\n",
      "learning rate for this epoch =  0.037062186113165134\n",
      "Error on this batch = 0.7656269669586883\n",
      "Error on this batch = 1.057970293056345\n",
      "Cost on val dataset after 54 epochs is = 1.034943901154386\n",
      "Initial Cost on Val dataset for this epoch 54 = 1.034943901154386\n",
      "learning rate for this epoch =  0.03688939732334406\n",
      "Error on this batch = 0.7639012079832719\n",
      "Error on this batch = 1.0565926145488056\n",
      "Cost on val dataset after 55 epochs is = 1.034113831584653\n",
      "Initial Cost on Val dataset for this epoch 55 = 1.034113831584653\n",
      "learning rate for this epoch =  0.03672056269893592\n",
      "Error on this batch = 0.7623221619594722\n",
      "Error on this batch = 1.055003124386783\n",
      "Cost on val dataset after 56 epochs is = 1.033265237054787\n",
      "Initial Cost on Val dataset for this epoch 56 = 1.033265237054787\n",
      "learning rate for this epoch =  0.03655552228545124\n",
      "Error on this batch = 0.7608823427351191\n",
      "Error on this batch = 1.0524151408511222\n",
      "Cost on val dataset after 57 epochs is = 1.0325839945623423\n",
      "Initial Cost on Val dataset for this epoch 57 = 1.0325839945623423\n",
      "learning rate for this epoch =  0.036394125309794766\n",
      "Error on this batch = 0.7593073528692518\n",
      "Error on this batch = 1.050785765128238\n",
      "Cost on val dataset after 58 epochs is = 1.0322248770084088\n",
      "Initial Cost on Val dataset for this epoch 58 = 1.0322248770084088\n",
      "learning rate for this epoch =  0.036236229503043296\n",
      "Error on this batch = 0.7585730244935783\n",
      "Error on this batch = 1.049072012904364\n",
      "Cost on val dataset after 59 epochs is = 1.0318107302586341\n",
      "Initial Cost on Val dataset for this epoch 59 = 1.0318107302586341\n",
      "learning rate for this epoch =  0.036081700483877405\n",
      "Error on this batch = 0.7573126379534177\n",
      "Error on this batch = 1.0471705541612089\n",
      "Cost on val dataset after 60 epochs is = 1.031524899182814\n",
      "Initial Cost on Val dataset for this epoch 60 = 1.031524899182814\n",
      "learning rate for this epoch =  0.03593041119630843\n",
      "Error on this batch = 0.7560998604781579\n",
      "Error on this batch = 1.0457146110527575\n",
      "Cost on val dataset after 61 epochs is = 1.0310694227757855\n",
      "Initial Cost on Val dataset for this epoch 61 = 1.0310694227757855\n",
      "learning rate for this epoch =  0.03578224139610262\n",
      "Error on this batch = 0.7550080179292911\n",
      "Error on this batch = 1.0446510721889513\n",
      "Cost on val dataset after 62 epochs is = 1.0308060489378477\n",
      "Initial Cost on Val dataset for this epoch 62 = 1.0308060489378477\n",
      "learning rate for this epoch =  0.03563707718096288\n",
      "Error on this batch = 0.7540290949818318\n",
      "Error on this batch = 1.0436034008841433\n",
      "Cost on val dataset after 63 epochs is = 1.0305380984918793\n",
      "Initial Cost on Val dataset for this epoch 63 = 1.0305380984918793\n",
      "learning rate for this epoch =  0.03549481056010053\n",
      "Error on this batch = 0.753282669621821\n",
      "Error on this batch = 1.042814613063983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 64 epochs is = 1.0301677233153075\n",
      "Initial Cost on Val dataset for this epoch 64 = 1.0301677233153075\n",
      "learning rate for this epoch =  0.035355339059327376\n",
      "Error on this batch = 0.7525712346792088\n",
      "Error on this batch = 1.0414964167249556\n",
      "Cost on val dataset after 65 epochs is = 1.0298608329336356\n",
      "Initial Cost on Val dataset for this epoch 65 = 1.0298608329336356\n",
      "learning rate for this epoch =  0.03521856535823236\n",
      "Error on this batch = 0.751912065722261\n",
      "Error on this batch = 1.040432927302541\n",
      "Cost on val dataset after 66 epochs is = 1.0297112432127649\n",
      "Initial Cost on Val dataset for this epoch 66 = 1.0297112432127649\n",
      "learning rate for this epoch =  0.035084396956386855\n",
      "Error on this batch = 0.7513912564437039\n",
      "Error on this batch = 1.0396461140236573\n",
      "Cost on val dataset after 67 epochs is = 1.0295036157879063\n",
      "Initial Cost on Val dataset for this epoch 67 = 1.0295036157879063\n",
      "learning rate for this epoch =  0.034952745865855124\n",
      "Error on this batch = 0.7506656190064607\n",
      "Error on this batch = 1.0377075948620607\n",
      "Cost on val dataset after 68 epochs is = 1.0293529406078088\n",
      "Initial Cost on Val dataset for this epoch 68 = 1.0293529406078088\n",
      "learning rate for this epoch =  0.03482352832757854\n",
      "Error on this batch = 0.7499521351931696\n",
      "Error on this batch = 1.0367119940084957\n",
      "Cost on val dataset after 69 epochs is = 1.0293108871294305\n",
      "Initial Cost on Val dataset for this epoch 69 = 1.0293108871294305\n",
      "learning rate for this epoch =  0.034696664549459105\n",
      "Error on this batch = 0.7487609705449094\n",
      "Error on this batch = 1.0365688648245202\n",
      "Cost on val dataset after 70 epochs is = 1.0293492713941812\n",
      "Initial Cost on Val dataset for this epoch 70 = 1.0293492713941812\n",
      "learning rate for this epoch =  0.034572078464194106\n",
      "Error on this batch = 0.7474779619114932\n",
      "Error on this batch = 1.0363433283742955\n",
      "Cost on val dataset after 71 epochs is = 1.0295276437477614\n",
      "Initial Cost on Val dataset for this epoch 71 = 1.0295276437477614\n",
      "learning rate for this epoch =  0.03444969750511394\n",
      "Error on this batch = 0.7455343652788995\n",
      "Error on this batch = 1.0357485865328935\n",
      "Cost on val dataset after 72 epochs is = 1.0297330437153411\n",
      "Initial Cost on Val dataset for this epoch 72 = 1.0297330437153411\n",
      "learning rate for this epoch =  0.03432945239845196\n",
      "Error on this batch = 0.7435538098330864\n",
      "Error on this batch = 1.0357569664645936\n",
      "Cost on val dataset after 73 epochs is = 1.030074270643092\n",
      "Initial Cost on Val dataset for this epoch 73 = 1.030074270643092\n",
      "learning rate for this epoch =  0.03421127697063215\n",
      "Error on this batch = 0.7426886099407493\n",
      "Error on this batch = 1.0359663459558468\n",
      "Cost on val dataset after 74 epochs is = 1.03024358926659\n",
      "Initial Cost on Val dataset for this epoch 74 = 1.03024358926659\n",
      "learning rate for this epoch =  0.03409510796929954\n",
      "Error on this batch = 0.7409055597359462\n",
      "Error on this batch = 1.0360820827512434\n",
      "Cost on val dataset after 75 epochs is = 1.0303219465255073\n",
      "Initial Cost on Val dataset for this epoch 75 = 1.0303219465255073\n",
      "learning rate for this epoch =  0.033980884896942454\n",
      "Error on this batch = 0.739160724620628\n",
      "Error on this batch = 1.0348105899015319\n",
      "Cost on val dataset after 76 epochs is = 1.0303724432650128\n",
      "Initial Cost on Val dataset for this epoch 76 = 1.0303724432650128\n",
      "learning rate for this epoch =  0.033868549856065716\n",
      "Error on this batch = 0.737236994192969\n",
      "Error on this batch = 1.0341623466155536\n",
      "Cost on val dataset after 77 epochs is = 1.0305708118322778\n",
      "Initial Cost on Val dataset for this epoch 77 = 1.0305708118322778\n",
      "learning rate for this epoch =  0.03375804740497264\n",
      "Error on this batch = 0.7353157712802986\n",
      "Error on this batch = 1.0338951895943727\n",
      "Cost on val dataset after 78 epochs is = 1.0310548419278427\n",
      "Initial Cost on Val dataset for this epoch 78 = 1.0310548419278427\n",
      "learning rate for this epoch =  0.03364932442330151\n",
      "Error on this batch = 0.7335667178308038\n",
      "Error on this batch = 1.033884415185547\n",
      "Cost on val dataset after 79 epochs is = 1.0311947513106106\n",
      "cost initial= 1.0310548419278427 , cost final=1.0311947513106106 , change in cost= 0.00013990938276786657\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with ReLU are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with ReLU is = 79\n",
      "The training time with ReLU is = 16.790sec\n",
      "The training accuracy with ReLU is = 88.661%\n",
      "The validation accuracy with ReLU is = 85.436%\n",
      "The test accuracy with ReLU is = 83.385%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.1\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'relu', 'adaptive', 'entropy')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'relu'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'relu'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'relu'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with ReLU are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with ReLU is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with ReLU is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with ReLU is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with ReLU is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with ReLU is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part F-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with Softplus activation and Cross Entropy------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part F-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with Softplus activation and Cross Entropy------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network with 2 hidden layer with [100, 100] units\n",
      "The parameters of the layers are of the shape:\n",
      "theta between layer 0 and layer 1 is (785, 100)\n",
      "theta between layer 1 and layer 2 is (101, 100)\n",
      "theta between layer 2 and layer 3 is (101, 26)\n",
      "Initial Cost on Val dataset for this epoch 1 = 19.81503930292858\n",
      "learning rate for this epoch =  0.1\n",
      "Error on this batch = 19.794280492670666\n",
      "Error on this batch = 4.175317200313914\n",
      "Cost on val dataset after 2 epochs is = 4.024354564890312\n",
      "Initial Cost on Val dataset for this epoch 2 = 4.024354564890312\n",
      "learning rate for this epoch =  0.08408964152537146\n",
      "Error on this batch = 4.051570739139761\n",
      "Error on this batch = 3.4029525993912\n",
      "Cost on val dataset after 3 epochs is = 2.9019077904745707\n",
      "Initial Cost on Val dataset for this epoch 3 = 2.9019077904745707\n",
      "learning rate for this epoch =  0.07598356856515927\n",
      "Error on this batch = 2.939627005348293\n",
      "Error on this batch = 2.645088093797996\n",
      "Cost on val dataset after 4 epochs is = 2.180768819383366\n",
      "Initial Cost on Val dataset for this epoch 4 = 2.180768819383366\n",
      "learning rate for this epoch =  0.07071067811865475\n",
      "Error on this batch = 2.183160605921156\n",
      "Error on this batch = 2.2109997141826585\n",
      "Cost on val dataset after 5 epochs is = 1.8151391120957396\n",
      "Initial Cost on Val dataset for this epoch 5 = 1.8151391120957396\n",
      "learning rate for this epoch =  0.0668740304976422\n",
      "Error on this batch = 1.7056436571446687\n",
      "Error on this batch = 1.9419549862038767\n",
      "Cost on val dataset after 6 epochs is = 1.5947659128193645\n",
      "Initial Cost on Val dataset for this epoch 6 = 1.5947659128193645\n",
      "learning rate for this epoch =  0.06389431042462725\n",
      "Error on this batch = 1.4186687270400646\n",
      "Error on this batch = 1.757283772649388\n",
      "Cost on val dataset after 7 epochs is = 1.4608112218876002\n",
      "Initial Cost on Val dataset for this epoch 7 = 1.4608112218876002\n",
      "learning rate for this epoch =  0.06147881529512644\n",
      "Error on this batch = 1.263012749531799\n",
      "Error on this batch = 1.6353944437397439\n",
      "Cost on val dataset after 8 epochs is = 1.3738471788646582\n",
      "Initial Cost on Val dataset for this epoch 8 = 1.3738471788646582\n",
      "learning rate for this epoch =  0.05946035575013606\n",
      "Error on this batch = 1.1671087519484054\n",
      "Error on this batch = 1.5402006186395398\n",
      "Cost on val dataset after 9 epochs is = 1.3086103301282008\n",
      "Initial Cost on Val dataset for this epoch 9 = 1.3086103301282008\n",
      "learning rate for this epoch =  0.05773502691896258\n",
      "Error on this batch = 1.0960765681666444\n",
      "Error on this batch = 1.4617006945685973\n",
      "Cost on val dataset after 10 epochs is = 1.2557603414382288\n",
      "Initial Cost on Val dataset for this epoch 10 = 1.2557603414382288\n",
      "learning rate for this epoch =  0.05623413251903491\n",
      "Error on this batch = 1.0387711111558608\n",
      "Error on this batch = 1.3978562776030845\n",
      "Cost on val dataset after 11 epochs is = 1.211612959325901\n",
      "Initial Cost on Val dataset for this epoch 11 = 1.211612959325901\n",
      "learning rate for this epoch =  0.05491004867761125\n",
      "Error on this batch = 0.9909991242506396\n",
      "Error on this batch = 1.3461805057436362\n",
      "Cost on val dataset after 12 epochs is = 1.1741266291400536\n",
      "Initial Cost on Val dataset for this epoch 12 = 1.1741266291400536\n",
      "learning rate for this epoch =  0.0537284965911771\n",
      "Error on this batch = 0.9504466209399789\n",
      "Error on this batch = 1.3035323999385344\n",
      "Cost on val dataset after 13 epochs is = 1.1418542492847117\n",
      "Initial Cost on Val dataset for this epoch 13 = 1.1418542492847117\n",
      "learning rate for this epoch =  0.052664038784792665\n",
      "Error on this batch = 0.9154033958052614\n",
      "Error on this batch = 1.2672033047914208\n",
      "Cost on val dataset after 14 epochs is = 1.113692245742254\n",
      "Initial Cost on Val dataset for this epoch 14 = 1.113692245742254\n",
      "learning rate for this epoch =  0.05169731539571706\n",
      "Error on this batch = 0.8844787509160691\n",
      "Error on this batch = 1.235290533610019\n",
      "Cost on val dataset after 15 epochs is = 1.0887824103037318\n",
      "Initial Cost on Val dataset for this epoch 15 = 1.0887824103037318\n",
      "learning rate for this epoch =  0.05081327481546148\n",
      "Error on this batch = 0.8565550235668147\n",
      "Error on this batch = 1.206577446312441\n",
      "Cost on val dataset after 16 epochs is = 1.0664662405637126\n",
      "Initial Cost on Val dataset for this epoch 16 = 1.0664662405637126\n",
      "learning rate for this epoch =  0.05\n",
      "Error on this batch = 0.8308115137541748\n",
      "Error on this batch = 1.180313514476632\n",
      "Cost on val dataset after 17 epochs is = 1.0462541879992329\n",
      "Initial Cost on Val dataset for this epoch 17 = 1.0462541879992329\n",
      "learning rate for this epoch =  0.049247906050545236\n",
      "Error on this batch = 0.8067263050640163\n",
      "Error on this batch = 1.1560307611646456\n",
      "Cost on val dataset after 18 epochs is = 1.027784838273554\n",
      "Initial Cost on Val dataset for this epoch 18 = 1.027784838273554\n",
      "learning rate for this epoch =  0.048549177170732344\n",
      "Error on this batch = 0.7840134212094205\n",
      "Error on this batch = 1.1334192423186769\n",
      "Cost on val dataset after 19 epochs is = 1.0107816739363182\n",
      "Initial Cost on Val dataset for this epoch 19 = 1.0107816739363182\n",
      "learning rate for this epoch =  0.04789736254435747\n",
      "Error on this batch = 0.7625255289054397\n",
      "Error on this batch = 1.1122536813542225\n",
      "Cost on val dataset after 20 epochs is = 0.9950240257989524\n",
      "Initial Cost on Val dataset for this epoch 20 = 0.9950240257989524\n",
      "learning rate for this epoch =  0.047287080450158794\n",
      "Error on this batch = 0.7421750718557846\n",
      "Error on this batch = 1.092355650003341\n",
      "Cost on val dataset after 21 epochs is = 0.9803330227766361\n",
      "Initial Cost on Val dataset for this epoch 21 = 0.9803330227766361\n",
      "learning rate for this epoch =  0.04671379777282001\n",
      "Error on this batch = 0.7228935777816361\n",
      "Error on this batch = 1.0735764527891596\n",
      "Cost on val dataset after 22 epochs is = 0.9665640748050499\n",
      "Initial Cost on Val dataset for this epoch 22 = 0.9665640748050499\n",
      "learning rate for this epoch =  0.04617366309441026\n",
      "Error on this batch = 0.7046174283095725\n",
      "Error on this batch = 1.055790052045333\n",
      "Cost on val dataset after 23 epochs is = 0.9536006640829484\n",
      "Initial Cost on Val dataset for this epoch 23 = 0.9536006640829484\n",
      "learning rate for this epoch =  0.04566337854967313\n",
      "Error on this batch = 0.6872845040710616\n",
      "Error on this batch = 1.0388898226474519\n",
      "Cost on val dataset after 24 epochs is = 0.9413485950739896\n",
      "Initial Cost on Val dataset for this epoch 24 = 0.9413485950739896\n",
      "learning rate for this epoch =  0.04518010018049225\n",
      "Error on this batch = 0.6708338538456735\n",
      "Error on this batch = 1.0227862096932843\n",
      "Cost on val dataset after 25 epochs is = 0.9297311174517937\n",
      "Initial Cost on Val dataset for this epoch 25 = 0.9297311174517937\n",
      "learning rate for this epoch =  0.044721359549995794\n",
      "Error on this batch = 0.6552060468642907\n",
      "Error on this batch = 1.0074042838588322\n",
      "Cost on val dataset after 26 epochs is = 0.9186851141159775\n",
      "Initial Cost on Val dataset for this epoch 26 = 0.9186851141159775\n",
      "learning rate for this epoch =  0.04428500142691474\n",
      "Error on this batch = 0.6403437477495788\n",
      "Error on this batch = 0.9926811052123786\n",
      "Cost on val dataset after 27 epochs is = 0.9081582341754629\n",
      "Initial Cost on Val dataset for this epoch 27 = 0.9081582341754629\n",
      "learning rate for this epoch =  0.043869133765083085\n",
      "Error on this batch = 0.6261923742468564\n",
      "Error on this batch = 0.9785631253474005\n",
      "Cost on val dataset after 28 epochs is = 0.8981067422748793\n",
      "Initial Cost on Val dataset for this epoch 28 = 0.8981067422748793\n",
      "learning rate for this epoch =  0.043472087194499145\n",
      "Error on this batch = 0.6127006932788553\n",
      "Error on this batch = 0.9650038766386039\n",
      "Cost on val dataset after 29 epochs is = 0.8884938724352862\n",
      "Initial Cost on Val dataset for this epoch 29 = 0.8884938724352862\n",
      "learning rate for this epoch =  0.04309238194589061\n",
      "Error on this batch = 0.5998212337018817\n",
      "Error on this batch = 0.95196210235771\n",
      "Cost on val dataset after 30 epochs is = 0.8792885295932316\n",
      "Initial Cost on Val dataset for this epoch 30 = 0.8792885295932316\n",
      "learning rate for this epoch =  0.042728700639623404\n",
      "Error on this batch = 0.5875104630310596\n",
      "Error on this batch = 0.9394003729403363\n",
      "Cost on val dataset after 31 epochs is = 0.8704642353409163\n",
      "Initial Cost on Val dataset for this epoch 31 = 0.8704642353409163\n",
      "learning rate for this epoch =  0.04237986574150217\n",
      "Error on this batch = 0.5757287447451864\n",
      "Error on this batch = 0.9272841522164496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 32 epochs is = 0.8619982543747718\n",
      "Initial Cost on Val dataset for this epoch 32 = 0.8619982543747718\n",
      "learning rate for this epoch =  0.04204482076268573\n",
      "Error on this batch = 0.564440134197126\n",
      "Error on this batch = 0.9155812301188323\n",
      "Cost on val dataset after 33 epochs is = 0.8538708642457267\n",
      "Initial Cost on Val dataset for this epoch 33 = 0.8538708642457267\n",
      "learning rate for this epoch =  0.04172261448611506\n",
      "Error on this batch = 0.5536120816443589\n",
      "Error on this batch = 0.9042614203676581\n",
      "Cost on val dataset after 34 epochs is = 0.8460647459155728\n",
      "Initial Cost on Val dataset for this epoch 34 = 0.8460647459155728\n",
      "learning rate for this epoch =  0.041412387656655204\n",
      "Error on this batch = 0.5432151008384287\n",
      "Error on this batch = 0.8932964255127908\n",
      "Cost on val dataset after 35 epochs is = 0.8385644798365265\n",
      "Initial Cost on Val dataset for this epoch 35 = 0.8385644798365265\n",
      "learning rate for this epoch =  0.04111336169005197\n",
      "Error on this batch = 0.5332224432901284\n",
      "Error on this batch = 0.882659789589944\n",
      "Cost on val dataset after 36 epochs is = 0.8313561350415861\n",
      "Initial Cost on Val dataset for this epoch 36 = 0.8313561350415861\n",
      "learning rate for this epoch =  0.040824829046386304\n",
      "Error on this batch = 0.5236098003524023\n",
      "Error on this batch = 0.8723268824104956\n",
      "Cost on val dataset after 37 epochs is = 0.8244269395728652\n",
      "Initial Cost on Val dataset for this epoch 37 = 0.8244269395728652\n",
      "learning rate for this epoch =  0.040546144983876986\n",
      "Error on this batch = 0.5143550414971988\n",
      "Error on this batch = 0.8622748822480821\n",
      "Cost on val dataset after 38 epochs is = 0.8177650210130687\n",
      "Initial Cost on Val dataset for this epoch 38 = 0.8177650210130687\n",
      "learning rate for this epoch =  0.04027672046365773\n",
      "Error on this batch = 0.5054379881323555\n",
      "Error on this batch = 0.8524827412963037\n",
      "Cost on val dataset after 39 epochs is = 0.8113592065707516\n",
      "Initial Cost on Val dataset for this epoch 39 = 0.8113592065707516\n",
      "learning rate for this epoch =  0.040016016019225\n",
      "Error on this batch = 0.49684021709719867\n",
      "Error on this batch = 0.8429311297661312\n",
      "Cost on val dataset after 40 epochs is = 0.8051988731899224\n",
      "Initial Cost on Val dataset for this epoch 40 = 0.8051988731899224\n",
      "learning rate for this epoch =  0.03976353643835253\n",
      "Error on this batch = 0.4885448855557945\n",
      "Error on this batch = 0.8336023609329187\n",
      "Cost on val dataset after 41 epochs is = 0.7992738393567818\n",
      "Initial Cost on Val dataset for this epoch 41 = 0.7992738393567818\n",
      "learning rate for this epoch =  0.03951882613244048\n",
      "Error on this batch = 0.48053656870611927\n",
      "Error on this batch = 0.8244803024714236\n",
      "Cost on val dataset after 42 epochs is = 0.7935742914699111\n",
      "Initial Cost on Val dataset for this epoch 42 = 0.7935742914699111\n",
      "learning rate for this epoch =  0.0392814650900513\n",
      "Error on this batch = 0.4728011031628492\n",
      "Error on this batch = 0.815550280324945\n",
      "Cost on val dataset after 43 epochs is = 0.7880907386718171\n",
      "Initial Cost on Val dataset for this epoch 43 = 0.7880907386718171\n",
      "learning rate for this epoch =  0.03905106532895161\n",
      "Error on this batch = 0.46532543169521995\n",
      "Error on this batch = 0.8067989809225796\n",
      "Cost on val dataset after 44 epochs is = 0.7828139908061222\n",
      "Initial Cost on Val dataset for this epoch 44 = 0.7828139908061222\n",
      "learning rate for this epoch =  0.03882726777522233\n",
      "Error on this batch = 0.4580974486681244\n",
      "Error on this batch = 0.798214356312802\n",
      "Cost on val dataset after 45 epochs is = 0.7777351546131134\n",
      "Initial Cost on Val dataset for this epoch 45 = 0.7777351546131134\n",
      "learning rate for this epoch =  0.03860973950960897\n",
      "Error on this batch = 0.45110584926161656\n",
      "Error on this batch = 0.7897855352231801\n",
      "Cost on val dataset after 46 epochs is = 0.7728456434169734\n",
      "Initial Cost on Val dataset for this epoch 46 = 0.7728456434169734\n",
      "learning rate for this epoch =  0.0383981713307935\n",
      "Error on this batch = 0.4443399884211794\n",
      "Error on this batch = 0.7815027416392137\n",
      "Cost on val dataset after 47 epochs is = 0.7681371954833152\n",
      "Initial Cost on Val dataset for this epoch 47 = 0.7681371954833152\n",
      "learning rate for this epoch =  0.03819227559309534\n",
      "Error on this batch = 0.4377897567384438\n",
      "Error on this batch = 0.7733572214392944\n",
      "Cost on val dataset after 48 epochs is = 0.7636018961152244\n",
      "Initial Cost on Val dataset for this epoch 48 = 0.7636018961152244\n",
      "learning rate for this epoch =  0.037991784282579634\n",
      "Error on this batch = 0.43144547972738745\n",
      "Error on this batch = 0.7653411768162613\n",
      "Cost on val dataset after 49 epochs is = 0.7592321986487192\n",
      "Initial Cost on Val dataset for this epoch 49 = 0.7592321986487192\n",
      "learning rate for this epoch =  0.03779644730092272\n",
      "Error on this batch = 0.4252978444911974\n",
      "Error on this batch = 0.7574477073775208\n",
      "Cost on val dataset after 50 epochs is = 0.7550209400382458\n",
      "Initial Cost on Val dataset for this epoch 50 = 0.7550209400382458\n",
      "learning rate for this epoch =  0.03760603093086394\n",
      "Error on this batch = 0.4193378543381791\n",
      "Error on this batch = 0.7496707558116427\n",
      "Cost on val dataset after 51 epochs is = 0.7509613478280944\n",
      "Initial Cost on Val dataset for this epoch 51 = 0.7509613478280944\n",
      "learning rate for this epoch =  0.03742031646082125\n",
      "Error on this batch = 0.4135568084934101\n",
      "Error on this batch = 0.7420050550569313\n",
      "Cost on val dataset after 52 epochs is = 0.747047036939446\n",
      "Initial Cost on Val dataset for this epoch 52 = 0.747047036939446\n",
      "learning rate for this epoch =  0.03723909894939824\n",
      "Error on this batch = 0.40794630152093336\n",
      "Error on this batch = 0.7344460734782431\n",
      "Cost on val dataset after 53 epochs is = 0.7432719965903717\n",
      "Initial Cost on Val dataset for this epoch 53 = 0.7432719965903717\n",
      "learning rate for this epoch =  0.037062186113165134\n",
      "Error on this batch = 0.40249823587668987\n",
      "Error on this batch = 0.7269899550462182\n",
      "Cost on val dataset after 54 epochs is = 0.73963056936663\n",
      "Initial Cost on Val dataset for this epoch 54 = 0.73963056936663\n",
      "learning rate for this epoch =  0.03688939732334406\n",
      "Error on this batch = 0.39720484114238674\n",
      "Error on this batch = 0.7196334529239737\n",
      "Cost on val dataset after 55 epochs is = 0.7361174255400672\n",
      "Initial Cost on Val dataset for this epoch 55 = 0.7361174255400672\n",
      "learning rate for this epoch =  0.03672056269893592\n",
      "Error on this batch = 0.3920586945684902\n",
      "Error on this batch = 0.7123738567642736\n",
      "Cost on val dataset after 56 epochs is = 0.732727535962796\n",
      "Initial Cost on Val dataset for this epoch 56 = 0.732727535962796\n",
      "learning rate for this epoch =  0.03655552228545124\n",
      "Error on this batch = 0.3870527390548233\n",
      "Error on this batch = 0.7052089157627738\n",
      "Cost on val dataset after 57 epochs is = 0.7294561463322637\n",
      "Initial Cost on Val dataset for this epoch 57 = 0.7294561463322637\n",
      "learning rate for this epoch =  0.036394125309794766\n",
      "Error on this batch = 0.3821802961627724\n",
      "Error on this batch = 0.6981367605926966\n",
      "Cost on val dataset after 58 epochs is = 0.7262987546493297\n",
      "Initial Cost on Val dataset for this epoch 58 = 0.7262987546493297\n",
      "learning rate for this epoch =  0.036236229503043296\n",
      "Error on this batch = 0.3774350729229525\n",
      "Error on this batch = 0.6911558276020116\n",
      "Cost on val dataset after 59 epochs is = 0.7232510926626842\n",
      "Initial Cost on Val dataset for this epoch 59 = 0.7232510926626842\n",
      "learning rate for this epoch =  0.036081700483877405\n",
      "Error on this batch = 0.37281116201639747\n",
      "Error on this batch = 0.6842647882490406\n",
      "Cost on val dataset after 60 epochs is = 0.720309111283709\n",
      "Initial Cost on Val dataset for this epoch 60 = 0.720309111283709\n",
      "learning rate for this epoch =  0.03593041119630843\n",
      "Error on this batch = 0.36830303542911735\n",
      "Error on this batch = 0.6774624859968607\n",
      "Cost on val dataset after 61 epochs is = 0.7174689694660624\n",
      "Initial Cost on Val dataset for this epoch 61 = 0.7174689694660624\n",
      "learning rate for this epoch =  0.03578224139610262\n",
      "Error on this batch = 0.363905532005148\n",
      "Error on this batch = 0.6707478820588517\n",
      "Cost on val dataset after 62 epochs is = 0.7147270258333436\n",
      "Initial Cost on Val dataset for this epoch 62 = 0.7147270258333436\n",
      "learning rate for this epoch =  0.03563707718096288\n",
      "Error on this batch = 0.3596138395267414\n",
      "Error on this batch = 0.6641200106472736\n",
      "Cost on val dataset after 63 epochs is = 0.7120798323040333\n",
      "Initial Cost on Val dataset for this epoch 63 = 0.7120798323040333\n",
      "learning rate for this epoch =  0.03549481056010053\n",
      "Error on this batch = 0.3554234720745421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.6575779437753928\n",
      "Cost on val dataset after 64 epochs is = 0.7095241290087071\n",
      "Initial Cost on Val dataset for this epoch 64 = 0.7095241290087071\n",
      "learning rate for this epoch =  0.035355339059327376\n",
      "Error on this batch = 0.35133024348788433\n",
      "Error on this batch = 0.651120765194832\n",
      "Cost on val dataset after 65 epochs is = 0.7070568398602558\n",
      "Initial Cost on Val dataset for this epoch 65 = 0.7070568398602558\n",
      "learning rate for this epoch =  0.03521856535823236\n",
      "Error on this batch = 0.3473302377733606\n",
      "Error on this batch = 0.6447475526927045\n",
      "Cost on val dataset after 66 epochs is = 0.7046750682018554\n",
      "Initial Cost on Val dataset for this epoch 66 = 0.7046750682018554\n",
      "learning rate for this epoch =  0.035084396956386855\n",
      "Error on this batch = 0.34341977731816914\n",
      "Error on this batch = 0.6384573677114791\n",
      "Cost on val dataset after 67 epochs is = 0.7023760920229639\n",
      "Initial Cost on Val dataset for this epoch 67 = 0.7023760920229639\n",
      "learning rate for this epoch =  0.034952745865855124\n",
      "Error on this batch = 0.33959538977407905\n",
      "Error on this batch = 0.6322492510770363\n",
      "Cost on val dataset after 68 epochs is = 0.7001573583132087\n",
      "Initial Cost on Val dataset for this epoch 68 = 0.7001573583132087\n",
      "learning rate for this epoch =  0.03482352832757854\n",
      "Error on this batch = 0.335853774504486\n",
      "Error on this batch = 0.6261222235146665\n",
      "Cost on val dataset after 69 epochs is = 0.6980164762280278\n",
      "Initial Cost on Val dataset for this epoch 69 = 0.6980164762280278\n",
      "learning rate for this epoch =  0.034696664549459105\n",
      "Error on this batch = 0.3321917695376546\n",
      "Error on this batch = 0.6200752895830152\n",
      "Cost on val dataset after 70 epochs is = 0.6959512088706691\n",
      "Initial Cost on Val dataset for this epoch 70 = 0.6959512088706691\n",
      "learning rate for this epoch =  0.034572078464194106\n",
      "Error on this batch = 0.32860632003825246\n",
      "Error on this batch = 0.6141074436458784\n",
      "Cost on val dataset after 71 epochs is = 0.6939594636458822\n",
      "Initial Cost on Val dataset for this epoch 71 = 0.6939594636458822\n",
      "learning rate for this epoch =  0.03444969750511394\n",
      "Error on this batch = 0.32509444937816573\n",
      "Error on this batch = 0.6082176765219431\n",
      "Cost on val dataset after 72 epochs is = 0.6920392812977493\n",
      "Initial Cost on Val dataset for this epoch 72 = 0.6920392812977493\n",
      "learning rate for this epoch =  0.03432945239845196\n",
      "Error on this batch = 0.3216532339271841\n",
      "Error on this batch = 0.6024049815075343\n",
      "Cost on val dataset after 73 epochs is = 0.6901888238906301\n",
      "Initial Cost on Val dataset for this epoch 73 = 0.6901888238906301\n",
      "learning rate for this epoch =  0.03421127697063215\n",
      "Error on this batch = 0.318279782658463\n",
      "Error on this batch = 0.5966683585777134\n",
      "Cost on val dataset after 74 epochs is = 0.6884063621117599\n",
      "Initial Cost on Val dataset for this epoch 74 = 0.6884063621117599\n",
      "learning rate for this epoch =  0.03409510796929954\n",
      "Error on this batch = 0.3149712225369282\n",
      "Error on this batch = 0.591006815767114\n",
      "Cost on val dataset after 75 epochs is = 0.6866902623538139\n",
      "Initial Cost on Val dataset for this epoch 75 = 0.6866902623538139\n",
      "learning rate for this epoch =  0.033980884896942454\n",
      "Error on this batch = 0.3117246904057037\n",
      "Error on this batch = 0.5854193670387337\n",
      "Cost on val dataset after 76 epochs is = 0.6850389740685472\n",
      "Initial Cost on Val dataset for this epoch 76 = 0.6850389740685472\n",
      "learning rate for this epoch =  0.033868549856065716\n",
      "Error on this batch = 0.30853733170379516\n",
      "Error on this batch = 0.5799050263675006\n",
      "Cost on val dataset after 77 epochs is = 0.6834510178678594\n",
      "Initial Cost on Val dataset for this epoch 77 = 0.6834510178678594\n",
      "learning rate for this epoch =  0.03375804740497264\n",
      "Error on this batch = 0.30540630586754386\n",
      "Error on this batch = 0.5744627982595009\n",
      "Cost on val dataset after 78 epochs is = 0.6819249747918824\n",
      "Initial Cost on Val dataset for this epoch 78 = 0.6819249747918824\n",
      "learning rate for this epoch =  0.03364932442330151\n",
      "Error on this batch = 0.3023287977503097\n",
      "Error on this batch = 0.5690916654263328\n",
      "Cost on val dataset after 79 epochs is = 0.6804594770752812\n",
      "Initial Cost on Val dataset for this epoch 79 = 0.6804594770752812\n",
      "learning rate for this epoch =  0.03354232998654124\n",
      "Error on this batch = 0.29930203391824317\n",
      "Error on this batch = 0.5637905747517188\n",
      "Cost on val dataset after 80 epochs is = 0.679053200634969\n",
      "Initial Cost on Val dataset for this epoch 80 = 0.679053200634969\n",
      "learning rate for this epoch =  0.0334370152488211\n",
      "Error on this batch = 0.2963233023164036\n",
      "Error on this batch = 0.5585584229529326\n",
      "Cost on val dataset after 81 epochs is = 0.6777048593858446\n",
      "Initial Cost on Val dataset for this epoch 81 = 0.6777048593858446\n",
      "learning rate for this epoch =  0.03333333333333333\n",
      "Error on this batch = 0.29338997359161306\n",
      "Error on this batch = 0.5533940434178725\n",
      "Cost on val dataset after 82 epochs is = 0.6764132013736177\n",
      "Initial Cost on Val dataset for this epoch 82 = 0.6764132013736177\n",
      "learning rate for this epoch =  0.03323123922980402\n",
      "Error on this batch = 0.29049952231339654\n",
      "Error on this batch = 0.548296195594857\n",
      "Cost on val dataset after 83 epochs is = 0.6751770065998076\n",
      "Initial Cost on Val dataset for this epoch 83 = 0.6751770065998076\n",
      "learning rate for this epoch =  0.033130689698479016\n",
      "Error on this batch = 0.2876495464358215\n",
      "Error on this batch = 0.5432635580580952\n",
      "Cost on val dataset after 84 epochs is = 0.6739950863070576\n",
      "Initial Cost on Val dataset for this epoch 84 = 0.6739950863070576\n",
      "learning rate for this epoch =  0.03303164318013808\n",
      "Error on this batch = 0.28483778357160966\n",
      "Error on this batch = 0.5382947260073537\n",
      "Cost on val dataset after 85 epochs is = 0.6728662833987044\n",
      "Initial Cost on Val dataset for this epoch 85 = 0.6728662833987044\n",
      "learning rate for this epoch =  0.032934059711691804\n",
      "Error on this batch = 0.2820621229951083\n",
      "Error on this batch = 0.5333882135241713\n",
      "Cost on val dataset after 86 epochs is = 0.6717894735947594\n",
      "Initial Cost on Val dataset for this epoch 86 = 0.6717894735947594\n",
      "learning rate for this epoch =  0.03283790084695403\n",
      "Error on this batch = 0.2793206127443727\n",
      "Error on this batch = 0.5285424604394556\n",
      "Cost on val dataset after 87 epochs is = 0.6707635668896909\n",
      "Initial Cost on Val dataset for this epoch 87 = 0.6707635668896909\n",
      "learning rate for this epoch =  0.0327431295822161\n",
      "Error on this batch = 0.2766114617278695\n",
      "Error on this batch = 0.5237558432186309\n",
      "Cost on val dataset after 88 epochs is = 0.6697875088868642\n",
      "Initial Cost on Val dataset for this epoch 88 = 0.6697875088868642\n",
      "learning rate for this epoch =  0.032649710286280526\n",
      "Error on this batch = 0.2739330372948091\n",
      "Error on this batch = 0.5190266889018003\n",
      "Cost on val dataset after 89 epochs is = 0.6688602816444292\n",
      "Initial Cost on Val dataset for this epoch 89 = 0.6688602816444292\n",
      "learning rate for this epoch =  0.03255760863463962\n",
      "Error on this batch = 0.2712838592036177\n",
      "Error on this batch = 0.5143532909067196\n",
      "Cost on val dataset after 90 epochs is = 0.6679809037712128\n",
      "Initial Cost on Val dataset for this epoch 90 = 0.6679809037712128\n",
      "learning rate for this epoch =  0.03246679154750989\n",
      "Error on this batch = 0.2686625912199312\n",
      "Error on this batch = 0.5097339254479143\n",
      "Cost on val dataset after 91 epochs is = 0.6671484296417182\n",
      "Initial Cost on Val dataset for this epoch 91 = 0.6671484296417182\n",
      "learning rate for this epoch =  0.03237722713145643\n",
      "Error on this batch = 0.26606803162924264\n",
      "Error on this batch = 0.5051668674431565\n",
      "Cost on val dataset after 92 epochs is = 0.666361947733479\n",
      "Initial Cost on Val dataset for this epoch 92 = 0.666361947733479\n",
      "learning rate for this epoch =  0.032288884624362205\n",
      "Error on this batch = 0.2634991037604885\n",
      "Error on this batch = 0.500650405026113\n",
      "Cost on val dataset after 93 epochs is = 0.6656205782054536\n",
      "Initial Cost on Val dataset for this epoch 93 = 0.6656205782054536\n",
      "learning rate for this epoch =  0.03220173434351674\n",
      "Error on this batch = 0.2609548472524764\n",
      "Error on this batch = 0.4961828520945838\n",
      "Cost on val dataset after 94 epochs is = 0.6649234699167269\n",
      "Initial Cost on Val dataset for this epoch 94 = 0.6649234699167269\n",
      "learning rate for this epoch =  0.0321157476366158\n",
      "Error on this batch = 0.25843441036251596\n",
      "Error on this batch = 0.4917625586295195\n",
      "Cost on val dataset after 95 epochs is = 0.6642697971234827\n",
      "Initial Cost on Val dataset for this epoch 95 = 0.6642697971234827\n",
      "learning rate for this epoch =  0.03203089683547987\n",
      "Error on this batch = 0.2559370432253678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4873879187714366\n",
      "Cost on val dataset after 96 epochs is = 0.6636587560904479\n",
      "Initial Cost on Val dataset for this epoch 96 = 0.6636587560904479\n",
      "learning rate for this epoch =  0.03194715521231362\n",
      "Error on this batch = 0.25346209169954426\n",
      "Error on this batch = 0.48305737681519106\n",
      "Cost on val dataset after 97 epochs is = 0.6630895618182764\n",
      "Initial Cost on Val dataset for this epoch 97 = 0.6630895618182764\n",
      "learning rate for this epoch =  0.031864496938342195\n",
      "Error on this batch = 0.2510089913201687\n",
      "Error on this batch = 0.47876943138302963\n",
      "Cost on val dataset after 98 epochs is = 0.6625614450315347\n",
      "Initial Cost on Val dataset for this epoch 98 = 0.6625614450315347\n",
      "learning rate for this epoch =  0.031782897044671854\n",
      "Error on this batch = 0.24857726090304874\n",
      "Error on this batch = 0.4745226380764392\n",
      "Cost on val dataset after 99 epochs is = 0.6620736495047799\n",
      "Initial Cost on Val dataset for this epoch 99 = 0.6620736495047799\n",
      "learning rate for this epoch =  0.0317023313852343\n",
      "Error on this batch = 0.24616649547403302\n",
      "Error on this batch = 0.4703156109115726\n",
      "Cost on val dataset after 100 epochs is = 0.6616254297379166\n",
      "Initial Cost on Val dataset for this epoch 100 = 0.6616254297379166\n",
      "learning rate for this epoch =  0.03162277660168379\n",
      "Error on this batch = 0.24377635838001369\n",
      "Error on this batch = 0.46614702282997655\n",
      "Cost on val dataset after 101 epochs is = 0.6612160489359875\n",
      "Initial Cost on Val dataset for this epoch 101 = 0.6612160489359875\n",
      "learning rate for this epoch =  0.03154421009012572\n",
      "Error on this batch = 0.24140657262453755\n",
      "Error on this batch = 0.46201560555810944\n",
      "Cost on val dataset after 102 epochs is = 0.6608447772097171\n",
      "Initial Cost on Val dataset for this epoch 102 = 0.6608447772097171\n",
      "learning rate for this epoch =  0.03146660996956416\n",
      "Error on this batch = 0.23905691162518905\n",
      "Error on this batch = 0.45792014907051026\n",
      "Cost on val dataset after 103 epochs is = 0.6605108898953872\n",
      "Initial Cost on Val dataset for this epoch 103 = 0.6605108898953872\n",
      "learning rate for this epoch =  0.03138995505196357\n",
      "Error on this batch = 0.2367271896906883\n",
      "Error on this batch = 0.4538595008918893\n",
      "Cost on val dataset after 104 epochs is = 0.660213665896556\n",
      "Initial Cost on Val dataset for this epoch 104 = 0.660213665896556\n",
      "learning rate for this epoch =  0.03131422481382735\n",
      "Error on this batch = 0.23441725255707052\n",
      "Error on this batch = 0.4498325654495985\n",
      "Cost on val dataset after 105 epochs is = 0.6599523859733016\n",
      "Initial Cost on Val dataset for this epoch 105 = 0.6599523859733016\n",
      "learning rate for this epoch =  0.03123939936920256\n",
      "Error on this batch = 0.23212696831043272\n",
      "Error on this batch = 0.4458383036564683\n",
      "Cost on val dataset after 106 epochs is = 0.6597263309421239\n",
      "Initial Cost on Val dataset for this epoch 106 = 0.6597263309421239\n",
      "learning rate for this epoch =  0.031165459444026558\n",
      "Error on this batch = 0.22985621897205719\n",
      "Error on this batch = 0.4418757328625806\n",
      "Cost on val dataset after 107 epochs is = 0.6595347797947124\n",
      "Initial Cost on Val dataset for this epoch 107 = 0.6595347797947124\n",
      "learning rate for this epoch =  0.03109238635173672\n",
      "Error on this batch = 0.2276048929469517\n",
      "Error on this batch = 0.43794392726289033\n",
      "Cost on val dataset after 108 epochs is = 0.6593770077891953\n",
      "Initial Cost on Val dataset for this epoch 108 = 0.6593770077891953\n",
      "learning rate for this epoch =  0.031020161970069987\n",
      "Error on this batch = 0.22537287845515067\n",
      "Error on this batch = 0.4340420187872627\n",
      "Cost on val dataset after 109 epochs is = 0.6592522846060409\n",
      "Initial Cost on Val dataset for this epoch 109 = 0.6592522846060409\n",
      "learning rate for this epoch =  0.030948768718983822\n",
      "Error on this batch = 0.22316005798987681\n",
      "Error on this batch = 0.430169198433845\n",
      "Cost on val dataset after 110 epochs is = 0.6591598726866676\n",
      "Initial Cost on Val dataset for this epoch 110 = 0.6591598726866676\n",
      "learning rate for this epoch =  0.030878189539634483\n",
      "Error on this batch = 0.2209663037871055\n",
      "Error on this batch = 0.42632471794095644\n",
      "Cost on val dataset after 111 epochs is = 0.6590990258820351\n",
      "Initial Cost on Val dataset for this epoch 111 = 0.6590990258820351\n",
      "learning rate for this epoch =  0.03080840787435305\n",
      "Error on this batch = 0.21879147425199452\n",
      "Error on this batch = 0.4225078916333017\n",
      "Cost on val dataset after 112 epochs is = 0.6590689885298519\n",
      "Initial Cost on Val dataset for this epoch 112 = 0.6590689885298519\n",
      "learning rate for this epoch =  0.03073940764756322\n",
      "Error on this batch = 0.21663541126960512\n",
      "Error on this batch = 0.4187180982328417\n",
      "Cost on val dataset after 113 epochs is = 0.6590689950541168\n",
      "Initial Cost on Val dataset for this epoch 113 = 0.6590689950541168\n",
      "learning rate for this epoch =  0.030671173247588647\n",
      "Error on this batch = 0.2144979383272848\n",
      "Error on this batch = 0.4149547824001269\n",
      "Cost on val dataset after 114 epochs is = 0.6590982701438248\n",
      "Initial Cost on Val dataset for this epoch 114 = 0.6590982701438248\n",
      "learning rate for this epoch =  0.0306036895093009\n",
      "Error on this batch = 0.21237885938836493\n",
      "Error on this batch = 0.41121745577345353\n",
      "Cost on val dataset after 115 epochs is = 0.6591560295249443\n",
      "Initial Cost on Val dataset for this epoch 115 = 0.6591560295249443\n",
      "learning rate for this epoch =  0.030536941697562214\n",
      "Error on this batch = 0.21027795847434008\n",
      "Error on this batch = 0.4075056973026557\n",
      "Cost on val dataset after 116 epochs is = 0.6592414812978483\n",
      "Initial Cost on Val dataset for this epoch 116 = 0.6592414812978483\n",
      "learning rate for this epoch =  0.03047091549142\n",
      "Error on this batch = 0.20819499992844406\n",
      "Error on this batch = 0.40381915272879076\n",
      "Cost on val dataset after 117 epochs is = 0.6593538277772112\n",
      "Initial Cost on Val dataset for this epoch 117 = 0.6593538277772112\n",
      "learning rate for this epoch =  0.030405596969012936\n",
      "Error on this batch = 0.20612972934197135\n",
      "Error on this batch = 0.40015753313345437\n",
      "Cost on val dataset after 118 epochs is = 0.6594922677468957\n",
      "Initial Cost on Val dataset for this epoch 118 = 0.6594922677468957\n",
      "learning rate for this epoch =  0.030340972593150727\n",
      "Error on this batch = 0.20408187512280965\n",
      "Error on this batch = 0.3965206125617627\n",
      "Cost on val dataset after 119 epochs is = 0.6596559990300415\n",
      "Initial Cost on Val dataset for this epoch 119 = 0.6596559990300415\n",
      "learning rate for this epoch =  0.030277029197532102\n",
      "Error on this batch = 0.20205115067345372\n",
      "Error on this batch = 0.39290822480005605\n",
      "Cost on val dataset after 120 epochs is = 0.6598442212733892\n",
      "Initial Cost on Val dataset for this epoch 120 = 0.6598442212733892\n",
      "learning rate for this epoch =  0.030213753973567684\n",
      "Error on this batch = 0.20003725712592144\n",
      "Error on this batch = 0.38932025945328674\n",
      "Cost on val dataset after 121 epochs is = 0.660056138852186\n",
      "Initial Cost on Val dataset for this epoch 121 = 0.660056138852186\n",
      "learning rate for this epoch =  0.030151134457776365\n",
      "Error on this batch = 0.19803988655783117\n",
      "Error on this batch = 0.38575665751096955\n",
      "Cost on val dataset after 122 epochs is = 0.6602909638140824\n",
      "cost initial= 0.660056138852186 , cost final=0.6602909638140824 , change in cost= 0.00023482496189641822\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer = [100, 100] with softplus are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs with softplus is = 122\n",
      "The training time with softplus is = 52.935sec\n",
      "The training accuracy with softplus is = 97.041%\n",
      "The validation accuracy with softplus is = 91.333%\n",
      "The test accuracy with softplus is = 89.800%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.1\n",
    "theta = theta_init(arch, 'normal')\n",
    "print(\"Training the network with {} hidden layer with {} units\".format(len(arch), arch))\n",
    "print(\"The parameters of the layers are of the shape:\")\n",
    "\n",
    "for j in range(len(theta)):\n",
    "    print(\"theta between layer {} and layer {} is {}\".format(j, j+1,theta[j].shape))\n",
    "    \n",
    "start = time.time()\n",
    "epoch, theta = training(mini_batch, X_valid, valid_class_enc, theta, lr, 'softplus', 'adaptive', 'entropy')\n",
    "\n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc, 'softplus'))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc, 'softplus'))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc, 'softplus'))\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer = {} with softplus are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs with softplus is = {}\".format(epochs[-1]))\n",
    "print(\"The training time with softplus is = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy with softplus is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy with softplus is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy with softplus is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Plotting Graphs for Part F - ReLU with Cross Entropy ------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"------------------Plotting Graphs for Part F - ReLU with Cross Entropy ------------------\")\n",
    "x=[0,1]\n",
    "data = [' ','ReLU', ' ' ,' ' ,' ',' ','Softplus']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy and Epochs for Neural Network [100,100]\\n with Cross-Entropy\")\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, valid_accuracy, marker='o',label='Validation Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Activation Function\")\n",
    "ax.set_xticklabels(data)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend()\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "plt.legend(loc=4)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/partf/comp_diff_act.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E - MLP Classifier using SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Running Part E-----------------------------------------------------\n",
      "------------------Training a 100x100 hidden layer network with MLP Classifier------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------Running Part E-----------------------------------------------------\")\n",
    "print(\"------------------Training a 100x100 hidden layer network with MLP Classifier------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlp_classifier\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "train_time = []\n",
    "clf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier - logistic with constant LR\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=300,\n",
    "                     tol=1e-5, verbose=True))\n",
    "#Classifier - logistic with early_stopping =True\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=300,\n",
    "                     early_stopping=True, tol=1e-5, verbose=True))\n",
    "#Classifier - logistic with invscaling with sqrt\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=1.5, learning_rate='invscaling', max_iter=300,\n",
    "                     tol=1e-4, verbose=True))\n",
    "#Classifier - logistic with invscaling with pow(1/4)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='logistic', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=1.5, learning_rate='invscaling', max_iter=300,\n",
    "                     power_t=(1/4), tol=1e-4, verbose=True))\n",
    "\n",
    "\n",
    "#Classifier ReLU with constant LR (1e-4)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=300,\n",
    "                     tol=1e-4, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-5)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=300,\n",
    "                     tol=1e-5, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-6) with early stopping\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.1, learning_rate='constant', max_iter=300,\n",
    "                     early_stopping=True, tol=1e-5, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-6) with invscaling sqrt\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.5, learning_rate='invscaling', max_iter=300,\n",
    "                     tol=1e-6, verbose=True))\n",
    "#Classifier ReLU with constant LR (1e-6) with invscaling pow(1/3)\n",
    "clf.append(mlp_classifier(hidden_layer_sizes=(100, 100), activation='relu', solver='sgd', \n",
    "                     batch_size=100, learning_rate_init=0.5, learning_rate='invscaling', max_iter=300,\n",
    "                     power_t=(1/4), tol=1e-6, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.40460332\n",
      "Iteration 2, loss = 3.65825736\n",
      "Iteration 3, loss = 2.59341721\n",
      "Iteration 4, loss = 1.86808921\n",
      "Iteration 5, loss = 1.46228532\n",
      "Iteration 6, loss = 1.19062547\n",
      "Iteration 7, loss = 1.02016738\n",
      "Iteration 8, loss = 0.89905273\n",
      "Iteration 9, loss = 0.80256029\n",
      "Iteration 10, loss = 0.72540441\n",
      "Iteration 11, loss = 0.66169977\n",
      "Iteration 12, loss = 0.60209063\n",
      "Iteration 13, loss = 0.55435190\n",
      "Iteration 14, loss = 0.50824701\n",
      "Iteration 15, loss = 0.46989664\n",
      "Iteration 16, loss = 0.43329583\n",
      "Iteration 17, loss = 0.40106575\n",
      "Iteration 18, loss = 0.37162261\n",
      "Iteration 19, loss = 0.34410214\n",
      "Iteration 20, loss = 0.31897630\n",
      "Iteration 21, loss = 0.29833690\n",
      "Iteration 22, loss = 0.27616668\n",
      "Iteration 23, loss = 0.25753959\n",
      "Iteration 24, loss = 0.23963949\n",
      "Iteration 25, loss = 0.22465562\n",
      "Iteration 26, loss = 0.20750124\n",
      "Iteration 27, loss = 0.19434431\n",
      "Iteration 28, loss = 0.18315380\n",
      "Iteration 29, loss = 0.16932220\n",
      "Iteration 30, loss = 0.15890379\n",
      "Iteration 31, loss = 0.14707486\n",
      "Iteration 32, loss = 0.13840479\n",
      "Iteration 33, loss = 0.13002659\n",
      "Iteration 34, loss = 0.12127050\n",
      "Iteration 35, loss = 0.11458463\n",
      "Iteration 36, loss = 0.10738695\n",
      "Iteration 37, loss = 0.10053629\n",
      "Iteration 38, loss = 0.09446812\n",
      "Iteration 39, loss = 0.08888247\n",
      "Iteration 40, loss = 0.08348534\n",
      "Iteration 41, loss = 0.07913526\n",
      "Iteration 42, loss = 0.07506207\n",
      "Iteration 43, loss = 0.07082417\n",
      "Iteration 44, loss = 0.06617989\n",
      "Iteration 45, loss = 0.06339926\n",
      "Iteration 46, loss = 0.06036783\n",
      "Iteration 47, loss = 0.05783983\n",
      "Iteration 48, loss = 0.05485184\n",
      "Iteration 49, loss = 0.05215946\n",
      "Iteration 50, loss = 0.04989933\n",
      "Iteration 51, loss = 0.04771127\n",
      "Iteration 52, loss = 0.04546919\n",
      "Iteration 53, loss = 0.04370078\n",
      "Iteration 54, loss = 0.04181560\n",
      "Iteration 55, loss = 0.03992045\n",
      "Iteration 56, loss = 0.03879798\n",
      "Iteration 57, loss = 0.03706502\n",
      "Iteration 58, loss = 0.03568478\n",
      "Iteration 59, loss = 0.03460123\n",
      "Iteration 60, loss = 0.03346881\n",
      "Iteration 61, loss = 0.03233961\n",
      "Iteration 62, loss = 0.03131941\n",
      "Iteration 63, loss = 0.03041169\n",
      "Iteration 64, loss = 0.02937328\n",
      "Iteration 65, loss = 0.02846130\n",
      "Iteration 66, loss = 0.02766459\n",
      "Iteration 67, loss = 0.02686969\n",
      "Iteration 68, loss = 0.02619908\n",
      "Iteration 69, loss = 0.02566509\n",
      "Iteration 70, loss = 0.02491060\n",
      "Iteration 71, loss = 0.02430568\n",
      "Iteration 72, loss = 0.02378324\n",
      "Iteration 73, loss = 0.02319618\n",
      "Iteration 74, loss = 0.02270638\n",
      "Iteration 75, loss = 0.02229419\n",
      "Iteration 76, loss = 0.02178419\n",
      "Iteration 77, loss = 0.02135950\n",
      "Iteration 78, loss = 0.02089837\n",
      "Iteration 79, loss = 0.02054251\n",
      "Iteration 80, loss = 0.02013434\n",
      "Iteration 81, loss = 0.01980036\n",
      "Iteration 82, loss = 0.01948302\n",
      "Iteration 83, loss = 0.01917230\n",
      "Iteration 84, loss = 0.01884028\n",
      "Iteration 85, loss = 0.01856316\n",
      "Iteration 86, loss = 0.01822751\n",
      "Iteration 87, loss = 0.01793694\n",
      "Iteration 88, loss = 0.01764419\n",
      "Iteration 89, loss = 0.01743937\n",
      "Iteration 90, loss = 0.01717637\n",
      "Iteration 91, loss = 0.01694908\n",
      "Iteration 92, loss = 0.01669067\n",
      "Iteration 93, loss = 0.01649996\n",
      "Iteration 94, loss = 0.01630108\n",
      "Iteration 95, loss = 0.01603015\n",
      "Iteration 96, loss = 0.01587349\n",
      "Iteration 97, loss = 0.01565323\n",
      "Iteration 98, loss = 0.01548490\n",
      "Iteration 99, loss = 0.01531070\n",
      "Iteration 100, loss = 0.01513245\n",
      "Iteration 101, loss = 0.01495096\n",
      "Iteration 102, loss = 0.01481403\n",
      "Iteration 103, loss = 0.01464677\n",
      "Iteration 104, loss = 0.01447748\n",
      "Iteration 105, loss = 0.01435223\n",
      "Iteration 106, loss = 0.01422201\n",
      "Iteration 107, loss = 0.01407006\n",
      "Iteration 108, loss = 0.01391471\n",
      "Iteration 109, loss = 0.01379470\n",
      "Iteration 110, loss = 0.01369154\n",
      "Iteration 111, loss = 0.01355423\n",
      "Iteration 112, loss = 0.01343865\n",
      "Iteration 113, loss = 0.01330840\n",
      "Iteration 114, loss = 0.01321249\n",
      "Iteration 115, loss = 0.01310142\n",
      "Iteration 116, loss = 0.01298407\n",
      "Iteration 117, loss = 0.01288661\n",
      "Iteration 118, loss = 0.01277362\n",
      "Iteration 119, loss = 0.01265411\n",
      "Iteration 120, loss = 0.01258023\n",
      "Iteration 121, loss = 0.01249746\n",
      "Iteration 122, loss = 0.01241155\n",
      "Iteration 123, loss = 0.01231473\n",
      "Iteration 124, loss = 0.01223288\n",
      "Iteration 125, loss = 0.01213745\n",
      "Iteration 126, loss = 0.01204023\n",
      "Iteration 127, loss = 0.01197678\n",
      "Iteration 128, loss = 0.01189792\n",
      "Iteration 129, loss = 0.01182631\n",
      "Iteration 130, loss = 0.01174179\n",
      "Iteration 131, loss = 0.01166801\n",
      "Iteration 132, loss = 0.01161189\n",
      "Iteration 133, loss = 0.01153192\n",
      "Iteration 134, loss = 0.01145476\n",
      "Iteration 135, loss = 0.01139906\n",
      "Iteration 136, loss = 0.01132273\n",
      "Iteration 137, loss = 0.01126198\n",
      "Iteration 138, loss = 0.01119580\n",
      "Iteration 139, loss = 0.01113412\n",
      "Iteration 140, loss = 0.01107961\n",
      "Iteration 141, loss = 0.01100240\n",
      "Iteration 142, loss = 0.01095875\n",
      "Iteration 143, loss = 0.01090911\n",
      "Iteration 144, loss = 0.01085206\n",
      "Iteration 145, loss = 0.01079314\n",
      "Iteration 146, loss = 0.01074778\n",
      "Iteration 147, loss = 0.01068993\n",
      "Iteration 148, loss = 0.01065170\n",
      "Iteration 149, loss = 0.01059266\n",
      "Iteration 150, loss = 0.01054335\n",
      "Iteration 151, loss = 0.01049554\n",
      "Iteration 152, loss = 0.01044857\n",
      "Iteration 153, loss = 0.01040894\n",
      "Iteration 154, loss = 0.01035517\n",
      "Iteration 155, loss = 0.01032177\n",
      "Iteration 156, loss = 0.01026075\n",
      "Iteration 157, loss = 0.01023273\n",
      "Iteration 158, loss = 0.01018419\n",
      "Iteration 159, loss = 0.01014498\n",
      "Iteration 160, loss = 0.01010816\n",
      "Iteration 161, loss = 0.01006448\n",
      "Iteration 162, loss = 0.01002928\n",
      "Iteration 163, loss = 0.00998688\n",
      "Iteration 164, loss = 0.00994585\n",
      "Iteration 165, loss = 0.00991461\n",
      "Iteration 166, loss = 0.00987625\n",
      "Iteration 167, loss = 0.00984336\n",
      "Iteration 168, loss = 0.00980434\n",
      "Iteration 169, loss = 0.00977845\n",
      "Iteration 170, loss = 0.00973321\n",
      "Iteration 171, loss = 0.00970183\n",
      "Iteration 172, loss = 0.00967627\n",
      "Iteration 173, loss = 0.00963897\n",
      "Iteration 174, loss = 0.00960945\n",
      "Iteration 175, loss = 0.00958250\n",
      "Iteration 176, loss = 0.00954386\n",
      "Iteration 177, loss = 0.00951408\n",
      "Iteration 178, loss = 0.00949245\n",
      "Iteration 179, loss = 0.00945253\n",
      "Iteration 180, loss = 0.00943035\n",
      "Iteration 181, loss = 0.00939806\n",
      "Iteration 182, loss = 0.00937703\n",
      "Iteration 183, loss = 0.00934656\n",
      "Iteration 184, loss = 0.00932061\n",
      "Iteration 185, loss = 0.00928748\n",
      "Iteration 186, loss = 0.00926873\n",
      "Iteration 187, loss = 0.00923812\n",
      "Iteration 188, loss = 0.00921832\n",
      "Iteration 189, loss = 0.00919485\n",
      "Iteration 190, loss = 0.00916865\n",
      "Iteration 191, loss = 0.00914586\n",
      "Iteration 192, loss = 0.00911963\n",
      "Iteration 193, loss = 0.00909737\n",
      "Iteration 194, loss = 0.00907375\n",
      "Iteration 195, loss = 0.00904686\n",
      "Iteration 196, loss = 0.00902738\n",
      "Iteration 197, loss = 0.00900312\n",
      "Iteration 198, loss = 0.00898518\n",
      "Iteration 199, loss = 0.00896121\n",
      "Iteration 200, loss = 0.00894048\n",
      "Iteration 201, loss = 0.00892280\n",
      "Iteration 202, loss = 0.00889935\n",
      "Iteration 203, loss = 0.00887552\n",
      "Iteration 204, loss = 0.00886129\n",
      "Iteration 205, loss = 0.00883932\n",
      "Iteration 206, loss = 0.00882030\n",
      "Iteration 207, loss = 0.00880226\n",
      "Iteration 208, loss = 0.00878532\n",
      "Iteration 209, loss = 0.00876514\n",
      "Iteration 210, loss = 0.00874537\n",
      "Iteration 211, loss = 0.00872640\n",
      "Iteration 212, loss = 0.00870637\n",
      "Iteration 213, loss = 0.00869449\n",
      "Iteration 214, loss = 0.00867463\n",
      "Iteration 215, loss = 0.00865820\n",
      "Iteration 216, loss = 0.00864281\n",
      "Iteration 217, loss = 0.00862223\n",
      "Iteration 218, loss = 0.00860423\n",
      "Iteration 219, loss = 0.00858925\n",
      "Iteration 220, loss = 0.00858035\n",
      "Iteration 221, loss = 0.00855651\n",
      "Iteration 222, loss = 0.00854304\n",
      "Iteration 223, loss = 0.00852476\n",
      "Iteration 224, loss = 0.00851121\n",
      "Iteration 225, loss = 0.00849722\n",
      "Iteration 226, loss = 0.00848261\n",
      "Iteration 227, loss = 0.00846866\n",
      "Iteration 228, loss = 0.00845148\n",
      "Iteration 229, loss = 0.00843967\n",
      "Iteration 230, loss = 0.00842487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 231, loss = 0.00840981\n",
      "Iteration 232, loss = 0.00839582\n",
      "Iteration 233, loss = 0.00838108\n",
      "Iteration 234, loss = 0.00836873\n",
      "Iteration 235, loss = 0.00835429\n",
      "Iteration 236, loss = 0.00834193\n",
      "Iteration 237, loss = 0.00832810\n",
      "Iteration 238, loss = 0.00831695\n",
      "Iteration 239, loss = 0.00830648\n",
      "Iteration 240, loss = 0.00829066\n",
      "Iteration 241, loss = 0.00827799\n",
      "Iteration 242, loss = 0.00826699\n",
      "Iteration 243, loss = 0.00825326\n",
      "Iteration 244, loss = 0.00823967\n",
      "Iteration 245, loss = 0.00823038\n",
      "Iteration 246, loss = 0.00821543\n",
      "Iteration 247, loss = 0.00820735\n",
      "Iteration 248, loss = 0.00819543\n",
      "Iteration 249, loss = 0.00818116\n",
      "Iteration 250, loss = 0.00817171\n",
      "Iteration 251, loss = 0.00816020\n",
      "Iteration 252, loss = 0.00815119\n",
      "Iteration 253, loss = 0.00814103\n",
      "Iteration 254, loss = 0.00812860\n",
      "Iteration 255, loss = 0.00811858\n",
      "Iteration 256, loss = 0.00810774\n",
      "Iteration 257, loss = 0.00809577\n",
      "Iteration 258, loss = 0.00808757\n",
      "Iteration 259, loss = 0.00807425\n",
      "Iteration 260, loss = 0.00806730\n",
      "Iteration 261, loss = 0.00805628\n",
      "Iteration 262, loss = 0.00804627\n",
      "Iteration 263, loss = 0.00803649\n",
      "Iteration 264, loss = 0.00802831\n",
      "Iteration 265, loss = 0.00801662\n",
      "Iteration 266, loss = 0.00800879\n",
      "Iteration 267, loss = 0.00799852\n",
      "Iteration 268, loss = 0.00798851\n",
      "Iteration 269, loss = 0.00798038\n",
      "Iteration 270, loss = 0.00797294\n",
      "Iteration 271, loss = 0.00796237\n",
      "Iteration 272, loss = 0.00795478\n",
      "Iteration 273, loss = 0.00794590\n",
      "Iteration 274, loss = 0.00793652\n",
      "Iteration 275, loss = 0.00792587\n",
      "Iteration 276, loss = 0.00791754\n",
      "Iteration 277, loss = 0.00791118\n",
      "Iteration 278, loss = 0.00790316\n",
      "Iteration 279, loss = 0.00789492\n",
      "Iteration 280, loss = 0.00788515\n",
      "Iteration 281, loss = 0.00787488\n",
      "Iteration 282, loss = 0.00786777\n",
      "Iteration 283, loss = 0.00786048\n",
      "Iteration 284, loss = 0.00785594\n",
      "Iteration 285, loss = 0.00784575\n",
      "Iteration 286, loss = 0.00783836\n",
      "Iteration 287, loss = 0.00782862\n",
      "Iteration 288, loss = 0.00782286\n",
      "Iteration 289, loss = 0.00781662\n",
      "Iteration 290, loss = 0.00780892\n",
      "Iteration 291, loss = 0.00780055\n",
      "Iteration 292, loss = 0.00779330\n",
      "Iteration 293, loss = 0.00778600\n",
      "Iteration 294, loss = 0.00777572\n",
      "Iteration 295, loss = 0.00777299\n",
      "Iteration 296, loss = 0.00776305\n",
      "Iteration 297, loss = 0.00776043\n",
      "Iteration 298, loss = 0.00775185\n",
      "Iteration 299, loss = 0.00774342\n",
      "Iteration 300, loss = 0.00773747\n",
      "The training Accuracy achieved is = 100.000\n",
      "The test Accuracy achieved is = 88.169\n",
      "The number of epochs is = 300\n",
      "The training time achieved is = 122.846\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.41870502\n",
      "Validation score: 0.000000\n",
      "Iteration 2, loss = 3.80648591\n",
      "Validation score: 0.000000\n",
      "Iteration 3, loss = 2.80774378\n",
      "Validation score: 0.127692\n",
      "Iteration 4, loss = 2.12584854\n",
      "Validation score: 0.412308\n",
      "Iteration 5, loss = 1.58673134\n",
      "Validation score: 0.607692\n",
      "Iteration 6, loss = 1.27460732\n",
      "Validation score: 0.693077\n",
      "Iteration 7, loss = 1.09366313\n",
      "Validation score: 0.720000\n",
      "Iteration 8, loss = 0.97055441\n",
      "Validation score: 0.751538\n",
      "Iteration 9, loss = 0.87260637\n",
      "Validation score: 0.764615\n",
      "Iteration 10, loss = 0.79303940\n",
      "Validation score: 0.796154\n",
      "Iteration 11, loss = 0.72543737\n",
      "Validation score: 0.805385\n",
      "Iteration 12, loss = 0.66701295\n",
      "Validation score: 0.815385\n",
      "Iteration 13, loss = 0.61402694\n",
      "Validation score: 0.820000\n",
      "Iteration 14, loss = 0.56863032\n",
      "Validation score: 0.837692\n",
      "Iteration 15, loss = 0.52379626\n",
      "Validation score: 0.843846\n",
      "Iteration 16, loss = 0.48699821\n",
      "Validation score: 0.851538\n",
      "Iteration 17, loss = 0.45046248\n",
      "Validation score: 0.852308\n",
      "Iteration 18, loss = 0.41649620\n",
      "Validation score: 0.861538\n",
      "Iteration 19, loss = 0.38949938\n",
      "Validation score: 0.864615\n",
      "Iteration 20, loss = 0.36351298\n",
      "Validation score: 0.870000\n",
      "Iteration 21, loss = 0.33567395\n",
      "Validation score: 0.868462\n",
      "Iteration 22, loss = 0.31280981\n",
      "Validation score: 0.868462\n",
      "Iteration 23, loss = 0.29285754\n",
      "Validation score: 0.871538\n",
      "Iteration 24, loss = 0.27263375\n",
      "Validation score: 0.873077\n",
      "Iteration 25, loss = 0.25217835\n",
      "Validation score: 0.874615\n",
      "Iteration 26, loss = 0.23781718\n",
      "Validation score: 0.880000\n",
      "Iteration 27, loss = 0.21981293\n",
      "Validation score: 0.883846\n",
      "Iteration 28, loss = 0.20647184\n",
      "Validation score: 0.890769\n",
      "Iteration 29, loss = 0.19194510\n",
      "Validation score: 0.886923\n",
      "Iteration 30, loss = 0.18028743\n",
      "Validation score: 0.893077\n",
      "Iteration 31, loss = 0.16822901\n",
      "Validation score: 0.893846\n",
      "Iteration 32, loss = 0.15601503\n",
      "Validation score: 0.896154\n",
      "Iteration 33, loss = 0.14779128\n",
      "Validation score: 0.893846\n",
      "Iteration 34, loss = 0.13682560\n",
      "Validation score: 0.891538\n",
      "Iteration 35, loss = 0.12897268\n",
      "Validation score: 0.893846\n",
      "Iteration 36, loss = 0.12073247\n",
      "Validation score: 0.897692\n",
      "Iteration 37, loss = 0.11285287\n",
      "Validation score: 0.897692\n",
      "Iteration 38, loss = 0.10638434\n",
      "Validation score: 0.897692\n",
      "Iteration 39, loss = 0.10035227\n",
      "Validation score: 0.896923\n",
      "Iteration 40, loss = 0.09384333\n",
      "Validation score: 0.896923\n",
      "Iteration 41, loss = 0.08858211\n",
      "Validation score: 0.898462\n",
      "Iteration 42, loss = 0.08380824\n",
      "Validation score: 0.897692\n",
      "Iteration 43, loss = 0.07948839\n",
      "Validation score: 0.899231\n",
      "Iteration 44, loss = 0.07476916\n",
      "Validation score: 0.903846\n",
      "Iteration 45, loss = 0.07139654\n",
      "Validation score: 0.897692\n",
      "Iteration 46, loss = 0.06790088\n",
      "Validation score: 0.902308\n",
      "Iteration 47, loss = 0.06399485\n",
      "Validation score: 0.897692\n",
      "Iteration 48, loss = 0.06138903\n",
      "Validation score: 0.899231\n",
      "Iteration 49, loss = 0.05835575\n",
      "Validation score: 0.902308\n",
      "Iteration 50, loss = 0.05542561\n",
      "Validation score: 0.902308\n",
      "Iteration 51, loss = 0.05309513\n",
      "Validation score: 0.903077\n",
      "Iteration 52, loss = 0.05115085\n",
      "Validation score: 0.901538\n",
      "Iteration 53, loss = 0.04856589\n",
      "Validation score: 0.903077\n",
      "Iteration 54, loss = 0.04659101\n",
      "Validation score: 0.903077\n",
      "Iteration 55, loss = 0.04471160\n",
      "Validation score: 0.901538\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 98.646\n",
      "The test Accuracy achieved is = 86.769\n",
      "The number of epochs is = 55\n",
      "The training time achieved is = 20.539\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=1.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 7.13846895\n",
      "Iteration 2, loss = 7.45431688\n",
      "Iteration 3, loss = 5.44180651\n",
      "Iteration 4, loss = 5.22387160\n",
      "Iteration 5, loss = 5.04474396\n",
      "Iteration 6, loss = 4.88750243\n",
      "Iteration 7, loss = 4.74554772\n",
      "Iteration 8, loss = 4.61522966\n",
      "Iteration 9, loss = 4.49446863\n",
      "Iteration 10, loss = 4.38245371\n",
      "Iteration 11, loss = 4.29138829\n",
      "Iteration 12, loss = 4.25796037\n",
      "Iteration 13, loss = 4.25598104\n",
      "Iteration 14, loss = 4.25621497\n",
      "Iteration 15, loss = 4.25609136\n",
      "Iteration 16, loss = 4.25604098\n",
      "Iteration 17, loss = 4.25584703\n",
      "Iteration 18, loss = 4.25576292\n",
      "Iteration 19, loss = 4.25569419\n",
      "Iteration 20, loss = 4.25597480\n",
      "Iteration 21, loss = 4.25556048\n",
      "Iteration 22, loss = 4.25563109\n",
      "Iteration 23, loss = 4.25565935\n",
      "Iteration 24, loss = 4.25562978\n",
      "Iteration 25, loss = 4.25568876\n",
      "Iteration 26, loss = 4.25562588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 4.25568938\n",
      "Iteration 28, loss = 4.25549576\n",
      "Iteration 29, loss = 4.25562269\n",
      "Iteration 30, loss = 4.25558693\n",
      "Iteration 31, loss = 4.25563824\n",
      "Iteration 32, loss = 4.25572331\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 0.000\n",
      "The test Accuracy achieved is = 0.000\n",
      "The number of epochs is = 32\n",
      "The training time achieved is = 13.065\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=1.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 4.91399452\n",
      "Iteration 2, loss = 3.93182210\n",
      "Iteration 3, loss = 3.83923340\n",
      "Iteration 4, loss = 3.80383519\n",
      "Iteration 5, loss = 3.78085040\n",
      "Iteration 6, loss = 3.76672143\n",
      "Iteration 7, loss = 3.75225345\n",
      "Iteration 8, loss = 3.74272756\n",
      "Iteration 9, loss = 3.73349655\n",
      "Iteration 10, loss = 3.72665091\n",
      "Iteration 11, loss = 3.71749473\n",
      "Iteration 12, loss = 3.70887694\n",
      "Iteration 13, loss = 3.70340983\n",
      "Iteration 14, loss = 3.69540066\n",
      "Iteration 15, loss = 3.68830307\n",
      "Iteration 16, loss = 3.68264760\n",
      "Iteration 17, loss = 3.67453794\n",
      "Iteration 18, loss = 3.66998067\n",
      "Iteration 19, loss = 3.66428589\n",
      "Iteration 20, loss = 3.65848501\n",
      "Iteration 21, loss = 3.65373224\n",
      "Iteration 22, loss = 3.64880639\n",
      "Iteration 23, loss = 3.64489247\n",
      "Iteration 24, loss = 3.64182831\n",
      "Iteration 25, loss = 3.63831051\n",
      "Iteration 26, loss = 3.63352885\n",
      "Iteration 27, loss = 3.62946179\n",
      "Iteration 28, loss = 3.62644387\n",
      "Iteration 29, loss = 3.62378164\n",
      "Iteration 30, loss = 3.61922564\n",
      "Iteration 31, loss = 3.61871742\n",
      "Iteration 32, loss = 3.61546889\n",
      "Iteration 33, loss = 3.61315608\n",
      "Iteration 34, loss = 3.61101271\n",
      "Iteration 35, loss = 3.60856549\n",
      "Iteration 36, loss = 3.60618434\n",
      "Iteration 37, loss = 3.60455918\n",
      "Iteration 38, loss = 3.60320969\n",
      "Iteration 39, loss = 3.59978663\n",
      "Iteration 40, loss = 3.59790686\n",
      "Iteration 41, loss = 3.59732178\n",
      "Iteration 42, loss = 3.59453803\n",
      "Iteration 43, loss = 3.59344715\n",
      "Iteration 44, loss = 3.59091029\n",
      "Iteration 45, loss = 3.58977809\n",
      "Iteration 46, loss = 3.58895719\n",
      "Iteration 47, loss = 3.58628498\n",
      "Iteration 48, loss = 3.58467671\n",
      "Iteration 49, loss = 3.58240802\n",
      "Iteration 50, loss = 3.58269256\n",
      "Iteration 51, loss = 3.58150216\n",
      "Iteration 52, loss = 3.57944985\n",
      "Iteration 53, loss = 3.57782205\n",
      "Iteration 54, loss = 3.57702788\n",
      "Iteration 55, loss = 3.57574943\n",
      "Iteration 56, loss = 3.57384504\n",
      "Iteration 57, loss = 3.57303836\n",
      "Iteration 58, loss = 3.57200717\n",
      "Iteration 59, loss = 3.57098455\n",
      "Iteration 60, loss = 3.56947216\n",
      "Iteration 61, loss = 3.56897916\n",
      "Iteration 62, loss = 3.56839861\n",
      "Iteration 63, loss = 3.56637148\n",
      "Iteration 64, loss = 3.56537455\n",
      "Iteration 65, loss = 3.56363770\n",
      "Iteration 66, loss = 3.56358802\n",
      "Iteration 67, loss = 3.56346938\n",
      "Iteration 68, loss = 3.56073357\n",
      "Iteration 69, loss = 3.55911318\n",
      "Iteration 70, loss = 3.55973916\n",
      "Iteration 71, loss = 3.55931071\n",
      "Iteration 72, loss = 3.55721068\n",
      "Iteration 73, loss = 3.55621607\n",
      "Iteration 74, loss = 3.55704377\n",
      "Iteration 75, loss = 3.55569546\n",
      "Iteration 76, loss = 3.55412340\n",
      "Iteration 77, loss = 3.55352452\n",
      "Iteration 78, loss = 3.55227687\n",
      "Iteration 79, loss = 3.55166782\n",
      "Iteration 80, loss = 3.55218662\n",
      "Iteration 81, loss = 3.54993320\n",
      "Iteration 82, loss = 3.54941196\n",
      "Iteration 83, loss = 3.54832376\n",
      "Iteration 84, loss = 3.54762889\n",
      "Iteration 85, loss = 3.54741147\n",
      "Iteration 86, loss = 3.54716358\n",
      "Iteration 87, loss = 3.54587120\n",
      "Iteration 88, loss = 3.54620382\n",
      "Iteration 89, loss = 3.54505844\n",
      "Iteration 90, loss = 3.54356568\n",
      "Iteration 91, loss = 3.54348196\n",
      "Iteration 92, loss = 3.54272636\n",
      "Iteration 93, loss = 3.54270742\n",
      "Iteration 94, loss = 3.54088747\n",
      "Iteration 95, loss = 3.54116482\n",
      "Iteration 96, loss = 3.54013446\n",
      "Iteration 97, loss = 3.53928523\n",
      "Iteration 98, loss = 3.53903637\n",
      "Iteration 99, loss = 3.53843557\n",
      "Iteration 100, loss = 3.53745690\n",
      "Iteration 101, loss = 3.53652644\n",
      "Iteration 102, loss = 3.53581117\n",
      "Iteration 103, loss = 3.53543368\n",
      "Iteration 104, loss = 3.53512771\n",
      "Iteration 105, loss = 3.53463199\n",
      "Iteration 106, loss = 3.53356008\n",
      "Iteration 107, loss = 3.53350275\n",
      "Iteration 108, loss = 3.53257350\n",
      "Iteration 109, loss = 3.53115377\n",
      "Iteration 110, loss = 3.53143242\n",
      "Iteration 111, loss = 3.53039052\n",
      "Iteration 112, loss = 3.52984282\n",
      "Iteration 113, loss = 3.53027202\n",
      "Iteration 114, loss = 3.52845802\n",
      "Iteration 115, loss = 3.52868546\n",
      "Iteration 116, loss = 3.52779691\n",
      "Iteration 117, loss = 3.52814632\n",
      "Iteration 118, loss = 3.52685872\n",
      "Iteration 119, loss = 3.52655535\n",
      "Iteration 120, loss = 3.52553096\n",
      "Iteration 121, loss = 3.52568823\n",
      "Iteration 122, loss = 3.52481642\n",
      "Iteration 123, loss = 3.52421138\n",
      "Iteration 124, loss = 3.52382266\n",
      "Iteration 125, loss = 3.52257861\n",
      "Iteration 126, loss = 3.52192303\n",
      "Iteration 127, loss = 3.52233005\n",
      "Iteration 128, loss = 3.52140567\n",
      "Iteration 129, loss = 3.52057420\n",
      "Iteration 130, loss = 3.52065039\n",
      "Iteration 131, loss = 3.52051809\n",
      "Iteration 132, loss = 3.51955523\n",
      "Iteration 133, loss = 3.51907359\n",
      "Iteration 134, loss = 3.51856928\n",
      "Iteration 135, loss = 3.51744904\n",
      "Iteration 136, loss = 3.51675082\n",
      "Iteration 137, loss = 3.51669936\n",
      "Iteration 138, loss = 3.51581921\n",
      "Iteration 139, loss = 3.51631620\n",
      "Iteration 140, loss = 3.51579168\n",
      "Iteration 141, loss = 3.51438687\n",
      "Iteration 142, loss = 3.51550731\n",
      "Iteration 143, loss = 3.51390289\n",
      "Iteration 144, loss = 3.51327623\n",
      "Iteration 145, loss = 3.51344213\n",
      "Iteration 146, loss = 3.51298435\n",
      "Iteration 147, loss = 3.51225494\n",
      "Iteration 148, loss = 3.51106757\n",
      "Iteration 149, loss = 3.51137381\n",
      "Iteration 150, loss = 3.51129717\n",
      "Iteration 151, loss = 3.51093952\n",
      "Iteration 152, loss = 3.51064927\n",
      "Iteration 153, loss = 3.50973491\n",
      "Iteration 154, loss = 3.50915819\n",
      "Iteration 155, loss = 3.50943088\n",
      "Iteration 156, loss = 3.50788596\n",
      "Iteration 157, loss = 3.50819357\n",
      "Iteration 158, loss = 3.50811451\n",
      "Iteration 159, loss = 3.50782738\n",
      "Iteration 160, loss = 3.50707017\n",
      "Iteration 161, loss = 3.50650156\n",
      "Iteration 162, loss = 3.50619528\n",
      "Iteration 163, loss = 3.50583304\n",
      "Iteration 164, loss = 3.50524275\n",
      "Iteration 165, loss = 3.50553286\n",
      "Iteration 166, loss = 3.50536904\n",
      "Iteration 167, loss = 3.50466331\n",
      "Iteration 168, loss = 3.50472269\n",
      "Iteration 169, loss = 3.50352557\n",
      "Iteration 170, loss = 3.50328870\n",
      "Iteration 171, loss = 3.50324675\n",
      "Iteration 172, loss = 3.50293436\n",
      "Iteration 173, loss = 3.50134288\n",
      "Iteration 174, loss = 3.50146505\n",
      "Iteration 175, loss = 3.50134998\n",
      "Iteration 176, loss = 3.50161447\n",
      "Iteration 177, loss = 3.49988847\n",
      "Iteration 178, loss = 3.49988604\n",
      "Iteration 179, loss = 3.49954866\n",
      "Iteration 180, loss = 3.49889496\n",
      "Iteration 181, loss = 3.49941020\n",
      "Iteration 182, loss = 3.49903626\n",
      "Iteration 183, loss = 3.49984419\n",
      "Iteration 184, loss = 3.49824230\n",
      "Iteration 185, loss = 3.49879804\n",
      "Iteration 186, loss = 3.49713388\n",
      "Iteration 187, loss = 3.49731594\n",
      "Iteration 188, loss = 3.49702645\n",
      "Iteration 189, loss = 3.49625978\n",
      "Iteration 190, loss = 3.49658024\n",
      "Iteration 191, loss = 3.49610327\n",
      "Iteration 192, loss = 3.49553097\n",
      "Iteration 193, loss = 3.49627181\n",
      "Iteration 194, loss = 3.49448156\n",
      "Iteration 195, loss = 3.49536530\n",
      "Iteration 196, loss = 3.49438673\n",
      "Iteration 197, loss = 3.49406735\n",
      "Iteration 198, loss = 3.49343632\n",
      "Iteration 199, loss = 3.49315752\n",
      "Iteration 200, loss = 3.49329251\n",
      "Iteration 201, loss = 3.49289044\n",
      "Iteration 202, loss = 3.49151367\n",
      "Iteration 203, loss = 3.49243984\n",
      "Iteration 204, loss = 3.49184309\n",
      "Iteration 205, loss = 3.49106858\n",
      "Iteration 206, loss = 3.49202045\n",
      "Iteration 207, loss = 3.49123346\n",
      "Iteration 208, loss = 3.49117795\n",
      "Iteration 209, loss = 3.49029557\n",
      "Iteration 210, loss = 3.49047260\n",
      "Iteration 211, loss = 3.48892008\n",
      "Iteration 212, loss = 3.48948648\n",
      "Iteration 213, loss = 3.48887443\n",
      "Iteration 214, loss = 3.48957380\n",
      "Iteration 215, loss = 3.48817100\n",
      "Iteration 216, loss = 3.48912778\n",
      "Iteration 217, loss = 3.48739125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 218, loss = 3.48769809\n",
      "Iteration 219, loss = 3.48729762\n",
      "Iteration 220, loss = 3.48715910\n",
      "Iteration 221, loss = 3.48680173\n",
      "Iteration 222, loss = 3.48582241\n",
      "Iteration 223, loss = 3.48655444\n",
      "Iteration 224, loss = 3.48599022\n",
      "Iteration 225, loss = 3.48537204\n",
      "Iteration 226, loss = 3.48522607\n",
      "Iteration 227, loss = 3.48494684\n",
      "Iteration 228, loss = 3.48435684\n",
      "Iteration 229, loss = 3.48454280\n",
      "Iteration 230, loss = 3.48392666\n",
      "Iteration 231, loss = 3.48378348\n",
      "Iteration 232, loss = 3.48448690\n",
      "Iteration 233, loss = 3.48399222\n",
      "Iteration 234, loss = 3.48337898\n",
      "Iteration 235, loss = 3.48239544\n",
      "Iteration 236, loss = 3.48258418\n",
      "Iteration 237, loss = 3.48207939\n",
      "Iteration 238, loss = 3.48169747\n",
      "Iteration 239, loss = 3.48187396\n",
      "Iteration 240, loss = 3.48167231\n",
      "Iteration 241, loss = 3.48135753\n",
      "Iteration 242, loss = 3.48121739\n",
      "Iteration 243, loss = 3.48072041\n",
      "Iteration 244, loss = 3.48084271\n",
      "Iteration 245, loss = 3.47948237\n",
      "Iteration 246, loss = 3.48030278\n",
      "Iteration 247, loss = 3.47924803\n",
      "Iteration 248, loss = 3.47980947\n",
      "Iteration 249, loss = 3.47897746\n",
      "Iteration 250, loss = 3.47922234\n",
      "Iteration 251, loss = 3.47875347\n",
      "Iteration 252, loss = 3.47778311\n",
      "Iteration 253, loss = 3.47825606\n",
      "Iteration 254, loss = 3.47843825\n",
      "Iteration 255, loss = 3.47764293\n",
      "Iteration 256, loss = 3.47720438\n",
      "Iteration 257, loss = 3.47668391\n",
      "Iteration 258, loss = 3.47714353\n",
      "Iteration 259, loss = 3.47708676\n",
      "Iteration 260, loss = 3.47646313\n",
      "Iteration 261, loss = 3.47616594\n",
      "Iteration 262, loss = 3.47641480\n",
      "Iteration 263, loss = 3.47567789\n",
      "Iteration 264, loss = 3.47569727\n",
      "Iteration 265, loss = 3.47466853\n",
      "Iteration 266, loss = 3.47511537\n",
      "Iteration 267, loss = 3.47433763\n",
      "Iteration 268, loss = 3.47454118\n",
      "Iteration 269, loss = 3.47470412\n",
      "Iteration 270, loss = 3.47395480\n",
      "Iteration 271, loss = 3.47373309\n",
      "Iteration 272, loss = 3.47365123\n",
      "Iteration 273, loss = 3.47383005\n",
      "Iteration 274, loss = 3.47309010\n",
      "Iteration 275, loss = 3.47355969\n",
      "Iteration 276, loss = 3.47184330\n",
      "Iteration 277, loss = 3.47273328\n",
      "Iteration 278, loss = 3.47214298\n",
      "Iteration 279, loss = 3.47133627\n",
      "Iteration 280, loss = 3.47165846\n",
      "Iteration 281, loss = 3.47119288\n",
      "Iteration 282, loss = 3.47148907\n",
      "Iteration 283, loss = 3.47136112\n",
      "Iteration 284, loss = 3.47048260\n",
      "Iteration 285, loss = 3.47034292\n",
      "Iteration 286, loss = 3.47050863\n",
      "Iteration 287, loss = 3.47030467\n",
      "Iteration 288, loss = 3.46995282\n",
      "Iteration 289, loss = 3.46990182\n",
      "Iteration 290, loss = 3.46974732\n",
      "Iteration 291, loss = 3.46889361\n",
      "Iteration 292, loss = 3.46883629\n",
      "Iteration 293, loss = 3.46928392\n",
      "Iteration 294, loss = 3.46812165\n",
      "Iteration 295, loss = 3.46939756\n",
      "Iteration 296, loss = 3.46852487\n",
      "Iteration 297, loss = 3.46711633\n",
      "Iteration 298, loss = 3.46875698\n",
      "Iteration 299, loss = 3.46800907\n",
      "Iteration 300, loss = 3.46805170\n",
      "The training Accuracy achieved is = 0.000\n",
      "The test Accuracy achieved is = 0.000\n",
      "The number of epochs is = 300\n",
      "The training time achieved is = 119.374\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.20564188\n",
      "Iteration 2, loss = 0.84699991\n",
      "Iteration 3, loss = 0.67897274\n",
      "Iteration 4, loss = 0.55336690\n",
      "Iteration 5, loss = 0.48714126\n",
      "Iteration 6, loss = 0.42865286\n",
      "Iteration 7, loss = 0.37533798\n",
      "Iteration 8, loss = 0.34030893\n",
      "Iteration 9, loss = 0.33340775\n",
      "Iteration 10, loss = 0.29316232\n",
      "Iteration 11, loss = 0.30977423\n",
      "Iteration 12, loss = 0.26116442\n",
      "Iteration 13, loss = 0.27792412\n",
      "Iteration 14, loss = 0.24079721\n",
      "Iteration 15, loss = 0.22271059\n",
      "Iteration 16, loss = 0.23372040\n",
      "Iteration 17, loss = 0.24623318\n",
      "Iteration 18, loss = 0.22151229\n",
      "Iteration 19, loss = 0.21697894\n",
      "Iteration 20, loss = 0.21017758\n",
      "Iteration 21, loss = 0.21053498\n",
      "Iteration 22, loss = 0.18698385\n",
      "Iteration 23, loss = 0.21293487\n",
      "Iteration 24, loss = 0.24990763\n",
      "Iteration 25, loss = 0.25381503\n",
      "Iteration 26, loss = 0.24885919\n",
      "Iteration 27, loss = 0.24162157\n",
      "Iteration 28, loss = 0.24025737\n",
      "Iteration 29, loss = 0.25086051\n",
      "Iteration 30, loss = 0.28615251\n",
      "Iteration 31, loss = 0.30911380\n",
      "Iteration 32, loss = 0.29792340\n",
      "Iteration 33, loss = 0.27336173\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 94.554\n",
      "The test Accuracy achieved is = 84.385\n",
      "The number of epochs is = 33\n",
      "The training time achieved is = 12.235\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.28979914\n",
      "Iteration 2, loss = 0.88911930\n",
      "Iteration 3, loss = 0.69475816\n",
      "Iteration 4, loss = 0.57677698\n",
      "Iteration 5, loss = 0.51519575\n",
      "Iteration 6, loss = 0.45094854\n",
      "Iteration 7, loss = 0.40337933\n",
      "Iteration 8, loss = 0.36424674\n",
      "Iteration 9, loss = 0.34018445\n",
      "Iteration 10, loss = 0.32644234\n",
      "Iteration 11, loss = 0.28808552\n",
      "Iteration 12, loss = 0.27290009\n",
      "Iteration 13, loss = 0.26489037\n",
      "Iteration 14, loss = 0.25169092\n",
      "Iteration 15, loss = 0.23217677\n",
      "Iteration 16, loss = 0.23047399\n",
      "Iteration 17, loss = 0.20566986\n",
      "Iteration 18, loss = 0.22593215\n",
      "Iteration 19, loss = 0.23590288\n",
      "Iteration 20, loss = 0.22283972\n",
      "Iteration 21, loss = 0.20217192\n",
      "Iteration 22, loss = 0.18791464\n",
      "Iteration 23, loss = 0.21317168\n",
      "Iteration 24, loss = 0.22151774\n",
      "Iteration 25, loss = 0.19430603\n",
      "Iteration 26, loss = 0.22417861\n",
      "Iteration 27, loss = 0.25753887\n",
      "Iteration 28, loss = 0.21218772\n",
      "Iteration 29, loss = 0.21051280\n",
      "Iteration 30, loss = 0.24182208\n",
      "Iteration 31, loss = 0.29157781\n",
      "Iteration 32, loss = 0.26107342\n",
      "Iteration 33, loss = 0.20315918\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 95.308\n",
      "The test Accuracy achieved is = 84.815\n",
      "The number of epochs is = 33\n",
      "The training time achieved is = 12.162\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 2.78784068\n",
      "Validation score: 0.617692\n",
      "Iteration 2, loss = 1.07674328\n",
      "Validation score: 0.723077\n",
      "Iteration 3, loss = 0.86862549\n",
      "Validation score: 0.745385\n",
      "Iteration 4, loss = 0.73382777\n",
      "Validation score: 0.767692\n",
      "Iteration 5, loss = 0.65783565\n",
      "Validation score: 0.793846\n",
      "Iteration 6, loss = 0.60641878\n",
      "Validation score: 0.794615\n",
      "Iteration 7, loss = 0.53564116\n",
      "Validation score: 0.809231\n",
      "Iteration 8, loss = 0.51093726\n",
      "Validation score: 0.813077\n",
      "Iteration 9, loss = 0.47192913\n",
      "Validation score: 0.807692\n",
      "Iteration 10, loss = 0.45043731\n",
      "Validation score: 0.811538\n",
      "Iteration 11, loss = 0.43567692\n",
      "Validation score: 0.835385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.40447182\n",
      "Validation score: 0.833077\n",
      "Iteration 13, loss = 0.37508219\n",
      "Validation score: 0.839231\n",
      "Iteration 14, loss = 0.37949745\n",
      "Validation score: 0.817692\n",
      "Iteration 15, loss = 0.34132941\n",
      "Validation score: 0.817692\n",
      "Iteration 16, loss = 0.34582382\n",
      "Validation score: 0.810769\n",
      "Iteration 17, loss = 0.33725949\n",
      "Validation score: 0.816154\n",
      "Iteration 18, loss = 0.32277617\n",
      "Validation score: 0.833846\n",
      "Iteration 19, loss = 0.32685822\n",
      "Validation score: 0.831538\n",
      "Iteration 20, loss = 0.34472605\n",
      "Validation score: 0.829231\n",
      "Iteration 21, loss = 0.31846586\n",
      "Validation score: 0.826154\n",
      "Iteration 22, loss = 0.32656429\n",
      "Validation score: 0.824615\n",
      "Iteration 23, loss = 0.32872850\n",
      "Validation score: 0.816154\n",
      "Iteration 24, loss = 0.29295252\n",
      "Validation score: 0.824615\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 90.869\n",
      "The test Accuracy achieved is = 82.046\n",
      "The number of epochs is = 24\n",
      "The training time achieved is = 8.041\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-06,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = inf\n",
      "Iteration 2, loss = 132.93802812\n",
      "Iteration 3, loss = 132.93339093\n",
      "Iteration 4, loss = 132.93074792\n",
      "Iteration 5, loss = 132.92883967\n",
      "Iteration 6, loss = 132.92734353\n",
      "Iteration 7, loss = 132.92611581\n",
      "Iteration 8, loss = 132.92508577\n",
      "Iteration 9, loss = 132.92416913\n",
      "Iteration 10, loss = 132.92336133\n",
      "Iteration 11, loss = 132.92263996\n",
      "Iteration 12, loss = 132.92197791\n",
      "Iteration 13, loss = 132.92136353\n",
      "Iteration 14, loss = 132.92080501\n",
      "Iteration 15, loss = 132.92027550\n",
      "Iteration 16, loss = 132.91977727\n",
      "Iteration 17, loss = 132.91931128\n",
      "Iteration 18, loss = 132.91885925\n",
      "Iteration 19, loss = 132.91842955\n",
      "Iteration 20, loss = 132.91803003\n",
      "Iteration 21, loss = 132.91762932\n",
      "Iteration 22, loss = 132.91725678\n",
      "Iteration 23, loss = 132.91689306\n",
      "Iteration 24, loss = 132.91654227\n",
      "Iteration 25, loss = 132.91620328\n",
      "Iteration 26, loss = 132.91587203\n",
      "Iteration 27, loss = 132.91554612\n",
      "Iteration 28, loss = 132.91523372\n",
      "Iteration 29, loss = 132.91493408\n",
      "Iteration 30, loss = 132.91462835\n",
      "Iteration 31, loss = 132.91434152\n",
      "Iteration 32, loss = 132.91405668\n",
      "Iteration 33, loss = 132.91377845\n",
      "Iteration 34, loss = 132.91350158\n",
      "Iteration 35, loss = 132.91323501\n",
      "Iteration 36, loss = 132.91296939\n",
      "Iteration 37, loss = 132.91271104\n",
      "Iteration 38, loss = 132.91245696\n",
      "Iteration 39, loss = 132.91221045\n",
      "Iteration 40, loss = 132.91195741\n",
      "Iteration 41, loss = 132.91171924\n",
      "Iteration 42, loss = 132.91147693\n",
      "Iteration 43, loss = 132.91124212\n",
      "Iteration 44, loss = 132.91101227\n",
      "Iteration 45, loss = 132.91078014\n",
      "Iteration 46, loss = 132.91055376\n",
      "Iteration 47, loss = 132.91033408\n",
      "Iteration 48, loss = 132.91011076\n",
      "Iteration 49, loss = 132.90989214\n",
      "Iteration 50, loss = 132.90967841\n",
      "Iteration 51, loss = 132.90946342\n",
      "Iteration 52, loss = 132.90925343\n",
      "Iteration 53, loss = 132.90904318\n",
      "Iteration 54, loss = 132.90883736\n",
      "Iteration 55, loss = 132.90863278\n",
      "Iteration 56, loss = 132.90843047\n",
      "Iteration 57, loss = 132.90823430\n",
      "Iteration 58, loss = 132.90803466\n",
      "Iteration 59, loss = 132.90783847\n",
      "Iteration 60, loss = 132.90764537\n",
      "Iteration 61, loss = 132.90744708\n",
      "Iteration 62, loss = 132.90725971\n",
      "Iteration 63, loss = 132.90707248\n",
      "Iteration 64, loss = 132.90688382\n",
      "Iteration 65, loss = 132.90669876\n",
      "Iteration 66, loss = 132.90651318\n",
      "Iteration 67, loss = 132.90632798\n",
      "Iteration 68, loss = 132.90614712\n",
      "Iteration 69, loss = 132.90596870\n",
      "Iteration 70, loss = 132.90578985\n",
      "Iteration 71, loss = 132.90560898\n",
      "Iteration 72, loss = 132.90543712\n",
      "Iteration 73, loss = 132.90526219\n",
      "Iteration 74, loss = 132.90508757\n",
      "Iteration 75, loss = 132.90491610\n",
      "Iteration 76, loss = 132.90474348\n",
      "Iteration 77, loss = 132.90457351\n",
      "Iteration 78, loss = 132.90440576\n",
      "Iteration 79, loss = 132.90423696\n",
      "Iteration 80, loss = 132.90407124\n",
      "Iteration 81, loss = 132.90390640\n",
      "Iteration 82, loss = 132.90374127\n",
      "Iteration 83, loss = 132.90357638\n",
      "Iteration 84, loss = 132.90341757\n",
      "Iteration 85, loss = 132.90325289\n",
      "Iteration 86, loss = 132.90309405\n",
      "Iteration 87, loss = 132.90293721\n",
      "Iteration 88, loss = 132.90277856\n",
      "Iteration 89, loss = 132.90262153\n",
      "Iteration 90, loss = 132.90246373\n",
      "Iteration 91, loss = 132.90230822\n",
      "Iteration 92, loss = 132.90215437\n",
      "Iteration 93, loss = 132.90199768\n",
      "Iteration 94, loss = 132.90184710\n",
      "Iteration 95, loss = 132.90169343\n",
      "Iteration 96, loss = 132.90154250\n",
      "Iteration 97, loss = 132.90139369\n",
      "Iteration 98, loss = 132.90124066\n",
      "Iteration 99, loss = 132.90109245\n",
      "Iteration 100, loss = 132.90094512\n",
      "Iteration 101, loss = 132.90079667\n",
      "Iteration 102, loss = 132.90064991\n",
      "Iteration 103, loss = 132.90050165\n",
      "Iteration 104, loss = 132.90036045\n",
      "Iteration 105, loss = 132.90021514\n",
      "Iteration 106, loss = 132.90007160\n",
      "Iteration 107, loss = 132.89992842\n",
      "Iteration 108, loss = 132.89978502\n",
      "Iteration 109, loss = 132.89964347\n",
      "Iteration 110, loss = 132.89950262\n",
      "Iteration 111, loss = 132.89936084\n",
      "Iteration 112, loss = 132.89922219\n",
      "Iteration 113, loss = 132.89908068\n",
      "Iteration 114, loss = 132.89894421\n",
      "Iteration 115, loss = 132.89880480\n",
      "Iteration 116, loss = 132.89866711\n",
      "Iteration 117, loss = 132.89853136\n",
      "Iteration 118, loss = 132.89839656\n",
      "Iteration 119, loss = 132.89826145\n",
      "Iteration 120, loss = 132.89812692\n",
      "Iteration 121, loss = 132.89799128\n",
      "Iteration 122, loss = 132.89785619\n",
      "Iteration 123, loss = 132.89772368\n",
      "Iteration 124, loss = 132.89759008\n",
      "Iteration 125, loss = 132.89745928\n",
      "Iteration 126, loss = 132.89732876\n",
      "Iteration 127, loss = 132.89719541\n",
      "Iteration 128, loss = 132.89706562\n",
      "Iteration 129, loss = 132.89693450\n",
      "Iteration 130, loss = 132.89680594\n",
      "Iteration 131, loss = 132.89667562\n",
      "Iteration 132, loss = 132.89655057\n",
      "Iteration 133, loss = 132.89642113\n",
      "Iteration 134, loss = 132.89629464\n",
      "Iteration 135, loss = 132.89616392\n",
      "Iteration 136, loss = 132.89603907\n",
      "Iteration 137, loss = 132.89591337\n",
      "Iteration 138, loss = 132.89578901\n",
      "Iteration 139, loss = 132.89566181\n",
      "Iteration 140, loss = 132.89553793\n",
      "Iteration 141, loss = 132.89541286\n",
      "Iteration 142, loss = 132.89528916\n",
      "Iteration 143, loss = 132.89516396\n",
      "Iteration 144, loss = 132.89504216\n",
      "Iteration 145, loss = 132.89491891\n",
      "Iteration 146, loss = 132.89479873\n",
      "Iteration 147, loss = 132.89467679\n",
      "Iteration 148, loss = 132.89455432\n",
      "Iteration 149, loss = 132.89443595\n",
      "Iteration 150, loss = 132.89431255\n",
      "Iteration 151, loss = 132.89419170\n",
      "Iteration 152, loss = 132.89407315\n",
      "Iteration 153, loss = 132.89395355\n",
      "Iteration 154, loss = 132.89383382\n",
      "Iteration 155, loss = 132.89371855\n",
      "Iteration 156, loss = 132.89359833\n",
      "Iteration 157, loss = 132.89348231\n",
      "Iteration 158, loss = 132.89336598\n",
      "Iteration 159, loss = 132.89324556\n",
      "Iteration 160, loss = 132.89312929\n",
      "Iteration 161, loss = 132.89301251\n",
      "Iteration 162, loss = 132.89289799\n",
      "Iteration 163, loss = 132.89278238\n",
      "Iteration 164, loss = 132.89266589\n",
      "Iteration 165, loss = 132.89255166\n",
      "Iteration 166, loss = 132.89243840\n",
      "Iteration 167, loss = 132.89232366\n",
      "Iteration 168, loss = 132.89221097\n",
      "Iteration 169, loss = 132.89209593\n",
      "Iteration 170, loss = 132.89198205\n",
      "Iteration 171, loss = 132.89187179\n",
      "Iteration 172, loss = 132.89175879\n",
      "Iteration 173, loss = 132.89164512\n",
      "Iteration 174, loss = 132.89153371\n",
      "Iteration 175, loss = 132.89142227\n",
      "Iteration 176, loss = 132.89131123\n",
      "Iteration 177, loss = 132.89120208\n",
      "Iteration 178, loss = 132.89109095\n",
      "Iteration 179, loss = 132.89098076\n",
      "Iteration 180, loss = 132.89087179\n",
      "Iteration 181, loss = 132.89075831\n",
      "Iteration 182, loss = 132.89065225\n",
      "Iteration 183, loss = 132.89054437\n",
      "Iteration 184, loss = 132.89043429\n",
      "Iteration 185, loss = 132.89032579\n",
      "Iteration 186, loss = 132.89021785\n",
      "Iteration 187, loss = 132.89011234\n",
      "Iteration 188, loss = 132.89000215\n",
      "Iteration 189, loss = 132.88989559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 190, loss = 132.88978760\n",
      "Iteration 191, loss = 132.88968212\n",
      "Iteration 192, loss = 132.88957618\n",
      "Iteration 193, loss = 132.88946912\n",
      "Iteration 194, loss = 132.88936370\n",
      "Iteration 195, loss = 132.88925785\n",
      "Iteration 196, loss = 132.88915110\n",
      "Iteration 197, loss = 132.88904749\n",
      "Iteration 198, loss = 132.88894242\n",
      "Iteration 199, loss = 132.88884021\n",
      "Iteration 200, loss = 132.88873705\n",
      "Iteration 201, loss = 132.88863193\n",
      "Iteration 202, loss = 132.88852857\n",
      "Iteration 203, loss = 132.88842428\n",
      "Iteration 204, loss = 132.88832135\n",
      "Iteration 205, loss = 132.88821796\n",
      "Iteration 206, loss = 132.88811475\n",
      "Iteration 207, loss = 132.88801489\n",
      "Iteration 208, loss = 132.88790984\n",
      "Iteration 209, loss = 132.88780798\n",
      "Iteration 210, loss = 132.88770785\n",
      "Iteration 211, loss = 132.88760554\n",
      "Iteration 212, loss = 132.88750406\n",
      "Iteration 213, loss = 132.88740371\n",
      "Iteration 214, loss = 132.88730415\n",
      "Iteration 215, loss = 132.88720120\n",
      "Iteration 216, loss = 132.88710270\n",
      "Iteration 217, loss = 132.88700264\n",
      "Iteration 218, loss = 132.88690267\n",
      "Iteration 219, loss = 132.88680377\n",
      "Iteration 220, loss = 132.88670305\n",
      "Iteration 221, loss = 132.88660334\n",
      "Iteration 222, loss = 132.88650579\n",
      "Iteration 223, loss = 132.88640606\n",
      "Iteration 224, loss = 132.88630981\n",
      "Iteration 225, loss = 132.88621183\n",
      "Iteration 226, loss = 132.88611248\n",
      "Iteration 227, loss = 132.88601427\n",
      "Iteration 228, loss = 132.88591807\n",
      "Iteration 229, loss = 132.88581932\n",
      "Iteration 230, loss = 132.88572408\n",
      "Iteration 231, loss = 132.88562613\n",
      "Iteration 232, loss = 132.88552965\n",
      "Iteration 233, loss = 132.88543416\n",
      "Iteration 234, loss = 132.88533679\n",
      "Iteration 235, loss = 132.88524147\n",
      "Iteration 236, loss = 132.88514574\n",
      "Iteration 237, loss = 132.88505010\n",
      "Iteration 238, loss = 132.88495352\n",
      "Iteration 239, loss = 132.88485871\n",
      "Iteration 240, loss = 132.88476491\n",
      "Iteration 241, loss = 132.88466876\n",
      "Iteration 242, loss = 132.88457577\n",
      "Iteration 243, loss = 132.88447772\n",
      "Iteration 244, loss = 132.88438653\n",
      "Iteration 245, loss = 132.88429186\n",
      "Iteration 246, loss = 132.88419795\n",
      "Iteration 247, loss = 132.88410295\n",
      "Iteration 248, loss = 132.88401183\n",
      "Iteration 249, loss = 132.88391859\n",
      "Iteration 250, loss = 132.88382529\n",
      "Iteration 251, loss = 132.88373152\n",
      "Iteration 252, loss = 132.88363852\n",
      "Iteration 253, loss = 132.88354587\n",
      "Iteration 254, loss = 132.88345313\n",
      "Iteration 255, loss = 132.88336095\n",
      "Iteration 256, loss = 132.88326926\n",
      "Iteration 257, loss = 132.88317661\n",
      "Iteration 258, loss = 132.88308666\n",
      "Iteration 259, loss = 132.88299611\n",
      "Iteration 260, loss = 132.88290371\n",
      "Iteration 261, loss = 132.88281372\n",
      "Iteration 262, loss = 132.88272184\n",
      "Iteration 263, loss = 132.88263151\n",
      "Iteration 264, loss = 132.88254104\n",
      "Iteration 265, loss = 132.88245138\n",
      "Iteration 266, loss = 132.88235988\n",
      "Iteration 267, loss = 132.88226982\n",
      "Iteration 268, loss = 132.88218133\n",
      "Iteration 269, loss = 132.88209081\n",
      "Iteration 270, loss = 132.88200003\n",
      "Iteration 271, loss = 132.88191116\n",
      "Iteration 272, loss = 132.88182121\n",
      "Iteration 273, loss = 132.88173392\n",
      "Iteration 274, loss = 132.88164296\n",
      "Iteration 275, loss = 132.88155505\n",
      "Iteration 276, loss = 132.88146683\n",
      "Iteration 277, loss = 132.88137869\n",
      "Iteration 278, loss = 132.88128930\n",
      "Iteration 279, loss = 132.88120173\n",
      "Iteration 280, loss = 132.88111335\n",
      "Iteration 281, loss = 132.88102664\n",
      "Iteration 282, loss = 132.88093798\n",
      "Iteration 283, loss = 132.88085115\n",
      "Iteration 284, loss = 132.88076355\n",
      "Iteration 285, loss = 132.88067722\n",
      "Iteration 286, loss = 132.88058878\n",
      "Iteration 287, loss = 132.88050298\n",
      "Iteration 288, loss = 132.88041691\n",
      "Iteration 289, loss = 132.88032992\n",
      "Iteration 290, loss = 132.88024224\n",
      "Iteration 291, loss = 132.88015719\n",
      "Iteration 292, loss = 132.88007207\n",
      "Iteration 293, loss = 132.87998503\n",
      "Iteration 294, loss = 132.87989884\n",
      "Iteration 295, loss = 132.87981460\n",
      "Iteration 296, loss = 132.87972851\n",
      "Iteration 297, loss = 132.87964323\n",
      "Iteration 298, loss = 132.87955759\n",
      "Iteration 299, loss = 132.87947167\n",
      "Iteration 300, loss = 132.87938748\n",
      "The training Accuracy achieved is = 0.000\n",
      "The test Accuracy achieved is = 0.000\n",
      "The number of epochs is = 300\n",
      "The training time achieved is = 104.743\n",
      "--------Training the classifier with following params--------------\n",
      "-------------------------------------------------------------------\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-06,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "-------------------------------------------------------------------\n",
      "Iteration 1, loss = 5.78560069\n",
      "Iteration 2, loss = 4.27928831\n",
      "Iteration 3, loss = 4.25852954\n",
      "Iteration 4, loss = 4.25827895\n",
      "Iteration 5, loss = 4.25777572\n",
      "Iteration 6, loss = 4.25760843\n",
      "Iteration 7, loss = 4.25789571\n",
      "Iteration 8, loss = 4.25817926\n",
      "Iteration 9, loss = 4.25717532\n",
      "Iteration 10, loss = 4.25699286\n",
      "Iteration 11, loss = 4.25721703\n",
      "Iteration 12, loss = 4.25701260\n",
      "Iteration 13, loss = 4.25685394\n",
      "Iteration 14, loss = 4.25658914\n",
      "Iteration 15, loss = 4.25637034\n",
      "Iteration 16, loss = 4.25381865\n",
      "Iteration 17, loss = 4.04755064\n",
      "Iteration 18, loss = 3.76470447\n",
      "Iteration 19, loss = 3.70816298\n",
      "Iteration 20, loss = 3.67168632\n",
      "Iteration 21, loss = 3.65021418\n",
      "Iteration 22, loss = 3.62918222\n",
      "Iteration 23, loss = 3.61705040\n",
      "Iteration 24, loss = 3.60010173\n",
      "Iteration 25, loss = 3.58834956\n",
      "Iteration 26, loss = 3.58205780\n",
      "Iteration 27, loss = 3.57451771\n",
      "Iteration 28, loss = 3.56698074\n",
      "Iteration 29, loss = 3.55933915\n",
      "Iteration 30, loss = 3.55616197\n",
      "Iteration 31, loss = 3.54816501\n",
      "Iteration 32, loss = 3.54584744\n",
      "Iteration 33, loss = 3.54228207\n",
      "Iteration 34, loss = 3.53596472\n",
      "Iteration 35, loss = 3.53232288\n",
      "Iteration 36, loss = 3.52930844\n",
      "Iteration 37, loss = 3.52745758\n",
      "Iteration 38, loss = 3.52254034\n",
      "Iteration 39, loss = 3.52229473\n",
      "Iteration 40, loss = 3.52048202\n",
      "Iteration 41, loss = 3.51779898\n",
      "Iteration 42, loss = 3.51632044\n",
      "Iteration 43, loss = 3.51631817\n",
      "Iteration 44, loss = 3.51151853\n",
      "Iteration 45, loss = 3.51149288\n",
      "Iteration 46, loss = 3.51089023\n",
      "Iteration 47, loss = 3.51109522\n",
      "Iteration 48, loss = 3.50876602\n",
      "Iteration 49, loss = 3.50716242\n",
      "Iteration 50, loss = 3.50672844\n",
      "Iteration 51, loss = 3.50484171\n",
      "Iteration 52, loss = 3.50064751\n",
      "Iteration 53, loss = 3.49932081\n",
      "Iteration 54, loss = 3.50195760\n",
      "Iteration 55, loss = 3.50186020\n",
      "Iteration 56, loss = 3.49988662\n",
      "Iteration 57, loss = 3.49510496\n",
      "Iteration 58, loss = 3.49395600\n",
      "Iteration 59, loss = 3.49351949\n",
      "Iteration 60, loss = 3.49766793\n",
      "Iteration 61, loss = 3.49433329\n",
      "Iteration 62, loss = 3.49417398\n",
      "Iteration 63, loss = 3.49352003\n",
      "Iteration 64, loss = 3.49431335\n",
      "Iteration 65, loss = 3.48886417\n",
      "Iteration 66, loss = 3.48916811\n",
      "Iteration 67, loss = 3.49129436\n",
      "Iteration 68, loss = 3.49079587\n",
      "Iteration 69, loss = 3.49238426\n",
      "Iteration 70, loss = 3.48760440\n",
      "Iteration 71, loss = 3.48685206\n",
      "Iteration 72, loss = 3.49034883\n",
      "Iteration 73, loss = 3.48940723\n",
      "Iteration 74, loss = 3.48651554\n",
      "Iteration 75, loss = 3.48936379\n",
      "Iteration 76, loss = 3.48542790\n",
      "Iteration 77, loss = 3.48751180\n",
      "Iteration 78, loss = 3.48612073\n",
      "Iteration 79, loss = 3.48446025\n",
      "Iteration 80, loss = 3.48703883\n",
      "Iteration 81, loss = 3.48579806\n",
      "Iteration 82, loss = 3.48494699\n",
      "Iteration 83, loss = 3.48574565\n",
      "Iteration 84, loss = 3.48768348\n",
      "Iteration 85, loss = 3.48339664\n",
      "Iteration 86, loss = 3.48237470\n",
      "Iteration 87, loss = 3.48330996\n",
      "Iteration 88, loss = 3.48703687\n",
      "Iteration 89, loss = 3.48293068\n",
      "Iteration 90, loss = 3.48494336\n",
      "Iteration 91, loss = 3.48032963\n",
      "Iteration 92, loss = 3.48495813\n",
      "Iteration 93, loss = 3.48248838\n",
      "Iteration 94, loss = 3.47915803\n",
      "Iteration 95, loss = 3.48267672\n",
      "Iteration 96, loss = 3.48305385\n",
      "Iteration 97, loss = 3.47929733\n",
      "Iteration 98, loss = 3.48010203\n",
      "Iteration 99, loss = 3.47913366\n",
      "Iteration 100, loss = 3.47993648\n",
      "Iteration 101, loss = 3.47956329\n",
      "Iteration 102, loss = 3.47849531\n",
      "Iteration 103, loss = 3.47808109\n",
      "Iteration 104, loss = 3.47925597\n",
      "Iteration 105, loss = 3.47800626\n",
      "Iteration 106, loss = 3.48113374\n",
      "Iteration 107, loss = 3.47971394\n",
      "Iteration 108, loss = 3.47832081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 109, loss = 3.47703219\n",
      "Iteration 110, loss = 3.47810221\n",
      "Iteration 111, loss = 3.47718002\n",
      "Iteration 112, loss = 3.47667924\n",
      "Iteration 113, loss = 3.47613561\n",
      "Iteration 114, loss = 3.47423825\n",
      "Iteration 115, loss = 3.47662475\n",
      "Iteration 116, loss = 3.47693220\n",
      "Iteration 117, loss = 3.47498324\n",
      "Iteration 118, loss = 3.48079618\n",
      "Iteration 119, loss = 3.47422535\n",
      "Iteration 120, loss = 3.47530092\n",
      "Iteration 121, loss = 3.47475872\n",
      "Iteration 122, loss = 3.47536341\n",
      "Iteration 123, loss = 3.47417743\n",
      "Iteration 124, loss = 3.47650518\n",
      "Iteration 125, loss = 3.47369265\n",
      "Iteration 126, loss = 3.47402384\n",
      "Iteration 127, loss = 3.47527795\n",
      "Iteration 128, loss = 3.47478390\n",
      "Iteration 129, loss = 3.47431473\n",
      "Iteration 130, loss = 3.47232344\n",
      "Iteration 131, loss = 3.47552252\n",
      "Iteration 132, loss = 3.47415420\n",
      "Iteration 133, loss = 3.47231852\n",
      "Iteration 134, loss = 3.47289952\n",
      "Iteration 135, loss = 3.47202561\n",
      "Iteration 136, loss = 3.47348028\n",
      "Iteration 137, loss = 3.47240603\n",
      "Iteration 138, loss = 3.47058356\n",
      "Iteration 139, loss = 3.47280234\n",
      "Iteration 140, loss = 3.47286917\n",
      "Iteration 141, loss = 3.47423509\n",
      "Iteration 142, loss = 3.47337567\n",
      "Iteration 143, loss = 3.47187379\n",
      "Iteration 144, loss = 3.47440365\n",
      "Iteration 145, loss = 3.46784720\n",
      "Iteration 146, loss = 3.47152455\n",
      "Iteration 147, loss = 3.47242535\n",
      "Iteration 148, loss = 3.47182072\n",
      "Iteration 149, loss = 3.46963152\n",
      "Iteration 150, loss = 3.47289806\n",
      "Iteration 151, loss = 3.47052882\n",
      "Iteration 152, loss = 3.47237631\n",
      "Iteration 153, loss = 3.47036335\n",
      "Iteration 154, loss = 3.47184490\n",
      "Iteration 155, loss = 3.47062397\n",
      "Iteration 156, loss = 3.47086159\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "The training Accuracy achieved is = 1.631\n",
      "The test Accuracy achieved is = 1.892\n",
      "The number of epochs is = 156\n",
      "The training time achieved is = 53.355\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf)):\n",
    "    print(\"--------Training the classifier with following params--------------\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(clf[i])\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    start =time.time()\n",
    "    clf[i].fit(X_train, train_class_enc)\n",
    "    end = time.time()\n",
    "    epochs.append(clf[i].n_iter_)\n",
    "    train_accuracy.append(clf[i].score(X_train, train_class_enc)*100)\n",
    "    test_accuracy.append(clf[i].score(X_test, test_actual_class_enc)*100)\n",
    "    train_time.append(end-start)\n",
    "    print(\"The training Accuracy achieved is = {:2.3f}\".format(train_accuracy[-1]))\n",
    "    print(\"The test Accuracy achieved is = {:2.3f}\".format(test_accuracy[-1]))    \n",
    "    print(\"The number of epochs is = {}\".format(epochs[-1]))    \n",
    "    print(\"The training time achieved is = {:2.3f}\".format(train_time[-1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=1.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='logistic', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=1.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxcdb3/8dcnySSZdEnSNnRJW0oplLVQqRSsQC0qgguIymURgeu9uAJetFeK9yqgbFb0J8ilgiKiLIpilUXKXkFZWigU2lK6UNqk+5KuaZsmn98f50w6TWeSSZvJZHLez8djHpk558w5nzmZOZ/zXc73mLsjIiLRVZDrAEREJLeUCEREIk6JQEQk4pQIREQiTolARCTilAhERCJOiUAEMLMlZvbRTtrWUDPbYmaFrSzjZjaiM+LZX2Y2LIy3KEvrv9rMfpX0+rNmtizch6PNbI6Zjc/GtqNCiaCL68wDVFdhZs+b2fbwh554PJLruDqKuy91957u3gjNn/c/9nV9ZnZNeCC+osX0K8Lp14Svx5tZTZp13GNmO8N9vd7MnjKzw5LmH2pmD5nZWjPbaGazzezK1pJZR3H3G9w9ef/8BPhmuA9nufuR7v58tuPozpQIJKdaOZAkfuiJx6c7NbD88y7wpRbTLgqnZ+rH7t4TGAysBu4BMLODgVeAZcDR7l4OfAEYA/Tav7D3yYHAnP1dSbZKMPlIiSCPmdl/mtnC8Azub2Y2KJxuZvYzM1ttZpvM7C0zOyqcd4aZzTWzzWZWa2bfSbPuAjP7HzN7P1zPvWZWHs77u5l9s8Xyb5rZ2eHzw8IzyvVmNt/Mzkla7h4zu8PMHjezrcBH2vmZx5tZTVhdsDYsMV2QNL88jHVNGPv/mFlB0vz/NLN54eefa2YfSFr9seGZ7kYz+4OZlYbv6Wdmj5pZXfiZXkheZ9K6rzWz28LnMTPbamaTw9fxsJTTJ7kqxcyuB04CfhGejf8iaZUfNbMF4XZvNzNrZdfMAMrM7Mhwe0cCpeH0dnH3bcD9wFHhpGuBf7n7le6+Ilxmvruf7+51KfbDJUn7eLGZfSVpXtp9aWbfDb+Tm8Pvzanh9GvM7PdmVmJmW4BC4E0zWxTOby41h9/bq8xskZmtM7M/mlmfcF5iv3/ZzJYCz7Z333RXSgR5yswmADcC5wADgfeBB8PZHwdOBg4FysNl1oXzfg18xd17EfzQ0/0YLg4fHwGGAz2BxEHqAeC8pFiOIDhLe8zMegBPERxIDgDOBf4vXCbhfOB6grPJF9v72YEBQD+gmuCs904zGxnOuy38zMOBUwjOki8J4/wCcE04rTfwGXbvFwj20yeAg4BR4ecH+DZQA1QB/YGrgVRjs0wHxofPPwisJPg/AJwIzHf39clvcPfvAS+wuwSUnGA/Fa5nVBjbaa3sE4DfsbtUcFH4ut3MrCdwATArnPRR4E/tWMVqgth7E+z7nyUl3JT7Mvz/fRP4YPjdPA1YkrxSd98RllgAjnH3g1Ns+zLgLIL//SBgA3B7i2VOAQ6n7f0ZGUoE+esC4G53f93ddwCTgBPNbBjQQHCQPQwwd5+XOJML5x1hZr3dfYO7v97K+n/q7ovdfUu4/nMtKE7/heDs+cCkZR8O4/gUsMTdf+Puu9x9FvBngqqEhL+6+z/dvcndt6fZ/q3hWWPi8cMW8/83PDBMBx4DzrGgmulcYJK7b3b3JcAtwIXhe/6DoPpjhgcWuvv7ydt09+XhwfoR4NikfTYQONDdG9z9BU89SNdLwCFm1pcgAfwaqA4PrKcQJIr2uMnd69x9KfBcUjzp/B44z8xiBPvh9+3c3nfMrA5YSJD4Lw6n9wVWpHtTS+7+mLsvCvfxdOBJglIPpN+XjUAJwXcz5u5L3H1RO+MH+CrwPXevCb+P1wCftz2rga5x963uXr8P6++WlAjy1yCCUgAA4cF6HVDt7s8SnL3fDqw2szvNrHe46OeAM4D3zWy6mZ2YyfrD50VAf3ffTHDwPTecdx5wX/j8QGBs8kGcIFEMSFrXsgw+3+XuXpH0+N+keRvcfWuL2AYRlBJiKeKuDp8PAVo7uKxMer6N4GAIMJng4PhkWNVxVao3hweWmQQH/ZMJDvz/Asaxb4kgXTwphQljIXADsMDdM9nPyX4S7usB7v6ZpAPxOoKDd0bM7HQzezms+qkj+L71C2en3JfuvhD4FsGBe7WZPWhhVWc7HQj8Jem7N48gyfRPWqa9+6XbUyLIX8sJvvQAhFUyfYFaAHe/1d2PA44gqCKaGE6f4e5nElTbTAX+mMn6gaHALmBV+PoBgrPPEwnqop8Lpy8Dprc4iPd0968lrWt/h7ytDD9vcmzLgbUEZ5wt465Nii1VdUKrwtLFt919OEF10pWJ+usUpgMTgNEE9fPTCaogjgf+kW4T7Y2pFfcSVL/c24HrfJrgBKJNZlZCUAL8CcFJQwXwOGDQ+r509/vd/cME/z8Hbt6HWJcBp7f4/pW6e23SMhpyuQUlgvwQM7PSpEcRwYH4EjM7Nvzx3QC84u5LzOyDZjY2rCLYCmwHmsys2MwuMLNyd28ANgFNabb5APBfZnZQWLVxA/AHd98Vzn+c4Ad7XTg9sZ5HgUPN7MKwwTQWxnN4B++Ta8PPcxJBddRDYXfMPwLXm1mvsOrqSnZXkfyKoPrjOAuMSKreSsvMPhUua8BGgjPMdPttOkE9/Vx33wk8T1Al9Z67r0nznlUEbRod4Q8EbUTpEjwtvkul4edqzQ+AD5nZZDMbEK5jRNiAW9Fi2WKCKp41wC4zOz2MJ7HtlPvSzEaa2YTwu7wdqCf9Pm7NFIL//4Hh9qrM7Mx9WE+kKBHkh8cJfhiJxzXu/jTwvwRnXysIznQTVTW9gbsIGsreJyjaTw7nXQgsMbNNBPWpzT1uWriboLHxH8B7BD/OyxIzw/rXhwkaEu9Pmr6Z4Id/LsFZ+kqCM7uSdn7mRC+axOO1pHkrw8+2nKBK6qvu/k447zKC5LeYoCH6/vCz4O4PETRS3w9sJigR9ckglkMIzoq3ELQD/J+7P5dm2X8BcXaf/c8l2HfpSgMAPyeox95gZrdmEE9a7l7v7k+3Uv9dzZ7fpXraKCWFVUQnAsOAOWa2keB7N5NgPyYvuxm4nCARbSDoGPC3pEXS7csS4CaCUt1KghLrpIw+9J5+Hm7vSTPbDLwMjN2H9USKpW7zEumaLLiC9PfuPjjXsYh0FyoRiIhEnBKBiEjEqWpIRCTiVCIQEYm4vBt0qV+/fj5s2LBchyEikldee+21te5elWpe3iWCYcOGMXPmzFyHISKSV8zs/XTzVDUkIhJxSgQiIhGnRCAiEnF510YgIrKvGhoaqKmpYfv2dKOf57/S0lIGDx5MLBbL+D1KBCISGTU1NfTq1Ythw4bR9lh7+cfdWbduHTU1NRx00EEZvy8SiWDqrFomT5vP8rp6BlXEmXjaSM4aXd32G0WkW9m+fXu3TQIAZkbfvn1ZsybdQLepdftEMHVWLZMefov6hkYAauvqmfTwWwBKBiIR1F2TQMK+fL5u31g8edr85iSQUN/QyORp83MUkYhI19LtE8HyutTDsqebLiKSTT17tnrH0Zzo9lVDgyri1KY46A+qiOcgGhHJJ1FpX+z2JYKJp40kHivcY1o8VsjE00bmKCIRyQeJ9sXaunqc3e2LU2fVtvne9lqyZAkTJkxg1KhRnHrqqSxduhSAhx56iKOOOopjjjmGk08+GYA5c+Zw/PHHc+yxxzJq1CgWLFiw39vv9iWCRPa+6e/vsHLTdsrjMa79zJHdMquLSOaufWQOc5dvSjt/1tI6djbuedvk+oZG/vtPs3ng1aUp33PEoN784NNHtjuWyy67jIsuuoiLLrqIu+++m8svv5ypU6dy3XXXMW3aNKqrq6mrqwNgypQpXHHFFVxwwQXs3LmTxsbGNtbetm5fIoAgGTw/cTwAl548XElARNrUMgm0NX1/vPTSS5x//vkAXHjhhbz44osAjBs3josvvpi77rqr+YB/4okncsMNN3DzzTfz/vvvE4/vfzV3ty8RJJTGConHCtmwdWeuQxGRLqCtM/dxNz2bsn2xuiLOH75yYrbC2sOUKVN45ZVXeOyxxzjuuON47bXXOP/88xk7diyPPfYYZ5xxBr/85S+ZMGHCfm0nEiWChMqyGHX1DbkOQ0TyQGe2L37oQx/iwQcfBOC+++7jpJNOAmDRokWMHTuW6667jqqqKpYtW8bixYsZPnw4l19+OWeeeSazZ8/e7+1HpkQAUF5WTN02lQhEpG2JKuSO7jW0bds2Bg8e3Pz6yiuv5LbbbuOSSy5h8uTJVFVV8Zvf/AaAiRMnsmDBAtydU089lWOOOYabb76Z3/3ud8RiMQYMGMDVV1+9X/FAHt6zeMyYMb6vN6Y5/66X2bmriT997UMdHJWI5IN58+Zx+OGH5zqMrEv1Oc3sNXcfk2r5SFUNVZTF2KASgYjIHiKWCIrZqDYCEZE9RCsRxGPUbWsg36rDRKTjdPff/758vkglgsqyYnY1OVt27Mp1KCKSA6Wlpaxbt67bJoPE/QhKS0vb9b6I9RoK7thTt62BXqWZ371HRLqHwYMHU1NT0+7x+vNJ4g5l7RGpRFBZVgwEiWBInxwHIyKdLhaLtevOXVERqaqhirBEoJ5DIiK7RSsRxMOqIfUcEhFpFq1E0Fw1pBKBiEhCpBJBeXx3Y7GIiAQilQiKiwroWVKkNgIRkSSRSgQQlAo2qkQgItIscomgsofGGxIRSRa5RFARL1avIRGRJNFLBGWqGhIRSZa1RGBmQ8zsOTOba2ZzzOyKFMuYmd1qZgvNbLaZfSBb8SRoKGoRkT1lc4iJXcC33f11M+sFvGZmT7n73KRlTgcOCR9jgTvCv1lTGQ5F3dTkFBRYNjclIpIXslYicPcV7v56+HwzMA9oeY+3M4F7PfAyUGFmA7MVEwS9hpocNm/XCKQiItBJbQRmNgwYDbzSYlY1sCzpdQ17JwvM7FIzm2lmM/d31MDmgefqVT0kIgKdkAjMrCfwZ+Bb7r5pX9bh7ne6+xh3H1NVVbVf8eweeE4NxiIikOVEYGYxgiRwn7s/nGKRWmBI0uvB4bSs0XhDIiJ7ymavIQN+Dcxz95+mWexvwJfC3kMnABvdfUW2YoLdJQKNNyQiEshmr6FxwIXAW2b2RjjtamAogLtPAR4HzgAWAtuAS7IYD5B8cxqVCEREIIuJwN1fBFrtn+nBjUO/ka0YUuldGnxktRGIiAQid2VxUWEBvUuL2KhhJkREgAgmAggajHV1sYhIIJKJoLIspsZiEZFQJBNBeVmxGotFREKRTASVZTENRS0iEopkIqiIx9iwVSUCERGIaCIoLytm0/ZdNDZ5rkMREcm5SCaCyvDqYnUhFRGJaCLYPcyEqodERCKaCIJhJnR1sYhIVBNBPFE1pBKBiEgkE0Fi4LkNW1UiEBGJZCJobiNQY7GISDQTQe/SGGZqLBYRgYgmgoICozyu8YZERCCiiQCCdgKNQCoiEuFEUB6P6YIyEREinAgqy2IqEYiIEOFEUFFWrDYCEREinQjUWCwiAlFOBPFituzYRUNjU65DERHJqcgmgsoeiYHnVCoQkWiLbCIo13hDIiJAhBNBYrwhlQhEJOoimwgS4w1pKGoRibrIJoLdJQJVDYlItEU2EZSXqbFYRAQinAh6lRRRWGDUqbFYRCIusonAzKiIx9RGICKRF9lEAEGD8UYlAhGJuIgnAg1FLSIS7USgm9OIiEQ8EZQVq/uoiERexBNBTDewF5HIi3QiqCyLsW1nIzt2NeY6FBGRnIl0IigPry5WzyERibJIJ4JKjTckIhLtRFAR13hDIiJZSwRmdreZrTazt9PMH29mG83sjfDx/WzFko5GIBURgaIsrvse4BfAva0s84K7fyqLMbQqkQh0cxoRibKslQjc/R/A+mytvyMkhqJWiUBEoizXbQQnmtmbZvZ3MzuyszdeVlxIrNB0dbGIRFo2q4ba8jpwoLtvMbMzgKnAIakWNLNLgUsBhg4d2mEBmJmuLhaRyMtZicDdN7n7lvD540DMzPqlWfZOdx/j7mOqqqo6NA6NNyQiUZezRGBmA8zMwufHh7Gs6+w4KjUCqYhEXNaqhszsAWA80M/MaoAfADEAd58CfB74mpntAuqBc93dsxVPOuVlMZat39bZmxUR6TKylgjc/bw25v+CoHtpTlWWxZhdoxKBiERXrnsN5VzQWKw2AhGJLiWCshg7djVRv1MjkIpINCkRJMYb0tXFIhJRkU8EzSOQblX1kIhEU+QTQXmYCFQiEJGoinwiSIw3pAZjEYmqyCeCxAikSgQiElVKBPHECKSqGhKRaIp8IogXF1JSVMDGepUIRCSaIp8IIKge2rBVJQIRiSYlAoIG4zqVCEQkojJKBGZ2sJmVhM/Hm9nlZlaR3dA6T3k8xkY1FotIRGVaIvgz0GhmI4A7gSHA/VmLqpNpKGoRibJME0GTu+8CPgvc5u4TgYHZC6tzVZTFVDUkIpGVaSJoMLPzgIuAR8NpseyE1PkSt6vMwe0QRERyLtNEcAlwInC9u79nZgcBv8teWJ2roixGQ6OzTSOQikgEZXRjGnefC1wOYGaVQC93vzmbgXWm5oHntu2kR0nW7tUjItIlZdpr6Hkz621mfYDXgbvM7KfZDa3zlMc13pCIRFemVUPl7r4JOBu4193HAh/NXlidq1LjDYlIhGWaCIrMbCBwDrsbi7uNijLdnEZEoivTRHAdMA1Y5O4zzGw4sCB7YXWu3W0EKhGISPRk2lj8EPBQ0uvFwOeyFVRnS9ycZqMuKhORCMq0sXiwmf3FzFaHjz+b2eBsB9dZSooKKSsuVIlARCIp06qh3wB/AwaFj0fCad1GRTymxmIRiaRME0GVu//G3XeFj3uAqizG1ekSVxeLiERNpolgnZl90cwKw8cXgXXZDKyzabwhEYmqTBPBvxN0HV0JrAA+D1ycpZhyQiOQikhUZZQI3P19d/+Mu1e5+wHufhbdqNcQBD2HdE8CEYmi/blD2ZUdFkUXUBlWDWkEUhGJmv1JBNZhUXQBFfFiGpuczTt25ToUEZFOtT+JoFudOlckxhvaquohEYmWVq8sNrPNpD7gGxDPSkQ5kjze0FDKchyNiEjnaTURuHuvzgok1yo03pCIRNT+VA11K7uHolYXUhGJFiWCkG5OIyJRpUQQqtDNaUQkopQIQrHCAnqWFOnqYhGJHCWCJBVlMTZqvCERiZisJQIzuzu8d8Hbaeabmd1qZgvNbLaZfSBbsWSqoiymEoGIRE42SwT3AJ9oZf7pwCHh41LgjizGkpHKsmK1EYhI5GQtEbj7P4D1rSxyJnCvB14GKsxsYLbiyUR5PKbuoyISOblsI6gGliW9rgmn5UxlWbHuSSAikZMXjcVmdqmZzTSzmWvWrMnadhKNxY1N3WoYJRGRVuUyEdQCQ5JeDw6n7cXd73T3Me4+pqoqe3fIrCgrxh02b1epQESiI5eJ4G/Al8LeQycAG919RQ7joSKu8YZEJHpaHXRuf5jZA8B4oJ+Z1QA/AGIA7j4FeBw4A1gIbAMuyVYsmarskTzeUI/cBiMi0kmylgjc/bw25jvwjWxtf180jzekBmMRiZC8aCzuLBqBVESiSIkgSfPNadRGICIRokSQ5Pl3VgNw7SNzGXfTs0ydlbITk4hIt6JEEJo6q5bvTd09LFJtXT2THn5LyUBEuj0lgtDkafOpb2jcY1p9QyOTp83PUUQiIp1DiSC0vK6+XdNFRLoLJYLQoIp4u6aLiHQXSgShiaeNJB4r3GNaSVEBE08bmaOIREQ6R9YuKMs3Z40OBj6dPG0+y+vqceDYIeXN00VEuislgiRnja5uPvBf+8gc7n3pfRav2cLwqp45jkxEJHtUNZTG18ePoKSogJ89vSDXoYiIZJUSQRpVvUq4ZNwwHnlzOfNWbMp1OCIiWaNE0IpLTzqYXqVF3PLku7kORUQka5QIWlFeFuMrJw/n6XmreH3phlyHIyKSFUoEbbhk3EH07VHMLU/qCmMR6Z6UCNrQo6SIr39kBP9cuI5/LVqb63BERDqcEkEGLhg7lIHlpfxk2nyC++mIiHQfSgQZKI0VctmEQ3h9aR3PzV+d63BERDqUEkGGvjBmMAf2LWPytHdpalKpQES6DyWCDMUKC/jWRw9h3opNPP72ilyHIyLSYZQI2uEzx1QzoHcJ33rwDQ666jHdxUxEugWNNdQOj7y5nPVbd7IrrBpK3MUM0OB0IpK3VCJoh8nT5rOzcc/2Ad3FTETynRJBO+guZiLSHSkRtIPuYiYi3ZESQTukuosZwPjD+uUgGhGRjqFE0A5nja7mxrOPproijgGDyksZUdWDP86o4ZXF63IdnojIPrF8GzJhzJgxPnPmzFyH0WzjtgY+e8c/Wb91Jw9/7UO6m5mIdElm9pq7j0k1TyWC/VReFuOei4+nwIx/v2cG67fuzHVIIiLtokTQAYb2LeOuLx3H8o3b+crvZrJjV2OuQxIRyZgSQQc57sA+3PKFY5ixZAP//afZGqVURPKGrizuQJ8+ZhBL129j8rT5bN/ZyNvLN7G8rp5BFXEmnjZSVx+LSJekRNDBvj7+YKbPX820uauap2koChHpylQ11MHMjJoNe19prKEoRKSrUiLIghUbt6ecrqEoRKQrUiLIgnRDTpSXxXRTGxHpcpQIsiDVUBRmULetgX+78yXeWbkpR5GJiOxNjcVZkGgQnjxtfnOvoe987FAampwb/z6PT976Iv8+bhgHV/XktmcXqmeRiORUVoeYMLNPAD8HCoFfuftNLeZfDEwGErf5+oW7/6q1dXa1ISbaa8PWnfx42js88OqyvebFY4XcePbRSgYi0uFyMsSEmRUCtwOnA0cA55nZESkW/YO7Hxs+Wk0C3UFlj2JuPHsUVT1L9pqnnkUikgvZbCM4Hljo7ovdfSfwIHBmFreXV9Zu2ZFyunoWiUhny2YiqAaS6z9qwmktfc7MZpvZn8xsSBbj6VLS9SwqLDBm19R1cjQiEmW57jX0CDDM3UcBTwG/TbWQmV1qZjPNbOaaNWs6NcBsSdWzqLjQiMcKOOv2f/LDR+eydceuHEUnIlGSzV5DtUDyGf5gdjcKA+DuyXdz+RXw41Qrcvc7gTshaCzu2DBzI1XPoomnjWTC4Qdw89/f4dcvvscTb6/kR589io3bGvZaTg3KItJRstZryMyKgHeBUwkSwAzgfHefk7TMQHdfET7/LPBddz+htfXme6+hTM1Ysp5JD7/FwtVbKDSjMen/pN5FItJeOek15O67gG8C04B5wB/dfY6ZXWdmnwkXu9zM5pjZm8DlwMXZiifffHBYHx67/MP0Ki3aIwmAeheJSMfK6gVl7v448HiLad9Pej4JmJTNGPJZSVEhW7anbidQ7yIR6Si5biyWNqTrXQTw4yfeYc3m1N1QRUQypSEmuriJp41k0sNvUd+w+/aXJUUFHDagJ3dMX8SvX3yPc8YMYVi/Mu5+cYkalEWk3ZQIurh0vYvOGl3N4jVb+OX0xdz3yvskD2qqG+GISHtkdayhbIhKr6H2OOGGZ1i5ae97IAwsL+WlSafmICIR6Wpy0mtIOs+qFEkAghvkTHp4Nm8sqyOR8KfOqmXcTc9y0FWPMe6mZ5k6qzble0UkOlQ11A0MqohTm6IXUTxWyNRZy3ng1WWM7N+Lwwf24ok5K9ne0ASoCklEAioRdAOphqtIXHT26vdO5YbPHk1pcSFT31jenAQSdE2CiCgRdANnja7mxrOPproijgHVFfHmK497lcY4f+xQ/vqNcVia99fW1fPn12pYtn6bqpBEIkhVQ93EWaOr26zeSVeFZMC3H3oTgP69SxhYXsqc5ZtoaAySQroqpKmzajUGkkg3oEQQIamuSYjHCrnhrKM4vLo3M95bz4wlG3h09vI9uqNCUIV09V/eYtn6bQztW8Z7a7cyZfoitTeIdAPqPhoxmZzFH3TVY+zrt6K6Is4/r5qw/4GKSIdqrfuoSgQRsz9VSNUVcZ6+8hSWbdjGx3/2j5Tvra2r5/WlGxg9pAKzoFVCVUgSRfn0vVcikL2kq0KaeNpI4sWFHNq/F9VpkgXA2f/3L0Yc0JPPHzeYslgBN/59fvO6VIUkUTB1Vu0ev6Gu/r1XIpC9tDasRUK6ZPGDTx8OGA+9VsNNf38n5foTXVbV8Czd1eRp8/f4bUDq731XoUQgKbVVhdRWsjj3+KEsWrOFU2+ZnvL9tXX1TJ72DsP79WTZhm0ZNzwrYUhLXe07sWrT9rSl5dq6et6u3ciRg3pjZl0mdjUWS1aNu+nZlD+KooKg/WBXy+5JSXqUFPL18SOoLCumT48Yb9du5K4X3mPHrt0XxaW6W1tX+XFJ9rWsgoHc3cFvxcZ6pjy/iAdmLGPnrqZWlx1YXsrwfmXMWFLHzsbWv88dpbXGYiUCyarWfqifHDWQZeu3MSFNqSFTPUoKufJjIxnap4wFqzdz6zML9riCOt9u7alElrl0JxrZ7L3W8v/z5Q8PY9GarTw0s4Ymd74wZjAjqnrykyff3et7P+mMwyiNFfL03FU8NXdVyt552YpdvYYkZ9qqQhpe1TNtw3N1RZxnvn0KddsaWL91J2fc+kLKbWzd0cgPH52bNob6hkZueHwenxw1kFjh7ovpMzngduRBOdPt5VMjY65srG/gmXmr0lbBZOsOfqn+P9c9Oo9Cg/PGDuWrpxzM4MoyAPr2LEn7/z5nzBAOuuqxTo29NSoRSM5lWrxPf/ZXyiOXncSy9ds48/Z/pt1OcWEBhw7oyVGDytnV2MQjs1e0Ws3UkdUOmaxr645dTLjleVZt2vuucy3PErtqqSGbifMbHzmYWGEBj7+1ghcXrqWh0Skw9rr4EYL/9S/OH82ph/ensCDd4Crtl27I9wG9S3j56o+2a13pvs8FBtedeRTnfnAIRYUdNwqQqoaky9uXs2XY+2Ca7sdVWRbjnDFDmLN8E3OWb2TDtoaUcRhQ2aOYogJj3ZYdNKb4eaS6z0Nb8Y+76Rlq6/Y+gBQXFjC4Ms6qTdvZurNxr/nJTjqkH4Mry9i8fSfT5qxqHgIk1cp9qn4AAAnaSURBVH7IhrY+Y7YTZ0J1RZwzjh7AGUcPZMmarVw99e09losVGj2Ki6irb2BY3zK+/OGDKCkq5OfPLGgzQbX8jN/5+KEcVV3Ok2FVzhvL6lLGa8B7N31yvz9jSVEB1RVxFq/dysj+vfj+p49g3Ih+HZJglQik2+iIg5G7M3zS42mvnv7iCUNpbHIeeHVZ2jiOHVLB2OF9OOGgvqzcVM91j8zbY5ulRQVccMKB9Cgp4u3ajTz7zuq06/rkqIEc0KuE/r1L+eX0RSmTVDxWwKH9e7FsQz3rt+5MuZ7epUXc+aUxHFVdTs+Sooz2V6aC/Tqb+qS2l6IC45RDq+jbs5j1W3cy/d01eySnhP69S3ilxdlyurjcnbkrNnHenS+zafuuvdZV1bOEV793avPFiunW9alRA3lizkrueuE93kxx8C6NFfD9Tx/BmcdUU1hgFBUYj7y5nKv/smdSMWj+nhwzuJz31m5NGde+1uuniv3MYwfxxNsruf7xedRsqOfIQb1ZuHpLm50k2qJEIJGSycEvk0bGdMv0LCli5IBezK6pS3ngS1ZgMOKAnixbX5/27LZllU9biaytIUDM4OCqnlTEi3izZmObJYd0+6uxyZm3YhMvL17HT6bNZ3uanjD9e5fQp0cJ81ZsShvT0D5lfPiQfpw0oh8btu3kh4/umTiLCws4blgFS9ZuY8XG1Ddagvafebs7H7z+adZuSZ08M1EejzHtWyczoLy0U3spbW9o5O5/vsfkJ+Z3SKOyGoslUjIZRqO1q6fbWuZHZx3FWaOrqd/ZyOtLN3DBr15JuQ0D3r72NMqKi9IeQJK3l4gdWr+YL90QIAN6l3Lj2Uczu2Yjs2vqeG7+6pSDB056+C3eW7uVYf3KeH/d3tdwTPzTm9z1wiKWrq9nc4qz35afMXG2ny5xlseLOLR/T/46q5b7X1macj07G5t4edF6TjtyAP/1sQP46ZPvpqyLH1QRbzWeveIzY10rSeDqMw5jV5PT2Ojc8tS7KZfZVN/AgPJSILP/T0cpjQXdpyc/kfp+IR3ZqKxEIJGUyQ+6rWXixYWMG9Evba+nQRVxyoqLMt5e8nZbO7CkS1BXnX4YHznsAD5y2AEAaXul1Dc0cuuzC0hXGdDQ6LyzcgtfOG4wJwzvy9jhffj8HS+l/YxtxXXtZ4LE2dDYxBvL6vjClJfSfrYpFx4HBCWETBJnJlobO+vSkw9ufv3gjGVtfkbI7ESjI6WLv71JsTVKBBJZmfygO6p0kem6MpFpUmntAPjsd05h2fp6PvrT1NdwNDU5N31uVPPrTD5jW3HFCgv44LA+rSbO9n7GTGT6/8l0uc7WGXEpEYjsp86sLkje5v4kqJKiQkYckP4ajlRnwdD2Z8znxJmL/2MmOiMuNRaLdGOd2eWzI+OSjqdeQyKSlg7K0aBeQyKSVmc3fkrX03HXL4uISF5SIhARiTglAhGRiFMiEBGJOCUCEZGIy7vuo2a2Bnh/H9/eD1jbgeF0NsWfO/kcO+R3/PkcO3Sd+A9096pUM/IuEewPM5uZrh9tPlD8uZPPsUN+x5/PsUN+xK+qIRGRiFMiEBGJuKglgjtzHcB+Uvy5k8+xQ37Hn8+xQx7EH6k2AhER2VvUSgQiItKCEoGISMRFJhGY2SfMbL6ZLTSzq3IdT3uZ2RIze8vM3jCzLj0Ot5ndbWarzeztpGl9zOwpM1sQ/q3MZYytSRP/NWZWG+7/N8zsjFzGmI6ZDTGz58xsrpnNMbMrwul5sf9bib/L738zKzWzV83szTD2a8PpB5nZK+Gx5w9mVpzrWFuKRBuBmRUC7wIfA2qAGcB57j43p4G1g5ktAca4e1e4MKVVZnYysAW4192PCqf9GFjv7jeFibjS3b+byzjTSRP/NcAWd/9JLmNri5kNBAa6++tm1gt4DTgLuJg82P+txH8OXXz/m5kBPdx9i5nFgBeBK4ArgYfd/UEzmwK86e535DLWlqJSIjgeWOjui919J/AgcGaOY+q23P0fwPoWk88Efhs+/y3Bj7tLShN/XnD3Fe7+evh8MzAPqCZP9n8r8Xd5HtgSvoyFDwcmAH8Kp3fJfR+VRFANLEt6XUOefLmSOPCkmb1mZpfmOph90N/dV4TPVwL9cxnMPvqmmc0Oq466ZNVKMjMbBowGXiEP93+L+CEP9r+ZFZrZG8Bq4ClgEVDn7rvCRbrksScqiaA7+LC7fwA4HfhGWH2Rlzyoj8y3Osk7gIOBY4EVwC25Dad1ZtYT+DPwLXfflDwvH/Z/ivjzYv+7e6O7HwsMJqiJOCzHIWUkKomgFhiS9HpwOC1vuHtt+Hc18BeCL1k+WRXW/ybqgVfnOJ52cfdV4Y+8CbiLLrz/w/rpPwP3ufvD4eS82f+p4s+n/Q/g7nXAc8CJQIWZJW4L3CWPPVFJBDOAQ8LW+2LgXOBvOY4pY2bWI2w4w8x6AB8H3m79XV3O34CLwucXAX/NYSztljiIhj5LF93/YYPlr4F57v7TpFl5sf/TxZ8P+9/MqsysInweJ+icMo8gIXw+XKxL7vtI9BoCCLub/T+gELjb3a/PcUgZM7PhBKUAgCLg/q4cv5k9AIwnGH53FfADYCrwR2AowTDi57h7l2yQTRP/eIJqCQeWAF9JqnPvMszsw8ALwFtAUzj5aoJ69i6//1uJ/zy6+P43s1EEjcGFBCfZf3T368Lf74NAH2AW8EV335G7SPcWmUQgIiKpRaVqSERE0lAiEBGJOCUCEZGIUyIQEYk4JQIRkYhTIhAJmVlj0uiWb3TkKLVmNix5NFORrqSo7UVEIqM+HB5AJFJUIhBpQ3gviB+H94N41cxGhNOHmdmz4UBoz5jZ0HB6fzP7Szgu/Ztm9qFwVYVmdlc4Vv2T4dWnmNnl4fj7s83swRx9TIkwJQKR3eItqob+LWneRnc/GvgFwRXqALcBv3X3UcB9wK3h9FuB6e5+DPABYE44/RDgdnc/EqgDPhdOvwoYHa7nq9n6cCLp6MpikZCZbXH3nimmLwEmuPvicEC0le7e18zWEtxEpSGcvsLd+5nZGmBw8jAC4ZDKT7n7IeHr7wIxd/+RmT1BcCOcqcDUpDHtRTqFSgQimfE0z9sjeXyZRna30X0SuJ2g9DAjaaRKkU6hRCCSmX9L+vtS+PxfBCPZAlxAMFgawDPA16D5RiXl6VZqZgXAEHd/DvguUA7sVSoRySadeYjsFg/vLpXwhLsnupBWmtlsgrP688JplwG/MbOJwBrgknD6FcCdZvZlgjP/rxHcTCWVQuD3YbIw4NZwLHuRTqM2ApE2hG0EY9x9ba5jEckGVQ2JiEScSgQiIhGnEoGISMQpEYiIRJwSgYhIxCkRiIhEnBKBiEjE/X+tiFLOvcbVUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.1, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-05,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-06,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de9yUdZ3/8dcbuQVSkRJKvRHRMswDipGnPGKbh7XAdMskU9N1dTe1deOnViukaRrt1mqZq4aHIjXLWFMsLU0qD4WKqOFZUUADEQQV5fT5/XF9bxlv57rve+575p7T+/l43A9mvtdhvtfMMO/5Hua6FBGYmZmVQ59qV8DMzBqHQ8XMzMrGoWJmZmXjUDEzs7JxqJiZWdk4VMzMrGwcKmZlJuk5SZ/opccaJuk1Set1sE5I+lBv1KenJA1P9e1bof1/TdIVBfcPk/RCeg5HSXpU0n6VeOxm4VBpIr35YVcrJP1B0pvpQ6Pt79fVrle5RMTzEbFhRKyBt4/3hO7uT9Kk9KF+Wrvy01L5pHR/P0nzcvZxlaSV6bl+RdLtkrYtWP5hSTdIelnSq5JmSzq9o2Asl4g4PyIKn5/vAl9Oz+GDEbF9RPyh0vVoZA4VaxgdfCi1fWi0/X2qVytWf54Avtiu7JhU3lXfiYgNgaHAQuAqAEkfBO4DXgB2jIiNgX8CRgMb9aza3bIl8GhPd1KpllU9cqgYAJL+WdJT6ZvlTZI2T+WS9D1JCyUtk/SwpB3SskMk/U3ScknzJX01Z999JH1D0ty0n2skbZyW3Srpy+3Wf0jSZ9LtbdM33VckPS7pswXrXSXpR5KmS3od2L/EY95P0rzUJfJyasmNL1i+carrolT3b0jqU7D8nyXNScf/N0m7FOx+5/QN/FVJ10vqn7YZLOlmSUvTMf2xcJ8F+/6mpIvT7RZJr0uanO4PSK2v9xV2F0k6D9gb+EFqJfygYJefkPRketwfSlIHT81fgfdI2j493vZA/1Rekoh4A/gZsEMq+iZwd0ScHhEvpnUej4ijImJpkefhuILn+BlJ/1KwLPe5lHRGek8uT++bA1L5JEk/ldRP0mvAesBDkp5Oy99uzaf37ZmSnpa0WNLPJb0vLWt73o+X9DxwR6nPTaNyqBiSxgDfBj4LbAbMBa5Liz8J7AN8GNg4rbM4Lfsx8C8RsRHZh0bef6xj09/+wNbAhkDbB961wOcL6rId2bfHWyRtANxO9qH0fuBI4JK0TpujgPPIvuX+qdRjBzYFBgOtZN/GL5M0Ii27OB3z1sC+ZN/ej0v1/CdgUiobCHyadc8LZM/TQcBWwMh0/AD/AcwDhgAfAL4GFDtX0l3Afun2x4CXyF4HgD2AxyPilcINIuLrwB9Z1zIrDOtD035Gprod2MFzAvAT1rVWjkn3SyZpQ2A88GAq+gTwixJ2sZCs7gPJnvvvFYR30ecyvX5fBj6W3psHAs8V7jQi3kotKYCdIuKDRR77FGAc2Wu/ObAE+GG7dfYFPkLnz2fTcKgYZP/pp0TEAxHxFnAWsIek4cAqsg/sbQFFxJy2b5hp2XaSBkbEkoh4oIP9/3dEPBMRr6X9H6msy+BXZN/qtyxY98ZUj0OB5yLiyohYHREPAr8k6y5p838R8eeIWBsRb+Y8/kXp22zb37ntlv9n+pC5C7gF+KyyrrQjgbMiYnlEPAf8F3B02uYEsi6ev0bmqYiYW/iYEbEgffD/Gti54DnbDNgyIlZFxB+j+An47gG2kbQJWZj8GGhNH9L7koVOKS6IiKUR8TxwZ0F98vwU+LykFrLn4aclPt5XJS0FniL7EnFsKt8EeDFvo/Yi4paIeDo9x3cBt5G1xiD/uVwD9CN7b7ZExHMR8XSJ9Qc4Cfh6RMxL78dJwBF6Z1fXpIh4PSJWdGP/DcmhYpB9C3v7AzF98C8GWiPiDrJWxQ+BhZIukzQwrXo4cAgwV9Jdkvboyv7T7b7AByJiOdkH+ZFp2eeBqen2lsBuhYFAFjqbFuzrhS4c36kRMajg7z8Lli2JiNfb1W1zstZLS5F6t6bbWwAdfVC9VHD7DbIPVoDJZB+0t6XunDOLbZw+pGaSBcg+ZCFyN/BxuhcqefUpKoXPU8D5wJMR0ZXnudB303O9aUR8uuBDfTFZEHSJpIMl3Zu6t5aSvd8Gp8VFn8uIeAr4ClkILJR0nVJ3bom2BH5V8N6bQxZYHyhYp9TnpeE5VAxgAdl/IABSt9MmwHyAiLgoIj4KbEfWDTYhlf81IsaSdU1NA37elf0Dw4DVwN/T/WvJvhXvQdZ3f2cqfwG4q10gbBgRJxfsq6en2X5vOt7Cui0AXib7Jty+3vML6lasy6RDqdXzHxGxNVmX2elt/f1F3AWMAUaRjWfcRdbNsiswI+8hSq1TB64h62K6poz7/B3Zl5FOSepH1jL9LtkXkEHAdEDQ8XMZET+LiL3IXr8ALuxGXV8ADm73/usfEfML1vFp3ttxqDSfFkn9C/76kn2oHydp5/Qf+Xzgvoh4TtLHJO2WukFeB94E1kpaX9J4SRtHxCpgGbA25zGvBf5d0lap++Z84PqIWJ2WTyf7z39OKm/bz83AhyUdnQarW1J9PlLm5+Sb6Xj2JutyuyFN0f05cJ6kjVL33Oms6wa6gqyL56PKfKigCy+XpEPTugJeJfvmm/e83UU2rvG3iFgJ/IGs2+3ZiFiUs83fycaAyuF6sjG1vC8LtHsv9U/H1ZGJwJ6SJkvaNO3jQ2nwfFC7ddcn68ZaBKyWdHCqT9tjF30uJY2QNCa9l98EVpD/HHfkUrLXf8v0eEMkje3GfpqKQ6X5TCf7T9b2Nykifgf8J9m3whfJvoG3dUcNBC4nG6ScS9Z9MTktOxp4TtIysv7nt2dOtTOFbKB3BvAs2X/0U9oWpv7qG8kGcX9WUL6c7EPkSLLWw0tk3zj7lXjMbbOh2v7uL1j2Ujq2BWTdbidFxGNp2SlkQfoM2SSAn6VjISJuIJsg8DNgOVlL7X1dqMs2ZN/WXyMbN7kkIu7MWfduYADrWiV/I3vu8lopAP9D1u+/RNJFXahProhYERG/62C8oJV3vpdW0EnrLXWD7QEMBx6V9CrZ+24m2fNYuO5y4FSyUFtCNinjpoJV8p7LfsAFZK3Nl8ha0md16aDf6X/S490maTlwL7BbN/bTVFR8jNCs8Sn75fRPI2Joteti1ijcUjEzs7JxqJiZWdm4+8vMzMrGLRUzMyubip0ETdIUsumZCyOi7VxR5wJjyab3LQSOjYgFys63dAbZ/PPlwMkR8VCRfY4hm7O+PnA/cHzBtFQkfYxsFsiREdHpqSAGDx4cw4cP79Fxmpk1m/vvv//liBhSbFnFur8k7UM21e+aglAZGBHL0u1Tge0i4iRJewJzImJJmos+KSJ2a7e/PmRTWg+IiCcknQPMjYgfp+XrkZ0n6k2yU450GiqjR4+OmTNnlu2YzcyagaT7I2J0sWUV6/6KiBlA+xPeLSu4uwHp16gRcXdELEnl95KdLru9TYCVEdF2+u3beecvc08hm+++sOe1NzOz7uj1awAoOz33F8l+AVvsVOXHA7cWKX8Z6CtpdETMBI4gO/8SklqBw9L+PlaJepuZWed6faA+Ir4eEVuQ/Xq5/XU09icLlTOKbBdkv6z+nqS/kI29rEmLvw+cUXB6j1ySTpQ0U9LMRYvyznRhZmbdUc2rlU0lO2XIRABJI8nOp3RwRCwutkFE3EM67bWkT5Kd3BCyq8Zdl047NBg4RNLqiJhWZB+XAZdBNqZSzgMys+axatUq5s2bx5tv5l1xof7179+foUOH0tLS0uVtejVUJG0TEU+mu2OBx1L5MLJzPx1dMGZSbPv3R8TCdKK4M8jOvUREbFWwzlXAzcUCxcysXObNm8dGG23E8OHD6fw8mvUnIli8eDHz5s1jq6226nyDpJJTiq8lu3LdYEnzyFokhyi7KttasplcJ6XVzyYbiL8kvTir22YWSJoOnBARC4AJkg4l67b7UbrWR6+a9uB8Jv/2cRYsXcHmgwYw4cARjBvV2vmGZtZQ3nzzzYYNFABJbLLJJpQ6TFCxUImIzxcp/nHOuieQndK72LJDCm5PIF3Lo4PHPbbrtSzNtAfnc9aND7NiVTaUM3/pCs668WEAB4tZE2rUQGnTnePzL+pLMPm3j78dKG1WrFrD5N8+XqUamZnVFodKCRYsLX5ZibxyM7NK2nDDDq8KXRXVnP1VdzYfNID5RQJk80EDqlAbM6snzTIe65ZKCSYcOIIBLeu9o2xAy3pMOHBElWpkZvWgbTx2/tIVBOvGY6c9OL/TbUv13HPPMWbMGEaOHMkBBxzA888/D8ANN9zADjvswE477cQ+++wDwKOPPsquu+7KzjvvzMiRI3nyySc72nWXuKVSgrZvFd++dQ5/X/YWgwa0MOnT2zfktw0z67pv/vpR/rZgWe7yB59fyso17/xt9opVa/h/v5jNtX95vug2220+kImf2r7kupxyyikcc8wxHHPMMUyZMoVTTz2VadOmcc455/Db3/6W1tZWli5dCsCll17Kaaedxvjx41m5ciVr1qzpZO+dc0ulRONGtXL76fsC8G/7f8iBYmadah8onZX3xD333MNRRx0FwNFHH82f/vQnAD7+8Y9z7LHHcvnll78dHnvssQfnn38+F154IXPnzmXAgJ535bul0g0brt+XPoJlb66qdlXMrAZ01qL4+AV3FB2PbR00gOv/ZY9KVesdLr30Uu677z5uueUWPvrRj3L//fdz1FFHsdtuu3HLLbdwyCGH8L//+7+MGTOmR4/jlko39OkjNurfwqsrHCpm1rneHI/dc889ue666wCYOnUqe++9NwBPP/00u+22G+eccw5DhgzhhRde4JlnnmHrrbfm1FNPZezYscyePbvHj++WSjdtPMChYmZd09ZNXu7ZX2+88QZDh667Usjpp5/OxRdfzHHHHcfkyZMZMmQIV155JQATJkzgySefJCI44IAD2Gmnnbjwwgv5yU9+QktLC5tuuilf+9rXelQfaPJr1PfkIl2fuvhPDN5wfa48btcy18rM6sGcOXP4yEc+Uu1qVFyx46zKRboanVsqZmbv5lDppoED+jpUzMzacah0U9ZSWV3taphZFTX68EF3js+h0k0DB7R4SrFZE+vfvz+LFy9u2GBpu55K//79S9rOs7+6YdqD87n2vudZuXote3779/y/g7b1jyDNmszQoUOZN29eydcbqSdtV34shUOlRO2vqbLg1Td9TRWzJtTS0lLSFRGbhbu/SuRrqpiZ5XOolMjXVDEzy+dQKVHetVN8TRUzM4dKyXxNFTOzfB6oL1HhOXzmL13Be9Zfj/MP29GD9GZmOFS6ZdyoVsaNamXsD/7EwAEtDhQzs8TdXz2w+aABHqA3MyvgUOmmaQ/OZ8aTi3h60et8/ILfV+Ra02Zm9cbdX93Q/geQ85f6B5BmZlDBloqkKZIWSnqkoOxcSbMlzZJ0m6TNU/n4VP6wpLsl7ZSzzzGSHpD0iKSrJfVN5WML9jtT0l6VOi7wDyDNzPJUsvvrKuCgdmWTI2JkROwM3AycncqfBfaNiB2Bc4HL2u9MUh/gauDIiNgBmAsckxb/Htgp7fdLwBVlPpZ38A8gzcyKq1ioRMQM4JV2ZcsK7m4ARCq/OyKWpPJ7gWJnMNsEWBkRT6T7twOHp+1fi3WnCn17v5XiH0CamRXX6wP1ks6T9AIwnnUtlULHA7cWKX8Z6Cup7RKWRwBbFOz3MEmPAbeQtVbyHv/E1EU2s7tnF/UPIM3Miuv1UImIr0fEFsBU4MuFyyTtTxYqZxTZLoAjge9J+guwHFhTsPxXEbEtMI6sCy3v8S+LiNERMXrIkCHdOoZxo1r59md2ZNCAlrfL+rd4Ip2ZWTU/CaeSuq8AJI0kGwsZGxGLi20QEfdExN4RsSswA3iiyDozgK0lDa5Mtdd5a/Xat28veWMVZ934sKcWm1lT69VQkbRNwd2xwGOpfBhwI3B0wZhJse3fn/7tR9aauTTd/5Akpdu7AP2AosFULp4BZmb2bhX7nYqka4H9gMGS5gETgUMkjQDWks3eOimtfjbZQPwlKRtWR8TotJ/pwAkRsQCYIOlQsjD8UUTckbY/HPiipFXACuBzBQP3FeEZYGZm76ZGvb5yV4wePTpmzpzZrW0/fsEdzC8SIK2DBvDnM8f0tGpmZjVL0v1tX/zb8+hyNxWbAQbwxsrVHlcxs6blUOmmYjPAwAP2ZtbcHCo9MG5UKxv0e/ewlAfszaxZOVR6yAP2ZmbrOFR6KO/ULBu36xYzM2sGDpUemnDgCFr66F3lr3vA3syakEOlh8aNamXD/u8eV1m1JjyuYmZNx6FSBkvfWFW03OMqZtZsHCpl4HEVM7OMQ6UMPK5iZpZxqJSBx1XMzDIOlTLJG1cpdn4wM7NG5VApk7xxFYG7wMysaThUymTCgSN496gKBLgLzMyahkOlTMaNaiXvIgLuAjOzZuFQKaNWd4GZWZNzqJRRR11gk256tLerY2bW6xwqZdRRF9jSFavcWjGzhudQKbO8LjBwa8XMGp9DpcwmHDgid5lbK2bW6BwqZTZuVCvvfU/+Ob/cWjGzRuZQqYCJn9o+d5lbK2bWyBwqFeDWipk1K4dKhbi1YmbNyKFSIW6tmFkzqlioSJoiaaGkRwrKzpU0W9IsSbdJ2jyVj0/lD0u6W9JOOfscI+kBSY9IulpS31K2721urZhZs6lkS+Uq4KB2ZZMjYmRE7AzcDJydyp8F9o2IHYFzgcva70xSH+Bq4MiI2AGYCxzT1e2rwa0VM2s2FQuViJgBvNKubFnB3Q3IzmBCRNwdEUtS+b3A0CK73ARYGRFPpPu3A4eXsH1VdNZa+ca0h3uxNmZmldXrYyqSzpP0AjCedS2VQscDtxYpfxnoK2l0un8EsEUJ27c9/omSZkqauWjRotIq3w2dtVam3vu8u8HMrGH0eqhExNcjYgtgKvDlwmWS9icLhTOKbBfAkcD3JP0FWA6s6er2Bfu5LCJGR8ToIUOG9PRwuqSj1opPNmlmjaSas7+mkrqvACSNBK4AxkbE4mIbRMQ9EbF3ROwKzACeKGX7aumsteJuMDNrFL0aKpK2Kbg7FngslQ8DbgSOLhgzKbb9+9O//chaI5eWsn01TfzU9kVPi9/G3WBm1ggqOaX4WuAeYISkeZKOBy5I04FnA58ETkurn002EH9Jmm48s2A/09umHgMTJM0BZgO/jog7Otu+Vowb1cr43YflLnc3mJk1AmVDFc1p9OjRMXNm7+bPqHNuY8kbq3KXf2H3YXxr3I69WCMzs9JIuj8iRhdb5l/U97LOusF+eu/zHl8xs7rlUOllnXWDgYPFzOqXQ6UKvjVuxw5ng4EH7s2sPjlUqqSzbjAP3JtZPXKoVElXusH8+xUzqzcOlSr61rgd+YLHV8ysgThUqszBYmaNxKFSA7oycO9gMbN64FCpEZ0N3IODxcxqn0OlRnRl4B4cLGZW2xwqNaQr4yvgYDGz2uVQqTEOFjOrZw6VGuRgMbN65VCpUQ4WM6tHDpUa5mAxs3rjUKlxDhYzqycOlTpQSrBsf/ZvfHZjM6sah0qd6GqwvL5yDV+5fpZbLWZWFQ6VOtLVYAF3h5lZdThU6oyDxcxqmUOlDjlYzKxWOVTqVKnB4gF8M+sNDpU69q1xO/L9z+3MgJbOX0YP4JtZb3Co1Llxo1qZc+7B7g4zs5rQpVCR9EFJ/dLt/SSdKmlQZatmpXB3mJnVgq62VH4JrJH0IeAyYAvgZx1tIGmKpIWSHikoO1fSbEmzJN0mafNUPj6VPyzpbkk75exzjKQHJD0i6WpJfVP5tpLukfSWpK928ZgaTinB4u4wM6uErobK2ohYDRwGXBwRE4DNOtnmKuCgdmWTI2JkROwM3AycncqfBfaNiB2Bc8mC6x0k9QGuBo6MiB2AucAxafErwKnAd7t4PA2rlGABd4eZWXl1NVRWSfo82Yf4zamsw4uqR8QMsg/7wrJlBXc3ACKV3x0RS1L5vcDQIrvcBFgZEU+k+7cDh6ftF0bEX4FVXTyehlbKAD64O8zMyqeroXIcsAdwXkQ8K2kr4CfdeUBJ50l6ARjPupZKoeOBW4uUvwz0lTQ63T+CrBuu1Mc/UdJMSTMXLVpU6uZ1o9QB/LbusFHn3OZwMbNuU0SUtoH0XmCLiJjdhXWHAzen7qr2y84C+kfExIKy/YFLgL0iYnGRbfYAvgP0A24DDk1daW3LJwGvRUSXusFGjx4dM2fO7Mqqde0b0x7mp/c+X9I2G6y/HucdtiPjRrVWqFZmVq8k3R8Ro4st6+rsrz9IGijpfcADwOWS/ruH9ZpK6r5KjzESuAIYWyxQACLinojYOyJ2BWYATxRbz96p1O4w8EC+mXVPVz9lNk7jIZ8BromI3YBPlPpgkrYpuDsWeCyVDwNuBI4uGDMptv3707/9gDOAS0utQ7MqtTusjcdbzKwUXQ2VvpI2Az7LuoH6Dkm6FrgHGCFpnqTjgQvSdODZwCeB09LqZ5MNxF+SphvPLNjP9Lapx8AESXOA2cCvI+KOtM6mkuYBpwPfSI83sIvH1lRKnR0GbrWYWdd1aUxF0j8B/wn8OSJOlrQ12fTgwzvZtKY1y5hKMdMenM+kmx5l6YrSJsx5rMXMOhpTKXmgvpE0c6gU6s5A/hd2H8a3xu1YoRqZWS0rx0D9UEm/Sr+QXyjpl5KK/ZbE6lB3BvI91mJmxXT1U+RK4CZg8/T361RmDaI7A/ltYy0OFzNr09VQGRIRV0bE6vR3FTCkgvWyKvH0YzPria5+ciyW9AVJ66W/LwBFf0ti9c/Tj82su7oaKl8im078EvAi2SlSjq1QnaxGuNViZqXq0qdFRMyNiE9HxJCIeH9EjKPg1/DWuNxqMbNS9OTKj6eXrRZW83rSanG4mDWPnoSKylYLqwttrRaHi5nl6UmoNO+vJptcd7vEPN5i1vg6DBVJyyUtK/K3nOz3KtbEutMlBh5vMWtkPk2LT9NSFt051Qv4XGJm9ajHp2kx60x3Wy0ebzFrLG6puKVSdtMenM9ZN85mxaq1JW/rlotZ7XNLxXpVd2eJgQfzzeqdQ8UqpruzxMCD+Wb1yqFiFefxFrPm4TEVj6n0Ko+3mNU/X/kxh0OlehwuZvXLoZLDoVJ9Dhez+uPZX1azejKY7zEXs9rjlopbKjWjJ62WNq2DBjDhwBFuvZhVkLu/cjhUalM5wsVdY2aV41DJ4VCpbQ4Xs9pUlTEVSVMkLZT0SEHZuZJmS5ol6TZJm6fy8an8YUl3S9opZ59jJD0g6RFJV0vqm8ol6SJJT6X97FKp47Le05Nf5rfxuItZ76rkQP1VwEHtyiZHxMiI2Bm4GTg7lT8L7BsROwLnApe135mkPsDVwJERsQMwFzgmLT4Y2Cb9nQj8qLyHYtXkcDGrHxULlYiYAbzSrmxZwd0NSBf6ioi7I2JJKr8XGFpkl5sAKyPiiXT/duDwdHsscE1k7gUGSdqsPEditcLhYlb7en1KsaTzJL0AjGddS6XQ8cCtRcpfBvpKauvHOwLYIt1uBV4oWHdeKiv2+CdKmilp5qJFi7pzCFZlheHSOmhAt/bhcDGrjIoO1EsaDtycuqvaLzsL6B8REwvK9gcuAfaKiMVFttkD+A7QD7gNODQidpZ0M3BBRPwprfd74IyI6HAU3gP1jaMcg/rvfU8LEz+1vQf1zTpRqz9+nMq67iskjQSuAMYWCxSAiLgnIvaOiF2BGUBbV9h81rVaIOs+89fPJlKOrrElb6xy68Wsh3o1VCRtU3B3LPBYKh8G3AgcXTBmUmz796d/+wFnAJemRTcBX0yzwHYHXo2IFytwCFbjPO5iVl0V6/6SdC2wHzAY+DswETgEGAGsJZu9dVJEzJd0BVmrZW7afHVb00rSdOCEiFggaTJwKFkY/igivp/WEfADstlmbwDHddb1Be7+agb+rYtZ+fnHjzkcKs3D4WJWPg6VHA6V5lOOcAEP6ltzc6jkcKg0r2kPzmfSTY+ydMWqHu3HrRdrRg6VHA4VA3eNmZXKoZLDoWKF3DVm1jUOlRwOFSumXOHi1os1KodKDoeKdcThYlacQyWHQ8W6olyD+uCuMWsMDpUcDhUrlVsvZg6VXA4V6y6HizUzh0oOh4r1VLm6xkR2caHWQQOYcOAIh4zVNIdKDoeKlVO5Wi/gFozVNodKDoeKVUI5wwU8uG+1x6GSw6FilVTOWWPg1ovVDodKDoeK9Ra3XqyROFRyOFSst5U7XNx6sWpwqORwqFi1lLtrDNx6sd7jUMnhULFa4ZljVk8cKjkcKlZryt2CcevFKsGhksOhYrXMg/tWqxwqORwqVg88NdlqjUMlh0PF6o1bL1YLHCo5HCpWrzx7zKrJoZLDoWKNwL99sd7mUMnhULFG4taL9RaHSg6HijUqB4xVUlVCRdIU4FBgYUTskMrOBcYCa4GFwLERsUDSeOAMsstKLAdOjoiHiuzzAGAy0Ad4LW3/lKQtgSnAEOAV4AsRMa+zOjpUrBmUu3sMHDDNrlqhsg/ZB/81BaEyMCKWpdunAttFxEmS9gTmRMQSSQcDkyJityL7fAIYGxFzJP0rsGtEHCvpBuDmiLha0hjguIg4urM6OlSsmVSi9eLxl+bUUaj0rdSDRsQMScPblS0ruLsB2cXuiIi7C8rvBYbm7RYYmG5vDCxIt7cDTk+37wSmdbfeZo1q3KjWtz/8yxUwr69cw1eun8W/Xz/LV640oMJjKilUbm5rqaSy84AvAq8C+0fEonbbfBXYNiJOKLK/vckCYwWwDNg9IpZJ+hlwX0T8j6TPAL8EBkfE4iL7OBE4EWDYsGEfnTt3blmO1axeVaJ7DNxF1siqNlBfLFQKlp0F9I+IiQVl+wOXAHvlBMKNwIURcZ+kCcCIiDhB0ubAD4CtgBnA4cAOEbG0o/q5+8tsnUp0j7VxwDSWWg2VYcD0gvGWkcCvgIMj4oki6w8B7o2IDxZs/5uI2K7dehsCj0VEXhfa2xwqZsU5YKwjVRlTyanINhHxZLo7FngslQ8DbgSOLhYoyRJgY0kfTuv8AzAnbT8YeCUi1gJnkc0EM5m0koMAAApiSURBVLNuqsT4S5slb6ziK9fP4ivXz3LANKBKzv66FtgPGAz8HZgIHAKMIJtSPBc4KSLmS7qCrMuqbYBjdVsKSpoOnJCmHh8GnJO2XwJ8KSKekXQE8G2ygfwZwL9FxFud1dEtFbPSVGr8xbPI6ot//JjDoWLWPe4ea24OlRwOFbPyqFTIOGBqk0Mlh0PFrPwcMI3PoZLDoWJWWQ6YxuRQyeFQMes9DpjG4VDJ4VAxqw7/ir++OVRyOFTMqsuzyOqTQyWHQ8Wsdjhg6odDJYdDxaw2OWBqm0Mlh0PFrPZVMmDAIdMdDpUcDhWz+lLpgAGHTFc4VHI4VMzqlwOmehwqORwqZo3BAdO7HCo5HCpmjccBU3kOlRwOFbPG5oCpDIdKDoeKWfPojYCB5ggZh0oOh4pZc/N05e5xqORwqJhZGwdM1zlUcjhUzKwYj8V0zKGSw6FiZp1xwLybQyWHQ8XMSuGAyThUcjhUzKy7mjlgHCo5HCpmVi7NFDIOlRwOFTOrhEYPGIdKDoeKmVVab/3oEnovaBwqORwqZtbbGuGX/VULFUlTgEOBhRGxQyo7FxgLrAUWAsdGxAJJ44EzAAHLgZMj4qEi+zwAmAz0AV5L2z8laRhwNTAIWA84MyKmd1Q/h4qZVVO9tmKqGSr7kH3wX1MQKgMjYlm6fSqwXUScJGlPYE5ELJF0MDApInYrss8ngLERMUfSvwK7RsSxki4DHoyIH0naDpgeEcM7qp9DxcxqRT0FTEeh0qdHNetERMwAXmlXtqzg7gZApPK7I2JJKr8XGJq3W2Bgur0xsKCTcjOzmjduVCuzJn6S5y74R77/uZ0ZNKClYo+15I1VfOX6WWx/9m+Y9uD8su67b1n31kWSzgO+CLwK7F9kleOBW3M2PwGYLmkFsAzYPZVPAm6TdApZWH0i57FPBE4EGDZsWDePwMyscsaNan1HK6JSrZjXV65hwi8eevsxy6HiA/WShgM3t3V/tVt2FtA/IiYWlO0PXALsFRGLi2xzI3BhRNwnaQIwIiJOkHQ62fH8l6Q9gB8DO0TE2ry6ufvLzOpNJQKmddAA/nzmmC6v31H3V1VaKgWmAtOBiQCSRgJXAAfnBMoQYKeIuC8VXQ/8Jt0+HjgIICLukdQfGEw2GcDMrCG0b8VAz4NmwdIV5agaUOExlWIkbVNwdyzwWCofBtwIHB0RT+RsvgTYWNKH0/1/AOak288DB6R9fQToDywqb+3NzGpPT8djNh80oGx1qWhLRdK1wH7AYEnzyFokh0gaQTaleC5wUlr9bGAT4BJJAKvbmleSpgMnpKnH/wz8UtJaspD5Utr+P4DLJf072aD9sdHMP8Ixs6ZU6nhMy3piwoEjyvb4/vGjx1TMrEm0D5juTi2u5TEVMzPrJcXGY8qt18dUzMyscTlUzMysbBwqZmZWNg4VMzMrG4eKmZmVTVNPKZa0iOy3MqUaDLxc5upUSyMdCzTW8fhYapOPBbaMiCHFFjR1qHSXpJl5c7TrTSMdCzTW8fhYapOPpWPu/jIzs7JxqJiZWdk4VLrnsmpXoIwa6VigsY7Hx1KbfCwd8JiKmZmVjVsqZmZWNg4VMzMrG4dKiSQdJOlxSU9JOrPa9SmVpOckPSxplqSZqex9km6X9GT6973VrmcxkqZIWijpkYKyonVX5qL0Os2WtEv1av5uOccySdL89NrMknRIwbKz0rE8LunA6tS6OElbSLpT0t8kPSrptFRed69NB8dSd6+NpP6S/iLpoXQs30zlW0m6L9X5eknrp/J+6f5Tafnwbj1wRPivi3/AesDTwNbA+sBDwHbVrleJx/AcMLhd2XeAM9PtM4ELq13PnLrvA+wCPNJZ3YFDgFsBAbsD91W7/l04lknAV4usu116r/UDtkrvwfWqfQwF9dsM2CXd3gh4ItW57l6bDo6l7l6b9PxumG63APel5/vnwJGp/FLg5HT7X4FL0+0jgeu787huqZRmV+CpiHgmIlYC15FdErnejQWuTrevBsZVsS65ImIG8Eq74ry6jwWuicy9wCBJm/VOTTuXcyx5xgLXRcRbEfEs8BTZe7EmRMSLEfFAur2c7BLfrdTha9PBseSp2dcmPb+vpbst6S+AMcAvUnn716Xt9foFcIDSZXhL4VApTSvwQsH9eXT8hqtFAdwm6X5JJ6ayD0TEi+n2S8AHqlO1bsmre72+Vl9OXUJTCroh6+ZYUpfJKLJvxXX92rQ7FqjD10bSepJmAQuB28laUksjYnVapbC+bx9LWv4q2SXeS+JQaT57RcQuwMHAv0nap3BhZG3fupxnXs91T34EfBDYGXgR+K/qVqc0kjYEfgl8JSKWFS6rt9emyLHU5WsTEWsiYmdgKFkLattKP6ZDpTTzgS0K7g9NZXUjIuanfxcCvyJ7o/29rfsh/buwejUsWV7d6+61ioi/pw+BtcDlrOtGqfljkdRC9iE8NSJuTMV1+doUO5Z6fm0AImIpcCewB1l3Y9ul5Avr+/axpOUbA4tLfSyHSmn+CmyTZk+sTzaYdVOV69RlkjaQtFHbbeCTwCNkx3BMWu0Y4P+qU8Nuyav7TcAX00yj3YFXC7pialK7cYXDyF4byI7lyDQ7ZytgG+AvvV2/PKnf/cfAnIj474JFdffa5B1LPb42koZIGpRuDwD+gWyM6E7giLRa+9el7fU6ArgjtTBLU+0ZCvX2RzZz5QmyvsmvV7s+JdZ9a7KZKg8Bj7bVn6zf9PfAk8DvgPdVu6459b+WrOthFVlf8PF5dSeb+fLD9Do9DIyudv27cCw/SXWdnf6Db1aw/tfTsTwOHFzt+rc7lr3IurZmA7PS3yH1+Np0cCx199oAI4EHU50fAc5O5VuTBd9TwA1Av1TeP91/Ki3fujuP69O0mJlZ2bj7y8zMysahYmZmZeNQMTOzsnGomJlZ2ThUzMysbBwqZhUgaU3BGW1nqYxntJY0vPDsxma1pG/nq5hZN6yI7PQYZk3FLRWzXqTsejbfUXZNm79I+lAqHy7pjnTCwt9LGpbKPyDpV+maGA9J2jPtaj1Jl6frZNyWfjGNpFPTtUBmS7quSodpTcyhYlYZA9p1f32uYNmrEbEj8APg+6nsYuDqiBgJTAUuSuUXAXdFxE5k1195NJVvA/wwIrYHlgKHp/IzgVFpPydV6uDM8vgX9WYVIOm1iNiwSPlzwJiIeCaduPCliNhE0stkp/5YlcpfjIjBkhYBQyPirYJ9DAduj4ht0v0zgJaI+Jak3wCvAdOAabHuehpmvcItFbPeFzm3S/FWwe01rBsf/Uey82rtAvy14Gy0Zr3CoWLW+z5X8O896fbdZGe9BhgP/DHd/j1wMrx9waWN83YqqQ+wRUTcCZxBduryd7WWzCrJ32LMKmNAuuJem99ERNu04vdKmk3W2vh8KjsFuFLSBGARcFwqPw24TNLxZC2Sk8nOblzMesBPU/AIuCiy62iY9RqPqZj1ojSmMjoiXq52Xcwqwd1fZmZWNm6pmJlZ2bilYmZmZeNQMTOzsnGomJlZ2ThUzMysbBwqZmZWNv8fkHxq1IaESe8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot for MLPClassifier(activation='relu', alpha=0.0001, batch_size=100, beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='invscaling',\n",
      "              learning_rate_init=0.5, max_fun=15000, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.25,\n",
      "              random_state=None, shuffle=True, solver='sgd', tol=1e-06,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(clf)):\n",
    "    print(\"Plot for {} \".format(clf[i]))\n",
    "    fig = plt.figure(i)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(clf[i].loss_curve_, marker='o', label='Loss')\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Loss over Epochs with MLPClassifier\")\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    #plt.savefig(\"plots/parte/relu_e-8.png\", dpi=1000, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Accuracy with different MLP classifiers with\\n ReLU Activation\")\n",
    "x=np.arange(len(clf))\n",
    "ax.plot(x, train_accuracy, marker='o', label='Train Accuracy')\n",
    "ax.plot(x, test_accuracy, marker='o', label='Test Accuracy')\n",
    "ax.set_xlabel(\"Classifier Type\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.legend()\n",
    "\n",
    "ax1=ax.twinx()\n",
    "ax1.set_ylabel(\"Number of Epochs\")\n",
    "ax1.plot(x, epochs, marker='*', color='m',label='Epochs')\n",
    "ax1.tick_params(axis='y', labelcolor='m', labelsize=12)\n",
    "plt.legend(loc=4)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig(\"plots/parte/accuracy_mlp_relu_1.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "plt.title(\"Epochs/Time with MLP Classifier \\n ReLU Activation\")\n",
    "ax.plot(x, epochs, c='b', marker='o', label='#epochs')\n",
    "ax.set_xlabel(\"Classifier Type\")\n",
    "ax.set_ylabel(\"Epochs\")\n",
    "ax.legend()\n",
    "\n",
    "ax1 = fig.add_subplot(212)\n",
    "ax1.plot(x, train_time, c='b', marker='o', label='train time')\n",
    "ax1.set_xlabel(\"Classifier type\")\n",
    "ax1.set_ylabel(\"train time(sec)\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"plots/parte/epochs_time_relu.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

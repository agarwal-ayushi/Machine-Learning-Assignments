{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "The total number of training samples = 11050\n",
      "The total number of validation samples = 1950\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "np.random.shuffle(X_train.to_numpy())\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "\n",
    "X_valid = X_train.iloc[(int(0.85*m)):]\n",
    "valid_class = train_class[(int(0.85*m)):]\n",
    "X_train = X_train.iloc[0:int(0.85*m)]\n",
    "train_class = train_class[0:int(0.85*m)]\n",
    "\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The total number of validation samples = {}\".format(X_valid.shape[0]))\n",
    "\n",
    "\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "valid_class_enc = pd.get_dummies(valid_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_valid = np.hstack((np.ones((X_valid.shape[0],1)), X_valid.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "arch_test = [1,5,10,50,100]\n",
    "arch = [arch_test[3]] #means one hidden layer with 2 perceptrons \n",
    "batch_size = 100 # Mini-Batch Size\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mini-batches formed is = 111\n"
     ]
    }
   ],
   "source": [
    "#Mini-Batch formation\n",
    "mini_batch = [(X_train[i:i+batch_size,:], train_class_enc[i:i+batch_size]) for i in range(0, m, batch_size)]\n",
    "print(\"The number of mini-batches formed is = {}\".format(len(mini_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta Initialization \n",
    "#np.random.seed(1)\n",
    "def theta_init(arch=[50]):\n",
    "    theta = []\n",
    "    for i in range(len(arch)+1):\n",
    "        if i == 0:\n",
    "            dim0=n+1\n",
    "            dim1=arch[i]\n",
    "        elif (i == len(arch)):\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1 = r\n",
    "        else:\n",
    "            dim0=arch[i-1]+1\n",
    "            dim1= arch[i]\n",
    "        theta.append(np.random.uniform(-0.07,0.07, (dim0,dim1)))\n",
    "        #theta[i] = np.vstack((np.zeros((1,dim1)),theta[i]))\n",
    "\n",
    "        #theta.append(0.01*(2*np.random.random((dim0, dim1))-1))\n",
    "        #theta.append(np.zeros((dim0, dim1)))\n",
    "        #theta.append(0.01*np.random.standard_normal((dim0, dim1)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_act(x):\n",
    "    return np.maximum(0.0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_relu(x):\n",
    "    #x[x<=0] = -0.01\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu_act(x):\n",
    "    np.where(x > 0, x, x * 0.1) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_leakyRelu(x):\n",
    "    x[x<=0] = 0.1\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_softplus(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, theta):\n",
    "    fm = []\n",
    "    fm.append(data)\n",
    "    for l in range(len(theta)):\n",
    "        if (l != len(theta)-1):\n",
    "            #print(\"relu\")\n",
    "            fm.append(relu_act(np.dot(fm[l], theta[l])))\n",
    "            fm[l+1]=np.hstack((np.ones((fm[l+1].shape[0],1)),fm[l+1]))\n",
    "        else:\n",
    "            fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "            #print(\"sigmoid output\")\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 26)\n"
     ]
    }
   ],
   "source": [
    "theta = theta_init([100, 100])\n",
    "print(theta[2].shape)\n",
    "fm = forward_prop(X_train, theta)\n",
    "cost_total(X_train, theta, train_class_enc, m)\n",
    "len(fm)-1\n",
    "for l in range(len(fm)-1, 0, -1):\n",
    "    #print(l)\n",
    "    a = (l==len(fm)-1)*1 + (l!= len(fm)-1)*2\n",
    "    #print(a)\n",
    "#cross_entropy_loss(X_train, theta, train_class_enc, m)\n",
    "#fm = forward_prop(X_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_total(X, theta, Y, m):\n",
    "    fm = forward_prop(X, theta)\n",
    "    cost = (1/(2*m))*np.sum((Y-fm[-1])**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(X, theta, Y, m):\n",
    "    fm = forward_prop(X, theta)\n",
    "    cost = -(1/m)*(np.sum(((Y*np.log(fm[-1]))+((1-Y)*(np.log(1-fm[-1]))))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, theta, actual_class):\n",
    "    pred_class = forward_prop(data, theta)\n",
    "    test_pred_class = pred_class[-1]\n",
    "    for i in range(len(test_pred_class)):\n",
    "        test_pred_class[i][test_pred_class[i] == np.max(test_pred_class[i])] = 1\n",
    "        test_pred_class[i][test_pred_class[i] != np.max(test_pred_class[i])] = 0\n",
    "\n",
    "\n",
    "    test_acc = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if (np.array_equal(test_pred_class[i], actual_class[i])):\n",
    "            test_acc+=1\n",
    "    test_acc /= data.shape[0]\n",
    "\n",
    "    #print(\"The Test Accuracy of the model = {}%\".format(test_acc*100))\n",
    "    return (test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "valid_accuracy =[]\n",
    "test_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(theta[0].shape, theta[1].shape, theta[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate =  0.6\n",
      "Initial Cost on dataset for this epoch 1 = 3.267907000423468\n",
      "Error on this batch = 3.272362999771186\n",
      "Error on this batch = 0.4999481390477945\n",
      "Cost on val dataset after 2 epochs is = 0.49990819731675784\n",
      "learning rate =  0.5045378491522288\n",
      "Initial Cost on dataset for this epoch 2 = 0.49990819731675784\n",
      "Error on this batch = 0.4998097869290041\n",
      "Error on this batch = 0.4999347325178544\n",
      "Cost on val dataset after 3 epochs is = 0.49988874902785857\n",
      "learning rate =  0.4559014113909555\n",
      "Initial Cost on dataset for this epoch 3 = 0.49988874902785857\n",
      "Error on this batch = 0.499775290743025\n",
      "Error on this batch = 0.49991678470720025\n",
      "Cost on val dataset after 4 epochs is = 0.4998627940213585\n",
      "learning rate =  0.42426406871192845\n",
      "Initial Cost on dataset for this epoch 4 = 0.4998627940213585\n",
      "Error on this batch = 0.4997301184712474\n",
      "Error on this batch = 0.4998905689987869\n",
      "Cost on val dataset after 5 epochs is = 0.4998253574941768\n",
      "learning rate =  0.40124418298585324\n",
      "Initial Cost on dataset for this epoch 5 = 0.4998253574941768\n",
      "Error on this batch = 0.4996662835179747\n",
      "Error on this batch = 0.49984861912641054\n",
      "Cost on val dataset after 6 epochs is = 0.4997660470063602\n",
      "learning rate =  0.38336586254776345\n",
      "Initial Cost on dataset for this epoch 6 = 0.4997660470063602\n",
      "Error on this batch = 0.4995668834996995\n",
      "Error on this batch = 0.4997724536660212\n",
      "Cost on val dataset after 7 epochs is = 0.49965796238211957\n",
      "learning rate =  0.3688728917707586\n",
      "Initial Cost on dataset for this epoch 7 = 0.49965796238211957\n",
      "Error on this batch = 0.4993883823099422\n",
      "Error on this batch = 0.4996023074309268\n",
      "Cost on val dataset after 8 epochs is = 0.4994041222671201\n",
      "learning rate =  0.35676213450081634\n",
      "Initial Cost on dataset for this epoch 8 = 0.4994041222671201\n",
      "Error on this batch = 0.4989722045909727\n",
      "Error on this batch = 0.499024233512731\n",
      "Cost on val dataset after 9 epochs is = 0.49833417039258177\n",
      "learning rate =  0.34641016151377546\n",
      "Initial Cost on dataset for this epoch 9 = 0.49833417039258177\n",
      "Error on this batch = 0.4971756659734753\n",
      "Error on this batch = 0.4941325677325719\n",
      "Cost on val dataset after 10 epochs is = 0.49306847281571\n",
      "learning rate =  0.33740479511420945\n",
      "Initial Cost on dataset for this epoch 10 = 0.49306847281571\n",
      "Error on this batch = 0.48947995437946346\n",
      "Error on this batch = 0.48640657011537236\n",
      "Cost on val dataset after 11 epochs is = 0.4882538109036643\n",
      "learning rate =  0.32946029206566746\n",
      "Initial Cost on dataset for this epoch 11 = 0.4882538109036643\n",
      "Error on this batch = 0.48719653019981857\n",
      "Error on this batch = 0.4834864501960263\n",
      "Cost on val dataset after 12 epochs is = 0.4852302875923006\n",
      "learning rate =  0.32237097954706256\n",
      "Initial Cost on dataset for this epoch 12 = 0.4852302875923006\n",
      "Error on this batch = 0.48418219676740876\n",
      "Error on this batch = 0.48132930819495345\n",
      "Cost on val dataset after 13 epochs is = 0.4825827067305735\n",
      "learning rate =  0.315984232708756\n",
      "Initial Cost on dataset for this epoch 13 = 0.4825827067305735\n",
      "Error on this batch = 0.48093110119936056\n",
      "Error on this batch = 0.47885687288236356\n",
      "Cost on val dataset after 14 epochs is = 0.48014897130391687\n",
      "learning rate =  0.31018389237430233\n",
      "Initial Cost on dataset for this epoch 14 = 0.48014897130391687\n",
      "Error on this batch = 0.4769857212550421\n",
      "Error on this batch = 0.4750186191932116\n",
      "Cost on val dataset after 15 epochs is = 0.4761223472107217\n",
      "learning rate =  0.30487964889276886\n",
      "Initial Cost on dataset for this epoch 15 = 0.4761223472107217\n",
      "Error on this batch = 0.4695638245271935\n",
      "Error on this batch = 0.46793398143091014\n",
      "Cost on val dataset after 16 epochs is = 0.46975703202418106\n",
      "learning rate =  0.3\n",
      "Initial Cost on dataset for this epoch 16 = 0.46975703202418106\n",
      "Error on this batch = 0.45830339295404343\n",
      "Error on this batch = 0.46197745236160426\n",
      "Cost on val dataset after 17 epochs is = 0.46493342383089403\n",
      "learning rate =  0.2954874363032714\n",
      "Initial Cost on dataset for this epoch 17 = 0.46493342383089403\n",
      "Error on this batch = 0.4517776653987888\n",
      "Error on this batch = 0.4563133137234209\n",
      "Cost on val dataset after 18 epochs is = 0.4593955607956916\n",
      "learning rate =  0.29129506302439406\n",
      "Initial Cost on dataset for this epoch 18 = 0.4593955607956916\n",
      "Error on this batch = 0.4460031127053543\n",
      "Error on this batch = 0.4473249387962006\n",
      "Cost on val dataset after 19 epochs is = 0.44979964084423407\n",
      "learning rate =  0.2873841752661448\n",
      "Initial Cost on dataset for this epoch 19 = 0.44979964084423407\n",
      "Error on this batch = 0.43680975219397133\n",
      "Error on this batch = 0.4314789627269988\n",
      "Cost on val dataset after 20 epochs is = 0.43407979227429844\n",
      "learning rate =  0.28372248270095274\n",
      "Initial Cost on dataset for this epoch 20 = 0.43407979227429844\n",
      "Error on this batch = 0.4221306765859492\n",
      "Error on this batch = 0.4114832184689798\n",
      "Cost on val dataset after 21 epochs is = 0.41423193733463304\n",
      "learning rate =  0.28028278663692\n",
      "Initial Cost on dataset for this epoch 21 = 0.41423193733463304\n",
      "Error on this batch = 0.4043100765018129\n",
      "Error on this batch = 0.3869250613692563\n",
      "Cost on val dataset after 22 epochs is = 0.3910518885320362\n",
      "learning rate =  0.27704197856646157\n",
      "Initial Cost on dataset for this epoch 22 = 0.3910518885320362\n",
      "Error on this batch = 0.3807593602080773\n",
      "Error on this batch = 0.36039150852269897\n",
      "Cost on val dataset after 23 epochs is = 0.368986355190564\n",
      "learning rate =  0.27398027129803876\n",
      "Initial Cost on dataset for this epoch 23 = 0.368986355190564\n",
      "Error on this batch = 0.3568158154203546\n",
      "Error on this batch = 0.3384275288002614\n",
      "Cost on val dataset after 24 epochs is = 0.3497348005320668\n",
      "learning rate =  0.27108060108295345\n",
      "Initial Cost on dataset for this epoch 24 = 0.3497348005320668\n",
      "Error on this batch = 0.33540905626076906\n",
      "Error on this batch = 0.3211133311612504\n",
      "Cost on val dataset after 25 epochs is = 0.3320896135401413\n",
      "learning rate =  0.2683281572999747\n",
      "Initial Cost on dataset for this epoch 25 = 0.3320896135401413\n",
      "Error on this batch = 0.3140981683009018\n",
      "Error on this batch = 0.30605339571633045\n",
      "Cost on val dataset after 26 epochs is = 0.3168493573693547\n",
      "learning rate =  0.2657100085614884\n",
      "Initial Cost on dataset for this epoch 26 = 0.3168493573693547\n",
      "Error on this batch = 0.29603184043247216\n",
      "Error on this batch = 0.29275657482514855\n",
      "Cost on val dataset after 27 epochs is = 0.3027979550498337\n",
      "learning rate =  0.2632148025904985\n",
      "Initial Cost on dataset for this epoch 27 = 0.3027979550498337\n",
      "Error on this batch = 0.2807641349751576\n",
      "Error on this batch = 0.28114490579785556\n",
      "Cost on val dataset after 28 epochs is = 0.2903652812687772\n",
      "learning rate =  0.26083252316699485\n",
      "Initial Cost on dataset for this epoch 28 = 0.2903652812687772\n",
      "Error on this batch = 0.2677291242492926\n",
      "Error on this batch = 0.27032728140160805\n",
      "Cost on val dataset after 29 epochs is = 0.2796073230094183\n",
      "learning rate =  0.2585542916753436\n",
      "Initial Cost on dataset for this epoch 29 = 0.2796073230094183\n",
      "Error on this batch = 0.25627844202127015\n",
      "Error on this batch = 0.26111934900717143\n",
      "Cost on val dataset after 30 epochs is = 0.2701453189768345\n",
      "learning rate =  0.2563722038377404\n",
      "Initial Cost on dataset for this epoch 30 = 0.2701453189768345\n",
      "Error on this batch = 0.2461274372054934\n",
      "Error on this batch = 0.25290646626139934\n",
      "Cost on val dataset after 31 epochs is = 0.2617017532770513\n",
      "learning rate =  0.254279194449013\n",
      "Initial Cost on dataset for this epoch 31 = 0.2617017532770513\n",
      "Error on this batch = 0.2370788688409156\n",
      "Error on this batch = 0.24530441932418626\n",
      "Cost on val dataset after 32 epochs is = 0.254148727921108\n",
      "learning rate =  0.2522689245761144\n",
      "Initial Cost on dataset for this epoch 32 = 0.254148727921108\n",
      "Error on this batch = 0.22880825664721727\n",
      "Error on this batch = 0.23842447357249885\n",
      "Cost on val dataset after 33 epochs is = 0.2473929513737722\n",
      "learning rate =  0.2503356869166904\n",
      "Initial Cost on dataset for this epoch 33 = 0.2473929513737722\n",
      "Error on this batch = 0.22124005871374672\n",
      "Error on this batch = 0.2320944258576041\n",
      "Cost on val dataset after 34 epochs is = 0.24130709547440515\n",
      "learning rate =  0.2484743259399312\n",
      "Initial Cost on dataset for this epoch 34 = 0.24130709547440515\n",
      "Error on this batch = 0.21405211817430228\n",
      "Error on this batch = 0.22628160682993156\n",
      "Cost on val dataset after 35 epochs is = 0.23574096299950842\n",
      "learning rate =  0.2466801701403118\n",
      "Initial Cost on dataset for this epoch 35 = 0.23574096299950842\n",
      "Error on this batch = 0.2073496792626495\n",
      "Error on this batch = 0.22088085951461356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 36 epochs is = 0.23068647984115795\n",
      "learning rate =  0.24494897427831783\n",
      "Initial Cost on dataset for this epoch 36 = 0.23068647984115795\n",
      "Error on this batch = 0.2012381992113918\n",
      "Error on this batch = 0.21600055140683466\n",
      "Cost on val dataset after 37 epochs is = 0.22604956019588743\n",
      "learning rate =  0.2432768699032619\n",
      "Initial Cost on dataset for this epoch 37 = 0.22604956019588743\n",
      "Error on this batch = 0.19576639819812364\n",
      "Error on this batch = 0.2114832192918935\n",
      "Cost on val dataset after 38 epochs is = 0.2218395350914849\n",
      "learning rate =  0.24166032278194638\n",
      "Initial Cost on dataset for this epoch 38 = 0.2218395350914849\n",
      "Error on this batch = 0.1907341049786173\n",
      "Error on this batch = 0.2072344837850791\n",
      "Cost on val dataset after 39 epochs is = 0.21794716224474112\n",
      "learning rate =  0.24009609611534996\n",
      "Initial Cost on dataset for this epoch 39 = 0.21794716224474112\n",
      "Error on this batch = 0.18607359515016333\n",
      "Error on this batch = 0.2032962838215315\n",
      "Cost on val dataset after 40 epochs is = 0.2144381573715065\n",
      "learning rate =  0.23858121863011517\n",
      "Initial Cost on dataset for this epoch 40 = 0.2144381573715065\n",
      "Error on this batch = 0.18184402229324861\n",
      "Error on this batch = 0.1994216743838137\n",
      "Cost on val dataset after 41 epochs is = 0.21116885184211456\n",
      "learning rate =  0.23711295679464287\n",
      "Initial Cost on dataset for this epoch 41 = 0.21116885184211456\n",
      "Error on this batch = 0.17805150940211945\n",
      "Error on this batch = 0.19554639327689866\n",
      "Cost on val dataset after 42 epochs is = 0.20813263032004642\n",
      "learning rate =  0.2356887905403078\n",
      "Initial Cost on dataset for this epoch 42 = 0.20813263032004642\n",
      "Error on this batch = 0.1745349300896206\n",
      "Error on this batch = 0.19178245176939981\n",
      "Cost on val dataset after 43 epochs is = 0.20529323148236234\n",
      "learning rate =  0.23430639197370967\n",
      "Initial Cost on dataset for this epoch 43 = 0.20529323148236234\n",
      "Error on this batch = 0.17132504584501576\n",
      "Error on this batch = 0.18788711425167248\n",
      "Cost on val dataset after 44 epochs is = 0.20261150441701847\n",
      "learning rate =  0.23296360665133395\n",
      "Initial Cost on dataset for this epoch 44 = 0.20261150441701847\n",
      "Error on this batch = 0.16818760308456882\n",
      "Error on this batch = 0.18435144903532052\n",
      "Cost on val dataset after 45 epochs is = 0.20008375731918673\n",
      "learning rate =  0.23165843705765382\n",
      "Initial Cost on dataset for this epoch 45 = 0.20008375731918673\n",
      "Error on this batch = 0.16527442285012342\n",
      "Error on this batch = 0.1809061762060581\n",
      "Cost on val dataset after 46 epochs is = 0.19761439562845065\n",
      "learning rate =  0.23038902798476096\n",
      "Initial Cost on dataset for this epoch 46 = 0.19761439562845065\n",
      "Error on this batch = 0.16258611033753514\n",
      "Error on this batch = 0.17758594122192028\n",
      "Cost on val dataset after 47 epochs is = 0.19529105764915547\n",
      "learning rate =  0.229153653558572\n",
      "Initial Cost on dataset for this epoch 47 = 0.19529105764915547\n",
      "Error on this batch = 0.1600463709836044\n",
      "Error on this batch = 0.17471335782148942\n",
      "Cost on val dataset after 48 epochs is = 0.19305862366393722\n",
      "learning rate =  0.22795070569547776\n",
      "Initial Cost on dataset for this epoch 48 = 0.19305862366393722\n",
      "Error on this batch = 0.15770273111245778\n",
      "Error on this batch = 0.17201418888252157\n",
      "Cost on val dataset after 49 epochs is = 0.1909513538132524\n",
      "learning rate =  0.2267786838055363\n",
      "Initial Cost on dataset for this epoch 49 = 0.1909513538132524\n",
      "Error on this batch = 0.15558289621169055\n",
      "Error on this batch = 0.1695738274885435\n",
      "Cost on val dataset after 50 epochs is = 0.18893958007658593\n",
      "learning rate =  0.2256361855851836\n",
      "Initial Cost on dataset for this epoch 50 = 0.18893958007658593\n",
      "Error on this batch = 0.15361180692728751\n",
      "Error on this batch = 0.16731386487402028\n",
      "Cost on val dataset after 51 epochs is = 0.187027275940572\n",
      "learning rate =  0.22452189876492748\n",
      "Initial Cost on dataset for this epoch 51 = 0.187027275940572\n",
      "Error on this batch = 0.15169724781341734\n",
      "Error on this batch = 0.16524820284266725\n",
      "Cost on val dataset after 52 epochs is = 0.1851592214217243\n",
      "learning rate =  0.22343459369638943\n",
      "Initial Cost on dataset for this epoch 52 = 0.1851592214217243\n",
      "Error on this batch = 0.14991533715468547\n",
      "Error on this batch = 0.1631916742464615\n",
      "Cost on val dataset after 53 epochs is = 0.18340790697890721\n",
      "learning rate =  0.2223731166789908\n",
      "Initial Cost on dataset for this epoch 53 = 0.18340790697890721\n",
      "Error on this batch = 0.14832072854930708\n",
      "Error on this batch = 0.16130620810294347\n",
      "Cost on val dataset after 54 epochs is = 0.18176705929239195\n",
      "learning rate =  0.22133638394006433\n",
      "Initial Cost on dataset for this epoch 54 = 0.18176705929239195\n",
      "Error on this batch = 0.14680599590161345\n",
      "Error on this batch = 0.15948166421666746\n",
      "Cost on val dataset after 55 epochs is = 0.18018175112227017\n",
      "learning rate =  0.2203233761936155\n",
      "Initial Cost on dataset for this epoch 55 = 0.18018175112227017\n",
      "Error on this batch = 0.1453354359890678\n",
      "Error on this batch = 0.15793722510437153\n",
      "Cost on val dataset after 56 epochs is = 0.17870065392570122\n",
      "learning rate =  0.21933313371270743\n",
      "Initial Cost on dataset for this epoch 56 = 0.17870065392570122\n",
      "Error on this batch = 0.14399050036576833\n",
      "Error on this batch = 0.1564287279061571\n",
      "Cost on val dataset after 57 epochs is = 0.17728189393819008\n",
      "learning rate =  0.21836475185876858\n",
      "Initial Cost on dataset for this epoch 57 = 0.17728189393819008\n",
      "Error on this batch = 0.14262826219348865\n",
      "Error on this batch = 0.15508797123918977\n",
      "Cost on val dataset after 58 epochs is = 0.17595055129437603\n",
      "learning rate =  0.21741737701825978\n",
      "Initial Cost on dataset for this epoch 58 = 0.17595055129437603\n",
      "Error on this batch = 0.1413880531214933\n",
      "Error on this batch = 0.15379623730417297\n",
      "Cost on val dataset after 59 epochs is = 0.17467694572014897\n",
      "learning rate =  0.2164902029032644\n",
      "Initial Cost on dataset for this epoch 59 = 0.17467694572014897\n",
      "Error on this batch = 0.14020294978962905\n",
      "Error on this batch = 0.15252716056054463\n",
      "Cost on val dataset after 60 epochs is = 0.17349714866263072\n",
      "learning rate =  0.21558246717785054\n",
      "Initial Cost on dataset for this epoch 60 = 0.17349714866263072\n",
      "Error on this batch = 0.13911289956695863\n",
      "Error on this batch = 0.1514478149732206\n",
      "Cost on val dataset after 61 epochs is = 0.17240883785149094\n",
      "learning rate =  0.2146934483766157\n",
      "Initial Cost on dataset for this epoch 61 = 0.17240883785149094\n",
      "Error on this batch = 0.1381094555991731\n",
      "Error on this batch = 0.15034981582726717\n",
      "Cost on val dataset after 62 epochs is = 0.1713827824136183\n",
      "learning rate =  0.21382246308577726\n",
      "Initial Cost on dataset for this epoch 62 = 0.1713827824136183\n",
      "Error on this batch = 0.13718424699657103\n",
      "Error on this batch = 0.14926111253049898\n",
      "Cost on val dataset after 63 epochs is = 0.17042186326320694\n",
      "learning rate =  0.21296886336060317\n",
      "Initial Cost on dataset for this epoch 63 = 0.17042186326320694\n",
      "Error on this batch = 0.13637169617567282\n",
      "Error on this batch = 0.1483359403716832\n",
      "Cost on val dataset after 64 epochs is = 0.16951811524234908\n",
      "learning rate =  0.21213203435596423\n",
      "Initial Cost on dataset for this epoch 64 = 0.16951811524234908\n",
      "Error on this batch = 0.13560553884718526\n",
      "Error on this batch = 0.14736308897956474\n",
      "Cost on val dataset after 65 epochs is = 0.16866315870611462\n",
      "learning rate =  0.21131139214939415\n",
      "Initial Cost on dataset for this epoch 65 = 0.16866315870611462\n",
      "Error on this batch = 0.13489492898374308\n",
      "Error on this batch = 0.14659655757974116\n",
      "Cost on val dataset after 66 epochs is = 0.16789409228726423\n",
      "learning rate =  0.21050638173832112\n",
      "Initial Cost on dataset for this epoch 66 = 0.16789409228726423\n",
      "Error on this batch = 0.13421328382089873\n",
      "Error on this batch = 0.1457884181630139\n",
      "Cost on val dataset after 67 epochs is = 0.16712003824058191\n",
      "learning rate =  0.20971647519513073\n",
      "Initial Cost on dataset for this epoch 67 = 0.16712003824058191\n",
      "Error on this batch = 0.1335950426981015\n",
      "Error on this batch = 0.14495339794491433\n",
      "Cost on val dataset after 68 epochs is = 0.1664404733623636\n",
      "learning rate =  0.2089411699654712\n",
      "Initial Cost on dataset for this epoch 68 = 0.1664404733623636\n",
      "Error on this batch = 0.13299196756118867\n",
      "Error on this batch = 0.1442421043158887\n",
      "Cost on val dataset after 69 epochs is = 0.16577427030982889\n",
      "learning rate =  0.2081799872967546\n",
      "Initial Cost on dataset for this epoch 69 = 0.16577427030982889\n",
      "Error on this batch = 0.13245938738625174\n",
      "Error on this batch = 0.143567111644729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 70 epochs is = 0.1651567018373064\n",
      "learning rate =  0.2074324707851646\n",
      "Initial Cost on dataset for this epoch 70 = 0.1651567018373064\n",
      "Error on this batch = 0.1318874494334545\n",
      "Error on this batch = 0.14276342855794927\n",
      "Cost on val dataset after 71 epochs is = 0.16456788115477486\n",
      "learning rate =  0.2066981850306836\n",
      "Initial Cost on dataset for this epoch 71 = 0.16456788115477486\n",
      "Error on this batch = 0.13128077597966936\n",
      "Error on this batch = 0.14213026910338497\n",
      "Cost on val dataset after 72 epochs is = 0.16399370760107035\n",
      "learning rate =  0.20597671439071177\n",
      "Initial Cost on dataset for this epoch 72 = 0.16399370760107035\n",
      "Error on this batch = 0.13056700655989786\n",
      "Error on this batch = 0.14171903144716155\n",
      "Cost on val dataset after 73 epochs is = 0.16339845217852816\n",
      "learning rate =  0.20526766182379289\n",
      "Initial Cost on dataset for this epoch 73 = 0.16339845217852816\n",
      "Error on this batch = 0.12989277862986065\n",
      "Error on this batch = 0.14085257713769925\n",
      "Cost on val dataset after 74 epochs is = 0.16287307573595453\n",
      "learning rate =  0.20457064781579723\n",
      "Initial Cost on dataset for this epoch 74 = 0.16287307573595453\n",
      "Error on this batch = 0.12917097838182348\n",
      "Error on this batch = 0.14025251818533702\n",
      "Cost on val dataset after 75 epochs is = 0.16235925143289306\n",
      "learning rate =  0.2038853093816547\n",
      "Initial Cost on dataset for this epoch 75 = 0.16235925143289306\n",
      "Error on this batch = 0.1285568633760854\n",
      "Error on this batch = 0.13958127293124156\n",
      "Cost on val dataset after 76 epochs is = 0.1618875315185397\n",
      "learning rate =  0.20321129913639427\n",
      "Initial Cost on dataset for this epoch 76 = 0.1618875315185397\n",
      "Error on this batch = 0.12800281464553698\n",
      "Error on this batch = 0.13893783220431624\n",
      "Cost on val dataset after 77 epochs is = 0.1614634219511131\n",
      "learning rate =  0.2025482844298358\n",
      "Initial Cost on dataset for this epoch 77 = 0.1614634219511131\n",
      "Error on this batch = 0.1275913911840697\n",
      "Error on this batch = 0.1383323156741804\n",
      "Cost on val dataset after 78 epochs is = 0.16099926746056945\n",
      "learning rate =  0.20189594653980908\n",
      "Initial Cost on dataset for this epoch 78 = 0.16099926746056945\n",
      "Error on this batch = 0.12728384051757843\n",
      "Error on this batch = 0.1376571684455507\n",
      "Cost on val dataset after 79 epochs is = 0.1605849899309837\n",
      "learning rate =  0.20125397991924746\n",
      "Initial Cost on dataset for this epoch 79 = 0.1605849899309837\n",
      "Error on this batch = 0.12697272442789517\n",
      "Error on this batch = 0.13697814546559742\n",
      "Cost on val dataset after 80 epochs is = 0.16017026385957073\n",
      "learning rate =  0.20062209149292662\n",
      "Initial Cost on dataset for this epoch 80 = 0.16017026385957073\n",
      "Error on this batch = 0.12659518504456974\n",
      "Error on this batch = 0.13636583611505854\n",
      "Cost on val dataset after 81 epochs is = 0.15974886837655236\n",
      "learning rate =  0.19999999999999998\n",
      "Initial Cost on dataset for this epoch 81 = 0.15974886837655236\n",
      "Error on this batch = 0.1262856870359386\n",
      "Error on this batch = 0.13584267443334347\n",
      "Cost on val dataset after 82 epochs is = 0.15934334790684715\n",
      "learning rate =  0.19938743537882408\n",
      "Initial Cost on dataset for this epoch 82 = 0.15934334790684715\n",
      "Error on this batch = 0.12596953861812904\n",
      "Error on this batch = 0.13523016426463838\n",
      "Cost on val dataset after 83 epochs is = 0.1589837486882678\n",
      "learning rate =  0.1987841381908741\n",
      "Initial Cost on dataset for this epoch 83 = 0.1589837486882678\n",
      "Error on this batch = 0.12567317602509534\n",
      "Error on this batch = 0.13467833575902663\n",
      "Cost on val dataset after 84 epochs is = 0.15862687525658486\n",
      "learning rate =  0.19818985908082842\n",
      "Initial Cost on dataset for this epoch 84 = 0.15862687525658486\n",
      "Error on this batch = 0.12543028635002873\n",
      "Error on this batch = 0.13407954222807836\n",
      "Cost on val dataset after 85 epochs is = 0.15824860057718798\n",
      "learning rate =  0.1976043582701508\n",
      "Initial Cost on dataset for this epoch 85 = 0.15824860057718798\n",
      "Error on this batch = 0.12515344038961637\n",
      "Error on this batch = 0.1335271442235202\n",
      "Cost on val dataset after 86 epochs is = 0.15794315210958196\n",
      "learning rate =  0.19702740508172414\n",
      "Initial Cost on dataset for this epoch 86 = 0.15794315210958196\n",
      "Error on this batch = 0.12484627573286089\n",
      "Error on this batch = 0.13299057506219286\n",
      "Cost on val dataset after 87 epochs is = 0.15764981488272928\n",
      "learning rate =  0.19645877749329657\n",
      "Initial Cost on dataset for this epoch 87 = 0.15764981488272928\n",
      "Error on this batch = 0.12464082802311428\n",
      "Error on this batch = 0.13260701078785192\n",
      "Cost on val dataset after 88 epochs is = 0.15733048529192142\n",
      "learning rate =  0.19589826171768313\n",
      "Initial Cost on dataset for this epoch 88 = 0.15733048529192142\n",
      "Error on this batch = 0.12435395270460105\n",
      "Error on this batch = 0.1321578361607656\n",
      "Cost on val dataset after 89 epochs is = 0.15701457455584966\n",
      "learning rate =  0.1953456518078377\n",
      "Initial Cost on dataset for this epoch 89 = 0.15701457455584966\n",
      "Error on this batch = 0.12406486771913121\n",
      "Error on this batch = 0.13173667601602582\n",
      "Cost on val dataset after 90 epochs is = 0.1567353795550627\n",
      "learning rate =  0.19480074928505933\n",
      "Initial Cost on dataset for this epoch 90 = 0.1567353795550627\n",
      "Error on this batch = 0.12371285576656249\n",
      "Error on this batch = 0.13117061911179545\n",
      "Cost on val dataset after 91 epochs is = 0.15644504669142814\n",
      "learning rate =  0.19426336278873857\n",
      "Initial Cost on dataset for this epoch 91 = 0.15644504669142814\n",
      "Error on this batch = 0.12340049566428801\n",
      "Error on this batch = 0.13070933365850443\n",
      "Cost on val dataset after 92 epochs is = 0.15615469738341192\n",
      "learning rate =  0.1937333077461732\n",
      "Initial Cost on dataset for this epoch 92 = 0.15615469738341192\n",
      "Error on this batch = 0.12308743484251565\n",
      "Error on this batch = 0.13027941678905108\n",
      "Cost on val dataset after 93 epochs is = 0.1558719665406515\n",
      "learning rate =  0.19321040606110043\n",
      "Initial Cost on dataset for this epoch 93 = 0.1558719665406515\n",
      "Error on this batch = 0.12280803546227269\n",
      "Error on this batch = 0.1298557962062691\n",
      "Cost on val dataset after 94 epochs is = 0.1556197139551278\n",
      "learning rate =  0.1926944858196948\n",
      "Initial Cost on dataset for this epoch 94 = 0.1556197139551278\n",
      "Error on this batch = 0.12251650556655388\n",
      "Error on this batch = 0.12949172521075802\n",
      "Cost on val dataset after 95 epochs is = 0.15536911278742596\n",
      "learning rate =  0.1921853810128792\n",
      "Initial Cost on dataset for this epoch 95 = 0.15536911278742596\n",
      "Error on this batch = 0.12227172999240982\n",
      "Error on this batch = 0.12912139699704148\n",
      "Cost on val dataset after 96 epochs is = 0.15513164425099243\n",
      "learning rate =  0.19168293127388172\n",
      "Initial Cost on dataset for this epoch 96 = 0.15513164425099243\n",
      "Error on this batch = 0.12194671777442766\n",
      "Error on this batch = 0.12867278929453568\n",
      "Cost on val dataset after 97 epochs is = 0.15489917965390365\n",
      "learning rate =  0.19118698163005315\n",
      "Initial Cost on dataset for this epoch 97 = 0.15489917965390365\n",
      "Error on this batch = 0.12166035197718274\n",
      "Error on this batch = 0.1283383525844935\n",
      "Cost on val dataset after 98 epochs is = 0.15470011165582226\n",
      "learning rate =  0.19069738226803112\n",
      "Initial Cost on dataset for this epoch 98 = 0.15470011165582226\n",
      "Error on this batch = 0.12140037984753582\n",
      "Error on this batch = 0.12798864332697918\n",
      "Cost on val dataset after 99 epochs is = 0.15448777731811209\n",
      "learning rate =  0.19021398831140582\n",
      "Initial Cost on dataset for this epoch 99 = 0.15448777731811209\n",
      "Error on this batch = 0.12121696225765778\n",
      "Error on this batch = 0.12777291419135856\n",
      "Cost on val dataset after 100 epochs is = 0.1542521838590518\n",
      "learning rate =  0.18973665961010275\n",
      "Initial Cost on dataset for this epoch 100 = 0.1542521838590518\n",
      "Error on this batch = 0.12100368044268002\n",
      "Error on this batch = 0.12747947124997971\n",
      "Cost on val dataset after 101 epochs is = 0.1540411704799088\n",
      "learning rate =  0.1892652605407543\n",
      "Initial Cost on dataset for this epoch 101 = 0.1540411704799088\n",
      "Error on this batch = 0.12066955015705007\n",
      "Error on this batch = 0.12717590503660942\n",
      "Cost on val dataset after 102 epochs is = 0.15385988951519103\n",
      "learning rate =  0.18879965981738495\n",
      "Initial Cost on dataset for this epoch 102 = 0.15385988951519103\n",
      "Error on this batch = 0.12045646262699411\n",
      "Error on this batch = 0.1269449595597247\n",
      "Cost on val dataset after 103 epochs is = 0.15369148392905702\n",
      "learning rate =  0.1883397303117814\n",
      "Initial Cost on dataset for this epoch 103 = 0.15369148392905702\n",
      "Error on this batch = 0.12025267694961933\n",
      "Error on this batch = 0.12667482378112915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 104 epochs is = 0.15350555298463975\n",
      "learning rate =  0.18788534888296407\n",
      "Initial Cost on dataset for this epoch 104 = 0.15350555298463975\n",
      "Error on this batch = 0.12010005608930982\n",
      "Error on this batch = 0.12645888978478304\n",
      "Cost on val dataset after 105 epochs is = 0.15336970144651244\n",
      "learning rate =  0.18743639621521535\n",
      "Initial Cost on dataset for this epoch 105 = 0.15336970144651244\n",
      "Error on this batch = 0.11981167187592918\n",
      "Error on this batch = 0.12608465704171004\n",
      "Cost on val dataset after 106 epochs is = 0.15322336002910442\n",
      "learning rate =  0.18699275666415935\n",
      "Initial Cost on dataset for this epoch 106 = 0.15322336002910442\n",
      "Error on this batch = 0.11962855263679795\n",
      "Error on this batch = 0.12582296274284932\n",
      "Cost on val dataset after 107 epochs is = 0.15313458164848387\n",
      "learning rate =  0.18655431811042028\n",
      "Initial Cost on dataset for this epoch 107 = 0.15313458164848387\n",
      "Error on this batch = 0.11944222845583041\n",
      "Error on this batch = 0.12555219649319302\n",
      "Cost on val dataset after 108 epochs is = 0.1529923693876309\n",
      "learning rate =  0.18612097182041992\n",
      "Initial Cost on dataset for this epoch 108 = 0.1529923693876309\n",
      "Error on this batch = 0.11923903095141601\n",
      "Error on this batch = 0.1253539726091179\n",
      "Cost on val dataset after 109 epochs is = 0.15285926210407494\n",
      "learning rate =  0.1856926123139029\n",
      "Initial Cost on dataset for this epoch 109 = 0.15285926210407494\n",
      "Error on this batch = 0.11902397819184948\n",
      "Error on this batch = 0.1250422795944157\n",
      "Cost on val dataset after 110 epochs is = 0.15274435773024866\n",
      "learning rate =  0.18526913723780689\n",
      "Initial Cost on dataset for this epoch 110 = 0.15274435773024866\n",
      "Error on this batch = 0.11875982415137788\n",
      "Error on this batch = 0.12477040830877052\n",
      "Cost on val dataset after 111 epochs is = 0.1526432562758315\n",
      "learning rate =  0.1848504472461183\n",
      "Initial Cost on dataset for this epoch 111 = 0.1526432562758315\n",
      "Error on this batch = 0.11855946211721208\n",
      "Error on this batch = 0.12449102641397801\n",
      "Cost on val dataset after 112 epochs is = 0.15257565297515302\n",
      "learning rate =  0.1844364458853793\n",
      "Initial Cost on dataset for this epoch 112 = 0.15257565297515302\n",
      "Error on this batch = 0.11835943108057828\n",
      "Error on this batch = 0.12418320854064273\n",
      "Cost on val dataset after 113 epochs is = 0.15244915077222715\n",
      "learning rate =  0.18402703948553187\n",
      "Initial Cost on dataset for this epoch 113 = 0.15244915077222715\n",
      "Error on this batch = 0.11811193683114816\n",
      "Error on this batch = 0.12389852062858417\n",
      "Cost on val dataset after 114 epochs is = 0.15237859700724626\n",
      "learning rate =  0.18362213705580538\n",
      "Initial Cost on dataset for this epoch 114 = 0.15237859700724626\n",
      "Error on this batch = 0.11781597999174619\n",
      "Error on this batch = 0.12358002070491915\n",
      "Cost on val dataset after 115 epochs is = 0.1522729882410018\n",
      "learning rate =  0.18322165018537329\n",
      "Initial Cost on dataset for this epoch 115 = 0.1522729882410018\n",
      "Error on this batch = 0.11762855549091822\n",
      "Error on this batch = 0.12330068691462774\n",
      "Cost on val dataset after 116 epochs is = 0.15221075448942537\n",
      "learning rate =  0.18282549294852\n",
      "Initial Cost on dataset for this epoch 116 = 0.15221075448942537\n",
      "Error on this batch = 0.11738624356109373\n",
      "Error on this batch = 0.12306996950135776\n",
      "Cost on val dataset after 117 epochs is = 0.15215045562022309\n",
      "learning rate =  0.1824335818140776\n",
      "Initial Cost on dataset for this epoch 117 = 0.15215045562022309\n",
      "Error on this batch = 0.11708878608506479\n",
      "Error on this batch = 0.1228014592825807\n",
      "Cost on val dataset after 118 epochs is = 0.15210617020312608\n",
      "learning rate =  0.18204583555890436\n",
      "Initial Cost on dataset for this epoch 118 = 0.15210617020312608\n",
      "Error on this batch = 0.11682022594808146\n",
      "Error on this batch = 0.12257355527157614\n",
      "Cost on val dataset after 119 epochs is = 0.15207363824807946\n",
      "learning rate =  0.1816621751851926\n",
      "Initial Cost on dataset for this epoch 119 = 0.15207363824807946\n",
      "Error on this batch = 0.11662697214319717\n",
      "Error on this batch = 0.12233583906822042\n",
      "Cost on val dataset after 120 epochs is = 0.1520308540143829\n",
      "learning rate =  0.18128252384140608\n",
      "Initial Cost on dataset for this epoch 120 = 0.1520308540143829\n",
      "Error on this batch = 0.11636977968832955\n",
      "Error on this batch = 0.1220999800458144\n",
      "Cost on val dataset after 121 epochs is = 0.15199710374199893\n",
      "learning rate =  0.18090680674665816\n",
      "Initial Cost on dataset for this epoch 121 = 0.15199710374199893\n",
      "Error on this batch = 0.1162038432510635\n",
      "Error on this batch = 0.12179650061823452\n",
      "Cost on val dataset after 122 epochs is = 0.15195239464736968\n",
      "learning rate =  0.18053495111835455\n",
      "Initial Cost on dataset for this epoch 122 = 0.15195239464736968\n",
      "Error on this batch = 0.11607667692052363\n",
      "Error on this batch = 0.12151150277300236\n",
      "Cost on val dataset after 123 epochs is = 0.15187629032377092\n",
      "learning rate =  0.1801668861029339\n",
      "Initial Cost on dataset for this epoch 123 = 0.15187629032377092\n",
      "Error on this batch = 0.11592711069266193\n",
      "Error on this batch = 0.12122902882505673\n",
      "Cost on val dataset after 124 epochs is = 0.1518594353091868\n",
      "learning rate =  0.17980254270954982\n",
      "Initial Cost on dataset for this epoch 124 = 0.1518594353091868\n",
      "Error on this batch = 0.11572100606552123\n",
      "Error on this batch = 0.12085686623576049\n",
      "Cost on val dataset after 125 epochs is = 0.15181340491675308\n",
      "learning rate =  0.17944185374654648\n",
      "Initial Cost on dataset for this epoch 125 = 0.15181340491675308\n",
      "Error on this batch = 0.11545011562638166\n",
      "Error on this batch = 0.12044109123989431\n",
      "Cost on val dataset after 126 epochs is = 0.15182163913232025\n",
      "learning rate =  0.17908475376058935\n",
      "Initial Cost on dataset for this epoch 126 = 0.15182163913232025\n",
      "Error on this batch = 0.11520682958188445\n",
      "Error on this batch = 0.11993750673197873\n",
      "Cost on val dataset after 127 epochs is = 0.15180460602604964\n",
      "learning rate =  0.17873117897831953\n",
      "Initial Cost on dataset for this epoch 127 = 0.15180460602604964\n",
      "Error on this batch = 0.1150566493541669\n",
      "Error on this batch = 0.11960976724421801\n",
      "Cost on val dataset after 128 epochs is = 0.15176824292276433\n",
      "learning rate =  0.17838106725040817\n",
      "Initial Cost on dataset for this epoch 128 = 0.15176824292276433\n",
      "Error on this batch = 0.11479981176708665\n",
      "Error on this batch = 0.11924707122068622\n",
      "Cost on val dataset after 129 epochs is = 0.1517416964579887\n",
      "learning rate =  0.1780343579978945\n",
      "Initial Cost on dataset for this epoch 129 = 0.1517416964579887\n",
      "Error on this batch = 0.1144964101085377\n",
      "Error on this batch = 0.11880331733394275\n",
      "Cost on val dataset after 130 epochs is = 0.15173180386696283\n",
      "learning rate =  0.17769099216069748\n",
      "Initial Cost on dataset for this epoch 130 = 0.15173180386696283\n",
      "Error on this batch = 0.11422763964744126\n",
      "Error on this batch = 0.11830728020626666\n",
      "Cost on val dataset after 131 epochs is = 0.1517345484386472\n",
      "learning rate =  0.17735091214819665\n",
      "Initial Cost on dataset for this epoch 131 = 0.1517345484386472\n",
      "Error on this batch = 0.11409158552278927\n",
      "Error on this batch = 0.11781958571265148\n",
      "Cost on val dataset after 132 epochs is = 0.1517801583558142\n",
      "learning rate =  0.17701406179178425\n",
      "Initial Cost on dataset for this epoch 132 = 0.1517801583558142\n",
      "Error on this batch = 0.11382382066242498\n",
      "Error on this batch = 0.11726205426866987\n",
      "Cost on val dataset after 133 epochs is = 0.15178054411158\n",
      "learning rate =  0.1766803862992956\n",
      "Initial Cost on dataset for this epoch 133 = 0.15178054411158\n",
      "Error on this batch = 0.11367287857074128\n",
      "Error on this batch = 0.11680479040505888\n",
      "Cost on val dataset after 134 epochs is = 0.15179433031000938\n",
      "learning rate =  0.17634983221122996\n",
      "Initial Cost on dataset for this epoch 134 = 0.15179433031000938\n",
      "Error on this batch = 0.11345359374602998\n",
      "Error on this batch = 0.11634948182573578\n",
      "Cost on val dataset after 135 epochs is = 0.15178486617236722\n",
      "learning rate =  0.17602234735867867\n",
      "Initial Cost on dataset for this epoch 135 = 0.15178486617236722\n",
      "Error on this batch = 0.11322626298196158\n",
      "Error on this batch = 0.1159650966549642\n",
      "Cost on val dataset after 136 epochs is = 0.15177611423110124\n",
      "learning rate =  0.17569788082288185\n",
      "Initial Cost on dataset for this epoch 136 = 0.15177611423110124\n",
      "Error on this batch = 0.1129810141711334\n",
      "Error on this batch = 0.11542094546950363\n",
      "Cost on val dataset after 137 epochs is = 0.15176704529910673\n",
      "learning rate =  0.17537638289633925\n",
      "Initial Cost on dataset for this epoch 137 = 0.15176704529910673\n",
      "Error on this batch = 0.11278514416517683\n",
      "Error on this batch = 0.11494614471062597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 138 epochs is = 0.15176374633553438\n",
      "learning rate =  0.1750578050454048\n",
      "Initial Cost on dataset for this epoch 138 = 0.15176374633553438\n",
      "Error on this batch = 0.11257788281208636\n",
      "Error on this batch = 0.11453660632830151\n",
      "Cost on val dataset after 139 epochs is = 0.15177139278429524\n",
      "learning rate =  0.17474209987429748\n",
      "Initial Cost on dataset for this epoch 139 = 0.15177139278429524\n",
      "Error on this batch = 0.11243045193668241\n",
      "Error on this batch = 0.11416733925519174\n",
      "Cost on val dataset after 140 epochs is = 0.1517791924655252\n",
      "learning rate =  0.17442922109046577\n",
      "Initial Cost on dataset for this epoch 140 = 0.1517791924655252\n",
      "Error on this batch = 0.11227202988557348\n",
      "Error on this batch = 0.11376955439180118\n",
      "Cost on val dataset after 141 epochs is = 0.15179463275569824\n",
      "learning rate =  0.17411912347124506\n",
      "Initial Cost on dataset for this epoch 141 = 0.15179463275569824\n",
      "Error on this batch = 0.11209996024234144\n",
      "Error on this batch = 0.11341673865477674\n",
      "Cost on val dataset after 142 epochs is = 0.1518037877261942\n",
      "learning rate =  0.17381176283175084\n",
      "Initial Cost on dataset for this epoch 142 = 0.1518037877261942\n",
      "Error on this batch = 0.11187988073212378\n",
      "Error on this batch = 0.11309335520826545\n",
      "Cost on val dataset after 143 epochs is = 0.15183153325889187\n",
      "learning rate =  0.17350709599395428\n",
      "Initial Cost on dataset for this epoch 143 = 0.15183153325889187\n",
      "Error on this batch = 0.11166769919959331\n",
      "Error on this batch = 0.11274377512330457\n",
      "Cost on val dataset after 144 epochs is = 0.1518339360891185\n",
      "learning rate =  0.17320508075688773\n",
      "Initial Cost on dataset for this epoch 144 = 0.1518339360891185\n",
      "Error on this batch = 0.1115098822400327\n",
      "Error on this batch = 0.11247144482302733\n",
      "Cost on val dataset after 145 epochs is = 0.15185892739037263\n",
      "learning rate =  0.17290567586793207\n",
      "Initial Cost on dataset for this epoch 145 = 0.15185892739037263\n",
      "Error on this batch = 0.11139069838346859\n",
      "Error on this batch = 0.11214514836202312\n",
      "Cost on val dataset after 146 epochs is = 0.1518625092142262\n",
      "learning rate =  0.1726088409951392\n",
      "Initial Cost on dataset for this epoch 146 = 0.1518625092142262\n",
      "Error on this batch = 0.11110649566046867\n",
      "Error on this batch = 0.11197183415653937\n",
      "Cost on val dataset after 147 epochs is = 0.15187283603318388\n",
      "learning rate =  0.1723145367005454\n",
      "Initial Cost on dataset for this epoch 147 = 0.15187283603318388\n",
      "Error on this batch = 0.11089622138582966\n",
      "Error on this batch = 0.1116725586685131\n",
      "Cost on val dataset after 148 epochs is = 0.15184909800443644\n",
      "learning rate =  0.172022724414434\n",
      "Initial Cost on dataset for this epoch 148 = 0.15184909800443644\n",
      "Error on this batch = 0.1107156982612538\n",
      "Error on this batch = 0.11144259270325378\n",
      "Cost on val dataset after 149 epochs is = 0.1518434289036374\n",
      "learning rate =  0.171733366410507\n",
      "Initial Cost on dataset for this epoch 149 = 0.1518434289036374\n",
      "Error on this batch = 0.1105377695685959\n",
      "Error on this batch = 0.11120946536605306\n",
      "Cost on val dataset after 150 epochs is = 0.15184635835466254\n",
      "learning rate =  0.17144642578192795\n",
      "Initial Cost on dataset for this epoch 150 = 0.15184635835466254\n",
      "Error on this batch = 0.11030806400479483\n",
      "Error on this batch = 0.11095053339010819\n",
      "Cost on val dataset after 151 epochs is = 0.1518664022047011\n",
      "learning rate =  0.1711618664182\n",
      "Initial Cost on dataset for this epoch 151 = 0.1518664022047011\n",
      "Error on this batch = 0.1102019820390462\n",
      "Error on this batch = 0.11076090998935934\n",
      "Cost on val dataset after 152 epochs is = 0.15188158181631753\n",
      "learning rate =  0.1708796529828442\n",
      "Initial Cost on dataset for this epoch 152 = 0.15188158181631753\n",
      "Error on this batch = 0.11005477194443283\n",
      "Error on this batch = 0.11061996546270407\n",
      "Cost on val dataset after 153 epochs is = 0.1519087843860938\n",
      "learning rate =  0.17059975089184612\n",
      "Initial Cost on dataset for this epoch 153 = 0.1519087843860938\n",
      "Error on this batch = 0.109864093353988\n",
      "Error on this batch = 0.11044666901231262\n",
      "Cost on val dataset after 154 epochs is = 0.15192838001988213\n",
      "learning rate =  0.17032212629283866\n",
      "Initial Cost on dataset for this epoch 154 = 0.15192838001988213\n",
      "Error on this batch = 0.10965648312606076\n",
      "Error on this batch = 0.11032442270127371\n",
      "Cost on val dataset after 155 epochs is = 0.15192110955661878\n",
      "learning rate =  0.17004674604499187\n",
      "Initial Cost on dataset for this epoch 155 = 0.15192110955661878\n",
      "Error on this batch = 0.10951411741086395\n",
      "Error on this batch = 0.11027129235138414\n",
      "Cost on val dataset after 156 epochs is = 0.1519213214676184\n",
      "learning rate =  0.16977357769958104\n",
      "Initial Cost on dataset for this epoch 156 = 0.1519213214676184\n",
      "Error on this batch = 0.10937032747552555\n",
      "Error on this batch = 0.11000748953835007\n",
      "Cost on val dataset after 157 epochs is = 0.15192454157308938\n",
      "learning rate =  0.16950258948120644\n",
      "Initial Cost on dataset for this epoch 157 = 0.15192454157308938\n",
      "Error on this batch = 0.10926326928163599\n",
      "Error on this batch = 0.10988874460949061\n",
      "Cost on val dataset after 158 epochs is = 0.15193128401123338\n",
      "learning rate =  0.16923375026963824\n",
      "Initial Cost on dataset for this epoch 158 = 0.15193128401123338\n",
      "Error on this batch = 0.10910906458359074\n",
      "Error on this batch = 0.10967631079961689\n",
      "Cost on val dataset after 159 epochs is = 0.15194173597914404\n",
      "learning rate =  0.16896702958226256\n",
      "Initial Cost on dataset for this epoch 159 = 0.15194173597914404\n",
      "Error on this batch = 0.10894133844644331\n",
      "Error on this batch = 0.1095097960652414\n",
      "Cost on val dataset after 160 epochs is = 0.1519038158111051\n",
      "learning rate =  0.16870239755710473\n",
      "Initial Cost on dataset for this epoch 160 = 0.1519038158111051\n",
      "Error on this batch = 0.1087609783949306\n",
      "Error on this batch = 0.10945750137129107\n",
      "Cost on val dataset after 161 epochs is = 0.15188683329513739\n",
      "learning rate =  0.16843982493640752\n",
      "Initial Cost on dataset for this epoch 161 = 0.15188683329513739\n",
      "Error on this batch = 0.10858064575290297\n",
      "Error on this batch = 0.10934068872496187\n",
      "Cost on val dataset after 162 epochs is = 0.15188707252094408\n",
      "learning rate =  0.1681792830507429\n",
      "Initial Cost on dataset for this epoch 162 = 0.15188707252094408\n",
      "Error on this batch = 0.10840087445726239\n",
      "Error on this batch = 0.10922190292248303\n",
      "Cost on val dataset after 163 epochs is = 0.15186967534370088\n",
      "learning rate =  0.1679207438036363\n",
      "Initial Cost on dataset for this epoch 163 = 0.15186967534370088\n",
      "Error on this batch = 0.10824317546694216\n",
      "Error on this batch = 0.1089779278399445\n",
      "Cost on val dataset after 164 epochs is = 0.15186168704125616\n",
      "learning rate =  0.16766417965668484\n",
      "Initial Cost on dataset for this epoch 164 = 0.15186168704125616\n",
      "Error on this batch = 0.10802465347284067\n",
      "Error on this batch = 0.10898607790240301\n",
      "Cost on val dataset after 165 epochs is = 0.1518557743253252\n",
      "learning rate =  0.1674095636151496\n",
      "Initial Cost on dataset for this epoch 165 = 0.1518557743253252\n",
      "Error on this batch = 0.10790614363978232\n",
      "Error on this batch = 0.10885266291798049\n",
      "Cost on val dataset after 166 epochs is = 0.151856744705525\n",
      "learning rate =  0.16715686921400502\n",
      "Initial Cost on dataset for this epoch 166 = 0.151856744705525\n",
      "Error on this batch = 0.10777831526049055\n",
      "Error on this batch = 0.10870927583575263\n",
      "Cost on val dataset after 167 epochs is = 0.15186776611885994\n",
      "learning rate =  0.16690607050442752\n",
      "Initial Cost on dataset for this epoch 167 = 0.15186776611885994\n",
      "Error on this batch = 0.10769482577103148\n",
      "Error on this batch = 0.10857561038068057\n",
      "Cost on val dataset after 168 epochs is = 0.15187023248021345\n",
      "learning rate =  0.16665714204070745\n",
      "Initial Cost on dataset for this epoch 168 = 0.15187023248021345\n",
      "Error on this batch = 0.10753316239719045\n",
      "Error on this batch = 0.1085178929335167\n",
      "Cost on val dataset after 169 epochs is = 0.15188703178511911\n",
      "learning rate =  0.16641005886756874\n",
      "Initial Cost on dataset for this epoch 169 = 0.15188703178511911\n",
      "Error on this batch = 0.1074247686520888\n",
      "Error on this batch = 0.10841404197230155\n",
      "Cost on val dataset after 170 epochs is = 0.15186679834190545\n",
      "learning rate =  0.1661647965078805\n",
      "Initial Cost on dataset for this epoch 170 = 0.15186679834190545\n",
      "Error on this batch = 0.10727546452297752\n",
      "Error on this batch = 0.1083693163061752\n",
      "Cost on val dataset after 171 epochs is = 0.15186635562937487\n",
      "learning rate =  0.1659213309507473\n",
      "Initial Cost on dataset for this epoch 171 = 0.15186635562937487\n",
      "Error on this batch = 0.10715457398569234\n",
      "Error on this batch = 0.1083176987846851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 172 epochs is = 0.15187728691778143\n",
      "learning rate =  0.16567963863996335\n",
      "Initial Cost on dataset for this epoch 172 = 0.15187728691778143\n",
      "Error on this batch = 0.10706141540474245\n",
      "Error on this batch = 0.10819364995542366\n",
      "Cost on val dataset after 173 epochs is = 0.15185208681526546\n",
      "learning rate =  0.16543969646281814\n",
      "Initial Cost on dataset for this epoch 173 = 0.15185208681526546\n",
      "Error on this batch = 0.10689649776753866\n",
      "Error on this batch = 0.10817334187816913\n",
      "Cost on val dataset after 174 epochs is = 0.15180373242710457\n",
      "learning rate =  0.1652014817392402\n",
      "Initial Cost on dataset for this epoch 174 = 0.15180373242710457\n",
      "Error on this batch = 0.10678880071549336\n",
      "Error on this batch = 0.10816616887421131\n",
      "Cost on val dataset after 175 epochs is = 0.15183209825100644\n",
      "learning rate =  0.1649649722112678\n",
      "Initial Cost on dataset for this epoch 175 = 0.15183209825100644\n",
      "Error on this batch = 0.10672635039875467\n",
      "Error on this batch = 0.1080274916788802\n",
      "Cost on val dataset after 176 epochs is = 0.15181555901028682\n",
      "learning rate =  0.16473014603283373\n",
      "Initial Cost on dataset for this epoch 176 = 0.15181555901028682\n",
      "Error on this batch = 0.10651933625866111\n",
      "Error on this batch = 0.10799411213827192\n",
      "Cost on val dataset after 177 epochs is = 0.1518194582367649\n",
      "learning rate =  0.16449698175985428\n",
      "Initial Cost on dataset for this epoch 177 = 0.1518194582367649\n",
      "Error on this batch = 0.10641149410641881\n",
      "Error on this batch = 0.10794443727020867\n",
      "Cost on val dataset after 178 epochs is = 0.15177053596096238\n",
      "learning rate =  0.164265458340611\n",
      "Initial Cost on dataset for this epoch 178 = 0.15177053596096238\n",
      "Error on this batch = 0.10621242441652502\n",
      "Error on this batch = 0.10791976739914937\n",
      "Cost on val dataset after 179 epochs is = 0.15178455003718602\n",
      "learning rate =  0.16403555510641493\n",
      "Initial Cost on dataset for this epoch 179 = 0.15178455003718602\n",
      "Error on this batch = 0.10615934590762599\n",
      "Error on this batch = 0.10781959569967625\n",
      "Cost on val dataset after 180 epochs is = 0.15177416594375925\n",
      "learning rate =  0.163807251762544\n",
      "Initial Cost on dataset for this epoch 180 = 0.15177416594375925\n",
      "Error on this batch = 0.10611530680199271\n",
      "Error on this batch = 0.10775409011368123\n",
      "Cost on val dataset after 181 epochs is = 0.15176957976010136\n",
      "learning rate =  0.1635805283794437\n",
      "Initial Cost on dataset for this epoch 181 = 0.15176957976010136\n",
      "Error on this batch = 0.10604585816873048\n",
      "Error on this batch = 0.10772269186957602\n",
      "Cost on val dataset after 182 epochs is = 0.15172343238004338\n",
      "learning rate =  0.1633553653841821\n",
      "Initial Cost on dataset for this epoch 182 = 0.15172343238004338\n",
      "Error on this batch = 0.10592859602212329\n",
      "Error on this batch = 0.10781404482584014\n",
      "Cost on val dataset after 183 epochs is = 0.1517396639959423\n",
      "learning rate =  0.16313174355215057\n",
      "Initial Cost on dataset for this epoch 183 = 0.1517396639959423\n",
      "Error on this batch = 0.10592933462287231\n",
      "Error on this batch = 0.10770948207956568\n",
      "Cost on val dataset after 184 epochs is = 0.15174433815545119\n",
      "learning rate =  0.16290964399900174\n",
      "Initial Cost on dataset for this epoch 184 = 0.15174433815545119\n",
      "Error on this batch = 0.10586317780375933\n",
      "Error on this batch = 0.10769098647017639\n",
      "Cost on val dataset after 185 epochs is = 0.1517425353184935\n",
      "learning rate =  0.1626890481728167\n",
      "Initial Cost on dataset for this epoch 185 = 0.1517425353184935\n",
      "Error on this batch = 0.10572761630501841\n",
      "Error on this batch = 0.10765821212463707\n",
      "Cost on val dataset after 186 epochs is = 0.15174620641687117\n",
      "learning rate =  0.1624699378464939\n",
      "Initial Cost on dataset for this epoch 186 = 0.15174620641687117\n",
      "Error on this batch = 0.10565904699885209\n",
      "Error on this batch = 0.10764816706215138\n",
      "Cost on val dataset after 187 epochs is = 0.15172075588569797\n",
      "learning rate =  0.16225229511035183\n",
      "Initial Cost on dataset for this epoch 187 = 0.15172075588569797\n",
      "Error on this batch = 0.10559174895638034\n",
      "Error on this batch = 0.10752293121335482\n",
      "Cost on val dataset after 188 epochs is = 0.15173613327535077\n",
      "learning rate =  0.16203610236493907\n",
      "Initial Cost on dataset for this epoch 188 = 0.15173613327535077\n",
      "Error on this batch = 0.1056296538732265\n",
      "Error on this batch = 0.10748347693806767\n",
      "Cost on val dataset after 189 epochs is = 0.151716610932141\n",
      "learning rate =  0.16182134231404424\n",
      "Initial Cost on dataset for this epoch 189 = 0.151716610932141\n",
      "Error on this batch = 0.10554360856901174\n",
      "Error on this batch = 0.10748787370046417\n",
      "Cost on val dataset after 190 epochs is = 0.1516897467317851\n",
      "learning rate =  0.1616079979578994\n",
      "Initial Cost on dataset for this epoch 190 = 0.1516897467317851\n",
      "Error on this batch = 0.10548370580809094\n",
      "Error on this batch = 0.10747663383072134\n",
      "Cost on val dataset after 191 epochs is = 0.1517006717199726\n",
      "learning rate =  0.16139605258657097\n",
      "Initial Cost on dataset for this epoch 191 = 0.1517006717199726\n",
      "Error on this batch = 0.10544294527462494\n",
      "Error on this batch = 0.10730744850206975\n",
      "Cost on val dataset after 192 epochs is = 0.15172363605241926\n",
      "learning rate =  0.16118548977353128\n",
      "Initial Cost on dataset for this epoch 192 = 0.15172363605241926\n",
      "Error on this batch = 0.10542336566516941\n",
      "Error on this batch = 0.10741961720134746\n",
      "Cost on val dataset after 193 epochs is = 0.15174850917581897\n",
      "learning rate =  0.1609762933694058\n",
      "Initial Cost on dataset for this epoch 193 = 0.15174850917581897\n",
      "Error on this batch = 0.10534801069123166\n",
      "Error on this batch = 0.10729047438832036\n",
      "Cost on val dataset after 194 epochs is = 0.15174541628955748\n",
      "learning rate =  0.16076844749588948\n",
      "Initial Cost on dataset for this epoch 194 = 0.15174541628955748\n",
      "Error on this batch = 0.10528255287933888\n",
      "Error on this batch = 0.1073250231426148\n",
      "Cost on val dataset after 195 epochs is = 0.1517404710181324\n",
      "learning rate =  0.16056193653982745\n",
      "Initial Cost on dataset for this epoch 195 = 0.1517404710181324\n",
      "Error on this batch = 0.10517242102211\n",
      "Error on this batch = 0.10729695151536767\n",
      "Cost on val dataset after 196 epochs is = 0.1517487540310064\n",
      "learning rate =  0.16035674514745463\n",
      "Initial Cost on dataset for this epoch 196 = 0.1517487540310064\n",
      "Error on this batch = 0.10519625592810102\n",
      "Error on this batch = 0.10736962144886202\n",
      "Cost on val dataset after 197 epochs is = 0.15176185003217074\n",
      "learning rate =  0.1601528582187888\n",
      "Initial Cost on dataset for this epoch 197 = 0.15176185003217074\n",
      "Error on this batch = 0.10513103154011272\n",
      "Error on this batch = 0.10740915661019722\n",
      "Cost on val dataset after 198 epochs is = 0.15172817504738298\n",
      "learning rate =  0.15995026090217312\n",
      "Initial Cost on dataset for this epoch 198 = 0.15172817504738298\n",
      "Error on this batch = 0.10503305270072191\n",
      "Error on this batch = 0.10739524739023872\n",
      "Cost on val dataset after 199 epochs is = 0.1516953322297066\n",
      "learning rate =  0.15974893858896244\n",
      "Initial Cost on dataset for this epoch 199 = 0.1516953322297066\n",
      "Error on this batch = 0.10502267601145404\n",
      "Error on this batch = 0.1074229563512588\n",
      "Cost on val dataset after 200 epochs is = 0.15168794202229063\n",
      "learning rate =  0.15954887690834965\n",
      "Initial Cost on dataset for this epoch 200 = 0.15168794202229063\n",
      "Error on this batch = 0.10492006698085188\n",
      "Error on this batch = 0.10742335587369985\n",
      "Cost on val dataset after 201 epochs is = 0.1517200941084473\n",
      "learning rate =  0.15935006172232735\n",
      "Initial Cost on dataset for this epoch 201 = 0.1517200941084473\n",
      "Error on this batch = 0.10485818339465422\n",
      "Error on this batch = 0.10747205475014222\n",
      "Cost on val dataset after 202 epochs is = 0.15175354551117554\n",
      "learning rate =  0.1591524791207806\n",
      "Initial Cost on dataset for this epoch 202 = 0.15175354551117554\n",
      "Error on this batch = 0.1048325234398978\n",
      "Error on this batch = 0.10747080687451195\n",
      "Cost on val dataset after 203 epochs is = 0.15178828296710795\n",
      "learning rate =  0.15895611541670698\n",
      "Initial Cost on dataset for this epoch 203 = 0.15178828296710795\n",
      "Error on this batch = 0.10476608760543743\n",
      "Error on this batch = 0.10736338937398636\n",
      "Cost on val dataset after 204 epochs is = 0.15181975021262398\n",
      "learning rate =  0.15876095714155977\n",
      "Initial Cost on dataset for this epoch 204 = 0.15181975021262398\n",
      "Error on this batch = 0.1047322880707214\n",
      "Error on this batch = 0.10738790760758718\n",
      "Cost on val dataset after 205 epochs is = 0.15186819748442756\n",
      "learning rate =  0.15856699104071065\n",
      "Initial Cost on dataset for this epoch 205 = 0.15186819748442756\n",
      "Error on this batch = 0.10470626595131968\n",
      "Error on this batch = 0.10737572999604805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on val dataset after 206 epochs is = 0.15190432722342423\n",
      "learning rate =  0.15837420406902836\n",
      "Initial Cost on dataset for this epoch 206 = 0.15190432722342423\n",
      "Error on this batch = 0.10464904410821613\n",
      "Error on this batch = 0.10736373121773657\n",
      "Cost on val dataset after 207 epochs is = 0.15191246894635474\n",
      "learning rate =  0.15818258338656938\n",
      "Initial Cost on dataset for this epoch 207 = 0.15191246894635474\n",
      "Error on this batch = 0.1046591074089304\n",
      "Error on this batch = 0.10734998567842868\n",
      "Cost on val dataset after 208 epochs is = 0.15200506008626738\n",
      "learning rate =  0.157992116354378\n",
      "Initial Cost on dataset for this epoch 208 = 0.15200506008626738\n",
      "Error on this batch = 0.10467426431447589\n",
      "Error on this batch = 0.10730430906437413\n",
      "Cost on val dataset after 209 epochs is = 0.1521058434200051\n",
      "learning rate =  0.15780279053039173\n",
      "Initial Cost on dataset for this epoch 209 = 0.1521058434200051\n",
      "Error on this batch = 0.10462230356701319\n",
      "Error on this batch = 0.10727385207303888\n",
      "Cost on val dataset after 210 epochs is = 0.15215330196158203\n",
      "cost initial= 0.1521058434200051 , cost final=0.15215330196158203 , change in cost= 4.745854157692242e-05\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer arch= [100, 100] are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 210.000\n",
      "The training time = 45.209sec\n",
      "The training accuracy is = 87.602%\n",
      "The validation accuracy is = 82.564%\n",
      "The test accuracy is = 81.908%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch=[100,100]\n",
    "lr=0.1\n",
    "lr0=0.6\n",
    "theta = theta_init(arch)\n",
    "costs = []\n",
    "epoch = 1\n",
    "start = time.time()\n",
    "#cost_init = cost_total(X_train, theta, train_class_enc, m) #Validation loss not giving much info\n",
    "cost_init = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0]) #Validation loss not giving much info\n",
    "costs.append(cost_init)\n",
    "early_stop= 0\n",
    "while(True):\n",
    "    count = 0\n",
    "    lr = lr0/(np.power(epoch, 1/4))\n",
    "    #if(lr < 0.001): lr = 0.001\n",
    "    print(\"learning rate = \", lr)\n",
    "\n",
    "    print(\"Initial Cost on dataset for this epoch {} = {}\".format(epoch, cost_init))\n",
    "\n",
    "    for b in mini_batch:\n",
    "        X_b = b[0]\n",
    "        Y_b = b[1]\n",
    "        fm = forward_prop(X_b, theta)\n",
    "        #print(fm[1][:,-1])\n",
    "        delta = [None]*len(fm)\n",
    "\n",
    "        if (count % 60 == 0):\n",
    "            print(\"Error on this batch = \"+str(cost_total(X_b, theta, Y_b, batch_size)))\n",
    "        #Backward Propagation\n",
    "        #print(len(fm))\n",
    "        for l in range(len(fm)-1, 0, -1):\n",
    "            if (l == len(fm)-1):\n",
    "                delta[l] = ((1/batch_size)*(Y_b - fm[l])*fm[l]*(1-fm[l]))\n",
    "                #delta[l] = ((1/batch_size)*((Y_b/fm[l])-((1-Y_b)/(1-fm[l])))*fm[l]*(1-fm[l]))\n",
    "                #print(\"delta for last layer=\",delta[l].shape)\n",
    "            else:\n",
    "                #print(fm[l][0])\n",
    "                if(l+1 == len(fm)-1):\n",
    "                    delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_relu(fm[l])\n",
    "                else:\n",
    "                    delta[l]=np.dot(delta[l+1][:,1:], theta[l].T)*deriv_relu(fm[l])\n",
    "                    #print(\"delta for hidden layer=\",np.mean(delta[l]))\n",
    "\n",
    "        for t in range(len(theta)):\n",
    "                if (t == len(theta)-1):\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1]) \n",
    "                else:\n",
    "                    theta[t] += lr*np.dot(fm[t].T, delta[t+1])[:,1:]\n",
    "        \n",
    "        count+=1\n",
    "    epoch+=1 #Number of epochs\n",
    "    #ite+=1\n",
    "\n",
    "    #cost_final = cost_total(X_train, theta, train_class_enc, m)\n",
    "    cost_final = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0])\n",
    "    if(epoch%10==0): costs.append(cost_final)\n",
    "    print(\"Cost on val dataset after {} epochs is = {}\".format(epoch, cost_final))\n",
    "    \n",
    "    if ((cost_final-cost_init) > 0):\n",
    "        early_stop +=1\n",
    "    else:\n",
    "        early_stop=0\n",
    "        theta0=theta\n",
    "\n",
    "    if (early_stop == 10):\n",
    "        print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "        break\n",
    "\n",
    "    cost_init = cost_final\n",
    "    \n",
    "    \n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer arch= {} are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs = {:2.3f}\".format(epochs[-1]))\n",
    "print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.01538461538462"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(X_test, theta, test_actual_class_enc)\n",
    "#calc_accuracy(X_test, theta0, test_actual_class_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f603b54a710>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Validation Loss with Epochs with ReLU\")\n",
    "x = np.arange(0,len(costs[1:]))\n",
    "ax.plot(x, costs[1:], marker='o', label='Loss')\n",
    "ax.set_xlabel(\"number of epochs\")\n",
    "ax.set_ylabel(\"Val Loss\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"plots/partd/relu_val_adapt_sqrt.png\", dpi=1000, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Loss with Epochs\")\n",
    "x = np.arange(0,len(costs[1:]))\n",
    "ax.plot(x, costs[1:], marker='o', label='Train Accuracy')\n",
    "ax.set_xlabel(\"number of epochs\")\n",
    "ax.set_ylabel(\"Train Loss\")data:image/png;base64,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\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"accuracy_HiddenUnit_val20per.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

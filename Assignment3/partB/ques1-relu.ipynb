{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "The total number of training samples = 11050\n",
      "The total number of validation samples = 1950\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "np.random.shuffle(X_train.to_numpy())\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "\n",
    "X_valid = X_train.iloc[(int(0.85*m)):]\n",
    "valid_class = train_class[(int(0.85*m)):]\n",
    "X_train = X_train.iloc[0:int(0.85*m)]\n",
    "train_class = train_class[0:int(0.85*m)]\n",
    "\n",
    "\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The total number of validation samples = {}\".format(X_valid.shape[0]))\n",
    "\n",
    "\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "valid_class_enc = pd.get_dummies(valid_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_valid = np.hstack((np.ones((X_valid.shape[0],1)), X_valid.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "arch_test = [1,5,10,50,100]\n",
    "arch = [arch_test[3]] #means one hidden layer with 2 perceptrons \n",
    "batch_size = 100 # Mini-Batch Size\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mini-batches formed is = 111\n"
     ]
    }
   ],
   "source": [
    "#Mini-Batch formation\n",
    "mini_batch = [(X_train[i:i+batch_size,:], train_class_enc[i:i+batch_size]) for i in range(0, m, batch_size)]\n",
    "print(\"The number of mini-batches formed is = {}\".format(len(mini_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta Initialization \n",
    "#np.random.seed(1)\n",
    "def theta_init(arch=[50]):\n",
    "    theta = []\n",
    "    for i in range(len(arch)+1):\n",
    "        if i == 0:\n",
    "            dim0=n+1\n",
    "            dim1=arch[i]\n",
    "        elif (i == len(arch)):\n",
    "            dim0=arch[i-1]\n",
    "            dim1 = r\n",
    "        else:\n",
    "            dim0=arch[i-1]\n",
    "            dim1= arch[i]\n",
    "        theta.append(np.random.normal(0,0.01, (dim0,dim1)))\n",
    "        #theta.append(0.01*(2*np.random.random((dim0, dim1))-1))\n",
    "        #theta.append(np.zeros((dim0, dim1)))\n",
    "        #theta.append(0.01*np.random.standard_normal((dim0, dim1)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_act(x):\n",
    "    return np.maximum(0.0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_softplus(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_relu(x):\n",
    "    #x[x<=0] = -0.01\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, theta):\n",
    "    fm = []\n",
    "    fm.append(data)\n",
    "    for l in range(len(theta)):\n",
    "        if (l != len(theta)-1):\n",
    "            #print(\"relu\")\n",
    "            fm.append(relu_act(np.dot(fm[l], theta[l])))\n",
    "        else:\n",
    "            fm.append(activation(np.dot(fm[l], theta[l])))\n",
    "            #print(\"sigmoid output\")\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.249991648690502"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta_init([100, 100, 100])\n",
    "print(theta[3].shape)\n",
    "cost_total(X_train, theta, train_class_enc, m)\n",
    "#fm = forward_prop(X_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_total(X, theta, Y, m):\n",
    "    fm = forward_prop(X, theta)\n",
    "    cost = (1/(2*m))*np.sum((Y-fm[-1])**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data, theta, actual_class):\n",
    "    pred_class = forward_prop(data, theta)\n",
    "    test_pred_class = pred_class[-1]\n",
    "    for i in range(len(test_pred_class)):\n",
    "        test_pred_class[i][test_pred_class[i] == np.max(test_pred_class[i])] = 1\n",
    "        test_pred_class[i][test_pred_class[i] != np.max(test_pred_class[i])] = 0\n",
    "\n",
    "\n",
    "    test_acc = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if (np.array_equal(test_pred_class[i], actual_class[i])):\n",
    "            test_acc+=1\n",
    "    test_acc /= data.shape[0]\n",
    "\n",
    "    #print(\"The Test Accuracy of the model = {}%\".format(test_acc*100))\n",
    "    return (test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_accuracy = []\n",
    "valid_accuracy =[]\n",
    "test_accuracy = []\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 100) (100, 100) (100, 26)\n"
     ]
    }
   ],
   "source": [
    "arch=[100, 100]\n",
    "lr=0.1\n",
    "theta = theta_init(arch)\n",
    "print(theta[0].shape, theta[1].shape, theta[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 1 = 3.2501942833744635\n",
      "Error on this batch = 3.2501647437457426\n",
      "Error on this batch = 0.4903101404871288\n",
      "Cost on val dataset after 2 epochs is = 0.4904962491827453\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 2 = 0.4904962491827453\n",
      "Error on this batch = 0.4898654351655779\n",
      "Error on this batch = 0.49084832652871413\n",
      "Cost on val dataset after 3 epochs is = 0.4897246698929074\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 3 = 0.4897246698929074\n",
      "Error on this batch = 0.4891033080706278\n",
      "Error on this batch = 0.4910352164460997\n",
      "Cost on val dataset after 4 epochs is = 0.4893057323191314\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 4 = 0.4893057323191314\n",
      "Error on this batch = 0.4886152608396129\n",
      "Error on this batch = 0.491053676763863\n",
      "Cost on val dataset after 5 epochs is = 0.4889798295174246\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 5 = 0.4889798295174246\n",
      "Error on this batch = 0.48825278791766397\n",
      "Error on this batch = 0.4909475299447998\n",
      "Cost on val dataset after 6 epochs is = 0.4886840098787067\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 6 = 0.4886840098787067\n",
      "Error on this batch = 0.48795221178130105\n",
      "Error on this batch = 0.49075164170179547\n",
      "Cost on val dataset after 7 epochs is = 0.48839429386678695\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 7 = 0.48839429386678695\n",
      "Error on this batch = 0.4876776127426639\n",
      "Error on this batch = 0.4904765765978983\n",
      "Cost on val dataset after 8 epochs is = 0.48809632898292016\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 8 = 0.48809632898292016\n",
      "Error on this batch = 0.4874035032819128\n",
      "Error on this batch = 0.4901241575884383\n",
      "Cost on val dataset after 9 epochs is = 0.4877789502177938\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 9 = 0.4877789502177938\n",
      "Error on this batch = 0.4871208706631957\n",
      "Error on this batch = 0.4896859892242141\n",
      "Cost on val dataset after 10 epochs is = 0.4874286702553238\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 10 = 0.4874286702553238\n",
      "Error on this batch = 0.4868171346388553\n",
      "Error on this batch = 0.48915492271996003\n",
      "Cost on val dataset after 11 epochs is = 0.48703449379623426\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 11 = 0.48703449379623426\n",
      "Error on this batch = 0.48647958012693165\n",
      "Error on this batch = 0.4885305691498644\n",
      "Cost on val dataset after 12 epochs is = 0.4865883162978083\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 12 = 0.4865883162978083\n",
      "Error on this batch = 0.486101668015197\n",
      "Error on this batch = 0.4878166930628378\n",
      "Cost on val dataset after 13 epochs is = 0.48608772161168057\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 13 = 0.48608772161168057\n",
      "Error on this batch = 0.4856770021216576\n",
      "Error on this batch = 0.48702449947630305\n",
      "Cost on val dataset after 14 epochs is = 0.4855349550090619\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 14 = 0.4855349550090619\n",
      "Error on this batch = 0.4851965460983884\n",
      "Error on this batch = 0.48618222608804545\n",
      "Cost on val dataset after 15 epochs is = 0.4849462071821541\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 15 = 0.4849462071821541\n",
      "Error on this batch = 0.4846788141968098\n",
      "Error on this batch = 0.48533347099497665\n",
      "Cost on val dataset after 16 epochs is = 0.48434394745662546\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 16 = 0.48434394745662546\n",
      "Error on this batch = 0.4841453246805946\n",
      "Error on this batch = 0.4845262001701579\n",
      "Cost on val dataset after 17 epochs is = 0.4837539429374862\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 17 = 0.4837539429374862\n",
      "Error on this batch = 0.48361767619606016\n",
      "Error on this batch = 0.48379039683578023\n",
      "Cost on val dataset after 18 epochs is = 0.4832045349408287\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 18 = 0.4832045349408287\n",
      "Error on this batch = 0.4831226277398779\n",
      "Error on this batch = 0.48315381736117374\n",
      "Cost on val dataset after 19 epochs is = 0.48271740634461624\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 19 = 0.48271740634461624\n",
      "Error on this batch = 0.4826810594105584\n",
      "Error on this batch = 0.4826281577475111\n",
      "Cost on val dataset after 20 epochs is = 0.48230596122470093\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 20 = 0.48230596122470093\n",
      "Error on this batch = 0.4823048821905332\n",
      "Error on this batch = 0.48220952897370795\n",
      "Cost on val dataset after 21 epochs is = 0.4819733384919676\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 21 = 0.4819733384919676\n",
      "Error on this batch = 0.48199903003142597\n",
      "Error on this batch = 0.48188448125727384\n",
      "Cost on val dataset after 22 epochs is = 0.4817118408721128\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 22 = 0.4817118408721128\n",
      "Error on this batch = 0.4817573230400538\n",
      "Error on this batch = 0.4816384377677305\n",
      "Cost on val dataset after 23 epochs is = 0.48151015019566884\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 23 = 0.48151015019566884\n",
      "Error on this batch = 0.481567771308966\n",
      "Error on this batch = 0.4814518025340551\n",
      "Cost on val dataset after 24 epochs is = 0.4813566754287103\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 24 = 0.4813566754287103\n",
      "Error on this batch = 0.48141751693010876\n",
      "Error on this batch = 0.48130844443965975\n",
      "Cost on val dataset after 25 epochs is = 0.48124038316622736\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 25 = 0.48124038316622736\n",
      "Error on this batch = 0.4812952272493452\n",
      "Error on this batch = 0.4811956846099611\n",
      "Cost on val dataset after 26 epochs is = 0.4811517991839769\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 26 = 0.4811517991839769\n",
      "Error on this batch = 0.48119335910266947\n",
      "Error on this batch = 0.4811030638481087\n",
      "Cost on val dataset after 27 epochs is = 0.4810840736051089\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 27 = 0.4810840736051089\n",
      "Error on this batch = 0.4811070897119102\n",
      "Error on this batch = 0.4810260178014654\n",
      "Cost on val dataset after 28 epochs is = 0.4810338907498922\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 28 = 0.4810338907498922\n",
      "Error on this batch = 0.48103547658006796\n",
      "Error on this batch = 0.4809626599989031\n",
      "Cost on val dataset after 29 epochs is = 0.4809965946131041\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 29 = 0.4809965946131041\n",
      "Error on this batch = 0.48097628051005986\n",
      "Error on this batch = 0.4809102138044354\n",
      "Cost on val dataset after 30 epochs is = 0.4809685172244342\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 30 = 0.4809685172244342\n",
      "Error on this batch = 0.48092822256334317\n",
      "Error on this batch = 0.48086684839695865\n",
      "Cost on val dataset after 31 epochs is = 0.4809470798705124\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 31 = 0.4809470798705124\n",
      "Error on this batch = 0.4808896743996145\n",
      "Error on this batch = 0.4808311267041892\n",
      "Cost on val dataset after 32 epochs is = 0.4809302615554072\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 32 = 0.4809302615554072\n",
      "Error on this batch = 0.4808590743062041\n",
      "Error on this batch = 0.4808015946075308\n",
      "Cost on val dataset after 33 epochs is = 0.4809163651868098\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 33 = 0.4809163651868098\n",
      "Error on this batch = 0.4808345190345601\n",
      "Error on this batch = 0.4807773028519364\n",
      "Cost on val dataset after 34 epochs is = 0.48090487283426836\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 34 = 0.48090487283426836\n",
      "Error on this batch = 0.48081531476811956\n",
      "Error on this batch = 0.4807573058805697\n",
      "Cost on val dataset after 35 epochs is = 0.48089522147892044\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 35 = 0.48089522147892044\n",
      "Error on this batch = 0.4808001206842236\n",
      "Error on this batch = 0.4807403621120656\n",
      "Cost on val dataset after 36 epochs is = 0.48088645471630165\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 36 = 0.48088645471630165\n",
      "Error on this batch = 0.48078797364644604\n",
      "Error on this batch = 0.4807258686238809\n",
      "Cost on val dataset after 37 epochs is = 0.4808784262955385\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 37 = 0.4808784262955385\n",
      "Error on this batch = 0.4807780147565632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4807131423062389\n",
      "Cost on val dataset after 38 epochs is = 0.48087115764485816\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 38 = 0.48087115764485816\n",
      "Error on this batch = 0.48076955842185326\n",
      "Error on this batch = 0.4807017166197393\n",
      "Cost on val dataset after 39 epochs is = 0.4808642972075116\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 39 = 0.4808642972075116\n",
      "Error on this batch = 0.48076214762231695\n",
      "Error on this batch = 0.48069131214777544\n",
      "Cost on val dataset after 40 epochs is = 0.4808576294008549\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 40 = 0.4808576294008549\n",
      "Error on this batch = 0.48075550286305774\n",
      "Error on this batch = 0.48068173427820854\n",
      "Cost on val dataset after 41 epochs is = 0.4808510091372489\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 41 = 0.4808510091372489\n",
      "Error on this batch = 0.48074942892183486\n",
      "Error on this batch = 0.48067272395704136\n",
      "Cost on val dataset after 42 epochs is = 0.48084437290309306\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 42 = 0.48084437290309306\n",
      "Error on this batch = 0.4807436852722448\n",
      "Error on this batch = 0.4806641067469733\n",
      "Cost on val dataset after 43 epochs is = 0.4808376206988551\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 43 = 0.4808376206988551\n",
      "Error on this batch = 0.4807381703423388\n",
      "Error on this batch = 0.48065565686555534\n",
      "Cost on val dataset after 44 epochs is = 0.48083068249694455\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 44 = 0.48083068249694455\n",
      "Error on this batch = 0.4807327668512517\n",
      "Error on this batch = 0.4806471505699817\n",
      "Cost on val dataset after 45 epochs is = 0.48082348435368966\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 45 = 0.48082348435368966\n",
      "Error on this batch = 0.4807271832546982\n",
      "Error on this batch = 0.48063855753643697\n",
      "Cost on val dataset after 46 epochs is = 0.4808158345241436\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 46 = 0.4808158345241436\n",
      "Error on this batch = 0.4807210743073395\n",
      "Error on this batch = 0.48062965082947573\n",
      "Cost on val dataset after 47 epochs is = 0.4808079229918103\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 47 = 0.4808079229918103\n",
      "Error on this batch = 0.4807149464921135\n",
      "Error on this batch = 0.48062070348986113\n",
      "Cost on val dataset after 48 epochs is = 0.4807998626013618\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 48 = 0.4807998626013618\n",
      "Error on this batch = 0.4807089056692447\n",
      "Error on this batch = 0.4806118022688824\n",
      "Cost on val dataset after 49 epochs is = 0.48079153170161665\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 49 = 0.48079153170161665\n",
      "Error on this batch = 0.48070290091164625\n",
      "Error on this batch = 0.48060278137286916\n",
      "Cost on val dataset after 50 epochs is = 0.480782890627666\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 50 = 0.480782890627666\n",
      "Error on this batch = 0.4806968721974799\n",
      "Error on this batch = 0.48059353905421104\n",
      "Cost on val dataset after 51 epochs is = 0.48077391569726097\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 51 = 0.48077391569726097\n",
      "Error on this batch = 0.48069070940623887\n",
      "Error on this batch = 0.4805840125791976\n",
      "Cost on val dataset after 52 epochs is = 0.48076458427797103\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 52 = 0.48076458427797103\n",
      "Error on this batch = 0.4806844588867559\n",
      "Error on this batch = 0.4805741320715399\n",
      "Cost on val dataset after 53 epochs is = 0.4807548514587055\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 53 = 0.4807548514587055\n",
      "Error on this batch = 0.48067803830934225\n",
      "Error on this batch = 0.4805638454198035\n",
      "Cost on val dataset after 54 epochs is = 0.48074470302300065\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 54 = 0.48074470302300065\n",
      "Error on this batch = 0.4806713494763378\n",
      "Error on this batch = 0.48055307529887037\n",
      "Cost on val dataset after 55 epochs is = 0.4807341154440271\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 55 = 0.4807341154440271\n",
      "Error on this batch = 0.4806644025194093\n",
      "Error on this batch = 0.48054177489993893\n",
      "Cost on val dataset after 56 epochs is = 0.48072299943668034\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 56 = 0.48072299943668034\n",
      "Error on this batch = 0.48065715653142266\n",
      "Error on this batch = 0.48053001211982066\n",
      "Cost on val dataset after 57 epochs is = 0.4807113013760974\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 57 = 0.4807113013760974\n",
      "Error on this batch = 0.48064966585757635\n",
      "Error on this batch = 0.48051771561368173\n",
      "Cost on val dataset after 58 epochs is = 0.4806990335011396\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 58 = 0.4806990335011396\n",
      "Error on this batch = 0.48064204704092095\n",
      "Error on this batch = 0.48050497479630766\n",
      "Cost on val dataset after 59 epochs is = 0.48068615476995247\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 59 = 0.48068615476995247\n",
      "Error on this batch = 0.48063415364851664\n",
      "Error on this batch = 0.48049158387685686\n",
      "Cost on val dataset after 60 epochs is = 0.48067259892222575\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 60 = 0.48067259892222575\n",
      "Error on this batch = 0.48062601244559505\n",
      "Error on this batch = 0.48047753726350834\n",
      "Cost on val dataset after 61 epochs is = 0.48065826658446437\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 61 = 0.48065826658446437\n",
      "Error on this batch = 0.48061754203443535\n",
      "Error on this batch = 0.4804627126528442\n",
      "Cost on val dataset after 62 epochs is = 0.4806427973305944\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 62 = 0.4806427973305944\n",
      "Error on this batch = 0.4806086240098442\n",
      "Error on this batch = 0.48044642367431084\n",
      "Cost on val dataset after 63 epochs is = 0.4806245195475457\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 63 = 0.4806245195475457\n",
      "Error on this batch = 0.4805976053545589\n",
      "Error on this batch = 0.4804272290247992\n",
      "Cost on val dataset after 64 epochs is = 0.4806033971951842\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 64 = 0.4806033971951842\n",
      "Error on this batch = 0.4805845078051915\n",
      "Error on this batch = 0.4804078757784222\n",
      "Cost on val dataset after 65 epochs is = 0.4805828431823462\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 65 = 0.4805828431823462\n",
      "Error on this batch = 0.48057225204525067\n",
      "Error on this batch = 0.48038846270460805\n",
      "Cost on val dataset after 66 epochs is = 0.48056212464646714\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 66 = 0.48056212464646714\n",
      "Error on this batch = 0.4805602104095656\n",
      "Error on this batch = 0.4803678086276015\n",
      "Cost on val dataset after 67 epochs is = 0.480540427195458\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 67 = 0.480540427195458\n",
      "Error on this batch = 0.48054801742585895\n",
      "Error on this batch = 0.48034577731568107\n",
      "Cost on val dataset after 68 epochs is = 0.4805175016790746\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 68 = 0.4805175016790746\n",
      "Error on this batch = 0.48053557808845426\n",
      "Error on this batch = 0.48032247368973774\n",
      "Cost on val dataset after 69 epochs is = 0.4804932221845857\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 69 = 0.4804932221845857\n",
      "Error on this batch = 0.4805226194314656\n",
      "Error on this batch = 0.4802979084718666\n",
      "Cost on val dataset after 70 epochs is = 0.48046749876883904\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 70 = 0.48046749876883904\n",
      "Error on this batch = 0.4805089621071011\n",
      "Error on this batch = 0.48027194777768856\n",
      "Cost on val dataset after 71 epochs is = 0.48044027964735136\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 71 = 0.48044027964735136\n",
      "Error on this batch = 0.48049456117608896\n",
      "Error on this batch = 0.4802445494015607\n",
      "Cost on val dataset after 72 epochs is = 0.4804114783958933\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 72 = 0.4804114783958933\n",
      "Error on this batch = 0.48047946366979477\n",
      "Error on this batch = 0.48021534009570616\n",
      "Cost on val dataset after 73 epochs is = 0.4803809023093086\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 73 = 0.4803809023093086\n",
      "Error on this batch = 0.48046378151336655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4801842545978018\n",
      "Cost on val dataset after 74 epochs is = 0.48034777157399744\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 74 = 0.48034777157399744\n",
      "Error on this batch = 0.4804471282280059\n",
      "Error on this batch = 0.4801507418252814\n",
      "Cost on val dataset after 75 epochs is = 0.4803104696956664\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 75 = 0.4803104696956664\n",
      "Error on this batch = 0.48042818686936145\n",
      "Error on this batch = 0.4801151566252274\n",
      "Cost on val dataset after 76 epochs is = 0.4802708197361791\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 76 = 0.4802708197361791\n",
      "Error on this batch = 0.4804082516592958\n",
      "Error on this batch = 0.4800775129474337\n",
      "Cost on val dataset after 77 epochs is = 0.48022876652870866\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 77 = 0.48022876652870866\n",
      "Error on this batch = 0.48038712726206984\n",
      "Error on this batch = 0.48003682309196294\n",
      "Cost on val dataset after 78 epochs is = 0.480183677011897\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 78 = 0.480183677011897\n",
      "Error on this batch = 0.48036482073980497\n",
      "Error on this batch = 0.4799925727695312\n",
      "Cost on val dataset after 79 epochs is = 0.48013550975973096\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 79 = 0.48013550975973096\n",
      "Error on this batch = 0.4803406510643377\n",
      "Error on this batch = 0.4799448355290295\n",
      "Cost on val dataset after 80 epochs is = 0.48008443924681077\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 80 = 0.48008443924681077\n",
      "Error on this batch = 0.4803153111798871\n",
      "Error on this batch = 0.4798939322223605\n",
      "Cost on val dataset after 81 epochs is = 0.48003010726390855\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 81 = 0.48003010726390855\n",
      "Error on this batch = 0.4802893143788964\n",
      "Error on this batch = 0.4798397954950863\n",
      "Cost on val dataset after 82 epochs is = 0.47997165925453655\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 82 = 0.47997165925453655\n",
      "Error on this batch = 0.4802621813581193\n",
      "Error on this batch = 0.4797804602000417\n",
      "Cost on val dataset after 83 epochs is = 0.47990782933589876\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 83 = 0.47990782933589876\n",
      "Error on this batch = 0.48023282966479314\n",
      "Error on this batch = 0.4797153412274001\n",
      "Cost on val dataset after 84 epochs is = 0.479839492200478\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 84 = 0.479839492200478\n",
      "Error on this batch = 0.4802018568766663\n",
      "Error on this batch = 0.4796471432836342\n",
      "Cost on val dataset after 85 epochs is = 0.47976719904694315\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 85 = 0.47976719904694315\n",
      "Error on this batch = 0.48017059160102166\n",
      "Error on this batch = 0.47957512788617274\n",
      "Cost on val dataset after 86 epochs is = 0.47968996684570825\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 86 = 0.47968996684570825\n",
      "Error on this batch = 0.480138453501189\n",
      "Error on this batch = 0.47949807589519583\n",
      "Cost on val dataset after 87 epochs is = 0.4796069941729735\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 87 = 0.4796069941729735\n",
      "Error on this batch = 0.48010541173472276\n",
      "Error on this batch = 0.4794150524635431\n",
      "Cost on val dataset after 88 epochs is = 0.47951773954711063\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 88 = 0.47951773954711063\n",
      "Error on this batch = 0.4800711405585606\n",
      "Error on this batch = 0.47932563502324366\n",
      "Cost on val dataset after 89 epochs is = 0.4794215034618349\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 89 = 0.4794215034618349\n",
      "Error on this batch = 0.4800354083060304\n",
      "Error on this batch = 0.4792288722868288\n",
      "Cost on val dataset after 90 epochs is = 0.47931760701339765\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 90 = 0.47931760701339765\n",
      "Error on this batch = 0.47999756582198044\n",
      "Error on this batch = 0.4791237360499316\n",
      "Cost on val dataset after 91 epochs is = 0.47920532593506904\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 91 = 0.47920532593506904\n",
      "Error on this batch = 0.47995750618555044\n",
      "Error on this batch = 0.47901003303920314\n",
      "Cost on val dataset after 92 epochs is = 0.4790837114429668\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 92 = 0.4790837114429668\n",
      "Error on this batch = 0.4799153220086278\n",
      "Error on this batch = 0.4788861355143089\n",
      "Cost on val dataset after 93 epochs is = 0.47895211161396345\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 93 = 0.47895211161396345\n",
      "Error on this batch = 0.4798717078388885\n",
      "Error on this batch = 0.47875130794088877\n",
      "Cost on val dataset after 94 epochs is = 0.4788093104614048\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 94 = 0.4788093104614048\n",
      "Error on this batch = 0.4798253946902685\n",
      "Error on this batch = 0.4786039318864893\n",
      "Cost on val dataset after 95 epochs is = 0.4786541063483425\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 95 = 0.4786541063483425\n",
      "Error on this batch = 0.4797763688095467\n",
      "Error on this batch = 0.47844302100045244\n",
      "Cost on val dataset after 96 epochs is = 0.4784851927706455\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 96 = 0.4784851927706455\n",
      "Error on this batch = 0.4797238843073184\n",
      "Error on this batch = 0.4782664325944531\n",
      "Cost on val dataset after 97 epochs is = 0.47830050714835787\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 97 = 0.47830050714835787\n",
      "Error on this batch = 0.4796680586723481\n",
      "Error on this batch = 0.47807250077702734\n",
      "Cost on val dataset after 98 epochs is = 0.4780983265308253\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 98 = 0.4780983265308253\n",
      "Error on this batch = 0.47960881148769974\n",
      "Error on this batch = 0.4778600192987999\n",
      "Cost on val dataset after 99 epochs is = 0.47787658638628605\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 99 = 0.47787658638628605\n",
      "Error on this batch = 0.4795444217393559\n",
      "Error on this batch = 0.4776249036336388\n",
      "Cost on val dataset after 100 epochs is = 0.477632602664975\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 100 = 0.477632602664975\n",
      "Error on this batch = 0.47947418499921035\n",
      "Error on this batch = 0.47736244689086577\n",
      "Cost on val dataset after 101 epochs is = 0.47736391436803494\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 101 = 0.47736391436803494\n",
      "Error on this batch = 0.4793988382554919\n",
      "Error on this batch = 0.47707309904239\n",
      "Cost on val dataset after 102 epochs is = 0.47706718096003575\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 102 = 0.47706718096003575\n",
      "Error on this batch = 0.479315065308801\n",
      "Error on this batch = 0.4767510465794819\n",
      "Cost on val dataset after 103 epochs is = 0.47673889539895353\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 103 = 0.47673889539895353\n",
      "Error on this batch = 0.4792219665999246\n",
      "Error on this batch = 0.47639204493591863\n",
      "Cost on val dataset after 104 epochs is = 0.47637448869911814\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 104 = 0.47637448869911814\n",
      "Error on this batch = 0.4791170234834572\n",
      "Error on this batch = 0.47598884829965543\n",
      "Cost on val dataset after 105 epochs is = 0.4759689617816954\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 105 = 0.4759689617816954\n",
      "Error on this batch = 0.47899706994195074\n",
      "Error on this batch = 0.47554040324648983\n",
      "Cost on val dataset after 106 epochs is = 0.47551793728260394\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 106 = 0.47551793728260394\n",
      "Error on this batch = 0.478859482219018\n",
      "Error on this batch = 0.47503605323334347\n",
      "Cost on val dataset after 107 epochs is = 0.4750154299100932\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 107 = 0.4750154299100932\n",
      "Error on this batch = 0.4787001249721363\n",
      "Error on this batch = 0.47447222190652144\n",
      "Cost on val dataset after 108 epochs is = 0.4744565640028046\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 108 = 0.4744565640028046\n",
      "Error on this batch = 0.4785151300682383\n",
      "Error on this batch = 0.473838482580449\n",
      "Cost on val dataset after 109 epochs is = 0.47383504576723406\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 109 = 0.47383504576723406\n",
      "Error on this batch = 0.47829875181561354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4731268176147729\n",
      "Cost on val dataset after 110 epochs is = 0.4731426409854353\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 110 = 0.4731426409854353\n",
      "Error on this batch = 0.4780418264987927\n",
      "Error on this batch = 0.47233705352768013\n",
      "Cost on val dataset after 111 epochs is = 0.4723741224053634\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 111 = 0.4723741224053634\n",
      "Error on this batch = 0.4777406610109991\n",
      "Error on this batch = 0.47145556195323546\n",
      "Cost on val dataset after 112 epochs is = 0.471522430472345\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 112 = 0.471522430472345\n",
      "Error on this batch = 0.4773780898575497\n",
      "Error on this batch = 0.4704828525749929\n",
      "Cost on val dataset after 113 epochs is = 0.47058386220639814\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 113 = 0.47058386220639814\n",
      "Error on this batch = 0.4769477596613041\n",
      "Error on this batch = 0.4694116819018925\n",
      "Cost on val dataset after 114 epochs is = 0.4695584353690608\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 114 = 0.4695584353690608\n",
      "Error on this batch = 0.4764358607180337\n",
      "Error on this batch = 0.4682319360287025\n",
      "Cost on val dataset after 115 epochs is = 0.46844796683612155\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 115 = 0.46844796683612155\n",
      "Error on this batch = 0.4758471335672978\n",
      "Error on this batch = 0.46697056589370506\n",
      "Cost on val dataset after 116 epochs is = 0.46726116358128167\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 116 = 0.46726116358128167\n",
      "Error on this batch = 0.47518208080627944\n",
      "Error on this batch = 0.46562428557238833\n",
      "Cost on val dataset after 117 epochs is = 0.4660111790703451\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 117 = 0.4660111790703451\n",
      "Error on this batch = 0.4744399591242041\n",
      "Error on this batch = 0.46421463053073864\n",
      "Cost on val dataset after 118 epochs is = 0.4647086908150542\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 118 = 0.4647086908150542\n",
      "Error on this batch = 0.47364382990711057\n",
      "Error on this batch = 0.46275771412823236\n",
      "Cost on val dataset after 119 epochs is = 0.46336459032093613\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 119 = 0.46336459032093613\n",
      "Error on this batch = 0.4728136024333628\n",
      "Error on this batch = 0.46127039233119577\n",
      "Cost on val dataset after 120 epochs is = 0.46200280282877915\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 120 = 0.46200280282877915\n",
      "Error on this batch = 0.47198168175829425\n",
      "Error on this batch = 0.4597785968388495\n",
      "Cost on val dataset after 121 epochs is = 0.4606268132347808\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 121 = 0.4606268132347808\n",
      "Error on this batch = 0.4711379405509185\n",
      "Error on this batch = 0.458281278299868\n",
      "Cost on val dataset after 122 epochs is = 0.45924543584243804\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 122 = 0.45924543584243804\n",
      "Error on this batch = 0.47029428964774356\n",
      "Error on this batch = 0.4567701464367275\n",
      "Cost on val dataset after 123 epochs is = 0.45786663255006815\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 123 = 0.45786663255006815\n",
      "Error on this batch = 0.46945468232462245\n",
      "Error on this batch = 0.4552508888880262\n",
      "Cost on val dataset after 124 epochs is = 0.4564878479566891\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 124 = 0.4564878479566891\n",
      "Error on this batch = 0.4686239316942111\n",
      "Error on this batch = 0.4537040493107838\n",
      "Cost on val dataset after 125 epochs is = 0.4551037306559656\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 125 = 0.4551037306559656\n",
      "Error on this batch = 0.46778539151467785\n",
      "Error on this batch = 0.45213149382944623\n",
      "Cost on val dataset after 126 epochs is = 0.4537100027527642\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 126 = 0.4537100027527642\n",
      "Error on this batch = 0.4669380875015745\n",
      "Error on this batch = 0.45050778630720645\n",
      "Cost on val dataset after 127 epochs is = 0.45227774463355735\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 127 = 0.45227774463355735\n",
      "Error on this batch = 0.46607701916496647\n",
      "Error on this batch = 0.4488345817245585\n",
      "Cost on val dataset after 128 epochs is = 0.4507996135203012\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 128 = 0.4507996135203012\n",
      "Error on this batch = 0.4651739727175195\n",
      "Error on this batch = 0.44707567048092656\n",
      "Cost on val dataset after 129 epochs is = 0.4492648574271718\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 129 = 0.4492648574271718\n",
      "Error on this batch = 0.46422849203493133\n",
      "Error on this batch = 0.44522827582475755\n",
      "Cost on val dataset after 130 epochs is = 0.44766227756472365\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 130 = 0.44766227756472365\n",
      "Error on this batch = 0.46322326222308013\n",
      "Error on this batch = 0.44329078040636677\n",
      "Cost on val dataset after 131 epochs is = 0.4459756327343019\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 131 = 0.4459756327343019\n",
      "Error on this batch = 0.4621492549369123\n",
      "Error on this batch = 0.44125730706842786\n",
      "Cost on val dataset after 132 epochs is = 0.44421217037919136\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 132 = 0.44421217037919136\n",
      "Error on this batch = 0.46099224360442137\n",
      "Error on this batch = 0.43910901597745766\n",
      "Cost on val dataset after 133 epochs is = 0.4423634458892519\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 133 = 0.4423634458892519\n",
      "Error on this batch = 0.45974869999937584\n",
      "Error on this batch = 0.43682658965003046\n",
      "Cost on val dataset after 134 epochs is = 0.44043051746938094\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 134 = 0.44043051746938094\n",
      "Error on this batch = 0.45839536897327565\n",
      "Error on this batch = 0.4344121002065087\n",
      "Cost on val dataset after 135 epochs is = 0.4384192920263918\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 135 = 0.4384192920263918\n",
      "Error on this batch = 0.45694105397690776\n",
      "Error on this batch = 0.43188431804994054\n",
      "Cost on val dataset after 136 epochs is = 0.4363345273934321\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 136 = 0.4363345273934321\n",
      "Error on this batch = 0.45538339777170467\n",
      "Error on this batch = 0.4292263516982767\n",
      "Cost on val dataset after 137 epochs is = 0.4341875257382176\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 137 = 0.4341875257382176\n",
      "Error on this batch = 0.45373130640262493\n",
      "Error on this batch = 0.42646689225609347\n",
      "Cost on val dataset after 138 epochs is = 0.43198477800237756\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 138 = 0.43198477800237756\n",
      "Error on this batch = 0.4519971982088725\n",
      "Error on this batch = 0.42360290704854153\n",
      "Cost on val dataset after 139 epochs is = 0.42972816684931325\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 139 = 0.42972816684931325\n",
      "Error on this batch = 0.45017505565205795\n",
      "Error on this batch = 0.4206876554946043\n",
      "Cost on val dataset after 140 epochs is = 0.4274275870411553\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 140 = 0.4274275870411553\n",
      "Error on this batch = 0.4482818936278639\n",
      "Error on this batch = 0.4177151156887106\n",
      "Cost on val dataset after 141 epochs is = 0.42509294561539096\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 141 = 0.42509294561539096\n",
      "Error on this batch = 0.446303747952323\n",
      "Error on this batch = 0.4146988835288951\n",
      "Cost on val dataset after 142 epochs is = 0.4227109576961304\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 142 = 0.4227109576961304\n",
      "Error on this batch = 0.44422460579701667\n",
      "Error on this batch = 0.4116463339081421\n",
      "Cost on val dataset after 143 epochs is = 0.42030227698479405\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 143 = 0.42030227698479405\n",
      "Error on this batch = 0.4420859582584042\n",
      "Error on this batch = 0.4085781747006634\n",
      "Cost on val dataset after 144 epochs is = 0.4178636485240263\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 144 = 0.4178636485240263\n",
      "Error on this batch = 0.4398802522008029\n",
      "Error on this batch = 0.4055068389229393\n",
      "Cost on val dataset after 145 epochs is = 0.4154231810314725\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 145 = 0.4154231810314725\n",
      "Error on this batch = 0.43762415415120515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.4025103032219744\n",
      "Cost on val dataset after 146 epochs is = 0.4129984389575961\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 146 = 0.4129984389575961\n",
      "Error on this batch = 0.4353743841397713\n",
      "Error on this batch = 0.3995979029673724\n",
      "Cost on val dataset after 147 epochs is = 0.41061022310331147\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 147 = 0.41061022310331147\n",
      "Error on this batch = 0.4331406638028389\n",
      "Error on this batch = 0.3967828923103507\n",
      "Cost on val dataset after 148 epochs is = 0.408280602258144\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 148 = 0.408280602258144\n",
      "Error on this batch = 0.4309699868656014\n",
      "Error on this batch = 0.3940985312820536\n",
      "Cost on val dataset after 149 epochs is = 0.40601951775991824\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 149 = 0.40601951775991824\n",
      "Error on this batch = 0.4288708240025868\n",
      "Error on this batch = 0.3915611287183118\n",
      "Cost on val dataset after 150 epochs is = 0.4038322438102619\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 150 = 0.4038322438102619\n",
      "Error on this batch = 0.4268408440084553\n",
      "Error on this batch = 0.38914824128046477\n",
      "Cost on val dataset after 151 epochs is = 0.40171304759653637\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 151 = 0.40171304759653637\n",
      "Error on this batch = 0.42485972598025135\n",
      "Error on this batch = 0.3868476672886142\n",
      "Cost on val dataset after 152 epochs is = 0.3996635640974845\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 152 = 0.3996635640974845\n",
      "Error on this batch = 0.4229513173926685\n",
      "Error on this batch = 0.38468167741359743\n",
      "Cost on val dataset after 153 epochs is = 0.39768052612008015\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 153 = 0.39768052612008015\n",
      "Error on this batch = 0.4211155518940191\n",
      "Error on this batch = 0.3825958963038715\n",
      "Cost on val dataset after 154 epochs is = 0.3957558385820779\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 154 = 0.3957558385820779\n",
      "Error on this batch = 0.41931767198185554\n",
      "Error on this batch = 0.3806008696763982\n",
      "Cost on val dataset after 155 epochs is = 0.39388002149769824\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 155 = 0.39388002149769824\n",
      "Error on this batch = 0.41756391326649933\n",
      "Error on this batch = 0.378694717701322\n",
      "Cost on val dataset after 156 epochs is = 0.3920551071276609\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 156 = 0.3920551071276609\n",
      "Error on this batch = 0.41584572680043835\n",
      "Error on this batch = 0.37685870826797563\n",
      "Cost on val dataset after 157 epochs is = 0.39028288989368737\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 157 = 0.39028288989368737\n",
      "Error on this batch = 0.4141574904475354\n",
      "Error on this batch = 0.37509248543135104\n",
      "Cost on val dataset after 158 epochs is = 0.3885589598659879\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 158 = 0.3885589598659879\n",
      "Error on this batch = 0.4124853745092793\n",
      "Error on this batch = 0.37337727621226735\n",
      "Cost on val dataset after 159 epochs is = 0.38687388251809884\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 159 = 0.38687388251809884\n",
      "Error on this batch = 0.4108204324257054\n",
      "Error on this batch = 0.37173180953979523\n",
      "Cost on val dataset after 160 epochs is = 0.38522894229388044\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 160 = 0.38522894229388044\n",
      "Error on this batch = 0.40916359929317236\n",
      "Error on this batch = 0.37013453857370904\n",
      "Cost on val dataset after 161 epochs is = 0.38362549217922237\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 161 = 0.38362549217922237\n",
      "Error on this batch = 0.4075300551323518\n",
      "Error on this batch = 0.3685882708864462\n",
      "Cost on val dataset after 162 epochs is = 0.38205285367223984\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 162 = 0.38205285367223984\n",
      "Error on this batch = 0.40587737046833755\n",
      "Error on this batch = 0.36707893613923875\n",
      "Cost on val dataset after 163 epochs is = 0.3805076157445808\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 163 = 0.3805076157445808\n",
      "Error on this batch = 0.40423224398154817\n",
      "Error on this batch = 0.3656030460444783\n",
      "Cost on val dataset after 164 epochs is = 0.3789889830521629\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 164 = 0.3789889830521629\n",
      "Error on this batch = 0.4025907551874991\n",
      "Error on this batch = 0.3641711102621028\n",
      "Cost on val dataset after 165 epochs is = 0.3775010456233824\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 165 = 0.3775010456233824\n",
      "Error on this batch = 0.40096514603279604\n",
      "Error on this batch = 0.3627635629289453\n",
      "Cost on val dataset after 166 epochs is = 0.3760379179378872\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 166 = 0.3760379179378872\n",
      "Error on this batch = 0.39934412339099246\n",
      "Error on this batch = 0.3613662481806594\n",
      "Cost on val dataset after 167 epochs is = 0.3745969404920015\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 167 = 0.3745969404920015\n",
      "Error on this batch = 0.3977199021703717\n",
      "Error on this batch = 0.35999384768339826\n",
      "Cost on val dataset after 168 epochs is = 0.37318372461230065\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 168 = 0.37318372461230065\n",
      "Error on this batch = 0.39609773369861373\n",
      "Error on this batch = 0.35864538299377274\n",
      "Cost on val dataset after 169 epochs is = 0.3717914280994046\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 169 = 0.3717914280994046\n",
      "Error on this batch = 0.3944669570349673\n",
      "Error on this batch = 0.35731956471237086\n",
      "Cost on val dataset after 170 epochs is = 0.3704158572796231\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 170 = 0.3704158572796231\n",
      "Error on this batch = 0.3928495004525381\n",
      "Error on this batch = 0.35600722312477856\n",
      "Cost on val dataset after 171 epochs is = 0.36905776586462896\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 171 = 0.36905776586462896\n",
      "Error on this batch = 0.39122651786182844\n",
      "Error on this batch = 0.3547310251893539\n",
      "Cost on val dataset after 172 epochs is = 0.3677192378222202\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 172 = 0.3677192378222202\n",
      "Error on this batch = 0.38959822220240364\n",
      "Error on this batch = 0.35348393705194286\n",
      "Cost on val dataset after 173 epochs is = 0.3664023945604871\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 173 = 0.3664023945604871\n",
      "Error on this batch = 0.38796860702644453\n",
      "Error on this batch = 0.3522465426124218\n",
      "Cost on val dataset after 174 epochs is = 0.36510625173792266\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 174 = 0.36510625173792266\n",
      "Error on this batch = 0.38634598033107254\n",
      "Error on this batch = 0.35100981581126006\n",
      "Cost on val dataset after 175 epochs is = 0.3638213462602962\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 175 = 0.3638213462602962\n",
      "Error on this batch = 0.38471464008996153\n",
      "Error on this batch = 0.34979152066348973\n",
      "Cost on val dataset after 176 epochs is = 0.3625548199300618\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 176 = 0.3625548199300618\n",
      "Error on this batch = 0.3830745417147447\n",
      "Error on this batch = 0.34857924775697846\n",
      "Cost on val dataset after 177 epochs is = 0.3613051934304402\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 177 = 0.3613051934304402\n",
      "Error on this batch = 0.38144448275975246\n",
      "Error on this batch = 0.34736413130800253\n",
      "Cost on val dataset after 178 epochs is = 0.36007218350375103\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 178 = 0.36007218350375103\n",
      "Error on this batch = 0.37978859938116394\n",
      "Error on this batch = 0.3461565743947634\n",
      "Cost on val dataset after 179 epochs is = 0.3588525453487416\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 179 = 0.3588525453487416\n",
      "Error on this batch = 0.3781687976905894\n",
      "Error on this batch = 0.34494240544174887\n",
      "Cost on val dataset after 180 epochs is = 0.35765176099401025\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 180 = 0.35765176099401025\n",
      "Error on this batch = 0.37653715722414105\n",
      "Error on this batch = 0.3437349311370228\n",
      "Cost on val dataset after 181 epochs is = 0.3564690151836313\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 181 = 0.3564690151836313\n",
      "Error on this batch = 0.37491963604422424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.3425239656819109\n",
      "Cost on val dataset after 182 epochs is = 0.35530097558013174\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 182 = 0.35530097558013174\n",
      "Error on this batch = 0.37331902612997203\n",
      "Error on this batch = 0.34131690524801017\n",
      "Cost on val dataset after 183 epochs is = 0.35414826263521154\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 183 = 0.35414826263521154\n",
      "Error on this batch = 0.37172881408530517\n",
      "Error on this batch = 0.34011572986149935\n",
      "Cost on val dataset after 184 epochs is = 0.35300769149034145\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 184 = 0.35300769149034145\n",
      "Error on this batch = 0.37015230583583064\n",
      "Error on this batch = 0.3389161879952484\n",
      "Cost on val dataset after 185 epochs is = 0.351890980696997\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 185 = 0.351890980696997\n",
      "Error on this batch = 0.36859099023734887\n",
      "Error on this batch = 0.3377216822691453\n",
      "Cost on val dataset after 186 epochs is = 0.35078686598368397\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 186 = 0.35078686598368397\n",
      "Error on this batch = 0.3670501545438683\n",
      "Error on this batch = 0.3365476817390807\n",
      "Cost on val dataset after 187 epochs is = 0.34970237693214107\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 187 = 0.34970237693214107\n",
      "Error on this batch = 0.3655224892660469\n",
      "Error on this batch = 0.33539670886145606\n",
      "Cost on val dataset after 188 epochs is = 0.34863443416262946\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 188 = 0.34863443416262946\n",
      "Error on this batch = 0.36400338464371546\n",
      "Error on this batch = 0.3342384690173274\n",
      "Cost on val dataset after 189 epochs is = 0.34758647410942756\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 189 = 0.34758647410942756\n",
      "Error on this batch = 0.36249508921388257\n",
      "Error on this batch = 0.3330923902556649\n",
      "Cost on val dataset after 190 epochs is = 0.34654658122862786\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 190 = 0.34654658122862786\n",
      "Error on this batch = 0.36101082376940236\n",
      "Error on this batch = 0.3319665634602128\n",
      "Cost on val dataset after 191 epochs is = 0.34551803807632137\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 191 = 0.34551803807632137\n",
      "Error on this batch = 0.3595245557503677\n",
      "Error on this batch = 0.3308314285270372\n",
      "Cost on val dataset after 192 epochs is = 0.3445043897205028\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 192 = 0.3445043897205028\n",
      "Error on this batch = 0.3580623114180003\n",
      "Error on this batch = 0.3297196867152664\n",
      "Cost on val dataset after 193 epochs is = 0.34350292572687025\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 193 = 0.34350292572687025\n",
      "Error on this batch = 0.3566115974061338\n",
      "Error on this batch = 0.3286097233851162\n",
      "Cost on val dataset after 194 epochs is = 0.34251257396641854\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 194 = 0.34251257396641854\n",
      "Error on this batch = 0.35516787987284537\n",
      "Error on this batch = 0.3275133738061248\n",
      "Cost on val dataset after 195 epochs is = 0.3415363441443469\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 195 = 0.3415363441443469\n",
      "Error on this batch = 0.35374164403040026\n",
      "Error on this batch = 0.32642382951562987\n",
      "Cost on val dataset after 196 epochs is = 0.3405640563690915\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 196 = 0.3405640563690915\n",
      "Error on this batch = 0.3523216010084665\n",
      "Error on this batch = 0.3253439308854243\n",
      "Cost on val dataset after 197 epochs is = 0.3396117355660857\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 197 = 0.3396117355660857\n",
      "Error on this batch = 0.35094246530666623\n",
      "Error on this batch = 0.32425956805205386\n",
      "Cost on val dataset after 198 epochs is = 0.338669460391367\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 198 = 0.338669460391367\n",
      "Error on this batch = 0.3495706519410834\n",
      "Error on this batch = 0.32319283985282105\n",
      "Cost on val dataset after 199 epochs is = 0.3377365068500503\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 199 = 0.3377365068500503\n",
      "Error on this batch = 0.3482141372375493\n",
      "Error on this batch = 0.322126959948929\n",
      "Cost on val dataset after 200 epochs is = 0.33681475691129564\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 200 = 0.33681475691129564\n",
      "Error on this batch = 0.34686019717282035\n",
      "Error on this batch = 0.3210753262018557\n",
      "Cost on val dataset after 201 epochs is = 0.3359080128584548\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 201 = 0.3359080128584548\n",
      "Error on this batch = 0.3455385611984514\n",
      "Error on this batch = 0.3200360038299297\n",
      "Cost on val dataset after 202 epochs is = 0.33501002034437827\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 202 = 0.33501002034437827\n",
      "Error on this batch = 0.34422280913193376\n",
      "Error on this batch = 0.31900386976498096\n",
      "Cost on val dataset after 203 epochs is = 0.3341170738043947\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 203 = 0.3341170738043947\n",
      "Error on this batch = 0.34290953315601763\n",
      "Error on this batch = 0.3179717389265149\n",
      "Cost on val dataset after 204 epochs is = 0.3332288548032654\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 204 = 0.3332288548032654\n",
      "Error on this batch = 0.3416184991667484\n",
      "Error on this batch = 0.3169369299327168\n",
      "Cost on val dataset after 205 epochs is = 0.3323414272142951\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 205 = 0.3323414272142951\n",
      "Error on this batch = 0.3403256203633035\n",
      "Error on this batch = 0.3159021893426372\n",
      "Cost on val dataset after 206 epochs is = 0.3314551805512544\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 206 = 0.3314551805512544\n",
      "Error on this batch = 0.33903820576538346\n",
      "Error on this batch = 0.3148580770537443\n",
      "Cost on val dataset after 207 epochs is = 0.33057631478364036\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 207 = 0.33057631478364036\n",
      "Error on this batch = 0.33775775400508146\n",
      "Error on this batch = 0.31382067575808026\n",
      "Cost on val dataset after 208 epochs is = 0.3296994393310419\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 208 = 0.3296994393310419\n",
      "Error on this batch = 0.33649024086614043\n",
      "Error on this batch = 0.3127749904398438\n",
      "Cost on val dataset after 209 epochs is = 0.3288289603829034\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 209 = 0.3288289603829034\n",
      "Error on this batch = 0.33522016343819816\n",
      "Error on this batch = 0.31174805721591214\n",
      "Cost on val dataset after 210 epochs is = 0.3279634187081006\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 210 = 0.3279634187081006\n",
      "Error on this batch = 0.3339580153535961\n",
      "Error on this batch = 0.3107192095332403\n",
      "Cost on val dataset after 211 epochs is = 0.3270972260349827\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 211 = 0.3270972260349827\n",
      "Error on this batch = 0.33269072273559863\n",
      "Error on this batch = 0.30967216717827833\n",
      "Cost on val dataset after 212 epochs is = 0.32624046998422385\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 212 = 0.32624046998422385\n",
      "Error on this batch = 0.3314442076148611\n",
      "Error on this batch = 0.30865190860204356\n",
      "Cost on val dataset after 213 epochs is = 0.3253827625520436\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 213 = 0.3253827625520436\n",
      "Error on this batch = 0.3301981584267584\n",
      "Error on this batch = 0.307616684171619\n",
      "Cost on val dataset after 214 epochs is = 0.3245293428384492\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 214 = 0.3245293428384492\n",
      "Error on this batch = 0.3289682839953821\n",
      "Error on this batch = 0.30657617345565213\n",
      "Cost on val dataset after 215 epochs is = 0.32366943750767796\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 215 = 0.32366943750767796\n",
      "Error on this batch = 0.3277311607672281\n",
      "Error on this batch = 0.3055395751465059\n",
      "Cost on val dataset after 216 epochs is = 0.32281503355319496\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 216 = 0.32281503355319496\n",
      "Error on this batch = 0.3265042582653203\n",
      "Error on this batch = 0.3044997728937211\n",
      "Cost on val dataset after 217 epochs is = 0.3219668785551467\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 217 = 0.3219668785551467\n",
      "Error on this batch = 0.32528574941484073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.3034721201973825\n",
      "Cost on val dataset after 218 epochs is = 0.3211164288964928\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 218 = 0.3211164288964928\n",
      "Error on this batch = 0.32406479425459156\n",
      "Error on this batch = 0.3024491785595373\n",
      "Cost on val dataset after 219 epochs is = 0.3202779717920785\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 219 = 0.3202779717920785\n",
      "Error on this batch = 0.3228579814855675\n",
      "Error on this batch = 0.30142929503077937\n",
      "Cost on val dataset after 220 epochs is = 0.31943511362152927\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 220 = 0.31943511362152927\n",
      "Error on this batch = 0.3216508564257965\n",
      "Error on this batch = 0.30042458691219376\n",
      "Cost on val dataset after 221 epochs is = 0.31859463249922454\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 221 = 0.31859463249922454\n",
      "Error on this batch = 0.32045324751093757\n",
      "Error on this batch = 0.29943444919569323\n",
      "Cost on val dataset after 222 epochs is = 0.31777085705677227\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 222 = 0.31777085705677227\n",
      "Error on this batch = 0.31928668836994917\n",
      "Error on this batch = 0.2984451197048112\n",
      "Cost on val dataset after 223 epochs is = 0.31694511092108824\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 223 = 0.31694511092108824\n",
      "Error on this batch = 0.3181276591870803\n",
      "Error on this batch = 0.2974682743585467\n",
      "Cost on val dataset after 224 epochs is = 0.31612271516180124\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 224 = 0.31612271516180124\n",
      "Error on this batch = 0.3169715665706657\n",
      "Error on this batch = 0.29649231455603775\n",
      "Cost on val dataset after 225 epochs is = 0.3153103901686336\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 225 = 0.3153103901686336\n",
      "Error on this batch = 0.3158492439150015\n",
      "Error on this batch = 0.29551866189277376\n",
      "Cost on val dataset after 226 epochs is = 0.3145003714188074\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 226 = 0.3145003714188074\n",
      "Error on this batch = 0.3147240309782913\n",
      "Error on this batch = 0.29454491142312883\n",
      "Cost on val dataset after 227 epochs is = 0.3137074594502213\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 227 = 0.3137074594502213\n",
      "Error on this batch = 0.3136321236372389\n",
      "Error on this batch = 0.29358208056386526\n",
      "Cost on val dataset after 228 epochs is = 0.3129062640133234\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 228 = 0.3129062640133234\n",
      "Error on this batch = 0.31252796028268287\n",
      "Error on this batch = 0.2926258622169757\n",
      "Cost on val dataset after 229 epochs is = 0.31213264352139153\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 229 = 0.31213264352139153\n",
      "Error on this batch = 0.3114723907741069\n",
      "Error on this batch = 0.2916687982584318\n",
      "Cost on val dataset after 230 epochs is = 0.3113481286426571\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 230 = 0.3113481286426571\n",
      "Error on this batch = 0.3104017477465594\n",
      "Error on this batch = 0.29072267190969797\n",
      "Cost on val dataset after 231 epochs is = 0.310576002997444\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 231 = 0.310576002997444\n",
      "Error on this batch = 0.30936878609899615\n",
      "Error on this batch = 0.28978096660804287\n",
      "Cost on val dataset after 232 epochs is = 0.30979773319012116\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 232 = 0.30979773319012116\n",
      "Error on this batch = 0.30833340921360697\n",
      "Error on this batch = 0.2888408456582189\n",
      "Cost on val dataset after 233 epochs is = 0.3090319818175873\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 233 = 0.3090319818175873\n",
      "Error on this batch = 0.30731441615703786\n",
      "Error on this batch = 0.28790267385600027\n",
      "Cost on val dataset after 234 epochs is = 0.30825851686169214\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 234 = 0.30825851686169214\n",
      "Error on this batch = 0.30630202252331484\n",
      "Error on this batch = 0.28698213065897016\n",
      "Cost on val dataset after 235 epochs is = 0.30748083278927957\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 235 = 0.30748083278927957\n",
      "Error on this batch = 0.30528639305313526\n",
      "Error on this batch = 0.2860830574395936\n",
      "Cost on val dataset after 236 epochs is = 0.30671164198572454\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 236 = 0.30671164198572454\n",
      "Error on this batch = 0.30429334663143304\n",
      "Error on this batch = 0.2851803426192385\n",
      "Cost on val dataset after 237 epochs is = 0.30592726918542357\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 237 = 0.30592726918542357\n",
      "Error on this batch = 0.3032938797590961\n",
      "Error on this batch = 0.2842739898424928\n",
      "Cost on val dataset after 238 epochs is = 0.30512759572239223\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 238 = 0.30512759572239223\n",
      "Error on this batch = 0.302297344916856\n",
      "Error on this batch = 0.2833709533898676\n",
      "Cost on val dataset after 239 epochs is = 0.30433135770134234\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 239 = 0.30433135770134234\n",
      "Error on this batch = 0.30129832017227687\n",
      "Error on this batch = 0.2824509919339585\n",
      "Cost on val dataset after 240 epochs is = 0.30350719953006994\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 240 = 0.30350719953006994\n",
      "Error on this batch = 0.3002807043992223\n",
      "Error on this batch = 0.2815469405064659\n",
      "Cost on val dataset after 241 epochs is = 0.30267166016405483\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 241 = 0.30267166016405483\n",
      "Error on this batch = 0.29925214484053464\n",
      "Error on this batch = 0.28066455434890303\n",
      "Cost on val dataset after 242 epochs is = 0.30185180413463075\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 242 = 0.30185180413463075\n",
      "Error on this batch = 0.2982572339021565\n",
      "Error on this batch = 0.27977713930915504\n",
      "Cost on val dataset after 243 epochs is = 0.30101950679253603\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 243 = 0.30101950679253603\n",
      "Error on this batch = 0.2972468497070016\n",
      "Error on this batch = 0.2789152217905048\n",
      "Cost on val dataset after 244 epochs is = 0.30018265038753106\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 244 = 0.30018265038753106\n",
      "Error on this batch = 0.2962161407705749\n",
      "Error on this batch = 0.2780604510951676\n",
      "Cost on val dataset after 245 epochs is = 0.29935675964062924\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 245 = 0.29935675964062924\n",
      "Error on this batch = 0.2952319228490308\n",
      "Error on this batch = 0.27719817873129093\n",
      "Cost on val dataset after 246 epochs is = 0.2985237220052496\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 246 = 0.2985237220052496\n",
      "Error on this batch = 0.29424987406887854\n",
      "Error on this batch = 0.27633151334625533\n",
      "Cost on val dataset after 247 epochs is = 0.29768951453453585\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 247 = 0.29768951453453585\n",
      "Error on this batch = 0.29327149665184576\n",
      "Error on this batch = 0.27545966647954645\n",
      "Cost on val dataset after 248 epochs is = 0.2968544066065411\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 248 = 0.2968544066065411\n",
      "Error on this batch = 0.29230042634646725\n",
      "Error on this batch = 0.27457181991068585\n",
      "Cost on val dataset after 249 epochs is = 0.29601882780753735\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 249 = 0.29601882780753735\n",
      "Error on this batch = 0.2913283121356038\n",
      "Error on this batch = 0.27369915427634034\n",
      "Cost on val dataset after 250 epochs is = 0.295182452145652\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 250 = 0.295182452145652\n",
      "Error on this batch = 0.2903592749926823\n",
      "Error on this batch = 0.272827563479282\n",
      "Cost on val dataset after 251 epochs is = 0.294348249543167\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 251 = 0.294348249543167\n",
      "Error on this batch = 0.28938205847672316\n",
      "Error on this batch = 0.2719401033444776\n",
      "Cost on val dataset after 252 epochs is = 0.2935095411174148\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 252 = 0.2935095411174148\n",
      "Error on this batch = 0.28838804210276914\n",
      "Error on this batch = 0.2710430585346785\n",
      "Cost on val dataset after 253 epochs is = 0.29267265348863275\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 253 = 0.29267265348863275\n",
      "Error on this batch = 0.28739107381727313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.2701473224014512\n",
      "Cost on val dataset after 254 epochs is = 0.291829577634163\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 254 = 0.291829577634163\n",
      "Error on this batch = 0.2863905316560982\n",
      "Error on this batch = 0.2692436223727591\n",
      "Cost on val dataset after 255 epochs is = 0.29098806769421653\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 255 = 0.29098806769421653\n",
      "Error on this batch = 0.28539528273488457\n",
      "Error on this batch = 0.2683551572907554\n",
      "Cost on val dataset after 256 epochs is = 0.2901428959748846\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 256 = 0.2901428959748846\n",
      "Error on this batch = 0.28439510644109306\n",
      "Error on this batch = 0.2674663483649014\n",
      "Cost on val dataset after 257 epochs is = 0.2892868433666891\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 257 = 0.2892868433666891\n",
      "Error on this batch = 0.28339915316113323\n",
      "Error on this batch = 0.2665896234430694\n",
      "Cost on val dataset after 258 epochs is = 0.2884385603097295\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 258 = 0.2884385603097295\n",
      "Error on this batch = 0.28242618756180454\n",
      "Error on this batch = 0.2657329828903255\n",
      "Cost on val dataset after 259 epochs is = 0.2875819724457072\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 259 = 0.2875819724457072\n",
      "Error on this batch = 0.28143197723294605\n",
      "Error on this batch = 0.264838791671576\n",
      "Cost on val dataset after 260 epochs is = 0.2867234860180037\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 260 = 0.2867234860180037\n",
      "Error on this batch = 0.28044006096244223\n",
      "Error on this batch = 0.26392443217817785\n",
      "Cost on val dataset after 261 epochs is = 0.2858506759508045\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 261 = 0.2858506759508045\n",
      "Error on this batch = 0.2794281788701804\n",
      "Error on this batch = 0.2630251529385988\n",
      "Cost on val dataset after 262 epochs is = 0.2849887585528984\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 262 = 0.2849887585528984\n",
      "Error on this batch = 0.27844611692297844\n",
      "Error on this batch = 0.2621131117948693\n",
      "Cost on val dataset after 263 epochs is = 0.2841160007390374\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 263 = 0.2841160007390374\n",
      "Error on this batch = 0.27744513539516663\n",
      "Error on this batch = 0.2611859694868492\n",
      "Cost on val dataset after 264 epochs is = 0.2832555426141281\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 264 = 0.2832555426141281\n",
      "Error on this batch = 0.27645226407882034\n",
      "Error on this batch = 0.2602689992918118\n",
      "Cost on val dataset after 265 epochs is = 0.28238031916561157\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 265 = 0.28238031916561157\n",
      "Error on this batch = 0.2754297829562614\n",
      "Error on this batch = 0.25935460557719575\n",
      "Cost on val dataset after 266 epochs is = 0.28149388805708453\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 266 = 0.28149388805708453\n",
      "Error on this batch = 0.2743634180284334\n",
      "Error on this batch = 0.25842013668326064\n",
      "Cost on val dataset after 267 epochs is = 0.28060744572375274\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 267 = 0.28060744572375274\n",
      "Error on this batch = 0.27331619236065846\n",
      "Error on this batch = 0.2575146441292579\n",
      "Cost on val dataset after 268 epochs is = 0.27971593764028785\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 268 = 0.27971593764028785\n",
      "Error on this batch = 0.27228848315608933\n",
      "Error on this batch = 0.2566106298608872\n",
      "Cost on val dataset after 269 epochs is = 0.2788400391563264\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 269 = 0.2788400391563264\n",
      "Error on this batch = 0.2712521713638901\n",
      "Error on this batch = 0.2557141290706058\n",
      "Cost on val dataset after 270 epochs is = 0.27795556879877437\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 270 = 0.27795556879877437\n",
      "Error on this batch = 0.27019184761803483\n",
      "Error on this batch = 0.25482160855661173\n",
      "Cost on val dataset after 271 epochs is = 0.2771014304441534\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 271 = 0.2771014304441534\n",
      "Error on this batch = 0.26917787656230435\n",
      "Error on this batch = 0.25391560894357945\n",
      "Cost on val dataset after 272 epochs is = 0.2762436450753771\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 272 = 0.2762436450753771\n",
      "Error on this batch = 0.2681576261341461\n",
      "Error on this batch = 0.2529952452427299\n",
      "Cost on val dataset after 273 epochs is = 0.275410990370978\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 273 = 0.275410990370978\n",
      "Error on this batch = 0.26717682470106596\n",
      "Error on this batch = 0.2520872442607549\n",
      "Cost on val dataset after 274 epochs is = 0.27456957216491046\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 274 = 0.27456957216491046\n",
      "Error on this batch = 0.2661634100459851\n",
      "Error on this batch = 0.25118025420020834\n",
      "Cost on val dataset after 275 epochs is = 0.2737266658459108\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 275 = 0.2737266658459108\n",
      "Error on this batch = 0.2651465551653945\n",
      "Error on this batch = 0.2502608255007013\n",
      "Cost on val dataset after 276 epochs is = 0.2728990596129314\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 276 = 0.2728990596129314\n",
      "Error on this batch = 0.2641511364092586\n",
      "Error on this batch = 0.2493420471700327\n",
      "Cost on val dataset after 277 epochs is = 0.2720530623904287\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 277 = 0.2720530623904287\n",
      "Error on this batch = 0.2631237728295987\n",
      "Error on this batch = 0.2484302017243037\n",
      "Cost on val dataset after 278 epochs is = 0.27121561001388433\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 278 = 0.27121561001388433\n",
      "Error on this batch = 0.2621003003003253\n",
      "Error on this batch = 0.2475256512364206\n",
      "Cost on val dataset after 279 epochs is = 0.27035591522574026\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 279 = 0.27035591522574026\n",
      "Error on this batch = 0.2610519941289686\n",
      "Error on this batch = 0.24664455721176715\n",
      "Cost on val dataset after 280 epochs is = 0.2695310676270645\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 280 = 0.2695310676270645\n",
      "Error on this batch = 0.2600496434500174\n",
      "Error on this batch = 0.24576298905619226\n",
      "Cost on val dataset after 281 epochs is = 0.26870442547852275\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 281 = 0.26870442547852275\n",
      "Error on this batch = 0.25905662124549855\n",
      "Error on this batch = 0.24489854135971914\n",
      "Cost on val dataset after 282 epochs is = 0.2678761646988491\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 282 = 0.2678761646988491\n",
      "Error on this batch = 0.2580616013571704\n",
      "Error on this batch = 0.2440470895175446\n",
      "Cost on val dataset after 283 epochs is = 0.26707102306313113\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 283 = 0.26707102306313113\n",
      "Error on this batch = 0.2571094597581038\n",
      "Error on this batch = 0.24317249138673164\n",
      "Cost on val dataset after 284 epochs is = 0.266267766661146\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 284 = 0.266267766661146\n",
      "Error on this batch = 0.25617962165503344\n",
      "Error on this batch = 0.24231085982823786\n",
      "Cost on val dataset after 285 epochs is = 0.265472028262051\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 285 = 0.265472028262051\n",
      "Error on this batch = 0.25526178255621573\n",
      "Error on this batch = 0.2414336585798958\n",
      "Cost on val dataset after 286 epochs is = 0.26467744328677406\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 286 = 0.26467744328677406\n",
      "Error on this batch = 0.25436289663130024\n",
      "Error on this batch = 0.24057582765440785\n",
      "Cost on val dataset after 287 epochs is = 0.26389979355848264\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 287 = 0.26389979355848264\n",
      "Error on this batch = 0.25350334466449775\n",
      "Error on this batch = 0.23972827521520956\n",
      "Cost on val dataset after 288 epochs is = 0.2631107075814967\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 288 = 0.2631107075814967\n",
      "Error on this batch = 0.2526394063854489\n",
      "Error on this batch = 0.23889479135984648\n",
      "Cost on val dataset after 289 epochs is = 0.2623320085844152\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 289 = 0.2623320085844152\n",
      "Error on this batch = 0.25178685535868567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.2380805387442225\n",
      "Cost on val dataset after 290 epochs is = 0.2615496255086712\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 290 = 0.2615496255086712\n",
      "Error on this batch = 0.25092973009272873\n",
      "Error on this batch = 0.23724262381691524\n",
      "Cost on val dataset after 291 epochs is = 0.2607741109502119\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 291 = 0.2607741109502119\n",
      "Error on this batch = 0.2500884864612173\n",
      "Error on this batch = 0.23639588250116694\n",
      "Cost on val dataset after 292 epochs is = 0.25999602129198757\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 292 = 0.25999602129198757\n",
      "Error on this batch = 0.24927075248747607\n",
      "Error on this batch = 0.23553613057442144\n",
      "Cost on val dataset after 293 epochs is = 0.2592216410707274\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 293 = 0.2592216410707274\n",
      "Error on this batch = 0.24844370553596778\n",
      "Error on this batch = 0.23470951480261126\n",
      "Cost on val dataset after 294 epochs is = 0.2584409185427892\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 294 = 0.2584409185427892\n",
      "Error on this batch = 0.24764671374365424\n",
      "Error on this batch = 0.2338845915098613\n",
      "Cost on val dataset after 295 epochs is = 0.25766021848627757\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 295 = 0.25766021848627757\n",
      "Error on this batch = 0.2468541834469923\n",
      "Error on this batch = 0.23305498812460657\n",
      "Cost on val dataset after 296 epochs is = 0.2568897363479219\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 296 = 0.2568897363479219\n",
      "Error on this batch = 0.24607368878315286\n",
      "Error on this batch = 0.2322380300627105\n",
      "Cost on val dataset after 297 epochs is = 0.2561194059206752\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 297 = 0.2561194059206752\n",
      "Error on this batch = 0.24530064815982985\n",
      "Error on this batch = 0.23141044701978097\n",
      "Cost on val dataset after 298 epochs is = 0.25534954429501594\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 298 = 0.25534954429501594\n",
      "Error on this batch = 0.244557539482954\n",
      "Error on this batch = 0.23059639579640517\n",
      "Cost on val dataset after 299 epochs is = 0.254575814370174\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 299 = 0.254575814370174\n",
      "Error on this batch = 0.24382466662890614\n",
      "Error on this batch = 0.22979751615388366\n",
      "Cost on val dataset after 300 epochs is = 0.2538012473555518\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 300 = 0.2538012473555518\n",
      "Error on this batch = 0.24311198163116224\n",
      "Error on this batch = 0.22896650791210146\n",
      "Cost on val dataset after 301 epochs is = 0.25302085618636977\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 301 = 0.25302085618636977\n",
      "Error on this batch = 0.24238573035386865\n",
      "Error on this batch = 0.22813666480179387\n",
      "Cost on val dataset after 302 epochs is = 0.2522441184050787\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 302 = 0.2522441184050787\n",
      "Error on this batch = 0.24166266662947272\n",
      "Error on this batch = 0.22733017708186742\n",
      "Cost on val dataset after 303 epochs is = 0.25147164617433115\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 303 = 0.25147164617433115\n",
      "Error on this batch = 0.24093738802991113\n",
      "Error on this batch = 0.22652258997699648\n",
      "Cost on val dataset after 304 epochs is = 0.25068803017670194\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 304 = 0.25068803017670194\n",
      "Error on this batch = 0.24019727451946365\n",
      "Error on this batch = 0.22573607667752282\n",
      "Cost on val dataset after 305 epochs is = 0.2499068551819586\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 305 = 0.2499068551819586\n",
      "Error on this batch = 0.2394484183356071\n",
      "Error on this batch = 0.2249465164343203\n",
      "Cost on val dataset after 306 epochs is = 0.2491384210243998\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 306 = 0.2491384210243998\n",
      "Error on this batch = 0.23872677428828987\n",
      "Error on this batch = 0.22418318416488908\n",
      "Cost on val dataset after 307 epochs is = 0.248374065168897\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 307 = 0.248374065168897\n",
      "Error on this batch = 0.2379868394981901\n",
      "Error on this batch = 0.22341001887628373\n",
      "Cost on val dataset after 308 epochs is = 0.24761049217532002\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 308 = 0.24761049217532002\n",
      "Error on this batch = 0.2372462573138494\n",
      "Error on this batch = 0.22260551166740267\n",
      "Cost on val dataset after 309 epochs is = 0.24685027711344815\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 309 = 0.24685027711344815\n",
      "Error on this batch = 0.23650069621694506\n",
      "Error on this batch = 0.22180963950107338\n",
      "Cost on val dataset after 310 epochs is = 0.24609414168048063\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 310 = 0.24609414168048063\n",
      "Error on this batch = 0.23575045309883375\n",
      "Error on this batch = 0.2210192964275251\n",
      "Cost on val dataset after 311 epochs is = 0.24533110498806915\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 311 = 0.24533110498806915\n",
      "Error on this batch = 0.23493987148725395\n",
      "Error on this batch = 0.22022784845264592\n",
      "Cost on val dataset after 312 epochs is = 0.2445640624515718\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 312 = 0.2445640624515718\n",
      "Error on this batch = 0.2341329041910654\n",
      "Error on this batch = 0.2194328902606031\n",
      "Cost on val dataset after 313 epochs is = 0.24379255025371938\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 313 = 0.24379255025371938\n",
      "Error on this batch = 0.2333139301912916\n",
      "Error on this batch = 0.2186608192188799\n",
      "Cost on val dataset after 314 epochs is = 0.2430297581050091\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 314 = 0.2430297581050091\n",
      "Error on this batch = 0.23249494149769484\n",
      "Error on this batch = 0.2179179501292684\n",
      "Cost on val dataset after 315 epochs is = 0.24227601610978677\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 315 = 0.24227601610978677\n",
      "Error on this batch = 0.23169113141784103\n",
      "Error on this batch = 0.21715726713833836\n",
      "Cost on val dataset after 316 epochs is = 0.24153334487788694\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 316 = 0.24153334487788694\n",
      "Error on this batch = 0.2308995151435469\n",
      "Error on this batch = 0.2163891522818771\n",
      "Cost on val dataset after 317 epochs is = 0.2407924866509929\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 317 = 0.2407924866509929\n",
      "Error on this batch = 0.23008852746633637\n",
      "Error on this batch = 0.21563904992101612\n",
      "Cost on val dataset after 318 epochs is = 0.24005378316354276\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 318 = 0.24005378316354276\n",
      "Error on this batch = 0.229277242849052\n",
      "Error on this batch = 0.21487697390419536\n",
      "Cost on val dataset after 319 epochs is = 0.23932976890021507\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 319 = 0.23932976890021507\n",
      "Error on this batch = 0.228477494204069\n",
      "Error on this batch = 0.2141274496338201\n",
      "Cost on val dataset after 320 epochs is = 0.2386079252564867\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 320 = 0.2386079252564867\n",
      "Error on this batch = 0.22767184705430515\n",
      "Error on this batch = 0.21337756504295877\n",
      "Cost on val dataset after 321 epochs is = 0.23788299519039124\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 321 = 0.23788299519039124\n",
      "Error on this batch = 0.22685000213652878\n",
      "Error on this batch = 0.21262680743217088\n",
      "Cost on val dataset after 322 epochs is = 0.2371619172458009\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 322 = 0.2371619172458009\n",
      "Error on this batch = 0.22601045281634718\n",
      "Error on this batch = 0.21186629620207875\n",
      "Cost on val dataset after 323 epochs is = 0.23645128053914205\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 323 = 0.23645128053914205\n",
      "Error on this batch = 0.22517739049573585\n",
      "Error on this batch = 0.2111206016442811\n",
      "Cost on val dataset after 324 epochs is = 0.23574159620993923\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 324 = 0.23574159620993923\n",
      "Error on this batch = 0.22430633034284625\n",
      "Error on this batch = 0.21033898464108888\n",
      "Cost on val dataset after 325 epochs is = 0.23503706233008567\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 325 = 0.23503706233008567\n",
      "Error on this batch = 0.22342320014901285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.20959052674727738\n",
      "Cost on val dataset after 326 epochs is = 0.2343400161501431\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 326 = 0.2343400161501431\n",
      "Error on this batch = 0.2225091194806259\n",
      "Error on this batch = 0.20882311930018546\n",
      "Cost on val dataset after 327 epochs is = 0.23364461184156457\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 327 = 0.23364461184156457\n",
      "Error on this batch = 0.22160010905952462\n",
      "Error on this batch = 0.20806030927501717\n",
      "Cost on val dataset after 328 epochs is = 0.23295195336099103\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 328 = 0.23295195336099103\n",
      "Error on this batch = 0.22069160947962702\n",
      "Error on this batch = 0.20728797432757184\n",
      "Cost on val dataset after 329 epochs is = 0.23227468833523468\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 329 = 0.23227468833523468\n",
      "Error on this batch = 0.21980182871298568\n",
      "Error on this batch = 0.20649850388633254\n",
      "Cost on val dataset after 330 epochs is = 0.23157419005490293\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 330 = 0.23157419005490293\n",
      "Error on this batch = 0.21889514356633707\n",
      "Error on this batch = 0.205713712131258\n",
      "Cost on val dataset after 331 epochs is = 0.2309029048342621\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 331 = 0.2309029048342621\n",
      "Error on this batch = 0.21802104776014253\n",
      "Error on this batch = 0.20492542252225882\n",
      "Cost on val dataset after 332 epochs is = 0.23022329909923878\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 332 = 0.23022329909923878\n",
      "Error on this batch = 0.2171380445453415\n",
      "Error on this batch = 0.2041378671355362\n",
      "Cost on val dataset after 333 epochs is = 0.2295410975724439\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 333 = 0.2295410975724439\n",
      "Error on this batch = 0.21625203494817682\n",
      "Error on this batch = 0.20337308941494686\n",
      "Cost on val dataset after 334 epochs is = 0.22886615881976244\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 334 = 0.22886615881976244\n",
      "Error on this batch = 0.21537379275041693\n",
      "Error on this batch = 0.20264893205718232\n",
      "Cost on val dataset after 335 epochs is = 0.22819121733917044\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 335 = 0.22819121733917044\n",
      "Error on this batch = 0.21450460906153662\n",
      "Error on this batch = 0.20191486841110148\n",
      "Cost on val dataset after 336 epochs is = 0.2275347703115413\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 336 = 0.2275347703115413\n",
      "Error on this batch = 0.21362666230921995\n",
      "Error on this batch = 0.20122129337022776\n",
      "Cost on val dataset after 337 epochs is = 0.22686789377126457\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 337 = 0.22686789377126457\n",
      "Error on this batch = 0.21272105911857267\n",
      "Error on this batch = 0.20049529710363115\n",
      "Cost on val dataset after 338 epochs is = 0.22620720224373336\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 338 = 0.22620720224373336\n",
      "Error on this batch = 0.2118193336515339\n",
      "Error on this batch = 0.1997611450800909\n",
      "Cost on val dataset after 339 epochs is = 0.2255441209339491\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 339 = 0.2255441209339491\n",
      "Error on this batch = 0.2109207646786947\n",
      "Error on this batch = 0.19904786282048537\n",
      "Cost on val dataset after 340 epochs is = 0.22489448578423143\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 340 = 0.22489448578423143\n",
      "Error on this batch = 0.21004601699488312\n",
      "Error on this batch = 0.1983019421394124\n",
      "Cost on val dataset after 341 epochs is = 0.22426741012829562\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 341 = 0.22426741012829562\n",
      "Error on this batch = 0.2091937860949374\n",
      "Error on this batch = 0.1975625138288543\n",
      "Cost on val dataset after 342 epochs is = 0.22363641716593188\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 342 = 0.22363641716593188\n",
      "Error on this batch = 0.20833043555227795\n",
      "Error on this batch = 0.1968072217663845\n",
      "Cost on val dataset after 343 epochs is = 0.22300137815925303\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 343 = 0.22300137815925303\n",
      "Error on this batch = 0.20748030746529555\n",
      "Error on this batch = 0.1960589523507142\n",
      "Cost on val dataset after 344 epochs is = 0.22237520698789773\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 344 = 0.22237520698789773\n",
      "Error on this batch = 0.20662795789742333\n",
      "Error on this batch = 0.19532811414679407\n",
      "Cost on val dataset after 345 epochs is = 0.22175264110575146\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 345 = 0.22175264110575146\n",
      "Error on this batch = 0.20579019027343626\n",
      "Error on this batch = 0.1946082705554122\n",
      "Cost on val dataset after 346 epochs is = 0.22112443319841502\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 346 = 0.22112443319841502\n",
      "Error on this batch = 0.20495766124641887\n",
      "Error on this batch = 0.19387451344879725\n",
      "Cost on val dataset after 347 epochs is = 0.220510124321971\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 347 = 0.220510124321971\n",
      "Error on this batch = 0.2041428145603193\n",
      "Error on this batch = 0.193154907963955\n",
      "Cost on val dataset after 348 epochs is = 0.21989788021378867\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 348 = 0.21989788021378867\n",
      "Error on this batch = 0.2032783952302785\n",
      "Error on this batch = 0.19243179624074103\n",
      "Cost on val dataset after 349 epochs is = 0.21926837928850595\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 349 = 0.21926837928850595\n",
      "Error on this batch = 0.20242084782981506\n",
      "Error on this batch = 0.19171685259325624\n",
      "Cost on val dataset after 350 epochs is = 0.2186580127165568\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 350 = 0.2186580127165568\n",
      "Error on this batch = 0.20162430430593525\n",
      "Error on this batch = 0.19099899475517906\n",
      "Cost on val dataset after 351 epochs is = 0.21804958002130964\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 351 = 0.21804958002130964\n",
      "Error on this batch = 0.20082782223918635\n",
      "Error on this batch = 0.1902454712119444\n",
      "Cost on val dataset after 352 epochs is = 0.21744790243013934\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 352 = 0.21744790243013934\n",
      "Error on this batch = 0.200066594770606\n",
      "Error on this batch = 0.18945716040824237\n",
      "Cost on val dataset after 353 epochs is = 0.21686101760611282\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 353 = 0.21686101760611282\n",
      "Error on this batch = 0.19930301559607624\n",
      "Error on this batch = 0.18866401531994\n",
      "Cost on val dataset after 354 epochs is = 0.2162554619120799\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 354 = 0.2162554619120799\n",
      "Error on this batch = 0.1985310951393631\n",
      "Error on this batch = 0.18787942479926112\n",
      "Cost on val dataset after 355 epochs is = 0.21565643879116425\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 355 = 0.21565643879116425\n",
      "Error on this batch = 0.19777219321861375\n",
      "Error on this batch = 0.1871137109368571\n",
      "Cost on val dataset after 356 epochs is = 0.2150634123869868\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 356 = 0.2150634123869868\n",
      "Error on this batch = 0.19705332333516803\n",
      "Error on this batch = 0.1863611877320779\n",
      "Cost on val dataset after 357 epochs is = 0.2144670395525424\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 357 = 0.2144670395525424\n",
      "Error on this batch = 0.19634733909319535\n",
      "Error on this batch = 0.1856352357755865\n",
      "Cost on val dataset after 358 epochs is = 0.21387409284139317\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 358 = 0.21387409284139317\n",
      "Error on this batch = 0.1956571386913938\n",
      "Error on this batch = 0.18490960340632448\n",
      "Cost on val dataset after 359 epochs is = 0.21328589398284215\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 359 = 0.21328589398284215\n",
      "Error on this batch = 0.19498185852771208\n",
      "Error on this batch = 0.18416839675819244\n",
      "Cost on val dataset after 360 epochs is = 0.2126702374308648\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 360 = 0.2126702374308648\n",
      "Error on this batch = 0.19426441486342377\n",
      "Error on this batch = 0.18340416479093172\n",
      "Cost on val dataset after 361 epochs is = 0.21207377922663154\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 361 = 0.21207377922663154\n",
      "Error on this batch = 0.19357608943946258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1826454471262071\n",
      "Cost on val dataset after 362 epochs is = 0.21146670533484274\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 362 = 0.21146670533484274\n",
      "Error on this batch = 0.19285509378580276\n",
      "Error on this batch = 0.18190522174868004\n",
      "Cost on val dataset after 363 epochs is = 0.21085094096804013\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 363 = 0.21085094096804013\n",
      "Error on this batch = 0.19213947976617288\n",
      "Error on this batch = 0.18116180717638755\n",
      "Cost on val dataset after 364 epochs is = 0.21023988807009797\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 364 = 0.21023988807009797\n",
      "Error on this batch = 0.19142929735740238\n",
      "Error on this batch = 0.18043597702908049\n",
      "Cost on val dataset after 365 epochs is = 0.20962167083325886\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 365 = 0.20962167083325886\n",
      "Error on this batch = 0.19071718038829893\n",
      "Error on this batch = 0.1797137272698584\n",
      "Cost on val dataset after 366 epochs is = 0.20900615332737174\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 366 = 0.20900615332737174\n",
      "Error on this batch = 0.19000730256940443\n",
      "Error on this batch = 0.1789841185246832\n",
      "Cost on val dataset after 367 epochs is = 0.20839852217238256\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 367 = 0.20839852217238256\n",
      "Error on this batch = 0.18931881183726243\n",
      "Error on this batch = 0.1783057918761237\n",
      "Cost on val dataset after 368 epochs is = 0.20778926622573862\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 368 = 0.20778926622573862\n",
      "Error on this batch = 0.188642613542892\n",
      "Error on this batch = 0.17762833425470623\n",
      "Cost on val dataset after 369 epochs is = 0.2071696524918636\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 369 = 0.2071696524918636\n",
      "Error on this batch = 0.1879640555446364\n",
      "Error on this batch = 0.17697199290192564\n",
      "Cost on val dataset after 370 epochs is = 0.20655520665458438\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 370 = 0.20655520665458438\n",
      "Error on this batch = 0.18729164844118992\n",
      "Error on this batch = 0.1763185667099312\n",
      "Cost on val dataset after 371 epochs is = 0.2058946961666741\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 371 = 0.2058946961666741\n",
      "Error on this batch = 0.1865865349020238\n",
      "Error on this batch = 0.17563808102837186\n",
      "Cost on val dataset after 372 epochs is = 0.20526559465960592\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 372 = 0.20526559465960592\n",
      "Error on this batch = 0.18590815589488435\n",
      "Error on this batch = 0.17496043502611003\n",
      "Cost on val dataset after 373 epochs is = 0.20463466721959353\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 373 = 0.20463466721959353\n",
      "Error on this batch = 0.18523284613120589\n",
      "Error on this batch = 0.17432309819375363\n",
      "Cost on val dataset after 374 epochs is = 0.20399759534335535\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 374 = 0.20399759534335535\n",
      "Error on this batch = 0.18451851761195\n",
      "Error on this batch = 0.1737098454019726\n",
      "Cost on val dataset after 375 epochs is = 0.20337256466078352\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 375 = 0.20337256466078352\n",
      "Error on this batch = 0.18382804430354696\n",
      "Error on this batch = 0.1731406760217682\n",
      "Cost on val dataset after 376 epochs is = 0.20275766160738123\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 376 = 0.20275766160738123\n",
      "Error on this batch = 0.18314324942284352\n",
      "Error on this batch = 0.17251948135361192\n",
      "Cost on val dataset after 377 epochs is = 0.20212528538185762\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 377 = 0.20212528538185762\n",
      "Error on this batch = 0.1824314295381102\n",
      "Error on this batch = 0.17184508770965815\n",
      "Cost on val dataset after 378 epochs is = 0.2014769090988446\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 378 = 0.2014769090988446\n",
      "Error on this batch = 0.18172908093832044\n",
      "Error on this batch = 0.17120094154335105\n",
      "Cost on val dataset after 379 epochs is = 0.20086833422415212\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 379 = 0.20086833422415212\n",
      "Error on this batch = 0.18100208383510347\n",
      "Error on this batch = 0.17058045459915003\n",
      "Cost on val dataset after 380 epochs is = 0.2002649673483619\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 380 = 0.2002649673483619\n",
      "Error on this batch = 0.18026393922077272\n",
      "Error on this batch = 0.16997844746199683\n",
      "Cost on val dataset after 381 epochs is = 0.1996824363621339\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 381 = 0.1996824363621339\n",
      "Error on this batch = 0.17957729576326642\n",
      "Error on this batch = 0.16940635841611773\n",
      "Cost on val dataset after 382 epochs is = 0.1990993706700331\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 382 = 0.1990993706700331\n",
      "Error on this batch = 0.17887177794912915\n",
      "Error on this batch = 0.1688477999920828\n",
      "Cost on val dataset after 383 epochs is = 0.19850966796647038\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 383 = 0.19850966796647038\n",
      "Error on this batch = 0.1782050571640115\n",
      "Error on this batch = 0.16829345850419777\n",
      "Cost on val dataset after 384 epochs is = 0.197944510687537\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 384 = 0.197944510687537\n",
      "Error on this batch = 0.17758980521943302\n",
      "Error on this batch = 0.16775378590659767\n",
      "Cost on val dataset after 385 epochs is = 0.19738354354901586\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 385 = 0.19738354354901586\n",
      "Error on this batch = 0.17696423708324627\n",
      "Error on this batch = 0.16723617520845616\n",
      "Cost on val dataset after 386 epochs is = 0.19681793759481953\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 386 = 0.19681793759481953\n",
      "Error on this batch = 0.17632773867113125\n",
      "Error on this batch = 0.16671224631018855\n",
      "Cost on val dataset after 387 epochs is = 0.19625103667890423\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 387 = 0.19625103667890423\n",
      "Error on this batch = 0.17568087916442882\n",
      "Error on this batch = 0.16622192902405977\n",
      "Cost on val dataset after 388 epochs is = 0.19568788237401058\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 388 = 0.19568788237401058\n",
      "Error on this batch = 0.17500645185061373\n",
      "Error on this batch = 0.1657424239734352\n",
      "Cost on val dataset after 389 epochs is = 0.1951302053774929\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 389 = 0.1951302053774929\n",
      "Error on this batch = 0.17435291052067164\n",
      "Error on this batch = 0.16523605621964002\n",
      "Cost on val dataset after 390 epochs is = 0.19456230863083904\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 390 = 0.19456230863083904\n",
      "Error on this batch = 0.17364308784500807\n",
      "Error on this batch = 0.16471208930838502\n",
      "Cost on val dataset after 391 epochs is = 0.19402064903868316\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 391 = 0.19402064903868316\n",
      "Error on this batch = 0.17297046223129997\n",
      "Error on this batch = 0.1641955012243256\n",
      "Cost on val dataset after 392 epochs is = 0.1934797903435266\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 392 = 0.1934797903435266\n",
      "Error on this batch = 0.1723130182088843\n",
      "Error on this batch = 0.16366525132697649\n",
      "Cost on val dataset after 393 epochs is = 0.19295088889133447\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 393 = 0.19295088889133447\n",
      "Error on this batch = 0.17165621338057294\n",
      "Error on this batch = 0.16312736824715252\n",
      "Cost on val dataset after 394 epochs is = 0.19243001243746413\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 394 = 0.19243001243746413\n",
      "Error on this batch = 0.171006446723288\n",
      "Error on this batch = 0.16257215712424458\n",
      "Cost on val dataset after 395 epochs is = 0.19190729320666666\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 395 = 0.19190729320666666\n",
      "Error on this batch = 0.17035914260255391\n",
      "Error on this batch = 0.16202460836138163\n",
      "Cost on val dataset after 396 epochs is = 0.1914051481709118\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 396 = 0.1914051481709118\n",
      "Error on this batch = 0.16974044737850474\n",
      "Error on this batch = 0.16146843499950278\n",
      "Cost on val dataset after 397 epochs is = 0.19089543715420285\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 397 = 0.19089543715420285\n",
      "Error on this batch = 0.1691130012076825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1609145187138526\n",
      "Cost on val dataset after 398 epochs is = 0.19038887467741633\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 398 = 0.19038887467741633\n",
      "Error on this batch = 0.1684860437782801\n",
      "Error on this batch = 0.1603322665753958\n",
      "Cost on val dataset after 399 epochs is = 0.18990255829090935\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 399 = 0.18990255829090935\n",
      "Error on this batch = 0.16785934364329427\n",
      "Error on this batch = 0.15973993852927965\n",
      "Cost on val dataset after 400 epochs is = 0.1894084896462124\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 400 = 0.1894084896462124\n",
      "Error on this batch = 0.16723866810778373\n",
      "Error on this batch = 0.15916222778427722\n",
      "Cost on val dataset after 401 epochs is = 0.1889233371441716\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 401 = 0.1889233371441716\n",
      "Error on this batch = 0.1666315138353149\n",
      "Error on this batch = 0.15854153151618647\n",
      "Cost on val dataset after 402 epochs is = 0.1884308435611699\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 402 = 0.1884308435611699\n",
      "Error on this batch = 0.1660564662227972\n",
      "Error on this batch = 0.15794092666057485\n",
      "Cost on val dataset after 403 epochs is = 0.18796145493541427\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 403 = 0.18796145493541427\n",
      "Error on this batch = 0.1655176707399626\n",
      "Error on this batch = 0.15733006933832852\n",
      "Cost on val dataset after 404 epochs is = 0.1874867063193342\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 404 = 0.1874867063193342\n",
      "Error on this batch = 0.1649388934618585\n",
      "Error on this batch = 0.1567721358483399\n",
      "Cost on val dataset after 405 epochs is = 0.18703168526466166\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 405 = 0.18703168526466166\n",
      "Error on this batch = 0.16438822641398496\n",
      "Error on this batch = 0.15621830772346432\n",
      "Cost on val dataset after 406 epochs is = 0.18658034711379315\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 406 = 0.18658034711379315\n",
      "Error on this batch = 0.16384409926489238\n",
      "Error on this batch = 0.15568834576601012\n",
      "Cost on val dataset after 407 epochs is = 0.18612511392994793\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 407 = 0.18612511392994793\n",
      "Error on this batch = 0.16331773476370776\n",
      "Error on this batch = 0.1551633918961343\n",
      "Cost on val dataset after 408 epochs is = 0.18568414844974468\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 408 = 0.18568414844974468\n",
      "Error on this batch = 0.1628089465359329\n",
      "Error on this batch = 0.15464240052736128\n",
      "Cost on val dataset after 409 epochs is = 0.18524045685064702\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 409 = 0.18524045685064702\n",
      "Error on this batch = 0.16227372165573517\n",
      "Error on this batch = 0.15411655550352926\n",
      "Cost on val dataset after 410 epochs is = 0.18480982092765247\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 410 = 0.18480982092765247\n",
      "Error on this batch = 0.16175938517350083\n",
      "Error on this batch = 0.15357541953755566\n",
      "Cost on val dataset after 411 epochs is = 0.18438292668050588\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 411 = 0.18438292668050588\n",
      "Error on this batch = 0.16126398897813082\n",
      "Error on this batch = 0.153067082317066\n",
      "Cost on val dataset after 412 epochs is = 0.18395999240490057\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 412 = 0.18395999240490057\n",
      "Error on this batch = 0.16076284126968152\n",
      "Error on this batch = 0.1525538857879045\n",
      "Cost on val dataset after 413 epochs is = 0.1835546838513756\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 413 = 0.1835546838513756\n",
      "Error on this batch = 0.16026557051115542\n",
      "Error on this batch = 0.15207367901510518\n",
      "Cost on val dataset after 414 epochs is = 0.18314641664238718\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 414 = 0.18314641664238718\n",
      "Error on this batch = 0.15976516732941673\n",
      "Error on this batch = 0.15159385173376333\n",
      "Cost on val dataset after 415 epochs is = 0.18274131176325342\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 415 = 0.18274131176325342\n",
      "Error on this batch = 0.15928364793505503\n",
      "Error on this batch = 0.15109818747526746\n",
      "Cost on val dataset after 416 epochs is = 0.18232747968938556\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 416 = 0.18232747968938556\n",
      "Error on this batch = 0.15879511003341257\n",
      "Error on this batch = 0.1506163401465724\n",
      "Cost on val dataset after 417 epochs is = 0.18195498619194495\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 417 = 0.18195498619194495\n",
      "Error on this batch = 0.1583546423274544\n",
      "Error on this batch = 0.15012424361254567\n",
      "Cost on val dataset after 418 epochs is = 0.18157905404089106\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 418 = 0.18157905404089106\n",
      "Error on this batch = 0.1579190455742977\n",
      "Error on this batch = 0.14962679186037284\n",
      "Cost on val dataset after 419 epochs is = 0.1811938483447039\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 419 = 0.1811938483447039\n",
      "Error on this batch = 0.1574877077233765\n",
      "Error on this batch = 0.1491390180989912\n",
      "Cost on val dataset after 420 epochs is = 0.18080980103086297\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 420 = 0.18080980103086297\n",
      "Error on this batch = 0.15705124063381748\n",
      "Error on this batch = 0.14864674310798875\n",
      "Cost on val dataset after 421 epochs is = 0.18043677058800178\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 421 = 0.18043677058800178\n",
      "Error on this batch = 0.15664245428463605\n",
      "Error on this batch = 0.14818850648783913\n",
      "Cost on val dataset after 422 epochs is = 0.18006962381862773\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 422 = 0.18006962381862773\n",
      "Error on this batch = 0.15624105601361638\n",
      "Error on this batch = 0.14771414666226076\n",
      "Cost on val dataset after 423 epochs is = 0.17972738359420226\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 423 = 0.17972738359420226\n",
      "Error on this batch = 0.15583632344504372\n",
      "Error on this batch = 0.14726437719032676\n",
      "Cost on val dataset after 424 epochs is = 0.17938075040967066\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 424 = 0.17938075040967066\n",
      "Error on this batch = 0.15543263104000488\n",
      "Error on this batch = 0.1468074133770177\n",
      "Cost on val dataset after 425 epochs is = 0.17904359414503399\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 425 = 0.17904359414503399\n",
      "Error on this batch = 0.15503561757537088\n",
      "Error on this batch = 0.14636715024877037\n",
      "Cost on val dataset after 426 epochs is = 0.1786920170436928\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 426 = 0.1786920170436928\n",
      "Error on this batch = 0.15463724860117248\n",
      "Error on this batch = 0.1459448432926087\n",
      "Cost on val dataset after 427 epochs is = 0.17836174205252814\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 427 = 0.17836174205252814\n",
      "Error on this batch = 0.15426473761519496\n",
      "Error on this batch = 0.145505700982078\n",
      "Cost on val dataset after 428 epochs is = 0.1780347123683752\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 428 = 0.1780347123683752\n",
      "Error on this batch = 0.15390310205425958\n",
      "Error on this batch = 0.14508552559632928\n",
      "Cost on val dataset after 429 epochs is = 0.17772068489044385\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 429 = 0.17772068489044385\n",
      "Error on this batch = 0.1535380426667868\n",
      "Error on this batch = 0.14464323105599725\n",
      "Cost on val dataset after 430 epochs is = 0.17739732702778552\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 430 = 0.17739732702778552\n",
      "Error on this batch = 0.15318950599645273\n",
      "Error on this batch = 0.14419928683376865\n",
      "Cost on val dataset after 431 epochs is = 0.17708475376704155\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 431 = 0.17708475376704155\n",
      "Error on this batch = 0.1528364350971456\n",
      "Error on this batch = 0.1437822117855304\n",
      "Cost on val dataset after 432 epochs is = 0.17678533882537661\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 432 = 0.17678533882537661\n",
      "Error on this batch = 0.15247613456442508\n",
      "Error on this batch = 0.1433746245902949\n",
      "Cost on val dataset after 433 epochs is = 0.1764823675748999\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 433 = 0.1764823675748999\n",
      "Error on this batch = 0.15208514269283666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1429877864724854\n",
      "Cost on val dataset after 434 epochs is = 0.17618051025310205\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 434 = 0.17618051025310205\n",
      "Error on this batch = 0.15172856049048639\n",
      "Error on this batch = 0.14258599075429104\n",
      "Cost on val dataset after 435 epochs is = 0.1758956302331279\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 435 = 0.1758956302331279\n",
      "Error on this batch = 0.15138169628165465\n",
      "Error on this batch = 0.14220384913071624\n",
      "Cost on val dataset after 436 epochs is = 0.17560400316279273\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 436 = 0.17560400316279273\n",
      "Error on this batch = 0.15104472728050802\n",
      "Error on this batch = 0.14182646927400705\n",
      "Cost on val dataset after 437 epochs is = 0.1753108649818463\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 437 = 0.1753108649818463\n",
      "Error on this batch = 0.15070621539762197\n",
      "Error on this batch = 0.14144219696962615\n",
      "Cost on val dataset after 438 epochs is = 0.17502890104430274\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 438 = 0.17502890104430274\n",
      "Error on this batch = 0.15038201319847727\n",
      "Error on this batch = 0.14104978297832663\n",
      "Cost on val dataset after 439 epochs is = 0.1747584052908504\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 439 = 0.1747584052908504\n",
      "Error on this batch = 0.15004780207479798\n",
      "Error on this batch = 0.1406664404097464\n",
      "Cost on val dataset after 440 epochs is = 0.17447872041257503\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 440 = 0.17447872041257503\n",
      "Error on this batch = 0.14971610173356587\n",
      "Error on this batch = 0.1402684114921331\n",
      "Cost on val dataset after 441 epochs is = 0.17420547361347774\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 441 = 0.17420547361347774\n",
      "Error on this batch = 0.14940521261255646\n",
      "Error on this batch = 0.1399003234134082\n",
      "Cost on val dataset after 442 epochs is = 0.1739317742447285\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 442 = 0.1739317742447285\n",
      "Error on this batch = 0.14910188425185453\n",
      "Error on this batch = 0.13953804624914765\n",
      "Cost on val dataset after 443 epochs is = 0.17367193223768373\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 443 = 0.17367193223768373\n",
      "Error on this batch = 0.14882317376672594\n",
      "Error on this batch = 0.1392011569904559\n",
      "Cost on val dataset after 444 epochs is = 0.17340232547649118\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 444 = 0.17340232547649118\n",
      "Error on this batch = 0.14852267348206824\n",
      "Error on this batch = 0.13885992627936866\n",
      "Cost on val dataset after 445 epochs is = 0.17313909058304505\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 445 = 0.17313909058304505\n",
      "Error on this batch = 0.14823178696045053\n",
      "Error on this batch = 0.1385390682511269\n",
      "Cost on val dataset after 446 epochs is = 0.17287156119539093\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 446 = 0.17287156119539093\n",
      "Error on this batch = 0.14793442589247727\n",
      "Error on this batch = 0.13821038664839827\n",
      "Cost on val dataset after 447 epochs is = 0.17262566059155238\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 447 = 0.17262566059155238\n",
      "Error on this batch = 0.14766011332922763\n",
      "Error on this batch = 0.13791015961214376\n",
      "Cost on val dataset after 448 epochs is = 0.172376746298444\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 448 = 0.172376746298444\n",
      "Error on this batch = 0.14739370805493385\n",
      "Error on this batch = 0.1375811382597381\n",
      "Cost on val dataset after 449 epochs is = 0.1721458860080754\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 449 = 0.1721458860080754\n",
      "Error on this batch = 0.1471463383715363\n",
      "Error on this batch = 0.13726521588800455\n",
      "Cost on val dataset after 450 epochs is = 0.1719294110247139\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 450 = 0.1719294110247139\n",
      "Error on this batch = 0.14689769174827735\n",
      "Error on this batch = 0.13696717322030003\n",
      "Cost on val dataset after 451 epochs is = 0.17170670648861172\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 451 = 0.17170670648861172\n",
      "Error on this batch = 0.14662784921820735\n",
      "Error on this batch = 0.13668924888312609\n",
      "Cost on val dataset after 452 epochs is = 0.17148014182651086\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 452 = 0.17148014182651086\n",
      "Error on this batch = 0.14636248940476423\n",
      "Error on this batch = 0.13639075679441387\n",
      "Cost on val dataset after 453 epochs is = 0.17127141691429376\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 453 = 0.17127141691429376\n",
      "Error on this batch = 0.14610958325656387\n",
      "Error on this batch = 0.13611727533086398\n",
      "Cost on val dataset after 454 epochs is = 0.17105003600654553\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 454 = 0.17105003600654553\n",
      "Error on this batch = 0.14586353299636984\n",
      "Error on this batch = 0.13576167606745476\n",
      "Cost on val dataset after 455 epochs is = 0.170836420818129\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 455 = 0.170836420818129\n",
      "Error on this batch = 0.1456260923448038\n",
      "Error on this batch = 0.13544352431435802\n",
      "Cost on val dataset after 456 epochs is = 0.17062655412846753\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 456 = 0.17062655412846753\n",
      "Error on this batch = 0.14538210824067702\n",
      "Error on this batch = 0.13516567028845333\n",
      "Cost on val dataset after 457 epochs is = 0.17042648573440744\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 457 = 0.17042648573440744\n",
      "Error on this batch = 0.1451361394842413\n",
      "Error on this batch = 0.1348200306635404\n",
      "Cost on val dataset after 458 epochs is = 0.17023297733228504\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 458 = 0.17023297733228504\n",
      "Error on this batch = 0.14489291188035341\n",
      "Error on this batch = 0.13450119565911575\n",
      "Cost on val dataset after 459 epochs is = 0.17003323681261953\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 459 = 0.17003323681261953\n",
      "Error on this batch = 0.14463219282461004\n",
      "Error on this batch = 0.13417964545411937\n",
      "Cost on val dataset after 460 epochs is = 0.16984038625524783\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 460 = 0.16984038625524783\n",
      "Error on this batch = 0.1444133891007397\n",
      "Error on this batch = 0.13383432552907604\n",
      "Cost on val dataset after 461 epochs is = 0.16965374201949765\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 461 = 0.16965374201949765\n",
      "Error on this batch = 0.14416288175611428\n",
      "Error on this batch = 0.13349364130504623\n",
      "Cost on val dataset after 462 epochs is = 0.16946874096900413\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 462 = 0.16946874096900413\n",
      "Error on this batch = 0.14392719144864718\n",
      "Error on this batch = 0.13312903263644\n",
      "Cost on val dataset after 463 epochs is = 0.1692682694132938\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 463 = 0.1692682694132938\n",
      "Error on this batch = 0.1436730519884371\n",
      "Error on this batch = 0.13279556764095085\n",
      "Cost on val dataset after 464 epochs is = 0.16910077214262964\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 464 = 0.16910077214262964\n",
      "Error on this batch = 0.14347448467085053\n",
      "Error on this batch = 0.13247725806840643\n",
      "Cost on val dataset after 465 epochs is = 0.16890938022450608\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 465 = 0.16890938022450608\n",
      "Error on this batch = 0.14323320682942753\n",
      "Error on this batch = 0.1321366071418719\n",
      "Cost on val dataset after 466 epochs is = 0.16873844221479636\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 466 = 0.16873844221479636\n",
      "Error on this batch = 0.14300687638529705\n",
      "Error on this batch = 0.13182258789497334\n",
      "Cost on val dataset after 467 epochs is = 0.16858180733915393\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 467 = 0.16858180733915393\n",
      "Error on this batch = 0.1427886904806989\n",
      "Error on this batch = 0.13151539978295823\n",
      "Cost on val dataset after 468 epochs is = 0.16841998704497693\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 468 = 0.16841998704497693\n",
      "Error on this batch = 0.14257503628140802\n",
      "Error on this batch = 0.13118338381903044\n",
      "Cost on val dataset after 469 epochs is = 0.16825677404435868\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 469 = 0.16825677404435868\n",
      "Error on this batch = 0.14236218588586755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.1308772141615699\n",
      "Cost on val dataset after 470 epochs is = 0.16809072304504974\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 470 = 0.16809072304504974\n",
      "Error on this batch = 0.142159936269641\n",
      "Error on this batch = 0.13055737011235785\n",
      "Cost on val dataset after 471 epochs is = 0.16792038199680173\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 471 = 0.16792038199680173\n",
      "Error on this batch = 0.1419425117486961\n",
      "Error on this batch = 0.13026256952650342\n",
      "Cost on val dataset after 472 epochs is = 0.16776504537400247\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 472 = 0.16776504537400247\n",
      "Error on this batch = 0.14170562374564147\n",
      "Error on this batch = 0.1299726169460428\n",
      "Cost on val dataset after 473 epochs is = 0.16758820377406286\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 473 = 0.16758820377406286\n",
      "Error on this batch = 0.14148982276079422\n",
      "Error on this batch = 0.1296729515844374\n",
      "Cost on val dataset after 474 epochs is = 0.16743928844201592\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 474 = 0.16743928844201592\n",
      "Error on this batch = 0.14130086861220328\n",
      "Error on this batch = 0.1293739463003283\n",
      "Cost on val dataset after 475 epochs is = 0.16728874039226949\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 475 = 0.16728874039226949\n",
      "Error on this batch = 0.14112558211583687\n",
      "Error on this batch = 0.1290809703635592\n",
      "Cost on val dataset after 476 epochs is = 0.16714378483742837\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 476 = 0.16714378483742837\n",
      "Error on this batch = 0.14094520462676716\n",
      "Error on this batch = 0.12880418129218438\n",
      "Cost on val dataset after 477 epochs is = 0.16701899132982795\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 477 = 0.16701899132982795\n",
      "Error on this batch = 0.1407686828771999\n",
      "Error on this batch = 0.12853748755421512\n",
      "Cost on val dataset after 478 epochs is = 0.16687715959042212\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 478 = 0.16687715959042212\n",
      "Error on this batch = 0.14059758931295327\n",
      "Error on this batch = 0.12825304400005388\n",
      "Cost on val dataset after 479 epochs is = 0.16673840322309286\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 479 = 0.16673840322309286\n",
      "Error on this batch = 0.14041478552216485\n",
      "Error on this batch = 0.12797941895567394\n",
      "Cost on val dataset after 480 epochs is = 0.16659595391341972\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 480 = 0.16659595391341972\n",
      "Error on this batch = 0.1402273781413984\n",
      "Error on this batch = 0.12770896515048516\n",
      "Cost on val dataset after 481 epochs is = 0.1664758429262377\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 481 = 0.1664758429262377\n",
      "Error on this batch = 0.1400467945602284\n",
      "Error on this batch = 0.12742195243295062\n",
      "Cost on val dataset after 482 epochs is = 0.16634583472640208\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 482 = 0.16634583472640208\n",
      "Error on this batch = 0.13987585238128428\n",
      "Error on this batch = 0.127144190839155\n",
      "Cost on val dataset after 483 epochs is = 0.1662216242943438\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 483 = 0.1662216242943438\n",
      "Error on this batch = 0.13970884379616372\n",
      "Error on this batch = 0.1268706207526774\n",
      "Cost on val dataset after 484 epochs is = 0.16609771764762785\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 484 = 0.16609771764762785\n",
      "Error on this batch = 0.13953835053124541\n",
      "Error on this batch = 0.1265884227109056\n",
      "Cost on val dataset after 485 epochs is = 0.1659625517024302\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 485 = 0.1659625517024302\n",
      "Error on this batch = 0.13937953311731516\n",
      "Error on this batch = 0.1263138103345019\n",
      "Cost on val dataset after 486 epochs is = 0.16585772650568062\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 486 = 0.16585772650568062\n",
      "Error on this batch = 0.1392375257448083\n",
      "Error on this batch = 0.1260292235404508\n",
      "Cost on val dataset after 487 epochs is = 0.16574202511775482\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 487 = 0.16574202511775482\n",
      "Error on this batch = 0.13907154682440961\n",
      "Error on this batch = 0.1257575652368432\n",
      "Cost on val dataset after 488 epochs is = 0.16561856619553764\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 488 = 0.16561856619553764\n",
      "Error on this batch = 0.13891066686808567\n",
      "Error on this batch = 0.12549511501830946\n",
      "Cost on val dataset after 489 epochs is = 0.1655008556985533\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 489 = 0.1655008556985533\n",
      "Error on this batch = 0.1387354569450444\n",
      "Error on this batch = 0.12521109411987777\n",
      "Cost on val dataset after 490 epochs is = 0.16538376185695683\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 490 = 0.16538376185695683\n",
      "Error on this batch = 0.1385677509767464\n",
      "Error on this batch = 0.12493660040383582\n",
      "Cost on val dataset after 491 epochs is = 0.16527238789883855\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 491 = 0.16527238789883855\n",
      "Error on this batch = 0.13839616657472195\n",
      "Error on this batch = 0.12467121912198748\n",
      "Cost on val dataset after 492 epochs is = 0.165165550234784\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 492 = 0.165165550234784\n",
      "Error on this batch = 0.13821456198630006\n",
      "Error on this batch = 0.124386182447215\n",
      "Cost on val dataset after 493 epochs is = 0.16506010364566567\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 493 = 0.16506010364566567\n",
      "Error on this batch = 0.13805617875766116\n",
      "Error on this batch = 0.12410450273275374\n",
      "Cost on val dataset after 494 epochs is = 0.16495924104663467\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 494 = 0.16495924104663467\n",
      "Error on this batch = 0.1378777662517099\n",
      "Error on this batch = 0.12382366263607064\n",
      "Cost on val dataset after 495 epochs is = 0.16487443172810368\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 495 = 0.16487443172810368\n",
      "Error on this batch = 0.13771388973747725\n",
      "Error on this batch = 0.12355805357311553\n",
      "Cost on val dataset after 496 epochs is = 0.1647817735748936\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 496 = 0.1647817735748936\n",
      "Error on this batch = 0.13755432252990293\n",
      "Error on this batch = 0.12331473249311214\n",
      "Cost on val dataset after 497 epochs is = 0.16468568007174636\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 497 = 0.16468568007174636\n",
      "Error on this batch = 0.13738326485150354\n",
      "Error on this batch = 0.12305235774116514\n",
      "Cost on val dataset after 498 epochs is = 0.16460775494029323\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 498 = 0.16460775494029323\n",
      "Error on this batch = 0.13722785317794692\n",
      "Error on this batch = 0.1227718469829064\n",
      "Cost on val dataset after 499 epochs is = 0.16452858402909662\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 499 = 0.16452858402909662\n",
      "Error on this batch = 0.13706418357421135\n",
      "Error on this batch = 0.12252891878362007\n",
      "Cost on val dataset after 500 epochs is = 0.16445723704115192\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 500 = 0.16445723704115192\n",
      "Error on this batch = 0.13689434423714328\n",
      "Error on this batch = 0.12224366432025392\n",
      "Cost on val dataset after 501 epochs is = 0.1643689527844343\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 501 = 0.1643689527844343\n",
      "Error on this batch = 0.13671683864539796\n",
      "Error on this batch = 0.1219906395062738\n",
      "Cost on val dataset after 502 epochs is = 0.16429790459125274\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 502 = 0.16429790459125274\n",
      "Error on this batch = 0.1365464191792714\n",
      "Error on this batch = 0.12171500312142419\n",
      "Cost on val dataset after 503 epochs is = 0.16423473196448723\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 503 = 0.16423473196448723\n",
      "Error on this batch = 0.1363933339179488\n",
      "Error on this batch = 0.12144034207600612\n",
      "Cost on val dataset after 504 epochs is = 0.16417779854327982\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 504 = 0.16417779854327982\n",
      "Error on this batch = 0.1362387627747299\n",
      "Error on this batch = 0.12117392000293904\n",
      "Cost on val dataset after 505 epochs is = 0.16411911251653713\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 505 = 0.16411911251653713\n",
      "Error on this batch = 0.13609487118130956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.12089755524547226\n",
      "Cost on val dataset after 506 epochs is = 0.1640563267056638\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 506 = 0.1640563267056638\n",
      "Error on this batch = 0.13592116204405366\n",
      "Error on this batch = 0.12062663753334628\n",
      "Cost on val dataset after 507 epochs is = 0.16398936297691163\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 507 = 0.16398936297691163\n",
      "Error on this batch = 0.1357756492581884\n",
      "Error on this batch = 0.12035827018576326\n",
      "Cost on val dataset after 508 epochs is = 0.16393272129170042\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 508 = 0.16393272129170042\n",
      "Error on this batch = 0.13563359265654612\n",
      "Error on this batch = 0.12012366709326515\n",
      "Cost on val dataset after 509 epochs is = 0.16387935222538205\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 509 = 0.16387935222538205\n",
      "Error on this batch = 0.1355136717326249\n",
      "Error on this batch = 0.11989015993679455\n",
      "Cost on val dataset after 510 epochs is = 0.16383630012849218\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 510 = 0.16383630012849218\n",
      "Error on this batch = 0.1354069018717094\n",
      "Error on this batch = 0.11965867787392981\n",
      "Cost on val dataset after 511 epochs is = 0.1637835687533477\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 511 = 0.1637835687533477\n",
      "Error on this batch = 0.13528137005991123\n",
      "Error on this batch = 0.11943569771008797\n",
      "Cost on val dataset after 512 epochs is = 0.16373377630651798\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 512 = 0.16373377630651798\n",
      "Error on this batch = 0.1351647103474806\n",
      "Error on this batch = 0.11923281711363376\n",
      "Cost on val dataset after 513 epochs is = 0.1636798789897939\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 513 = 0.1636798789897939\n",
      "Error on this batch = 0.1350393982052508\n",
      "Error on this batch = 0.11901382449089454\n",
      "Cost on val dataset after 514 epochs is = 0.16363075950121905\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 514 = 0.16363075950121905\n",
      "Error on this batch = 0.13489825673596378\n",
      "Error on this batch = 0.11879371690636\n",
      "Cost on val dataset after 515 epochs is = 0.16357571466886164\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 515 = 0.16357571466886164\n",
      "Error on this batch = 0.13479323835237136\n",
      "Error on this batch = 0.11856348112042746\n",
      "Cost on val dataset after 516 epochs is = 0.16352830258444434\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 516 = 0.16352830258444434\n",
      "Error on this batch = 0.13469651673761707\n",
      "Error on this batch = 0.11833518003352579\n",
      "Cost on val dataset after 517 epochs is = 0.1634901679890897\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 517 = 0.1634901679890897\n",
      "Error on this batch = 0.13463297388963977\n",
      "Error on this batch = 0.11811892793415797\n",
      "Cost on val dataset after 518 epochs is = 0.16344699439778276\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 518 = 0.16344699439778276\n",
      "Error on this batch = 0.1345236728588504\n",
      "Error on this batch = 0.11789277060116797\n",
      "Cost on val dataset after 519 epochs is = 0.16340513680663776\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 519 = 0.16340513680663776\n",
      "Error on this batch = 0.13443217916891873\n",
      "Error on this batch = 0.11767780525387675\n",
      "Cost on val dataset after 520 epochs is = 0.16335680870365116\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 520 = 0.16335680870365116\n",
      "Error on this batch = 0.13433800535384105\n",
      "Error on this batch = 0.11747262560278862\n",
      "Cost on val dataset after 521 epochs is = 0.16331961174975204\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 521 = 0.16331961174975204\n",
      "Error on this batch = 0.13424776223717227\n",
      "Error on this batch = 0.11727217636813947\n",
      "Cost on val dataset after 522 epochs is = 0.1632801359658778\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 522 = 0.1632801359658778\n",
      "Error on this batch = 0.13416467297344772\n",
      "Error on this batch = 0.1170636215957095\n",
      "Cost on val dataset after 523 epochs is = 0.16323163411620562\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 523 = 0.16323163411620562\n",
      "Error on this batch = 0.1340480111203913\n",
      "Error on this batch = 0.11685599971754457\n",
      "Cost on val dataset after 524 epochs is = 0.16317875882705335\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 524 = 0.16317875882705335\n",
      "Error on this batch = 0.1339656238970105\n",
      "Error on this batch = 0.11664580801731486\n",
      "Cost on val dataset after 525 epochs is = 0.16312717638602142\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 525 = 0.16312717638602142\n",
      "Error on this batch = 0.13387167374867287\n",
      "Error on this batch = 0.11642681474027863\n",
      "Cost on val dataset after 526 epochs is = 0.16308048908635037\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 526 = 0.16308048908635037\n",
      "Error on this batch = 0.1337662283059562\n",
      "Error on this batch = 0.11621033522418145\n",
      "Cost on val dataset after 527 epochs is = 0.16302034698765458\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 527 = 0.16302034698765458\n",
      "Error on this batch = 0.13366125866067016\n",
      "Error on this batch = 0.11601611075262355\n",
      "Cost on val dataset after 528 epochs is = 0.16297906915746976\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 528 = 0.16297906915746976\n",
      "Error on this batch = 0.13355019123200587\n",
      "Error on this batch = 0.11583187240524437\n",
      "Cost on val dataset after 529 epochs is = 0.16293270439589808\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 529 = 0.16293270439589808\n",
      "Error on this batch = 0.13344980127447886\n",
      "Error on this batch = 0.11567311428259729\n",
      "Cost on val dataset after 530 epochs is = 0.16288982166377397\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 530 = 0.16288982166377397\n",
      "Error on this batch = 0.1333776685233738\n",
      "Error on this batch = 0.11552715597862925\n",
      "Cost on val dataset after 531 epochs is = 0.16285828023391127\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 531 = 0.16285828023391127\n",
      "Error on this batch = 0.13326841425853628\n",
      "Error on this batch = 0.11537443776893291\n",
      "Cost on val dataset after 532 epochs is = 0.16282376018999134\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 532 = 0.16282376018999134\n",
      "Error on this batch = 0.1331774819506523\n",
      "Error on this batch = 0.1152493925926633\n",
      "Cost on val dataset after 533 epochs is = 0.16279679033692732\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 533 = 0.16279679033692732\n",
      "Error on this batch = 0.13308351784653116\n",
      "Error on this batch = 0.11512915636258975\n",
      "Cost on val dataset after 534 epochs is = 0.162760705603907\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 534 = 0.162760705603907\n",
      "Error on this batch = 0.13299968260501438\n",
      "Error on this batch = 0.11502212566290566\n",
      "Cost on val dataset after 535 epochs is = 0.16273349804839704\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 535 = 0.16273349804839704\n",
      "Error on this batch = 0.13288446281426058\n",
      "Error on this batch = 0.11491079891920687\n",
      "Cost on val dataset after 536 epochs is = 0.1627027175269044\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 536 = 0.1627027175269044\n",
      "Error on this batch = 0.1327912087854783\n",
      "Error on this batch = 0.11479391452463056\n",
      "Cost on val dataset after 537 epochs is = 0.1626667293205812\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 537 = 0.1626667293205812\n",
      "Error on this batch = 0.1327031597831496\n",
      "Error on this batch = 0.11468163746962289\n",
      "Cost on val dataset after 538 epochs is = 0.1626146409188228\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 538 = 0.1626146409188228\n",
      "Error on this batch = 0.13260129274045152\n",
      "Error on this batch = 0.11458420752801363\n",
      "Cost on val dataset after 539 epochs is = 0.16261259957380367\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 539 = 0.16261259957380367\n",
      "Error on this batch = 0.13255277539097285\n",
      "Error on this batch = 0.1144931040259442\n",
      "Cost on val dataset after 540 epochs is = 0.16257403505577864\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 540 = 0.16257403505577864\n",
      "Error on this batch = 0.13246269839787503\n",
      "Error on this batch = 0.11438596559621356\n",
      "Cost on val dataset after 541 epochs is = 0.16257835963636125\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 541 = 0.16257835963636125\n",
      "Error on this batch = 0.1323878211160374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11428261931980206\n",
      "Cost on val dataset after 542 epochs is = 0.16255692233458757\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 542 = 0.16255692233458757\n",
      "Error on this batch = 0.13229851910352788\n",
      "Error on this batch = 0.11416573218832136\n",
      "Cost on val dataset after 543 epochs is = 0.162515938790997\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 543 = 0.162515938790997\n",
      "Error on this batch = 0.13219185391049793\n",
      "Error on this batch = 0.1140876313889364\n",
      "Cost on val dataset after 544 epochs is = 0.16251591602713275\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 544 = 0.16251591602713275\n",
      "Error on this batch = 0.13211811728484854\n",
      "Error on this batch = 0.11401217062615458\n",
      "Cost on val dataset after 545 epochs is = 0.16247698492822327\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 545 = 0.16247698492822327\n",
      "Error on this batch = 0.1320124206434859\n",
      "Error on this batch = 0.11394541620881216\n",
      "Cost on val dataset after 546 epochs is = 0.16247866146623047\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 546 = 0.16247866146623047\n",
      "Error on this batch = 0.13194964908118814\n",
      "Error on this batch = 0.11387940983831653\n",
      "Cost on val dataset after 547 epochs is = 0.16243602107016356\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 547 = 0.16243602107016356\n",
      "Error on this batch = 0.13183727798881548\n",
      "Error on this batch = 0.11382750750679421\n",
      "Cost on val dataset after 548 epochs is = 0.16243021784205058\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 548 = 0.16243021784205058\n",
      "Error on this batch = 0.13177361573462437\n",
      "Error on this batch = 0.11379308812113693\n",
      "Cost on val dataset after 549 epochs is = 0.16237935111978155\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 549 = 0.16237935111978155\n",
      "Error on this batch = 0.13166077579837152\n",
      "Error on this batch = 0.1137245772620997\n",
      "Cost on val dataset after 550 epochs is = 0.16235618782913425\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 550 = 0.16235618782913425\n",
      "Error on this batch = 0.13155113841646432\n",
      "Error on this batch = 0.11370032375433806\n",
      "Cost on val dataset after 551 epochs is = 0.16236139568215593\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 551 = 0.16236139568215593\n",
      "Error on this batch = 0.13147083133759713\n",
      "Error on this batch = 0.11366126399527254\n",
      "Cost on val dataset after 552 epochs is = 0.16232173016742238\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 552 = 0.16232173016742238\n",
      "Error on this batch = 0.13134457057531815\n",
      "Error on this batch = 0.1136495016635298\n",
      "Cost on val dataset after 553 epochs is = 0.16230814026740867\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 553 = 0.16230814026740867\n",
      "Error on this batch = 0.13125670190056604\n",
      "Error on this batch = 0.11360644191598583\n",
      "Cost on val dataset after 554 epochs is = 0.16230956466192997\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 554 = 0.16230956466192997\n",
      "Error on this batch = 0.131163222858253\n",
      "Error on this batch = 0.1135746989105029\n",
      "Cost on val dataset after 555 epochs is = 0.1622956834556417\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 555 = 0.1622956834556417\n",
      "Error on this batch = 0.13106329948783174\n",
      "Error on this batch = 0.11354753500561975\n",
      "Cost on val dataset after 556 epochs is = 0.16228793416651924\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 556 = 0.16228793416651924\n",
      "Error on this batch = 0.13095398163937463\n",
      "Error on this batch = 0.1135172823976264\n",
      "Cost on val dataset after 557 epochs is = 0.16228426389844192\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 557 = 0.16228426389844192\n",
      "Error on this batch = 0.13084271970572187\n",
      "Error on this batch = 0.11349779955187007\n",
      "Cost on val dataset after 558 epochs is = 0.16226074103379315\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 558 = 0.16226074103379315\n",
      "Error on this batch = 0.13076569564970497\n",
      "Error on this batch = 0.11347017318214891\n",
      "Cost on val dataset after 559 epochs is = 0.16226231281934184\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 559 = 0.16226231281934184\n",
      "Error on this batch = 0.1307059670491072\n",
      "Error on this batch = 0.11344666448532417\n",
      "Cost on val dataset after 560 epochs is = 0.1622513829713155\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 560 = 0.1622513829713155\n",
      "Error on this batch = 0.130615404512273\n",
      "Error on this batch = 0.11343912250594212\n",
      "Cost on val dataset after 561 epochs is = 0.16223351124657678\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 561 = 0.16223351124657678\n",
      "Error on this batch = 0.1305427493913429\n",
      "Error on this batch = 0.11341717611594959\n",
      "Cost on val dataset after 562 epochs is = 0.1622276703547988\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 562 = 0.1622276703547988\n",
      "Error on this batch = 0.13048114323828433\n",
      "Error on this batch = 0.11338143609727212\n",
      "Cost on val dataset after 563 epochs is = 0.16220456177064307\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 563 = 0.16220456177064307\n",
      "Error on this batch = 0.13038316365762134\n",
      "Error on this batch = 0.11335355586986444\n",
      "Cost on val dataset after 564 epochs is = 0.1621832074182928\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 564 = 0.1621832074182928\n",
      "Error on this batch = 0.13027619429929604\n",
      "Error on this batch = 0.11331402949158192\n",
      "Cost on val dataset after 565 epochs is = 0.16218084907435112\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 565 = 0.16218084907435112\n",
      "Error on this batch = 0.13017999276595338\n",
      "Error on this batch = 0.11324122853065077\n",
      "Cost on val dataset after 566 epochs is = 0.16217408404902323\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 566 = 0.16217408404902323\n",
      "Error on this batch = 0.13011147168155765\n",
      "Error on this batch = 0.11319756808475219\n",
      "Cost on val dataset after 567 epochs is = 0.16216036361304914\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 567 = 0.16216036361304914\n",
      "Error on this batch = 0.1300470737877526\n",
      "Error on this batch = 0.11316331244875917\n",
      "Cost on val dataset after 568 epochs is = 0.16214212601479938\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 568 = 0.16214212601479938\n",
      "Error on this batch = 0.1299822681653132\n",
      "Error on this batch = 0.11313314221353793\n",
      "Cost on val dataset after 569 epochs is = 0.16213643479096376\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 569 = 0.16213643479096376\n",
      "Error on this batch = 0.1299131962811679\n",
      "Error on this batch = 0.11310105674554474\n",
      "Cost on val dataset after 570 epochs is = 0.16212707722588127\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 570 = 0.16212707722588127\n",
      "Error on this batch = 0.12982787831257653\n",
      "Error on this batch = 0.11306488956965711\n",
      "Cost on val dataset after 571 epochs is = 0.16211862723924203\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 571 = 0.16211862723924203\n",
      "Error on this batch = 0.12972456855843906\n",
      "Error on this batch = 0.11299692655931018\n",
      "Cost on val dataset after 572 epochs is = 0.16211187049204956\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 572 = 0.16211187049204956\n",
      "Error on this batch = 0.1296284997259537\n",
      "Error on this batch = 0.11293035329729638\n",
      "Cost on val dataset after 573 epochs is = 0.16208856332970353\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 573 = 0.16208856332970353\n",
      "Error on this batch = 0.12951760819340177\n",
      "Error on this batch = 0.1128906408201469\n",
      "Cost on val dataset after 574 epochs is = 0.16206763741784486\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 574 = 0.16206763741784486\n",
      "Error on this batch = 0.12941117837394675\n",
      "Error on this batch = 0.11284704900639483\n",
      "Cost on val dataset after 575 epochs is = 0.1620586526333188\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 575 = 0.1620586526333188\n",
      "Error on this batch = 0.12931110159166984\n",
      "Error on this batch = 0.11279580852444014\n",
      "Cost on val dataset after 576 epochs is = 0.1620587420600507\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 576 = 0.1620587420600507\n",
      "Error on this batch = 0.12921631341808026\n",
      "Error on this batch = 0.11276688958035877\n",
      "Cost on val dataset after 577 epochs is = 0.16203561952979398\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 577 = 0.16203561952979398\n",
      "Error on this batch = 0.12910352967011382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.11272341281890036\n",
      "Cost on val dataset after 578 epochs is = 0.16201140732598704\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 578 = 0.16201140732598704\n",
      "Error on this batch = 0.12900034172485036\n",
      "Error on this batch = 0.1126615046382992\n",
      "Cost on val dataset after 579 epochs is = 0.16199039872868592\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 579 = 0.16199039872868592\n",
      "Error on this batch = 0.12887511973537089\n",
      "Error on this batch = 0.11261438969358778\n",
      "Cost on val dataset after 580 epochs is = 0.16196924462882784\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 580 = 0.16196924462882784\n",
      "Error on this batch = 0.12876941498658342\n",
      "Error on this batch = 0.11253857270026521\n",
      "Cost on val dataset after 581 epochs is = 0.16194503622944262\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 581 = 0.16194503622944262\n",
      "Error on this batch = 0.12865666125111694\n",
      "Error on this batch = 0.11244788246664661\n",
      "Cost on val dataset after 582 epochs is = 0.16191849401649666\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 582 = 0.16191849401649666\n",
      "Error on this batch = 0.12854101290713354\n",
      "Error on this batch = 0.112354165297862\n",
      "Cost on val dataset after 583 epochs is = 0.16189432497566755\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 583 = 0.16189432497566755\n",
      "Error on this batch = 0.1284328851634546\n",
      "Error on this batch = 0.11227205418502444\n",
      "Cost on val dataset after 584 epochs is = 0.1618626389161465\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 584 = 0.1618626389161465\n",
      "Error on this batch = 0.1283171636686698\n",
      "Error on this batch = 0.1121810891393157\n",
      "Cost on val dataset after 585 epochs is = 0.16182546381475338\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 585 = 0.16182546381475338\n",
      "Error on this batch = 0.12819811724499458\n",
      "Error on this batch = 0.11206834481499996\n",
      "Cost on val dataset after 586 epochs is = 0.16179381135942347\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 586 = 0.16179381135942347\n",
      "Error on this batch = 0.1281001829439001\n",
      "Error on this batch = 0.11197567819340094\n",
      "Cost on val dataset after 587 epochs is = 0.16175817794154373\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 587 = 0.16175817794154373\n",
      "Error on this batch = 0.12799067560833505\n",
      "Error on this batch = 0.111854202101609\n",
      "Cost on val dataset after 588 epochs is = 0.1617215589393428\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 588 = 0.1617215589393428\n",
      "Error on this batch = 0.1278746124806958\n",
      "Error on this batch = 0.11174038606700183\n",
      "Cost on val dataset after 589 epochs is = 0.1616852383235133\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 589 = 0.1616852383235133\n",
      "Error on this batch = 0.12778028005696088\n",
      "Error on this batch = 0.11165024324434132\n",
      "Cost on val dataset after 590 epochs is = 0.1616364263871492\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 590 = 0.1616364263871492\n",
      "Error on this batch = 0.12768072855809687\n",
      "Error on this batch = 0.11156310197421565\n",
      "Cost on val dataset after 591 epochs is = 0.16162022308198767\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 591 = 0.16162022308198767\n",
      "Error on this batch = 0.12760238058825166\n",
      "Error on this batch = 0.11147486208341764\n",
      "Cost on val dataset after 592 epochs is = 0.16159522499521156\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 592 = 0.16159522499521156\n",
      "Error on this batch = 0.12752302175916289\n",
      "Error on this batch = 0.11138529640676734\n",
      "Cost on val dataset after 593 epochs is = 0.1615674094262465\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 593 = 0.1615674094262465\n",
      "Error on this batch = 0.12743947270813138\n",
      "Error on this batch = 0.11125622341265258\n",
      "Cost on val dataset after 594 epochs is = 0.16154351269991693\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 594 = 0.16154351269991693\n",
      "Error on this batch = 0.1273650541170776\n",
      "Error on this batch = 0.11112232096997976\n",
      "Cost on val dataset after 595 epochs is = 0.16152313040168012\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 595 = 0.16152313040168012\n",
      "Error on this batch = 0.12727789646642537\n",
      "Error on this batch = 0.11098235034352398\n",
      "Cost on val dataset after 596 epochs is = 0.16148581458745587\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 596 = 0.16148581458745587\n",
      "Error on this batch = 0.12720785212871583\n",
      "Error on this batch = 0.11082181211045454\n",
      "Cost on val dataset after 597 epochs is = 0.1614529557517757\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 597 = 0.1614529557517757\n",
      "Error on this batch = 0.12710980188748827\n",
      "Error on this batch = 0.11067630392403911\n",
      "Cost on val dataset after 598 epochs is = 0.16141915358654893\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 598 = 0.16141915358654893\n",
      "Error on this batch = 0.12699123639398383\n",
      "Error on this batch = 0.11052897769437174\n",
      "Cost on val dataset after 599 epochs is = 0.16137293547552084\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 599 = 0.16137293547552084\n",
      "Error on this batch = 0.12689922739434567\n",
      "Error on this batch = 0.11036742802273838\n",
      "Cost on val dataset after 600 epochs is = 0.16133751634266322\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 600 = 0.16133751634266322\n",
      "Error on this batch = 0.1268333626217575\n",
      "Error on this batch = 0.1101785592985817\n",
      "Cost on val dataset after 601 epochs is = 0.1613038348062455\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 601 = 0.1613038348062455\n",
      "Error on this batch = 0.1267815815712663\n",
      "Error on this batch = 0.10998767501432162\n",
      "Cost on val dataset after 602 epochs is = 0.16127417037880193\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 602 = 0.16127417037880193\n",
      "Error on this batch = 0.12671598059817538\n",
      "Error on this batch = 0.10983735445774351\n",
      "Cost on val dataset after 603 epochs is = 0.1612307246216204\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 603 = 0.1612307246216204\n",
      "Error on this batch = 0.12662822280722158\n",
      "Error on this batch = 0.10967681050481576\n",
      "Cost on val dataset after 604 epochs is = 0.16119726708203896\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 604 = 0.16119726708203896\n",
      "Error on this batch = 0.12654293021949656\n",
      "Error on this batch = 0.10954072634258687\n",
      "Cost on val dataset after 605 epochs is = 0.16114760663384062\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 605 = 0.16114760663384062\n",
      "Error on this batch = 0.1264582820696673\n",
      "Error on this batch = 0.10937973335293803\n",
      "Cost on val dataset after 606 epochs is = 0.16111140150658976\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 606 = 0.16111140150658976\n",
      "Error on this batch = 0.12637519897871147\n",
      "Error on this batch = 0.10921684775550791\n",
      "Cost on val dataset after 607 epochs is = 0.1610735551437936\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 607 = 0.1610735551437936\n",
      "Error on this batch = 0.12629599272585626\n",
      "Error on this batch = 0.10906357808543798\n",
      "Cost on val dataset after 608 epochs is = 0.1610367480023112\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 608 = 0.1610367480023112\n",
      "Error on this batch = 0.12622281724049844\n",
      "Error on this batch = 0.10891491983053989\n",
      "Cost on val dataset after 609 epochs is = 0.16099863498023187\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 609 = 0.16099863498023187\n",
      "Error on this batch = 0.12614663120144484\n",
      "Error on this batch = 0.1087615666179872\n",
      "Cost on val dataset after 610 epochs is = 0.1609818081639883\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 610 = 0.1609818081639883\n",
      "Error on this batch = 0.12610420979873765\n",
      "Error on this batch = 0.10863149107218922\n",
      "Cost on val dataset after 611 epochs is = 0.16094439439814984\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 611 = 0.16094439439814984\n",
      "Error on this batch = 0.12604565512651777\n",
      "Error on this batch = 0.10848237802284974\n",
      "Cost on val dataset after 612 epochs is = 0.1609020394344264\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 612 = 0.1609020394344264\n",
      "Error on this batch = 0.12599186943765883\n",
      "Error on this batch = 0.1083796690057644\n",
      "Cost on val dataset after 613 epochs is = 0.16084714922825222\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 613 = 0.16084714922825222\n",
      "Error on this batch = 0.12591724010548308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.10825228866371461\n",
      "Cost on val dataset after 614 epochs is = 0.16078953057292608\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 614 = 0.16078953057292608\n",
      "Error on this batch = 0.12583588814432808\n",
      "Error on this batch = 0.10812526039273496\n",
      "Cost on val dataset after 615 epochs is = 0.16074725995530575\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 615 = 0.16074725995530575\n",
      "Error on this batch = 0.12577766081774922\n",
      "Error on this batch = 0.10801136948349721\n",
      "Cost on val dataset after 616 epochs is = 0.16069141502642847\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 616 = 0.16069141502642847\n",
      "Error on this batch = 0.12569542061105715\n",
      "Error on this batch = 0.10785041450849633\n",
      "Cost on val dataset after 617 epochs is = 0.1606380131574032\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 617 = 0.1606380131574032\n",
      "Error on this batch = 0.1255970884902558\n",
      "Error on this batch = 0.10772284192701845\n",
      "Cost on val dataset after 618 epochs is = 0.16058531430688533\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 618 = 0.16058531430688533\n",
      "Error on this batch = 0.12555240008549212\n",
      "Error on this batch = 0.10762756366639276\n",
      "Cost on val dataset after 619 epochs is = 0.16053463735660173\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 619 = 0.16053463735660173\n",
      "Error on this batch = 0.12550405967595507\n",
      "Error on this batch = 0.10748313366266798\n",
      "Cost on val dataset after 620 epochs is = 0.1605057872272045\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 620 = 0.1605057872272045\n",
      "Error on this batch = 0.12547134738603283\n",
      "Error on this batch = 0.10735235959732388\n",
      "Cost on val dataset after 621 epochs is = 0.16045513777188872\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 621 = 0.16045513777188872\n",
      "Error on this batch = 0.1254275801182271\n",
      "Error on this batch = 0.10720303234759904\n",
      "Cost on val dataset after 622 epochs is = 0.16042267989869421\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 622 = 0.16042267989869421\n",
      "Error on this batch = 0.12540667369715777\n",
      "Error on this batch = 0.107080005755612\n",
      "Cost on val dataset after 623 epochs is = 0.1603720524002785\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 623 = 0.1603720524002785\n",
      "Error on this batch = 0.1253573351820957\n",
      "Error on this batch = 0.10694308854657343\n",
      "Cost on val dataset after 624 epochs is = 0.16034164969960862\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 624 = 0.16034164969960862\n",
      "Error on this batch = 0.12531968530249102\n",
      "Error on this batch = 0.10683707556025038\n",
      "Cost on val dataset after 625 epochs is = 0.16029364503639604\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 625 = 0.16029364503639604\n",
      "Error on this batch = 0.12529896088120313\n",
      "Error on this batch = 0.10672889198740965\n",
      "Cost on val dataset after 626 epochs is = 0.1602775456286607\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 626 = 0.1602775456286607\n",
      "Error on this batch = 0.12528931822917763\n",
      "Error on this batch = 0.10660950057083608\n",
      "Cost on val dataset after 627 epochs is = 0.16024714083400962\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 627 = 0.16024714083400962\n",
      "Error on this batch = 0.1252783294174854\n",
      "Error on this batch = 0.10648107729603787\n",
      "Cost on val dataset after 628 epochs is = 0.16022128591024265\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 628 = 0.16022128591024265\n",
      "Error on this batch = 0.1252800687334889\n",
      "Error on this batch = 0.1063532723538352\n",
      "Cost on val dataset after 629 epochs is = 0.1602026546079933\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 629 = 0.1602026546079933\n",
      "Error on this batch = 0.1252794377191139\n",
      "Error on this batch = 0.106233390943402\n",
      "Cost on val dataset after 630 epochs is = 0.16017221749710603\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 630 = 0.16017221749710603\n",
      "Error on this batch = 0.1252781336084119\n",
      "Error on this batch = 0.1061200517957474\n",
      "Cost on val dataset after 631 epochs is = 0.16014117047357637\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 631 = 0.16014117047357637\n",
      "Error on this batch = 0.125254050727101\n",
      "Error on this batch = 0.10600094796844062\n",
      "Cost on val dataset after 632 epochs is = 0.16010409667954018\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 632 = 0.16010409667954018\n",
      "Error on this batch = 0.125217061074595\n",
      "Error on this batch = 0.10588985960952778\n",
      "Cost on val dataset after 633 epochs is = 0.16006578534977717\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 633 = 0.16006578534977717\n",
      "Error on this batch = 0.12517838999039652\n",
      "Error on this batch = 0.105820193635981\n",
      "Cost on val dataset after 634 epochs is = 0.16001803804824125\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 634 = 0.16001803804824125\n",
      "Error on this batch = 0.12515031507399882\n",
      "Error on this batch = 0.10570946180060499\n",
      "Cost on val dataset after 635 epochs is = 0.15996772336737766\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 635 = 0.15996772336737766\n",
      "Error on this batch = 0.12509697134317124\n",
      "Error on this batch = 0.10560812750153346\n",
      "Cost on val dataset after 636 epochs is = 0.15992625352747714\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 636 = 0.15992625352747714\n",
      "Error on this batch = 0.12506536585512476\n",
      "Error on this batch = 0.10549374118627623\n",
      "Cost on val dataset after 637 epochs is = 0.15989387328556634\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 637 = 0.15989387328556634\n",
      "Error on this batch = 0.1250512033756587\n",
      "Error on this batch = 0.10539517966006696\n",
      "Cost on val dataset after 638 epochs is = 0.1598573665135432\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 638 = 0.1598573665135432\n",
      "Error on this batch = 0.1250174416085272\n",
      "Error on this batch = 0.10530507420761533\n",
      "Cost on val dataset after 639 epochs is = 0.15982427138393962\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 639 = 0.15982427138393962\n",
      "Error on this batch = 0.12499914342866283\n",
      "Error on this batch = 0.10520433213336007\n",
      "Cost on val dataset after 640 epochs is = 0.15979683914475748\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 640 = 0.15979683914475748\n",
      "Error on this batch = 0.12498132580113032\n",
      "Error on this batch = 0.10510972942193034\n",
      "Cost on val dataset after 641 epochs is = 0.15977282338040863\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 641 = 0.15977282338040863\n",
      "Error on this batch = 0.12494621923699802\n",
      "Error on this batch = 0.10500268485762998\n",
      "Cost on val dataset after 642 epochs is = 0.15975970388812036\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 642 = 0.15975970388812036\n",
      "Error on this batch = 0.12489613214625837\n",
      "Error on this batch = 0.10490522589302076\n",
      "Cost on val dataset after 643 epochs is = 0.15972788191011666\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 643 = 0.15972788191011666\n",
      "Error on this batch = 0.12483827785870996\n",
      "Error on this batch = 0.10481374330016074\n",
      "Cost on val dataset after 644 epochs is = 0.15968929961598027\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 644 = 0.15968929961598027\n",
      "Error on this batch = 0.12477817430325677\n",
      "Error on this batch = 0.10473017675009062\n",
      "Cost on val dataset after 645 epochs is = 0.15965887560824607\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 645 = 0.15965887560824607\n",
      "Error on this batch = 0.12473684908520669\n",
      "Error on this batch = 0.1046695178825205\n",
      "Cost on val dataset after 646 epochs is = 0.15962613482191124\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 646 = 0.15962613482191124\n",
      "Error on this batch = 0.12470202815436707\n",
      "Error on this batch = 0.10460953567095346\n",
      "Cost on val dataset after 647 epochs is = 0.15959179621606143\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 647 = 0.15959179621606143\n",
      "Error on this batch = 0.12464390350047716\n",
      "Error on this batch = 0.10452435133423325\n",
      "Cost on val dataset after 648 epochs is = 0.15956675054485142\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 648 = 0.15956675054485142\n",
      "Error on this batch = 0.12459264911747793\n",
      "Error on this batch = 0.10442197336874481\n",
      "Cost on val dataset after 649 epochs is = 0.15953628002615727\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 649 = 0.15953628002615727\n",
      "Error on this batch = 0.12450602370777031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.10432565658828793\n",
      "Cost on val dataset after 650 epochs is = 0.1595073603082412\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 650 = 0.1595073603082412\n",
      "Error on this batch = 0.12442718076719747\n",
      "Error on this batch = 0.10423537729498705\n",
      "Cost on val dataset after 651 epochs is = 0.15947055998779883\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 651 = 0.15947055998779883\n",
      "Error on this batch = 0.12435834930007839\n",
      "Error on this batch = 0.10414456614645279\n",
      "Cost on val dataset after 652 epochs is = 0.15946463426035107\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 652 = 0.15946463426035107\n",
      "Error on this batch = 0.12432369317015418\n",
      "Error on this batch = 0.10405247507888536\n",
      "Cost on val dataset after 653 epochs is = 0.15943353336459062\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 653 = 0.15943353336459062\n",
      "Error on this batch = 0.12425114483439549\n",
      "Error on this batch = 0.10393819090288245\n",
      "Cost on val dataset after 654 epochs is = 0.15940663875510028\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 654 = 0.15940663875510028\n",
      "Error on this batch = 0.12418749509628171\n",
      "Error on this batch = 0.1038349077336106\n",
      "Cost on val dataset after 655 epochs is = 0.15937555827165623\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 655 = 0.15937555827165623\n",
      "Error on this batch = 0.12410094923762924\n",
      "Error on this batch = 0.10374690882065636\n",
      "Cost on val dataset after 656 epochs is = 0.15935707873862895\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 656 = 0.15935707873862895\n",
      "Error on this batch = 0.12406230358029526\n",
      "Error on this batch = 0.10366027153461235\n",
      "Cost on val dataset after 657 epochs is = 0.159370460777218\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 657 = 0.159370460777218\n",
      "Error on this batch = 0.12402277395059376\n",
      "Error on this batch = 0.10359338605921017\n",
      "Cost on val dataset after 658 epochs is = 0.15932995495882638\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 658 = 0.15932995495882638\n",
      "Error on this batch = 0.12396654272621031\n",
      "Error on this batch = 0.10351478862353056\n",
      "Cost on val dataset after 659 epochs is = 0.15931436244687402\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 659 = 0.15931436244687402\n",
      "Error on this batch = 0.12390938043655059\n",
      "Error on this batch = 0.10344605600147047\n",
      "Cost on val dataset after 660 epochs is = 0.15933185051359922\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 660 = 0.15933185051359922\n",
      "Error on this batch = 0.12390810336849349\n",
      "Error on this batch = 0.10335983556421187\n",
      "Cost on val dataset after 661 epochs is = 0.15928455913338188\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 661 = 0.15928455913338188\n",
      "Error on this batch = 0.12385361836626668\n",
      "Error on this batch = 0.10327948677573298\n",
      "Cost on val dataset after 662 epochs is = 0.15929549485938185\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 662 = 0.15929549485938185\n",
      "Error on this batch = 0.1238658208403307\n",
      "Error on this batch = 0.10323534810192224\n",
      "Cost on val dataset after 663 epochs is = 0.15926931968068514\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 663 = 0.15926931968068514\n",
      "Error on this batch = 0.1238440502411606\n",
      "Error on this batch = 0.10319460237458326\n",
      "Cost on val dataset after 664 epochs is = 0.1592909388825565\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 664 = 0.1592909388825565\n",
      "Error on this batch = 0.12386244461366033\n",
      "Error on this batch = 0.10311079945380247\n",
      "Cost on val dataset after 665 epochs is = 0.15925527575509751\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 665 = 0.15925527575509751\n",
      "Error on this batch = 0.12384549387722318\n",
      "Error on this batch = 0.10304018678248862\n",
      "Cost on val dataset after 666 epochs is = 0.15927691108678999\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 666 = 0.15927691108678999\n",
      "Error on this batch = 0.12390344978956921\n",
      "Error on this batch = 0.1029825606755405\n",
      "Cost on val dataset after 667 epochs is = 0.1592465197736495\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 667 = 0.1592465197736495\n",
      "Error on this batch = 0.12383147147668477\n",
      "Error on this batch = 0.10291940978683478\n",
      "Cost on val dataset after 668 epochs is = 0.15924090683107037\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 668 = 0.15924090683107037\n",
      "Error on this batch = 0.12378752037067406\n",
      "Error on this batch = 0.10287192056299473\n",
      "Cost on val dataset after 669 epochs is = 0.15928328171701447\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 669 = 0.15928328171701447\n",
      "Error on this batch = 0.12380927055920914\n",
      "Error on this batch = 0.10281912021158181\n",
      "Cost on val dataset after 670 epochs is = 0.15925958804063217\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 670 = 0.15925958804063217\n",
      "Error on this batch = 0.12376965354658545\n",
      "Error on this batch = 0.1027650343746335\n",
      "Cost on val dataset after 671 epochs is = 0.15925215492424613\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 671 = 0.15925215492424613\n",
      "Error on this batch = 0.12374431968221794\n",
      "Error on this batch = 0.10271882376242893\n",
      "Cost on val dataset after 672 epochs is = 0.15925004012593577\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 672 = 0.15925004012593577\n",
      "Error on this batch = 0.12372251405728037\n",
      "Error on this batch = 0.10267436196950874\n",
      "Cost on val dataset after 673 epochs is = 0.15925581371489306\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 673 = 0.15925581371489306\n",
      "Error on this batch = 0.12371526657211103\n",
      "Error on this batch = 0.10263160027790978\n",
      "Cost on val dataset after 674 epochs is = 0.1592576839642285\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 674 = 0.1592576839642285\n",
      "Error on this batch = 0.12369930260559718\n",
      "Error on this batch = 0.10258268932789387\n",
      "Cost on val dataset after 675 epochs is = 0.15925168839218606\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 675 = 0.15925168839218606\n",
      "Error on this batch = 0.1236620725225556\n",
      "Error on this batch = 0.10251593536446266\n",
      "Cost on val dataset after 676 epochs is = 0.15925132260153926\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 676 = 0.15925132260153926\n",
      "Error on this batch = 0.12364004770284413\n",
      "Error on this batch = 0.10246158162416197\n",
      "Cost on val dataset after 677 epochs is = 0.1592382909975775\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 677 = 0.1592382909975775\n",
      "Error on this batch = 0.12360574611253529\n",
      "Error on this batch = 0.10240229181172801\n",
      "Cost on val dataset after 678 epochs is = 0.1592514979561087\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 678 = 0.1592514979561087\n",
      "Error on this batch = 0.1235914275643236\n",
      "Error on this batch = 0.10233047184168463\n",
      "Cost on val dataset after 679 epochs is = 0.1592535301896027\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 679 = 0.1592535301896027\n",
      "Error on this batch = 0.12357353899057795\n",
      "Error on this batch = 0.10226207200529341\n",
      "Cost on val dataset after 680 epochs is = 0.1592641488082577\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 680 = 0.1592641488082577\n",
      "Error on this batch = 0.12355633370571478\n",
      "Error on this batch = 0.10217909250095325\n",
      "Cost on val dataset after 681 epochs is = 0.15927000915488543\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 681 = 0.15927000915488543\n",
      "Error on this batch = 0.12355119349208053\n",
      "Error on this batch = 0.10209220666897512\n",
      "Cost on val dataset after 682 epochs is = 0.15926213887490284\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 682 = 0.15926213887490284\n",
      "Error on this batch = 0.12354168805960221\n",
      "Error on this batch = 0.10199667240515642\n",
      "Cost on val dataset after 683 epochs is = 0.15926929251588046\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 683 = 0.15926929251588046\n",
      "Error on this batch = 0.12353952154559367\n",
      "Error on this batch = 0.10190656568844161\n",
      "Cost on val dataset after 684 epochs is = 0.15928121519311572\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 684 = 0.15928121519311572\n",
      "Error on this batch = 0.12352481683070482\n",
      "Error on this batch = 0.10181810478751409\n",
      "Cost on val dataset after 685 epochs is = 0.15930604957307584\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 685 = 0.15930604957307584\n",
      "Error on this batch = 0.1235395870340814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on this batch = 0.10171523379054408\n",
      "Cost on val dataset after 686 epochs is = 0.15931466197653876\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 686 = 0.15931466197653876\n",
      "Error on this batch = 0.12352756142473954\n",
      "Error on this batch = 0.10162922260202757\n",
      "Cost on val dataset after 687 epochs is = 0.15933583491534817\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 687 = 0.15933583491534817\n",
      "Error on this batch = 0.12354028087790024\n",
      "Error on this batch = 0.10152474679017436\n",
      "Cost on val dataset after 688 epochs is = 0.1593517110688788\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 688 = 0.1593517110688788\n",
      "Error on this batch = 0.12356459092473268\n",
      "Error on this batch = 0.10143742367168823\n",
      "Cost on val dataset after 689 epochs is = 0.1593513879458478\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 689 = 0.1593513879458478\n",
      "Error on this batch = 0.1235511085490165\n",
      "Error on this batch = 0.10135306656444903\n",
      "Cost on val dataset after 690 epochs is = 0.15934146939129779\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 690 = 0.15934146939129779\n",
      "Error on this batch = 0.12354208046298397\n",
      "Error on this batch = 0.10126063827931656\n",
      "Cost on val dataset after 691 epochs is = 0.15935514578349577\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 691 = 0.15935514578349577\n",
      "Error on this batch = 0.12354917864341829\n",
      "Error on this batch = 0.10120286252806768\n",
      "Cost on val dataset after 692 epochs is = 0.1593671865758972\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 692 = 0.1593671865758972\n",
      "Error on this batch = 0.12356886776938515\n",
      "Error on this batch = 0.10113465600388834\n",
      "Cost on val dataset after 693 epochs is = 0.15938384786382176\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 693 = 0.15938384786382176\n",
      "Error on this batch = 0.12361271162196971\n",
      "Error on this batch = 0.10106656150823934\n",
      "Cost on val dataset after 694 epochs is = 0.15939989214415662\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 694 = 0.15939989214415662\n",
      "Error on this batch = 0.12364864650699371\n",
      "Error on this batch = 0.1009563725802531\n",
      "Cost on val dataset after 695 epochs is = 0.15941710802709014\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 695 = 0.15941710802709014\n",
      "Error on this batch = 0.12370026164538592\n",
      "Error on this batch = 0.10088329454146955\n",
      "Cost on val dataset after 696 epochs is = 0.15942764254465258\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 696 = 0.15942764254465258\n",
      "Error on this batch = 0.12373782797893312\n",
      "Error on this batch = 0.10079668866024818\n",
      "Cost on val dataset after 697 epochs is = 0.15944163059329805\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 697 = 0.15944163059329805\n",
      "Error on this batch = 0.12374411457916704\n",
      "Error on this batch = 0.10071643757053457\n",
      "Cost on val dataset after 698 epochs is = 0.15947736264977055\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 698 = 0.15947736264977055\n",
      "Error on this batch = 0.12377145262191665\n",
      "Error on this batch = 0.10063896105856582\n",
      "Cost on val dataset after 699 epochs is = 0.15949890977173398\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 699 = 0.15949890977173398\n",
      "Error on this batch = 0.12380518789020452\n",
      "Error on this batch = 0.10055111189659822\n",
      "Cost on val dataset after 700 epochs is = 0.15951588253217697\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 700 = 0.15951588253217697\n",
      "Error on this batch = 0.12383772909526404\n",
      "Error on this batch = 0.10045794108278645\n",
      "Cost on val dataset after 701 epochs is = 0.1595371313678628\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 701 = 0.1595371313678628\n",
      "Error on this batch = 0.12388364709390856\n",
      "Error on this batch = 0.10039601920094987\n",
      "Cost on val dataset after 702 epochs is = 0.1595479997304646\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 702 = 0.1595479997304646\n",
      "Error on this batch = 0.12392884136545984\n",
      "Error on this batch = 0.10032934056580889\n",
      "Cost on val dataset after 703 epochs is = 0.1595714488366861\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 703 = 0.1595714488366861\n",
      "Error on this batch = 0.12397888042558856\n",
      "Error on this batch = 0.10025531476393401\n",
      "Cost on val dataset after 704 epochs is = 0.15960052566681657\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 704 = 0.15960052566681657\n",
      "Error on this batch = 0.12404956147766104\n",
      "Error on this batch = 0.10017046314561351\n",
      "Cost on val dataset after 705 epochs is = 0.1596184402907504\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 705 = 0.1596184402907504\n",
      "Error on this batch = 0.12406583272435626\n",
      "Error on this batch = 0.10009166969202628\n",
      "Cost on val dataset after 706 epochs is = 0.15965277479648313\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 706 = 0.15965277479648313\n",
      "Error on this batch = 0.1241297645032459\n",
      "Error on this batch = 0.10004349407712614\n",
      "Cost on val dataset after 707 epochs is = 0.15965612046904942\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 707 = 0.15965612046904942\n",
      "Error on this batch = 0.12415885914979974\n",
      "Error on this batch = 0.09999639769884294\n",
      "Cost on val dataset after 708 epochs is = 0.1596724894712767\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 708 = 0.1596724894712767\n",
      "Error on this batch = 0.12420829514830121\n",
      "Error on this batch = 0.09994305819677513\n",
      "Cost on val dataset after 709 epochs is = 0.15968448782136638\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 709 = 0.15968448782136638\n",
      "Error on this batch = 0.12424660633763855\n",
      "Error on this batch = 0.09989802370420078\n",
      "Cost on val dataset after 710 epochs is = 0.15970229694545585\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 710 = 0.15970229694545585\n",
      "Error on this batch = 0.12430020535847268\n",
      "Error on this batch = 0.09986158980302393\n",
      "Cost on val dataset after 711 epochs is = 0.15972473913652852\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 711 = 0.15972473913652852\n",
      "Error on this batch = 0.12438138666353962\n",
      "Error on this batch = 0.09982251717244284\n",
      "Cost on val dataset after 712 epochs is = 0.15974242965976923\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 712 = 0.15974242965976923\n",
      "Error on this batch = 0.12443384649620909\n",
      "Error on this batch = 0.09977960607813373\n",
      "Cost on val dataset after 713 epochs is = 0.1597772904730011\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 713 = 0.1597772904730011\n",
      "Error on this batch = 0.12450054837384684\n",
      "Error on this batch = 0.0997348334395273\n",
      "Cost on val dataset after 714 epochs is = 0.1598048984026003\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 714 = 0.1598048984026003\n",
      "Error on this batch = 0.12455258896017447\n",
      "Error on this batch = 0.09971191198324716\n",
      "Cost on val dataset after 715 epochs is = 0.1598359239196823\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 715 = 0.1598359239196823\n",
      "Error on this batch = 0.1246147858738362\n",
      "Error on this batch = 0.09971272189246572\n",
      "Cost on val dataset after 716 epochs is = 0.1598651024922388\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 716 = 0.1598651024922388\n",
      "Error on this batch = 0.12467299067082245\n",
      "Error on this batch = 0.09970896388307594\n",
      "Cost on val dataset after 717 epochs is = 0.1598974745849206\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 717 = 0.1598974745849206\n",
      "Error on this batch = 0.12470364088582388\n",
      "Error on this batch = 0.09970005833666207\n",
      "Cost on val dataset after 718 epochs is = 0.1599310504264821\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 718 = 0.1599310504264821\n",
      "Error on this batch = 0.12474882818250475\n",
      "Error on this batch = 0.0996891824885083\n",
      "Cost on val dataset after 719 epochs is = 0.1599536331801559\n",
      "learning rate =  0.1\n",
      "Initial Cost on dataset for this epoch 719 = 0.1599536331801559\n",
      "Error on this batch = 0.12479708905041881\n",
      "Error on this batch = 0.09968706191133951\n",
      "Cost on val dataset after 720 epochs is = 0.15999695276114206\n",
      "cost initial= 0.1599536331801559 , cost final=0.15999695276114206 , change in cost= 4.3319580986161954e-05\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "The stats for number of units in the hidden layer arch= [100, 100] are as below:\n",
      "------------------------------------------------------------------------------\n",
      "The number of epochs = 720.000\n",
      "The training time = 438.756sec\n",
      "The training accuracy is = 87.059%\n",
      "The validation accuracy is = 82.359%\n",
      "The test accuracy is = 81.138%\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "epoch = 1\n",
    "start = time.time()\n",
    "#cost_init = cost_total(X_train, theta, train_class_enc, m) #Validation loss not giving much info\n",
    "cost_init = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0]) #Validation loss not giving much info\n",
    "costs.append(cost_init)\n",
    "early_stop= 0\n",
    "while(True):\n",
    "    count = 0\n",
    "    #lr = lr0/(np.power(epoch, 1/3))\n",
    "    #if(lr < 0.001): lr = 0.001\n",
    "    print(\"learning rate = \", lr)\n",
    "\n",
    "    print(\"Initial Cost on dataset for this epoch {} = {}\".format(epoch, cost_init))\n",
    "\n",
    "    for b in mini_batch:\n",
    "        X_b = b[0]\n",
    "        Y_b = b[1]\n",
    "        fm = forward_prop(X_b, theta)\n",
    "        delta = [None]*len(fm)\n",
    "\n",
    "        if (count % 60 == 0):\n",
    "            print(\"Error on this batch = \"+str(cost_total(X_b, theta, Y_b, batch_size)))\n",
    "        #Backward Propagation\n",
    "\n",
    "        for l in range(len(fm)-1, 0, -1):\n",
    "            if (l == len(fm)-1):\n",
    "                delta[l] = ((1/batch_size)*(Y_b - fm[l])*fm[l]*(1-fm[l]))\n",
    "                #print(\"delta for last layer=\",delta[l])\n",
    "            else:\n",
    "                delta[l]=np.dot(delta[l+1], theta[l].T)*deriv_relu(fm[l])\n",
    "                #print(\"delta for hidden layer=\",np.mean(delta[l]))\n",
    "\n",
    "        for t in range(len(theta)):\n",
    "            theta[t] += lr*np.dot(fm[t].T, delta[t+1])\n",
    "        \n",
    "        count+=1\n",
    "    epoch+=1 #Number of epochs\n",
    "    #ite+=1\n",
    "\n",
    "    #cost_final = cost_total(X_train, theta, train_class_enc, m)\n",
    "    cost_final = cost_total(X_valid, theta, valid_class_enc, X_valid.shape[0])\n",
    "    if(epoch%10==0): costs.append(cost_final)\n",
    "    print(\"Cost on val dataset after {} epochs is = {}\".format(epoch, cost_final))\n",
    "    \n",
    "    if ((cost_final-cost_init) > 0):\n",
    "        early_stop +=1\n",
    "    else:\n",
    "        early_stop=0\n",
    "    if (early_stop == 30):\n",
    "        print(\"cost initial= {} , cost final={} , change in cost= {}\".format(cost_init,cost_final, cost_final-cost_init))\n",
    "        break\n",
    "\n",
    "    cost_init = cost_final\n",
    "    \n",
    "    \n",
    "epochs.append(epoch)\n",
    "train_time.append(time.time()-start)\n",
    "train_accuracy.append(calc_accuracy(X_train, theta, train_class_enc))\n",
    "valid_accuracy.append(calc_accuracy(X_valid, theta, valid_class_enc))\n",
    "test_accuracy.append(calc_accuracy(X_test, theta, test_actual_class_enc))\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"The stats for number of units in the hidden layer arch= {} are as below:\".format(arch))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"The number of epochs = {:2.3f}\".format(epochs[-1]))\n",
    "print(\"The training time = {:2.3f}sec\".format(train_time[-1]))\n",
    "print(\"The training accuracy is = {:2.3f}%\".format(train_accuracy[-1]))\n",
    "print(\"The validation accuracy is = {:2.3f}%\".format(valid_accuracy[-1]))\n",
    "print(\"The test accuracy is = {:2.3f}%\".format(test_accuracy[-1]))\n",
    "print(\"------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12953123909740702"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_total(X_train, theta, train_class_enc, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5yU1Z3n8c+XpoEWkRbpiQFUiBIUowLp0XFMvMUoxgSdXF4xxqzOuOskG8dkjCaYZDIGMwnRmRhnx53EUTKbMdE46hjiZYl3jRuVVhBEQkRU7BYFUS5KA93Nb/94nm6KoqqpvlRXddX3/XrVi+dev6ou6lfnnOeco4jAzMws25BSB2BmZuXJCcLMzHJygjAzs5ycIMzMLCcnCDMzy8kJwszMcnKCsD2SVCPpHUkHljqWYpD0W0mf72b/TZKuGMCQekTSKZJeHsDn+ztJP+lm/3+X9PBAxWPF4wRRgdIv887HDkmtGet5vwjziYiOiNg7Ilb3IpZDJJV1Z5uIODUifgF9/3LrfL1Zf4N3JH2q3wIusYi4MiK+CP3z95XUnPEZfV3SPEkjCzw3b3KU9DtJ5xd6vO1uaKkDsP4XEXt3Lqf/Gf57RNyf73hJQyOifSBiqxaZfwMryOkR8bCkccBvga8Df1/imKqeSxBVSNL3JP1K0s2SNgPnSjpW0hOSNkhaI+mfJdWmxw9NfxVPTNdvSvffK2mzpN9LmtSLOEak11kjqUXSjyQNS/f9iaR70njekvRoxnnflPSapE2S/iDpxBzXnixpvSSl6z+T9FrG/pslXZQu/07S+ZKOAP4F+HD6a/bNjEuO6evrTZ/rJknXSXogvdZDkg7I2P8hSU2SNkp6StIxGfv2k/Tv6fv1tqTbs679dUnr0vfmv2Vs/7ik5enzNUv62zyxNUs6Kl0+L/2bT0nX/1rSbeny9yT9e3rao+m2zpLSn+68nK5J/36rJJ1ayPsTEa+RJIhpGXGNSD8br0p6Q9L/ljSikOtZ3zhBVK+/AH4JjAZ+BbQDXwHGAscBM4G/7ub8c4C/A8YAq4ErexHDd4BG4Ehgevq8l6f7LgNWAQ3A/sC3ASQdnsY1IyL2AU5Pn38XEfECsC29NsDxwFZJk9P1E4BHss5ZClwEPJZWqY3t59fb6VyS1z4WeB74j/S1jQXuBv4J2A/4X8A9kvZNz/slMAyYCvwJcG3GNScAdcA44IvAv0raJ933M+CCiBhF8n7s8rozPAqcmC6fQPL+H5+xnuu84yEpMaWPhen2PweWpq/jGuDGvO9GhjRZzgRWZmy+GpiUxj4ZmAh8q5DrWd84QVSv30XEbyJiR0S0RsTCiHgyItojYhVwPcmXQj63RURTRLQBvyDjF18PfB64IiLWRcRaYA7whXRfG8mX3YERsT0iOksQ7cAI4PC0auylNN5cHgFOkDQB2Arcma5PJvmifa4Hsfbo9aa/nDMfkzN2/yYiHo+IbcA3geMlvRf4BLAsIm5O/w7/QfIlfUb6xfkR4EsR8XZEtGW8J6Sv73vp9vkkyfH96b42YKqkURHxVkQ8kyfsR9j5N/8w8IOM9XwJIp8XI2JeRHQA/weYkCbAfO5KS7OrgWaSzwKShgD/A/hq+ro3pXGd3YNYrJecIKrXq5krkg6VdLeSRsJNJP9Bu/sP/XrG8hagN3Xu44BXMtZfAcany3PT9QckvSjpMoCIWAF8LY1vbVpVtH+e6z9C8ov4eJJfxw+TfNGdQFJK6Enjao9eb0TUZz1eyNj9asZxG4GNJO9F9vsBO9+TA4A30+NzeTP9Ms4V418As4DVkh7OrLbK8ghJshpPkohvI6luO4QkKS/t7jVnyX6/oPv37ONpCecjJCWkMen2/YHhwLOdyRa4i6QEtSftQG3WtlqShGkFcIKoXtlfjj8l+UV9SFp18x1ARY7hNeCgjPUDgRaAiNgUEX8bEROBs4BvSDoh3XdTRBxHUu1QQ/KLMpdHSJJD56/fx0h+GXf3a3gg7rjKbHMYTVLN9xq7vx+w8z15FRibUW1UsLRkOIvkS/Uu4JY8x/2B5Ev1y8AjEbEBeAv4K/In1H59vyLiQZIS2tXppjeA7cCUjGQ7OiJGF3C51STVUZkmsXsStjycIKzTKJJfsu9KOozu2x96LG1ozHwMAW4GviNprKQGkjr+m9LjPyHp4LSReSPQAeyQdJikkyQNB1rTx45czxkRy9Pzzib5wnsbeBs4k/wJ4g2S6pDsX5796RNKbgoYDnyP5Mt3DcmX9+GSPqvkxoBzgEOAuyPiVeB+4DpJ9ZJqJR2f/ykSkuoknSNpn7R6bDN53q/UoyTtMJ3vz8NZ69nWAiHpfXt81YW7BviYpA+kpaIbgB9LalBiQlajt3J8vkTStnaBpMb0vCkk7Ww5E6TtzgnCOn0NOI/kC+SnJP+5+lNr1uN44LvAsyQllyXAk+wsDUwBHgTeAR4Hro2Ix0iqG64C3iSpxtiX7hssHwXWpl/AkHzR7UifN5f7gBeANyS9nueYPdLu/SAuzth9E0lieJOk4fW/AUTEOpKqoG8A64G/Jal6eTs979z03z+SJLK/KTCc84BX0qrDCzKuk8sjJD8WHs2zvouI2EzyN3syrQJqLDCmvCLidZJSxN+lm75G8qv/KZIfC78laazudCC7f74Oioi702v8PD3vLpLG8nl9jbFayBMGmQ0cSTcBKyPiilLHYrYnLkGYmVlOThBmZpaTq5jMzCwnlyDMzCynog7WJ2kmyXAANcANETE3a//5JPc7t6Sb/iUibkj3nUc6vAJJD9H/091zjR07NiZOnNh/wZuZVYGnn376zYhoyLWvaAlCUg1wHfBRkq7zCyXNj4jnsw79VURclHXuGJKRHBtJOuI8nZ77NnlMnDiRpqamfn0NZmaVTlLejoPFrGI6muR2vlURsZ2kc8qZBZ57GnBfOm7M2yT3ps8sUpxmZpZDMRPEeHYd76eZnePsZPqUpCWSbtPOYY8LOlfShUqGRm5at25df8VtZmaUvpH6N8DEiDiSpJTQbTtDtoi4PiIaI6KxoSFnFZqZmfVSMRupW8gYlIxkvPqWzAMiYn3G6g0kQyh0nnti1rkP93uEZlaW2traaG5uZuvWraUOpWKMGDGCCRMmUFtb+DBjxUwQC4HJSmbeaiEZMO2czAMkvTdjjJxZwPJ0eQHw/YyJUk5l50QyZlbhmpubGTVqFBMnTiQZd8/6IiJYv349zc3NTJpU+GSIRUsQEdGuZErHBSS3uc6LiGWS5gBN6aQmF0uaRTLE8FvA+em5b0m6kiTJAMyJiLeKEeedi1q4esEKXtvQyrj6Oi47bQpnTc/VVGJmA2Xr1q1ODv1IEvvttx89bastaj+IiLgHuCdr23cyli8nT8kgIuZR5FEX71zUwuV3LKW1LZlnpWVDK5ffkcyJ4iRhVlpODv2rN+9nqRupS+rqBSu6kkOn1rYOrl6wokQRmZmVj6pOEK9taM25vWVDK5Nm381xcx/kzkUtOY8xs8q1fv16pk2bxrRp09h///0ZP3581/r27dsLusZf/uVfsmJF4T82b7jhBr761a/2NuSiKGoVU7kbV19HS54kESSJ4rL/fJbv/mYZG7a0dbVRALu0W5x0aAMP/WFdwetu5zDrX/3dlrjffvuxePFiAK644gr23ntvLr300l2OiQgigiFDcv/O/tnPftbr5y8XVV2CuOy0KdTV1nR7TNuO4O0tbbskjMtue5aWDa1d2256YnWP1i+/YynfvnMpx819sKukkr3ukotZYTrbErP/jxXj/9DKlSuZOnUqn//85zn88MNZs2YNF154IY2NjRx++OHMmTOn69gPfehDLF68mPb2durr65k9ezZHHXUUxx57LGvXri34OW+66SaOOOIIPvCBD/DNb34TgPb2dr7whS90bf/nf/5nAK655hqmTp3KkUceybnndjdxYGGqugTR+Quj85dHIQOft+3o+/DorW0d3PTE6q71ziSSuZ6r5OJSh1Wj7/5mGc+/tinv/kWrN7C9Y9dptlvbOvj6bUu4+anVOc+ZOm4f/v4Th/cqnj/84Q/8/Oc/p7ExmV117ty5jBkzhvb2dk466SQ+/elPM3Xq1F3O2bhxIyeccAJz587lkksuYd68ecyePXuPz9Xc3My3v/1tmpqaGD16NKeccgp33XUXDQ0NvPnmmyxdmtxUs2HDBgCuuuoqXnnlFYYNG9a1rS+qugQBSZJ4fPbJvDT3DMbX15U6nC7ZJZdi/SIyG+yyk8OetvfVwQcf3JUcAG6++WZmzJjBjBkzWL58Oc8/nz0eKdTV1XH66acD8MEPfpCXX365oOd68sknOfnkkxk7diy1tbWcc845PProoxxyyCGsWLGCiy++mAULFjB69GgADj/8cM4991x+8Ytf9KhDXD5VXYLIdtlpU3a57bWcdN5d5VKEVZs9/dI/bu6DOdsSx9fX8au/Prbf4xk5cmTX8gsvvMC1117LU089RX19Peeee27O3t/Dhg3rWq6pqaG9vb1PMey3334sWbKEe++9l+uuu47bb7+d66+/ngULFvDII48wf/58vv/977NkyRJqarqvRu9O1ZcgMp01fTw/+OQRjK+vQ0B9XS21NbveO1w7RLtt66nent2yodXtFGZZcrUl1tXWdN1QUkybNm1i1KhR7LPPPqxZs4YFCxb06/WPOeYYHnroIdavX097ezu33HILJ5xwAuvWrSMi+MxnPsOcOXN45pln6OjooLm5mZNPPpmrrrqKN998ky1btvTp+V2CyHLW9PG7/ErPdXcE9O0uppMObeD2p1t6VVLp/KXkTn1miey2xIFss5sxYwZTp07l0EMP5aCDDuK4447r0/VuvPFGbrvttq71pqYmrrzySk488UQigk984hOcccYZPPPMM1xwwQVEBJL44Q9/SHt7O+eccw6bN29mx44dXHrppYwaNapP8VTMnNSNjY0xmCYMyk48mUlkdF0t725vp61jz3+b8fV1PD775AGI2GzgLF++nMMOO6zUYVScXO+rpKcjojHX8S5BlEh2SSVbdgLJ118jX2c/M7O+coIoU9kJJF9D3LgyuvPKzCqLG6kHiVwNccOHDhmQhjizUqiU6u9y0Zv30wlikMi+w0ok7Q+zjhpX6tDM+t2IESNYv369k0Q/6ZwPYsSIET06z43Ug9SvFq7mG7cvpb6ulo2t7m1tlcUzyvW/fDPKuZG6Ag2rGcIQwYbWNsC3vVplqa2t7dHMZ1YcrmIapP7xt38ke1goz2VhZv3JCWKQynd7q297NbP+4gQxSOW7vdW3vZpZf3GCGKR826uZFZsbqQepXHNZHDVhtBuozazfFLUEIWmmpBWSVkrKOzuGpE9JCkmN6fpESa2SFqePnxQzzsEqcy6L8/98Ik+v3sDq9X0bvdHMrFPRShCSaoDrgI8CzcBCSfMj4vms40YBXwGezLrEixExrVjxVZovnXgw//H7l5l57aO0bu9wvwgz67NiliCOBlZGxKqI2A7cApyZ47grgR8C7hHTB79/cT1IbNne4VnozKxfFDNBjAdezVhvTrd1kTQDOCAi7s5x/iRJiyQ9IunDuZ5A0oWSmiQ1rVu3rt8CH4yuXrCCjqyOEe4XYWZ9UbK7mCQNAX4EfC3H7jXAgRExHbgE+KWkfbIPiojrI6IxIhobGhqKG3CZc78IM+tvxUwQLcABGesT0m2dRgEfAB6W9DLwZ8B8SY0RsS0i1gNExNPAi8D7ixjroOd+EWbW34qZIBYCkyVNkjQMOBuY37kzIjZGxNiImBgRE4EngFkR0SSpIW3kRtL7gMnAqiLGOuiVcl5eM6tMRbuLKSLaJV0ELABqgHkRsUzSHKApIuZ3c/rxwBxJbcAO4IsR8VaxYq0Emf0iOicW+tYZh/ouJjPrtaJ2lIuIe4B7srZ9J8+xJ2Ys3w7cXszYKlHnLHQrXt/MaT9+lAoZyd3MSsRDbVSgKfuP4tD9R/Hrxa+VOhQzG8ScICrUrGnjaHrlbV59yz2rzax3nCAq1CeOTKYinf+sSxFm1jtOEBXqgDF70XjQvsx3NZOZ9ZITRAWbuN9erHhjM5Nm381xcx/0sBtm1iNOEBXqzkUt3LV0DYDHZjKzXnGCqFBXL1jB1rYdu2zz2Exm1hNOEBXKYzOZWV85QVQoj81kZn3lBFGhPDaTmfWV56SuULnGZrrstPd7bCYzK5gTRAXrHJtp1bp3OPmfHqFmiAuMZlY4f2NUgfc17M37xo7k/uVvlDoUMxtEnCCqxEcO+xOeXPUW72xrL3UoZjZIOEFUiY8c9h62d+zgsT9W99zdZlY4J4gq0XjQvoyuq+U+VzOZWYGcIKrE0JohnDSlgYdXrKNjh2cSMrM9c4KoIh857D289e52Fq1+u9ShmNkg4ARRRU6Y0sDQIeL+5WtLHYqZDQJOEFVknxG1TBq7Fzc8tspDgJvZHrmjXBW5c1ELL6/fQnvaBtE5BDjgHtZmtpuiliAkzZS0QtJKSbO7Oe5TkkJSY8a2y9PzVkg6rZhxVourF6ygrWPXBmoPAW5m+RStBCGpBrgO+CjQDCyUND8ins86bhTwFeDJjG1TgbOBw4FxwP2S3h8RHcWKtxp4CHAz64liliCOBlZGxKqI2A7cApyZ47grgR8CWzO2nQncEhHbIuIlYGV6PesDDwFuZj1RzAQxHng1Y7053dZF0gzggIi4u6fnpudfKKlJUtO6de4hvCceAtzMeqJkdzFJGgL8CPhab68REddHRGNENDY0NPRfcBXqrOnj+cEnj2B8WmIQ8N1Zh7uB2sxyKuZdTC3AARnrE9JtnUYBHwAelgSwPzBf0qwCzrVe6hwC/IlV6zn7+ieoHapSh2RmZaqYJYiFwGRJkyQNI2l0nt+5MyI2RsTYiJgYEROBJ4BZEdGUHne2pOGSJgGTgaeKGGvVOWbSGA7aby9uXdhc6lDMrEwVLUFERDtwEbAAWA7cGhHLJM1JSwndnbsMuBV4Hvi/wJd9B1P/ksRnPjiB369az+r1W0odjpmVIUVUxsBtjY2N0dTUVOowBpU1G1v587kP8jcnHcIlp7qh2qwaSXo6Ihpz7fNQG1XsvaPrmPKeUVz30EoPvWFmu/FQG1XszkUtvLjuHTo7V3voDTPL5BJEFfPQG2bWHSeIKuahN8ysO04QVcxDb5hZd5wgqliuoTeGDx3ioTfMDHAjdVXrbIi+esEKXtvQSgB/OnFfN1CbGeAEUfU6h94A+MZtS/ivxS2s3byVPxk1osSRmVmpuYrJunzpxINp79jBjY+9VOpQzKwMOEFYl4ljRzJtQj3XP+o5q83MVUyW4c5FLSxbs4nOnhHuOGdW3VyCsC5XL1jBtvYdu2xzxzmz6uUEYV3ccc7MMjlBWBd3nDOzTE4Q1iVXx7ka4Y5zZlXKjdTWJbvj3N4jhrJ5azsHjNmrxJGZWSn0aMIgJZNH7xUR7xYvpN7xhEH9791t7Zz4jw+zV+0Q2ncEr23Yyrj6Oi47bYrvajKrEH2aMEjSzyXtI2kvYCmwUtIl/R2klZ+Rw4dy8qENvPJWKy0bthLsvPXV/SPMKl8hbRBHRsQm4CzgPuAg4PxiBmXl47EX3txtm299NasOhSSIWklDgTOBX0fEdmDHHs6xCrFmw9ac233rq1nlKyRB3ACsBvYFHpF0IPBOUaOysuFbX82q1x4TRERcExHjIuLUSFq0XwVOLuTikmZKWiFppaTZOfZ/UdJSSYsl/U7S1HT7REmt6fbFkn7S0xdm/SPXra91tZ4zwqwaFNJIfZGkfdLlnwJPAh8u4Lwa4DrgdGAq8LnOBJDhlxFxRERMA64CfpSx78WImJY+vljYy7H+dtb08fzgk0cwPqPEcMaR43wXk1kVKKQfxIUR8S+STgXeA/wPYB7wwT2cdzSwMiJWAUi6haQd4/nOA9LG704jgcLvubUB0zlnRETwhRuf4jeLW/jdC+t4Y9M23/ZqVsEKaYPo/NL+GPAfEfFsgeeNJ6mO6tScbtuFpC9LepGkBHFxxq5JkhZJekRSzhKLpAslNUlqWrduXQEhWV9I4qQpDWzrCF7ftM23vZpVuEK+6J+VdA/wceBeSXvTj7/0I+K6iDgY+Abw7XTzGuDAiJgOXAL8srOaK+vc6yOiMSIaGxoa+isk68a8x1/ebZtvezWrTIVUMf0lSXXSyojYImkscEEB57UAB2SsT0i35XML8K8AEbEN2JYuP52WMN4PuKt0iXnEV7PqUchdTB3AWODrkuYCfxoRiwq49kJgsqRJkoYBZwPzMw+QNDlj9QzghXR7Q9rIjaT3AZOBVQU8pxWZb3s1qx6F3MX0D8DXSb6gVwGXSfrens6LiHbgImABsBy4NSKWSZojaVZ62EWSlklaTFKVdF66/XhgSbr9NuCLEfFWD1+bFUGu216HDpFvezWrQHscrE/SEmBG+oVP2qv6mYg4cgDiK5gH6xs4dy5q6RrxtW5YDVu2dzB272Gsf2e772oyG2S6G6yv0OG+RwFvZyxbFeu87RXg1oWr+cbtS3nzne2A57E2qySF3MV0FfCMpBsk3UjSUDy3uGHZYHHtAyt3u6XNdzWZVYY9liAi4iZJDwHHpJu+A7QVNSobNHxXk1nlKqiKKSJagDs61yWtBg4sVlA2eIyrr6MlRzLwXU1mg19v56RWv0Zhg1auu5oANm9tY9Lsuzlu7oPuZW02SPU2QXjMJAN2HcxPwD4jkkLppq3tHorDbJDLW8Uk6RpyJwIBo4sWkQ06mXc1HTf3QTZtbd9lf2ejte9qMhtcumuDeK6bfZ6T2nJyo7VZ5cibICLixoEMxCqDG63NKkdv2yDMcsrXaD31vaM4bu6Dbrg2G0QK7UltVpDOdobOoTj2Hz2Cd7a2cd/ytV3HuLe12eDgBGH9LrPRGuCY79/P5m0duxzjhmuz8rfHBJHO//BXwMTM4yPiwuKFZZVk7aZtObe74dqsvBVSgvg18ATwO6BjD8ea7cYN12aDUyEJYmREfK3okVjFuuy0KVx+x1Ja23b+vhCwZXs7k2bf7SHCzcpUIXcx3Svp1KJHYhUru7d1bY0I4O0tbe5tbVbGCpkw6G2SntNbgO0kP/4iIsYUP7zCecKgwePP5z7Aaxu27rZ9fH0dj88+uQQRmVWvvk4YNLaf47EqtyZHcgA3WpuVm+7GYpocES8Ah+c5ZElxQrJK50Zrs8GhuxLEbOAC4Loc+wI4vigRWcXL1WgN8M62Njdam5WR7sZiuiD998MDF45Vg+ze1nsPr2Hztg42tiajwLqntVl5KGgsJkmHSvqkpHM6HwWeN1PSCkkrJc3Osf+LkpZKWizpd5KmZuy7PD1vhaTTCn9JNhicNX08j88+mZfmnsE+dcN22+95rc1Kr5Ce1N8GTgUOBRYAp5F0mvvlHs6rIame+ijQDCyUND8ins847JcR8ZP0+FnAj4CZaaI4m6T9Yxxwv6T3R4Q76lUgDxFuVp4KKUF8FjgJWBMRXwCOAkYWcN7RwMqIWBUR24FbgDMzD4iITRmrI9k5QdGZwC0RsS0iXgJWptezCpSvcdqN1malVUiCaE1/ubdLGgW8DhxUwHnjgVcz1pvTbbuQ9GVJLwJXARf38NwLJTVJalq3bl0BIVk5yjdE+IFj6jxEuFkJFZIgFkmqB+YBTcBT6aNfRMR1EXEw8A3g2z089/qIaIyIxoaGhv4KyQZYdk/rcfUjeM+oYfx+1Vu0bGh1b2uzEum2DUKSgCsiYgNwnaQFwD4R8UwB124BDshYn5Buy+cW4F97ea4NctlDhB/7gwd2O8ZDhJsNrG5LEJGMw3FfxvrKApMDwEJgsqRJkoaRNDrPzzxA0uSM1TOAF9Ll+cDZkoZLmgRMph9LLVb+Xt/o3tZmpVbIUBuLJU2PiEU9uXBEtEu6iOTOpxpgXkQskzQHaIqI+cBFkk4B2oC3gfPSc5dJuhV4HmgHvuw7mKqLe1ublV7ewfokDU2/5JcBU4AXgXfZOVjfjIELc888WF9luXNRS84hwuv3qmXDljb3tjbrJ70drO8pYAYwqyhRmXUju7f1sBqxrSN4e0sb4N7WZgOhuwQhgIh4cYBiMdtFZsN1riHC3WhtVlzdJYgGSZfk2xkRPypCPGY5eYhws4HXXYKoAfYmLUmYlZIbrc0GXncJYk1EzBmwSMy6kW+IcM9rbVY8e2yDMCsH2Y3WI2qH0Nq2w43WZkXUXUe5jwxYFGYFyBwifMzI4bvt9xDhZv0rb4KIiLcGMhCznvAQ4WbFV9CEQWblxkOEmxWfE4QNSvmGCH93W7uHBzfrJ4WMxWRWdrIbrfcaVsO72zvY0OpGa7P+4hKEDVqZjdb1e3lea7P+5gRhFcGN1mb9zwnCKoIbrc36nxOEVYR8jdaHjxvlea3NesmN1FYRshut9x89gne2tvHb59d2HeOGa7OecYKwipE9r/Ux37+fzdt2HbvJQ4SbFc5VTFax1m7alnO7G67NCuMEYRXLDddmfeMEYRUrb2/r7e5tbVYIt0FYxco3RPgGDxFuVpCiliAkzZS0QtJKSbNz7L9E0vOSlkh6QNJBGfs6JC1OH/OLGadVLg8RbtZ7RStBSKoBrgM+CjQDCyXNj4jnMw5bBDRGxBZJXwKuAj6b7muNiGnFis+qj3tbm/VMMUsQRwMrI2JVRGwHbgHOzDwgIh6KiC3p6hPAhCLGY1XOjdZmPVPMBDEeeDVjvTndls8FwL0Z6yMkNUl6QtJZuU6QdGF6TNO6dev6HrFVtHyN1hu2bHejtVkOZdFILelcoBE4IWPzQRHRIul9wIOSlkbEi5nnRcT1wPUAjY2NMWAB26CU3Wg9um4oG1vbeXd70pnOjdZmuypmCaIFOCBjfUK6bReSTgG+BcyKiK6eTRHRkv67CngYmF7EWK1KZDZajxxeS/avCjdam+1UzASxEJgsaZKkYcDZwC53I0maDvyUJDmszdi+r6Th6fJY4Dggs3HbrM/caG3WvaJVMUVEu6SLgAVADTAvIpZJmgM0RcR84Gpgb+A/JQGsjohZwGHATyXtIElic7PufjLrs3H1dbTkSAZ7D6/huLkP8tqGVsbV13HZaVNc5WRVSRGVUXXf2NgYTU1NpXN72CEAAA4XSURBVA7DBpE7F7Vw+R1LaW3r6Pa4utoafvDJI5wkrCJJejoiGnPt81AbVrXOmj6eH3zyCMbX1yFgfH0d+4zYvVDtdgmrVmVxF5NZqWQPET5p9t05j3O7hFUjlyDMMuTrNDdEcl8JqzpOEGYZ8nWm64gg2NlXwknCqoEThFmG7HaJIdr9GLdJWLVwG4RZlsx2CbdJWDVzCcKsG26TsGrmBGHWDbdJWDVzgjDrhtskrJq5DcJsD9wmYdXKJQizHsjfJoHbJKziOEGY9UD+NgncJmEVxwnCrAey2yRq3CZhFcxtEGY95DYJqxZOEGZ9kG9Oib2GeU4JG/xcxWTWB/naJN7d3kHLhla3S9ig5gRh1ge55pSor6vd7Ti3S9hg5BnlzPrZpNl3k+9/lcBVTlZWPKOc2QDK11cCfCusDS5OEGb9LF+7RCZXOdlg4LuYzPpZZ9XR1QtW8FraUJ2Lb4W1clfUEoSkmZJWSFopaXaO/ZdIel7SEkkPSDooY995kl5IH+cVM06z/nbW9PE8PvtkXpp7BuM9ZLgNUkVLEJJqgOuA04GpwOckTc06bBHQGBFHArcBV6XnjgH+HjgGOBr4e0n7FitWs2LykOE2WBWzBHE0sDIiVkXEduAW4MzMAyLioYjYkq4+AUxIl08D7ouItyLibeA+YGYRYzUrGg/PYYNVMdsgxgOvZqw3k5QI8rkAuLebc3e7J1DShcCFAAceeGBfYjUrKg/PYYNRWTRSSzoXaARO6Ml5EXE9cD0k/SCKEJpZv8s3PMfewz08h5WXYlYxtQAHZKxPSLftQtIpwLeAWRGxrSfnmg1G+dokNm/z8BxWXoqZIBYCkyVNkjQMOBuYn3mApOnAT0mSw9qMXQuAUyXtmzZOn5puMxv0cg3PMdrDc1gZKupQG5I+BvwYqAHmRcQ/SJoDNEXEfEn3A0cAa9JTVkfErPTcvwK+mW7/h4j4WXfP5aE2bDDz8BxWKt0NtVHUNoiIuAe4J2vbdzKWT+nm3HnAvOJFZ1Y+8rVLwK7DcwBOEjZgPNSGWRnw8BxWjpwgzMpAdrtEPi0bWt372gZMWdzmama79pU4bu6DrnKyknMJwqwMFVrl9LVbn3WJworGJQizMlToiLAd6V2ILlFYMXhGObNBoLsqp0z1dbWMHD7UvbGtYJ5RzmyQK6TKCWBDa5t7Y1u/cQnCbJC4c1FLV5XTEKmremlPaiR2RLhEYTl1V4JwgjAbhO5c1MLldyylta2jR+fVDhF7jxjKhi1tThgGlLAntZkVR3Yj9rj6OrZsb+ftLW3dnte2I7qOccO27YlLEGYVorelCjdsVzdXMZlVid62U2TKroY66dAGHvrDOieQCuUEYVaFelui2BO3Y1QWt0GYVaHsdorRdbW8u72dto6+/SjM1Y7R9Mpbu5QysksdLoUMTi5BmFWRzCqoQhu2i6GutoZPfXB8j5JKriQDuzbUOzH1nKuYzCynYlVDDYTaIQLRoxJRfyWmckky2Qm/N7E5QZhZXplfMv1VDVXJepNkelPa2dM1cv2t6mpr+MEnj+hRknCCMLOCZf8qzfyiyvWlJMg7mKAlelPayTZ0CEja4zXG19fx+OyTC76uG6nNrGCZ81LkkiuB3P50S4+qqaotqbTt6Purbd8BhbxrrxUwqGOhnCDMrEdyJZDGg8b0uPqkp0klW29+lVdDYhpXX9dv13KCMLM+21OpI5feJJX+qNfva2Iq5yRTV1vT9b70h6ImCEkzgWuBGuCGiJibtf944MfAkcDZEXFbxr4OYGm6ujoiZhUzVjMbWL1JKvmu0xN9TUy9STL90QaR6xrF7rRYtAQhqQa4Dvgo0AwslDQ/Ip7POGw1cD5waY5LtEbEtGLFZ2bVqT8SU0+TTDHuYhqIW26LWYI4GlgZEasAJN0CnAl0JYiIeDndt6OIcZiZ9aveJplSlJj6opgzyo0HXs1Yb063FWqEpCZJT0g6K9cBki5Mj2lat25dX2I1M7Ms5Tzl6EHpvbnnAD+WdHD2ARFxfUQ0RkRjQ0PDwEdoZlbBipkgWoADMtYnpNsKEhEt6b+rgIeB6f0ZnJmZda+YCWIhMFnSJEnDgLOB+YWcKGlfScPT5bHAcWS0XZiZWfEVLUFERDtwEbAAWA7cGhHLJM2RNAtA0p9KagY+A/xU0rL09MOAJknPAg8Bc7PufjIzsyKrmLGYJK0DXunDJcYCb/ZTOMU2WGIdLHGCYy0Wx1oc/RnrQRGRsxG3YhJEX0lqyjdgVbkZLLEOljjBsRaLYy2OgYq1nO9iMjOzEnKCMDOznJwgdrq+1AH0wGCJdbDECY61WBxrcQxIrG6DMDOznFyCMDOznJwgzMwsp6pPEJJmSlohaaWk2aWOJ5OkeZLWSnouY9sYSfdJeiH9d99SxthJ0gGSHpL0vKRlkr6Sbi+7eCWNkPSUpGfTWL+bbp8k6cn0s/CrdASAkpNUI2mRpLvS9bKME0DSy5KWSlosqSndVo6fgXpJt0n6g6Tlko4t0zinpO9l52OTpK8OVKxVnSAy5qw4HZgKfE7S1NJGtYt/B2ZmbZsNPBARk4EH0vVy0A58LSKmAn8GfDl9L8sx3m3AyRFxFDANmCnpz4AfAtdExCHA28AFJYwx01dIRiPoVK5xdjopIqZl3Kdfjp+Ba4H/GxGHAkeRvL9lF2dErEjfy2nAB4EtwH8xULFGRNU+gGOBBRnrlwOXlzqurBgnAs9lrK8A3psuvxdYUeoY88T9a5LJoso6XmAv4BngGJKeqUNzfTZKGN+E9AvgZOAukhkvyy7OjHhfBsZmbSurzwAwGniJ9Cadco0zR9ynAo8PZKxVXYKg73NWlMJ7ImJNuvw68J5SBpOLpIkko+8+SZnGm1bbLAbWAvcBLwIbIhlDDMrns/Bj4OtA56Ra+1GecXYK4LeSnpZ0Ybqt3D4Dk4B1wM/SqrsbJI2k/OLMdjZwc7o8ILFWe4IY1CL5+VBW9ylL2hu4HfhqRGzK3FdO8UZERyTF9gkksx8eWuKQdiPp48DaiHi61LH0wIciYgZJte2X03nnu5TJZ2AoMAP414iYDrxLVhVNmcTZJW1nmgX8Z/a+YsZa7QmiT3NWlMgbkt4LkP67tsTxdJFUS5IcfhERd6SbyzZegIjYQDJi8LFAvaTOaXjL4bNwHDBL0svALSTVTNdSfnF2iZ3zuKwlqSs/mvL7DDQDzRHxZLp+G0nCKLc4M50OPBMRb6TrAxJrtSeIXs9ZUULzgfPS5fNI6vpLTpKAG4HlEfGjjF1lF6+kBkn16XIdSVvJcpJE8en0sJLHGhGXR8SEiJhI8tl8MCI+T5nF2UnSSEmjOpdJ6syfo8w+AxHxOvCqpCnppo+QzDdTVnFm+Rw7q5dgoGItdcNLqR/Ax4A/ktRBf6vU8WTFdjOwBmgj+dVzAUkd9APAC8D9wJhSx5nG+iGSYu4SYHH6+Fg5xgscCSxKY30O+E66/X3AU8BKkqL88FLHmhHzicBd5RxnGtez6WNZ5/+nMv0MTAOa0s/AncC+5RhnGutIYD0wOmPbgMTqoTbMzCynaq9iMjOzPJwgzMwsJycIMzPLyQnCzMxycoIwM7OcnCDMMkh6WFLRJ4OXdHE6iugviv1cWc97haRLB/I5bfAauudDzKwQkobGzjGS9uR/AqdERHMxYzLrC5cgbNCRNDH99f1v6XwOv017RO9SApA0Nh2mAknnS7ozHTv/ZUkXSbokHaztCUljMp7iC+nY+89JOjo9f6SS+TmeSs85M+O68yU9SNJxKTvWS9LrPCfpq+m2n5B0KrtX0t9mHV8j6WpJCyUtkfTX6fYTJT0q6W4l85f8RNKQdN/n0jkYnpP0w4xrzZT0jJJ5LzJjm5q+T6skXZzx+u5Oj31O0mf78jeyClHqXoJ++NHTB8kQ6O3AtHT9VuDcdPlhoDFdHgu8nC6fT9LzeBTQAGwEvpjuu4ZkcMHO8/8tXT6edKh14PsZz1FP0vt+ZHrdZnL0ZCUZv39petzeJL2Lp6f7XiZrWOx0+4XAt9Pl4SS9fSeR9KTeSpJYakhGoP00MA5Ynb6mocCDwFnp+qvApPRaY9J/rwD+X3rtsSQ9dGuBT3W+7vS40YX8Lfyo7IermGyweikiFqfLT5MkjT15KCI2A5slbQR+k25fSjL8RqebASLiUUn7pOM2nUoycF5n/f0I4MB0+b6IeCvH830I+K+IeBdA0h3Ah0mG+cjnVOBISZ1jLY0GJgPbgaciYlV6rZvT67cBD0fEunT7L0gSWwfwaES8lL6WzPjujohtwDZJa0mGil4K/FNaArkrIh7rJkarEk4QNlhty1juAOrS5XZ2Vp2O6OacHRnrO9j1/0L2+DNBMlHPpyJiReYOSceQDBfdXwT8TUQsyHqeE/PE1RvZ793QiPijpBkk42d9T9IDETGnl9e3CuE2CKs0L5NU7cDOEU976rMAkj4EbIyIjcAC4G/SUWuRNL2A6zwGnCVpr3R0079It3VnAfCldOh0JL0/PRfg6HTk4SFpjL8jGbTvhLS9pYZk1M9HgCeA4yVNSq8zJvuJMkkaB2yJiJuAq0mGv7Yq5xKEVZp/BG5VMpvZ3b28xlZJi0jq5v8q3XYlyexuS9Iv6JeAj3d3kYh4RtK/k3yJA9wQEd1VLwHcQFJd9kyajNaRtClAMjz9vwCHkAz5/V8RsUPS7HRdJNVHvwZI34M70njXkgxrns8RwNWSdpBUW31pD3FaFfBormaDQFrFdGlEdJuUzPqTq5jMzCwnlyDMzCwnlyDMzCwnJwgzM8vJCcLMzHJygjAzs5ycIMzMLKf/D8KwZvG7zuFPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Train Loss with Epochs with ReLU\")\n",
    "x = np.arange(0,len(costs[1:300]))\n",
    "ax.plot(x, costs[1:300], marker='o', label='Train Loss')\n",
    "ax.set_xlabel(\"number of epochs\")\n",
    "ax.set_ylabel(\"Train Loss\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"relu_trainloss.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Loss with Epochs\")\n",
    "x = np.arange(0,len(costs[1:]))\n",
    "ax.plot(x, costs[1:], marker='o', label='Train Accuracy')\n",
    "ax.set_xlabel(\"number of epochs\")\n",
    "ax.set_ylabel(\"Train Loss\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig(\"accuracy_HiddenUnit_val20per.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

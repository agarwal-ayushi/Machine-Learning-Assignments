{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Reading the Data-------------------------\n",
      "----------------Data Reading completed-------------------\n",
      "The total number of training samples = 13000\n",
      "The number of features = 784\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------Reading the Data-------------------------\")\n",
    "PATH = os.getcwd()\n",
    "os.chdir('Alphabets/')\n",
    "\n",
    "X_train = pd.read_csv('train.csv', sep=',', header=None, index_col=False)\n",
    "X_test = pd.read_csv('test.csv', sep=',', header=None, index_col=False)\n",
    "\n",
    "train_class = X_train[X_train.columns[-1]]\n",
    "test_actual_class = X_test[X_test.columns[-1]]\n",
    "\n",
    "X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "print(\"----------------Data Reading completed-------------------\")\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "m = X_train.shape[0] # Number of Training Samples\n",
    "n = X_train.shape[1] # Number of input features\n",
    "\n",
    "print(\"The total number of training samples = {}\".format(m))\n",
    "print(\"The number of features = {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Perform 1-hot encoding of class labels------------\n"
     ]
    }
   ],
   "source": [
    "#To get the one hot encoding of each label\n",
    "print(\"--------Perform 1-hot encoding of class labels------------\")\n",
    "\n",
    "train_class_enc = pd.get_dummies(train_class).to_numpy()\n",
    "test_actual_class_enc = pd.get_dummies(test_actual_class).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the intercept term to the data samples both in training and test dataset\n",
    "X_train = np.hstack((np.ones((m,1)),X_train.to_numpy()))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "arch = [10] #means one hidden layer with 2 perceptrons \n",
    "M = 100 # Mini-Batch Size\n",
    "r = np.max(train_class) + 1 # Default value of the number of classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = np.random.random((n+1,arch[0]))\n",
    "theta2 = np.random.random((arch[0],r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.9520288128047689\n",
      "Error = 0.0739838002926372\n",
      "Error = 0.0739645176161679\n"
     ]
    }
   ],
   "source": [
    "for it in range(60000):\n",
    "    # Forward Propagation\n",
    "    l0 = X_train\n",
    "    l1 = activation(np.dot(l0, theta1))\n",
    "    l2 = activation(np.dot(l1, theta2))\n",
    "\n",
    "    if (it % 5000 == 0):\n",
    "        print(\"Error = \"+str(np.mean(np.abs(train_class_enc-l2))))\n",
    "\n",
    "    #Backward Propagation\n",
    "    delta_l2 = (1/m)*(train_class_enc - l2)*l2*(1-l2)\n",
    "\n",
    "    delta_l1 = np.dot(delta_l2, theta2.T)*l1*(1-l1)\n",
    "\n",
    "    theta1 += lr*np.dot(l0.T, delta_l1)\n",
    "    theta2 += lr*np.dot(l1.T, delta_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, theta):\n",
    "    l0 = data\n",
    "    l1 = activation(np.dot(l0, theta[0]))\n",
    "    l2 = activation(np.dot(l1, theta[1]))\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_class = forward_prop(X_test, [theta1, theta2])\n",
    "test_acc = 0\n",
    "for i in range(len(test_actual_class_enc)):\n",
    "    if (np.array_equal(test_pred_class[i], test_actual_class_enc[i])):\n",
    "        test_acc++\n",
    "test_acc /= X_test.shape[0]\n",
    "\n",
    "print(\"The Test Accuracy of the model = {}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-Batch\n",
    "\n",
    "batch_size = M\n",
    "mini_batch = [(X_train[i:i+r,:], train_class_enc[i:i+r]) for i in range(0, m, M)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
